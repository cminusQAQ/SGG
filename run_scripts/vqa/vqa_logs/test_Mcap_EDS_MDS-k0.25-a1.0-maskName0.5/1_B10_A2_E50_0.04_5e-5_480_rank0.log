2022-10-11 17:12:35 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-11 17:12:35 - utils.py[line:261] - INFO: Start init
2022-10-11 17:12:35 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-11 17:12:35 - utils.py[line:261] - INFO: Start init
2022-10-11 17:12:36 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-11 17:12:36 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-11 17:12:36 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-11 17:12:36 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-11 17:12:43 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 10, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=10, batch_size_valid='8', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=50, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[2], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-11 17:12:43 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-11 17:12:43 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-11 17:12:48 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-11 17:12:48 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-11 17:12:48 - train.py[line:119] - INFO: model: OFAModel
2022-10-11 17:12:48 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-11 17:12:48 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-11 17:12:48 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-11 17:12:48 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-11 17:12:48 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-11 17:12:49 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-11 17:12:49 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-11 17:12:49 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-11 17:12:49 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-11 17:12:49 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-11 17:12:49 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 10
2022-10-11 17:12:49 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt
2022-10-11 17:13:16 - trainer.py[line:605] - INFO: Loading EMA from checkpoint
2022-10-11 17:13:16 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-11 17:13:16 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-10-11 17:13:17 - trainer.py[line:612] - INFO: Loading EMA fp32 params from checkpoint
2022-10-11 17:13:17 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt (epoch 8 @ 0 updates)
2022-10-11 17:13:17 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 0 row count 578200 total row count 1156400
2022-10-11 17:13:19 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 1 row count 578200 total row count 1156400
Total steps 1445500, warmup steps 57820, warmup_factor 1.7295053614666207e-05
2022-10-11 17:13:19 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-11 17:13:19 - train.py[line:312] - INFO: Start iterating over samples
Total steps 1445500, warmup steps 57820, warmup_factor 1.7295053614666207e-05
2022-10-11 17:13:46 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 28910 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=49.5, ups=0.45, wpb=110.8, bsz=40, num_updates=10, lr=8.64753e-09, gnorm=2.337, clip=100, loss_scale=128, train_wall=26, gb_free=22.7, ema_decay=0.9999, wall=57
2022-10-11 17:14:10 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 28910 loss=0.865, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=47.4, ups=0.43, wpb=109.6, bsz=40, num_updates=20, lr=1.72951e-08, gnorm=2.561, clip=100, loss_scale=128, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=80
2022-10-11 17:14:32 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 28910 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=49.8, ups=0.45, wpb=111.1, bsz=40, num_updates=30, lr=2.59426e-08, gnorm=2.589, clip=100, loss_scale=128, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=103
2022-10-11 17:14:54 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 28910 loss=0.802, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=50.5, ups=0.45, wpb=111.6, bsz=40, num_updates=40, lr=3.45901e-08, gnorm=2.361, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=125
2022-10-11 17:15:17 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 28910 loss=0.81, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=48.5, ups=0.44, wpb=109.4, bsz=40, num_updates=50, lr=4.32376e-08, gnorm=2.406, clip=100, loss_scale=128, train_wall=22, gb_free=22.9, ema_decay=0.9999, wall=147
2022-10-11 17:15:39 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 28910 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=48.6, ups=0.44, wpb=111.1, bsz=40, num_updates=60, lr=5.18852e-08, gnorm=2.262, clip=100, loss_scale=128, train_wall=23, gb_free=22.5, ema_decay=0.9999, wall=170
2022-10-11 17:16:02 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 28910 loss=0.77, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=49.3, ups=0.45, wpb=109.8, bsz=40, num_updates=70, lr=6.05327e-08, gnorm=2.4, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=192
2022-10-11 17:16:24 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 28910 loss=0.76, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=49.1, ups=0.45, wpb=110, bsz=40, num_updates=80, lr=6.91802e-08, gnorm=2.101, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=215
2022-10-11 17:16:47 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 28910 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=49, ups=0.44, wpb=111, bsz=40, num_updates=90, lr=7.78277e-08, gnorm=2.407, clip=100, loss_scale=128, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=238
2022-10-11 17:17:10 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 28910 loss=0.803, loss_v1=0, loss_v2=0, nll_loss=0.715, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=48.4, ups=0.44, wpb=110.1, bsz=40, num_updates=100, lr=8.64753e-08, gnorm=2.567, clip=100, loss_scale=128, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=260
2022-10-11 17:17:32 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 28910 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=49, ups=0.45, wpb=110, bsz=40, num_updates=110, lr=9.51228e-08, gnorm=2.469, clip=100, loss_scale=128, train_wall=22, gb_free=23, ema_decay=0.9999, wall=283
2022-10-11 17:17:54 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 28910 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=49.5, ups=0.45, wpb=111.2, bsz=40, num_updates=120, lr=1.0377e-07, gnorm=2.421, clip=100, loss_scale=128, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=305
2022-10-11 17:18:17 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 28910 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=48.4, ups=0.44, wpb=110.8, bsz=40, num_updates=130, lr=1.12418e-07, gnorm=2.553, clip=100, loss_scale=128, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=328
2022-10-11 17:18:40 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 28910 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=49.3, ups=0.44, wpb=110.9, bsz=40, num_updates=140, lr=1.21065e-07, gnorm=2.589, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=351
2022-10-11 17:19:03 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 28910 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=47.4, ups=0.43, wpb=110.6, bsz=40, num_updates=150, lr=1.29713e-07, gnorm=2.459, clip=100, loss_scale=128, train_wall=23, gb_free=23, ema_decay=0.9999, wall=374
2022-10-11 17:19:28 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 28910 loss=0.821, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=45.1, ups=0.41, wpb=110.5, bsz=40, num_updates=160, lr=1.3836e-07, gnorm=2.487, clip=100, loss_scale=128, train_wall=24, gb_free=22.8, ema_decay=0.9999, wall=398
2022-10-11 17:19:52 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 28910 loss=0.862, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=45.3, ups=0.41, wpb=111, bsz=40, num_updates=170, lr=1.47008e-07, gnorm=2.605, clip=100, loss_scale=128, train_wall=24, gb_free=22.8, ema_decay=0.9999, wall=423
2022-10-11 17:20:18 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 28910 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=43.5, ups=0.39, wpb=111.4, bsz=40, num_updates=180, lr=1.55655e-07, gnorm=2.119, clip=100, loss_scale=128, train_wall=25, gb_free=22.8, ema_decay=0.9999, wall=449
2022-10-11 17:20:42 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 28910 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=45.9, ups=0.41, wpb=111.8, bsz=40, num_updates=190, lr=1.64303e-07, gnorm=2.261, clip=100, loss_scale=128, train_wall=24, gb_free=22.5, ema_decay=0.9999, wall=473
2022-10-11 17:21:08 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 28910 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=42.9, ups=0.39, wpb=109.9, bsz=40, num_updates=200, lr=1.72951e-07, gnorm=2.64, clip=100, loss_scale=128, train_wall=25, gb_free=23, ema_decay=0.9999, wall=499
2022-10-11 17:21:34 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 28910 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=41.9, ups=0.38, wpb=110.7, bsz=40, num_updates=210, lr=1.81598e-07, gnorm=2.164, clip=100, loss_scale=128, train_wall=26, gb_free=22.7, ema_decay=0.9999, wall=525
2022-10-11 17:22:00 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 28910 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=42.2, ups=0.38, wpb=109.8, bsz=40, num_updates=220, lr=1.90246e-07, gnorm=2.039, clip=90, loss_scale=128, train_wall=26, gb_free=23, ema_decay=0.9999, wall=551
2022-10-11 17:22:24 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 28910 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=46, ups=0.41, wpb=110.9, bsz=40, num_updates=230, lr=1.98893e-07, gnorm=2.333, clip=100, loss_scale=128, train_wall=24, gb_free=22.6, ema_decay=0.9999, wall=575
2022-10-11 17:22:50 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 28910 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=44.1, ups=0.4, wpb=111.4, bsz=40, num_updates=240, lr=2.07541e-07, gnorm=1.993, clip=100, loss_scale=128, train_wall=25, gb_free=23.1, ema_decay=0.9999, wall=601
2022-10-11 17:23:14 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 28910 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=45.3, ups=0.41, wpb=109.5, bsz=40, num_updates=250, lr=2.16188e-07, gnorm=2.297, clip=100, loss_scale=128, train_wall=24, gb_free=22.9, ema_decay=0.9999, wall=625
2022-10-11 17:23:38 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 28910 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=46.1, ups=0.42, wpb=110.5, bsz=40, num_updates=260, lr=2.24836e-07, gnorm=2.097, clip=100, loss_scale=128, train_wall=24, gb_free=22.8, ema_decay=0.9999, wall=649
2022-10-11 17:24:02 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 28910 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=44.6, ups=0.41, wpb=108.9, bsz=40, num_updates=270, lr=2.33483e-07, gnorm=2.383, clip=100, loss_scale=128, train_wall=24, gb_free=22.8, ema_decay=0.9999, wall=673
2022-10-11 17:24:29 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 28910 loss=0.808, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=41.6, ups=0.38, wpb=109.6, bsz=40, num_updates=280, lr=2.42131e-07, gnorm=2.346, clip=100, loss_scale=128, train_wall=26, gb_free=22.7, ema_decay=0.9999, wall=699
2022-10-11 17:24:53 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 28910 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=44.4, ups=0.4, wpb=110, bsz=40, num_updates=290, lr=2.50778e-07, gnorm=1.997, clip=100, loss_scale=128, train_wall=25, gb_free=22.8, ema_decay=0.9999, wall=724
2022-10-11 17:25:20 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 28910 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=41.3, ups=0.38, wpb=109.8, bsz=40, num_updates=300, lr=2.59426e-07, gnorm=2.037, clip=100, loss_scale=128, train_wall=26, gb_free=22.9, ema_decay=0.9999, wall=751
2022-10-11 17:25:47 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 28910 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=40.3, ups=0.37, wpb=110.2, bsz=40, num_updates=310, lr=2.68073e-07, gnorm=1.775, clip=100, loss_scale=128, train_wall=27, gb_free=22.8, ema_decay=0.9999, wall=778
2022-10-11 17:26:16 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 28910 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=39.1, ups=0.35, wpb=111.3, bsz=40, num_updates=320, lr=2.76721e-07, gnorm=1.815, clip=100, loss_scale=128, train_wall=28, gb_free=23, ema_decay=0.9999, wall=807
2022-10-11 17:26:44 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 28910 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=39.2, ups=0.35, wpb=110.5, bsz=40, num_updates=330, lr=2.85368e-07, gnorm=2.051, clip=90, loss_scale=128, train_wall=28, gb_free=22.8, ema_decay=0.9999, wall=835
2022-10-11 17:27:12 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 28910 loss=0.773, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=40.2, ups=0.36, wpb=111.2, bsz=40, num_updates=340, lr=2.94016e-07, gnorm=2.102, clip=100, loss_scale=128, train_wall=27, gb_free=23, ema_decay=0.9999, wall=863
2022-10-11 17:27:37 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 28910 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=45.3, ups=0.41, wpb=111.8, bsz=40, num_updates=350, lr=3.02663e-07, gnorm=1.793, clip=100, loss_scale=128, train_wall=25, gb_free=22.8, ema_decay=0.9999, wall=887
2022-10-11 17:28:00 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 28910 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=47.5, ups=0.43, wpb=110.2, bsz=40, num_updates=360, lr=3.11311e-07, gnorm=2.346, clip=100, loss_scale=128, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=911
2022-10-11 17:28:16 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 28910 loss=0.741, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=67.1, ups=0.61, wpb=110.4, bsz=40, num_updates=370, lr=3.19958e-07, gnorm=1.914, clip=100, loss_scale=128, train_wall=16, gb_free=22.8, ema_decay=0.9999, wall=927
2022-10-11 17:28:28 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 28910 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=92.4, ups=0.84, wpb=109.9, bsz=40, num_updates=380, lr=3.28606e-07, gnorm=1.792, clip=100, loss_scale=128, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=939
2022-10-11 17:28:40 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 28910 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=94.4, ups=0.85, wpb=111, bsz=40, num_updates=390, lr=3.37254e-07, gnorm=1.559, clip=100, loss_scale=128, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=951
2022-10-11 17:28:52 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 28910 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=93.3, ups=0.84, wpb=110.5, bsz=40, num_updates=400, lr=3.45901e-07, gnorm=1.74, clip=100, loss_scale=128, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=963
2022-10-11 17:29:04 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 28910 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=92.3, ups=0.84, wpb=109.5, bsz=40, num_updates=410, lr=3.54549e-07, gnorm=1.51, clip=90, loss_scale=128, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=974
2022-10-11 17:29:26 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 28910 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=50.2, ups=0.45, wpb=110.4, bsz=40, num_updates=420, lr=3.63196e-07, gnorm=1.476, clip=90, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=996
2022-10-11 17:29:48 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 28910 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=48.8, ups=0.44, wpb=111.3, bsz=40, num_updates=430, lr=3.71844e-07, gnorm=1.368, clip=80, loss_scale=128, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=1019
2022-10-11 17:30:11 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 28910 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=48.6, ups=0.44, wpb=109.6, bsz=40, num_updates=440, lr=3.80491e-07, gnorm=1.641, clip=100, loss_scale=128, train_wall=22, gb_free=22.9, ema_decay=0.9999, wall=1042
2022-10-11 17:30:34 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 28910 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=49.1, ups=0.44, wpb=110.8, bsz=40, num_updates=450, lr=3.89139e-07, gnorm=1.544, clip=90, loss_scale=128, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=1064
2022-10-11 17:30:57 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 28910 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=47.2, ups=0.43, wpb=109.6, bsz=40, num_updates=460, lr=3.97786e-07, gnorm=1.47, clip=90, loss_scale=128, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=1088
2022-10-11 17:31:19 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 28910 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=50.3, ups=0.46, wpb=110.3, bsz=40, num_updates=470, lr=4.06434e-07, gnorm=1.274, clip=60, loss_scale=128, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=1110
2022-10-11 17:31:41 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 28910 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=49.7, ups=0.46, wpb=109.2, bsz=40, num_updates=480, lr=4.15081e-07, gnorm=1.295, clip=80, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=1132
2022-10-11 17:32:03 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 28910 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=48.8, ups=0.44, wpb=110.4, bsz=40, num_updates=490, lr=4.23729e-07, gnorm=1.152, clip=60, loss_scale=128, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=1154
2022-10-11 17:32:27 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 28910 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.621, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=47.7, ups=0.43, wpb=110, bsz=40, num_updates=500, lr=4.32376e-07, gnorm=1.248, clip=70, loss_scale=128, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=1177
2022-10-11 17:32:50 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 28910 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=47.5, ups=0.44, wpb=108.7, bsz=40, num_updates=510, lr=4.41024e-07, gnorm=1.212, clip=80, loss_scale=128, train_wall=23, gb_free=23, ema_decay=0.9999, wall=1201
2022-10-11 17:33:14 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 28910 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=49.7, ups=0.45, wpb=111.5, bsz=40, num_updates=520, lr=4.49671e-07, gnorm=1.044, clip=40, loss_scale=256, train_wall=22, gb_free=22.6, ema_decay=0.9999, wall=1223
2022-10-11 17:33:35 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=51.1, ups=0.46, wpb=111, bsz=40, num_updates=530, lr=4.58319e-07, gnorm=1.314, clip=60, loss_scale=256, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=1246
2022-10-11 17:33:58 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 28910 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=48.6, ups=0.44, wpb=110.1, bsz=40, num_updates=540, lr=4.66966e-07, gnorm=0.833, clip=30, loss_scale=256, train_wall=23, gb_free=23, ema_decay=0.9999, wall=1269
2022-10-11 17:34:20 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 28910 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=50, ups=0.45, wpb=110.9, bsz=40, num_updates=550, lr=4.75614e-07, gnorm=1.044, clip=50, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=1291
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 1648278
Killing subprocess 1648279
Main process received SIGINT, exiting
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 183, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 109, in _get_module_details
    __import__(pkg_name)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/__init__.py", line 561, in <module>
    from .functional import *
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/functional.py", line 6, in <module>
    import torch.nn.functional as F
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/modules/__init__.py", line 22, in <module>
    from .padding import ReflectionPad1d, ReflectionPad2d, ReplicationPad1d, ReplicationPad2d, \
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 818, in get_code
  File "<frozen importlib._bootstrap_external>", line 917, in get_data
KeyboardInterrupt
2022-10-11 17:35:29 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-11 17:35:29 - utils.py[line:261] - INFO: Start init
2022-10-11 17:35:29 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-11 17:35:29 - utils.py[line:261] - INFO: Start init
2022-10-11 17:35:29 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-11 17:35:29 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-11 17:35:29 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-11 17:35:29 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-11 17:35:37 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 10, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=10, batch_size_valid='8', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=50, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[2], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-11 17:35:37 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-11 17:35:37 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-10-11 17:35:42 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-11 17:35:42 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-11 17:35:42 - train.py[line:119] - INFO: model: OFAModel
2022-10-11 17:35:42 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-11 17:35:42 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-11 17:35:42 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-11 17:35:42 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-11 17:35:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-11 17:35:43 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-11 17:35:43 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-11 17:35:43 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-11 17:35:43 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-11 17:35:43 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-11 17:35:43 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 10
2022-10-11 17:35:43 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt
2022-10-11 17:36:09 - trainer.py[line:605] - INFO: Loading EMA from checkpoint
2022-10-11 17:36:09 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-11 17:36:10 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-10-11 17:36:10 - trainer.py[line:612] - INFO: Loading EMA fp32 params from checkpoint
2022-10-11 17:36:10 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt (epoch 8 @ 0 updates)
2022-10-11 17:36:10 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 0 row count 578200 total row count 1156400
2022-10-11 17:36:11 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 1445500, warmup steps 57820, warmup_factor 1.7295053614666207e-05
2022-10-11 17:36:12 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-11 17:36:12 - train.py[line:312] - INFO: Start iterating over samples
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 1 row count 578200 total row count 1156400
Total steps 1445500, warmup steps 57820, warmup_factor 1.7295053614666207e-05
2022-10-11 17:36:41 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 28910 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=47.2, ups=0.43, wpb=110.8, bsz=40, num_updates=10, lr=8.64753e-09, gnorm=2.337, clip=100, loss_scale=128, train_wall=28, gb_free=22.7, ema_decay=0.9999, wall=57
2022-10-11 17:37:03 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 28910 loss=0.865, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=48.8, ups=0.45, wpb=109.6, bsz=40, num_updates=20, lr=1.72951e-08, gnorm=2.561, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=80
2022-10-11 17:37:25 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 28910 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=50.5, ups=0.45, wpb=111.1, bsz=40, num_updates=30, lr=2.59426e-08, gnorm=2.588, clip=100, loss_scale=128, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=102
2022-10-11 17:37:47 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 28910 loss=0.802, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=51.9, ups=0.47, wpb=111.6, bsz=40, num_updates=40, lr=3.45901e-08, gnorm=2.36, clip=100, loss_scale=128, train_wall=21, gb_free=22.8, ema_decay=0.9999, wall=123
2022-10-11 17:38:09 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 28910 loss=0.81, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=49.6, ups=0.45, wpb=109.4, bsz=40, num_updates=50, lr=4.32376e-08, gnorm=2.406, clip=100, loss_scale=128, train_wall=22, gb_free=22.9, ema_decay=0.9999, wall=146
2022-10-11 17:38:31 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 28910 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=49.2, ups=0.44, wpb=111.1, bsz=40, num_updates=60, lr=5.18852e-08, gnorm=2.263, clip=100, loss_scale=128, train_wall=23, gb_free=22.5, ema_decay=0.9999, wall=168
2022-10-11 17:38:54 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 28910 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=49.6, ups=0.45, wpb=109.8, bsz=40, num_updates=70, lr=6.05327e-08, gnorm=2.4, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=190
2022-10-11 17:39:16 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 28910 loss=0.76, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=49.8, ups=0.45, wpb=110, bsz=40, num_updates=80, lr=6.91802e-08, gnorm=2.1, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=212
2022-10-11 17:39:38 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 28910 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=48.9, ups=0.44, wpb=111, bsz=40, num_updates=90, lr=7.78277e-08, gnorm=2.408, clip=100, loss_scale=128, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=235
2022-10-11 17:40:01 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 28910 loss=0.803, loss_v1=0, loss_v2=0, nll_loss=0.715, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=48.8, ups=0.44, wpb=110.1, bsz=40, num_updates=100, lr=8.64753e-08, gnorm=2.566, clip=100, loss_scale=128, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=258
2022-10-11 17:40:23 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 28910 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=49.5, ups=0.45, wpb=110, bsz=40, num_updates=110, lr=9.51228e-08, gnorm=2.469, clip=100, loss_scale=128, train_wall=22, gb_free=23, ema_decay=0.9999, wall=280
2022-10-11 17:40:45 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 28910 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=50.3, ups=0.45, wpb=111.2, bsz=40, num_updates=120, lr=1.0377e-07, gnorm=2.42, clip=100, loss_scale=128, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=302
2022-10-11 17:41:08 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 28910 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=49.4, ups=0.45, wpb=110.8, bsz=40, num_updates=130, lr=1.12418e-07, gnorm=2.552, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=324
2022-10-11 17:41:30 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 28910 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=49.8, ups=0.45, wpb=110.9, bsz=40, num_updates=140, lr=1.21065e-07, gnorm=2.589, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=347
2022-10-11 17:41:52 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 28910 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=51.5, ups=0.47, wpb=110.6, bsz=40, num_updates=150, lr=1.29713e-07, gnorm=2.46, clip=100, loss_scale=128, train_wall=21, gb_free=23, ema_decay=0.9999, wall=368
2022-10-11 17:42:14 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 28910 loss=0.821, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=49.9, ups=0.45, wpb=110.5, bsz=40, num_updates=160, lr=1.3836e-07, gnorm=2.485, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=390
2022-10-11 17:42:36 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 28910 loss=0.862, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=49.5, ups=0.45, wpb=111, bsz=40, num_updates=170, lr=1.47008e-07, gnorm=2.606, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=413
2022-10-11 17:42:59 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 28910 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=49.6, ups=0.45, wpb=111.4, bsz=40, num_updates=180, lr=1.55655e-07, gnorm=2.118, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=435
2022-10-11 17:43:21 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 28910 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=51.1, ups=0.46, wpb=111.8, bsz=40, num_updates=190, lr=1.64303e-07, gnorm=2.26, clip=100, loss_scale=128, train_wall=22, gb_free=22.5, ema_decay=0.9999, wall=457
2022-10-11 17:43:43 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 28910 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=49.5, ups=0.45, wpb=109.9, bsz=40, num_updates=200, lr=1.72951e-07, gnorm=2.64, clip=100, loss_scale=128, train_wall=22, gb_free=23, ema_decay=0.9999, wall=480
2022-10-11 17:44:06 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 28910 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=47.5, ups=0.43, wpb=110.7, bsz=40, num_updates=210, lr=1.81598e-07, gnorm=2.164, clip=100, loss_scale=128, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=503
2022-10-11 17:44:29 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 28910 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=48.8, ups=0.44, wpb=109.8, bsz=40, num_updates=220, lr=1.90246e-07, gnorm=2.039, clip=90, loss_scale=128, train_wall=22, gb_free=23, ema_decay=0.9999, wall=525
2022-10-11 17:44:51 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 28910 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=49.7, ups=0.45, wpb=110.9, bsz=40, num_updates=230, lr=1.98893e-07, gnorm=2.333, clip=100, loss_scale=128, train_wall=22, gb_free=22.6, ema_decay=0.9999, wall=548
2022-10-11 17:45:13 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 28910 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=49.6, ups=0.45, wpb=111.4, bsz=40, num_updates=240, lr=2.07541e-07, gnorm=1.994, clip=100, loss_scale=128, train_wall=22, gb_free=23.1, ema_decay=0.9999, wall=570
2022-10-11 17:45:36 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 28910 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=49.5, ups=0.45, wpb=109.5, bsz=40, num_updates=250, lr=2.16188e-07, gnorm=2.296, clip=100, loss_scale=128, train_wall=22, gb_free=22.9, ema_decay=0.9999, wall=592
2022-10-11 17:45:58 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 28910 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=49.9, ups=0.45, wpb=110.5, bsz=40, num_updates=260, lr=2.24836e-07, gnorm=2.098, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=614
2022-10-11 17:46:20 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 28910 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=48.9, ups=0.45, wpb=108.9, bsz=40, num_updates=270, lr=2.33483e-07, gnorm=2.383, clip=100, loss_scale=128, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=637
2022-10-11 17:46:42 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 28910 loss=0.808, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=49.3, ups=0.45, wpb=109.6, bsz=40, num_updates=280, lr=2.42131e-07, gnorm=2.348, clip=100, loss_scale=128, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=659
2022-10-11 17:47:05 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 28910 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=48.4, ups=0.44, wpb=110, bsz=40, num_updates=290, lr=2.50778e-07, gnorm=1.994, clip=100, loss_scale=128, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=682
2022-10-11 17:47:29 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 28910 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=46.6, ups=0.42, wpb=109.8, bsz=40, num_updates=300, lr=2.59426e-07, gnorm=2.039, clip=100, loss_scale=128, train_wall=23, gb_free=22.9, ema_decay=0.9999, wall=705
2022-10-11 17:47:53 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 28910 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=44.7, ups=0.41, wpb=110.2, bsz=40, num_updates=310, lr=2.68073e-07, gnorm=1.773, clip=100, loss_scale=128, train_wall=25, gb_free=22.8, ema_decay=0.9999, wall=730
2022-10-11 17:48:18 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 28910 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=45, ups=0.4, wpb=111.3, bsz=40, num_updates=320, lr=2.76721e-07, gnorm=1.813, clip=100, loss_scale=128, train_wall=25, gb_free=23, ema_decay=0.9999, wall=755
2022-10-11 17:48:43 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 28910 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=44.6, ups=0.4, wpb=110.5, bsz=40, num_updates=330, lr=2.85368e-07, gnorm=2.051, clip=90, loss_scale=128, train_wall=25, gb_free=22.8, ema_decay=0.9999, wall=779
2022-10-11 17:49:07 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 28910 loss=0.773, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=46.4, ups=0.42, wpb=111.2, bsz=40, num_updates=340, lr=2.94016e-07, gnorm=2.102, clip=100, loss_scale=128, train_wall=24, gb_free=23, ema_decay=0.9999, wall=804
2022-10-11 17:49:31 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 28910 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=46.3, ups=0.41, wpb=111.8, bsz=40, num_updates=350, lr=3.02663e-07, gnorm=1.794, clip=100, loss_scale=128, train_wall=24, gb_free=22.8, ema_decay=0.9999, wall=828
2022-10-11 17:49:55 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 28910 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=45, ups=0.41, wpb=110.2, bsz=40, num_updates=360, lr=3.11311e-07, gnorm=2.385, clip=100, loss_scale=128, train_wall=24, gb_free=22.8, ema_decay=0.9999, wall=852
2022-10-11 17:50:19 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 28910 loss=0.741, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=46.3, ups=0.42, wpb=110.4, bsz=40, num_updates=370, lr=3.19958e-07, gnorm=1.916, clip=100, loss_scale=128, train_wall=24, gb_free=22.8, ema_decay=0.9999, wall=876
2022-10-11 17:50:44 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 28910 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=44.5, ups=0.4, wpb=109.9, bsz=40, num_updates=380, lr=3.28606e-07, gnorm=1.793, clip=100, loss_scale=128, train_wall=25, gb_free=22.8, ema_decay=0.9999, wall=901
2022-10-11 17:51:08 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 28910 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=46, ups=0.41, wpb=111, bsz=40, num_updates=390, lr=3.37254e-07, gnorm=1.559, clip=100, loss_scale=128, train_wall=24, gb_free=22.8, ema_decay=0.9999, wall=925
2022-10-11 17:51:33 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 28910 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=45.6, ups=0.41, wpb=110.5, bsz=40, num_updates=400, lr=3.45901e-07, gnorm=1.743, clip=100, loss_scale=128, train_wall=24, gb_free=22.8, ema_decay=0.9999, wall=949
2022-10-11 17:51:57 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 28910 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=44.3, ups=0.4, wpb=109.5, bsz=40, num_updates=410, lr=3.54549e-07, gnorm=1.509, clip=90, loss_scale=128, train_wall=25, gb_free=22.9, ema_decay=0.9999, wall=974
2022-10-11 17:52:22 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 28910 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=44.4, ups=0.4, wpb=110.4, bsz=40, num_updates=420, lr=3.63196e-07, gnorm=1.475, clip=90, loss_scale=128, train_wall=25, gb_free=22.8, ema_decay=0.9999, wall=999
2022-10-11 17:52:47 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 28910 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=44.9, ups=0.4, wpb=111.3, bsz=40, num_updates=430, lr=3.71844e-07, gnorm=1.368, clip=80, loss_scale=128, train_wall=25, gb_free=22.7, ema_decay=0.9999, wall=1024
2022-10-11 17:53:11 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 28910 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=45.1, ups=0.41, wpb=109.6, bsz=40, num_updates=440, lr=3.80491e-07, gnorm=1.644, clip=100, loss_scale=128, train_wall=24, gb_free=22.9, ema_decay=0.9999, wall=1048
2022-10-11 17:53:36 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 28910 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=45.1, ups=0.41, wpb=110.8, bsz=40, num_updates=450, lr=3.89139e-07, gnorm=1.545, clip=90, loss_scale=128, train_wall=25, gb_free=22.8, ema_decay=0.9999, wall=1073
2022-10-11 17:54:01 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 28910 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=43.7, ups=0.4, wpb=109.6, bsz=40, num_updates=460, lr=3.97786e-07, gnorm=1.473, clip=90, loss_scale=128, train_wall=25, gb_free=22.8, ema_decay=0.9999, wall=1098
2022-10-11 17:54:25 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 28910 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=45.4, ups=0.41, wpb=110.3, bsz=40, num_updates=470, lr=4.06434e-07, gnorm=1.277, clip=60, loss_scale=128, train_wall=24, gb_free=22.7, ema_decay=0.9999, wall=1122
2022-10-11 17:54:38 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 28910 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=86.2, ups=0.79, wpb=109.2, bsz=40, num_updates=480, lr=4.15081e-07, gnorm=1.295, clip=80, loss_scale=128, train_wall=13, gb_free=22.8, ema_decay=0.9999, wall=1135
2022-10-11 17:54:50 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 28910 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.9, ups=0.84, wpb=110.4, bsz=40, num_updates=490, lr=4.23729e-07, gnorm=1.153, clip=60, loss_scale=128, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=1147
2022-10-11 17:55:02 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 28910 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.621, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=91.7, ups=0.83, wpb=110, bsz=40, num_updates=500, lr=4.32376e-07, gnorm=1.242, clip=70, loss_scale=128, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=1159
2022-10-11 17:55:14 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 28910 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=89.6, ups=0.82, wpb=108.7, bsz=40, num_updates=510, lr=4.41024e-07, gnorm=1.211, clip=80, loss_scale=128, train_wall=12, gb_free=23, ema_decay=0.9999, wall=1171
2022-10-11 17:55:28 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 28910 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=82.6, ups=0.74, wpb=111.5, bsz=40, num_updates=520, lr=4.49671e-07, gnorm=1.04, clip=40, loss_scale=256, train_wall=13, gb_free=22.6, ema_decay=0.9999, wall=1184
2022-10-11 17:55:51 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=49.2, ups=0.44, wpb=111, bsz=40, num_updates=530, lr=4.58319e-07, gnorm=1.305, clip=60, loss_scale=256, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=1207
2022-10-11 17:56:13 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 28910 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=49.4, ups=0.45, wpb=110.1, bsz=40, num_updates=540, lr=4.66966e-07, gnorm=0.833, clip=30, loss_scale=256, train_wall=22, gb_free=23, ema_decay=0.9999, wall=1230
2022-10-11 17:56:35 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 28910 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=50.3, ups=0.45, wpb=110.9, bsz=40, num_updates=550, lr=4.75614e-07, gnorm=1.043, clip=50, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=1252
2022-10-11 17:56:57 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 28910 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=49.5, ups=0.45, wpb=110.1, bsz=40, num_updates=560, lr=4.84262e-07, gnorm=1.126, clip=60, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=1274
2022-10-11 17:57:19 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 28910 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=50.4, ups=0.46, wpb=110.1, bsz=40, num_updates=570, lr=4.92909e-07, gnorm=0.885, clip=30, loss_scale=256, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=1296
2022-10-11 17:57:41 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 28910 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=51.3, ups=0.46, wpb=111.1, bsz=40, num_updates=580, lr=5.01557e-07, gnorm=1.056, clip=60, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=1318
2022-10-11 17:58:03 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 28910 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=50.4, ups=0.45, wpb=112.1, bsz=40, num_updates=590, lr=5.10204e-07, gnorm=1.086, clip=50, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=1340
2022-10-11 17:58:26 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 28910 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=47.7, ups=0.43, wpb=110.4, bsz=40, num_updates=600, lr=5.18852e-07, gnorm=1.439, clip=70, loss_scale=256, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=1363
2022-10-11 17:58:49 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 28910 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=49.2, ups=0.45, wpb=109.4, bsz=40, num_updates=610, lr=5.27499e-07, gnorm=1.226, clip=60, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=1385
2022-10-11 17:59:11 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 28910 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=48.3, ups=0.44, wpb=109.6, bsz=40, num_updates=620, lr=5.36147e-07, gnorm=0.849, clip=30, loss_scale=256, train_wall=23, gb_free=22.9, ema_decay=0.9999, wall=1408
2022-10-11 17:59:34 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 28910 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=49, ups=0.44, wpb=111.7, bsz=40, num_updates=630, lr=5.44794e-07, gnorm=1.015, clip=40, loss_scale=256, train_wall=23, gb_free=22.6, ema_decay=0.9999, wall=1431
2022-10-11 17:59:57 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 28910 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=47.8, ups=0.44, wpb=109.8, bsz=40, num_updates=640, lr=5.53442e-07, gnorm=1.471, clip=70, loss_scale=256, train_wall=23, gb_free=23, ema_decay=0.9999, wall=1454
2022-10-11 18:00:19 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 28910 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.586, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=49.5, ups=0.45, wpb=110.1, bsz=40, num_updates=650, lr=5.62089e-07, gnorm=0.965, clip=50, loss_scale=256, train_wall=22, gb_free=23, ema_decay=0.9999, wall=1476
2022-10-11 18:00:42 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 28910 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=48, ups=0.43, wpb=110.6, bsz=40, num_updates=660, lr=5.70737e-07, gnorm=0.913, clip=30, loss_scale=256, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=1499
2022-10-11 18:01:05 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 28910 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.587, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=49.7, ups=0.45, wpb=109.8, bsz=40, num_updates=670, lr=5.79384e-07, gnorm=0.972, clip=30, loss_scale=256, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=1521
2022-10-11 18:01:28 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 28910 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=47.4, ups=0.43, wpb=109.6, bsz=40, num_updates=680, lr=5.88032e-07, gnorm=1.186, clip=60, loss_scale=256, train_wall=23, gb_free=23, ema_decay=0.9999, wall=1544
2022-10-11 18:01:51 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 28910 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=47.7, ups=0.43, wpb=109.9, bsz=40, num_updates=690, lr=5.96679e-07, gnorm=1.097, clip=60, loss_scale=256, train_wall=23, gb_free=23, ema_decay=0.9999, wall=1567
2022-10-11 18:02:13 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 28910 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=51.1, ups=0.45, wpb=112.4, bsz=40, num_updates=700, lr=6.05327e-07, gnorm=0.809, clip=20, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=1590
2022-10-11 18:02:35 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 28910 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=49.5, ups=0.45, wpb=110, bsz=40, num_updates=710, lr=6.13974e-07, gnorm=0.898, clip=50, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=1612
2022-10-11 18:02:59 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 28910 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=46.5, ups=0.42, wpb=110.5, bsz=40, num_updates=720, lr=6.22622e-07, gnorm=0.9, clip=40, loss_scale=256, train_wall=24, gb_free=22.9, ema_decay=0.9999, wall=1636
2022-10-11 18:03:22 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 28910 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=47.3, ups=0.43, wpb=110.5, bsz=40, num_updates=730, lr=6.31269e-07, gnorm=1.04, clip=40, loss_scale=256, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=1659
2022-10-11 18:03:44 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 28910 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.624, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=49.7, ups=0.45, wpb=109.9, bsz=40, num_updates=740, lr=6.39917e-07, gnorm=1.057, clip=50, loss_scale=256, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=1681
2022-10-11 18:04:07 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 28910 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=50.8, ups=0.46, wpb=111.6, bsz=40, num_updates=750, lr=6.48565e-07, gnorm=1.04, clip=50, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=1703
2022-10-11 18:04:29 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 28910 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.587, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=48.8, ups=0.45, wpb=109.4, bsz=40, num_updates=760, lr=6.57212e-07, gnorm=0.986, clip=30, loss_scale=256, train_wall=22, gb_free=22.6, ema_decay=0.9999, wall=1726
2022-10-11 18:04:52 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 28910 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=48.6, ups=0.43, wpb=111.8, bsz=40, num_updates=770, lr=6.6586e-07, gnorm=1.148, clip=50, loss_scale=256, train_wall=23, gb_free=22.9, ema_decay=0.9999, wall=1749
2022-10-11 18:05:15 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 28910 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=49.5, ups=0.44, wpb=111.6, bsz=40, num_updates=780, lr=6.74507e-07, gnorm=1.052, clip=60, loss_scale=256, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=1772
2022-10-11 18:05:37 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 28910 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=49.9, ups=0.45, wpb=110.5, bsz=40, num_updates=790, lr=6.83155e-07, gnorm=1.043, clip=50, loss_scale=256, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=1794
2022-10-11 18:05:59 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 28910 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=48.7, ups=0.45, wpb=108.7, bsz=40, num_updates=800, lr=6.91802e-07, gnorm=1.024, clip=40, loss_scale=256, train_wall=22, gb_free=22.9, ema_decay=0.9999, wall=1816
2022-10-11 18:06:23 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 28910 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=47.7, ups=0.43, wpb=110.1, bsz=40, num_updates=810, lr=7.0045e-07, gnorm=1.003, clip=50, loss_scale=256, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=1839
2022-10-11 18:06:45 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 28910 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=50.2, ups=0.45, wpb=110.3, bsz=40, num_updates=820, lr=7.09097e-07, gnorm=0.981, clip=50, loss_scale=256, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=1861
2022-10-11 18:07:08 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 28910 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=49.8, ups=0.45, wpb=111.5, bsz=40, num_updates=830, lr=7.17745e-07, gnorm=1.058, clip=60, loss_scale=256, train_wall=22, gb_free=23, ema_decay=0.9999, wall=1884
2022-10-11 18:07:29 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 28910 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=50.9, ups=0.46, wpb=110.4, bsz=40, num_updates=840, lr=7.26392e-07, gnorm=0.966, clip=40, loss_scale=256, train_wall=22, gb_free=22.7, ema_decay=0.9999, wall=1906
2022-10-11 18:07:53 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 28910 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=47.4, ups=0.43, wpb=109.9, bsz=40, num_updates=850, lr=7.3504e-07, gnorm=1.024, clip=40, loss_scale=256, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=1929
2022-10-11 18:08:15 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 28910 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=48.9, ups=0.44, wpb=111, bsz=40, num_updates=860, lr=7.43687e-07, gnorm=1.065, clip=50, loss_scale=256, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=1952
2022-10-11 18:08:38 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 28910 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.603, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=47.5, ups=0.43, wpb=109.8, bsz=40, num_updates=870, lr=7.52335e-07, gnorm=1.054, clip=40, loss_scale=256, train_wall=23, gb_free=22.6, ema_decay=0.9999, wall=1975
2022-10-11 18:09:01 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 28910 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=48.2, ups=0.44, wpb=109.8, bsz=40, num_updates=880, lr=7.60982e-07, gnorm=1.091, clip=50, loss_scale=256, train_wall=23, gb_free=23, ema_decay=0.9999, wall=1998
2022-10-11 18:09:24 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 28910 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=49.4, ups=0.44, wpb=112.1, bsz=40, num_updates=890, lr=7.6963e-07, gnorm=0.96, clip=10, loss_scale=256, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=2021
2022-10-11 18:09:47 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 28910 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=48, ups=0.44, wpb=110.2, bsz=40, num_updates=900, lr=7.78277e-07, gnorm=0.933, clip=40, loss_scale=256, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=2044
2022-10-11 18:10:09 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 28910 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.586, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=50.2, ups=0.45, wpb=110.6, bsz=40, num_updates=910, lr=7.86925e-07, gnorm=1.059, clip=50, loss_scale=256, train_wall=22, gb_free=23, ema_decay=0.9999, wall=2066
2022-10-11 18:10:31 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 28910 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=49.8, ups=0.45, wpb=111.7, bsz=40, num_updates=920, lr=7.95572e-07, gnorm=0.844, clip=30, loss_scale=256, train_wall=22, gb_free=22.9, ema_decay=0.9999, wall=2088
2022-10-11 18:10:54 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=49.2, ups=0.44, wpb=111.3, bsz=40, num_updates=930, lr=8.0422e-07, gnorm=0.844, clip=40, loss_scale=256, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=2111
2022-10-11 18:11:16 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 28910 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=49.5, ups=0.45, wpb=110.7, bsz=40, num_updates=940, lr=8.12868e-07, gnorm=0.998, clip=50, loss_scale=256, train_wall=22, gb_free=22.4, ema_decay=0.9999, wall=2133
2022-10-11 18:11:39 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 28910 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=48.9, ups=0.44, wpb=109.8, bsz=40, num_updates=950, lr=8.21515e-07, gnorm=0.878, clip=30, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=2156
2022-10-11 18:12:01 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 28910 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=49.3, ups=0.45, wpb=109, bsz=40, num_updates=960, lr=8.30163e-07, gnorm=1.026, clip=40, loss_scale=256, train_wall=22, gb_free=22.3, ema_decay=0.9999, wall=2178
2022-10-11 18:12:24 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 28910 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=48.1, ups=0.43, wpb=110.6, bsz=40, num_updates=970, lr=8.3881e-07, gnorm=0.94, clip=30, loss_scale=256, train_wall=23, gb_free=22.8, ema_decay=0.9999, wall=2201
2022-10-11 18:12:47 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 28910 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=47.5, ups=0.43, wpb=109.6, bsz=40, num_updates=980, lr=8.47458e-07, gnorm=1.08, clip=60, loss_scale=256, train_wall=23, gb_free=22.7, ema_decay=0.9999, wall=2224
2022-10-11 18:13:09 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 28910 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=50.3, ups=0.45, wpb=111.3, bsz=40, num_updates=990, lr=8.56105e-07, gnorm=1.062, clip=50, loss_scale=256, train_wall=22, gb_free=22.8, ema_decay=0.9999, wall=2246
2022-10-11 18:13:32 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=50, ups=0.45, wpb=112.1, bsz=40, num_updates=1000, lr=8.64753e-07, gnorm=0.924, clip=30, loss_scale=256, train_wall=22, gb_free=23, ema_decay=0.9999, wall=2268
2022-10-11 18:13:32 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-11 18:13:32 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-11 18:13:33 - train.py[line:549] - INFO: 0 / 9351
2022-10-11 18:13:33 - train.py[line:551] - INFO: load:0.88 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-11 18:18:49 - train.py[line:549] - INFO: 200 / 9351
2022-10-11 18:18:49 - train.py[line:551] - INFO: load:0.90 valid_run:315.17 task_valid:83.16 collect_output:230.91
2022-10-11 18:22:29 - train.py[line:549] - INFO: 400 / 9351
2022-10-11 18:22:29 - train.py[line:551] - INFO: load:0.92 valid_run:535.81 task_valid:164.34 collect_output:369.29
2022-10-11 18:26:58 - train.py[line:549] - INFO: 600 / 9351
2022-10-11 18:26:58 - train.py[line:551] - INFO: load:0.94 valid_run:804.61 task_valid:242.95 collect_output:558.38
2022-10-11 18:31:32 - train.py[line:549] - INFO: 800 / 9351
2022-10-11 18:31:32 - train.py[line:551] - INFO: load:0.97 valid_run:1078.37 task_valid:321.55 collect_output:752.44
2022-10-11 18:37:59 - train.py[line:549] - INFO: 1000 / 9351
2022-10-11 18:37:59 - train.py[line:551] - INFO: load:0.99 valid_run:1465.20 task_valid:400.86 collect_output:1058.84
2022-10-11 18:40:30 - train.py[line:549] - INFO: 1200 / 9351
2022-10-11 18:40:30 - train.py[line:551] - INFO: load:1.02 valid_run:1616.51 task_valid:478.94 collect_output:1130.96
2022-10-11 18:44:46 - train.py[line:549] - INFO: 1400 / 9351
2022-10-11 18:44:46 - train.py[line:551] - INFO: load:1.04 valid_run:1872.51 task_valid:559.21 collect_output:1305.60
2022-10-11 18:49:05 - train.py[line:549] - INFO: 1600 / 9351
2022-10-11 18:49:05 - train.py[line:551] - INFO: load:1.07 valid_run:2130.69 task_valid:641.15 collect_output:1480.65
2022-10-11 18:53:31 - train.py[line:549] - INFO: 1800 / 9351
2022-10-11 18:53:31 - train.py[line:551] - INFO: load:1.09 valid_run:2396.95 task_valid:722.46 collect_output:1664.32
2022-10-11 18:58:39 - train.py[line:549] - INFO: 2000 / 9351
2022-10-11 18:58:39 - train.py[line:551] - INFO: load:1.12 valid_run:2705.12 task_valid:803.21 collect_output:1890.44
2022-10-11 19:02:15 - train.py[line:549] - INFO: 2200 / 9351
2022-10-11 19:02:15 - train.py[line:551] - INFO: load:1.14 valid_run:2920.94 task_valid:883.80 collect_output:2024.44
2022-10-11 19:06:32 - train.py[line:549] - INFO: 2400 / 9351
2022-10-11 19:06:32 - train.py[line:551] - INFO: load:1.16 valid_run:3178.00 task_valid:964.81 collect_output:2199.22
2022-10-11 19:10:57 - train.py[line:549] - INFO: 2600 / 9351
2022-10-11 19:10:57 - train.py[line:551] - INFO: load:1.19 valid_run:3443.11 task_valid:1044.74 collect_output:2383.22
2022-10-11 19:17:09 - train.py[line:549] - INFO: 2800 / 9351
2022-10-11 19:17:09 - train.py[line:551] - INFO: load:1.21 valid_run:3814.34 task_valid:1123.37 collect_output:2674.68
2022-10-11 19:19:57 - train.py[line:549] - INFO: 3000 / 9351
2022-10-11 19:19:57 - train.py[line:551] - INFO: load:1.24 valid_run:3982.69 task_valid:1200.81 collect_output:2764.51
2022-10-11 19:24:09 - train.py[line:549] - INFO: 3200 / 9351
2022-10-11 19:24:09 - train.py[line:551] - INFO: load:1.26 valid_run:4234.92 task_valid:1279.78 collect_output:2936.69
2022-10-11 19:28:29 - train.py[line:549] - INFO: 3400 / 9351
2022-10-11 19:28:29 - train.py[line:551] - INFO: load:1.28 valid_run:4494.45 task_valid:1359.26 collect_output:3115.60
2022-10-11 19:32:47 - train.py[line:549] - INFO: 3600 / 9351
2022-10-11 19:32:47 - train.py[line:551] - INFO: load:1.31 valid_run:4752.77 task_valid:1439.48 collect_output:3292.64
2022-10-11 19:39:11 - train.py[line:549] - INFO: 3800 / 9351
2022-10-11 19:39:11 - train.py[line:551] - INFO: load:1.33 valid_run:5136.64 task_valid:1516.97 collect_output:3597.97
2022-10-11 19:41:28 - train.py[line:549] - INFO: 4000 / 9351
2022-10-11 19:41:28 - train.py[line:551] - INFO: load:1.35 valid_run:5272.86 task_valid:1595.93 collect_output:3654.14
2022-10-11 19:45:41 - train.py[line:549] - INFO: 4200 / 9351
2022-10-11 19:45:41 - train.py[line:551] - INFO: load:1.38 valid_run:5526.42 task_valid:1677.84 collect_output:3824.66
2022-10-11 19:49:56 - train.py[line:549] - INFO: 4400 / 9351
2022-10-11 19:49:56 - train.py[line:551] - INFO: load:1.40 valid_run:5781.08 task_valid:1757.78 collect_output:3998.25
2022-10-11 19:54:10 - train.py[line:549] - INFO: 4600 / 9351
2022-10-11 19:54:10 - train.py[line:551] - INFO: load:1.43 valid_run:6034.86 task_valid:1837.05 collect_output:4171.63
2022-10-11 20:00:14 - train.py[line:549] - INFO: 4800 / 9351
2022-10-11 20:00:14 - train.py[line:551] - INFO: load:1.45 valid_run:6398.93 task_valid:1916.19 collect_output:4455.26
2022-10-11 20:02:50 - train.py[line:549] - INFO: 5000 / 9351
2022-10-11 20:02:50 - train.py[line:551] - INFO: load:1.48 valid_run:6554.92 task_valid:1997.91 collect_output:4528.29
2022-10-11 20:07:01 - train.py[line:549] - INFO: 5200 / 9351
2022-10-11 20:07:01 - train.py[line:551] - INFO: load:1.50 valid_run:6805.40 task_valid:2079.35 collect_output:4696.07
2022-10-11 20:11:09 - train.py[line:549] - INFO: 5400 / 9351
2022-10-11 20:11:09 - train.py[line:551] - INFO: load:1.53 valid_run:7053.67 task_valid:2160.23 collect_output:4862.19
2022-10-11 20:15:19 - train.py[line:549] - INFO: 5600 / 9351
2022-10-11 20:15:19 - train.py[line:551] - INFO: load:1.55 valid_run:7303.66 task_valid:2241.97 collect_output:5029.26
2022-10-11 20:20:57 - train.py[line:549] - INFO: 5800 / 9351
2022-10-11 20:20:57 - train.py[line:551] - INFO: load:1.58 valid_run:7641.32 task_valid:2321.71 collect_output:5286.02
2022-10-11 20:24:05 - train.py[line:549] - INFO: 6000 / 9351
2022-10-11 20:24:05 - train.py[line:551] - INFO: load:1.60 valid_run:7829.74 task_valid:2403.10 collect_output:5391.88
2022-10-11 20:28:10 - train.py[line:549] - INFO: 6200 / 9351
2022-10-11 20:28:10 - train.py[line:551] - INFO: load:1.63 valid_run:8074.35 task_valid:2483.41 collect_output:5555.04
2022-10-11 20:32:25 - train.py[line:549] - INFO: 6400 / 9351
2022-10-11 20:32:25 - train.py[line:551] - INFO: load:1.66 valid_run:8329.58 task_valid:2565.08 collect_output:5727.47
2022-10-11 20:36:11 - train.py[line:549] - INFO: 6600 / 9351
2022-10-11 20:36:11 - train.py[line:551] - INFO: load:1.68 valid_run:8555.63 task_valid:2646.89 collect_output:5870.59
2022-10-11 20:37:35 - train.py[line:549] - INFO: 6800 / 9351
2022-10-11 20:37:35 - train.py[line:551] - INFO: load:1.71 valid_run:8639.33 task_valid:2727.08 collect_output:5873.01
2022-10-11 20:38:58 - train.py[line:549] - INFO: 7000 / 9351
2022-10-11 20:38:58 - train.py[line:551] - INFO: load:1.73 valid_run:8722.14 task_valid:2805.66 collect_output:5876.18
2022-10-11 20:40:21 - train.py[line:549] - INFO: 7200 / 9351
2022-10-11 20:40:21 - train.py[line:551] - INFO: load:1.75 valid_run:8805.07 task_valid:2885.43 collect_output:5878.31
2022-10-11 20:41:44 - train.py[line:549] - INFO: 7400 / 9351
2022-10-11 20:41:44 - train.py[line:551] - INFO: load:1.77 valid_run:8888.65 task_valid:2964.59 collect_output:5881.65
2022-10-11 20:43:10 - train.py[line:549] - INFO: 7600 / 9351
2022-10-11 20:43:10 - train.py[line:551] - INFO: load:1.79 valid_run:8973.68 task_valid:3044.86 collect_output:5885.38
2022-10-11 20:44:34 - train.py[line:549] - INFO: 7800 / 9351
2022-10-11 20:44:34 - train.py[line:551] - INFO: load:1.82 valid_run:9058.46 task_valid:3125.66 collect_output:5888.27
2022-10-11 20:45:58 - train.py[line:549] - INFO: 8000 / 9351
2022-10-11 20:45:58 - train.py[line:551] - INFO: load:1.84 valid_run:9142.21 task_valid:3205.28 collect_output:5891.20
2022-10-11 20:47:23 - train.py[line:549] - INFO: 8200 / 9351
2022-10-11 20:47:23 - train.py[line:551] - INFO: load:1.86 valid_run:9227.06 task_valid:3287.82 collect_output:5892.33
2022-10-11 20:48:47 - train.py[line:549] - INFO: 8400 / 9351
2022-10-11 20:48:47 - train.py[line:551] - INFO: load:1.89 valid_run:9310.62 task_valid:3368.86 collect_output:5893.81
2022-10-11 20:50:11 - train.py[line:549] - INFO: 8600 / 9351
2022-10-11 20:50:11 - train.py[line:551] - INFO: load:1.91 valid_run:9394.71 task_valid:3449.15 collect_output:5896.56
2022-10-11 20:51:34 - train.py[line:549] - INFO: 8800 / 9351
2022-10-11 20:51:34 - train.py[line:551] - INFO: load:1.93 valid_run:9478.13 task_valid:3528.21 collect_output:5899.89
2022-10-11 20:52:58 - train.py[line:549] - INFO: 9000 / 9351
2022-10-11 20:52:58 - train.py[line:551] - INFO: load:1.95 valid_run:9562.06 task_valid:3610.13 collect_output:5900.85
2022-10-11 20:54:22 - train.py[line:549] - INFO: 9200 / 9351
2022-10-11 20:54:22 - train.py[line:551] - INFO: load:1.98 valid_run:9645.44 task_valid:3691.05 collect_output:5902.23

====================================================================================================
SGG eval:     R @ 50: 0.6398;     R @ 100: 0.6786;     R @ 500: 0.7089;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4336;    mR @ 100: 0.4819;    mR @ 500: 0.5271;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.3714) (eating:0.7647) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5323) (lying on:0.5000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9624) (says:0.0000) (sitting on:0.6774) (standing on:0.5113) (using:0.4500) (walking in:0.0000) (walking on:0.5856) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6398;     R @ 100: 0.6786;     R @ 500: 0.7089;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4336;    mR @ 100: 0.4819;    mR @ 500: 0.5271;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.3714) (eating:0.7647) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5323) (lying on:0.5000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9624) (says:0.0000) (sitting on:0.6774) (standing on:0.5113) (using:0.4500) (walking in:0.0000) (walking on:0.5856) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2022-10-11 20:55:36 - train.py[line:487] - INFO: 0.6786467787114846
2022-10-11 20:55:36 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-11 20:55:36 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.335 | loss_v1 0 | loss_v2 0 | nll_loss 0.225 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.678647 | ppl 1.17 | vqa_score 0.4696 | wps 46.1 | wpb 48 | bsz 16 | num_updates 1000
2022-10-11 20:55:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2022-10-11 20:55:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-11 20:55:43 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-11 20:55:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 0.6786467787114846) (writing took 13.398273143917322 seconds)
2022-10-11 20:56:01 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 28910 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=0.1, ups=0, wpb=109.3, bsz=40, num_updates=1010, lr=8.734e-07, gnorm=1.124, clip=60, loss_scale=256, train_wall=11, gb_free=22.6, ema_decay=0.9999, wall=12018
2022-10-11 20:56:14 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 28910 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=89.6, ups=0.81, wpb=110.6, bsz=40, num_updates=1020, lr=8.82048e-07, gnorm=0.872, clip=40, loss_scale=256, train_wall=12, gb_free=23, ema_decay=0.9999, wall=12030
2022-10-11 20:56:26 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 28910 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.4, ups=0.83, wpb=111.2, bsz=40, num_updates=1030, lr=8.90695e-07, gnorm=0.953, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12042
2022-10-11 20:56:38 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=93, ups=0.84, wpb=110.8, bsz=40, num_updates=1040, lr=8.99343e-07, gnorm=1.224, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12054
2022-10-11 20:56:50 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 28910 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=93.4, ups=0.84, wpb=111.2, bsz=40, num_updates=1050, lr=9.0799e-07, gnorm=1.043, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12066
2022-10-11 20:57:01 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 28910 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=92.7, ups=0.85, wpb=108.6, bsz=40, num_updates=1060, lr=9.16638e-07, gnorm=1.147, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12078
2022-10-11 20:57:13 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 28910 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.58, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=93.1, ups=0.84, wpb=111, bsz=40, num_updates=1070, lr=9.25285e-07, gnorm=1.133, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12090
2022-10-11 20:57:25 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 28910 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.3, ups=0.83, wpb=110.8, bsz=40, num_updates=1080, lr=9.33933e-07, gnorm=0.982, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12102
2022-10-11 20:57:37 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 28910 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=92.4, ups=0.84, wpb=109.7, bsz=40, num_updates=1090, lr=9.4258e-07, gnorm=1.082, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12114
2022-10-11 20:57:49 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 28910 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=94.1, ups=0.85, wpb=110.4, bsz=40, num_updates=1100, lr=9.51228e-07, gnorm=1.165, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12126
2022-10-11 20:58:01 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 28910 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=92.2, ups=0.83, wpb=110.4, bsz=40, num_updates=1110, lr=9.59875e-07, gnorm=1.081, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12138
2022-10-11 20:58:13 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 28910 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93.5, ups=0.85, wpb=110, bsz=40, num_updates=1120, lr=9.68523e-07, gnorm=1.037, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12149
2022-10-11 20:58:25 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 28910 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.6, ups=0.85, wpb=110.7, bsz=40, num_updates=1130, lr=9.77171e-07, gnorm=1.055, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12161
2022-10-11 20:58:37 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 28910 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=92.3, ups=0.83, wpb=110.6, bsz=40, num_updates=1140, lr=9.85818e-07, gnorm=1.037, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12173
2022-10-11 20:58:48 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 28910 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=93.3, ups=0.85, wpb=110, bsz=40, num_updates=1150, lr=9.94466e-07, gnorm=1.047, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12185
2022-10-11 20:59:00 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 28910 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.9, ups=0.84, wpb=110, bsz=40, num_updates=1160, lr=1.00311e-06, gnorm=1.085, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12197
2022-10-11 20:59:12 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 28910 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=94.9, ups=0.86, wpb=110.3, bsz=40, num_updates=1170, lr=1.01176e-06, gnorm=1.139, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12209
2022-10-11 20:59:24 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 28910 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=93.1, ups=0.84, wpb=110.3, bsz=40, num_updates=1180, lr=1.02041e-06, gnorm=1.033, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12221
2022-10-11 20:59:36 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 28910 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.7, ups=0.84, wpb=108.9, bsz=40, num_updates=1190, lr=1.02906e-06, gnorm=1.144, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12232
2022-10-11 20:59:48 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 28910 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=94.1, ups=0.86, wpb=109.8, bsz=40, num_updates=1200, lr=1.0377e-06, gnorm=1.019, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12244
2022-10-11 21:00:00 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 28910 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.7, ups=0.82, wpb=109.1, bsz=40, num_updates=1210, lr=1.04635e-06, gnorm=1.276, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12256
2022-10-11 21:00:12 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 28910 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91.5, ups=0.83, wpb=110.1, bsz=40, num_updates=1220, lr=1.055e-06, gnorm=1.074, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12268
2022-10-11 21:00:24 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=94.1, ups=0.85, wpb=111.3, bsz=40, num_updates=1230, lr=1.06365e-06, gnorm=1.097, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12280
2022-10-11 21:00:36 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 28910 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=90.1, ups=0.83, wpb=108.6, bsz=40, num_updates=1240, lr=1.07229e-06, gnorm=1.189, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12292
2022-10-11 21:00:48 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 28910 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.6, ups=0.84, wpb=108.5, bsz=40, num_updates=1250, lr=1.08094e-06, gnorm=1.082, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12304
2022-10-11 21:01:00 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 28910 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=90.1, ups=0.82, wpb=109.5, bsz=40, num_updates=1260, lr=1.08959e-06, gnorm=1.089, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12316
2022-10-11 21:01:12 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 28910 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93.1, ups=0.84, wpb=110.2, bsz=40, num_updates=1270, lr=1.09824e-06, gnorm=0.913, clip=20, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12328
2022-10-11 21:01:23 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 28910 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=92.7, ups=0.84, wpb=110, bsz=40, num_updates=1280, lr=1.10688e-06, gnorm=1.013, clip=20, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12340
2022-10-11 21:01:35 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=92.9, ups=0.85, wpb=109.4, bsz=40, num_updates=1290, lr=1.11553e-06, gnorm=1.14, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12352
2022-10-11 21:01:47 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=93.3, ups=0.83, wpb=111.9, bsz=40, num_updates=1300, lr=1.12418e-06, gnorm=1.13, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12364
2022-10-11 21:01:59 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.5, ups=0.84, wpb=110.4, bsz=40, num_updates=1310, lr=1.13283e-06, gnorm=0.939, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12376
2022-10-11 21:02:11 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 28910 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=94.1, ups=0.86, wpb=109.6, bsz=40, num_updates=1320, lr=1.14147e-06, gnorm=1.198, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12388
2022-10-11 21:02:23 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 28910 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.2, ups=0.85, wpb=110.8, bsz=40, num_updates=1330, lr=1.15012e-06, gnorm=0.922, clip=30, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=12399
2022-10-11 21:02:34 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 28910 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=95, ups=0.85, wpb=112.1, bsz=40, num_updates=1340, lr=1.15877e-06, gnorm=0.899, clip=40, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=12411
2022-10-11 21:02:46 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 28910 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.7, ups=0.83, wpb=110.5, bsz=40, num_updates=1350, lr=1.16742e-06, gnorm=1.058, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12423
2022-10-11 21:02:58 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 28910 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=94.2, ups=0.85, wpb=111, bsz=40, num_updates=1360, lr=1.17606e-06, gnorm=0.999, clip=40, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=12435
2022-10-11 21:03:10 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 28910 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=92.3, ups=0.84, wpb=109.7, bsz=40, num_updates=1370, lr=1.18471e-06, gnorm=1.162, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12447
2022-10-11 21:03:22 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 28910 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96, ups=0.87, wpb=110.2, bsz=40, num_updates=1380, lr=1.19336e-06, gnorm=1.208, clip=60, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=12458
2022-10-11 21:03:33 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 28910 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.7, ups=0.85, wpb=109.7, bsz=40, num_updates=1390, lr=1.20201e-06, gnorm=0.971, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12470
2022-10-11 21:03:45 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 28910 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92, ups=0.84, wpb=109.3, bsz=40, num_updates=1400, lr=1.21065e-06, gnorm=1.28, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12482
2022-10-11 21:03:57 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.2, ups=0.83, wpb=110.9, bsz=40, num_updates=1410, lr=1.2193e-06, gnorm=0.943, clip=20, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12494
2022-10-11 21:04:09 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 28910 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.4, ups=0.83, wpb=110.2, bsz=40, num_updates=1420, lr=1.22795e-06, gnorm=1.081, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12506
2022-10-11 21:04:22 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 28910 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.4, ups=0.83, wpb=109.8, bsz=40, num_updates=1430, lr=1.2366e-06, gnorm=1.119, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12518
2022-10-11 21:04:34 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 28910 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.4, ups=0.83, wpb=108.6, bsz=40, num_updates=1440, lr=1.24524e-06, gnorm=0.995, clip=40, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=12530
2022-10-11 21:04:45 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 28910 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=93.6, ups=0.84, wpb=110.9, bsz=40, num_updates=1450, lr=1.25389e-06, gnorm=1.1, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12542
2022-10-11 21:04:58 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 28910 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.8, ups=0.82, wpb=109.1, bsz=40, num_updates=1460, lr=1.26254e-06, gnorm=1.195, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12554
2022-10-11 21:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 28910 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93.3, ups=0.84, wpb=110.7, bsz=40, num_updates=1470, lr=1.27119e-06, gnorm=0.988, clip=30, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12566
2022-10-11 21:05:21 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 28910 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.1, ups=0.84, wpb=110.5, bsz=40, num_updates=1480, lr=1.27983e-06, gnorm=1.026, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12578
2022-10-11 21:05:33 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 28910 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.2, ups=0.86, wpb=110.8, bsz=40, num_updates=1490, lr=1.28848e-06, gnorm=1.103, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12590
2022-10-11 21:05:45 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.9, ups=0.85, wpb=111.8, bsz=40, num_updates=1500, lr=1.29713e-06, gnorm=1.023, clip=40, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12602
2022-10-11 21:05:56 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 28910 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=94.5, ups=0.85, wpb=110.6, bsz=40, num_updates=1510, lr=1.30578e-06, gnorm=1.05, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12613
2022-10-11 21:06:08 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 28910 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93.5, ups=0.85, wpb=110.1, bsz=40, num_updates=1520, lr=1.31442e-06, gnorm=1.058, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12625
2022-10-11 21:06:20 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 28910 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.2, ups=0.86, wpb=111.6, bsz=40, num_updates=1530, lr=1.32307e-06, gnorm=1.066, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12637
2022-10-11 21:06:32 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 28910 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=93.8, ups=0.85, wpb=110.2, bsz=40, num_updates=1540, lr=1.33172e-06, gnorm=1.23, clip=90, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12648
2022-10-11 21:06:44 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 28910 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93, ups=0.84, wpb=111, bsz=40, num_updates=1550, lr=1.34037e-06, gnorm=1.056, clip=70, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12660
2022-10-11 21:06:55 - progress_bar.py[line:274] - INFO: epoch 001:   1560 / 28910 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=93.6, ups=0.85, wpb=109.6, bsz=40, num_updates=1560, lr=1.34901e-06, gnorm=1.061, clip=50, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12672
2022-10-11 21:07:07 - progress_bar.py[line:274] - INFO: epoch 001:   1570 / 28910 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=93.7, ups=0.85, wpb=109.7, bsz=40, num_updates=1570, lr=1.35766e-06, gnorm=1.034, clip=50, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12684
2022-10-11 21:07:19 - progress_bar.py[line:274] - INFO: epoch 001:   1580 / 28910 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=93.9, ups=0.85, wpb=110.9, bsz=40, num_updates=1580, lr=1.36631e-06, gnorm=1.048, clip=60, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12696
2022-10-11 21:07:31 - progress_bar.py[line:274] - INFO: epoch 001:   1590 / 28910 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.3, ups=0.84, wpb=111.3, bsz=40, num_updates=1590, lr=1.37496e-06, gnorm=1.065, clip=60, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12708
2022-10-11 21:07:33 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-11 21:07:44 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87, ups=0.78, wpb=112.2, bsz=40, num_updates=1600, lr=1.3836e-06, gnorm=0.889, clip=30, loss_scale=512, train_wall=13, gb_free=23.1, ema_decay=0.9999, wall=12721
2022-10-11 21:07:56 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.1, ups=0.83, wpb=109.4, bsz=40, num_updates=1610, lr=1.39225e-06, gnorm=1.155, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12733
2022-10-11 21:08:08 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 28910 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=93.2, ups=0.85, wpb=110, bsz=40, num_updates=1620, lr=1.4009e-06, gnorm=0.975, clip=30, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12744
2022-10-11 21:08:20 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94, ups=0.84, wpb=111.3, bsz=40, num_updates=1630, lr=1.40955e-06, gnorm=0.954, clip=20, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12756
2022-10-11 21:08:31 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 28910 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93, ups=0.84, wpb=110.6, bsz=40, num_updates=1640, lr=1.41819e-06, gnorm=1.052, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12768
2022-10-11 21:08:43 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.2, ups=0.85, wpb=110.5, bsz=40, num_updates=1650, lr=1.42684e-06, gnorm=1.059, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12780
2022-10-11 21:08:55 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 28910 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93.2, ups=0.84, wpb=110.8, bsz=40, num_updates=1660, lr=1.43549e-06, gnorm=1.113, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12792
2022-10-11 21:09:07 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 28910 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.4, ups=0.84, wpb=110.6, bsz=40, num_updates=1670, lr=1.44414e-06, gnorm=1.032, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12804
2022-10-11 21:09:19 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.6, ups=0.84, wpb=109.6, bsz=40, num_updates=1680, lr=1.45278e-06, gnorm=1.145, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12816
2022-10-11 21:09:31 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 28910 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.7, ups=0.83, wpb=110.2, bsz=40, num_updates=1690, lr=1.46143e-06, gnorm=1.153, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12828
2022-10-11 21:09:43 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 28910 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=93.7, ups=0.86, wpb=109.2, bsz=40, num_updates=1700, lr=1.47008e-06, gnorm=1.248, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12839
2022-10-11 21:09:55 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=93.5, ups=0.85, wpb=109.8, bsz=40, num_updates=1710, lr=1.47873e-06, gnorm=1.159, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=12851
2022-10-11 21:10:06 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 28910 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93, ups=0.84, wpb=110.6, bsz=40, num_updates=1720, lr=1.48737e-06, gnorm=0.958, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12863
2022-10-11 21:10:19 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.4, ups=0.83, wpb=110.6, bsz=40, num_updates=1730, lr=1.49602e-06, gnorm=1.091, clip=60, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=12875
2022-10-11 21:10:30 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 28910 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=93.1, ups=0.85, wpb=110.1, bsz=40, num_updates=1740, lr=1.50467e-06, gnorm=0.903, clip=20, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12887
2022-10-11 21:10:42 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=93, ups=0.84, wpb=110.6, bsz=40, num_updates=1750, lr=1.51332e-06, gnorm=1.037, clip=40, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12899
2022-10-11 21:10:54 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 28910 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94, ups=0.85, wpb=111.2, bsz=40, num_updates=1760, lr=1.52196e-06, gnorm=1, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12911
2022-10-11 21:11:06 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=93, ups=0.84, wpb=110.3, bsz=40, num_updates=1770, lr=1.53061e-06, gnorm=1.046, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12923
2022-10-11 21:11:18 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 28910 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.9, ups=0.81, wpb=110.6, bsz=40, num_updates=1780, lr=1.53926e-06, gnorm=1.111, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=12935
2022-10-11 21:11:30 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=93.2, ups=0.84, wpb=111.2, bsz=40, num_updates=1790, lr=1.54791e-06, gnorm=1.061, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12947
2022-10-11 21:11:42 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 28910 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93, ups=0.85, wpb=109.6, bsz=40, num_updates=1800, lr=1.55655e-06, gnorm=1.131, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12959
2022-10-11 21:11:54 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 28910 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.3, ups=0.83, wpb=108.4, bsz=40, num_updates=1810, lr=1.5652e-06, gnorm=1.055, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=12971
2022-10-11 21:12:06 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 28910 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.7, ups=0.84, wpb=110.3, bsz=40, num_updates=1820, lr=1.57385e-06, gnorm=1.005, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=12983
2022-10-11 21:12:18 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 28910 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.6, ups=0.84, wpb=108.3, bsz=40, num_updates=1830, lr=1.5825e-06, gnorm=0.998, clip=40, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=12995
2022-10-11 21:12:30 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 28910 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.2, ups=0.82, wpb=110.4, bsz=40, num_updates=1840, lr=1.59114e-06, gnorm=1.223, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=13007
2022-10-11 21:12:42 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.1, ups=0.87, wpb=111.9, bsz=40, num_updates=1850, lr=1.59979e-06, gnorm=0.918, clip=40, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=13018
2022-10-11 21:12:54 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.7, ups=0.84, wpb=109, bsz=40, num_updates=1860, lr=1.60844e-06, gnorm=1.049, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=13030
2022-10-11 21:13:06 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 28910 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=93.8, ups=0.84, wpb=111.8, bsz=40, num_updates=1870, lr=1.61709e-06, gnorm=1.016, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=13042
2022-10-11 21:13:17 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=94.7, ups=0.86, wpb=110.4, bsz=40, num_updates=1880, lr=1.62574e-06, gnorm=1.051, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=13054
2022-10-11 21:13:29 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.5, ups=0.84, wpb=111.1, bsz=40, num_updates=1890, lr=1.63438e-06, gnorm=1.105, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=13066
2022-10-11 21:13:41 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 28910 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.4, ups=0.85, wpb=109.2, bsz=40, num_updates=1900, lr=1.64303e-06, gnorm=1.108, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=13078
2022-10-11 21:13:53 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.5, ups=0.83, wpb=109.2, bsz=40, num_updates=1910, lr=1.65168e-06, gnorm=1.032, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=13090
2022-10-11 21:14:05 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.1, ups=0.85, wpb=110.9, bsz=40, num_updates=1920, lr=1.66033e-06, gnorm=1, clip=30, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=13102
2022-10-11 21:14:17 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.6, ups=0.82, wpb=110, bsz=40, num_updates=1930, lr=1.66897e-06, gnorm=0.985, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=13114
2022-10-11 21:14:29 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=93.1, ups=0.84, wpb=110.4, bsz=40, num_updates=1940, lr=1.67762e-06, gnorm=1.08, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=13126
2022-10-11 21:14:41 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.1, ups=0.84, wpb=110.2, bsz=40, num_updates=1950, lr=1.68627e-06, gnorm=0.987, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=13138
2022-10-11 21:14:53 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.1, ups=0.86, wpb=108.9, bsz=40, num_updates=1960, lr=1.69492e-06, gnorm=1.06, clip=40, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=13149
2022-10-11 21:15:05 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.6, ups=0.82, wpb=110.3, bsz=40, num_updates=1970, lr=1.70356e-06, gnorm=1.006, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=13161
2022-10-11 21:15:17 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.3, ups=0.83, wpb=111.8, bsz=40, num_updates=1980, lr=1.71221e-06, gnorm=0.996, clip=30, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=13173
2022-10-11 21:15:28 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.9, ups=0.85, wpb=111.2, bsz=40, num_updates=1990, lr=1.72086e-06, gnorm=1.009, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=13185
2022-10-11 21:15:40 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.8, ups=0.84, wpb=109.5, bsz=40, num_updates=2000, lr=1.72951e-06, gnorm=1.045, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=13197
2022-10-11 21:15:40 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-11 21:15:41 - train.py[line:549] - INFO: 0 / 9351
2022-10-11 21:15:41 - train.py[line:551] - INFO: load:0.79 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-11 21:17:06 - train.py[line:549] - INFO: 200 / 9351
2022-10-11 21:17:06 - train.py[line:551] - INFO: load:0.82 valid_run:84.40 task_valid:81.61 collect_output:1.63
2022-10-11 21:18:30 - train.py[line:549] - INFO: 400 / 9351
2022-10-11 21:18:30 - train.py[line:551] - INFO: load:0.84 valid_run:168.63 task_valid:163.22 collect_output:3.10
2022-10-11 21:19:53 - train.py[line:549] - INFO: 600 / 9351
2022-10-11 21:19:53 - train.py[line:551] - INFO: load:0.86 valid_run:251.55 task_valid:242.61 collect_output:5.44
2022-10-11 21:21:17 - train.py[line:549] - INFO: 800 / 9351
2022-10-11 21:21:17 - train.py[line:551] - INFO: load:0.88 valid_run:335.26 task_valid:321.71 collect_output:8.92
2022-10-11 21:22:41 - train.py[line:549] - INFO: 1000 / 9351
2022-10-11 21:22:41 - train.py[line:551] - INFO: load:0.90 valid_run:419.53 task_valid:400.85 collect_output:13.05
2022-10-11 21:24:05 - train.py[line:549] - INFO: 1200 / 9351
2022-10-11 21:24:05 - train.py[line:551] - INFO: load:0.92 valid_run:503.04 task_valid:479.10 collect_output:17.23
2022-10-11 21:25:28 - train.py[line:549] - INFO: 1400 / 9351
2022-10-11 21:25:28 - train.py[line:551] - INFO: load:0.94 valid_run:586.06 task_valid:559.16 collect_output:19.16
2022-10-11 21:26:52 - train.py[line:549] - INFO: 1600 / 9351
2022-10-11 21:26:52 - train.py[line:551] - INFO: load:0.97 valid_run:669.81 task_valid:641.04 collect_output:20.00
2022-10-11 21:28:16 - train.py[line:549] - INFO: 1800 / 9351
2022-10-11 21:28:16 - train.py[line:551] - INFO: load:0.99 valid_run:754.24 task_valid:721.50 collect_output:22.89
2022-10-11 21:29:40 - train.py[line:549] - INFO: 2000 / 9351
2022-10-11 21:29:40 - train.py[line:551] - INFO: load:1.01 valid_run:838.45 task_valid:801.92 collect_output:25.63
2022-10-11 21:31:05 - train.py[line:549] - INFO: 2200 / 9351
2022-10-11 21:31:05 - train.py[line:551] - INFO: load:1.03 valid_run:922.54 task_valid:881.77 collect_output:28.79
2022-10-11 21:32:29 - train.py[line:549] - INFO: 2400 / 9351
2022-10-11 21:32:29 - train.py[line:551] - INFO: load:1.05 valid_run:1006.63 task_valid:962.28 collect_output:31.33
2022-10-11 21:33:54 - train.py[line:549] - INFO: 2600 / 9351
2022-10-11 21:33:54 - train.py[line:551] - INFO: load:1.08 valid_run:1091.52 task_valid:1042.27 collect_output:35.19
2022-10-11 21:35:18 - train.py[line:549] - INFO: 2800 / 9351
2022-10-11 21:35:18 - train.py[line:551] - INFO: load:1.10 valid_run:1175.68 task_valid:1121.15 collect_output:39.36
2022-10-11 21:36:41 - train.py[line:549] - INFO: 3000 / 9351
2022-10-11 21:36:41 - train.py[line:551] - INFO: load:1.12 valid_run:1258.78 task_valid:1198.43 collect_output:44.16
2022-10-11 21:38:03 - train.py[line:549] - INFO: 3200 / 9351
2022-10-11 21:38:03 - train.py[line:551] - INFO: load:1.14 valid_run:1340.85 task_valid:1277.21 collect_output:46.43
2022-10-11 21:39:27 - train.py[line:549] - INFO: 3400 / 9351
2022-10-11 21:39:27 - train.py[line:551] - INFO: load:1.16 valid_run:1424.52 task_valid:1356.43 collect_output:49.87
2022-10-11 21:40:50 - train.py[line:549] - INFO: 3600 / 9351
2022-10-11 21:40:50 - train.py[line:551] - INFO: load:1.18 valid_run:1507.72 task_valid:1436.86 collect_output:51.59
2022-10-11 21:42:12 - train.py[line:549] - INFO: 3800 / 9351
2022-10-11 21:42:12 - train.py[line:551] - INFO: load:1.20 valid_run:1589.68 task_valid:1514.52 collect_output:54.85
2022-10-11 21:43:35 - train.py[line:549] - INFO: 4000 / 9351
2022-10-11 21:43:35 - train.py[line:551] - INFO: load:1.23 valid_run:1672.22 task_valid:1593.79 collect_output:57.01
2022-10-11 21:44:58 - train.py[line:549] - INFO: 4200 / 9351
2022-10-11 21:44:58 - train.py[line:551] - INFO: load:1.25 valid_run:1755.92 task_valid:1675.41 collect_output:58.02
2022-10-11 21:46:22 - train.py[line:549] - INFO: 4400 / 9351
2022-10-11 21:46:22 - train.py[line:551] - INFO: load:1.27 valid_run:1839.19 task_valid:1754.92 collect_output:60.73
2022-10-11 21:47:44 - train.py[line:549] - INFO: 4600 / 9351
2022-10-11 21:47:44 - train.py[line:551] - INFO: load:1.29 valid_run:1921.57 task_valid:1833.60 collect_output:63.44
2022-10-11 21:49:08 - train.py[line:549] - INFO: 4800 / 9351
2022-10-11 21:49:08 - train.py[line:551] - INFO: load:1.32 valid_run:2005.09 task_valid:1911.67 collect_output:67.87
2022-10-11 21:50:31 - train.py[line:549] - INFO: 5000 / 9351
2022-10-11 21:50:31 - train.py[line:551] - INFO: load:1.34 valid_run:2088.70 task_valid:1991.92 collect_output:70.22
2022-10-11 21:51:55 - train.py[line:549] - INFO: 5200 / 9351
2022-10-11 21:51:55 - train.py[line:551] - INFO: load:1.36 valid_run:2171.96 task_valid:2072.04 collect_output:72.33
2022-10-11 21:53:18 - train.py[line:549] - INFO: 5400 / 9351
2022-10-11 21:53:18 - train.py[line:551] - INFO: load:1.38 valid_run:2254.69 task_valid:2151.94 collect_output:74.13
2022-10-11 21:54:41 - train.py[line:549] - INFO: 5600 / 9351
2022-10-11 21:54:41 - train.py[line:551] - INFO: load:1.40 valid_run:2338.52 task_valid:2232.87 collect_output:76.01
2022-10-11 21:56:04 - train.py[line:549] - INFO: 5800 / 9351
2022-10-11 21:56:04 - train.py[line:551] - INFO: load:1.43 valid_run:2421.46 task_valid:2311.91 collect_output:78.87
2022-10-11 21:57:27 - train.py[line:549] - INFO: 6000 / 9351
2022-10-11 21:57:27 - train.py[line:551] - INFO: load:1.45 valid_run:2504.30 task_valid:2391.68 collect_output:80.93
2022-10-11 21:58:50 - train.py[line:549] - INFO: 6200 / 9351
2022-10-11 21:58:50 - train.py[line:551] - INFO: load:1.47 valid_run:2587.25 task_valid:2471.17 collect_output:83.35
2022-10-11 22:00:15 - train.py[line:549] - INFO: 6400 / 9351
2022-10-11 22:00:15 - train.py[line:551] - INFO: load:1.49 valid_run:2672.05 task_valid:2552.36 collect_output:85.94
2022-10-11 22:01:39 - train.py[line:549] - INFO: 6600 / 9351
2022-10-11 22:01:39 - train.py[line:551] - INFO: load:1.51 valid_run:2755.67 task_valid:2633.74 collect_output:87.13
2022-10-11 22:03:02 - train.py[line:549] - INFO: 6800 / 9351
2022-10-11 22:03:02 - train.py[line:551] - INFO: load:1.54 valid_run:2838.83 task_valid:2713.09 collect_output:89.91
2022-10-11 22:04:25 - train.py[line:549] - INFO: 7000 / 9351
2022-10-11 22:04:25 - train.py[line:551] - INFO: load:1.56 valid_run:2921.65 task_valid:2791.83 collect_output:92.92
2022-10-11 22:05:48 - train.py[line:549] - INFO: 7200 / 9351
2022-10-11 22:05:48 - train.py[line:551] - INFO: load:1.58 valid_run:3004.58 task_valid:2871.63 collect_output:94.98
2022-10-11 22:07:12 - train.py[line:549] - INFO: 7400 / 9351
2022-10-11 22:07:12 - train.py[line:551] - INFO: load:1.60 valid_run:3088.75 task_valid:2951.08 collect_output:98.43
2022-10-11 22:08:38 - train.py[line:549] - INFO: 7600 / 9351
2022-10-11 22:08:38 - train.py[line:551] - INFO: load:1.63 valid_run:3174.73 task_valid:3032.28 collect_output:101.93
2022-10-11 22:10:04 - train.py[line:549] - INFO: 7800 / 9351
2022-10-11 22:10:04 - train.py[line:551] - INFO: load:1.65 valid_run:3260.12 task_valid:3113.33 collect_output:105.04
2022-10-11 22:11:27 - train.py[line:549] - INFO: 8000 / 9351
2022-10-11 22:11:27 - train.py[line:551] - INFO: load:1.67 valid_run:3343.80 task_valid:3192.19 collect_output:108.63
2022-10-11 22:12:52 - train.py[line:549] - INFO: 8200 / 9351
2022-10-11 22:12:52 - train.py[line:551] - INFO: load:1.69 valid_run:3428.39 task_valid:3273.99 collect_output:110.24
2022-10-11 22:14:17 - train.py[line:549] - INFO: 8400 / 9351
2022-10-11 22:14:17 - train.py[line:551] - INFO: load:1.71 valid_run:3512.76 task_valid:3355.43 collect_output:111.94
2022-10-11 22:15:42 - train.py[line:549] - INFO: 8600 / 9351
2022-10-11 22:15:42 - train.py[line:551] - INFO: load:1.74 valid_run:3598.03 task_valid:3436.65 collect_output:114.77
2022-10-11 22:17:07 - train.py[line:549] - INFO: 8800 / 9351
2022-10-11 22:17:07 - train.py[line:551] - INFO: load:1.76 valid_run:3682.70 task_valid:3516.49 collect_output:118.36
2022-10-11 22:18:32 - train.py[line:549] - INFO: 9000 / 9351
2022-10-11 22:18:32 - train.py[line:551] - INFO: load:1.78 valid_run:3768.00 task_valid:3599.11 collect_output:119.79
2022-10-11 22:19:56 - train.py[line:549] - INFO: 9200 / 9351
2022-10-11 22:19:56 - train.py[line:551] - INFO: load:1.81 valid_run:3852.22 task_valid:3680.49 collect_output:121.47

====================================================================================================
SGG eval:     R @ 50: 0.6507;     R @ 100: 0.6908;     R @ 500: 0.7179;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4462;    mR @ 100: 0.4957;    mR @ 500: 0.5265;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5625) (covering:0.5143) (eating:0.8235) (flying in:1.0000) (growing on:0.2500) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7092) (standing on:0.4713) (using:0.5000) (walking in:0.0000) (walking on:0.6351) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2022-10-11 22:21:11 - train.py[line:487] - INFO: 0.6908134453781511

====================================================================================================
SGG eval:     R @ 50: 0.6507;     R @ 100: 0.6908;     R @ 500: 0.7179;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4462;    mR @ 100: 0.4957;    mR @ 500: 0.5265;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5625) (covering:0.5143) (eating:0.8235) (flying in:1.0000) (growing on:0.2500) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7092) (standing on:0.4713) (using:0.5000) (walking in:0.0000) (walking on:0.6351) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2022-10-11 22:21:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-11 22:21:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.321 | loss_v1 0 | loss_v2 0 | nll_loss 0.193 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.690813 | ppl 1.14 | vqa_score 0.5169 | wps 114.2 | wpb 48 | bsz 16 | num_updates 2000 | best_R@100 0.690813
2022-10-11 22:21:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2022-10-11 22:21:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-11 22:21:17 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-11 22:21:23 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.6908134453781511) (writing took 11.725669256411493 seconds)
2022-10-11 22:21:35 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 28910 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=2010, lr=1.73815e-06, gnorm=1.065, clip=70, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=17151
2022-10-11 22:21:47 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.6, ups=0.83, wpb=109.3, bsz=40, num_updates=2020, lr=1.7468e-06, gnorm=1.122, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17163
2022-10-11 22:21:59 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 28910 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.4, ups=0.82, wpb=110.3, bsz=40, num_updates=2030, lr=1.75545e-06, gnorm=1.073, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17176
2022-10-11 22:22:11 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.9, ups=0.85, wpb=109.7, bsz=40, num_updates=2040, lr=1.7641e-06, gnorm=1.023, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17187
2022-10-11 22:22:23 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.5, ups=0.84, wpb=109.7, bsz=40, num_updates=2050, lr=1.77274e-06, gnorm=1.028, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17199
2022-10-11 22:22:34 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.2, ups=0.85, wpb=110.7, bsz=40, num_updates=2060, lr=1.78139e-06, gnorm=1.1, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17211
2022-10-11 22:22:46 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 28910 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.6, ups=0.83, wpb=108.5, bsz=40, num_updates=2070, lr=1.79004e-06, gnorm=1.088, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17223
2022-10-11 22:22:58 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.3, ups=0.84, wpb=110.2, bsz=40, num_updates=2080, lr=1.79869e-06, gnorm=1.056, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17235
2022-10-11 22:23:10 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 28910 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=94.3, ups=0.86, wpb=109.8, bsz=40, num_updates=2090, lr=1.80733e-06, gnorm=1.15, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17247
2022-10-11 22:23:22 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.3, ups=0.86, wpb=111.1, bsz=40, num_updates=2100, lr=1.81598e-06, gnorm=0.994, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17258
2022-10-11 22:23:34 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 28910 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=92.3, ups=0.84, wpb=109.7, bsz=40, num_updates=2110, lr=1.82463e-06, gnorm=1.153, clip=70, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17270
2022-10-11 22:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   2121 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.9, ups=0.84, wpb=108.7, bsz=40, num_updates=2120, lr=1.83328e-06, gnorm=1.129, clip=80, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17282
2022-10-11 22:23:57 - progress_bar.py[line:274] - INFO: epoch 001:   2131 / 28910 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=92.1, ups=0.85, wpb=108.8, bsz=40, num_updates=2130, lr=1.84192e-06, gnorm=1.173, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17294
2022-10-11 22:23:59 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-11 22:24:10 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 28910 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=83.7, ups=0.77, wpb=108.3, bsz=40, num_updates=2140, lr=1.85057e-06, gnorm=1.144, clip=80, loss_scale=512, train_wall=13, gb_free=22.9, ema_decay=0.9999, wall=17307
2022-10-11 22:24:22 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.2, ups=0.85, wpb=110.1, bsz=40, num_updates=2150, lr=1.85922e-06, gnorm=1.013, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17319
2022-10-11 22:24:34 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.6, ups=0.84, wpb=110.2, bsz=40, num_updates=2160, lr=1.86787e-06, gnorm=1.036, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17331
2022-10-11 22:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.8, ups=0.84, wpb=109.2, bsz=40, num_updates=2170, lr=1.87651e-06, gnorm=1.184, clip=100, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17343
2022-10-11 22:24:58 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 28910 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.8, ups=0.83, wpb=111.4, bsz=40, num_updates=2180, lr=1.88516e-06, gnorm=1.08, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17355
2022-10-11 22:25:10 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 28910 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.2, ups=0.84, wpb=110.4, bsz=40, num_updates=2190, lr=1.89381e-06, gnorm=1.109, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17367
2022-10-11 22:25:22 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.3, ups=0.86, wpb=109.4, bsz=40, num_updates=2200, lr=1.90246e-06, gnorm=1.092, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17378
2022-10-11 22:25:33 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.4, ups=0.84, wpb=111.2, bsz=40, num_updates=2210, lr=1.9111e-06, gnorm=1.008, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17390
2022-10-11 22:25:45 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.4, ups=0.86, wpb=109.7, bsz=40, num_updates=2220, lr=1.91975e-06, gnorm=1.114, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17402
2022-10-11 22:25:57 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 28910 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.8, ups=0.83, wpb=110.5, bsz=40, num_updates=2230, lr=1.9284e-06, gnorm=1.123, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17414
2022-10-11 22:26:09 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 28910 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.3, ups=0.84, wpb=109.2, bsz=40, num_updates=2240, lr=1.93705e-06, gnorm=1.159, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17426
2022-10-11 22:26:21 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.2, ups=0.84, wpb=110.4, bsz=40, num_updates=2250, lr=1.94569e-06, gnorm=1.162, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17438
2022-10-11 22:26:33 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.4, ups=0.85, wpb=112, bsz=40, num_updates=2260, lr=1.95434e-06, gnorm=1.029, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17449
2022-10-11 22:26:45 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.1, ups=0.85, wpb=111.1, bsz=40, num_updates=2270, lr=1.96299e-06, gnorm=1.048, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17461
2022-10-11 22:26:56 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 28910 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.3, ups=0.86, wpb=111.1, bsz=40, num_updates=2280, lr=1.97164e-06, gnorm=1.033, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17473
2022-10-11 22:27:08 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95, ups=0.86, wpb=110.8, bsz=40, num_updates=2290, lr=1.98028e-06, gnorm=1.025, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17485
2022-10-11 22:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.1, ups=0.85, wpb=109.4, bsz=40, num_updates=2300, lr=1.98893e-06, gnorm=1.092, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17496
2022-10-11 22:27:31 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.8, ups=0.86, wpb=110.3, bsz=40, num_updates=2310, lr=1.99758e-06, gnorm=1.092, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17508
2022-10-11 22:27:43 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.8, ups=0.84, wpb=108.9, bsz=40, num_updates=2320, lr=2.00623e-06, gnorm=1.133, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17520
2022-10-11 22:27:55 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.2, ups=0.85, wpb=109.3, bsz=40, num_updates=2330, lr=2.01487e-06, gnorm=1.127, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17532
2022-10-11 22:28:07 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.6, ups=0.85, wpb=110.4, bsz=40, num_updates=2340, lr=2.02352e-06, gnorm=1.058, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17544
2022-10-11 22:28:19 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 28910 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.3, ups=0.84, wpb=110.2, bsz=40, num_updates=2350, lr=2.03217e-06, gnorm=1.205, clip=100, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17555
2022-10-11 22:28:31 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 28910 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.1, ups=0.83, wpb=109.6, bsz=40, num_updates=2360, lr=2.04082e-06, gnorm=1.181, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17568
2022-10-11 22:28:43 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.2, ups=0.84, wpb=111.2, bsz=40, num_updates=2370, lr=2.04946e-06, gnorm=0.99, clip=40, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17579
2022-10-11 22:28:54 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 28910 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95, ups=0.86, wpb=111.1, bsz=40, num_updates=2380, lr=2.05811e-06, gnorm=1.065, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17591
2022-10-11 22:29:06 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.1, ups=0.84, wpb=110.1, bsz=40, num_updates=2390, lr=2.06676e-06, gnorm=1.068, clip=40, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17603
2022-10-11 22:29:18 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.8, ups=0.84, wpb=109.5, bsz=40, num_updates=2400, lr=2.07541e-06, gnorm=1.12, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17615
2022-10-11 22:29:30 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.5, ups=0.84, wpb=110.2, bsz=40, num_updates=2410, lr=2.08405e-06, gnorm=1.105, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17627
2022-10-11 22:29:42 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 28910 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.3, ups=0.86, wpb=110.2, bsz=40, num_updates=2420, lr=2.0927e-06, gnorm=1.163, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17639
2022-10-11 22:29:54 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.3, ups=0.84, wpb=110.9, bsz=40, num_updates=2430, lr=2.10135e-06, gnorm=1.071, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17650
2022-10-11 22:30:06 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94, ups=0.84, wpb=111.9, bsz=40, num_updates=2440, lr=2.11e-06, gnorm=1.058, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17662
2022-10-11 22:30:18 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 28910 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.4, ups=0.84, wpb=109.5, bsz=40, num_updates=2450, lr=2.11864e-06, gnorm=1.084, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17674
2022-10-11 22:30:29 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 28910 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.4, ups=0.85, wpb=110.9, bsz=40, num_updates=2460, lr=2.12729e-06, gnorm=1.032, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17686
2022-10-11 22:30:41 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.4, ups=0.85, wpb=111.8, bsz=40, num_updates=2470, lr=2.13594e-06, gnorm=1.074, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17698
2022-10-11 22:30:53 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.8, ups=0.85, wpb=109.5, bsz=40, num_updates=2480, lr=2.14459e-06, gnorm=1.091, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17710
2022-10-11 22:31:05 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.2, ups=0.83, wpb=111.5, bsz=40, num_updates=2490, lr=2.15323e-06, gnorm=1.041, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17722
2022-10-11 22:31:17 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.5, ups=0.84, wpb=110.8, bsz=40, num_updates=2500, lr=2.16188e-06, gnorm=0.934, clip=20, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17734
2022-10-11 22:31:29 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 28910 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=93.2, ups=0.85, wpb=110.3, bsz=40, num_updates=2510, lr=2.17053e-06, gnorm=1.121, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17746
2022-10-11 22:31:41 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.3, ups=0.84, wpb=109.9, bsz=40, num_updates=2520, lr=2.17918e-06, gnorm=1.097, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17757
2022-10-11 22:31:53 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.8, ups=0.83, wpb=110.4, bsz=40, num_updates=2530, lr=2.18782e-06, gnorm=1.103, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17770
2022-10-11 22:32:04 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.5, ups=0.86, wpb=111, bsz=40, num_updates=2540, lr=2.19647e-06, gnorm=1.044, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17781
2022-10-11 22:32:16 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.3, ups=0.85, wpb=108.7, bsz=40, num_updates=2550, lr=2.20512e-06, gnorm=1.172, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17793
2022-10-11 22:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.4, ups=0.85, wpb=111.7, bsz=40, num_updates=2560, lr=2.21377e-06, gnorm=0.977, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17805
2022-10-11 22:32:40 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.5, ups=0.85, wpb=111.3, bsz=40, num_updates=2570, lr=2.22241e-06, gnorm=1.015, clip=40, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17817
2022-10-11 22:32:52 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.4, ups=0.84, wpb=110, bsz=40, num_updates=2580, lr=2.23106e-06, gnorm=1.085, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=17828
2022-10-11 22:33:04 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.8, ups=0.84, wpb=109.8, bsz=40, num_updates=2590, lr=2.23971e-06, gnorm=1.027, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17840
2022-10-11 22:33:16 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.7, ups=0.84, wpb=111.2, bsz=40, num_updates=2600, lr=2.24836e-06, gnorm=1.028, clip=30, loss_scale=512, train_wall=12, gb_free=22.5, ema_decay=0.9999, wall=17852
2022-10-11 22:33:27 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.2, ups=0.85, wpb=111.2, bsz=40, num_updates=2610, lr=2.257e-06, gnorm=1.08, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17864
2022-10-11 22:33:39 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 28910 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=93.6, ups=0.84, wpb=111.9, bsz=40, num_updates=2620, lr=2.26565e-06, gnorm=1.1, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17876
2022-10-11 22:33:51 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.7, ups=0.84, wpb=109.6, bsz=40, num_updates=2630, lr=2.2743e-06, gnorm=1.066, clip=40, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=17888
2022-10-11 22:34:03 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.9, ups=0.83, wpb=111.3, bsz=40, num_updates=2640, lr=2.28295e-06, gnorm=1.138, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17900
2022-10-11 22:34:15 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.4, ups=0.84, wpb=110.7, bsz=40, num_updates=2650, lr=2.29159e-06, gnorm=1.056, clip=60, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17912
2022-10-11 22:34:27 - progress_bar.py[line:274] - INFO: epoch 001:   2662 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.5, ups=0.84, wpb=109.8, bsz=40, num_updates=2660, lr=2.30024e-06, gnorm=1.036, clip=60, loss_scale=1024, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=17924
2022-10-11 22:34:39 - progress_bar.py[line:274] - INFO: epoch 001:   2672 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.9, ups=0.86, wpb=107.3, bsz=40, num_updates=2670, lr=2.30889e-06, gnorm=1.21, clip=80, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=17935
2022-10-11 22:34:51 - progress_bar.py[line:274] - INFO: epoch 001:   2682 / 28910 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.1, ups=0.83, wpb=110.4, bsz=40, num_updates=2680, lr=2.31754e-06, gnorm=1.091, clip=80, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17948
2022-10-11 22:35:03 - progress_bar.py[line:274] - INFO: epoch 001:   2692 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.2, ups=0.82, wpb=110.4, bsz=40, num_updates=2690, lr=2.32618e-06, gnorm=1.124, clip=90, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17960
2022-10-11 22:35:07 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-11 22:35:16 - progress_bar.py[line:274] - INFO: epoch 001:   2703 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86, ups=0.78, wpb=110.7, bsz=40, num_updates=2700, lr=2.33483e-06, gnorm=1.098, clip=70, loss_scale=512, train_wall=13, gb_free=22.8, ema_decay=0.9999, wall=17973
2022-10-11 22:35:28 - progress_bar.py[line:274] - INFO: epoch 001:   2713 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.84, wpb=110.1, bsz=40, num_updates=2710, lr=2.34348e-06, gnorm=1.1, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=17985
2022-10-11 22:35:40 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 28910 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.9, ups=0.84, wpb=110.5, bsz=40, num_updates=2720, lr=2.35213e-06, gnorm=1.193, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=17997
2022-10-11 22:35:52 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.1, ups=0.84, wpb=108.2, bsz=40, num_updates=2730, lr=2.36077e-06, gnorm=1.129, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18008
2022-10-11 22:36:04 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.6, ups=0.85, wpb=110.5, bsz=40, num_updates=2740, lr=2.36942e-06, gnorm=1.076, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18020
2022-10-11 22:36:15 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.2, ups=0.85, wpb=110.1, bsz=40, num_updates=2750, lr=2.37807e-06, gnorm=1.169, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=18032
2022-10-11 22:36:27 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.8, ups=0.86, wpb=109.6, bsz=40, num_updates=2760, lr=2.38672e-06, gnorm=1.083, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=18044
2022-10-11 22:36:38 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.4, ups=0.87, wpb=110.2, bsz=40, num_updates=2770, lr=2.39536e-06, gnorm=1.03, clip=70, loss_scale=512, train_wall=11, gb_free=23, ema_decay=0.9999, wall=18055
2022-10-11 22:36:50 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.2, ups=0.84, wpb=110.4, bsz=40, num_updates=2780, lr=2.40401e-06, gnorm=1.126, clip=80, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=18067
2022-10-11 22:37:02 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.7, ups=0.85, wpb=111.8, bsz=40, num_updates=2790, lr=2.41266e-06, gnorm=1.078, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18079
2022-10-11 22:37:14 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.4, ups=0.84, wpb=111.5, bsz=40, num_updates=2800, lr=2.42131e-06, gnorm=1.119, clip=70, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=18091
2022-10-11 22:37:26 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.2, ups=0.83, wpb=111.7, bsz=40, num_updates=2810, lr=2.42996e-06, gnorm=1.036, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=18103
2022-10-11 22:37:38 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.5, ups=0.85, wpb=111.1, bsz=40, num_updates=2820, lr=2.4386e-06, gnorm=1.162, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=18115
2022-10-11 22:37:50 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.1, ups=0.85, wpb=110.1, bsz=40, num_updates=2830, lr=2.44725e-06, gnorm=1.097, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=18127
2022-10-11 22:38:02 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.7, ups=0.84, wpb=111.7, bsz=40, num_updates=2840, lr=2.4559e-06, gnorm=1.027, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=18139
2022-10-11 22:38:13 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.9, ups=0.87, wpb=110.4, bsz=40, num_updates=2850, lr=2.46455e-06, gnorm=1.185, clip=80, loss_scale=512, train_wall=11, gb_free=22.7, ema_decay=0.9999, wall=18150
2022-10-11 22:38:25 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 28910 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.9, ups=0.85, wpb=109, bsz=40, num_updates=2860, lr=2.47319e-06, gnorm=1.201, clip=100, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=18162
2022-10-11 22:38:37 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.84, wpb=109.7, bsz=40, num_updates=2870, lr=2.48184e-06, gnorm=1.115, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18174
2022-10-11 22:38:49 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.8, ups=0.85, wpb=110.6, bsz=40, num_updates=2880, lr=2.49049e-06, gnorm=1.149, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18186
2022-10-11 22:39:01 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.4, ups=0.83, wpb=109.6, bsz=40, num_updates=2890, lr=2.49914e-06, gnorm=1.175, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=18198
2022-10-11 22:39:13 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.8, ups=0.85, wpb=111.7, bsz=40, num_updates=2900, lr=2.50778e-06, gnorm=1.067, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18209
2022-10-11 22:39:25 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93, ups=0.84, wpb=110.9, bsz=40, num_updates=2910, lr=2.51643e-06, gnorm=1.106, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18221
2022-10-11 22:39:36 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.4, ups=0.86, wpb=110.6, bsz=40, num_updates=2920, lr=2.52508e-06, gnorm=1.136, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18233
2022-10-11 22:39:48 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.9, ups=0.86, wpb=110.5, bsz=40, num_updates=2930, lr=2.53373e-06, gnorm=1.115, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18245
2022-10-11 22:40:00 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 28910 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.5, ups=0.85, wpb=110.5, bsz=40, num_updates=2940, lr=2.54237e-06, gnorm=1.109, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18256
2022-10-11 22:40:11 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.5, ups=0.85, wpb=111.3, bsz=40, num_updates=2950, lr=2.55102e-06, gnorm=1.06, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18268
2022-10-11 22:40:23 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 28910 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.3, ups=0.85, wpb=110.2, bsz=40, num_updates=2960, lr=2.55967e-06, gnorm=1.157, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=18280
2022-10-11 22:40:35 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.8, ups=0.84, wpb=109.3, bsz=40, num_updates=2970, lr=2.56832e-06, gnorm=1.137, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18292
2022-10-11 22:40:47 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.2, ups=0.84, wpb=111.1, bsz=40, num_updates=2980, lr=2.57696e-06, gnorm=1.136, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=18304
2022-10-11 22:40:59 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.9, ups=0.85, wpb=110.9, bsz=40, num_updates=2990, lr=2.58561e-06, gnorm=1.022, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=18316
2022-10-11 22:41:11 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.9, ups=0.85, wpb=110.9, bsz=40, num_updates=3000, lr=2.59426e-06, gnorm=1.071, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=18328
2022-10-11 22:41:11 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-11 22:41:12 - train.py[line:549] - INFO: 0 / 9351
2022-10-11 22:41:12 - train.py[line:551] - INFO: load:0.84 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-11 22:42:36 - train.py[line:549] - INFO: 200 / 9351
2022-10-11 22:42:36 - train.py[line:551] - INFO: load:0.86 valid_run:83.83 task_valid:81.32 collect_output:1.44
2022-10-11 22:43:59 - train.py[line:549] - INFO: 400 / 9351
2022-10-11 22:43:59 - train.py[line:551] - INFO: load:0.88 valid_run:167.45 task_valid:162.44 collect_output:2.87
2022-10-11 22:45:22 - train.py[line:549] - INFO: 600 / 9351
2022-10-11 22:45:22 - train.py[line:551] - INFO: load:0.90 valid_run:249.70 task_valid:241.12 collect_output:5.32
2022-10-11 22:46:45 - train.py[line:549] - INFO: 800 / 9351
2022-10-11 22:46:45 - train.py[line:551] - INFO: load:0.92 valid_run:333.00 task_valid:320.01 collect_output:8.66
2022-10-11 22:48:09 - train.py[line:549] - INFO: 1000 / 9351
2022-10-11 22:48:09 - train.py[line:551] - INFO: load:0.95 valid_run:417.19 task_valid:399.04 collect_output:12.78
2022-10-11 22:49:33 - train.py[line:549] - INFO: 1200 / 9351
2022-10-11 22:49:33 - train.py[line:551] - INFO: load:0.97 valid_run:500.55 task_valid:476.97 collect_output:17.17
2022-10-11 22:50:56 - train.py[line:549] - INFO: 1400 / 9351
2022-10-11 22:50:56 - train.py[line:551] - INFO: load:0.99 valid_run:583.35 task_valid:556.96 collect_output:18.95
2022-10-11 22:52:19 - train.py[line:549] - INFO: 1600 / 9351
2022-10-11 22:52:19 - train.py[line:551] - INFO: load:1.02 valid_run:667.16 task_valid:638.71 collect_output:19.94
2022-10-11 22:53:44 - train.py[line:549] - INFO: 1800 / 9351
2022-10-11 22:53:44 - train.py[line:551] - INFO: load:1.04 valid_run:751.72 task_valid:719.06 collect_output:23.11
2022-10-11 22:55:08 - train.py[line:549] - INFO: 2000 / 9351
2022-10-11 22:55:08 - train.py[line:551] - INFO: load:1.06 valid_run:835.85 task_valid:799.58 collect_output:25.63
2022-10-11 22:56:32 - train.py[line:549] - INFO: 2200 / 9351
2022-10-11 22:56:32 - train.py[line:551] - INFO: load:1.08 valid_run:920.07 task_valid:879.55 collect_output:28.82
2022-10-11 22:57:57 - train.py[line:549] - INFO: 2400 / 9351
2022-10-11 22:57:57 - train.py[line:551] - INFO: load:1.10 valid_run:1004.15 task_valid:959.85 collect_output:31.54
2022-10-11 22:59:22 - train.py[line:549] - INFO: 2600 / 9351
2022-10-11 22:59:22 - train.py[line:551] - INFO: load:1.13 valid_run:1089.13 task_valid:1039.72 collect_output:35.60
2022-10-11 23:00:46 - train.py[line:549] - INFO: 2800 / 9351
2022-10-11 23:00:46 - train.py[line:551] - INFO: load:1.15 valid_run:1173.20 task_valid:1118.52 collect_output:39.81
2022-10-11 23:02:09 - train.py[line:549] - INFO: 3000 / 9351
2022-10-11 23:02:09 - train.py[line:551] - INFO: load:1.17 valid_run:1256.36 task_valid:1196.00 collect_output:44.43
2022-10-11 23:03:32 - train.py[line:549] - INFO: 3200 / 9351
2022-10-11 23:03:32 - train.py[line:551] - INFO: load:1.19 valid_run:1338.83 task_valid:1275.19 collect_output:46.67
2022-10-11 23:04:56 - train.py[line:549] - INFO: 3400 / 9351
2022-10-11 23:04:56 - train.py[line:551] - INFO: load:1.21 valid_run:1423.50 task_valid:1355.80 collect_output:49.58
2022-10-11 23:06:20 - train.py[line:549] - INFO: 3600 / 9351
2022-10-11 23:06:20 - train.py[line:551] - INFO: load:1.24 valid_run:1506.97 task_valid:1436.48 collect_output:51.27
2022-10-11 23:07:42 - train.py[line:549] - INFO: 3800 / 9351
2022-10-11 23:07:42 - train.py[line:551] - INFO: load:1.26 valid_run:1588.94 task_valid:1514.16 collect_output:54.48
2022-10-11 23:09:04 - train.py[line:549] - INFO: 4000 / 9351
2022-10-11 23:09:04 - train.py[line:551] - INFO: load:1.28 valid_run:1670.93 task_valid:1592.95 collect_output:56.64
2022-10-11 23:10:28 - train.py[line:549] - INFO: 4200 / 9351
2022-10-11 23:10:28 - train.py[line:551] - INFO: load:1.30 valid_run:1754.72 task_valid:1674.54 collect_output:57.78
2022-10-11 23:11:51 - train.py[line:549] - INFO: 4400 / 9351
2022-10-11 23:11:51 - train.py[line:551] - INFO: load:1.32 valid_run:1838.11 task_valid:1754.47 collect_output:60.18
2022-10-11 23:13:15 - train.py[line:549] - INFO: 4600 / 9351
2022-10-11 23:13:15 - train.py[line:551] - INFO: load:1.35 valid_run:1921.82 task_valid:1834.28 collect_output:62.89
2022-10-11 23:14:40 - train.py[line:549] - INFO: 4800 / 9351
2022-10-11 23:14:40 - train.py[line:551] - INFO: load:1.37 valid_run:2006.37 task_valid:1912.98 collect_output:67.59
2022-10-11 23:16:04 - train.py[line:549] - INFO: 5000 / 9351
2022-10-11 23:16:04 - train.py[line:551] - INFO: load:1.39 valid_run:2091.23 task_valid:1994.52 collect_output:69.75
2022-10-11 23:17:29 - train.py[line:549] - INFO: 5200 / 9351
2022-10-11 23:17:29 - train.py[line:551] - INFO: load:1.41 valid_run:2175.43 task_valid:2075.43 collect_output:71.91
2022-10-11 23:18:52 - train.py[line:549] - INFO: 5400 / 9351
2022-10-11 23:18:52 - train.py[line:551] - INFO: load:1.43 valid_run:2258.94 task_valid:2155.92 collect_output:73.72
2022-10-11 23:20:17 - train.py[line:549] - INFO: 5600 / 9351
2022-10-11 23:20:17 - train.py[line:551] - INFO: load:1.46 valid_run:2343.63 task_valid:2237.49 collect_output:75.64
2022-10-11 23:21:41 - train.py[line:549] - INFO: 5800 / 9351
2022-10-11 23:21:41 - train.py[line:551] - INFO: load:1.48 valid_run:2427.49 task_valid:2317.16 collect_output:78.69
2022-10-11 23:23:05 - train.py[line:549] - INFO: 6000 / 9351
2022-10-11 23:23:05 - train.py[line:551] - INFO: load:1.50 valid_run:2511.36 task_valid:2397.90 collect_output:80.63
2022-10-11 23:24:29 - train.py[line:549] - INFO: 6200 / 9351
2022-10-11 23:24:29 - train.py[line:551] - INFO: load:1.52 valid_run:2595.61 task_valid:2478.24 collect_output:83.36
2022-10-11 23:25:55 - train.py[line:549] - INFO: 6400 / 9351
2022-10-11 23:25:55 - train.py[line:551] - INFO: load:1.55 valid_run:2681.42 task_valid:2560.03 collect_output:86.10
2022-10-11 23:27:20 - train.py[line:549] - INFO: 6600 / 9351
2022-10-11 23:27:20 - train.py[line:551] - INFO: load:1.57 valid_run:2766.03 task_valid:2642.03 collect_output:87.52
2022-10-11 23:28:44 - train.py[line:549] - INFO: 6800 / 9351
2022-10-11 23:28:44 - train.py[line:551] - INFO: load:1.60 valid_run:2849.99 task_valid:2722.08 collect_output:90.23
2022-10-11 23:30:08 - train.py[line:549] - INFO: 7000 / 9351
2022-10-11 23:30:08 - train.py[line:551] - INFO: load:1.63 valid_run:2933.80 task_valid:2801.35 collect_output:93.58
2022-10-11 23:31:32 - train.py[line:549] - INFO: 7200 / 9351
2022-10-11 23:31:32 - train.py[line:551] - INFO: load:1.65 valid_run:3017.99 task_valid:2882.04 collect_output:95.84
2022-10-11 23:32:56 - train.py[line:549] - INFO: 7400 / 9351
2022-10-11 23:32:56 - train.py[line:551] - INFO: load:1.67 valid_run:3101.66 task_valid:2961.13 collect_output:99.33
2022-10-11 23:34:21 - train.py[line:549] - INFO: 7600 / 9351
2022-10-11 23:34:21 - train.py[line:551] - INFO: load:1.69 valid_run:3186.58 task_valid:3041.59 collect_output:102.68
2022-10-11 23:35:45 - train.py[line:549] - INFO: 7800 / 9351
2022-10-11 23:35:45 - train.py[line:551] - INFO: load:1.71 valid_run:3270.85 task_valid:3121.74 collect_output:105.72
2022-10-11 23:37:08 - train.py[line:549] - INFO: 8000 / 9351
2022-10-11 23:37:08 - train.py[line:551] - INFO: load:1.73 valid_run:3353.45 task_valid:3199.68 collect_output:109.34
2022-10-11 23:38:31 - train.py[line:549] - INFO: 8200 / 9351
2022-10-11 23:38:31 - train.py[line:551] - INFO: load:1.76 valid_run:3437.06 task_valid:3280.88 collect_output:110.67
2022-10-11 23:39:55 - train.py[line:549] - INFO: 8400 / 9351
2022-10-11 23:39:55 - train.py[line:551] - INFO: load:1.78 valid_run:3520.56 task_valid:3361.72 collect_output:112.28
2022-10-11 23:41:19 - train.py[line:549] - INFO: 8600 / 9351
2022-10-11 23:41:19 - train.py[line:551] - INFO: load:1.80 valid_run:3604.54 task_valid:3442.11 collect_output:114.77
2022-10-11 23:42:42 - train.py[line:549] - INFO: 8800 / 9351
2022-10-11 23:42:42 - train.py[line:551] - INFO: load:1.82 valid_run:3687.97 task_valid:3521.13 collect_output:118.15
2022-10-11 23:44:06 - train.py[line:549] - INFO: 9000 / 9351
2022-10-11 23:44:06 - train.py[line:551] - INFO: load:1.84 valid_run:3771.87 task_valid:3602.91 collect_output:119.21
2022-10-11 23:45:30 - train.py[line:549] - INFO: 9200 / 9351
2022-10-11 23:45:30 - train.py[line:551] - INFO: load:1.87 valid_run:3855.40 task_valid:3683.86 collect_output:120.72

====================================================================================================
SGG eval:     R @ 50: 0.6592;     R @ 100: 0.6953;     R @ 500: 0.7222;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4498;    mR @ 100: 0.4999;    mR @ 500: 0.5351;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.4429) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:1.0000) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7202) (standing on:0.4613) (using:0.5500) (walking in:0.0000) (walking on:0.6216) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================

2022-10-11 23:46:44 - train.py[line:487] - INFO: 0.6953164756811816

====================================================================================================
SGG eval:     R @ 50: 0.6592;     R @ 100: 0.6953;     R @ 500: 0.7222;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4498;    mR @ 100: 0.4999;    mR @ 500: 0.5351;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.4429) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:1.0000) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7202) (standing on:0.4613) (using:0.5500) (walking in:0.0000) (walking on:0.6216) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================

2022-10-11 23:46:44 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-11 23:46:44 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.34 | loss_v1 0 | loss_v2 0 | nll_loss 0.205 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.695316 | ppl 1.15 | vqa_score 0.5327 | wps 114.1 | wpb 48 | bsz 16 | num_updates 3000 | best_R@100 0.695316
2022-10-11 23:46:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2022-10-11 23:46:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-11 23:46:50 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-11 23:46:55 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 0.6953164756811816) (writing took 11.383270821999758 seconds)
2022-10-11 23:47:07 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=3010, lr=2.60291e-06, gnorm=1.184, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=22284
2022-10-11 23:47:19 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94, ups=0.85, wpb=110.4, bsz=40, num_updates=3020, lr=2.61155e-06, gnorm=1.113, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22296
2022-10-11 23:47:31 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.8, ups=0.85, wpb=111.5, bsz=40, num_updates=3030, lr=2.6202e-06, gnorm=1.045, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22308
2022-10-11 23:47:43 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.7, ups=0.86, wpb=109, bsz=40, num_updates=3040, lr=2.62885e-06, gnorm=1.015, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22319
2022-10-11 23:47:54 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.6, ups=0.86, wpb=110.5, bsz=40, num_updates=3050, lr=2.6375e-06, gnorm=1.063, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22331
2022-10-11 23:48:06 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.4, ups=0.87, wpb=111.4, bsz=40, num_updates=3060, lr=2.64614e-06, gnorm=1.138, clip=90, loss_scale=512, train_wall=11, gb_free=23.1, ema_decay=0.9999, wall=22343
2022-10-11 23:48:18 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.8, ups=0.83, wpb=109.5, bsz=40, num_updates=3070, lr=2.65479e-06, gnorm=1.08, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22355
2022-10-11 23:48:30 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 28910 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.4, ups=0.86, wpb=110.2, bsz=40, num_updates=3080, lr=2.66344e-06, gnorm=1.017, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22366
2022-10-11 23:48:41 - progress_bar.py[line:274] - INFO: epoch 001:   3093 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.6, ups=0.85, wpb=110.1, bsz=40, num_updates=3090, lr=2.67209e-06, gnorm=0.985, clip=30, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=22378
2022-10-11 23:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   3103 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92, ups=0.84, wpb=109.7, bsz=40, num_updates=3100, lr=2.68073e-06, gnorm=1.076, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22390
2022-10-11 23:49:05 - progress_bar.py[line:274] - INFO: epoch 001:   3113 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.3, ups=0.85, wpb=109, bsz=40, num_updates=3110, lr=2.68938e-06, gnorm=1.141, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=22402
2022-10-11 23:49:17 - progress_bar.py[line:274] - INFO: epoch 001:   3123 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.83, wpb=111.1, bsz=40, num_updates=3120, lr=2.69803e-06, gnorm=1.143, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=22414
2022-10-11 23:49:29 - progress_bar.py[line:274] - INFO: epoch 001:   3133 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.6, ups=0.87, wpb=111.2, bsz=40, num_updates=3130, lr=2.70668e-06, gnorm=1.083, clip=70, loss_scale=512, train_wall=11, gb_free=22.7, ema_decay=0.9999, wall=22425
2022-10-11 23:49:41 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.6, ups=0.83, wpb=109.8, bsz=40, num_updates=3140, lr=2.71532e-06, gnorm=1.045, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22437
2022-10-11 23:49:52 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.6, ups=0.87, wpb=109.9, bsz=40, num_updates=3150, lr=2.72397e-06, gnorm=1.064, clip=70, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=22449
2022-10-11 23:50:04 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.8, ups=0.84, wpb=109.5, bsz=40, num_updates=3160, lr=2.73262e-06, gnorm=1.162, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22461
2022-10-11 23:50:16 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 28910 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93, ups=0.84, wpb=110.2, bsz=40, num_updates=3170, lr=2.74127e-06, gnorm=1.156, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22473
2022-10-11 23:50:28 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94, ups=0.85, wpb=110.4, bsz=40, num_updates=3180, lr=2.74991e-06, gnorm=1.121, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22485
2022-10-11 23:50:40 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.1, ups=0.85, wpb=109.4, bsz=40, num_updates=3190, lr=2.75856e-06, gnorm=1.154, clip=80, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=22496
2022-10-11 23:50:51 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.7, ups=0.86, wpb=109.6, bsz=40, num_updates=3200, lr=2.76721e-06, gnorm=1.172, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22508
2022-10-11 23:51:03 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93, ups=0.85, wpb=109.4, bsz=40, num_updates=3210, lr=2.77586e-06, gnorm=1.138, clip=60, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22520
2022-10-11 23:51:15 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.3, ups=0.85, wpb=108.4, bsz=40, num_updates=3220, lr=2.7845e-06, gnorm=1.124, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22532
2022-10-11 23:51:27 - progress_bar.py[line:274] - INFO: epoch 001:   3233 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.2, ups=0.85, wpb=111.7, bsz=40, num_updates=3230, lr=2.79315e-06, gnorm=1.125, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22543
2022-10-11 23:51:38 - progress_bar.py[line:274] - INFO: epoch 001:   3243 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.2, ups=0.84, wpb=109.3, bsz=40, num_updates=3240, lr=2.8018e-06, gnorm=1.003, clip=50, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22555
2022-10-11 23:51:50 - progress_bar.py[line:274] - INFO: epoch 001:   3253 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.2, ups=0.85, wpb=110.2, bsz=40, num_updates=3250, lr=2.81045e-06, gnorm=1.096, clip=60, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=22567
2022-10-11 23:52:02 - progress_bar.py[line:274] - INFO: epoch 001:   3263 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.83, wpb=109.3, bsz=40, num_updates=3260, lr=2.81909e-06, gnorm=1.097, clip=80, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=22579
2022-10-11 23:52:14 - progress_bar.py[line:274] - INFO: epoch 001:   3273 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94, ups=0.86, wpb=109.8, bsz=40, num_updates=3270, lr=2.82774e-06, gnorm=1.158, clip=90, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22591
2022-10-11 23:52:26 - progress_bar.py[line:274] - INFO: epoch 001:   3283 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.6, ups=0.85, wpb=109.9, bsz=40, num_updates=3280, lr=2.83639e-06, gnorm=1.022, clip=40, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22602
2022-10-11 23:52:37 - progress_bar.py[line:274] - INFO: epoch 001:   3293 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.8, ups=0.87, wpb=109.5, bsz=40, num_updates=3290, lr=2.84504e-06, gnorm=1.027, clip=60, loss_scale=1024, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=22614
2022-10-11 23:52:49 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-11 23:52:50 - progress_bar.py[line:274] - INFO: epoch 001:   3304 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=84.8, ups=0.76, wpb=111.1, bsz=40, num_updates=3300, lr=2.85368e-06, gnorm=1.115, clip=60, loss_scale=512, train_wall=13, gb_free=22.7, ema_decay=0.9999, wall=22627
2022-10-11 23:53:02 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.83, wpb=110.2, bsz=40, num_updates=3310, lr=2.86233e-06, gnorm=1.054, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22639
2022-10-11 23:53:14 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.83, wpb=110.5, bsz=40, num_updates=3320, lr=2.87098e-06, gnorm=1.151, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22651
2022-10-11 23:53:26 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.9, ups=0.84, wpb=111.1, bsz=40, num_updates=3330, lr=2.87963e-06, gnorm=1.113, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22663
2022-10-11 23:53:38 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.3, ups=0.83, wpb=109.5, bsz=40, num_updates=3340, lr=2.88827e-06, gnorm=1.158, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22675
2022-10-11 23:53:50 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.5, ups=0.86, wpb=111.6, bsz=40, num_updates=3350, lr=2.89692e-06, gnorm=1.019, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22687
2022-10-11 23:54:02 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.6, ups=0.85, wpb=111.2, bsz=40, num_updates=3360, lr=2.90557e-06, gnorm=1.036, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=22698
2022-10-11 23:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.2, ups=0.86, wpb=110, bsz=40, num_updates=3370, lr=2.91422e-06, gnorm=1.069, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22710
2022-10-11 23:54:25 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.5, ups=0.85, wpb=109, bsz=40, num_updates=3380, lr=2.92286e-06, gnorm=1.197, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22722
2022-10-11 23:54:37 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.9, ups=0.85, wpb=111.4, bsz=40, num_updates=3390, lr=2.93151e-06, gnorm=1.014, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22734
2022-10-11 23:54:49 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.5, ups=0.84, wpb=109.5, bsz=40, num_updates=3400, lr=2.94016e-06, gnorm=1.176, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22746
2022-10-11 23:55:01 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.9, ups=0.85, wpb=111.7, bsz=40, num_updates=3410, lr=2.94881e-06, gnorm=1.146, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22757
2022-10-11 23:55:13 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.84, wpb=109.7, bsz=40, num_updates=3420, lr=2.95745e-06, gnorm=1.137, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=22769
2022-10-11 23:55:24 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.9, ups=0.85, wpb=110.4, bsz=40, num_updates=3430, lr=2.9661e-06, gnorm=1.06, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22781
2022-10-11 23:55:36 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.6, ups=0.84, wpb=111.1, bsz=40, num_updates=3440, lr=2.97475e-06, gnorm=1.119, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=22793
2022-10-11 23:55:48 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.8, ups=0.85, wpb=109.7, bsz=40, num_updates=3450, lr=2.9834e-06, gnorm=1.162, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22805
2022-10-11 23:56:00 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.4, ups=0.84, wpb=109.8, bsz=40, num_updates=3460, lr=2.99204e-06, gnorm=1.13, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=22816
2022-10-11 23:56:12 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.9, ups=0.85, wpb=110.9, bsz=40, num_updates=3470, lr=3.00069e-06, gnorm=1.106, clip=80, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=22828
2022-10-11 23:56:23 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.7, ups=0.85, wpb=111.9, bsz=40, num_updates=3480, lr=3.00934e-06, gnorm=1.153, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22840
2022-10-11 23:56:35 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.82, wpb=111.2, bsz=40, num_updates=3490, lr=3.01799e-06, gnorm=1.092, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22852
2022-10-11 23:56:47 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.2, ups=0.86, wpb=109.2, bsz=40, num_updates=3500, lr=3.02663e-06, gnorm=1.11, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22864
2022-10-11 23:56:59 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.1, ups=0.84, wpb=109.4, bsz=40, num_updates=3510, lr=3.03528e-06, gnorm=1.186, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22876
2022-10-11 23:57:11 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.84, wpb=108.7, bsz=40, num_updates=3520, lr=3.04393e-06, gnorm=1.133, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22887
2022-10-11 23:57:22 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.6, ups=0.86, wpb=110.1, bsz=40, num_updates=3530, lr=3.05258e-06, gnorm=1.17, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22899
2022-10-11 23:57:34 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.84, wpb=109.3, bsz=40, num_updates=3540, lr=3.06122e-06, gnorm=1.205, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22911
2022-10-11 23:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95, ups=0.86, wpb=110.8, bsz=40, num_updates=3550, lr=3.06987e-06, gnorm=1.197, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22923
2022-10-11 23:57:58 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.84, wpb=110.5, bsz=40, num_updates=3560, lr=3.07852e-06, gnorm=1.123, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22935
2022-10-11 23:58:10 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.4, ups=0.84, wpb=111.2, bsz=40, num_updates=3570, lr=3.08717e-06, gnorm=1.088, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=22946
2022-10-11 23:58:21 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.5, ups=0.86, wpb=110, bsz=40, num_updates=3580, lr=3.09581e-06, gnorm=1.079, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22958
2022-10-11 23:58:34 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.8, ups=0.82, wpb=111.4, bsz=40, num_updates=3590, lr=3.10446e-06, gnorm=1.051, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=22970
2022-10-11 23:58:46 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.7, ups=0.83, wpb=109.9, bsz=40, num_updates=3600, lr=3.11311e-06, gnorm=1.021, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=22982
2022-10-11 23:58:57 - progress_bar.py[line:274] - INFO: epoch 001:   3614 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.2, ups=0.85, wpb=110.1, bsz=40, num_updates=3610, lr=3.12176e-06, gnorm=1.139, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=22994
2022-10-11 23:59:10 - progress_bar.py[line:274] - INFO: epoch 001:   3624 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.7, ups=0.84, wpb=109, bsz=40, num_updates=3620, lr=3.1304e-06, gnorm=1.075, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23006
2022-10-11 23:59:21 - progress_bar.py[line:274] - INFO: epoch 001:   3634 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.1, ups=0.86, wpb=111, bsz=40, num_updates=3630, lr=3.13905e-06, gnorm=1.03, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23018
2022-10-11 23:59:33 - progress_bar.py[line:274] - INFO: epoch 001:   3644 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.4, ups=0.84, wpb=112.2, bsz=40, num_updates=3640, lr=3.1477e-06, gnorm=1.042, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=23030
2022-10-11 23:59:45 - progress_bar.py[line:274] - INFO: epoch 001:   3654 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.8, ups=0.85, wpb=111.7, bsz=40, num_updates=3650, lr=3.15635e-06, gnorm=1.03, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=23042
2022-10-11 23:59:57 - progress_bar.py[line:274] - INFO: epoch 001:   3664 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.6, ups=0.87, wpb=111.4, bsz=40, num_updates=3660, lr=3.16499e-06, gnorm=1.049, clip=60, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=23053
2022-10-12 00:00:09 - progress_bar.py[line:274] - INFO: epoch 001:   3674 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.1, ups=0.82, wpb=110.5, bsz=40, num_updates=3670, lr=3.17364e-06, gnorm=1.089, clip=60, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=23065
2022-10-12 00:00:21 - progress_bar.py[line:274] - INFO: epoch 001:   3684 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.5, ups=0.84, wpb=110, bsz=40, num_updates=3680, lr=3.18229e-06, gnorm=1.259, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=23077
2022-10-12 00:00:33 - progress_bar.py[line:274] - INFO: epoch 001:   3694 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.7, ups=0.84, wpb=111.2, bsz=40, num_updates=3690, lr=3.19094e-06, gnorm=1.094, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=23090
2022-10-12 00:00:45 - progress_bar.py[line:274] - INFO: epoch 001:   3704 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.8, ups=0.87, wpb=110.6, bsz=40, num_updates=3700, lr=3.19958e-06, gnorm=1.139, clip=70, loss_scale=512, train_wall=11, gb_free=23, ema_decay=0.9999, wall=23101
2022-10-12 00:00:57 - progress_bar.py[line:274] - INFO: epoch 001:   3714 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.83, wpb=110.6, bsz=40, num_updates=3710, lr=3.20823e-06, gnorm=1.089, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23114
2022-10-12 00:01:08 - progress_bar.py[line:274] - INFO: epoch 001:   3724 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.6, ups=0.86, wpb=110.8, bsz=40, num_updates=3720, lr=3.21688e-06, gnorm=1.117, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23125
2022-10-12 00:01:20 - progress_bar.py[line:274] - INFO: epoch 001:   3734 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.8, ups=0.84, wpb=110.3, bsz=40, num_updates=3730, lr=3.22553e-06, gnorm=1.137, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=23137
2022-10-12 00:01:32 - progress_bar.py[line:274] - INFO: epoch 001:   3744 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.3, ups=0.87, wpb=111.1, bsz=40, num_updates=3740, lr=3.23418e-06, gnorm=1.081, clip=80, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=23149
2022-10-12 00:01:44 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.1, ups=0.85, wpb=110.7, bsz=40, num_updates=3750, lr=3.24282e-06, gnorm=1.037, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=23160
2022-10-12 00:01:56 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.84, wpb=109.6, bsz=40, num_updates=3760, lr=3.25147e-06, gnorm=1.212, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23172
2022-10-12 00:02:07 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.9, ups=0.85, wpb=111, bsz=40, num_updates=3770, lr=3.26012e-06, gnorm=1.089, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=23184
2022-10-12 00:02:19 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.1, ups=0.84, wpb=110.5, bsz=40, num_updates=3780, lr=3.26877e-06, gnorm=1.182, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23196
2022-10-12 00:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.1, ups=0.84, wpb=109.8, bsz=40, num_updates=3790, lr=3.27741e-06, gnorm=1.102, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23208
2022-10-12 00:02:43 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.8, ups=0.87, wpb=111.2, bsz=40, num_updates=3800, lr=3.28606e-06, gnorm=1.069, clip=60, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=23219
2022-10-12 00:02:55 - progress_bar.py[line:274] - INFO: epoch 001:   3814 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.1, ups=0.84, wpb=109, bsz=40, num_updates=3810, lr=3.29471e-06, gnorm=1.253, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23231
2022-10-12 00:03:06 - progress_bar.py[line:274] - INFO: epoch 001:   3824 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.8, ups=0.85, wpb=110.8, bsz=40, num_updates=3820, lr=3.30336e-06, gnorm=1.247, clip=80, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=23243
2022-10-12 00:03:18 - progress_bar.py[line:274] - INFO: epoch 001:   3834 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.3, ups=0.86, wpb=111.3, bsz=40, num_updates=3830, lr=3.312e-06, gnorm=1.079, clip=80, loss_scale=1024, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=23255
2022-10-12 00:03:30 - progress_bar.py[line:274] - INFO: epoch 001:   3844 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.83, wpb=110.2, bsz=40, num_updates=3840, lr=3.32065e-06, gnorm=1.07, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=23267
2022-10-12 00:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   3854 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93, ups=0.85, wpb=109.7, bsz=40, num_updates=3850, lr=3.3293e-06, gnorm=1.173, clip=90, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=23279
2022-10-12 00:03:55 - progress_bar.py[line:274] - INFO: epoch 001:   3864 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92, ups=0.84, wpb=109.3, bsz=40, num_updates=3860, lr=3.33795e-06, gnorm=1.094, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=23291
2022-10-12 00:04:06 - progress_bar.py[line:274] - INFO: epoch 001:   3874 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.2, ups=0.86, wpb=110.2, bsz=40, num_updates=3870, lr=3.34659e-06, gnorm=1.168, clip=100, loss_scale=1024, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=23303
2022-10-12 00:04:18 - progress_bar.py[line:274] - INFO: epoch 001:   3884 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.84, wpb=109.8, bsz=40, num_updates=3880, lr=3.35524e-06, gnorm=1.045, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=23315
2022-10-12 00:04:24 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 00:04:31 - progress_bar.py[line:274] - INFO: epoch 001:   3895 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=113.1, nsentences=40, sample_size=113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.7, ups=0.78, wpb=113.1, bsz=40, num_updates=3890, lr=3.36389e-06, gnorm=1.01, clip=60, loss_scale=512, train_wall=13, gb_free=22.6, ema_decay=0.9999, wall=23328
2022-10-12 00:04:43 - progress_bar.py[line:274] - INFO: epoch 001:   3905 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.9, ups=0.85, wpb=109.8, bsz=40, num_updates=3900, lr=3.37254e-06, gnorm=1.11, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23339
2022-10-12 00:04:54 - progress_bar.py[line:274] - INFO: epoch 001:   3915 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.6, ups=0.85, wpb=109.7, bsz=40, num_updates=3910, lr=3.38118e-06, gnorm=1.105, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=23351
2022-10-12 00:05:06 - progress_bar.py[line:274] - INFO: epoch 001:   3925 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.9, ups=0.87, wpb=110.8, bsz=40, num_updates=3920, lr=3.38983e-06, gnorm=1.093, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=23363
2022-10-12 00:05:18 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.6, ups=0.84, wpb=110, bsz=40, num_updates=3930, lr=3.39848e-06, gnorm=1.197, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=23375
2022-10-12 00:05:30 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 28910 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.6, ups=0.85, wpb=111.8, bsz=40, num_updates=3940, lr=3.40713e-06, gnorm=1.199, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23386
2022-10-12 00:05:41 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.9, ups=0.86, wpb=111, bsz=40, num_updates=3950, lr=3.41577e-06, gnorm=1.159, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=23398
2022-10-12 00:05:53 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.4, ups=0.85, wpb=109.7, bsz=40, num_updates=3960, lr=3.42442e-06, gnorm=1.212, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=23410
2022-10-12 00:06:05 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.83, wpb=110.2, bsz=40, num_updates=3970, lr=3.43307e-06, gnorm=1.178, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=23422
2022-10-12 00:06:17 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.5, ups=0.86, wpb=108.6, bsz=40, num_updates=3980, lr=3.44172e-06, gnorm=1.168, clip=80, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=23433
2022-10-12 00:06:29 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.84, wpb=110.4, bsz=40, num_updates=3990, lr=3.45036e-06, gnorm=1.051, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=23445
2022-10-12 00:06:40 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.9, ups=0.87, wpb=109.7, bsz=40, num_updates=4000, lr=3.45901e-06, gnorm=1.107, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=23457
2022-10-12 00:06:40 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 00:06:41 - train.py[line:549] - INFO: 0 / 9351
2022-10-12 00:06:41 - train.py[line:551] - INFO: load:0.81 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 00:08:05 - train.py[line:549] - INFO: 200 / 9351
2022-10-12 00:08:05 - train.py[line:551] - INFO: load:0.83 valid_run:83.23 task_valid:80.78 collect_output:1.41
2022-10-12 00:09:28 - train.py[line:549] - INFO: 400 / 9351
2022-10-12 00:09:28 - train.py[line:551] - INFO: load:0.85 valid_run:166.77 task_valid:161.96 collect_output:2.71
2022-10-12 00:10:50 - train.py[line:549] - INFO: 600 / 9351
2022-10-12 00:10:50 - train.py[line:551] - INFO: load:0.87 valid_run:248.54 task_valid:240.65 collect_output:4.71
2022-10-12 00:12:13 - train.py[line:549] - INFO: 800 / 9351
2022-10-12 00:12:13 - train.py[line:551] - INFO: load:0.90 valid_run:331.31 task_valid:318.99 collect_output:8.14
2022-10-12 00:13:37 - train.py[line:549] - INFO: 1000 / 9351
2022-10-12 00:13:37 - train.py[line:551] - INFO: load:0.92 valid_run:415.27 task_valid:397.79 collect_output:12.30
2022-10-12 00:15:00 - train.py[line:549] - INFO: 1200 / 9351
2022-10-12 00:15:00 - train.py[line:551] - INFO: load:0.94 valid_run:498.15 task_valid:475.48 collect_output:16.49
2022-10-12 00:16:23 - train.py[line:549] - INFO: 1400 / 9351
2022-10-12 00:16:23 - train.py[line:551] - INFO: load:0.96 valid_run:580.97 task_valid:555.57 collect_output:18.18
2022-10-12 00:17:46 - train.py[line:549] - INFO: 1600 / 9351
2022-10-12 00:17:46 - train.py[line:551] - INFO: load:0.98 valid_run:664.51 task_valid:637.31 collect_output:18.94
2022-10-12 00:19:11 - train.py[line:549] - INFO: 1800 / 9351
2022-10-12 00:19:11 - train.py[line:551] - INFO: load:1.00 valid_run:749.57 task_valid:718.35 collect_output:21.80
2022-10-12 00:20:37 - train.py[line:549] - INFO: 2000 / 9351
2022-10-12 00:20:37 - train.py[line:551] - INFO: load:1.03 valid_run:834.79 task_valid:799.11 collect_output:25.08
2022-10-12 00:22:02 - train.py[line:549] - INFO: 2200 / 9351
2022-10-12 00:22:02 - train.py[line:551] - INFO: load:1.05 valid_run:919.92 task_valid:879.62 collect_output:28.49
2022-10-12 00:23:27 - train.py[line:549] - INFO: 2400 / 9351
2022-10-12 00:23:27 - train.py[line:551] - INFO: load:1.07 valid_run:1004.77 task_valid:960.69 collect_output:30.99
2022-10-12 00:24:52 - train.py[line:549] - INFO: 2600 / 9351
2022-10-12 00:24:52 - train.py[line:551] - INFO: load:1.09 valid_run:1090.19 task_valid:1040.85 collect_output:35.12
2022-10-12 00:26:17 - train.py[line:549] - INFO: 2800 / 9351
2022-10-12 00:26:17 - train.py[line:551] - INFO: load:1.12 valid_run:1175.34 task_valid:1120.72 collect_output:39.18
2022-10-12 00:27:41 - train.py[line:549] - INFO: 3000 / 9351
2022-10-12 00:27:41 - train.py[line:551] - INFO: load:1.15 valid_run:1258.72 task_valid:1198.36 collect_output:43.78
2022-10-12 00:29:04 - train.py[line:549] - INFO: 3200 / 9351
2022-10-12 00:29:04 - train.py[line:551] - INFO: load:1.17 valid_run:1341.77 task_valid:1277.80 collect_output:46.33
2022-10-12 00:30:29 - train.py[line:549] - INFO: 3400 / 9351
2022-10-12 00:30:29 - train.py[line:551] - INFO: load:1.20 valid_run:1426.79 task_valid:1358.24 collect_output:49.68
2022-10-12 00:31:53 - train.py[line:549] - INFO: 3600 / 9351
2022-10-12 00:31:53 - train.py[line:551] - INFO: load:1.22 valid_run:1510.57 task_valid:1439.02 collect_output:51.50
2022-10-12 00:33:16 - train.py[line:549] - INFO: 3800 / 9351
2022-10-12 00:33:16 - train.py[line:551] - INFO: load:1.24 valid_run:1593.73 task_valid:1517.38 collect_output:55.07
2022-10-12 00:34:39 - train.py[line:549] - INFO: 4000 / 9351
2022-10-12 00:34:39 - train.py[line:551] - INFO: load:1.27 valid_run:1676.97 task_valid:1596.95 collect_output:57.49
2022-10-12 00:36:04 - train.py[line:549] - INFO: 4200 / 9351
2022-10-12 00:36:04 - train.py[line:551] - INFO: load:1.29 valid_run:1761.81 task_valid:1679.42 collect_output:58.65
2022-10-12 00:37:28 - train.py[line:549] - INFO: 4400 / 9351
2022-10-12 00:37:28 - train.py[line:551] - INFO: load:1.32 valid_run:1845.78 task_valid:1759.59 collect_output:61.26
2022-10-12 00:38:51 - train.py[line:549] - INFO: 4600 / 9351
2022-10-12 00:38:51 - train.py[line:551] - INFO: load:1.34 valid_run:1928.67 task_valid:1838.69 collect_output:63.95
2022-10-12 00:40:15 - train.py[line:549] - INFO: 4800 / 9351
2022-10-12 00:40:15 - train.py[line:551] - INFO: load:1.36 valid_run:2012.44 task_valid:1916.61 collect_output:68.79
2022-10-12 00:41:39 - train.py[line:549] - INFO: 5000 / 9351
2022-10-12 00:41:39 - train.py[line:551] - INFO: load:1.38 valid_run:2096.38 task_valid:1997.36 collect_output:70.91
2022-10-12 00:43:03 - train.py[line:549] - INFO: 5200 / 9351
2022-10-12 00:43:03 - train.py[line:551] - INFO: load:1.41 valid_run:2179.86 task_valid:2077.60 collect_output:73.10
2022-10-12 00:44:25 - train.py[line:549] - INFO: 5400 / 9351
2022-10-12 00:44:25 - train.py[line:551] - INFO: load:1.43 valid_run:2262.61 task_valid:2157.54 collect_output:74.84
2022-10-12 00:45:49 - train.py[line:549] - INFO: 5600 / 9351
2022-10-12 00:45:49 - train.py[line:551] - INFO: load:1.46 valid_run:2346.31 task_valid:2238.31 collect_output:76.75
2022-10-12 00:47:12 - train.py[line:549] - INFO: 5800 / 9351
2022-10-12 00:47:12 - train.py[line:551] - INFO: load:1.48 valid_run:2429.10 task_valid:2317.28 collect_output:79.55
2022-10-12 00:48:35 - train.py[line:549] - INFO: 6000 / 9351
2022-10-12 00:48:35 - train.py[line:551] - INFO: load:1.50 valid_run:2512.03 task_valid:2397.22 collect_output:81.52
2022-10-12 00:49:58 - train.py[line:549] - INFO: 6200 / 9351
2022-10-12 00:49:58 - train.py[line:551] - INFO: load:1.52 valid_run:2595.23 task_valid:2476.82 collect_output:84.08
2022-10-12 00:51:23 - train.py[line:549] - INFO: 6400 / 9351
2022-10-12 00:51:23 - train.py[line:551] - INFO: load:1.54 valid_run:2679.95 task_valid:2557.67 collect_output:86.94
2022-10-12 00:52:47 - train.py[line:549] - INFO: 6600 / 9351
2022-10-12 00:52:47 - train.py[line:551] - INFO: load:1.57 valid_run:2763.40 task_valid:2638.85 collect_output:88.19
2022-10-12 00:54:10 - train.py[line:549] - INFO: 6800 / 9351
2022-10-12 00:54:10 - train.py[line:551] - INFO: load:1.59 valid_run:2846.45 task_valid:2718.51 collect_output:90.52
2022-10-12 00:55:32 - train.py[line:549] - INFO: 7000 / 9351
2022-10-12 00:55:32 - train.py[line:551] - INFO: load:1.61 valid_run:2928.70 task_valid:2796.72 collect_output:93.54
2022-10-12 00:56:55 - train.py[line:549] - INFO: 7200 / 9351
2022-10-12 00:56:55 - train.py[line:551] - INFO: load:1.63 valid_run:3011.43 task_valid:2876.69 collect_output:95.23
2022-10-12 00:58:18 - train.py[line:549] - INFO: 7400 / 9351
2022-10-12 00:58:18 - train.py[line:551] - INFO: load:1.65 valid_run:3094.51 task_valid:2955.63 collect_output:98.32
2022-10-12 00:59:43 - train.py[line:549] - INFO: 7600 / 9351
2022-10-12 00:59:43 - train.py[line:551] - INFO: load:1.68 valid_run:3179.11 task_valid:3035.89 collect_output:101.60
2022-10-12 01:01:07 - train.py[line:549] - INFO: 7800 / 9351
2022-10-12 01:01:07 - train.py[line:551] - INFO: load:1.70 valid_run:3263.27 task_valid:3115.89 collect_output:104.72
2022-10-12 01:02:29 - train.py[line:549] - INFO: 8000 / 9351
2022-10-12 01:02:29 - train.py[line:551] - INFO: load:1.72 valid_run:3345.83 task_valid:3194.23 collect_output:107.93
2022-10-12 01:03:53 - train.py[line:549] - INFO: 8200 / 9351
2022-10-12 01:03:53 - train.py[line:551] - INFO: load:1.74 valid_run:3429.05 task_valid:3275.19 collect_output:109.17
2022-10-12 01:05:16 - train.py[line:549] - INFO: 8400 / 9351
2022-10-12 01:05:16 - train.py[line:551] - INFO: load:1.77 valid_run:3512.38 task_valid:3356.07 collect_output:110.59
2022-10-12 01:06:40 - train.py[line:549] - INFO: 8600 / 9351
2022-10-12 01:06:40 - train.py[line:551] - INFO: load:1.79 valid_run:3596.27 task_valid:3436.29 collect_output:113.21
2022-10-12 01:08:04 - train.py[line:549] - INFO: 8800 / 9351
2022-10-12 01:08:04 - train.py[line:551] - INFO: load:1.81 valid_run:3679.85 task_valid:3515.59 collect_output:116.43
2022-10-12 01:09:28 - train.py[line:549] - INFO: 9000 / 9351
2022-10-12 01:09:28 - train.py[line:551] - INFO: load:1.84 valid_run:3764.01 task_valid:3597.58 collect_output:117.55
2022-10-12 01:10:51 - train.py[line:549] - INFO: 9200 / 9351
2022-10-12 01:10:51 - train.py[line:551] - INFO: load:1.86 valid_run:3847.39 task_valid:3678.33 collect_output:119.14

====================================================================================================
SGG eval:     R @ 50: 0.6674;     R @ 100: 0.6954;     R @ 500: 0.7214;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4566;    mR @ 100: 0.5031;    mR @ 500: 0.5389;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.3714) (eating:0.8235) (flying in:0.8182) (growing on:0.3750) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7279) (standing on:0.4493) (using:0.5500) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-12 01:12:05 - train.py[line:487] - INFO: 0.6953861726508785

====================================================================================================
SGG eval:     R @ 50: 0.6674;     R @ 100: 0.6954;     R @ 500: 0.7214;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4566;    mR @ 100: 0.5031;    mR @ 500: 0.5389;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.3714) (eating:0.8235) (flying in:0.8182) (growing on:0.3750) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7279) (standing on:0.4493) (using:0.5500) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-12 01:12:05 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 01:12:05 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.338 | loss_v1 0 | loss_v2 0 | nll_loss 0.194 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.695386 | ppl 1.14 | vqa_score 0.545 | wps 114.3 | wpb 48 | bsz 16 | num_updates 4000 | best_R@100 0.695386
2022-10-12 01:12:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2022-10-12 01:12:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-12 01:12:11 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-12 01:12:17 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.6953861726508785) (writing took 11.546953670214862 seconds)
2022-10-12 01:12:28 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=0.3, ups=0, wpb=109.2, bsz=40, num_updates=4010, lr=3.46766e-06, gnorm=1.163, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27405
2022-10-12 01:12:40 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.84, wpb=111.1, bsz=40, num_updates=4020, lr=3.47631e-06, gnorm=1.051, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27417
2022-10-12 01:12:52 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.2, ups=0.85, wpb=111.2, bsz=40, num_updates=4030, lr=3.48495e-06, gnorm=1.12, clip=60, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=27429
2022-10-12 01:13:04 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.3, ups=0.83, wpb=111.1, bsz=40, num_updates=4040, lr=3.4936e-06, gnorm=1.02, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27441
2022-10-12 01:13:16 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.8, ups=0.87, wpb=110.7, bsz=40, num_updates=4050, lr=3.50225e-06, gnorm=1.083, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27452
2022-10-12 01:13:27 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.5, ups=0.86, wpb=110.2, bsz=40, num_updates=4060, lr=3.5109e-06, gnorm=1.074, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=27464
2022-10-12 01:13:39 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.3, ups=0.85, wpb=110.6, bsz=40, num_updates=4070, lr=3.51954e-06, gnorm=1.168, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27476
2022-10-12 01:13:51 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.1, ups=0.84, wpb=110.1, bsz=40, num_updates=4080, lr=3.52819e-06, gnorm=1.098, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27488
2022-10-12 01:14:03 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.82, wpb=109.3, bsz=40, num_updates=4090, lr=3.53684e-06, gnorm=1.14, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=27500
2022-10-12 01:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.4, ups=0.85, wpb=110.2, bsz=40, num_updates=4100, lr=3.54549e-06, gnorm=1.177, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=27512
2022-10-12 01:14:27 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.83, wpb=110.1, bsz=40, num_updates=4110, lr=3.55413e-06, gnorm=1.181, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27524
2022-10-12 01:14:39 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92, ups=0.84, wpb=109.8, bsz=40, num_updates=4120, lr=3.56278e-06, gnorm=1.057, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=27536
2022-10-12 01:14:51 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.9, ups=0.86, wpb=110.5, bsz=40, num_updates=4130, lr=3.57143e-06, gnorm=1.197, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=27547
2022-10-12 01:15:02 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.6, ups=0.85, wpb=110, bsz=40, num_updates=4140, lr=3.58008e-06, gnorm=1.047, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27559
2022-10-12 01:15:14 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.1, ups=0.85, wpb=111, bsz=40, num_updates=4150, lr=3.58872e-06, gnorm=1.054, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27571
2022-10-12 01:15:26 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.1, ups=0.85, wpb=109.7, bsz=40, num_updates=4160, lr=3.59737e-06, gnorm=1.1, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27583
2022-10-12 01:15:38 - progress_bar.py[line:274] - INFO: epoch 001:   4175 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93, ups=0.85, wpb=109, bsz=40, num_updates=4170, lr=3.60602e-06, gnorm=1.181, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27594
2022-10-12 01:15:49 - progress_bar.py[line:274] - INFO: epoch 001:   4185 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.7, ups=0.86, wpb=111, bsz=40, num_updates=4180, lr=3.61467e-06, gnorm=1.154, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27606
2022-10-12 01:16:01 - progress_bar.py[line:274] - INFO: epoch 001:   4195 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.84, wpb=110.6, bsz=40, num_updates=4190, lr=3.62331e-06, gnorm=1.064, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=27618
2022-10-12 01:16:13 - progress_bar.py[line:274] - INFO: epoch 001:   4205 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.1, ups=0.85, wpb=111.3, bsz=40, num_updates=4200, lr=3.63196e-06, gnorm=1.09, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27630
2022-10-12 01:16:25 - progress_bar.py[line:274] - INFO: epoch 001:   4215 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.7, ups=0.86, wpb=109.6, bsz=40, num_updates=4210, lr=3.64061e-06, gnorm=1.182, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27642
2022-10-12 01:16:36 - progress_bar.py[line:274] - INFO: epoch 001:   4225 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.4, ups=0.86, wpb=110.9, bsz=40, num_updates=4220, lr=3.64926e-06, gnorm=1.089, clip=70, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=27653
2022-10-12 01:16:49 - progress_bar.py[line:274] - INFO: epoch 001:   4235 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.82, wpb=110.3, bsz=40, num_updates=4230, lr=3.6579e-06, gnorm=1.113, clip=80, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=27665
2022-10-12 01:17:00 - progress_bar.py[line:274] - INFO: epoch 001:   4245 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.7, ups=0.85, wpb=111.3, bsz=40, num_updates=4240, lr=3.66655e-06, gnorm=1.156, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27677
2022-10-12 01:17:12 - progress_bar.py[line:274] - INFO: epoch 001:   4255 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95, ups=0.86, wpb=110.7, bsz=40, num_updates=4250, lr=3.6752e-06, gnorm=1.176, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=27689
2022-10-12 01:17:24 - progress_bar.py[line:274] - INFO: epoch 001:   4265 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.4, ups=0.86, wpb=112, bsz=40, num_updates=4260, lr=3.68385e-06, gnorm=1.084, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=27700
2022-10-12 01:17:36 - progress_bar.py[line:274] - INFO: epoch 001:   4275 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.3, ups=0.84, wpb=109.3, bsz=40, num_updates=4270, lr=3.69249e-06, gnorm=1.167, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=27712
2022-10-12 01:17:47 - progress_bar.py[line:274] - INFO: epoch 001:   4285 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.9, ups=0.87, wpb=108.4, bsz=40, num_updates=4280, lr=3.70114e-06, gnorm=1.251, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=27724
2022-10-12 01:17:59 - progress_bar.py[line:274] - INFO: epoch 001:   4295 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.4, ups=0.87, wpb=110.9, bsz=40, num_updates=4290, lr=3.70979e-06, gnorm=1.121, clip=70, loss_scale=512, train_wall=11, gb_free=22.9, ema_decay=0.9999, wall=27735
2022-10-12 01:18:10 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.2, ups=0.85, wpb=110.5, bsz=40, num_updates=4300, lr=3.71844e-06, gnorm=1.162, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27747
2022-10-12 01:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.5, ups=0.85, wpb=111.3, bsz=40, num_updates=4310, lr=3.72708e-06, gnorm=1.066, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=27759
2022-10-12 01:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   4325 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.83, wpb=110.2, bsz=40, num_updates=4320, lr=3.73573e-06, gnorm=1.088, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27771
2022-10-12 01:18:46 - progress_bar.py[line:274] - INFO: epoch 001:   4335 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.8, ups=0.85, wpb=109, bsz=40, num_updates=4330, lr=3.74438e-06, gnorm=1.181, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27783
2022-10-12 01:18:58 - progress_bar.py[line:274] - INFO: epoch 001:   4345 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.5, ups=0.83, wpb=110.9, bsz=40, num_updates=4340, lr=3.75303e-06, gnorm=1.066, clip=60, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=27795
2022-10-12 01:19:10 - progress_bar.py[line:274] - INFO: epoch 001:   4355 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.4, ups=0.84, wpb=111.5, bsz=40, num_updates=4350, lr=3.76167e-06, gnorm=1.152, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27807
2022-10-12 01:19:22 - progress_bar.py[line:274] - INFO: epoch 001:   4365 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.84, wpb=110.6, bsz=40, num_updates=4360, lr=3.77032e-06, gnorm=1.182, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=27818
2022-10-12 01:19:34 - progress_bar.py[line:274] - INFO: epoch 001:   4375 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.9, ups=0.85, wpb=110.3, bsz=40, num_updates=4370, lr=3.77897e-06, gnorm=1.207, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=27830
2022-10-12 01:19:45 - progress_bar.py[line:274] - INFO: epoch 001:   4385 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.7, ups=0.85, wpb=110.7, bsz=40, num_updates=4380, lr=3.78762e-06, gnorm=1.24, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=27842
2022-10-12 01:19:57 - progress_bar.py[line:274] - INFO: epoch 001:   4395 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.8, ups=0.86, wpb=110.9, bsz=40, num_updates=4390, lr=3.79626e-06, gnorm=1.066, clip=70, loss_scale=512, train_wall=12, gb_free=22.4, ema_decay=0.9999, wall=27854
2022-10-12 01:20:08 - progress_bar.py[line:274] - INFO: epoch 001:   4405 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96, ups=0.87, wpb=110.9, bsz=40, num_updates=4400, lr=3.80491e-06, gnorm=1.149, clip=60, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27865
2022-10-12 01:20:20 - progress_bar.py[line:274] - INFO: epoch 001:   4415 / 28910 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.4, ups=0.86, wpb=110.6, bsz=40, num_updates=4410, lr=3.81356e-06, gnorm=1.175, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27877
2022-10-12 01:20:32 - progress_bar.py[line:274] - INFO: epoch 001:   4425 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.6, ups=0.84, wpb=112, bsz=40, num_updates=4420, lr=3.82221e-06, gnorm=1.086, clip=70, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27889
2022-10-12 01:20:44 - progress_bar.py[line:274] - INFO: epoch 001:   4435 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.2, ups=0.83, wpb=110.6, bsz=40, num_updates=4430, lr=3.83085e-06, gnorm=1.128, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=27901
2022-10-12 01:20:56 - progress_bar.py[line:274] - INFO: epoch 001:   4445 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.7, ups=0.85, wpb=110.4, bsz=40, num_updates=4440, lr=3.8395e-06, gnorm=1.09, clip=90, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27913
2022-10-12 01:21:08 - progress_bar.py[line:274] - INFO: epoch 001:   4455 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.7, ups=0.85, wpb=110.9, bsz=40, num_updates=4450, lr=3.84815e-06, gnorm=1.033, clip=60, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=27924
2022-10-12 01:21:19 - progress_bar.py[line:274] - INFO: epoch 001:   4465 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.84, wpb=110, bsz=40, num_updates=4460, lr=3.8568e-06, gnorm=1.17, clip=70, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27936
2022-10-12 01:21:31 - progress_bar.py[line:274] - INFO: epoch 001:   4475 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.3, ups=0.85, wpb=109.6, bsz=40, num_updates=4470, lr=3.86544e-06, gnorm=1.233, clip=100, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27948
2022-10-12 01:21:43 - progress_bar.py[line:274] - INFO: epoch 001:   4485 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.9, ups=0.85, wpb=110.1, bsz=40, num_updates=4480, lr=3.87409e-06, gnorm=1.122, clip=90, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27960
2022-10-12 01:21:55 - progress_bar.py[line:274] - INFO: epoch 001:   4495 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.84, wpb=109.6, bsz=40, num_updates=4490, lr=3.88274e-06, gnorm=1.209, clip=90, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27972
2022-10-12 01:22:07 - progress_bar.py[line:274] - INFO: epoch 001:   4505 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.4, ups=0.84, wpb=109.5, bsz=40, num_updates=4500, lr=3.89139e-06, gnorm=1.144, clip=70, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=27983
2022-10-12 01:22:19 - progress_bar.py[line:274] - INFO: epoch 001:   4515 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.9, ups=0.84, wpb=110.2, bsz=40, num_updates=4510, lr=3.90003e-06, gnorm=1.073, clip=50, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=27995
2022-10-12 01:22:30 - progress_bar.py[line:274] - INFO: epoch 001:   4525 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.6, ups=0.85, wpb=109.5, bsz=40, num_updates=4520, lr=3.90868e-06, gnorm=1.2, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28007
2022-10-12 01:22:42 - progress_bar.py[line:274] - INFO: epoch 001:   4535 / 28910 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.7, ups=0.85, wpb=108.4, bsz=40, num_updates=4530, lr=3.91733e-06, gnorm=1.284, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28019
2022-10-12 01:22:54 - progress_bar.py[line:274] - INFO: epoch 001:   4545 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.7, ups=0.84, wpb=109.9, bsz=40, num_updates=4540, lr=3.92598e-06, gnorm=1.076, clip=100, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28031
2022-10-12 01:23:06 - progress_bar.py[line:274] - INFO: epoch 001:   4555 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.83, wpb=110.2, bsz=40, num_updates=4550, lr=3.93462e-06, gnorm=1.136, clip=100, loss_scale=1024, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=28043
2022-10-12 01:23:18 - progress_bar.py[line:274] - INFO: epoch 001:   4565 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.3, ups=0.85, wpb=110.8, bsz=40, num_updates=4560, lr=3.94327e-06, gnorm=1.147, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28055
2022-10-12 01:23:30 - progress_bar.py[line:274] - INFO: epoch 001:   4575 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.1, ups=0.85, wpb=110.1, bsz=40, num_updates=4570, lr=3.95192e-06, gnorm=1.11, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28066
2022-10-12 01:23:42 - progress_bar.py[line:274] - INFO: epoch 001:   4585 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.7, ups=0.84, wpb=110.7, bsz=40, num_updates=4580, lr=3.96057e-06, gnorm=1.171, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28078
2022-10-12 01:23:53 - progress_bar.py[line:274] - INFO: epoch 001:   4595 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.8, ups=0.86, wpb=109.7, bsz=40, num_updates=4590, lr=3.96921e-06, gnorm=1.233, clip=100, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=28090
2022-10-12 01:24:05 - progress_bar.py[line:274] - INFO: epoch 001:   4605 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.8, ups=0.85, wpb=108.6, bsz=40, num_updates=4600, lr=3.97786e-06, gnorm=1.302, clip=100, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=28102
2022-10-12 01:24:17 - progress_bar.py[line:274] - INFO: epoch 001:   4615 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.3, ups=0.84, wpb=110.6, bsz=40, num_updates=4610, lr=3.98651e-06, gnorm=1.138, clip=70, loss_scale=1024, train_wall=12, gb_free=22.5, ema_decay=0.9999, wall=28114
2022-10-12 01:24:29 - progress_bar.py[line:274] - INFO: epoch 001:   4625 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.83, wpb=108.6, bsz=40, num_updates=4620, lr=3.99516e-06, gnorm=1.236, clip=90, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28126
2022-10-12 01:24:41 - progress_bar.py[line:274] - INFO: epoch 001:   4635 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.6, ups=0.84, wpb=109.3, bsz=40, num_updates=4630, lr=4.0038e-06, gnorm=1.184, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28137
2022-10-12 01:24:52 - progress_bar.py[line:274] - INFO: epoch 001:   4645 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.85, wpb=109.4, bsz=40, num_updates=4640, lr=4.01245e-06, gnorm=1.184, clip=90, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28149
2022-10-12 01:25:04 - progress_bar.py[line:274] - INFO: epoch 001:   4655 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.2, ups=0.85, wpb=109.8, bsz=40, num_updates=4650, lr=4.0211e-06, gnorm=1.133, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28161
2022-10-12 01:25:16 - progress_bar.py[line:274] - INFO: epoch 001:   4665 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.9, ups=0.84, wpb=112.1, bsz=40, num_updates=4660, lr=4.02975e-06, gnorm=1.097, clip=80, loss_scale=1024, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=28173
2022-10-12 01:25:28 - progress_bar.py[line:274] - INFO: epoch 001:   4675 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.6, ups=0.84, wpb=111.6, bsz=40, num_updates=4670, lr=4.0384e-06, gnorm=1.127, clip=100, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28185
2022-10-12 01:25:40 - progress_bar.py[line:274] - INFO: epoch 001:   4685 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.81, wpb=110.6, bsz=40, num_updates=4680, lr=4.04704e-06, gnorm=1.145, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28197
2022-10-12 01:25:52 - progress_bar.py[line:274] - INFO: epoch 001:   4695 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.8, ups=0.85, wpb=109.6, bsz=40, num_updates=4690, lr=4.05569e-06, gnorm=1.107, clip=90, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28209
2022-10-12 01:26:04 - progress_bar.py[line:274] - INFO: epoch 001:   4705 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.83, wpb=110.6, bsz=40, num_updates=4700, lr=4.06434e-06, gnorm=1.014, clip=50, loss_scale=1024, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=28221
2022-10-12 01:26:17 - progress_bar.py[line:274] - INFO: epoch 001:   4715 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.81, wpb=111, bsz=40, num_updates=4710, lr=4.07299e-06, gnorm=1.146, clip=80, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=28233
2022-10-12 01:26:29 - progress_bar.py[line:274] - INFO: epoch 001:   4725 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.82, wpb=110.5, bsz=40, num_updates=4720, lr=4.08163e-06, gnorm=1.209, clip=80, loss_scale=1024, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=28245
2022-10-12 01:26:41 - progress_bar.py[line:274] - INFO: epoch 001:   4735 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.8, ups=0.84, wpb=110, bsz=40, num_updates=4730, lr=4.09028e-06, gnorm=1.129, clip=70, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=28257
2022-10-12 01:26:52 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 01:26:54 - progress_bar.py[line:274] - INFO: epoch 001:   4746 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.5, ups=0.77, wpb=111.1, bsz=40, num_updates=4740, lr=4.09893e-06, gnorm=1.171, clip=80, loss_scale=512, train_wall=13, gb_free=22.7, ema_decay=0.9999, wall=28270
2022-10-12 01:27:05 - progress_bar.py[line:274] - INFO: epoch 001:   4756 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.9, ups=0.85, wpb=110.5, bsz=40, num_updates=4750, lr=4.10758e-06, gnorm=1.147, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28282
2022-10-12 01:27:17 - progress_bar.py[line:274] - INFO: epoch 001:   4766 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.3, ups=0.85, wpb=110.7, bsz=40, num_updates=4760, lr=4.11622e-06, gnorm=1.185, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=28294
2022-10-12 01:27:29 - progress_bar.py[line:274] - INFO: epoch 001:   4776 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.83, wpb=110.3, bsz=40, num_updates=4770, lr=4.12487e-06, gnorm=1.14, clip=100, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=28306
2022-10-12 01:27:41 - progress_bar.py[line:274] - INFO: epoch 001:   4786 / 28910 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.84, wpb=108.6, bsz=40, num_updates=4780, lr=4.13352e-06, gnorm=1.233, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=28318
2022-10-12 01:27:53 - progress_bar.py[line:274] - INFO: epoch 001:   4796 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.4, ups=0.85, wpb=112.4, bsz=40, num_updates=4790, lr=4.14217e-06, gnorm=1.123, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28329
2022-10-12 01:28:05 - progress_bar.py[line:274] - INFO: epoch 001:   4806 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.6, ups=0.85, wpb=110.7, bsz=40, num_updates=4800, lr=4.15081e-06, gnorm=1.201, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28341
2022-10-12 01:28:17 - progress_bar.py[line:274] - INFO: epoch 001:   4816 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.84, wpb=110.5, bsz=40, num_updates=4810, lr=4.15946e-06, gnorm=1.137, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=28353
2022-10-12 01:28:28 - progress_bar.py[line:274] - INFO: epoch 001:   4826 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.84, wpb=108.4, bsz=40, num_updates=4820, lr=4.16811e-06, gnorm=1.222, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28365
2022-10-12 01:28:40 - progress_bar.py[line:274] - INFO: epoch 001:   4836 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.9, ups=0.84, wpb=110.6, bsz=40, num_updates=4830, lr=4.17676e-06, gnorm=1.157, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28377
2022-10-12 01:28:52 - progress_bar.py[line:274] - INFO: epoch 001:   4846 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.8, ups=0.84, wpb=112.9, bsz=40, num_updates=4840, lr=4.1854e-06, gnorm=1.041, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28389
2022-10-12 01:29:04 - progress_bar.py[line:274] - INFO: epoch 001:   4856 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.84, wpb=109.7, bsz=40, num_updates=4850, lr=4.19405e-06, gnorm=1.176, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28401
2022-10-12 01:29:16 - progress_bar.py[line:274] - INFO: epoch 001:   4866 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.1, ups=0.84, wpb=109.8, bsz=40, num_updates=4860, lr=4.2027e-06, gnorm=1.178, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28413
2022-10-12 01:29:28 - progress_bar.py[line:274] - INFO: epoch 001:   4876 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.3, ups=0.83, wpb=110.6, bsz=40, num_updates=4870, lr=4.21135e-06, gnorm=1.221, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28425
2022-10-12 01:29:40 - progress_bar.py[line:274] - INFO: epoch 001:   4886 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.9, ups=0.86, wpb=111, bsz=40, num_updates=4880, lr=4.21999e-06, gnorm=1.078, clip=80, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=28437
2022-10-12 01:29:52 - progress_bar.py[line:274] - INFO: epoch 001:   4896 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.9, ups=0.84, wpb=111, bsz=40, num_updates=4890, lr=4.22864e-06, gnorm=1.068, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28448
2022-10-12 01:30:04 - progress_bar.py[line:274] - INFO: epoch 001:   4906 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.6, ups=0.85, wpb=110.4, bsz=40, num_updates=4900, lr=4.23729e-06, gnorm=1.089, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28460
2022-10-12 01:30:15 - progress_bar.py[line:274] - INFO: epoch 001:   4916 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.9, ups=0.85, wpb=110.9, bsz=40, num_updates=4910, lr=4.24594e-06, gnorm=1.017, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28472
2022-10-12 01:30:27 - progress_bar.py[line:274] - INFO: epoch 001:   4926 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96, ups=0.86, wpb=112.2, bsz=40, num_updates=4920, lr=4.25458e-06, gnorm=1.035, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=28484
2022-10-12 01:30:39 - progress_bar.py[line:274] - INFO: epoch 001:   4936 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.82, wpb=110.2, bsz=40, num_updates=4930, lr=4.26323e-06, gnorm=1.1, clip=80, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=28496
2022-10-12 01:30:51 - progress_bar.py[line:274] - INFO: epoch 001:   4946 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.84, wpb=109.8, bsz=40, num_updates=4940, lr=4.27188e-06, gnorm=1.126, clip=80, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=28508
2022-10-12 01:31:03 - progress_bar.py[line:274] - INFO: epoch 001:   4956 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.6, ups=0.85, wpb=111.1, bsz=40, num_updates=4950, lr=4.28053e-06, gnorm=1.057, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=28520
2022-10-12 01:31:15 - progress_bar.py[line:274] - INFO: epoch 001:   4966 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.3, ups=0.83, wpb=109.5, bsz=40, num_updates=4960, lr=4.28917e-06, gnorm=1.168, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=28532
2022-10-12 01:31:27 - progress_bar.py[line:274] - INFO: epoch 001:   4976 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.9, ups=0.85, wpb=108.7, bsz=40, num_updates=4970, lr=4.29782e-06, gnorm=1.091, clip=70, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=28544
2022-10-12 01:31:39 - progress_bar.py[line:274] - INFO: epoch 001:   4986 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.84, wpb=111.1, bsz=40, num_updates=4980, lr=4.30647e-06, gnorm=1.047, clip=30, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28555
2022-10-12 01:31:51 - progress_bar.py[line:274] - INFO: epoch 001:   4996 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.1, ups=0.84, wpb=109.3, bsz=40, num_updates=4990, lr=4.31512e-06, gnorm=1.187, clip=80, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=28567
2022-10-12 01:32:02 - progress_bar.py[line:274] - INFO: epoch 001:   5006 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.9, ups=0.84, wpb=112.3, bsz=40, num_updates=5000, lr=4.32376e-06, gnorm=1.13, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=28579
2022-10-12 01:32:02 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 01:32:03 - train.py[line:549] - INFO: 0 / 9351
2022-10-12 01:32:03 - train.py[line:551] - INFO: load:0.85 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 01:33:29 - train.py[line:549] - INFO: 200 / 9351
2022-10-12 01:33:29 - train.py[line:551] - INFO: load:0.87 valid_run:85.12 task_valid:82.09 collect_output:1.75
2022-10-12 01:34:54 - train.py[line:549] - INFO: 400 / 9351
2022-10-12 01:34:54 - train.py[line:551] - INFO: load:0.89 valid_run:170.18 task_valid:164.07 collect_output:3.59
2022-10-12 01:36:17 - train.py[line:549] - INFO: 600 / 9351
2022-10-12 01:36:17 - train.py[line:551] - INFO: load:0.91 valid_run:253.81 task_valid:243.48 collect_output:6.52
2022-10-12 01:37:43 - train.py[line:549] - INFO: 800 / 9351
2022-10-12 01:37:43 - train.py[line:551] - INFO: load:0.94 valid_run:338.92 task_valid:322.99 collect_output:11.00
2022-10-12 01:39:09 - train.py[line:549] - INFO: 1000 / 9351
2022-10-12 01:39:09 - train.py[line:551] - INFO: load:0.96 valid_run:425.05 task_valid:402.99 collect_output:15.89
2022-10-12 01:40:34 - train.py[line:549] - INFO: 1200 / 9351
2022-10-12 01:40:34 - train.py[line:551] - INFO: load:0.98 valid_run:510.00 task_valid:481.80 collect_output:20.82
2022-10-12 01:41:58 - train.py[line:549] - INFO: 1400 / 9351
2022-10-12 01:41:58 - train.py[line:551] - INFO: load:1.01 valid_run:594.49 task_valid:562.30 collect_output:23.72
2022-10-12 01:43:23 - train.py[line:549] - INFO: 1600 / 9351
2022-10-12 01:43:23 - train.py[line:551] - INFO: load:1.03 valid_run:679.61 task_valid:644.93 collect_output:24.97
2022-10-12 01:44:49 - train.py[line:549] - INFO: 1800 / 9351
2022-10-12 01:44:49 - train.py[line:551] - INFO: load:1.06 valid_run:764.92 task_valid:726.04 collect_output:28.02
2022-10-12 01:46:13 - train.py[line:549] - INFO: 2000 / 9351
2022-10-12 01:46:13 - train.py[line:551] - INFO: load:1.08 valid_run:848.94 task_valid:806.50 collect_output:30.50
2022-10-12 01:47:37 - train.py[line:549] - INFO: 2200 / 9351
2022-10-12 01:47:37 - train.py[line:551] - INFO: load:1.11 valid_run:933.39 task_valid:887.04 collect_output:33.28
2022-10-12 01:49:02 - train.py[line:549] - INFO: 2400 / 9351
2022-10-12 01:49:02 - train.py[line:551] - INFO: load:1.13 valid_run:1017.81 task_valid:967.72 collect_output:35.94
2022-10-12 01:50:27 - train.py[line:549] - INFO: 2600 / 9351
2022-10-12 01:50:27 - train.py[line:551] - INFO: load:1.15 valid_run:1102.94 task_valid:1047.99 collect_output:39.70
2022-10-12 01:51:51 - train.py[line:549] - INFO: 2800 / 9351
2022-10-12 01:51:51 - train.py[line:551] - INFO: load:1.17 valid_run:1187.22 task_valid:1126.86 collect_output:44.06
2022-10-12 01:53:15 - train.py[line:549] - INFO: 3000 / 9351
2022-10-12 01:53:15 - train.py[line:551] - INFO: load:1.20 valid_run:1270.63 task_valid:1204.07 collect_output:49.18
2022-10-12 01:54:38 - train.py[line:549] - INFO: 3200 / 9351
2022-10-12 01:54:38 - train.py[line:551] - INFO: load:1.22 valid_run:1353.21 task_valid:1283.33 collect_output:51.41
2022-10-12 01:56:02 - train.py[line:549] - INFO: 3400 / 9351
2022-10-12 01:56:02 - train.py[line:551] - INFO: load:1.24 valid_run:1437.53 task_valid:1363.21 collect_output:54.74
2022-10-12 01:57:26 - train.py[line:549] - INFO: 3600 / 9351
2022-10-12 01:57:26 - train.py[line:551] - INFO: load:1.27 valid_run:1521.23 task_valid:1443.81 collect_output:56.74
2022-10-12 01:58:48 - train.py[line:549] - INFO: 3800 / 9351
2022-10-12 01:58:48 - train.py[line:551] - INFO: load:1.30 valid_run:1603.55 task_valid:1521.48 collect_output:60.31
2022-10-12 02:00:11 - train.py[line:549] - INFO: 4000 / 9351
2022-10-12 02:00:11 - train.py[line:551] - INFO: load:1.32 valid_run:1686.21 task_valid:1600.51 collect_output:62.83
2022-10-12 02:01:35 - train.py[line:549] - INFO: 4200 / 9351
2022-10-12 02:01:35 - train.py[line:551] - INFO: load:1.34 valid_run:1770.15 task_valid:1682.18 collect_output:64.06
2022-10-12 02:02:58 - train.py[line:549] - INFO: 4400 / 9351
2022-10-12 02:02:58 - train.py[line:551] - INFO: load:1.36 valid_run:1853.77 task_valid:1762.13 collect_output:66.62
2022-10-12 02:04:21 - train.py[line:549] - INFO: 4600 / 9351
2022-10-12 02:04:21 - train.py[line:551] - INFO: load:1.39 valid_run:1936.56 task_valid:1841.23 collect_output:69.25
2022-10-12 02:05:45 - train.py[line:549] - INFO: 4800 / 9351
2022-10-12 02:05:45 - train.py[line:551] - INFO: load:1.41 valid_run:2020.21 task_valid:1919.44 collect_output:73.60
2022-10-12 02:07:10 - train.py[line:549] - INFO: 5000 / 9351
2022-10-12 02:07:10 - train.py[line:551] - INFO: load:1.44 valid_run:2104.68 task_valid:2000.73 collect_output:75.68
2022-10-12 02:08:33 - train.py[line:549] - INFO: 5200 / 9351
2022-10-12 02:08:33 - train.py[line:551] - INFO: load:1.46 valid_run:2188.38 task_valid:2081.36 collect_output:77.66
2022-10-12 02:09:56 - train.py[line:549] - INFO: 5400 / 9351
2022-10-12 02:09:56 - train.py[line:551] - INFO: load:1.48 valid_run:2271.28 task_valid:2161.55 collect_output:79.30
2022-10-12 02:11:20 - train.py[line:549] - INFO: 5600 / 9351
2022-10-12 02:11:20 - train.py[line:551] - INFO: load:1.51 valid_run:2355.30 task_valid:2242.65 collect_output:81.15
2022-10-12 02:12:44 - train.py[line:549] - INFO: 5800 / 9351
2022-10-12 02:12:44 - train.py[line:551] - INFO: load:1.53 valid_run:2438.71 task_valid:2321.77 collect_output:84.38
2022-10-12 02:14:07 - train.py[line:549] - INFO: 6000 / 9351
2022-10-12 02:14:07 - train.py[line:551] - INFO: load:1.55 valid_run:2522.32 task_valid:2402.24 collect_output:86.44
2022-10-12 02:15:31 - train.py[line:549] - INFO: 6200 / 9351
2022-10-12 02:15:31 - train.py[line:551] - INFO: load:1.58 valid_run:2605.96 task_valid:2482.24 collect_output:88.97
2022-10-12 02:16:57 - train.py[line:549] - INFO: 6400 / 9351
2022-10-12 02:16:57 - train.py[line:551] - INFO: load:1.60 valid_run:2691.29 task_valid:2563.61 collect_output:91.85
2022-10-12 02:18:20 - train.py[line:549] - INFO: 6600 / 9351
2022-10-12 02:18:20 - train.py[line:551] - INFO: load:1.62 valid_run:2774.91 task_valid:2644.89 collect_output:93.13
2022-10-12 02:19:44 - train.py[line:549] - INFO: 6800 / 9351
2022-10-12 02:19:44 - train.py[line:551] - INFO: load:1.65 valid_run:2858.55 task_valid:2724.99 collect_output:95.60
2022-10-12 02:21:07 - train.py[line:549] - INFO: 7000 / 9351
2022-10-12 02:21:07 - train.py[line:551] - INFO: load:1.67 valid_run:2941.38 task_valid:2803.60 collect_output:98.71
2022-10-12 02:22:30 - train.py[line:549] - INFO: 7200 / 9351
2022-10-12 02:22:30 - train.py[line:551] - INFO: load:1.69 valid_run:3024.82 task_valid:2883.90 collect_output:100.76
2022-10-12 02:23:54 - train.py[line:549] - INFO: 7400 / 9351
2022-10-12 02:23:54 - train.py[line:551] - INFO: load:1.71 valid_run:3108.12 task_valid:2963.10 collect_output:103.79
2022-10-12 02:25:19 - train.py[line:549] - INFO: 7600 / 9351
2022-10-12 02:25:19 - train.py[line:551] - INFO: load:1.74 valid_run:3193.06 task_valid:3043.60 collect_output:107.14
2022-10-12 02:26:43 - train.py[line:549] - INFO: 7800 / 9351
2022-10-12 02:26:43 - train.py[line:551] - INFO: load:1.76 valid_run:3277.53 task_valid:3124.18 collect_output:109.92
2022-10-12 02:28:06 - train.py[line:549] - INFO: 8000 / 9351
2022-10-12 02:28:06 - train.py[line:551] - INFO: load:1.78 valid_run:3360.69 task_valid:3202.77 collect_output:113.35
2022-10-12 02:29:31 - train.py[line:549] - INFO: 8200 / 9351
2022-10-12 02:29:31 - train.py[line:551] - INFO: load:1.81 valid_run:3444.85 task_valid:3284.25 collect_output:114.96
2022-10-12 02:30:54 - train.py[line:549] - INFO: 8400 / 9351
2022-10-12 02:30:54 - train.py[line:551] - INFO: load:1.83 valid_run:3528.62 task_valid:3365.57 collect_output:116.31
2022-10-12 02:32:19 - train.py[line:549] - INFO: 8600 / 9351
2022-10-12 02:32:19 - train.py[line:551] - INFO: load:1.85 valid_run:3612.90 task_valid:3446.34 collect_output:118.72
2022-10-12 02:33:43 - train.py[line:549] - INFO: 8800 / 9351
2022-10-12 02:33:43 - train.py[line:551] - INFO: load:1.88 valid_run:3696.57 task_valid:3525.67 collect_output:121.98
2022-10-12 02:35:07 - train.py[line:549] - INFO: 9000 / 9351
2022-10-12 02:35:07 - train.py[line:551] - INFO: load:1.90 valid_run:3780.90 task_valid:3607.99 collect_output:122.90
2022-10-12 02:36:31 - train.py[line:549] - INFO: 9200 / 9351
2022-10-12 02:36:31 - train.py[line:551] - INFO: load:1.93 valid_run:3864.69 task_valid:3689.26 collect_output:124.35

====================================================================================================
SGG eval:     R @ 50: 0.6722;     R @ 100: 0.6960;     R @ 500: 0.7198;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4707;    mR @ 100: 0.5002;    mR @ 500: 0.5452;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.8125) (covering:0.3714) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.4677) (lying on:0.4667) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9467) (says:0.0000) (sitting on:0.7279) (standing on:0.4493) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-12 02:37:45 - train.py[line:487] - INFO: 0.6959770817417876

====================================================================================================
SGG eval:     R @ 50: 0.6722;     R @ 100: 0.6960;     R @ 500: 0.7198;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4707;    mR @ 100: 0.5002;    mR @ 500: 0.5452;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.8125) (covering:0.3714) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.4677) (lying on:0.4667) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9467) (says:0.0000) (sitting on:0.7279) (standing on:0.4493) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-12 02:37:45 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 02:37:45 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.341 | loss_v1 0 | loss_v2 0 | nll_loss 0.193 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.695977 | ppl 1.14 | vqa_score 0.5597 | wps 113.8 | wpb 48 | bsz 16 | num_updates 5000 | best_R@100 0.695977
2022-10-12 02:37:45 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 5000 updates
2022-10-12 02:37:45 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-12 02:37:51 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-12 02:37:57 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 0.6959770817417876) (writing took 12.118701019790024 seconds)
2022-10-12 02:38:09 - progress_bar.py[line:274] - INFO: epoch 001:   5016 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=0.3, ups=0, wpb=109.8, bsz=40, num_updates=5010, lr=4.33241e-06, gnorm=1.159, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=32546
2022-10-12 02:38:21 - progress_bar.py[line:274] - INFO: epoch 001:   5026 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.5, ups=0.84, wpb=110.5, bsz=40, num_updates=5020, lr=4.34106e-06, gnorm=1.114, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=32558
2022-10-12 02:38:33 - progress_bar.py[line:274] - INFO: epoch 001:   5036 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.9, ups=0.83, wpb=112.1, bsz=40, num_updates=5030, lr=4.34971e-06, gnorm=1.087, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=32570
2022-10-12 02:38:45 - progress_bar.py[line:274] - INFO: epoch 001:   5046 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.84, wpb=109.9, bsz=40, num_updates=5040, lr=4.35835e-06, gnorm=1.197, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32582
2022-10-12 02:38:57 - progress_bar.py[line:274] - INFO: epoch 001:   5056 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.83, wpb=110.8, bsz=40, num_updates=5050, lr=4.367e-06, gnorm=1.003, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32594
2022-10-12 02:39:09 - progress_bar.py[line:274] - INFO: epoch 001:   5066 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.84, wpb=111.3, bsz=40, num_updates=5060, lr=4.37565e-06, gnorm=1.157, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=32606
2022-10-12 02:39:21 - progress_bar.py[line:274] - INFO: epoch 001:   5076 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.84, wpb=111.3, bsz=40, num_updates=5070, lr=4.3843e-06, gnorm=1.071, clip=40, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=32618
2022-10-12 02:39:33 - progress_bar.py[line:274] - INFO: epoch 001:   5086 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.1, ups=0.83, wpb=109.5, bsz=40, num_updates=5080, lr=4.39294e-06, gnorm=1.202, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=32630
2022-10-12 02:39:45 - progress_bar.py[line:274] - INFO: epoch 001:   5096 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94, ups=0.85, wpb=110.2, bsz=40, num_updates=5090, lr=4.40159e-06, gnorm=1.277, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=32642
2022-10-12 02:39:57 - progress_bar.py[line:274] - INFO: epoch 001:   5106 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.8, ups=0.85, wpb=111, bsz=40, num_updates=5100, lr=4.41024e-06, gnorm=1.176, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32653
2022-10-12 02:40:08 - progress_bar.py[line:274] - INFO: epoch 001:   5116 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.9, ups=0.84, wpb=110, bsz=40, num_updates=5110, lr=4.41889e-06, gnorm=1.162, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=32665
2022-10-12 02:40:20 - progress_bar.py[line:274] - INFO: epoch 001:   5126 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.9, ups=0.84, wpb=110.2, bsz=40, num_updates=5120, lr=4.42753e-06, gnorm=1.143, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=32677
2022-10-12 02:40:32 - progress_bar.py[line:274] - INFO: epoch 001:   5136 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.84, wpb=110.9, bsz=40, num_updates=5130, lr=4.43618e-06, gnorm=1.142, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=32689
2022-10-12 02:40:44 - progress_bar.py[line:274] - INFO: epoch 001:   5146 / 28910 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.7, ups=0.86, wpb=109.1, bsz=40, num_updates=5140, lr=4.44483e-06, gnorm=1.234, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=32701
2022-10-12 02:40:56 - progress_bar.py[line:274] - INFO: epoch 001:   5156 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.8, ups=0.84, wpb=109.9, bsz=40, num_updates=5150, lr=4.45348e-06, gnorm=1.093, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=32712
2022-10-12 02:41:08 - progress_bar.py[line:274] - INFO: epoch 001:   5166 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.5, ups=0.84, wpb=110.1, bsz=40, num_updates=5160, lr=4.46212e-06, gnorm=1.089, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32724
2022-10-12 02:41:19 - progress_bar.py[line:274] - INFO: epoch 001:   5176 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.5, ups=0.86, wpb=110.7, bsz=40, num_updates=5170, lr=4.47077e-06, gnorm=1.161, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32736
2022-10-12 02:41:31 - progress_bar.py[line:274] - INFO: epoch 001:   5186 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.4, ups=0.84, wpb=110.8, bsz=40, num_updates=5180, lr=4.47942e-06, gnorm=1.148, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=32748
2022-10-12 02:41:43 - progress_bar.py[line:274] - INFO: epoch 001:   5196 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.7, ups=0.84, wpb=109.7, bsz=40, num_updates=5190, lr=4.48807e-06, gnorm=1.205, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32760
2022-10-12 02:41:55 - progress_bar.py[line:274] - INFO: epoch 001:   5206 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.1, ups=0.85, wpb=110, bsz=40, num_updates=5200, lr=4.49671e-06, gnorm=1.183, clip=100, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=32771
2022-10-12 02:42:06 - progress_bar.py[line:274] - INFO: epoch 001:   5216 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.7, ups=0.85, wpb=112, bsz=40, num_updates=5210, lr=4.50536e-06, gnorm=1.12, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=32783
2022-10-12 02:42:18 - progress_bar.py[line:274] - INFO: epoch 001:   5226 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.6, ups=0.86, wpb=110, bsz=40, num_updates=5220, lr=4.51401e-06, gnorm=1.137, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32795
2022-10-12 02:42:30 - progress_bar.py[line:274] - INFO: epoch 001:   5236 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.6, ups=0.83, wpb=110.5, bsz=40, num_updates=5230, lr=4.52266e-06, gnorm=1.199, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=32807
2022-10-12 02:42:42 - progress_bar.py[line:274] - INFO: epoch 001:   5246 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.85, wpb=109, bsz=40, num_updates=5240, lr=4.5313e-06, gnorm=1.19, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=32819
2022-10-12 02:42:54 - progress_bar.py[line:274] - INFO: epoch 001:   5256 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.8, ups=0.85, wpb=109, bsz=40, num_updates=5250, lr=4.53995e-06, gnorm=1.137, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=32830
2022-10-12 02:43:06 - progress_bar.py[line:274] - INFO: epoch 001:   5266 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.8, ups=0.84, wpb=111, bsz=40, num_updates=5260, lr=4.5486e-06, gnorm=1.096, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32842
2022-10-12 02:43:18 - progress_bar.py[line:274] - INFO: epoch 001:   5276 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.82, wpb=109.6, bsz=40, num_updates=5270, lr=4.55725e-06, gnorm=1.103, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32855
2022-10-12 02:43:30 - progress_bar.py[line:274] - INFO: epoch 001:   5286 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.85, wpb=108.5, bsz=40, num_updates=5280, lr=4.56589e-06, gnorm=1.19, clip=100, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=32866
2022-10-12 02:43:41 - progress_bar.py[line:274] - INFO: epoch 001:   5296 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.9, ups=0.86, wpb=110.6, bsz=40, num_updates=5290, lr=4.57454e-06, gnorm=1.114, clip=60, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32878
2022-10-12 02:43:53 - progress_bar.py[line:274] - INFO: epoch 001:   5306 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.8, ups=0.85, wpb=109.7, bsz=40, num_updates=5300, lr=4.58319e-06, gnorm=1.104, clip=50, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32890
2022-10-12 02:44:05 - progress_bar.py[line:274] - INFO: epoch 001:   5316 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.84, wpb=108.9, bsz=40, num_updates=5310, lr=4.59184e-06, gnorm=1.161, clip=100, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32902
2022-10-12 02:44:17 - progress_bar.py[line:274] - INFO: epoch 001:   5326 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.83, wpb=110, bsz=40, num_updates=5320, lr=4.60048e-06, gnorm=1.092, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32914
2022-10-12 02:44:29 - progress_bar.py[line:274] - INFO: epoch 001:   5336 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.9, ups=0.86, wpb=110.3, bsz=40, num_updates=5330, lr=4.60913e-06, gnorm=1.148, clip=90, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=32925
2022-10-12 02:44:40 - progress_bar.py[line:274] - INFO: epoch 001:   5346 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.5, ups=0.84, wpb=109.5, bsz=40, num_updates=5340, lr=4.61778e-06, gnorm=1.18, clip=100, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32937
2022-10-12 02:44:53 - progress_bar.py[line:274] - INFO: epoch 001:   5356 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.82, wpb=112.1, bsz=40, num_updates=5350, lr=4.62643e-06, gnorm=1.086, clip=60, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=32949
2022-10-12 02:45:05 - progress_bar.py[line:274] - INFO: epoch 001:   5366 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.83, wpb=111.5, bsz=40, num_updates=5360, lr=4.63507e-06, gnorm=1.155, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32961
2022-10-12 02:45:16 - progress_bar.py[line:274] - INFO: epoch 001:   5376 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.4, ups=0.86, wpb=109.8, bsz=40, num_updates=5370, lr=4.64372e-06, gnorm=1.057, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=32973
2022-10-12 02:45:28 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 02:45:29 - progress_bar.py[line:274] - INFO: epoch 001:   5387 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.2, ups=0.77, wpb=111.2, bsz=40, num_updates=5380, lr=4.65237e-06, gnorm=1.059, clip=50, loss_scale=512, train_wall=13, gb_free=22.7, ema_decay=0.9999, wall=32986
2022-10-12 02:45:41 - progress_bar.py[line:274] - INFO: epoch 001:   5397 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.83, wpb=111.1, bsz=40, num_updates=5390, lr=4.66102e-06, gnorm=1.16, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=32998
2022-10-12 02:45:53 - progress_bar.py[line:274] - INFO: epoch 001:   5407 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.5, ups=0.85, wpb=109.4, bsz=40, num_updates=5400, lr=4.66966e-06, gnorm=1.186, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=33010
2022-10-12 02:46:05 - progress_bar.py[line:274] - INFO: epoch 001:   5417 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.3, ups=0.83, wpb=109.6, bsz=40, num_updates=5410, lr=4.67831e-06, gnorm=1.154, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=33022
2022-10-12 02:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   5427 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.84, wpb=111.4, bsz=40, num_updates=5420, lr=4.68696e-06, gnorm=1.245, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33034
2022-10-12 02:46:29 - progress_bar.py[line:274] - INFO: epoch 001:   5437 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.83, wpb=109.3, bsz=40, num_updates=5430, lr=4.69561e-06, gnorm=1.216, clip=100, loss_scale=512, train_wall=12, gb_free=23.2, ema_decay=0.9999, wall=33046
2022-10-12 02:46:41 - progress_bar.py[line:274] - INFO: epoch 001:   5447 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93, ups=0.84, wpb=110.3, bsz=40, num_updates=5440, lr=4.70425e-06, gnorm=1.103, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33057
2022-10-12 02:46:52 - progress_bar.py[line:274] - INFO: epoch 001:   5457 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.8, ups=0.85, wpb=109.9, bsz=40, num_updates=5450, lr=4.7129e-06, gnorm=1.15, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33069
2022-10-12 02:47:04 - progress_bar.py[line:274] - INFO: epoch 001:   5467 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.7, ups=0.85, wpb=109.1, bsz=40, num_updates=5460, lr=4.72155e-06, gnorm=1.152, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33081
2022-10-12 02:47:16 - progress_bar.py[line:274] - INFO: epoch 001:   5477 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.5, ups=0.86, wpb=111.5, bsz=40, num_updates=5470, lr=4.7302e-06, gnorm=1.151, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33093
2022-10-12 02:47:28 - progress_bar.py[line:274] - INFO: epoch 001:   5487 / 28910 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.83, wpb=109.2, bsz=40, num_updates=5480, lr=4.73884e-06, gnorm=1.233, clip=90, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=33105
2022-10-12 02:47:40 - progress_bar.py[line:274] - INFO: epoch 001:   5497 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.4, ups=0.85, wpb=110.9, bsz=40, num_updates=5490, lr=4.74749e-06, gnorm=1.197, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33116
2022-10-12 02:47:52 - progress_bar.py[line:274] - INFO: epoch 001:   5507 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.83, wpb=111.1, bsz=40, num_updates=5500, lr=4.75614e-06, gnorm=1.106, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33128
2022-10-12 02:48:04 - progress_bar.py[line:274] - INFO: epoch 001:   5517 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.84, wpb=109.2, bsz=40, num_updates=5510, lr=4.76479e-06, gnorm=1.102, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33140
2022-10-12 02:48:16 - progress_bar.py[line:274] - INFO: epoch 001:   5527 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.83, wpb=111.2, bsz=40, num_updates=5520, lr=4.77343e-06, gnorm=1.146, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33152
2022-10-12 02:48:28 - progress_bar.py[line:274] - INFO: epoch 001:   5537 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.1, ups=0.84, wpb=110.8, bsz=40, num_updates=5530, lr=4.78208e-06, gnorm=1.081, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33164
2022-10-12 02:48:39 - progress_bar.py[line:274] - INFO: epoch 001:   5547 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.6, ups=0.84, wpb=109.7, bsz=40, num_updates=5540, lr=4.79073e-06, gnorm=1.018, clip=40, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33176
2022-10-12 02:48:51 - progress_bar.py[line:274] - INFO: epoch 001:   5557 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.1, ups=0.84, wpb=110.9, bsz=40, num_updates=5550, lr=4.79938e-06, gnorm=1.021, clip=40, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33188
2022-10-12 02:49:03 - progress_bar.py[line:274] - INFO: epoch 001:   5567 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.84, wpb=110.6, bsz=40, num_updates=5560, lr=4.80802e-06, gnorm=1.097, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33200
2022-10-12 02:49:15 - progress_bar.py[line:274] - INFO: epoch 001:   5577 / 28910 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.5, ups=0.86, wpb=110.4, bsz=40, num_updates=5570, lr=4.81667e-06, gnorm=1.141, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33212
2022-10-12 02:49:27 - progress_bar.py[line:274] - INFO: epoch 001:   5587 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94, ups=0.85, wpb=110.6, bsz=40, num_updates=5580, lr=4.82532e-06, gnorm=1.175, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33223
2022-10-12 02:49:38 - progress_bar.py[line:274] - INFO: epoch 001:   5597 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.8, ups=0.86, wpb=110.9, bsz=40, num_updates=5590, lr=4.83397e-06, gnorm=1.095, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33235
2022-10-12 02:49:50 - progress_bar.py[line:274] - INFO: epoch 001:   5607 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.1, ups=0.84, wpb=111.7, bsz=40, num_updates=5600, lr=4.84262e-06, gnorm=1.069, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33247
2022-10-12 02:50:02 - progress_bar.py[line:274] - INFO: epoch 001:   5617 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.7, ups=0.84, wpb=111, bsz=40, num_updates=5610, lr=4.85126e-06, gnorm=1.09, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33259
2022-10-12 02:50:14 - progress_bar.py[line:274] - INFO: epoch 001:   5627 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.84, wpb=110.4, bsz=40, num_updates=5620, lr=4.85991e-06, gnorm=1.103, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33271
2022-10-12 02:50:26 - progress_bar.py[line:274] - INFO: epoch 001:   5637 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.9, ups=0.86, wpb=110.5, bsz=40, num_updates=5630, lr=4.86856e-06, gnorm=1.134, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33282
2022-10-12 02:50:37 - progress_bar.py[line:274] - INFO: epoch 001:   5647 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94, ups=0.84, wpb=111.6, bsz=40, num_updates=5640, lr=4.87721e-06, gnorm=1.014, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33294
2022-10-12 02:50:49 - progress_bar.py[line:274] - INFO: epoch 001:   5657 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.9, ups=0.84, wpb=110.4, bsz=40, num_updates=5650, lr=4.88585e-06, gnorm=1.134, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33306
2022-10-12 02:51:01 - progress_bar.py[line:274] - INFO: epoch 001:   5667 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.2, ups=0.84, wpb=110.5, bsz=40, num_updates=5660, lr=4.8945e-06, gnorm=1.194, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33318
2022-10-12 02:51:13 - progress_bar.py[line:274] - INFO: epoch 001:   5677 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.4, ups=0.84, wpb=110.3, bsz=40, num_updates=5670, lr=4.90315e-06, gnorm=1.181, clip=90, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=33330
2022-10-12 02:51:25 - progress_bar.py[line:274] - INFO: epoch 001:   5687 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.84, wpb=110.1, bsz=40, num_updates=5680, lr=4.9118e-06, gnorm=1.201, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33342
2022-10-12 02:51:37 - progress_bar.py[line:274] - INFO: epoch 001:   5697 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.2, ups=0.84, wpb=112.1, bsz=40, num_updates=5690, lr=4.92044e-06, gnorm=1.096, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33354
2022-10-12 02:51:49 - progress_bar.py[line:274] - INFO: epoch 001:   5707 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.83, wpb=110.1, bsz=40, num_updates=5700, lr=4.92909e-06, gnorm=1.086, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33366
2022-10-12 02:52:01 - progress_bar.py[line:274] - INFO: epoch 001:   5717 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.84, wpb=110, bsz=40, num_updates=5710, lr=4.93774e-06, gnorm=1.145, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33378
2022-10-12 02:52:13 - progress_bar.py[line:274] - INFO: epoch 001:   5727 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.4, ups=0.85, wpb=110.5, bsz=40, num_updates=5720, lr=4.94639e-06, gnorm=1.057, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33389
2022-10-12 02:52:24 - progress_bar.py[line:274] - INFO: epoch 001:   5737 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.1, ups=0.84, wpb=110.4, bsz=40, num_updates=5730, lr=4.95503e-06, gnorm=1.138, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33401
2022-10-12 02:52:36 - progress_bar.py[line:274] - INFO: epoch 001:   5747 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.1, ups=0.85, wpb=110.4, bsz=40, num_updates=5740, lr=4.96368e-06, gnorm=1.166, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33413
2022-10-12 02:52:48 - progress_bar.py[line:274] - INFO: epoch 001:   5757 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.5, ups=0.85, wpb=109.7, bsz=40, num_updates=5750, lr=4.97233e-06, gnorm=1.206, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33425
2022-10-12 02:53:00 - progress_bar.py[line:274] - INFO: epoch 001:   5767 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.84, wpb=110.4, bsz=40, num_updates=5760, lr=4.98098e-06, gnorm=1.095, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33437
2022-10-12 02:53:12 - progress_bar.py[line:274] - INFO: epoch 001:   5777 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.1, ups=0.85, wpb=109.9, bsz=40, num_updates=5770, lr=4.98962e-06, gnorm=1.19, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=33448
2022-10-12 02:53:24 - progress_bar.py[line:274] - INFO: epoch 001:   5787 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.84, wpb=109.5, bsz=40, num_updates=5780, lr=4.99827e-06, gnorm=1.183, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33460
2022-10-12 02:53:35 - progress_bar.py[line:274] - INFO: epoch 001:   5797 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.3, ups=0.85, wpb=111.3, bsz=40, num_updates=5790, lr=5.00692e-06, gnorm=0.983, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33472
2022-10-12 02:53:47 - progress_bar.py[line:274] - INFO: epoch 001:   5807 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.8, ups=0.86, wpb=108.8, bsz=40, num_updates=5800, lr=5.01557e-06, gnorm=1.123, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33484
2022-10-12 02:53:59 - progress_bar.py[line:274] - INFO: epoch 001:   5817 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94, ups=0.85, wpb=110.8, bsz=40, num_updates=5810, lr=5.02421e-06, gnorm=1.094, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33496
2022-10-12 02:54:11 - progress_bar.py[line:274] - INFO: epoch 001:   5827 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.7, ups=0.84, wpb=110.8, bsz=40, num_updates=5820, lr=5.03286e-06, gnorm=1.145, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33508
2022-10-12 02:54:23 - progress_bar.py[line:274] - INFO: epoch 001:   5837 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.84, wpb=109.8, bsz=40, num_updates=5830, lr=5.04151e-06, gnorm=1.313, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33520
2022-10-12 02:54:34 - progress_bar.py[line:274] - INFO: epoch 001:   5847 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.3, ups=0.86, wpb=110.5, bsz=40, num_updates=5840, lr=5.05016e-06, gnorm=1.014, clip=40, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33531
2022-10-12 02:54:46 - progress_bar.py[line:274] - INFO: epoch 001:   5857 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.83, wpb=109.8, bsz=40, num_updates=5850, lr=5.0588e-06, gnorm=1.155, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33543
2022-10-12 02:54:59 - progress_bar.py[line:274] - INFO: epoch 001:   5867 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.9, ups=0.82, wpb=110.2, bsz=40, num_updates=5860, lr=5.06745e-06, gnorm=1.199, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33555
2022-10-12 02:55:11 - progress_bar.py[line:274] - INFO: epoch 001:   5877 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.83, wpb=110.3, bsz=40, num_updates=5870, lr=5.0761e-06, gnorm=1.164, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33567
2022-10-12 02:55:23 - progress_bar.py[line:274] - INFO: epoch 001:   5887 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.84, wpb=109.8, bsz=40, num_updates=5880, lr=5.08475e-06, gnorm=1.068, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33579
2022-10-12 02:55:35 - progress_bar.py[line:274] - INFO: epoch 001:   5897 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.8, ups=0.84, wpb=111.8, bsz=40, num_updates=5890, lr=5.09339e-06, gnorm=1.046, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33591
2022-10-12 02:55:46 - progress_bar.py[line:274] - INFO: epoch 001:   5907 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.5, ups=0.85, wpb=109.1, bsz=40, num_updates=5900, lr=5.10204e-06, gnorm=1.298, clip=100, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=33603
2022-10-12 02:55:57 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 02:55:59 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.5, ups=0.79, wpb=113, bsz=40, num_updates=5910, lr=5.11069e-06, gnorm=1.054, clip=80, loss_scale=512, train_wall=13, gb_free=22.7, ema_decay=0.9999, wall=33616
2022-10-12 02:56:11 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.6, ups=0.85, wpb=109.5, bsz=40, num_updates=5920, lr=5.11934e-06, gnorm=1.207, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=33627
2022-10-12 02:56:23 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.3, ups=0.84, wpb=110.7, bsz=40, num_updates=5930, lr=5.12798e-06, gnorm=1.164, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33639
2022-10-12 02:56:34 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.2, ups=0.84, wpb=109.2, bsz=40, num_updates=5940, lr=5.13663e-06, gnorm=1.147, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33651
2022-10-12 02:56:46 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.1, ups=0.86, wpb=109.7, bsz=40, num_updates=5950, lr=5.14528e-06, gnorm=1.201, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33663
2022-10-12 02:56:58 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.8, ups=0.85, wpb=109.1, bsz=40, num_updates=5960, lr=5.15393e-06, gnorm=1.169, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33675
2022-10-12 02:57:10 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.85, wpb=110.4, bsz=40, num_updates=5970, lr=5.16257e-06, gnorm=1.14, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33686
2022-10-12 02:57:22 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.84, wpb=109.4, bsz=40, num_updates=5980, lr=5.17122e-06, gnorm=1.173, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=33698
2022-10-12 02:57:34 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.82, wpb=110.6, bsz=40, num_updates=5990, lr=5.17987e-06, gnorm=1.223, clip=100, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33711
2022-10-12 02:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.3, ups=0.85, wpb=109.8, bsz=40, num_updates=6000, lr=5.18852e-06, gnorm=1.158, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=33722
2022-10-12 02:57:46 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 02:57:47 - train.py[line:549] - INFO: 0 / 9351
2022-10-12 02:57:47 - train.py[line:551] - INFO: load:0.84 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 02:59:11 - train.py[line:549] - INFO: 200 / 9351
2022-10-12 02:59:11 - train.py[line:551] - INFO: load:0.87 valid_run:83.86 task_valid:81.47 collect_output:1.31
2022-10-12 03:00:34 - train.py[line:549] - INFO: 400 / 9351
2022-10-12 03:00:34 - train.py[line:551] - INFO: load:0.89 valid_run:167.47 task_valid:162.73 collect_output:2.60
2022-10-12 03:01:56 - train.py[line:549] - INFO: 600 / 9351
2022-10-12 03:01:56 - train.py[line:551] - INFO: load:0.91 valid_run:249.64 task_valid:241.55 collect_output:4.88
2022-10-12 03:03:20 - train.py[line:549] - INFO: 800 / 9351
2022-10-12 03:03:20 - train.py[line:551] - INFO: load:0.93 valid_run:333.20 task_valid:320.50 collect_output:8.44
2022-10-12 03:04:44 - train.py[line:549] - INFO: 1000 / 9351
2022-10-12 03:04:44 - train.py[line:551] - INFO: load:0.95 valid_run:417.50 task_valid:399.70 collect_output:12.48
2022-10-12 03:06:08 - train.py[line:549] - INFO: 1200 / 9351
2022-10-12 03:06:08 - train.py[line:551] - INFO: load:0.98 valid_run:501.17 task_valid:477.83 collect_output:16.92
2022-10-12 03:07:31 - train.py[line:549] - INFO: 1400 / 9351
2022-10-12 03:07:31 - train.py[line:551] - INFO: load:1.00 valid_run:584.42 task_valid:558.20 collect_output:18.76
2022-10-12 03:08:56 - train.py[line:549] - INFO: 1600 / 9351
2022-10-12 03:08:56 - train.py[line:551] - INFO: load:1.02 valid_run:668.50 task_valid:640.25 collect_output:19.77
2022-10-12 03:10:20 - train.py[line:549] - INFO: 1800 / 9351
2022-10-12 03:10:20 - train.py[line:551] - INFO: load:1.05 valid_run:753.35 task_valid:721.18 collect_output:22.61
2022-10-12 03:11:45 - train.py[line:549] - INFO: 2000 / 9351
2022-10-12 03:11:45 - train.py[line:551] - INFO: load:1.07 valid_run:837.37 task_valid:801.33 collect_output:25.46
2022-10-12 03:13:09 - train.py[line:549] - INFO: 2200 / 9351
2022-10-12 03:13:09 - train.py[line:551] - INFO: load:1.09 valid_run:921.47 task_valid:881.17 collect_output:28.67
2022-10-12 03:14:33 - train.py[line:549] - INFO: 2400 / 9351
2022-10-12 03:14:33 - train.py[line:551] - INFO: load:1.12 valid_run:1005.73 task_valid:962.02 collect_output:31.00
2022-10-12 03:15:58 - train.py[line:549] - INFO: 2600 / 9351
2022-10-12 03:15:58 - train.py[line:551] - INFO: load:1.14 valid_run:1090.78 task_valid:1042.23 collect_output:34.76
2022-10-12 03:17:23 - train.py[line:549] - INFO: 2800 / 9351
2022-10-12 03:17:23 - train.py[line:551] - INFO: load:1.16 valid_run:1175.18 task_valid:1121.48 collect_output:38.80
2022-10-12 03:18:46 - train.py[line:549] - INFO: 3000 / 9351
2022-10-12 03:18:46 - train.py[line:551] - INFO: load:1.18 valid_run:1258.35 task_valid:1198.96 collect_output:43.44
2022-10-12 03:20:09 - train.py[line:549] - INFO: 3200 / 9351
2022-10-12 03:20:09 - train.py[line:551] - INFO: load:1.21 valid_run:1340.99 task_valid:1278.63 collect_output:45.31
2022-10-12 03:21:33 - train.py[line:549] - INFO: 3400 / 9351
2022-10-12 03:21:33 - train.py[line:551] - INFO: load:1.23 valid_run:1425.05 task_valid:1358.39 collect_output:48.55
2022-10-12 03:22:56 - train.py[line:549] - INFO: 3600 / 9351
2022-10-12 03:22:56 - train.py[line:551] - INFO: load:1.25 valid_run:1508.24 task_valid:1438.70 collect_output:50.40
2022-10-12 03:24:18 - train.py[line:549] - INFO: 3800 / 9351
2022-10-12 03:24:18 - train.py[line:551] - INFO: load:1.27 valid_run:1590.43 task_valid:1516.50 collect_output:53.73
2022-10-12 03:25:41 - train.py[line:549] - INFO: 4000 / 9351
2022-10-12 03:25:41 - train.py[line:551] - INFO: load:1.30 valid_run:1673.12 task_valid:1595.61 collect_output:56.21
2022-10-12 03:27:05 - train.py[line:549] - INFO: 4200 / 9351
2022-10-12 03:27:05 - train.py[line:551] - INFO: load:1.32 valid_run:1757.38 task_valid:1677.82 collect_output:57.20
2022-10-12 03:28:29 - train.py[line:549] - INFO: 4400 / 9351
2022-10-12 03:28:29 - train.py[line:551] - INFO: load:1.34 valid_run:1841.15 task_valid:1757.76 collect_output:59.97
2022-10-12 03:29:53 - train.py[line:549] - INFO: 4600 / 9351
2022-10-12 03:29:53 - train.py[line:551] - INFO: load:1.36 valid_run:1924.73 task_valid:1837.28 collect_output:62.93
2022-10-12 03:31:17 - train.py[line:549] - INFO: 4800 / 9351
2022-10-12 03:31:17 - train.py[line:551] - INFO: load:1.39 valid_run:2008.94 task_valid:1915.62 collect_output:67.73
2022-10-12 03:32:42 - train.py[line:549] - INFO: 5000 / 9351
2022-10-12 03:32:42 - train.py[line:551] - INFO: load:1.41 valid_run:2093.73 task_valid:1996.94 collect_output:70.12
2022-10-12 03:34:06 - train.py[line:549] - INFO: 5200 / 9351
2022-10-12 03:34:06 - train.py[line:551] - INFO: load:1.43 valid_run:2178.19 task_valid:2077.82 collect_output:72.54
2022-10-12 03:35:30 - train.py[line:549] - INFO: 5400 / 9351
2022-10-12 03:35:30 - train.py[line:551] - INFO: load:1.46 valid_run:2261.50 task_valid:2158.09 collect_output:74.45
2022-10-12 03:36:54 - train.py[line:549] - INFO: 5600 / 9351
2022-10-12 03:36:54 - train.py[line:551] - INFO: load:1.48 valid_run:2346.00 task_valid:2239.60 collect_output:76.35
2022-10-12 03:38:18 - train.py[line:549] - INFO: 5800 / 9351
2022-10-12 03:38:18 - train.py[line:551] - INFO: load:1.50 valid_run:2429.92 task_valid:2319.45 collect_output:79.20
2022-10-12 03:39:43 - train.py[line:549] - INFO: 6000 / 9351
2022-10-12 03:39:43 - train.py[line:551] - INFO: load:1.52 valid_run:2514.16 task_valid:2400.34 collect_output:81.39
2022-10-12 03:41:06 - train.py[line:549] - INFO: 6200 / 9351
2022-10-12 03:41:06 - train.py[line:551] - INFO: load:1.56 valid_run:2597.81 task_valid:2480.50 collect_output:83.74
2022-10-12 03:42:32 - train.py[line:549] - INFO: 6400 / 9351
2022-10-12 03:42:32 - train.py[line:551] - INFO: load:1.58 valid_run:2683.62 task_valid:2562.23 collect_output:86.69
2022-10-12 03:43:56 - train.py[line:549] - INFO: 6600 / 9351
2022-10-12 03:43:56 - train.py[line:551] - INFO: load:1.60 valid_run:2767.93 task_valid:2643.97 collect_output:88.12
2022-10-12 03:45:21 - train.py[line:549] - INFO: 6800 / 9351
2022-10-12 03:45:21 - train.py[line:551] - INFO: load:1.62 valid_run:2851.95 task_valid:2724.26 collect_output:90.71
2022-10-12 03:46:44 - train.py[line:549] - INFO: 7000 / 9351
2022-10-12 03:46:44 - train.py[line:551] - INFO: load:1.64 valid_run:2935.68 task_valid:2803.36 collect_output:94.20
2022-10-12 03:48:08 - train.py[line:549] - INFO: 7200 / 9351
2022-10-12 03:48:08 - train.py[line:551] - INFO: load:1.67 valid_run:3019.56 task_valid:2884.00 collect_output:96.28
2022-10-12 03:49:33 - train.py[line:549] - INFO: 7400 / 9351
2022-10-12 03:49:33 - train.py[line:551] - INFO: load:1.69 valid_run:3103.78 task_valid:2963.70 collect_output:99.63
2022-10-12 03:50:57 - train.py[line:549] - INFO: 7600 / 9351
2022-10-12 03:50:57 - train.py[line:551] - INFO: load:1.71 valid_run:3188.63 task_valid:3044.05 collect_output:103.09
2022-10-12 03:52:22 - train.py[line:549] - INFO: 7800 / 9351
2022-10-12 03:52:22 - train.py[line:551] - INFO: load:1.73 valid_run:3272.95 task_valid:3124.24 collect_output:106.17
2022-10-12 03:53:45 - train.py[line:549] - INFO: 8000 / 9351
2022-10-12 03:53:45 - train.py[line:551] - INFO: load:1.76 valid_run:3355.75 task_valid:3202.66 collect_output:109.47
2022-10-12 03:55:08 - train.py[line:549] - INFO: 8200 / 9351
2022-10-12 03:55:08 - train.py[line:551] - INFO: load:1.78 valid_run:3439.33 task_valid:3283.71 collect_output:110.97
2022-10-12 03:56:32 - train.py[line:549] - INFO: 8400 / 9351
2022-10-12 03:56:32 - train.py[line:551] - INFO: load:1.80 valid_run:3522.98 task_valid:3364.76 collect_output:112.51
2022-10-12 03:57:56 - train.py[line:549] - INFO: 8600 / 9351
2022-10-12 03:57:56 - train.py[line:551] - INFO: load:1.82 valid_run:3607.02 task_valid:3445.12 collect_output:115.12
2022-10-12 03:59:20 - train.py[line:549] - INFO: 8800 / 9351
2022-10-12 03:59:20 - train.py[line:551] - INFO: load:1.85 valid_run:3690.70 task_valid:3524.71 collect_output:118.14
2022-10-12 04:00:44 - train.py[line:549] - INFO: 9000 / 9351
2022-10-12 04:00:44 - train.py[line:551] - INFO: load:1.87 valid_run:3775.08 task_valid:3607.01 collect_output:119.13
2022-10-12 04:02:08 - train.py[line:549] - INFO: 9200 / 9351
2022-10-12 04:02:08 - train.py[line:551] - INFO: load:1.89 valid_run:3858.72 task_valid:3688.29 collect_output:120.39

====================================================================================================
SGG eval:     R @ 50: 0.6789;     R @ 100: 0.6999;     R @ 500: 0.7247;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4823;    mR @ 100: 0.5008;    mR @ 500: 0.5603;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.8125) (covering:0.2286) (eating:0.8235) (flying in:0.5909) (growing on:0.5000) (hanging from:0.4032) (lying on:0.5000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9500) (says:0.0000) (sitting on:0.7517) (standing on:0.4343) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6789;     R @ 100: 0.6999;     R @ 500: 0.7247;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4823;    mR @ 100: 0.5008;    mR @ 500: 0.5603;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.8125) (covering:0.2286) (eating:0.8235) (flying in:0.5909) (growing on:0.5000) (hanging from:0.4032) (lying on:0.5000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9500) (says:0.0000) (sitting on:0.7517) (standing on:0.4343) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-12 04:03:22 - train.py[line:487] - INFO: 0.6999104150751209
2022-10-12 04:03:22 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 04:03:22 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.334 | loss_v1 0 | loss_v2 0 | nll_loss 0.18 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.69991 | ppl 1.13 | vqa_score 0.5642 | wps 114 | wpb 48 | bsz 16 | num_updates 6000 | best_R@100 0.69991
2022-10-12 04:03:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-10-12 04:03:22 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-12 04:03:28 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-12 04:03:34 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6999104150751209) (writing took 11.643592796754092 seconds)
2022-10-12 04:03:46 - progress_bar.py[line:274] - INFO: epoch 001:   6018 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=0.3, ups=0, wpb=110.7, bsz=40, num_updates=6010, lr=5.19716e-06, gnorm=1.27, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=37683
2022-10-12 04:03:57 - progress_bar.py[line:274] - INFO: epoch 001:   6028 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.8, ups=0.87, wpb=109.4, bsz=40, num_updates=6020, lr=5.20581e-06, gnorm=1.166, clip=100, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=37694
2022-10-12 04:04:09 - progress_bar.py[line:274] - INFO: epoch 001:   6038 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.82, wpb=110.4, bsz=40, num_updates=6030, lr=5.21446e-06, gnorm=1.28, clip=90, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=37706
2022-10-12 04:04:21 - progress_bar.py[line:274] - INFO: epoch 001:   6048 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.2, ups=0.85, wpb=111.6, bsz=40, num_updates=6040, lr=5.22311e-06, gnorm=1.129, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=37718
2022-10-12 04:04:33 - progress_bar.py[line:274] - INFO: epoch 001:   6058 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.85, wpb=109.6, bsz=40, num_updates=6050, lr=5.23175e-06, gnorm=1.101, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=37730
2022-10-12 04:04:45 - progress_bar.py[line:274] - INFO: epoch 001:   6068 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.3, ups=0.83, wpb=110, bsz=40, num_updates=6060, lr=5.2404e-06, gnorm=1.076, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=37742
2022-10-12 04:04:57 - progress_bar.py[line:274] - INFO: epoch 001:   6078 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.82, wpb=109.2, bsz=40, num_updates=6070, lr=5.24905e-06, gnorm=1.183, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=37754
2022-10-12 04:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   6088 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.3, ups=0.85, wpb=111.6, bsz=40, num_updates=6080, lr=5.2577e-06, gnorm=1.026, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=37766
2022-10-12 04:05:21 - progress_bar.py[line:274] - INFO: epoch 001:   6098 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.84, wpb=110.6, bsz=40, num_updates=6090, lr=5.26634e-06, gnorm=1.084, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=37778
2022-10-12 04:05:33 - progress_bar.py[line:274] - INFO: epoch 001:   6108 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.4, ups=0.85, wpb=111, bsz=40, num_updates=6100, lr=5.27499e-06, gnorm=1.046, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=37789
2022-10-12 04:05:44 - progress_bar.py[line:274] - INFO: epoch 001:   6118 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.8, ups=0.86, wpb=109.4, bsz=40, num_updates=6110, lr=5.28364e-06, gnorm=1.218, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=37801
2022-10-12 04:05:56 - progress_bar.py[line:274] - INFO: epoch 001:   6128 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.9, ups=0.84, wpb=110.4, bsz=40, num_updates=6120, lr=5.29229e-06, gnorm=1.227, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=37813
2022-10-12 04:06:08 - progress_bar.py[line:274] - INFO: epoch 001:   6138 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.5, ups=0.85, wpb=111.2, bsz=40, num_updates=6130, lr=5.30093e-06, gnorm=1.001, clip=40, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=37825
2022-10-12 04:06:20 - progress_bar.py[line:274] - INFO: epoch 001:   6148 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.5, ups=0.85, wpb=111, bsz=40, num_updates=6140, lr=5.30958e-06, gnorm=1.089, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=37836
2022-10-12 04:06:31 - progress_bar.py[line:274] - INFO: epoch 001:   6158 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.3, ups=0.85, wpb=110.8, bsz=40, num_updates=6150, lr=5.31823e-06, gnorm=1.087, clip=60, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=37848
2022-10-12 04:06:43 - progress_bar.py[line:274] - INFO: epoch 001:   6168 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.7, ups=0.86, wpb=110.8, bsz=40, num_updates=6160, lr=5.32688e-06, gnorm=1.096, clip=50, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=37860
2022-10-12 04:06:55 - progress_bar.py[line:274] - INFO: epoch 001:   6178 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.84, wpb=110.4, bsz=40, num_updates=6170, lr=5.33552e-06, gnorm=1.149, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=37872
2022-10-12 04:07:07 - progress_bar.py[line:274] - INFO: epoch 001:   6188 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.2, ups=0.86, wpb=110.1, bsz=40, num_updates=6180, lr=5.34417e-06, gnorm=1.157, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=37883
2022-10-12 04:07:19 - progress_bar.py[line:274] - INFO: epoch 001:   6198 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.84, wpb=109.2, bsz=40, num_updates=6190, lr=5.35282e-06, gnorm=1.141, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=37895
2022-10-12 04:07:30 - progress_bar.py[line:274] - INFO: epoch 001:   6208 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.1, ups=0.84, wpb=110.5, bsz=40, num_updates=6200, lr=5.36147e-06, gnorm=1.094, clip=50, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=37907
2022-10-12 04:07:42 - progress_bar.py[line:274] - INFO: epoch 001:   6218 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.83, wpb=110.1, bsz=40, num_updates=6210, lr=5.37011e-06, gnorm=1.144, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=37919
2022-10-12 04:07:54 - progress_bar.py[line:274] - INFO: epoch 001:   6228 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.7, ups=0.87, wpb=110.6, bsz=40, num_updates=6220, lr=5.37876e-06, gnorm=1.034, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=37931
2022-10-12 04:08:06 - progress_bar.py[line:274] - INFO: epoch 001:   6238 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.84, wpb=109.3, bsz=40, num_updates=6230, lr=5.38741e-06, gnorm=1.152, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=37943
2022-10-12 04:08:18 - progress_bar.py[line:274] - INFO: epoch 001:   6248 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.1, ups=0.84, wpb=109.8, bsz=40, num_updates=6240, lr=5.39606e-06, gnorm=1.214, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=37955
2022-10-12 04:08:30 - progress_bar.py[line:274] - INFO: epoch 001:   6258 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.84, wpb=109.5, bsz=40, num_updates=6250, lr=5.4047e-06, gnorm=1.202, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=37967
2022-10-12 04:08:42 - progress_bar.py[line:274] - INFO: epoch 001:   6268 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.82, wpb=109.4, bsz=40, num_updates=6260, lr=5.41335e-06, gnorm=1.181, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=37979
2022-10-12 04:08:54 - progress_bar.py[line:274] - INFO: epoch 001:   6278 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.4, ups=0.86, wpb=111.2, bsz=40, num_updates=6270, lr=5.422e-06, gnorm=1.203, clip=100, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=37990
2022-10-12 04:09:05 - progress_bar.py[line:274] - INFO: epoch 001:   6288 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.3, ups=0.85, wpb=110.4, bsz=40, num_updates=6280, lr=5.43065e-06, gnorm=1.166, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38002
2022-10-12 04:09:17 - progress_bar.py[line:274] - INFO: epoch 001:   6298 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.83, wpb=109.5, bsz=40, num_updates=6290, lr=5.43929e-06, gnorm=1.062, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38014
2022-10-12 04:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   6308 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.83, wpb=109.4, bsz=40, num_updates=6300, lr=5.44794e-06, gnorm=1.12, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38026
2022-10-12 04:09:41 - progress_bar.py[line:274] - INFO: epoch 001:   6318 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.7, ups=0.87, wpb=109.7, bsz=40, num_updates=6310, lr=5.45659e-06, gnorm=1.157, clip=100, loss_scale=512, train_wall=11, gb_free=22.9, ema_decay=0.9999, wall=38038
2022-10-12 04:09:53 - progress_bar.py[line:274] - INFO: epoch 001:   6328 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.8, ups=0.86, wpb=110.3, bsz=40, num_updates=6320, lr=5.46524e-06, gnorm=1.108, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38049
2022-10-12 04:10:04 - progress_bar.py[line:274] - INFO: epoch 001:   6338 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.7, ups=0.86, wpb=110.4, bsz=40, num_updates=6330, lr=5.47388e-06, gnorm=1.135, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38061
2022-10-12 04:10:16 - progress_bar.py[line:274] - INFO: epoch 001:   6348 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.84, wpb=110.5, bsz=40, num_updates=6340, lr=5.48253e-06, gnorm=1.217, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38073
2022-10-12 04:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   6358 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.7, ups=0.87, wpb=109.1, bsz=40, num_updates=6350, lr=5.49118e-06, gnorm=1.244, clip=90, loss_scale=512, train_wall=11, gb_free=22.5, ema_decay=0.9999, wall=38084
2022-10-12 04:10:40 - progress_bar.py[line:274] - INFO: epoch 001:   6368 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.85, wpb=109.3, bsz=40, num_updates=6360, lr=5.49983e-06, gnorm=1.131, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38096
2022-10-12 04:10:51 - progress_bar.py[line:274] - INFO: epoch 001:   6378 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.5, ups=0.84, wpb=110.7, bsz=40, num_updates=6370, lr=5.50847e-06, gnorm=1.11, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=38108
2022-10-12 04:11:03 - progress_bar.py[line:274] - INFO: epoch 001:   6388 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.84, wpb=109.6, bsz=40, num_updates=6380, lr=5.51712e-06, gnorm=1.204, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=38120
2022-10-12 04:11:15 - progress_bar.py[line:274] - INFO: epoch 001:   6398 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.9, ups=0.87, wpb=110.4, bsz=40, num_updates=6390, lr=5.52577e-06, gnorm=1.066, clip=80, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=38132
2022-10-12 04:11:27 - progress_bar.py[line:274] - INFO: epoch 001:   6408 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.9, ups=0.85, wpb=111.1, bsz=40, num_updates=6400, lr=5.53442e-06, gnorm=1.226, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38143
2022-10-12 04:11:38 - progress_bar.py[line:274] - INFO: epoch 001:   6418 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=6410, lr=5.54306e-06, gnorm=1.12, clip=80, loss_scale=512, train_wall=11, gb_free=23.1, ema_decay=0.9999, wall=38155
2022-10-12 04:11:50 - progress_bar.py[line:274] - INFO: epoch 001:   6428 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.6, ups=0.84, wpb=111.1, bsz=40, num_updates=6420, lr=5.55171e-06, gnorm=1.051, clip=60, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38167
2022-10-12 04:12:02 - progress_bar.py[line:274] - INFO: epoch 001:   6438 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.2, ups=0.86, wpb=109.7, bsz=40, num_updates=6430, lr=5.56036e-06, gnorm=1.185, clip=80, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=38178
2022-10-12 04:12:13 - progress_bar.py[line:274] - INFO: epoch 001:   6448 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.5, ups=0.86, wpb=110.9, bsz=40, num_updates=6440, lr=5.56901e-06, gnorm=1.151, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38190
2022-10-12 04:12:25 - progress_bar.py[line:274] - INFO: epoch 001:   6458 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.84, wpb=108.5, bsz=40, num_updates=6450, lr=5.57765e-06, gnorm=1.176, clip=90, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=38202
2022-10-12 04:12:37 - progress_bar.py[line:274] - INFO: epoch 001:   6468 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.83, wpb=111.8, bsz=40, num_updates=6460, lr=5.5863e-06, gnorm=1.138, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38214
2022-10-12 04:12:49 - progress_bar.py[line:274] - INFO: epoch 001:   6478 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.1, ups=0.84, wpb=110, bsz=40, num_updates=6470, lr=5.59495e-06, gnorm=1.047, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38226
2022-10-12 04:13:01 - progress_bar.py[line:274] - INFO: epoch 001:   6488 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.2, ups=0.85, wpb=111.4, bsz=40, num_updates=6480, lr=5.6036e-06, gnorm=1.097, clip=70, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=38238
2022-10-12 04:13:12 - progress_bar.py[line:274] - INFO: epoch 001:   6498 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.8, ups=0.87, wpb=109.8, bsz=40, num_updates=6490, lr=5.61224e-06, gnorm=1.161, clip=80, loss_scale=1024, train_wall=11, gb_free=23, ema_decay=0.9999, wall=38249
2022-10-12 04:13:24 - progress_bar.py[line:274] - INFO: epoch 001:   6508 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.3, ups=0.86, wpb=110.2, bsz=40, num_updates=6500, lr=5.62089e-06, gnorm=1.11, clip=90, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38261
2022-10-12 04:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   6518 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.5, ups=0.83, wpb=110.9, bsz=40, num_updates=6510, lr=5.62954e-06, gnorm=1.106, clip=70, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=38273
2022-10-12 04:13:38 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 04:13:49 - progress_bar.py[line:274] - INFO: epoch 001:   6529 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.8, ups=0.78, wpb=110.1, bsz=40, num_updates=6520, lr=5.63819e-06, gnorm=1.179, clip=100, loss_scale=512, train_wall=13, gb_free=22.8, ema_decay=0.9999, wall=38286
2022-10-12 04:14:01 - progress_bar.py[line:274] - INFO: epoch 001:   6539 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.9, ups=0.85, wpb=110, bsz=40, num_updates=6530, lr=5.64684e-06, gnorm=1.096, clip=70, loss_scale=512, train_wall=12, gb_free=23.2, ema_decay=0.9999, wall=38297
2022-10-12 04:14:13 - progress_bar.py[line:274] - INFO: epoch 001:   6549 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.4, ups=0.84, wpb=109.4, bsz=40, num_updates=6540, lr=5.65548e-06, gnorm=1.156, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38309
2022-10-12 04:14:25 - progress_bar.py[line:274] - INFO: epoch 001:   6559 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.7, ups=0.84, wpb=110.6, bsz=40, num_updates=6550, lr=5.66413e-06, gnorm=1.077, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38321
2022-10-12 04:14:36 - progress_bar.py[line:274] - INFO: epoch 001:   6569 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.84, wpb=109.4, bsz=40, num_updates=6560, lr=5.67278e-06, gnorm=1.218, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38333
2022-10-12 04:14:48 - progress_bar.py[line:274] - INFO: epoch 001:   6579 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.84, wpb=110.3, bsz=40, num_updates=6570, lr=5.68143e-06, gnorm=1.124, clip=70, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=38345
2022-10-12 04:15:00 - progress_bar.py[line:274] - INFO: epoch 001:   6589 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.2, ups=0.85, wpb=110, bsz=40, num_updates=6580, lr=5.69007e-06, gnorm=1.1, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38357
2022-10-12 04:15:12 - progress_bar.py[line:274] - INFO: epoch 001:   6599 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92, ups=0.84, wpb=109.2, bsz=40, num_updates=6590, lr=5.69872e-06, gnorm=1.191, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38369
2022-10-12 04:15:24 - progress_bar.py[line:274] - INFO: epoch 001:   6609 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.9, ups=0.87, wpb=110.7, bsz=40, num_updates=6600, lr=5.70737e-06, gnorm=1.107, clip=70, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=38380
2022-10-12 04:15:36 - progress_bar.py[line:274] - INFO: epoch 001:   6619 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.4, ups=0.84, wpb=110.6, bsz=40, num_updates=6610, lr=5.71602e-06, gnorm=1.118, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38392
2022-10-12 04:15:47 - progress_bar.py[line:274] - INFO: epoch 001:   6629 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.6, ups=0.86, wpb=110.6, bsz=40, num_updates=6620, lr=5.72466e-06, gnorm=1.185, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38404
2022-10-12 04:15:59 - progress_bar.py[line:274] - INFO: epoch 001:   6639 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.84, wpb=108.9, bsz=40, num_updates=6630, lr=5.73331e-06, gnorm=1.21, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38416
2022-10-12 04:16:11 - progress_bar.py[line:274] - INFO: epoch 001:   6649 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.83, wpb=110.5, bsz=40, num_updates=6640, lr=5.74196e-06, gnorm=1.178, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38428
2022-10-12 04:16:23 - progress_bar.py[line:274] - INFO: epoch 001:   6659 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.6, ups=0.86, wpb=109.9, bsz=40, num_updates=6650, lr=5.75061e-06, gnorm=1.141, clip=70, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=38440
2022-10-12 04:16:35 - progress_bar.py[line:274] - INFO: epoch 001:   6669 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.1, ups=0.85, wpb=109.4, bsz=40, num_updates=6660, lr=5.75925e-06, gnorm=1.116, clip=70, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=38451
2022-10-12 04:16:46 - progress_bar.py[line:274] - INFO: epoch 001:   6679 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.5, ups=0.85, wpb=110.5, bsz=40, num_updates=6670, lr=5.7679e-06, gnorm=1.187, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38463
2022-10-12 04:16:58 - progress_bar.py[line:274] - INFO: epoch 001:   6689 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.4, ups=0.86, wpb=111.1, bsz=40, num_updates=6680, lr=5.77655e-06, gnorm=1.108, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=38475
2022-10-12 04:17:10 - progress_bar.py[line:274] - INFO: epoch 001:   6699 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.84, wpb=108.7, bsz=40, num_updates=6690, lr=5.7852e-06, gnorm=1.266, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=38487
2022-10-12 04:17:22 - progress_bar.py[line:274] - INFO: epoch 001:   6709 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.8, ups=0.83, wpb=110.8, bsz=40, num_updates=6700, lr=5.79384e-06, gnorm=1.221, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38499
2022-10-12 04:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   6719 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.7, ups=0.82, wpb=110.1, bsz=40, num_updates=6710, lr=5.80249e-06, gnorm=1.179, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38511
2022-10-12 04:17:46 - progress_bar.py[line:274] - INFO: epoch 001:   6729 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.84, wpb=110.9, bsz=40, num_updates=6720, lr=5.81114e-06, gnorm=1.013, clip=30, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38523
2022-10-12 04:17:58 - progress_bar.py[line:274] - INFO: epoch 001:   6739 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.5, ups=0.84, wpb=109.7, bsz=40, num_updates=6730, lr=5.81979e-06, gnorm=1.116, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38535
2022-10-12 04:18:10 - progress_bar.py[line:274] - INFO: epoch 001:   6749 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.3, ups=0.85, wpb=110, bsz=40, num_updates=6740, lr=5.82843e-06, gnorm=1.247, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38547
2022-10-12 04:18:21 - progress_bar.py[line:274] - INFO: epoch 001:   6759 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.4, ups=0.86, wpb=110.4, bsz=40, num_updates=6750, lr=5.83708e-06, gnorm=1.277, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38558
2022-10-12 04:18:33 - progress_bar.py[line:274] - INFO: epoch 001:   6769 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.4, ups=0.87, wpb=110.3, bsz=40, num_updates=6760, lr=5.84573e-06, gnorm=1.039, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38570
2022-10-12 04:18:45 - progress_bar.py[line:274] - INFO: epoch 001:   6779 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.84, wpb=110.2, bsz=40, num_updates=6770, lr=5.85438e-06, gnorm=1.158, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38582
2022-10-12 04:18:57 - progress_bar.py[line:274] - INFO: epoch 001:   6789 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.85, wpb=108.5, bsz=40, num_updates=6780, lr=5.86302e-06, gnorm=1.197, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=38594
2022-10-12 04:19:08 - progress_bar.py[line:274] - INFO: epoch 001:   6799 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.9, ups=0.86, wpb=110, bsz=40, num_updates=6790, lr=5.87167e-06, gnorm=1.178, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=38605
2022-10-12 04:19:20 - progress_bar.py[line:274] - INFO: epoch 001:   6809 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.1, ups=0.84, wpb=110.2, bsz=40, num_updates=6800, lr=5.88032e-06, gnorm=1.255, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38617
2022-10-12 04:19:32 - progress_bar.py[line:274] - INFO: epoch 001:   6819 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.1, ups=0.85, wpb=110.2, bsz=40, num_updates=6810, lr=5.88897e-06, gnorm=1.107, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=38629
2022-10-12 04:19:44 - progress_bar.py[line:274] - INFO: epoch 001:   6829 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.85, wpb=108.9, bsz=40, num_updates=6820, lr=5.89761e-06, gnorm=1.185, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38641
2022-10-12 04:19:56 - progress_bar.py[line:274] - INFO: epoch 001:   6839 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.84, wpb=109.8, bsz=40, num_updates=6830, lr=5.90626e-06, gnorm=1.06, clip=50, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=38652
2022-10-12 04:20:08 - progress_bar.py[line:274] - INFO: epoch 001:   6849 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.84, wpb=110, bsz=40, num_updates=6840, lr=5.91491e-06, gnorm=1.171, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38664
2022-10-12 04:20:19 - progress_bar.py[line:274] - INFO: epoch 001:   6859 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.6, ups=0.87, wpb=110.3, bsz=40, num_updates=6850, lr=5.92356e-06, gnorm=1.145, clip=90, loss_scale=512, train_wall=11, gb_free=22.9, ema_decay=0.9999, wall=38676
2022-10-12 04:20:31 - progress_bar.py[line:274] - INFO: epoch 001:   6869 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.4, ups=0.83, wpb=110.8, bsz=40, num_updates=6860, lr=5.9322e-06, gnorm=1.184, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=38688
2022-10-12 04:20:43 - progress_bar.py[line:274] - INFO: epoch 001:   6879 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.5, ups=0.86, wpb=110.1, bsz=40, num_updates=6870, lr=5.94085e-06, gnorm=1.104, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38700
2022-10-12 04:20:55 - progress_bar.py[line:274] - INFO: epoch 001:   6889 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.2, ups=0.84, wpb=111.3, bsz=40, num_updates=6880, lr=5.9495e-06, gnorm=1.169, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=38712
2022-10-12 04:21:07 - progress_bar.py[line:274] - INFO: epoch 001:   6899 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.1, ups=0.85, wpb=110.8, bsz=40, num_updates=6890, lr=5.95815e-06, gnorm=1.116, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=38723
2022-10-12 04:21:18 - progress_bar.py[line:274] - INFO: epoch 001:   6909 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.6, ups=0.84, wpb=109.9, bsz=40, num_updates=6900, lr=5.96679e-06, gnorm=1.184, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=38735
2022-10-12 04:21:30 - progress_bar.py[line:274] - INFO: epoch 001:   6919 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.7, ups=0.86, wpb=110.4, bsz=40, num_updates=6910, lr=5.97544e-06, gnorm=1.294, clip=100, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=38747
2022-10-12 04:21:42 - progress_bar.py[line:274] - INFO: epoch 001:   6929 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.2, ups=0.86, wpb=110.4, bsz=40, num_updates=6920, lr=5.98409e-06, gnorm=1.181, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=38758
2022-10-12 04:21:53 - progress_bar.py[line:274] - INFO: epoch 001:   6939 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.3, ups=0.85, wpb=110.8, bsz=40, num_updates=6930, lr=5.99274e-06, gnorm=1.088, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=38770
2022-10-12 04:22:05 - progress_bar.py[line:274] - INFO: epoch 001:   6949 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94, ups=0.85, wpb=110.6, bsz=40, num_updates=6940, lr=6.00138e-06, gnorm=1.057, clip=50, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=38782
2022-10-12 04:22:17 - progress_bar.py[line:274] - INFO: epoch 001:   6959 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.4, ups=0.83, wpb=110.4, bsz=40, num_updates=6950, lr=6.01003e-06, gnorm=1.09, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38794
2022-10-12 04:22:29 - progress_bar.py[line:274] - INFO: epoch 001:   6969 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.3, ups=0.84, wpb=111.9, bsz=40, num_updates=6960, lr=6.01868e-06, gnorm=1.022, clip=50, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=38806
2022-10-12 04:22:41 - progress_bar.py[line:274] - INFO: epoch 001:   6979 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.9, ups=0.87, wpb=110.8, bsz=40, num_updates=6970, lr=6.02733e-06, gnorm=1.087, clip=80, loss_scale=512, train_wall=11, gb_free=22.6, ema_decay=0.9999, wall=38817
2022-10-12 04:22:52 - progress_bar.py[line:274] - INFO: epoch 001:   6989 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.4, ups=0.85, wpb=111.1, bsz=40, num_updates=6980, lr=6.03597e-06, gnorm=1.187, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38829
2022-10-12 04:23:04 - progress_bar.py[line:274] - INFO: epoch 001:   6999 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.6, ups=0.86, wpb=109.9, bsz=40, num_updates=6990, lr=6.04462e-06, gnorm=1.202, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=38841
2022-10-12 04:23:16 - progress_bar.py[line:274] - INFO: epoch 001:   7009 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.7, ups=0.87, wpb=111, bsz=40, num_updates=7000, lr=6.05327e-06, gnorm=1.018, clip=50, loss_scale=512, train_wall=11, gb_free=23, ema_decay=0.9999, wall=38852
2022-10-12 04:23:16 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 04:23:17 - train.py[line:549] - INFO: 0 / 9351
2022-10-12 04:23:17 - train.py[line:551] - INFO: load:0.82 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 04:24:41 - train.py[line:549] - INFO: 200 / 9351
2022-10-12 04:24:41 - train.py[line:551] - INFO: load:0.85 valid_run:84.13 task_valid:81.77 collect_output:1.24
2022-10-12 04:26:04 - train.py[line:549] - INFO: 400 / 9351
2022-10-12 04:26:04 - train.py[line:551] - INFO: load:0.87 valid_run:167.64 task_valid:162.92 collect_output:2.56
2022-10-12 04:27:26 - train.py[line:549] - INFO: 600 / 9351
2022-10-12 04:27:26 - train.py[line:551] - INFO: load:0.89 valid_run:249.58 task_valid:241.62 collect_output:4.74
2022-10-12 04:28:49 - train.py[line:549] - INFO: 800 / 9351
2022-10-12 04:28:49 - train.py[line:551] - INFO: load:0.91 valid_run:332.53 task_valid:320.18 collect_output:8.09
2022-10-12 04:30:13 - train.py[line:549] - INFO: 1000 / 9351
2022-10-12 04:30:13 - train.py[line:551] - INFO: load:0.93 valid_run:416.55 task_valid:399.51 collect_output:11.69
2022-10-12 04:31:37 - train.py[line:549] - INFO: 1200 / 9351
2022-10-12 04:31:37 - train.py[line:551] - INFO: load:0.96 valid_run:500.22 task_valid:478.50 collect_output:15.28
2022-10-12 04:33:00 - train.py[line:549] - INFO: 1400 / 9351
2022-10-12 04:33:00 - train.py[line:551] - INFO: load:0.98 valid_run:582.93 task_valid:558.45 collect_output:17.00
2022-10-12 04:34:23 - train.py[line:549] - INFO: 1600 / 9351
2022-10-12 04:34:23 - train.py[line:551] - INFO: load:1.00 valid_run:666.42 task_valid:640.01 collect_output:17.91
2022-10-12 04:35:48 - train.py[line:549] - INFO: 1800 / 9351
2022-10-12 04:35:48 - train.py[line:551] - INFO: load:1.02 valid_run:750.78 task_valid:720.60 collect_output:20.54
2022-10-12 04:37:13 - train.py[line:549] - INFO: 2000 / 9351
2022-10-12 04:37:13 - train.py[line:551] - INFO: load:1.05 valid_run:835.44 task_valid:801.53 collect_output:23.10
2022-10-12 04:38:37 - train.py[line:549] - INFO: 2200 / 9351
2022-10-12 04:38:37 - train.py[line:551] - INFO: load:1.07 valid_run:920.20 task_valid:881.87 collect_output:26.27
2022-10-12 04:40:02 - train.py[line:549] - INFO: 2400 / 9351
2022-10-12 04:40:02 - train.py[line:551] - INFO: load:1.09 valid_run:1004.54 task_valid:962.95 collect_output:28.39
2022-10-12 04:41:27 - train.py[line:549] - INFO: 2600 / 9351
2022-10-12 04:41:27 - train.py[line:551] - INFO: load:1.11 valid_run:1089.72 task_valid:1043.48 collect_output:31.84
2022-10-12 04:42:52 - train.py[line:549] - INFO: 2800 / 9351
2022-10-12 04:42:52 - train.py[line:551] - INFO: load:1.14 valid_run:1174.32 task_valid:1122.83 collect_output:35.91
2022-10-12 04:44:15 - train.py[line:549] - INFO: 3000 / 9351
2022-10-12 04:44:15 - train.py[line:551] - INFO: load:1.16 valid_run:1257.86 task_valid:1200.95 collect_output:40.07
2022-10-12 04:45:38 - train.py[line:549] - INFO: 3200 / 9351
2022-10-12 04:45:38 - train.py[line:551] - INFO: load:1.18 valid_run:1340.97 task_valid:1280.59 collect_output:42.34
2022-10-12 04:47:03 - train.py[line:549] - INFO: 3400 / 9351
2022-10-12 04:47:03 - train.py[line:551] - INFO: load:1.21 valid_run:1425.98 task_valid:1360.76 collect_output:46.05
2022-10-12 04:48:27 - train.py[line:549] - INFO: 3600 / 9351
2022-10-12 04:48:27 - train.py[line:551] - INFO: load:1.23 valid_run:1509.66 task_valid:1441.60 collect_output:47.73
2022-10-12 04:49:50 - train.py[line:549] - INFO: 3800 / 9351
2022-10-12 04:49:50 - train.py[line:551] - INFO: load:1.25 valid_run:1592.51 task_valid:1519.87 collect_output:51.07
2022-10-12 04:51:13 - train.py[line:549] - INFO: 4000 / 9351
2022-10-12 04:51:13 - train.py[line:551] - INFO: load:1.27 valid_run:1675.80 task_valid:1599.41 collect_output:53.59
2022-10-12 04:52:38 - train.py[line:549] - INFO: 4200 / 9351
2022-10-12 04:52:38 - train.py[line:551] - INFO: load:1.30 valid_run:1760.44 task_valid:1681.67 collect_output:54.69
2022-10-12 04:54:03 - train.py[line:549] - INFO: 4400 / 9351
2022-10-12 04:54:03 - train.py[line:551] - INFO: load:1.32 valid_run:1844.73 task_valid:1762.11 collect_output:57.32
2022-10-12 04:55:26 - train.py[line:549] - INFO: 4600 / 9351
2022-10-12 04:55:26 - train.py[line:551] - INFO: load:1.34 valid_run:1928.06 task_valid:1841.60 collect_output:59.95
2022-10-12 04:56:50 - train.py[line:549] - INFO: 4800 / 9351
2022-10-12 04:56:50 - train.py[line:551] - INFO: load:1.37 valid_run:2012.36 task_valid:1920.02 collect_output:64.73
2022-10-12 04:58:14 - train.py[line:549] - INFO: 5000 / 9351
2022-10-12 04:58:14 - train.py[line:551] - INFO: load:1.39 valid_run:2096.49 task_valid:2000.89 collect_output:66.95
2022-10-12 04:59:38 - train.py[line:549] - INFO: 5200 / 9351
2022-10-12 04:59:38 - train.py[line:551] - INFO: load:1.41 valid_run:2180.21 task_valid:2081.59 collect_output:68.91
2022-10-12 05:01:01 - train.py[line:549] - INFO: 5400 / 9351
2022-10-12 05:01:01 - train.py[line:551] - INFO: load:1.43 valid_run:2262.79 task_valid:2161.40 collect_output:70.64
2022-10-12 05:02:25 - train.py[line:549] - INFO: 5600 / 9351
2022-10-12 05:02:25 - train.py[line:551] - INFO: load:1.46 valid_run:2346.52 task_valid:2242.31 collect_output:72.44
2022-10-12 05:03:48 - train.py[line:549] - INFO: 5800 / 9351
2022-10-12 05:03:48 - train.py[line:551] - INFO: load:1.48 valid_run:2429.48 task_valid:2321.45 collect_output:75.19
2022-10-12 05:05:11 - train.py[line:549] - INFO: 6000 / 9351
2022-10-12 05:05:11 - train.py[line:551] - INFO: load:1.50 valid_run:2512.76 task_valid:2401.69 collect_output:77.15
2022-10-12 05:06:34 - train.py[line:549] - INFO: 6200 / 9351
2022-10-12 05:06:34 - train.py[line:551] - INFO: load:1.52 valid_run:2596.05 task_valid:2481.48 collect_output:79.59
2022-10-12 05:07:59 - train.py[line:549] - INFO: 6400 / 9351
2022-10-12 05:07:59 - train.py[line:551] - INFO: load:1.54 valid_run:2681.02 task_valid:2562.72 collect_output:82.26
2022-10-12 05:09:23 - train.py[line:549] - INFO: 6600 / 9351
2022-10-12 05:09:23 - train.py[line:551] - INFO: load:1.57 valid_run:2764.77 task_valid:2644.15 collect_output:83.49
2022-10-12 05:10:46 - train.py[line:549] - INFO: 6800 / 9351
2022-10-12 05:10:46 - train.py[line:551] - INFO: load:1.59 valid_run:2847.75 task_valid:2723.57 collect_output:86.04
2022-10-12 05:12:09 - train.py[line:549] - INFO: 7000 / 9351
2022-10-12 05:12:09 - train.py[line:551] - INFO: load:1.61 valid_run:2930.25 task_valid:2801.82 collect_output:89.24
2022-10-12 05:13:32 - train.py[line:549] - INFO: 7200 / 9351
2022-10-12 05:13:32 - train.py[line:551] - INFO: load:1.63 valid_run:3013.24 task_valid:2881.86 collect_output:91.12
2022-10-12 05:14:55 - train.py[line:549] - INFO: 7400 / 9351
2022-10-12 05:14:55 - train.py[line:551] - INFO: load:1.66 valid_run:3096.14 task_valid:2960.53 collect_output:94.33
2022-10-12 05:16:20 - train.py[line:549] - INFO: 7600 / 9351
2022-10-12 05:16:20 - train.py[line:551] - INFO: load:1.68 valid_run:3181.10 task_valid:3040.96 collect_output:97.79
2022-10-12 05:17:44 - train.py[line:549] - INFO: 7800 / 9351
2022-10-12 05:17:44 - train.py[line:551] - INFO: load:1.70 valid_run:3265.31 task_valid:3121.16 collect_output:100.73
2022-10-12 05:19:07 - train.py[line:549] - INFO: 8000 / 9351
2022-10-12 05:19:07 - train.py[line:551] - INFO: load:1.72 valid_run:3348.21 task_valid:3199.66 collect_output:104.06
2022-10-12 05:20:31 - train.py[line:549] - INFO: 8200 / 9351
2022-10-12 05:20:31 - train.py[line:551] - INFO: load:1.74 valid_run:3431.84 task_valid:3280.88 collect_output:105.41
2022-10-12 05:21:54 - train.py[line:549] - INFO: 8400 / 9351
2022-10-12 05:21:54 - train.py[line:551] - INFO: load:1.77 valid_run:3515.50 task_valid:3362.02 collect_output:106.87
2022-10-12 05:23:18 - train.py[line:549] - INFO: 8600 / 9351
2022-10-12 05:23:18 - train.py[line:551] - INFO: load:1.79 valid_run:3599.34 task_valid:3442.18 collect_output:109.48
2022-10-12 05:24:42 - train.py[line:549] - INFO: 8800 / 9351
2022-10-12 05:24:42 - train.py[line:551] - INFO: load:1.81 valid_run:3682.78 task_valid:3521.41 collect_output:112.63
2022-10-12 05:26:06 - train.py[line:549] - INFO: 9000 / 9351
2022-10-12 05:26:06 - train.py[line:551] - INFO: load:1.83 valid_run:3766.91 task_valid:3603.40 collect_output:113.72
2022-10-12 05:27:29 - train.py[line:549] - INFO: 9200 / 9351
2022-10-12 05:27:29 - train.py[line:551] - INFO: load:1.86 valid_run:3849.79 task_valid:3683.75 collect_output:115.23

====================================================================================================
SGG eval:     R @ 50: 0.6743;     R @ 100: 0.6936;     R @ 500: 0.7177;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4800;    mR @ 100: 0.4999;    mR @ 500: 0.5522;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.2286) (eating:0.8235) (flying in:0.6818) (growing on:0.5000) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9500) (says:0.0000) (sitting on:0.7585) (standing on:0.4093) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-12 05:28:43 - train.py[line:487] - INFO: 0.6936073847720906

====================================================================================================
SGG eval:     R @ 50: 0.6743;     R @ 100: 0.6936;     R @ 500: 0.7177;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4800;    mR @ 100: 0.4999;    mR @ 500: 0.5522;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.2286) (eating:0.8235) (flying in:0.6818) (growing on:0.5000) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9500) (says:0.0000) (sitting on:0.7585) (standing on:0.4093) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-12 05:28:43 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 05:28:43 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.327 | loss_v1 0 | loss_v2 0 | nll_loss 0.171 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.693607 | ppl 1.13 | vqa_score 0.5766 | wps 114.2 | wpb 48 | bsz 16 | num_updates 7000 | best_R@100 0.69991
2022-10-12 05:28:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 7000 updates
2022-10-12 05:28:43 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-12 05:28:49 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-12 05:28:52 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 0.6936073847720906) (writing took 8.622481777332723 seconds)
2022-10-12 05:29:04 - progress_bar.py[line:274] - INFO: epoch 001:   7019 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=0.3, ups=0, wpb=112, bsz=40, num_updates=7010, lr=6.06192e-06, gnorm=1.125, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=42801
2022-10-12 05:29:16 - progress_bar.py[line:274] - INFO: epoch 001:   7029 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.84, wpb=110.7, bsz=40, num_updates=7020, lr=6.07056e-06, gnorm=1.091, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=42813
2022-10-12 05:29:28 - progress_bar.py[line:274] - INFO: epoch 001:   7039 / 28910 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.84, wpb=107.9, bsz=40, num_updates=7030, lr=6.07921e-06, gnorm=1.16, clip=70, loss_scale=1024, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=42825
2022-10-12 05:29:40 - progress_bar.py[line:274] - INFO: epoch 001:   7049 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.84, wpb=110.7, bsz=40, num_updates=7040, lr=6.08786e-06, gnorm=1.125, clip=80, loss_scale=1024, train_wall=12, gb_free=22.5, ema_decay=0.9999, wall=42837
2022-10-12 05:29:52 - progress_bar.py[line:274] - INFO: epoch 001:   7059 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95, ups=0.85, wpb=111.3, bsz=40, num_updates=7050, lr=6.09651e-06, gnorm=1.192, clip=90, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=42848
2022-10-12 05:30:03 - progress_bar.py[line:274] - INFO: epoch 001:   7069 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.84, wpb=109.9, bsz=40, num_updates=7060, lr=6.10515e-06, gnorm=1.15, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=42860
2022-10-12 05:30:15 - progress_bar.py[line:274] - INFO: epoch 001:   7079 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=96, ups=0.86, wpb=112, bsz=40, num_updates=7070, lr=6.1138e-06, gnorm=1.11, clip=90, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=42872
2022-10-12 05:30:27 - progress_bar.py[line:274] - INFO: epoch 001:   7089 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.6, ups=0.85, wpb=111.3, bsz=40, num_updates=7080, lr=6.12245e-06, gnorm=1.076, clip=70, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=42884
2022-10-12 05:30:39 - progress_bar.py[line:274] - INFO: epoch 001:   7099 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.2, ups=0.84, wpb=110.9, bsz=40, num_updates=7090, lr=6.1311e-06, gnorm=1.068, clip=60, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=42896
2022-10-12 05:30:51 - progress_bar.py[line:274] - INFO: epoch 001:   7109 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.1, ups=0.84, wpb=109.1, bsz=40, num_updates=7100, lr=6.13974e-06, gnorm=1.139, clip=90, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=42907
2022-10-12 05:30:59 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 05:31:03 - progress_bar.py[line:274] - INFO: epoch 001:   7120 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=86.1, ups=0.78, wpb=110, bsz=40, num_updates=7110, lr=6.14839e-06, gnorm=1.089, clip=60, loss_scale=512, train_wall=13, gb_free=22.8, ema_decay=0.9999, wall=42920
2022-10-12 05:31:15 - progress_bar.py[line:274] - INFO: epoch 001:   7130 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.1, ups=0.84, wpb=110.2, bsz=40, num_updates=7120, lr=6.15704e-06, gnorm=1.139, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=42932
2022-10-12 05:31:27 - progress_bar.py[line:274] - INFO: epoch 001:   7140 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.5, ups=0.84, wpb=110, bsz=40, num_updates=7130, lr=6.16569e-06, gnorm=1.168, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=42944
2022-10-12 05:31:39 - progress_bar.py[line:274] - INFO: epoch 001:   7150 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.84, wpb=108.9, bsz=40, num_updates=7140, lr=6.17433e-06, gnorm=1.091, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=42956
2022-10-12 05:31:51 - progress_bar.py[line:274] - INFO: epoch 001:   7160 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.8, ups=0.85, wpb=111.4, bsz=40, num_updates=7150, lr=6.18298e-06, gnorm=1.202, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=42968
2022-10-12 05:32:03 - progress_bar.py[line:274] - INFO: epoch 001:   7170 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.5, ups=0.85, wpb=110, bsz=40, num_updates=7160, lr=6.19163e-06, gnorm=1.135, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=42979
2022-10-12 05:32:14 - progress_bar.py[line:274] - INFO: epoch 001:   7180 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.7, ups=0.87, wpb=111.1, bsz=40, num_updates=7170, lr=6.20028e-06, gnorm=1.066, clip=50, loss_scale=512, train_wall=11, gb_free=22.7, ema_decay=0.9999, wall=42991
2022-10-12 05:32:26 - progress_bar.py[line:274] - INFO: epoch 001:   7190 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.7, ups=0.84, wpb=111.4, bsz=40, num_updates=7180, lr=6.20892e-06, gnorm=1.152, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43003
2022-10-12 05:32:38 - progress_bar.py[line:274] - INFO: epoch 001:   7200 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.83, wpb=111.2, bsz=40, num_updates=7190, lr=6.21757e-06, gnorm=1.103, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43015
2022-10-12 05:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   7210 / 28910 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.3, ups=0.85, wpb=109.7, bsz=40, num_updates=7200, lr=6.22622e-06, gnorm=1.197, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43027
2022-10-12 05:33:02 - progress_bar.py[line:274] - INFO: epoch 001:   7220 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95, ups=0.86, wpb=111.1, bsz=40, num_updates=7210, lr=6.23487e-06, gnorm=1.221, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43038
2022-10-12 05:33:13 - progress_bar.py[line:274] - INFO: epoch 001:   7230 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.4, ups=0.84, wpb=110.7, bsz=40, num_updates=7220, lr=6.24351e-06, gnorm=1.121, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43050
2022-10-12 05:33:25 - progress_bar.py[line:274] - INFO: epoch 001:   7240 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.8, ups=0.84, wpb=109.2, bsz=40, num_updates=7230, lr=6.25216e-06, gnorm=1.023, clip=40, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43062
2022-10-12 05:33:37 - progress_bar.py[line:274] - INFO: epoch 001:   7250 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.3, ups=0.85, wpb=111.7, bsz=40, num_updates=7240, lr=6.26081e-06, gnorm=1.001, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43074
2022-10-12 05:33:49 - progress_bar.py[line:274] - INFO: epoch 001:   7260 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.2, ups=0.83, wpb=111.2, bsz=40, num_updates=7250, lr=6.26946e-06, gnorm=1.091, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43086
2022-10-12 05:34:01 - progress_bar.py[line:274] - INFO: epoch 001:   7270 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.8, ups=0.85, wpb=110.2, bsz=40, num_updates=7260, lr=6.2781e-06, gnorm=1.177, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43098
2022-10-12 05:34:13 - progress_bar.py[line:274] - INFO: epoch 001:   7280 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.9, ups=0.85, wpb=109.6, bsz=40, num_updates=7270, lr=6.28675e-06, gnorm=1.058, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43109
2022-10-12 05:34:25 - progress_bar.py[line:274] - INFO: epoch 001:   7290 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.85, wpb=109.2, bsz=40, num_updates=7280, lr=6.2954e-06, gnorm=1.124, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43121
2022-10-12 05:34:36 - progress_bar.py[line:274] - INFO: epoch 001:   7300 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.8, ups=0.84, wpb=110.2, bsz=40, num_updates=7290, lr=6.30405e-06, gnorm=1.021, clip=50, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=43133
2022-10-12 05:34:48 - progress_bar.py[line:274] - INFO: epoch 001:   7310 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.7, ups=0.84, wpb=110.4, bsz=40, num_updates=7300, lr=6.31269e-06, gnorm=1.09, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43145
2022-10-12 05:35:00 - progress_bar.py[line:274] - INFO: epoch 001:   7320 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.83, wpb=110.6, bsz=40, num_updates=7310, lr=6.32134e-06, gnorm=1.129, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43157
2022-10-12 05:35:12 - progress_bar.py[line:274] - INFO: epoch 001:   7330 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.1, ups=0.85, wpb=111.3, bsz=40, num_updates=7320, lr=6.32999e-06, gnorm=1.09, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43169
2022-10-12 05:35:24 - progress_bar.py[line:274] - INFO: epoch 001:   7340 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.7, ups=0.85, wpb=111.7, bsz=40, num_updates=7330, lr=6.33864e-06, gnorm=1.145, clip=80, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=43181
2022-10-12 05:35:36 - progress_bar.py[line:274] - INFO: epoch 001:   7350 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.9, ups=0.85, wpb=110.9, bsz=40, num_updates=7340, lr=6.34728e-06, gnorm=1.088, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43193
2022-10-12 05:35:47 - progress_bar.py[line:274] - INFO: epoch 001:   7360 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.9, ups=0.86, wpb=111.2, bsz=40, num_updates=7350, lr=6.35593e-06, gnorm=1.159, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43204
2022-10-12 05:35:59 - progress_bar.py[line:274] - INFO: epoch 001:   7370 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.9, ups=0.84, wpb=112.3, bsz=40, num_updates=7360, lr=6.36458e-06, gnorm=1.107, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43216
2022-10-12 05:36:11 - progress_bar.py[line:274] - INFO: epoch 001:   7380 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.83, wpb=111.7, bsz=40, num_updates=7370, lr=6.37323e-06, gnorm=1.084, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43228
2022-10-12 05:36:23 - progress_bar.py[line:274] - INFO: epoch 001:   7390 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.5, ups=0.84, wpb=109.9, bsz=40, num_updates=7380, lr=6.38187e-06, gnorm=1.113, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43240
2022-10-12 05:36:35 - progress_bar.py[line:274] - INFO: epoch 001:   7400 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.9, ups=0.83, wpb=110.8, bsz=40, num_updates=7390, lr=6.39052e-06, gnorm=1.127, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43252
2022-10-12 05:36:47 - progress_bar.py[line:274] - INFO: epoch 001:   7410 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.9, ups=0.85, wpb=110.9, bsz=40, num_updates=7400, lr=6.39917e-06, gnorm=1.128, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43264
2022-10-12 05:36:59 - progress_bar.py[line:274] - INFO: epoch 001:   7420 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.9, ups=0.85, wpb=110.7, bsz=40, num_updates=7410, lr=6.40782e-06, gnorm=1.096, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43276
2022-10-12 05:37:11 - progress_bar.py[line:274] - INFO: epoch 001:   7430 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.9, ups=0.85, wpb=109.9, bsz=40, num_updates=7420, lr=6.41646e-06, gnorm=1.103, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43288
2022-10-12 05:37:23 - progress_bar.py[line:274] - INFO: epoch 001:   7440 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.9, ups=0.83, wpb=110.6, bsz=40, num_updates=7430, lr=6.42511e-06, gnorm=1.05, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43300
2022-10-12 05:37:35 - progress_bar.py[line:274] - INFO: epoch 001:   7450 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.83, wpb=109.3, bsz=40, num_updates=7440, lr=6.43376e-06, gnorm=1.134, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43312
2022-10-12 05:37:48 - progress_bar.py[line:274] - INFO: epoch 001:   7460 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.5, ups=0.86, wpb=110.3, bsz=40, num_updates=7450, lr=6.44241e-06, gnorm=1.114, clip=80, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=43323
2022-10-12 05:37:59 - progress_bar.py[line:274] - INFO: epoch 001:   7470 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.3, ups=0.85, wpb=110.5, bsz=40, num_updates=7460, lr=6.45105e-06, gnorm=1.186, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43336
2022-10-12 05:38:11 - progress_bar.py[line:274] - INFO: epoch 001:   7480 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.9, ups=0.85, wpb=110.9, bsz=40, num_updates=7470, lr=6.4597e-06, gnorm=1.057, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43348
2022-10-12 05:38:23 - progress_bar.py[line:274] - INFO: epoch 001:   7490 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.83, wpb=110.9, bsz=40, num_updates=7480, lr=6.46835e-06, gnorm=1.06, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43360
2022-10-12 05:38:35 - progress_bar.py[line:274] - INFO: epoch 001:   7500 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.3, ups=0.86, wpb=110.9, bsz=40, num_updates=7490, lr=6.477e-06, gnorm=1.067, clip=60, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=43372
2022-10-12 05:38:47 - progress_bar.py[line:274] - INFO: epoch 001:   7510 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.3, ups=0.85, wpb=110, bsz=40, num_updates=7500, lr=6.48565e-06, gnorm=1.115, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43383
2022-10-12 05:38:59 - progress_bar.py[line:274] - INFO: epoch 001:   7520 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.84, wpb=109.8, bsz=40, num_updates=7510, lr=6.49429e-06, gnorm=1.206, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43395
2022-10-12 05:39:10 - progress_bar.py[line:274] - INFO: epoch 001:   7530 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.4, ups=0.85, wpb=109.5, bsz=40, num_updates=7520, lr=6.50294e-06, gnorm=1.106, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43407
2022-10-12 05:39:23 - progress_bar.py[line:274] - INFO: epoch 001:   7540 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92, ups=0.82, wpb=111.9, bsz=40, num_updates=7530, lr=6.51159e-06, gnorm=1.019, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43419
2022-10-12 05:39:34 - progress_bar.py[line:274] - INFO: epoch 001:   7550 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.6, ups=0.86, wpb=109.5, bsz=40, num_updates=7540, lr=6.52024e-06, gnorm=1.131, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43431
2022-10-12 05:39:46 - progress_bar.py[line:274] - INFO: epoch 001:   7560 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.83, wpb=108.7, bsz=40, num_updates=7550, lr=6.52888e-06, gnorm=1.164, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43443
2022-10-12 05:39:58 - progress_bar.py[line:274] - INFO: epoch 001:   7570 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.2, ups=0.85, wpb=110.8, bsz=40, num_updates=7560, lr=6.53753e-06, gnorm=1.059, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43455
2022-10-12 05:40:10 - progress_bar.py[line:274] - INFO: epoch 001:   7580 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.84, wpb=109.7, bsz=40, num_updates=7570, lr=6.54618e-06, gnorm=1.126, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43467
2022-10-12 05:40:22 - progress_bar.py[line:274] - INFO: epoch 001:   7590 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.7, ups=0.84, wpb=109.7, bsz=40, num_updates=7580, lr=6.55483e-06, gnorm=1, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43478
2022-10-12 05:40:34 - progress_bar.py[line:274] - INFO: epoch 001:   7600 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.84, wpb=109.9, bsz=40, num_updates=7590, lr=6.56347e-06, gnorm=1.183, clip=100, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=43490
2022-10-12 05:40:46 - progress_bar.py[line:274] - INFO: epoch 001:   7610 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.83, wpb=110.2, bsz=40, num_updates=7600, lr=6.57212e-06, gnorm=1.189, clip=80, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=43502
2022-10-12 05:40:57 - progress_bar.py[line:274] - INFO: epoch 001:   7620 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.9, ups=0.85, wpb=110.2, bsz=40, num_updates=7610, lr=6.58077e-06, gnorm=1.076, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43514
2022-10-12 05:41:09 - progress_bar.py[line:274] - INFO: epoch 001:   7630 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.84, wpb=109.9, bsz=40, num_updates=7620, lr=6.58942e-06, gnorm=1.121, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43526
2022-10-12 05:41:21 - progress_bar.py[line:274] - INFO: epoch 001:   7640 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.4, ups=0.85, wpb=111.5, bsz=40, num_updates=7630, lr=6.59806e-06, gnorm=1.099, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43538
2022-10-12 05:41:33 - progress_bar.py[line:274] - INFO: epoch 001:   7650 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.5, ups=0.84, wpb=111.9, bsz=40, num_updates=7640, lr=6.60671e-06, gnorm=1.069, clip=70, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43550
2022-10-12 05:41:45 - progress_bar.py[line:274] - INFO: epoch 001:   7660 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.5, ups=0.84, wpb=109.3, bsz=40, num_updates=7650, lr=6.61536e-06, gnorm=1.099, clip=70, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43562
2022-10-12 05:41:57 - progress_bar.py[line:274] - INFO: epoch 001:   7670 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.2, ups=0.85, wpb=111.6, bsz=40, num_updates=7660, lr=6.62401e-06, gnorm=0.983, clip=50, loss_scale=1024, train_wall=12, gb_free=22.5, ema_decay=0.9999, wall=43573
2022-10-12 05:42:08 - progress_bar.py[line:274] - INFO: epoch 001:   7680 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.7, ups=0.85, wpb=110.5, bsz=40, num_updates=7670, lr=6.63265e-06, gnorm=1.117, clip=60, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43585
2022-10-12 05:42:20 - progress_bar.py[line:274] - INFO: epoch 001:   7690 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.4, ups=0.84, wpb=109.7, bsz=40, num_updates=7680, lr=6.6413e-06, gnorm=1.118, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43597
2022-10-12 05:42:26 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 05:42:33 - progress_bar.py[line:274] - INFO: epoch 001:   7701 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=85.6, ups=0.78, wpb=110.3, bsz=40, num_updates=7690, lr=6.64995e-06, gnorm=1.17, clip=90, loss_scale=512, train_wall=13, gb_free=22.6, ema_decay=0.9999, wall=43610
2022-10-12 05:42:45 - progress_bar.py[line:274] - INFO: epoch 001:   7711 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.83, wpb=109.5, bsz=40, num_updates=7700, lr=6.6586e-06, gnorm=1.282, clip=100, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43622
2022-10-12 05:42:57 - progress_bar.py[line:274] - INFO: epoch 001:   7721 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.85, wpb=109.3, bsz=40, num_updates=7710, lr=6.66724e-06, gnorm=1.297, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43634
2022-10-12 05:43:09 - progress_bar.py[line:274] - INFO: epoch 001:   7731 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.8, ups=0.83, wpb=111.3, bsz=40, num_updates=7720, lr=6.67589e-06, gnorm=1.166, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43646
2022-10-12 05:43:21 - progress_bar.py[line:274] - INFO: epoch 001:   7741 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.4, ups=0.85, wpb=110.7, bsz=40, num_updates=7730, lr=6.68454e-06, gnorm=1.133, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43657
2022-10-12 05:43:33 - progress_bar.py[line:274] - INFO: epoch 001:   7751 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.8, ups=0.84, wpb=110, bsz=40, num_updates=7740, lr=6.69319e-06, gnorm=1.101, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43669
2022-10-12 05:43:44 - progress_bar.py[line:274] - INFO: epoch 001:   7761 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.4, ups=0.87, wpb=111.9, bsz=40, num_updates=7750, lr=6.70183e-06, gnorm=1.12, clip=80, loss_scale=512, train_wall=11, gb_free=22.9, ema_decay=0.9999, wall=43681
2022-10-12 05:43:56 - progress_bar.py[line:274] - INFO: epoch 001:   7771 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.7, ups=0.86, wpb=111.8, bsz=40, num_updates=7760, lr=6.71048e-06, gnorm=1.097, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43692
2022-10-12 05:44:08 - progress_bar.py[line:274] - INFO: epoch 001:   7781 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.84, wpb=108.4, bsz=40, num_updates=7770, lr=6.71913e-06, gnorm=1.221, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43704
2022-10-12 05:44:19 - progress_bar.py[line:274] - INFO: epoch 001:   7791 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.2, ups=0.86, wpb=109.8, bsz=40, num_updates=7780, lr=6.72778e-06, gnorm=1.185, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43716
2022-10-12 05:44:31 - progress_bar.py[line:274] - INFO: epoch 001:   7801 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.6, ups=0.84, wpb=111, bsz=40, num_updates=7790, lr=6.73642e-06, gnorm=1.027, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43728
2022-10-12 05:44:43 - progress_bar.py[line:274] - INFO: epoch 001:   7811 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.83, wpb=110.2, bsz=40, num_updates=7800, lr=6.74507e-06, gnorm=1.215, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43740
2022-10-12 05:44:55 - progress_bar.py[line:274] - INFO: epoch 001:   7821 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.4, ups=0.84, wpb=111, bsz=40, num_updates=7810, lr=6.75372e-06, gnorm=1.113, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=43752
2022-10-12 05:45:07 - progress_bar.py[line:274] - INFO: epoch 001:   7831 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94, ups=0.84, wpb=112, bsz=40, num_updates=7820, lr=6.76237e-06, gnorm=1.134, clip=90, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=43764
2022-10-12 05:45:19 - progress_bar.py[line:274] - INFO: epoch 001:   7841 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.4, ups=0.85, wpb=110.1, bsz=40, num_updates=7830, lr=6.77101e-06, gnorm=1.137, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43776
2022-10-12 05:45:31 - progress_bar.py[line:274] - INFO: epoch 001:   7851 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.6, ups=0.83, wpb=109.8, bsz=40, num_updates=7840, lr=6.77966e-06, gnorm=1.135, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43788
2022-10-12 05:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   7861 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.9, ups=0.84, wpb=110, bsz=40, num_updates=7850, lr=6.78831e-06, gnorm=1.25, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43800
2022-10-12 05:45:55 - progress_bar.py[line:274] - INFO: epoch 001:   7871 / 28910 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.5, ups=0.85, wpb=109.1, bsz=40, num_updates=7860, lr=6.79696e-06, gnorm=1.198, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43811
2022-10-12 05:46:06 - progress_bar.py[line:274] - INFO: epoch 001:   7881 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.85, wpb=108.7, bsz=40, num_updates=7870, lr=6.8056e-06, gnorm=1.17, clip=100, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43823
2022-10-12 05:46:18 - progress_bar.py[line:274] - INFO: epoch 001:   7891 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95, ups=0.86, wpb=110.1, bsz=40, num_updates=7880, lr=6.81425e-06, gnorm=1.043, clip=40, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43835
2022-10-12 05:46:30 - progress_bar.py[line:274] - INFO: epoch 001:   7901 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.7, ups=0.84, wpb=111.6, bsz=40, num_updates=7890, lr=6.8229e-06, gnorm=1.076, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43847
2022-10-12 05:46:42 - progress_bar.py[line:274] - INFO: epoch 001:   7911 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.6, ups=0.85, wpb=109.7, bsz=40, num_updates=7900, lr=6.83155e-06, gnorm=1.149, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43858
2022-10-12 05:46:54 - progress_bar.py[line:274] - INFO: epoch 001:   7921 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.2, ups=0.84, wpb=111.1, bsz=40, num_updates=7910, lr=6.84019e-06, gnorm=1.103, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43870
2022-10-12 05:47:06 - progress_bar.py[line:274] - INFO: epoch 001:   7931 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.9, ups=0.84, wpb=110.9, bsz=40, num_updates=7920, lr=6.84884e-06, gnorm=1.13, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43882
2022-10-12 05:47:18 - progress_bar.py[line:274] - INFO: epoch 001:   7941 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.83, wpb=110.3, bsz=40, num_updates=7930, lr=6.85749e-06, gnorm=1.197, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43894
2022-10-12 05:47:30 - progress_bar.py[line:274] - INFO: epoch 001:   7951 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.7, ups=0.83, wpb=110, bsz=40, num_updates=7940, lr=6.86614e-06, gnorm=1.139, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43906
2022-10-12 05:47:41 - progress_bar.py[line:274] - INFO: epoch 001:   7961 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.84, wpb=109.3, bsz=40, num_updates=7950, lr=6.87478e-06, gnorm=1.179, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43918
2022-10-12 05:47:54 - progress_bar.py[line:274] - INFO: epoch 001:   7971 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.83, wpb=110.7, bsz=40, num_updates=7960, lr=6.88343e-06, gnorm=1.17, clip=100, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=43930
2022-10-12 05:48:05 - progress_bar.py[line:274] - INFO: epoch 001:   7981 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.7, ups=0.86, wpb=111.5, bsz=40, num_updates=7970, lr=6.89208e-06, gnorm=1.032, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43942
2022-10-12 05:48:17 - progress_bar.py[line:274] - INFO: epoch 001:   7991 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.2, ups=0.85, wpb=110.7, bsz=40, num_updates=7980, lr=6.90073e-06, gnorm=1.153, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=43954
2022-10-12 05:48:29 - progress_bar.py[line:274] - INFO: epoch 001:   8001 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.4, ups=0.85, wpb=111.2, bsz=40, num_updates=7990, lr=6.90937e-06, gnorm=1.055, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=43966
2022-10-12 05:48:41 - progress_bar.py[line:274] - INFO: epoch 001:   8011 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.8, ups=0.85, wpb=110.4, bsz=40, num_updates=8000, lr=6.91802e-06, gnorm=1.24, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=43977
2022-10-12 05:48:41 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 05:48:42 - train.py[line:549] - INFO: 0 / 9351
2022-10-12 05:48:42 - train.py[line:551] - INFO: load:0.83 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 05:50:06 - train.py[line:549] - INFO: 200 / 9351
2022-10-12 05:50:06 - train.py[line:551] - INFO: load:0.85 valid_run:84.22 task_valid:81.47 collect_output:1.56
2022-10-12 05:51:30 - train.py[line:549] - INFO: 400 / 9351
2022-10-12 05:51:30 - train.py[line:551] - INFO: load:0.87 valid_run:168.36 task_valid:162.97 collect_output:2.99
2022-10-12 05:52:54 - train.py[line:549] - INFO: 600 / 9351
2022-10-12 05:52:54 - train.py[line:551] - INFO: load:0.89 valid_run:251.81 task_valid:242.70 collect_output:5.48
2022-10-12 05:54:19 - train.py[line:549] - INFO: 800 / 9351
2022-10-12 05:54:19 - train.py[line:551] - INFO: load:0.91 valid_run:336.76 task_valid:322.63 collect_output:9.20
2022-10-12 05:55:44 - train.py[line:549] - INFO: 1000 / 9351
2022-10-12 05:55:44 - train.py[line:551] - INFO: load:0.93 valid_run:421.74 task_valid:402.16 collect_output:13.43
2022-10-12 05:57:08 - train.py[line:549] - INFO: 1200 / 9351
2022-10-12 05:57:08 - train.py[line:551] - INFO: load:0.96 valid_run:506.46 task_valid:480.58 collect_output:18.56
2022-10-12 05:58:33 - train.py[line:549] - INFO: 1400 / 9351
2022-10-12 05:58:33 - train.py[line:551] - INFO: load:0.98 valid_run:590.96 task_valid:561.47 collect_output:21.01
2022-10-12 05:59:58 - train.py[line:549] - INFO: 1600 / 9351
2022-10-12 05:59:58 - train.py[line:551] - INFO: load:1.00 valid_run:675.67 task_valid:643.81 collect_output:22.12
2022-10-12 06:01:24 - train.py[line:549] - INFO: 1800 / 9351
2022-10-12 06:01:24 - train.py[line:551] - INFO: load:1.02 valid_run:761.34 task_valid:724.85 collect_output:25.55
2022-10-12 06:02:48 - train.py[line:549] - INFO: 2000 / 9351
2022-10-12 06:02:48 - train.py[line:551] - INFO: load:1.04 valid_run:845.62 task_valid:804.98 collect_output:28.62
2022-10-12 06:04:13 - train.py[line:549] - INFO: 2200 / 9351
2022-10-12 06:04:13 - train.py[line:551] - INFO: load:1.06 valid_run:930.23 task_valid:885.31 collect_output:31.81
2022-10-12 06:05:37 - train.py[line:549] - INFO: 2400 / 9351
2022-10-12 06:05:37 - train.py[line:551] - INFO: load:1.09 valid_run:1014.44 task_valid:965.78 collect_output:34.48
2022-10-12 06:07:02 - train.py[line:549] - INFO: 2600 / 9351
2022-10-12 06:07:02 - train.py[line:551] - INFO: load:1.11 valid_run:1099.47 task_valid:1046.05 collect_output:38.15
2022-10-12 06:08:26 - train.py[line:549] - INFO: 2800 / 9351
2022-10-12 06:08:26 - train.py[line:551] - INFO: load:1.13 valid_run:1183.79 task_valid:1124.96 collect_output:42.46
2022-10-12 06:09:49 - train.py[line:549] - INFO: 3000 / 9351
2022-10-12 06:09:49 - train.py[line:551] - INFO: load:1.15 valid_run:1266.92 task_valid:1202.18 collect_output:47.30
2022-10-12 06:11:12 - train.py[line:549] - INFO: 3200 / 9351
2022-10-12 06:11:12 - train.py[line:551] - INFO: load:1.17 valid_run:1349.66 task_valid:1281.67 collect_output:49.41
2022-10-12 06:12:36 - train.py[line:549] - INFO: 3400 / 9351
2022-10-12 06:12:36 - train.py[line:551] - INFO: load:1.19 valid_run:1433.81 task_valid:1361.51 collect_output:52.66
2022-10-12 06:14:00 - train.py[line:549] - INFO: 3600 / 9351
2022-10-12 06:14:00 - train.py[line:551] - INFO: load:1.22 valid_run:1517.56 task_valid:1442.38 collect_output:54.41
2022-10-12 06:15:22 - train.py[line:549] - INFO: 3800 / 9351
2022-10-12 06:15:22 - train.py[line:551] - INFO: load:1.24 valid_run:1599.53 task_valid:1520.04 collect_output:57.67
2022-10-12 06:16:45 - train.py[line:549] - INFO: 4000 / 9351
2022-10-12 06:16:45 - train.py[line:551] - INFO: load:1.26 valid_run:1682.06 task_valid:1599.18 collect_output:60.01
2022-10-12 06:18:09 - train.py[line:549] - INFO: 4200 / 9351
2022-10-12 06:18:09 - train.py[line:551] - INFO: load:1.29 valid_run:1766.18 task_valid:1681.15 collect_output:61.10
2022-10-12 06:19:33 - train.py[line:549] - INFO: 4400 / 9351
2022-10-12 06:19:33 - train.py[line:551] - INFO: load:1.31 valid_run:1849.95 task_valid:1761.40 collect_output:63.52
2022-10-12 06:20:56 - train.py[line:549] - INFO: 4600 / 9351
2022-10-12 06:20:56 - train.py[line:551] - INFO: load:1.33 valid_run:1932.69 task_valid:1840.49 collect_output:66.11
2022-10-12 06:22:19 - train.py[line:549] - INFO: 4800 / 9351
2022-10-12 06:22:19 - train.py[line:551] - INFO: load:1.35 valid_run:2016.36 task_valid:1918.84 collect_output:70.36
2022-10-12 06:23:44 - train.py[line:549] - INFO: 5000 / 9351
2022-10-12 06:23:44 - train.py[line:551] - INFO: load:1.38 valid_run:2100.95 task_valid:2000.38 collect_output:72.28
2022-10-12 06:25:08 - train.py[line:549] - INFO: 5200 / 9351
2022-10-12 06:25:08 - train.py[line:551] - INFO: load:1.40 valid_run:2184.73 task_valid:2080.94 collect_output:74.41
2022-10-12 06:26:31 - train.py[line:549] - INFO: 5400 / 9351
2022-10-12 06:26:31 - train.py[line:551] - INFO: load:1.42 valid_run:2267.96 task_valid:2161.22 collect_output:76.29
2022-10-12 06:27:56 - train.py[line:549] - INFO: 5600 / 9351
2022-10-12 06:27:56 - train.py[line:551] - INFO: load:1.44 valid_run:2352.41 task_valid:2242.68 collect_output:78.17
2022-10-12 06:29:19 - train.py[line:549] - INFO: 5800 / 9351
2022-10-12 06:29:19 - train.py[line:551] - INFO: load:1.47 valid_run:2436.01 task_valid:2322.41 collect_output:80.96
2022-10-12 06:30:43 - train.py[line:549] - INFO: 6000 / 9351
2022-10-12 06:30:43 - train.py[line:551] - INFO: load:1.49 valid_run:2519.38 task_valid:2402.65 collect_output:83.02
2022-10-12 06:32:06 - train.py[line:549] - INFO: 6200 / 9351
2022-10-12 06:32:06 - train.py[line:551] - INFO: load:1.51 valid_run:2602.67 task_valid:2482.32 collect_output:85.61
2022-10-12 06:33:31 - train.py[line:549] - INFO: 6400 / 9351
2022-10-12 06:33:31 - train.py[line:551] - INFO: load:1.53 valid_run:2687.65 task_valid:2563.69 collect_output:88.14
2022-10-12 06:34:55 - train.py[line:549] - INFO: 6600 / 9351
2022-10-12 06:34:55 - train.py[line:551] - INFO: load:1.55 valid_run:2771.42 task_valid:2645.16 collect_output:89.37
2022-10-12 06:36:18 - train.py[line:549] - INFO: 6800 / 9351
2022-10-12 06:36:18 - train.py[line:551] - INFO: load:1.58 valid_run:2854.77 task_valid:2724.91 collect_output:91.91
2022-10-12 06:37:41 - train.py[line:549] - INFO: 7000 / 9351
2022-10-12 06:37:41 - train.py[line:551] - INFO: load:1.60 valid_run:2937.51 task_valid:2803.49 collect_output:94.99
2022-10-12 06:39:05 - train.py[line:549] - INFO: 7200 / 9351
2022-10-12 06:39:05 - train.py[line:551] - INFO: load:1.62 valid_run:3020.82 task_valid:2883.78 collect_output:96.92
2022-10-12 06:40:28 - train.py[line:549] - INFO: 7400 / 9351
2022-10-12 06:40:28 - train.py[line:551] - INFO: load:1.64 valid_run:3104.25 task_valid:2962.87 collect_output:100.19
2022-10-12 06:41:53 - train.py[line:549] - INFO: 7600 / 9351
2022-10-12 06:41:53 - train.py[line:551] - INFO: load:1.66 valid_run:3189.33 task_valid:3043.50 collect_output:103.57
2022-10-12 06:43:18 - train.py[line:549] - INFO: 7800 / 9351
2022-10-12 06:43:18 - train.py[line:551] - INFO: load:1.69 valid_run:3273.93 task_valid:3123.69 collect_output:106.92
2022-10-12 06:44:40 - train.py[line:549] - INFO: 8000 / 9351
2022-10-12 06:44:40 - train.py[line:551] - INFO: load:1.71 valid_run:3356.50 task_valid:3202.15 collect_output:109.95
2022-10-12 06:46:04 - train.py[line:549] - INFO: 8200 / 9351
2022-10-12 06:46:04 - train.py[line:551] - INFO: load:1.73 valid_run:3440.41 task_valid:3283.61 collect_output:111.31
2022-10-12 06:47:28 - train.py[line:549] - INFO: 8400 / 9351
2022-10-12 06:47:28 - train.py[line:551] - INFO: load:1.75 valid_run:3524.17 task_valid:3364.81 collect_output:112.74
2022-10-12 06:48:54 - train.py[line:549] - INFO: 8600 / 9351
2022-10-12 06:48:54 - train.py[line:551] - INFO: load:1.78 valid_run:3609.83 task_valid:3446.12 collect_output:115.80
2022-10-12 06:50:19 - train.py[line:549] - INFO: 8800 / 9351
2022-10-12 06:50:19 - train.py[line:551] - INFO: load:1.80 valid_run:3695.00 task_valid:3525.89 collect_output:119.94
2022-10-12 06:51:45 - train.py[line:549] - INFO: 9000 / 9351
2022-10-12 06:51:45 - train.py[line:551] - INFO: load:1.83 valid_run:3780.49 task_valid:3608.79 collect_output:121.26
2022-10-12 06:53:09 - train.py[line:549] - INFO: 9200 / 9351
2022-10-12 06:53:09 - train.py[line:551] - INFO: load:1.85 valid_run:3864.74 task_valid:3690.09 collect_output:123.04

====================================================================================================
SGG eval:     R @ 50: 0.6668;     R @ 100: 0.6889;     R @ 500: 0.7127;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4832;    mR @ 100: 0.4974;    mR @ 500: 0.5513;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8659) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.5000) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9500) (says:0.0000) (sitting on:0.7449) (standing on:0.4093) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6668;     R @ 100: 0.6889;     R @ 500: 0.7127;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4832;    mR @ 100: 0.4974;    mR @ 500: 0.5513;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8659) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.5000) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9500) (says:0.0000) (sitting on:0.7449) (standing on:0.4093) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-12 06:54:24 - train.py[line:487] - INFO: 0.688910415075121
2022-10-12 06:54:24 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 06:54:24 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.357 | loss_v1 0 | loss_v2 0 | nll_loss 0.206 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.68891 | ppl 1.15 | vqa_score 0.5732 | wps 113.8 | wpb 48 | bsz 16 | num_updates 8000 | best_R@100 0.69991
2022-10-12 06:54:24 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2022-10-12 06:54:24 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-12 06:54:30 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-12 06:54:33 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.688910415075121) (writing took 8.870248960796744 seconds)
2022-10-12 06:54:45 - progress_bar.py[line:274] - INFO: epoch 001:   8021 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=0.3, ups=0, wpb=110.9, bsz=40, num_updates=8010, lr=6.92667e-06, gnorm=1.211, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=47941
2022-10-12 06:54:57 - progress_bar.py[line:274] - INFO: epoch 001:   8031 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.83, wpb=108.3, bsz=40, num_updates=8020, lr=6.93532e-06, gnorm=1.159, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=47953
2022-10-12 06:55:09 - progress_bar.py[line:274] - INFO: epoch 001:   8041 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.2, ups=0.83, wpb=110.5, bsz=40, num_updates=8030, lr=6.94396e-06, gnorm=1.099, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=47965
2022-10-12 06:55:20 - progress_bar.py[line:274] - INFO: epoch 001:   8051 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.9, ups=0.86, wpb=112.1, bsz=40, num_updates=8040, lr=6.95261e-06, gnorm=1.087, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=47977
2022-10-12 06:55:32 - progress_bar.py[line:274] - INFO: epoch 001:   8061 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.1, ups=0.83, wpb=110.3, bsz=40, num_updates=8050, lr=6.96126e-06, gnorm=1.252, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=47989
2022-10-12 06:55:44 - progress_bar.py[line:274] - INFO: epoch 001:   8071 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.7, ups=0.83, wpb=109.8, bsz=40, num_updates=8060, lr=6.96991e-06, gnorm=1.13, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48001
2022-10-12 06:55:56 - progress_bar.py[line:274] - INFO: epoch 001:   8081 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.9, ups=0.84, wpb=110.6, bsz=40, num_updates=8070, lr=6.97855e-06, gnorm=1.134, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48013
2022-10-12 06:56:08 - progress_bar.py[line:274] - INFO: epoch 001:   8091 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.5, ups=0.84, wpb=110.1, bsz=40, num_updates=8080, lr=6.9872e-06, gnorm=1.202, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=48025
2022-10-12 06:56:20 - progress_bar.py[line:274] - INFO: epoch 001:   8101 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.82, wpb=110.9, bsz=40, num_updates=8090, lr=6.99585e-06, gnorm=1.266, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48037
2022-10-12 06:56:32 - progress_bar.py[line:274] - INFO: epoch 001:   8111 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.3, ups=0.85, wpb=110.9, bsz=40, num_updates=8100, lr=7.0045e-06, gnorm=1.146, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48049
2022-10-12 06:56:44 - progress_bar.py[line:274] - INFO: epoch 001:   8121 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.86, wpb=109.2, bsz=40, num_updates=8110, lr=7.01314e-06, gnorm=1.152, clip=80, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=48061
2022-10-12 06:56:56 - progress_bar.py[line:274] - INFO: epoch 001:   8131 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.2, ups=0.84, wpb=110.8, bsz=40, num_updates=8120, lr=7.02179e-06, gnorm=1.253, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48073
2022-10-12 06:57:08 - progress_bar.py[line:274] - INFO: epoch 001:   8141 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.83, wpb=110.6, bsz=40, num_updates=8130, lr=7.03044e-06, gnorm=1.214, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48085
2022-10-12 06:57:20 - progress_bar.py[line:274] - INFO: epoch 001:   8151 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.9, ups=0.84, wpb=110.1, bsz=40, num_updates=8140, lr=7.03909e-06, gnorm=1.176, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48096
2022-10-12 06:57:31 - progress_bar.py[line:274] - INFO: epoch 001:   8161 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.9, ups=0.85, wpb=109.3, bsz=40, num_updates=8150, lr=7.04773e-06, gnorm=1.132, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48108
2022-10-12 06:57:43 - progress_bar.py[line:274] - INFO: epoch 001:   8171 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.5, ups=0.85, wpb=108.8, bsz=40, num_updates=8160, lr=7.05638e-06, gnorm=1.252, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48120
2022-10-12 06:57:55 - progress_bar.py[line:274] - INFO: epoch 001:   8181 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.83, wpb=109.7, bsz=40, num_updates=8170, lr=7.06503e-06, gnorm=1.143, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48132
2022-10-12 06:58:07 - progress_bar.py[line:274] - INFO: epoch 001:   8191 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.1, ups=0.83, wpb=110.6, bsz=40, num_updates=8180, lr=7.07368e-06, gnorm=1.15, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48144
2022-10-12 06:58:19 - progress_bar.py[line:274] - INFO: epoch 001:   8201 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.4, ups=0.86, wpb=109.5, bsz=40, num_updates=8190, lr=7.08232e-06, gnorm=1.169, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48156
2022-10-12 06:58:31 - progress_bar.py[line:274] - INFO: epoch 001:   8211 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.4, ups=0.84, wpb=110, bsz=40, num_updates=8200, lr=7.09097e-06, gnorm=1.189, clip=100, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48168
2022-10-12 06:58:43 - progress_bar.py[line:274] - INFO: epoch 001:   8221 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.5, ups=0.85, wpb=111.7, bsz=40, num_updates=8210, lr=7.09962e-06, gnorm=1.098, clip=80, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=48179
2022-10-12 06:58:55 - progress_bar.py[line:274] - INFO: epoch 001:   8231 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.82, wpb=111.4, bsz=40, num_updates=8220, lr=7.10827e-06, gnorm=1.194, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48192
2022-10-12 06:59:07 - progress_bar.py[line:274] - INFO: epoch 001:   8241 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.3, ups=0.85, wpb=110.5, bsz=40, num_updates=8230, lr=7.11691e-06, gnorm=1.137, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48203
2022-10-12 06:59:19 - progress_bar.py[line:274] - INFO: epoch 001:   8251 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.4, ups=0.83, wpb=111.2, bsz=40, num_updates=8240, lr=7.12556e-06, gnorm=1.093, clip=60, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48215
2022-10-12 06:59:31 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 06:59:32 - progress_bar.py[line:274] - INFO: epoch 001:   8262 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=83.2, ups=0.75, wpb=110.3, bsz=40, num_updates=8250, lr=7.13421e-06, gnorm=1.104, clip=70, loss_scale=512, train_wall=13, gb_free=22.7, ema_decay=0.9999, wall=48229
2022-10-12 06:59:44 - progress_bar.py[line:274] - INFO: epoch 001:   8272 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.8, ups=0.85, wpb=110.9, bsz=40, num_updates=8260, lr=7.14286e-06, gnorm=1.147, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48240
2022-10-12 06:59:56 - progress_bar.py[line:274] - INFO: epoch 001:   8282 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.84, wpb=109.5, bsz=40, num_updates=8270, lr=7.1515e-06, gnorm=1.189, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48252
2022-10-12 07:00:08 - progress_bar.py[line:274] - INFO: epoch 001:   8292 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.82, wpb=109, bsz=40, num_updates=8280, lr=7.16015e-06, gnorm=1.242, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48264
2022-10-12 07:00:20 - progress_bar.py[line:274] - INFO: epoch 001:   8302 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.1, ups=0.84, wpb=110.1, bsz=40, num_updates=8290, lr=7.1688e-06, gnorm=1.194, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=48276
2022-10-12 07:00:32 - progress_bar.py[line:274] - INFO: epoch 001:   8312 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.9, ups=0.83, wpb=111.3, bsz=40, num_updates=8300, lr=7.17745e-06, gnorm=1.229, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48288
2022-10-12 07:00:44 - progress_bar.py[line:274] - INFO: epoch 001:   8322 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.6, ups=0.83, wpb=109.1, bsz=40, num_updates=8310, lr=7.18609e-06, gnorm=1.175, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48300
2022-10-12 07:00:56 - progress_bar.py[line:274] - INFO: epoch 001:   8332 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.8, ups=0.84, wpb=111, bsz=40, num_updates=8320, lr=7.19474e-06, gnorm=1.127, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48312
2022-10-12 07:01:08 - progress_bar.py[line:274] - INFO: epoch 001:   8342 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.9, ups=0.83, wpb=110.5, bsz=40, num_updates=8330, lr=7.20339e-06, gnorm=1.116, clip=70, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=48324
2022-10-12 07:01:20 - progress_bar.py[line:274] - INFO: epoch 001:   8352 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.4, ups=0.85, wpb=111.2, bsz=40, num_updates=8340, lr=7.21204e-06, gnorm=1.146, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48336
2022-10-12 07:01:31 - progress_bar.py[line:274] - INFO: epoch 001:   8362 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.1, ups=0.84, wpb=111.7, bsz=40, num_updates=8350, lr=7.22068e-06, gnorm=1.166, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48348
2022-10-12 07:01:43 - progress_bar.py[line:274] - INFO: epoch 001:   8372 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.84, wpb=109, bsz=40, num_updates=8360, lr=7.22933e-06, gnorm=1.22, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48360
2022-10-12 07:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   8382 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.6, ups=0.85, wpb=109.9, bsz=40, num_updates=8370, lr=7.23798e-06, gnorm=1.245, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48372
2022-10-12 07:02:07 - progress_bar.py[line:274] - INFO: epoch 001:   8392 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.8, ups=0.83, wpb=110.7, bsz=40, num_updates=8380, lr=7.24663e-06, gnorm=1.102, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48384
2022-10-12 07:02:19 - progress_bar.py[line:274] - INFO: epoch 001:   8402 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.84, wpb=107.8, bsz=40, num_updates=8390, lr=7.25527e-06, gnorm=1.269, clip=100, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=48396
2022-10-12 07:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   8412 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.4, ups=0.85, wpb=109.8, bsz=40, num_updates=8400, lr=7.26392e-06, gnorm=1.176, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48408
2022-10-12 07:02:43 - progress_bar.py[line:274] - INFO: epoch 001:   8422 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.83, wpb=110.5, bsz=40, num_updates=8410, lr=7.27257e-06, gnorm=1.24, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48420
2022-10-12 07:02:55 - progress_bar.py[line:274] - INFO: epoch 001:   8432 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.6, ups=0.84, wpb=109.9, bsz=40, num_updates=8420, lr=7.28122e-06, gnorm=1.178, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48432
2022-10-12 07:03:07 - progress_bar.py[line:274] - INFO: epoch 001:   8442 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.2, ups=0.85, wpb=109.4, bsz=40, num_updates=8430, lr=7.28987e-06, gnorm=1.248, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48443
2022-10-12 07:03:18 - progress_bar.py[line:274] - INFO: epoch 001:   8452 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.9, ups=0.85, wpb=112, bsz=40, num_updates=8440, lr=7.29851e-06, gnorm=1.222, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48455
2022-10-12 07:03:30 - progress_bar.py[line:274] - INFO: epoch 001:   8462 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.84, wpb=108.1, bsz=40, num_updates=8450, lr=7.30716e-06, gnorm=1.27, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48467
2022-10-12 07:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   8472 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.6, ups=0.84, wpb=110.4, bsz=40, num_updates=8460, lr=7.31581e-06, gnorm=1.14, clip=80, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=48479
2022-10-12 07:03:54 - progress_bar.py[line:274] - INFO: epoch 001:   8482 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.9, ups=0.86, wpb=111.9, bsz=40, num_updates=8470, lr=7.32446e-06, gnorm=1.225, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48491
2022-10-12 07:04:06 - progress_bar.py[line:274] - INFO: epoch 001:   8492 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.83, wpb=109.4, bsz=40, num_updates=8480, lr=7.3331e-06, gnorm=1.256, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48503
2022-10-12 07:04:18 - progress_bar.py[line:274] - INFO: epoch 001:   8502 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.9, ups=0.85, wpb=112.2, bsz=40, num_updates=8490, lr=7.34175e-06, gnorm=1.242, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48514
2022-10-12 07:04:30 - progress_bar.py[line:274] - INFO: epoch 001:   8512 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.2, ups=0.82, wpb=111.1, bsz=40, num_updates=8500, lr=7.3504e-06, gnorm=1.153, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48527
2022-10-12 07:04:42 - progress_bar.py[line:274] - INFO: epoch 001:   8522 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.4, ups=0.85, wpb=111, bsz=40, num_updates=8510, lr=7.35905e-06, gnorm=1.163, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48538
2022-10-12 07:04:54 - progress_bar.py[line:274] - INFO: epoch 001:   8532 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.83, wpb=110, bsz=40, num_updates=8520, lr=7.36769e-06, gnorm=1.288, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48550
2022-10-12 07:05:06 - progress_bar.py[line:274] - INFO: epoch 001:   8542 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.2, ups=0.84, wpb=111.3, bsz=40, num_updates=8530, lr=7.37634e-06, gnorm=1.096, clip=60, loss_scale=512, train_wall=12, gb_free=22.3, ema_decay=0.9999, wall=48562
2022-10-12 07:05:18 - progress_bar.py[line:274] - INFO: epoch 001:   8552 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.4, ups=0.83, wpb=111.4, bsz=40, num_updates=8540, lr=7.38499e-06, gnorm=1.038, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48574
2022-10-12 07:05:30 - progress_bar.py[line:274] - INFO: epoch 001:   8562 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.7, ups=0.85, wpb=111.4, bsz=40, num_updates=8550, lr=7.39364e-06, gnorm=1.137, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48586
2022-10-12 07:05:42 - progress_bar.py[line:274] - INFO: epoch 001:   8572 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.7, ups=0.83, wpb=109.3, bsz=40, num_updates=8560, lr=7.40228e-06, gnorm=1.102, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48598
2022-10-12 07:05:54 - progress_bar.py[line:274] - INFO: epoch 001:   8582 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.2, ups=0.82, wpb=110.9, bsz=40, num_updates=8570, lr=7.41093e-06, gnorm=1.232, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48610
2022-10-12 07:06:06 - progress_bar.py[line:274] - INFO: epoch 001:   8592 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.84, wpb=111.4, bsz=40, num_updates=8580, lr=7.41958e-06, gnorm=1.247, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48622
2022-10-12 07:06:18 - progress_bar.py[line:274] - INFO: epoch 001:   8602 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.83, wpb=110.3, bsz=40, num_updates=8590, lr=7.42823e-06, gnorm=1.13, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48634
2022-10-12 07:06:29 - progress_bar.py[line:274] - INFO: epoch 001:   8612 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.9, ups=0.85, wpb=109.5, bsz=40, num_updates=8600, lr=7.43687e-06, gnorm=1.176, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48646
2022-10-12 07:06:42 - progress_bar.py[line:274] - INFO: epoch 001:   8622 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.8, ups=0.82, wpb=110.7, bsz=40, num_updates=8610, lr=7.44552e-06, gnorm=1.19, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48658
2022-10-12 07:06:53 - progress_bar.py[line:274] - INFO: epoch 001:   8632 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.3, ups=0.85, wpb=110.4, bsz=40, num_updates=8620, lr=7.45417e-06, gnorm=1.224, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48670
2022-10-12 07:07:05 - progress_bar.py[line:274] - INFO: epoch 001:   8642 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.2, ups=0.85, wpb=110.4, bsz=40, num_updates=8630, lr=7.46282e-06, gnorm=1.065, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48682
2022-10-12 07:07:17 - progress_bar.py[line:274] - INFO: epoch 001:   8652 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.4, ups=0.84, wpb=111.5, bsz=40, num_updates=8640, lr=7.47146e-06, gnorm=1.139, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48694
2022-10-12 07:07:29 - progress_bar.py[line:274] - INFO: epoch 001:   8662 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.4, ups=0.85, wpb=110.2, bsz=40, num_updates=8650, lr=7.48011e-06, gnorm=1.106, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=48706
2022-10-12 07:07:41 - progress_bar.py[line:274] - INFO: epoch 001:   8672 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.82, wpb=110.2, bsz=40, num_updates=8660, lr=7.48876e-06, gnorm=1.213, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48718
2022-10-12 07:07:53 - progress_bar.py[line:274] - INFO: epoch 001:   8682 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.84, wpb=110.1, bsz=40, num_updates=8670, lr=7.49741e-06, gnorm=1.272, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48730
2022-10-12 07:08:05 - progress_bar.py[line:274] - INFO: epoch 001:   8692 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.4, ups=0.85, wpb=111, bsz=40, num_updates=8680, lr=7.50605e-06, gnorm=1.092, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=48741
2022-10-12 07:08:17 - progress_bar.py[line:274] - INFO: epoch 001:   8702 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93, ups=0.85, wpb=109.6, bsz=40, num_updates=8690, lr=7.5147e-06, gnorm=1.265, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48753
2022-10-12 07:08:29 - progress_bar.py[line:274] - INFO: epoch 001:   8712 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.2, ups=0.83, wpb=108.5, bsz=40, num_updates=8700, lr=7.52335e-06, gnorm=1.176, clip=70, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=48765
2022-10-12 07:08:40 - progress_bar.py[line:274] - INFO: epoch 001:   8722 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.7, ups=0.84, wpb=110.9, bsz=40, num_updates=8710, lr=7.532e-06, gnorm=1.206, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48777
2022-10-12 07:08:52 - progress_bar.py[line:274] - INFO: epoch 001:   8732 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.8, ups=0.87, wpb=109.3, bsz=40, num_updates=8720, lr=7.54064e-06, gnorm=1.326, clip=90, loss_scale=512, train_wall=11, gb_free=22.6, ema_decay=0.9999, wall=48789
2022-10-12 07:09:04 - progress_bar.py[line:274] - INFO: epoch 001:   8742 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.7, ups=0.85, wpb=111.7, bsz=40, num_updates=8730, lr=7.54929e-06, gnorm=1.115, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=48801
2022-10-12 07:09:16 - progress_bar.py[line:274] - INFO: epoch 001:   8752 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.2, ups=0.84, wpb=109.3, bsz=40, num_updates=8740, lr=7.55794e-06, gnorm=1.155, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48812
2022-10-12 07:09:27 - progress_bar.py[line:274] - INFO: epoch 001:   8762 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.6, ups=0.87, wpb=111.3, bsz=40, num_updates=8750, lr=7.56659e-06, gnorm=1.091, clip=60, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=48824
2022-10-12 07:09:39 - progress_bar.py[line:274] - INFO: epoch 001:   8772 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.5, ups=0.84, wpb=109.8, bsz=40, num_updates=8760, lr=7.57523e-06, gnorm=1.15, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48836
2022-10-12 07:09:51 - progress_bar.py[line:274] - INFO: epoch 001:   8782 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.8, ups=0.84, wpb=109, bsz=40, num_updates=8770, lr=7.58388e-06, gnorm=1.254, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48848
2022-10-12 07:10:03 - progress_bar.py[line:274] - INFO: epoch 001:   8792 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.2, ups=0.85, wpb=110.5, bsz=40, num_updates=8780, lr=7.59253e-06, gnorm=1.197, clip=90, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48859
2022-10-12 07:10:14 - progress_bar.py[line:274] - INFO: epoch 001:   8802 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.1, ups=0.85, wpb=108.3, bsz=40, num_updates=8790, lr=7.60118e-06, gnorm=1.237, clip=90, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=48871
2022-10-12 07:10:26 - progress_bar.py[line:274] - INFO: epoch 001:   8812 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.7, ups=0.84, wpb=111, bsz=40, num_updates=8800, lr=7.60982e-06, gnorm=1.092, clip=70, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48883
2022-10-12 07:10:38 - progress_bar.py[line:274] - INFO: epoch 001:   8822 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.2, ups=0.87, wpb=109.5, bsz=40, num_updates=8810, lr=7.61847e-06, gnorm=1.188, clip=80, loss_scale=1024, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=48895
2022-10-12 07:10:50 - progress_bar.py[line:274] - INFO: epoch 001:   8832 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.8, ups=0.83, wpb=111.2, bsz=40, num_updates=8820, lr=7.62712e-06, gnorm=1.139, clip=90, loss_scale=1024, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=48907
2022-10-12 07:11:02 - progress_bar.py[line:274] - INFO: epoch 001:   8842 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.8, ups=0.84, wpb=110, bsz=40, num_updates=8830, lr=7.63577e-06, gnorm=1.208, clip=70, loss_scale=1024, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=48918
2022-10-12 07:11:14 - progress_bar.py[line:274] - INFO: epoch 001:   8852 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.8, ups=0.84, wpb=109.1, bsz=40, num_updates=8840, lr=7.64441e-06, gnorm=1.249, clip=90, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48930
2022-10-12 07:11:23 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 07:11:26 - progress_bar.py[line:274] - INFO: epoch 001:   8863 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.6, ups=0.79, wpb=110.2, bsz=40, num_updates=8850, lr=7.65306e-06, gnorm=1.29, clip=100, loss_scale=512, train_wall=13, gb_free=22.7, ema_decay=0.9999, wall=48943
2022-10-12 07:11:38 - progress_bar.py[line:274] - INFO: epoch 001:   8873 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.8, ups=0.84, wpb=110.2, bsz=40, num_updates=8860, lr=7.66171e-06, gnorm=1.129, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48955
2022-10-12 07:11:50 - progress_bar.py[line:274] - INFO: epoch 001:   8883 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.86, wpb=109, bsz=40, num_updates=8870, lr=7.67036e-06, gnorm=1.138, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=48967
2022-10-12 07:12:02 - progress_bar.py[line:274] - INFO: epoch 001:   8893 / 28910 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.9, ups=0.83, wpb=111.3, bsz=40, num_updates=8880, lr=7.679e-06, gnorm=1.359, clip=100, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=48979
2022-10-12 07:12:14 - progress_bar.py[line:274] - INFO: epoch 001:   8903 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.2, ups=0.85, wpb=112.1, bsz=40, num_updates=8890, lr=7.68765e-06, gnorm=1.213, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=48990
2022-10-12 07:12:26 - progress_bar.py[line:274] - INFO: epoch 001:   8913 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.84, wpb=109.4, bsz=40, num_updates=8900, lr=7.6963e-06, gnorm=1.178, clip=60, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=49002
2022-10-12 07:12:37 - progress_bar.py[line:274] - INFO: epoch 001:   8923 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.1, ups=0.86, wpb=109.8, bsz=40, num_updates=8910, lr=7.70495e-06, gnorm=1.122, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=49014
2022-10-12 07:12:49 - progress_bar.py[line:274] - INFO: epoch 001:   8933 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.8, ups=0.85, wpb=111.5, bsz=40, num_updates=8920, lr=7.71359e-06, gnorm=1.17, clip=80, loss_scale=512, train_wall=12, gb_free=22.5, ema_decay=0.9999, wall=49026
2022-10-12 07:13:01 - progress_bar.py[line:274] - INFO: epoch 001:   8943 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.8, ups=0.85, wpb=111, bsz=40, num_updates=8930, lr=7.72224e-06, gnorm=1.152, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=49037
2022-10-12 07:13:12 - progress_bar.py[line:274] - INFO: epoch 001:   8953 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.8, ups=0.85, wpb=110.5, bsz=40, num_updates=8940, lr=7.73089e-06, gnorm=1.203, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=49049
2022-10-12 07:13:24 - progress_bar.py[line:274] - INFO: epoch 001:   8963 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.6, ups=0.84, wpb=110.9, bsz=40, num_updates=8950, lr=7.73954e-06, gnorm=1.124, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=49061
2022-10-12 07:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   8973 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.2, ups=0.84, wpb=110.3, bsz=40, num_updates=8960, lr=7.74818e-06, gnorm=1.316, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=49073
2022-10-12 07:13:48 - progress_bar.py[line:274] - INFO: epoch 001:   8983 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.5, ups=0.86, wpb=110.5, bsz=40, num_updates=8970, lr=7.75683e-06, gnorm=1.263, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=49085
2022-10-12 07:14:00 - progress_bar.py[line:274] - INFO: epoch 001:   8993 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.8, ups=0.85, wpb=109.2, bsz=40, num_updates=8980, lr=7.76548e-06, gnorm=1.122, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=49096
2022-10-12 07:14:12 - progress_bar.py[line:274] - INFO: epoch 001:   9003 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.5, ups=0.84, wpb=109.5, bsz=40, num_updates=8990, lr=7.77413e-06, gnorm=1.298, clip=100, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=49108
2022-10-12 07:14:23 - progress_bar.py[line:274] - INFO: epoch 001:   9013 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.84, wpb=110.7, bsz=40, num_updates=9000, lr=7.78277e-06, gnorm=1.159, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=49120
2022-10-12 07:14:23 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 07:14:25 - train.py[line:549] - INFO: 0 / 9351
2022-10-12 07:14:25 - train.py[line:551] - INFO: load:0.89 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 07:15:48 - train.py[line:549] - INFO: 200 / 9351
2022-10-12 07:15:48 - train.py[line:551] - INFO: load:0.91 valid_run:83.64 task_valid:81.10 collect_output:1.46
2022-10-12 07:17:12 - train.py[line:549] - INFO: 400 / 9351
2022-10-12 07:17:12 - train.py[line:551] - INFO: load:0.93 valid_run:167.13 task_valid:162.27 collect_output:2.69
2022-10-12 07:18:34 - train.py[line:549] - INFO: 600 / 9351
2022-10-12 07:18:34 - train.py[line:551] - INFO: load:0.96 valid_run:249.42 task_valid:241.27 collect_output:4.87
2022-10-12 07:19:57 - train.py[line:549] - INFO: 800 / 9351
2022-10-12 07:19:57 - train.py[line:551] - INFO: load:0.98 valid_run:332.58 task_valid:319.87 collect_output:8.37
2022-10-12 07:21:22 - train.py[line:549] - INFO: 1000 / 9351
2022-10-12 07:21:22 - train.py[line:551] - INFO: load:1.00 valid_run:417.09 task_valid:399.44 collect_output:12.24
2022-10-12 07:22:46 - train.py[line:549] - INFO: 1200 / 9351
2022-10-12 07:22:46 - train.py[line:551] - INFO: load:1.02 valid_run:500.63 task_valid:477.53 collect_output:16.58
2022-10-12 07:24:09 - train.py[line:549] - INFO: 1400 / 9351
2022-10-12 07:24:09 - train.py[line:551] - INFO: load:1.05 valid_run:584.15 task_valid:558.23 collect_output:18.29
2022-10-12 07:25:33 - train.py[line:549] - INFO: 1600 / 9351
2022-10-12 07:25:33 - train.py[line:551] - INFO: load:1.07 valid_run:667.95 task_valid:639.96 collect_output:19.29
2022-10-12 07:26:58 - train.py[line:549] - INFO: 1800 / 9351
2022-10-12 07:26:58 - train.py[line:551] - INFO: load:1.09 valid_run:752.47 task_valid:720.60 collect_output:22.09
2022-10-12 07:28:21 - train.py[line:549] - INFO: 2000 / 9351
2022-10-12 07:28:21 - train.py[line:551] - INFO: load:1.11 valid_run:836.28 task_valid:800.70 collect_output:24.74
2022-10-12 07:29:45 - train.py[line:549] - INFO: 2200 / 9351
2022-10-12 07:29:45 - train.py[line:551] - INFO: load:1.14 valid_run:920.12 task_valid:880.46 collect_output:27.77
2022-10-12 07:31:10 - train.py[line:549] - INFO: 2400 / 9351
2022-10-12 07:31:10 - train.py[line:551] - INFO: load:1.16 valid_run:1004.30 task_valid:961.12 collect_output:30.21
2022-10-12 07:32:34 - train.py[line:549] - INFO: 2600 / 9351
2022-10-12 07:32:34 - train.py[line:551] - INFO: load:1.18 valid_run:1088.92 task_valid:1040.82 collect_output:34.08
2022-10-12 07:33:58 - train.py[line:549] - INFO: 2800 / 9351
2022-10-12 07:33:58 - train.py[line:551] - INFO: load:1.21 valid_run:1173.03 task_valid:1119.75 collect_output:38.20
2022-10-12 07:35:21 - train.py[line:549] - INFO: 3000 / 9351
2022-10-12 07:35:21 - train.py[line:551] - INFO: load:1.23 valid_run:1255.92 task_valid:1197.10 collect_output:42.69
2022-10-12 07:36:44 - train.py[line:549] - INFO: 3200 / 9351
2022-10-12 07:36:44 - train.py[line:551] - INFO: load:1.25 valid_run:1338.26 task_valid:1276.37 collect_output:44.69
2022-10-12 07:38:08 - train.py[line:549] - INFO: 3400 / 9351
2022-10-12 07:38:08 - train.py[line:551] - INFO: load:1.27 valid_run:1422.27 task_valid:1356.12 collect_output:47.90
2022-10-12 07:39:31 - train.py[line:549] - INFO: 3600 / 9351
2022-10-12 07:39:31 - train.py[line:551] - INFO: load:1.30 valid_run:1505.39 task_valid:1436.57 collect_output:49.53
2022-10-12 07:40:54 - train.py[line:549] - INFO: 3800 / 9351
2022-10-12 07:40:54 - train.py[line:551] - INFO: load:1.32 valid_run:1587.83 task_valid:1514.65 collect_output:52.83
2022-10-12 07:42:16 - train.py[line:549] - INFO: 4000 / 9351
2022-10-12 07:42:16 - train.py[line:551] - INFO: load:1.34 valid_run:1669.88 task_valid:1593.42 collect_output:55.10
2022-10-12 07:43:40 - train.py[line:549] - INFO: 4200 / 9351
2022-10-12 07:43:40 - train.py[line:551] - INFO: load:1.36 valid_run:1753.88 task_valid:1675.16 collect_output:56.32
2022-10-12 07:45:03 - train.py[line:549] - INFO: 4400 / 9351
2022-10-12 07:45:03 - train.py[line:551] - INFO: load:1.39 valid_run:1837.26 task_valid:1755.05 collect_output:58.75
2022-10-12 07:46:26 - train.py[line:549] - INFO: 4600 / 9351
2022-10-12 07:46:26 - train.py[line:551] - INFO: load:1.41 valid_run:1919.95 task_valid:1834.31 collect_output:61.14
2022-10-12 07:47:50 - train.py[line:549] - INFO: 4800 / 9351
2022-10-12 07:47:50 - train.py[line:551] - INFO: load:1.43 valid_run:2003.85 task_valid:1912.58 collect_output:65.68
2022-10-12 07:49:14 - train.py[line:549] - INFO: 5000 / 9351
2022-10-12 07:49:14 - train.py[line:551] - INFO: load:1.46 valid_run:2087.73 task_valid:1993.27 collect_output:67.83
2022-10-12 07:50:38 - train.py[line:549] - INFO: 5200 / 9351
2022-10-12 07:50:38 - train.py[line:551] - INFO: load:1.48 valid_run:2171.43 task_valid:2073.85 collect_output:69.86
2022-10-12 07:52:00 - train.py[line:549] - INFO: 5400 / 9351
2022-10-12 07:52:00 - train.py[line:551] - INFO: load:1.50 valid_run:2254.19 task_valid:2153.83 collect_output:71.59
2022-10-12 07:53:25 - train.py[line:549] - INFO: 5600 / 9351
2022-10-12 07:53:25 - train.py[line:551] - INFO: load:1.53 valid_run:2338.40 task_valid:2235.19 collect_output:73.37
2022-10-12 07:54:49 - train.py[line:549] - INFO: 5800 / 9351
2022-10-12 07:54:49 - train.py[line:551] - INFO: load:1.55 valid_run:2422.44 task_valid:2314.99 collect_output:76.46
2022-10-12 07:56:13 - train.py[line:549] - INFO: 6000 / 9351
2022-10-12 07:56:13 - train.py[line:551] - INFO: load:1.57 valid_run:2507.04 task_valid:2396.15 collect_output:78.72
2022-10-12 07:57:37 - train.py[line:549] - INFO: 6200 / 9351
2022-10-12 07:57:37 - train.py[line:551] - INFO: load:1.60 valid_run:2591.01 task_valid:2476.28 collect_output:81.37
2022-10-12 07:59:04 - train.py[line:549] - INFO: 6400 / 9351
2022-10-12 07:59:04 - train.py[line:551] - INFO: load:1.63 valid_run:2677.34 task_valid:2558.44 collect_output:84.24
2022-10-12 08:00:29 - train.py[line:549] - INFO: 6600 / 9351
2022-10-12 08:00:29 - train.py[line:551] - INFO: load:1.65 valid_run:2762.24 task_valid:2640.70 collect_output:85.68
2022-10-12 08:01:53 - train.py[line:549] - INFO: 6800 / 9351
2022-10-12 08:01:53 - train.py[line:551] - INFO: load:1.67 valid_run:2846.56 task_valid:2720.78 collect_output:88.80
2022-10-12 08:03:18 - train.py[line:549] - INFO: 7000 / 9351
2022-10-12 08:03:18 - train.py[line:551] - INFO: load:1.70 valid_run:2930.93 task_valid:2800.03 collect_output:92.61
2022-10-12 08:04:42 - train.py[line:549] - INFO: 7200 / 9351
2022-10-12 08:04:42 - train.py[line:551] - INFO: load:1.73 valid_run:3014.82 task_valid:2880.43 collect_output:94.85
2022-10-12 08:06:06 - train.py[line:549] - INFO: 7400 / 9351
2022-10-12 08:06:06 - train.py[line:551] - INFO: load:1.76 valid_run:3099.14 task_valid:2960.31 collect_output:98.01
2022-10-12 08:07:33 - train.py[line:549] - INFO: 7600 / 9351
2022-10-12 08:07:33 - train.py[line:551] - INFO: load:1.78 valid_run:3185.81 task_valid:3041.53 collect_output:102.21
2022-10-12 08:09:00 - train.py[line:549] - INFO: 7800 / 9351
2022-10-12 08:09:00 - train.py[line:551] - INFO: load:1.80 valid_run:3272.79 task_valid:3122.57 collect_output:106.90
2022-10-12 08:10:24 - train.py[line:549] - INFO: 8000 / 9351
2022-10-12 08:10:24 - train.py[line:551] - INFO: load:1.83 valid_run:3356.82 task_valid:3201.45 collect_output:110.84
2022-10-12 08:11:49 - train.py[line:549] - INFO: 8200 / 9351
2022-10-12 08:11:49 - train.py[line:551] - INFO: load:1.85 valid_run:3441.99 task_valid:3283.42 collect_output:112.87
2022-10-12 08:13:14 - train.py[line:549] - INFO: 8400 / 9351
2022-10-12 08:13:14 - train.py[line:551] - INFO: load:1.87 valid_run:3526.98 task_valid:3365.31 collect_output:114.80
2022-10-12 08:14:38 - train.py[line:549] - INFO: 8600 / 9351
2022-10-12 08:14:38 - train.py[line:551] - INFO: load:1.89 valid_run:3611.13 task_valid:3445.69 collect_output:117.47
2022-10-12 08:16:03 - train.py[line:549] - INFO: 8800 / 9351
2022-10-12 08:16:03 - train.py[line:551] - INFO: load:1.92 valid_run:3695.40 task_valid:3525.33 collect_output:121.03
2022-10-12 08:17:27 - train.py[line:549] - INFO: 9000 / 9351
2022-10-12 08:17:27 - train.py[line:551] - INFO: load:1.94 valid_run:3779.49 task_valid:3607.26 collect_output:122.12
2022-10-12 08:18:50 - train.py[line:549] - INFO: 9200 / 9351
2022-10-12 08:18:50 - train.py[line:551] - INFO: load:1.96 valid_run:3863.18 task_valid:3688.33 collect_output:123.68

====================================================================================================
SGG eval:     R @ 50: 0.6663;     R @ 100: 0.6876;     R @ 500: 0.7111;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4539;    mR @ 100: 0.4691;    mR @ 500: 0.5274;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9500) (says:0.0000) (sitting on:0.7551) (standing on:0.4093) (using:0.6000) (walking in:0.0000) (walking on:0.6892) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6663;     R @ 100: 0.6876;     R @ 500: 0.7111;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4539;    mR @ 100: 0.4691;    mR @ 500: 0.5274;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9500) (says:0.0000) (sitting on:0.7551) (standing on:0.4093) (using:0.6000) (walking in:0.0000) (walking on:0.6892) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-12 08:20:04 - train.py[line:487] - INFO: 0.6876134453781513
2022-10-12 08:20:04 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 08:20:04 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.354 | loss_v1 0 | loss_v2 0 | nll_loss 0.201 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.687613 | ppl 1.15 | vqa_score 0.589 | wps 113.9 | wpb 48 | bsz 16 | num_updates 9000 | best_R@100 0.69991
2022-10-12 08:20:04 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 9000 updates
2022-10-12 08:20:04 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_9000.pt
2022-10-12 08:20:11 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_9000.pt
2022-10-12 08:20:13 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 0.6876134453781513) (writing took 8.64563750801608 seconds)
2022-10-12 08:20:25 - progress_bar.py[line:274] - INFO: epoch 001:   9023 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=0.3, ups=0, wpb=110.2, bsz=40, num_updates=9010, lr=7.79142e-06, gnorm=1.177, clip=100, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=53082
2022-10-12 08:20:37 - progress_bar.py[line:274] - INFO: epoch 001:   9033 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.8, ups=0.85, wpb=110.7, bsz=40, num_updates=9020, lr=7.80007e-06, gnorm=1.13, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53094
2022-10-12 08:20:49 - progress_bar.py[line:274] - INFO: epoch 001:   9043 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.83, wpb=111.1, bsz=40, num_updates=9030, lr=7.80872e-06, gnorm=1.283, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=53106
2022-10-12 08:21:01 - progress_bar.py[line:274] - INFO: epoch 001:   9053 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.7, ups=0.83, wpb=110.1, bsz=40, num_updates=9040, lr=7.81736e-06, gnorm=1.137, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53118
2022-10-12 08:21:13 - progress_bar.py[line:274] - INFO: epoch 001:   9063 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.5, ups=0.85, wpb=110.9, bsz=40, num_updates=9050, lr=7.82601e-06, gnorm=1.178, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53130
2022-10-12 08:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   9073 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.84, wpb=109, bsz=40, num_updates=9060, lr=7.83466e-06, gnorm=1.13, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53142
2022-10-12 08:21:37 - progress_bar.py[line:274] - INFO: epoch 001:   9083 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.8, ups=0.85, wpb=109.3, bsz=40, num_updates=9070, lr=7.84331e-06, gnorm=1.242, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53153
2022-10-12 08:21:49 - progress_bar.py[line:274] - INFO: epoch 001:   9093 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=91.6, ups=0.83, wpb=110.7, bsz=40, num_updates=9080, lr=7.85195e-06, gnorm=1.166, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53165
2022-10-12 08:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   9103 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.85, wpb=108.9, bsz=40, num_updates=9090, lr=7.8606e-06, gnorm=1.187, clip=70, loss_scale=512, train_wall=12, gb_free=22.5, ema_decay=0.9999, wall=53177
2022-10-12 08:22:13 - progress_bar.py[line:274] - INFO: epoch 001:   9113 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.83, wpb=108.8, bsz=40, num_updates=9100, lr=7.86925e-06, gnorm=1.301, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53189
2022-10-12 08:22:25 - progress_bar.py[line:274] - INFO: epoch 001:   9123 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.9, ups=0.84, wpb=109.9, bsz=40, num_updates=9110, lr=7.8779e-06, gnorm=1.287, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53201
2022-10-12 08:22:36 - progress_bar.py[line:274] - INFO: epoch 001:   9133 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.1, ups=0.87, wpb=111.3, bsz=40, num_updates=9120, lr=7.88654e-06, gnorm=1.207, clip=90, loss_scale=512, train_wall=11, gb_free=22.7, ema_decay=0.9999, wall=53213
2022-10-12 08:22:48 - progress_bar.py[line:274] - INFO: epoch 001:   9143 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.5, ups=0.85, wpb=112.2, bsz=40, num_updates=9130, lr=7.89519e-06, gnorm=1.319, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53224
2022-10-12 08:22:59 - progress_bar.py[line:274] - INFO: epoch 001:   9153 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.4, ups=0.87, wpb=110.7, bsz=40, num_updates=9140, lr=7.90384e-06, gnorm=1.268, clip=100, loss_scale=512, train_wall=11, gb_free=22.7, ema_decay=0.9999, wall=53236
2022-10-12 08:23:11 - progress_bar.py[line:274] - INFO: epoch 001:   9163 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.1, ups=0.84, wpb=110.2, bsz=40, num_updates=9150, lr=7.91249e-06, gnorm=1.187, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53248
2022-10-12 08:23:23 - progress_bar.py[line:274] - INFO: epoch 001:   9173 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.84, wpb=111, bsz=40, num_updates=9160, lr=7.92113e-06, gnorm=1.207, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53260
2022-10-12 08:23:35 - progress_bar.py[line:274] - INFO: epoch 001:   9183 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.84, wpb=109.2, bsz=40, num_updates=9170, lr=7.92978e-06, gnorm=1.187, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53272
2022-10-12 08:23:47 - progress_bar.py[line:274] - INFO: epoch 001:   9193 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.8, ups=0.85, wpb=110.3, bsz=40, num_updates=9180, lr=7.93843e-06, gnorm=1.051, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53284
2022-10-12 08:23:59 - progress_bar.py[line:274] - INFO: epoch 001:   9203 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.5, ups=0.84, wpb=110.5, bsz=40, num_updates=9190, lr=7.94708e-06, gnorm=1.185, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53295
2022-10-12 08:24:11 - progress_bar.py[line:274] - INFO: epoch 001:   9213 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.1, ups=0.84, wpb=109.9, bsz=40, num_updates=9200, lr=7.95572e-06, gnorm=1.076, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53307
2022-10-12 08:24:22 - progress_bar.py[line:274] - INFO: epoch 001:   9223 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.9, ups=0.85, wpb=109.1, bsz=40, num_updates=9210, lr=7.96437e-06, gnorm=1.159, clip=70, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=53319
2022-10-12 08:24:34 - progress_bar.py[line:274] - INFO: epoch 001:   9233 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.7, ups=0.84, wpb=110.1, bsz=40, num_updates=9220, lr=7.97302e-06, gnorm=1.107, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53331
2022-10-12 08:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   9243 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.8, ups=0.85, wpb=112, bsz=40, num_updates=9230, lr=7.98167e-06, gnorm=1.107, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53343
2022-10-12 08:24:59 - progress_bar.py[line:274] - INFO: epoch 001:   9253 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.82, wpb=111, bsz=40, num_updates=9240, lr=7.99031e-06, gnorm=1.181, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=53355
2022-10-12 08:25:11 - progress_bar.py[line:274] - INFO: epoch 001:   9263 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.9, ups=0.85, wpb=109.9, bsz=40, num_updates=9250, lr=7.99896e-06, gnorm=1.003, clip=40, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53367
2022-10-12 08:25:22 - progress_bar.py[line:274] - INFO: epoch 001:   9273 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.2, ups=0.85, wpb=110.8, bsz=40, num_updates=9260, lr=8.00761e-06, gnorm=1.041, clip=50, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53379
2022-10-12 08:25:34 - progress_bar.py[line:274] - INFO: epoch 001:   9283 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.7, ups=0.85, wpb=109.4, bsz=40, num_updates=9270, lr=8.01626e-06, gnorm=1.142, clip=60, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=53391
2022-10-12 08:25:46 - progress_bar.py[line:274] - INFO: epoch 001:   9293 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.9, ups=0.87, wpb=109.2, bsz=40, num_updates=9280, lr=8.0249e-06, gnorm=1.11, clip=90, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=53402
2022-10-12 08:25:58 - progress_bar.py[line:274] - INFO: epoch 001:   9303 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.1, ups=0.84, wpb=110.1, bsz=40, num_updates=9290, lr=8.03355e-06, gnorm=1.231, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53414
2022-10-12 08:26:09 - progress_bar.py[line:274] - INFO: epoch 001:   9313 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.5, ups=0.84, wpb=110.6, bsz=40, num_updates=9300, lr=8.0422e-06, gnorm=1.139, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53426
2022-10-12 08:26:21 - progress_bar.py[line:274] - INFO: epoch 001:   9323 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.2, ups=0.85, wpb=110.4, bsz=40, num_updates=9310, lr=8.05085e-06, gnorm=1.197, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=53438
2022-10-12 08:26:33 - progress_bar.py[line:274] - INFO: epoch 001:   9333 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.8, ups=0.82, wpb=111.7, bsz=40, num_updates=9320, lr=8.05949e-06, gnorm=1.184, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=53450
2022-10-12 08:26:45 - progress_bar.py[line:274] - INFO: epoch 001:   9343 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.9, ups=0.86, wpb=110.6, bsz=40, num_updates=9330, lr=8.06814e-06, gnorm=1.225, clip=70, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=53462
2022-10-12 08:26:57 - progress_bar.py[line:274] - INFO: epoch 001:   9353 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.4, ups=0.85, wpb=111, bsz=40, num_updates=9340, lr=8.07679e-06, gnorm=1.158, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53474
2022-10-12 08:27:09 - progress_bar.py[line:274] - INFO: epoch 001:   9363 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.2, ups=0.85, wpb=110.2, bsz=40, num_updates=9350, lr=8.08544e-06, gnorm=1.209, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53485
2022-10-12 08:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   9373 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.7, ups=0.84, wpb=110.4, bsz=40, num_updates=9360, lr=8.09409e-06, gnorm=1.101, clip=80, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53497
2022-10-12 08:27:32 - progress_bar.py[line:274] - INFO: epoch 001:   9383 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.1, ups=0.84, wpb=110.7, bsz=40, num_updates=9370, lr=8.10273e-06, gnorm=1.155, clip=90, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53509
2022-10-12 08:27:44 - progress_bar.py[line:274] - INFO: epoch 001:   9393 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=93.3, ups=0.84, wpb=111.1, bsz=40, num_updates=9380, lr=8.11138e-06, gnorm=1.166, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53521
2022-10-12 08:27:56 - progress_bar.py[line:274] - INFO: epoch 001:   9403 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.5, ups=0.84, wpb=109.5, bsz=40, num_updates=9390, lr=8.12003e-06, gnorm=1.285, clip=100, loss_scale=1024, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=53533
2022-10-12 08:28:09 - progress_bar.py[line:274] - INFO: epoch 001:   9413 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.9, ups=0.85, wpb=111.4, bsz=40, num_updates=9400, lr=8.12868e-06, gnorm=1.156, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53545
2022-10-12 08:28:10 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 08:28:22 - progress_bar.py[line:274] - INFO: epoch 001:   9424 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=86.1, ups=0.78, wpb=110.3, bsz=40, num_updates=9410, lr=8.13732e-06, gnorm=1.177, clip=70, loss_scale=512, train_wall=13, gb_free=23, ema_decay=0.9999, wall=53558
2022-10-12 08:28:34 - progress_bar.py[line:274] - INFO: epoch 001:   9434 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.84, wpb=109.4, bsz=40, num_updates=9420, lr=8.14597e-06, gnorm=1.237, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53570
2022-10-12 08:28:45 - progress_bar.py[line:274] - INFO: epoch 001:   9444 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.1, ups=0.84, wpb=112, bsz=40, num_updates=9430, lr=8.15462e-06, gnorm=1.299, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53582
2022-10-12 08:28:57 - progress_bar.py[line:274] - INFO: epoch 001:   9454 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.2, ups=0.85, wpb=109.5, bsz=40, num_updates=9440, lr=8.16327e-06, gnorm=1.148, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53594
2022-10-12 08:29:09 - progress_bar.py[line:274] - INFO: epoch 001:   9464 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.4, ups=0.85, wpb=110.6, bsz=40, num_updates=9450, lr=8.17191e-06, gnorm=1.061, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53606
2022-10-12 08:29:21 - progress_bar.py[line:274] - INFO: epoch 001:   9474 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95, ups=0.85, wpb=111.2, bsz=40, num_updates=9460, lr=8.18056e-06, gnorm=1.163, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53617
2022-10-12 08:29:32 - progress_bar.py[line:274] - INFO: epoch 001:   9484 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.9, ups=0.85, wpb=110, bsz=40, num_updates=9470, lr=8.18921e-06, gnorm=1.207, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53629
2022-10-12 08:29:44 - progress_bar.py[line:274] - INFO: epoch 001:   9494 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.83, wpb=109.7, bsz=40, num_updates=9480, lr=8.19786e-06, gnorm=1.184, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53641
2022-10-12 08:29:57 - progress_bar.py[line:274] - INFO: epoch 001:   9504 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.1, ups=0.83, wpb=111, bsz=40, num_updates=9490, lr=8.2065e-06, gnorm=1.152, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53653
2022-10-12 08:30:09 - progress_bar.py[line:274] - INFO: epoch 001:   9514 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.1, ups=0.84, wpb=111.2, bsz=40, num_updates=9500, lr=8.21515e-06, gnorm=1.062, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53665
2022-10-12 08:30:20 - progress_bar.py[line:274] - INFO: epoch 001:   9524 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.3, ups=0.86, wpb=109, bsz=40, num_updates=9510, lr=8.2238e-06, gnorm=1.175, clip=100, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53677
2022-10-12 08:30:32 - progress_bar.py[line:274] - INFO: epoch 001:   9534 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.8, ups=0.83, wpb=110.6, bsz=40, num_updates=9520, lr=8.23245e-06, gnorm=1.074, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53689
2022-10-12 08:30:44 - progress_bar.py[line:274] - INFO: epoch 001:   9544 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.3, ups=0.85, wpb=110.6, bsz=40, num_updates=9530, lr=8.24109e-06, gnorm=1.113, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53701
2022-10-12 08:30:56 - progress_bar.py[line:274] - INFO: epoch 001:   9554 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.1, ups=0.83, wpb=111.2, bsz=40, num_updates=9540, lr=8.24974e-06, gnorm=1.256, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53713
2022-10-12 08:31:08 - progress_bar.py[line:274] - INFO: epoch 001:   9564 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.3, ups=0.87, wpb=110.4, bsz=40, num_updates=9550, lr=8.25839e-06, gnorm=1.236, clip=100, loss_scale=512, train_wall=11, gb_free=22.7, ema_decay=0.9999, wall=53724
2022-10-12 08:31:20 - progress_bar.py[line:274] - INFO: epoch 001:   9574 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.84, wpb=110.1, bsz=40, num_updates=9560, lr=8.26704e-06, gnorm=1.153, clip=70, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=53736
2022-10-12 08:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   9584 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.7, ups=0.85, wpb=110, bsz=40, num_updates=9570, lr=8.27568e-06, gnorm=1.208, clip=90, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=53749
2022-10-12 08:31:44 - progress_bar.py[line:274] - INFO: epoch 001:   9594 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.6, ups=0.85, wpb=109.2, bsz=40, num_updates=9580, lr=8.28433e-06, gnorm=1.168, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53760
2022-10-12 08:31:55 - progress_bar.py[line:274] - INFO: epoch 001:   9604 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.9, ups=0.85, wpb=110.5, bsz=40, num_updates=9590, lr=8.29298e-06, gnorm=1.144, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=53772
2022-10-12 08:32:07 - progress_bar.py[line:274] - INFO: epoch 001:   9614 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.7, ups=0.85, wpb=109.6, bsz=40, num_updates=9600, lr=8.30163e-06, gnorm=1.169, clip=90, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=53784
2022-10-12 08:32:19 - progress_bar.py[line:274] - INFO: epoch 001:   9624 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.8, ups=0.84, wpb=111.2, bsz=40, num_updates=9610, lr=8.31027e-06, gnorm=1.195, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53796
2022-10-12 08:32:31 - progress_bar.py[line:274] - INFO: epoch 001:   9634 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94, ups=0.85, wpb=110, bsz=40, num_updates=9620, lr=8.31892e-06, gnorm=1.039, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53807
2022-10-12 08:32:43 - progress_bar.py[line:274] - INFO: epoch 001:   9644 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.7, ups=0.83, wpb=110.7, bsz=40, num_updates=9630, lr=8.32757e-06, gnorm=1.135, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53820
2022-10-12 08:32:55 - progress_bar.py[line:274] - INFO: epoch 001:   9654 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.84, wpb=110, bsz=40, num_updates=9640, lr=8.33622e-06, gnorm=1.239, clip=90, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=53831
2022-10-12 08:33:06 - progress_bar.py[line:274] - INFO: epoch 001:   9664 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.85, wpb=108.6, bsz=40, num_updates=9650, lr=8.34486e-06, gnorm=1.289, clip=80, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=53843
2022-10-12 08:33:19 - progress_bar.py[line:274] - INFO: epoch 001:   9674 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.82, wpb=110.7, bsz=40, num_updates=9660, lr=8.35351e-06, gnorm=1.125, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53855
2022-10-12 08:33:31 - progress_bar.py[line:274] - INFO: epoch 001:   9684 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.5, ups=0.84, wpb=110.6, bsz=40, num_updates=9670, lr=8.36216e-06, gnorm=1.246, clip=100, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=53867
2022-10-12 08:33:42 - progress_bar.py[line:274] - INFO: epoch 001:   9694 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.4, ups=0.85, wpb=108.2, bsz=40, num_updates=9680, lr=8.37081e-06, gnorm=1.149, clip=90, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=53879
2022-10-12 08:33:54 - progress_bar.py[line:274] - INFO: epoch 001:   9704 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.5, ups=0.86, wpb=110.4, bsz=40, num_updates=9690, lr=8.37945e-06, gnorm=1.144, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53891
2022-10-12 08:34:06 - progress_bar.py[line:274] - INFO: epoch 001:   9714 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=94.5, ups=0.86, wpb=110.4, bsz=40, num_updates=9700, lr=8.3881e-06, gnorm=1.002, clip=30, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53902
2022-10-12 08:34:17 - progress_bar.py[line:274] - INFO: epoch 001:   9724 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95, ups=0.85, wpb=111.2, bsz=40, num_updates=9710, lr=8.39675e-06, gnorm=1.219, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53914
2022-10-12 08:34:29 - progress_bar.py[line:274] - INFO: epoch 001:   9734 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.1, ups=0.85, wpb=108.7, bsz=40, num_updates=9720, lr=8.4054e-06, gnorm=1.191, clip=70, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=53926
2022-10-12 08:34:41 - progress_bar.py[line:274] - INFO: epoch 001:   9744 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.84, wpb=108.4, bsz=40, num_updates=9730, lr=8.41404e-06, gnorm=1.296, clip=100, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=53938
2022-10-12 08:34:53 - progress_bar.py[line:274] - INFO: epoch 001:   9754 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=93.2, ups=0.84, wpb=110.6, bsz=40, num_updates=9740, lr=8.42269e-06, gnorm=1.173, clip=90, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=53950
2022-10-12 08:35:05 - progress_bar.py[line:274] - INFO: epoch 001:   9764 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.3, ups=0.83, wpb=109.6, bsz=40, num_updates=9750, lr=8.43134e-06, gnorm=1.078, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53962
2022-10-12 08:35:17 - progress_bar.py[line:274] - INFO: epoch 001:   9774 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.8, ups=0.84, wpb=110.3, bsz=40, num_updates=9760, lr=8.43999e-06, gnorm=1.085, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53974
2022-10-12 08:35:29 - progress_bar.py[line:274] - INFO: epoch 001:   9784 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.8, ups=0.81, wpb=109.5, bsz=40, num_updates=9770, lr=8.44863e-06, gnorm=1.225, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=53986
2022-10-12 08:35:41 - progress_bar.py[line:274] - INFO: epoch 001:   9794 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.4, ups=0.84, wpb=110.6, bsz=40, num_updates=9780, lr=8.45728e-06, gnorm=1.223, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=53998
2022-10-12 08:35:53 - progress_bar.py[line:274] - INFO: epoch 001:   9804 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95, ups=0.85, wpb=111.9, bsz=40, num_updates=9790, lr=8.46593e-06, gnorm=1.108, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=54010
2022-10-12 08:36:05 - progress_bar.py[line:274] - INFO: epoch 001:   9814 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.3, ups=0.85, wpb=110.4, bsz=40, num_updates=9800, lr=8.47458e-06, gnorm=1.144, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=54022
2022-10-12 08:36:17 - progress_bar.py[line:274] - INFO: epoch 001:   9824 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.1, ups=0.84, wpb=111, bsz=40, num_updates=9810, lr=8.48322e-06, gnorm=1.115, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=54033
2022-10-12 08:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   9834 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.2, ups=0.86, wpb=110, bsz=40, num_updates=9820, lr=8.49187e-06, gnorm=1.242, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=54045
2022-10-12 08:36:40 - progress_bar.py[line:274] - INFO: epoch 001:   9844 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.4, ups=0.84, wpb=109.7, bsz=40, num_updates=9830, lr=8.50052e-06, gnorm=1.086, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=54057
2022-10-12 08:36:52 - progress_bar.py[line:274] - INFO: epoch 001:   9854 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.6, ups=0.84, wpb=108.7, bsz=40, num_updates=9840, lr=8.50917e-06, gnorm=1.257, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=54069
2022-10-12 08:37:04 - progress_bar.py[line:274] - INFO: epoch 001:   9864 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.1, ups=0.85, wpb=111.8, bsz=40, num_updates=9850, lr=8.51781e-06, gnorm=1.103, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=54081
2022-10-12 08:37:16 - progress_bar.py[line:274] - INFO: epoch 001:   9874 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.1, ups=0.85, wpb=111.5, bsz=40, num_updates=9860, lr=8.52646e-06, gnorm=1.241, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=54092
2022-10-12 08:37:28 - progress_bar.py[line:274] - INFO: epoch 001:   9884 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.8, ups=0.84, wpb=108.7, bsz=40, num_updates=9870, lr=8.53511e-06, gnorm=1.232, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=54104
2022-10-12 08:37:39 - progress_bar.py[line:274] - INFO: epoch 001:   9894 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.2, ups=0.85, wpb=111.9, bsz=40, num_updates=9880, lr=8.54376e-06, gnorm=1.158, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=54116
2022-10-12 08:37:51 - progress_bar.py[line:274] - INFO: epoch 001:   9904 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.6, ups=0.84, wpb=110.6, bsz=40, num_updates=9890, lr=8.5524e-06, gnorm=1.131, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=54128
2022-10-12 08:38:03 - progress_bar.py[line:274] - INFO: epoch 001:   9914 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.4, ups=0.86, wpb=110.7, bsz=40, num_updates=9900, lr=8.56105e-06, gnorm=1.143, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=54140
2022-10-12 08:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   9924 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.86, wpb=109, bsz=40, num_updates=9910, lr=8.5697e-06, gnorm=1.171, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=54151
2022-10-12 08:38:27 - progress_bar.py[line:274] - INFO: epoch 001:   9934 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.1, ups=0.84, wpb=110, bsz=40, num_updates=9920, lr=8.57835e-06, gnorm=1.193, clip=90, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=54163
2022-10-12 08:38:38 - progress_bar.py[line:274] - INFO: epoch 001:   9944 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.3, ups=0.86, wpb=111.2, bsz=40, num_updates=9930, lr=8.58699e-06, gnorm=1.138, clip=90, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=54175
2022-10-12 08:38:50 - progress_bar.py[line:274] - INFO: epoch 001:   9954 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.84, wpb=109.5, bsz=40, num_updates=9940, lr=8.59564e-06, gnorm=1.271, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=54187
2022-10-12 08:39:02 - progress_bar.py[line:274] - INFO: epoch 001:   9964 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.6, ups=0.84, wpb=110.5, bsz=40, num_updates=9950, lr=8.60429e-06, gnorm=1.127, clip=70, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=54199
2022-10-12 08:39:14 - progress_bar.py[line:274] - INFO: epoch 001:   9974 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.9, ups=0.84, wpb=110.6, bsz=40, num_updates=9960, lr=8.61294e-06, gnorm=1.17, clip=70, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=54211
2022-10-12 08:39:26 - progress_bar.py[line:274] - INFO: epoch 001:   9984 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.1, ups=0.86, wpb=110.1, bsz=40, num_updates=9970, lr=8.62158e-06, gnorm=1.181, clip=70, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=54223
2022-10-12 08:39:38 - progress_bar.py[line:274] - INFO: epoch 001:   9994 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.3, ups=0.84, wpb=110.3, bsz=40, num_updates=9980, lr=8.63023e-06, gnorm=1.116, clip=80, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=54235
2022-10-12 08:39:50 - progress_bar.py[line:274] - INFO: epoch 001:  10004 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.4, ups=0.84, wpb=109.7, bsz=40, num_updates=9990, lr=8.63888e-06, gnorm=1.157, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=54246
2022-10-12 08:40:02 - progress_bar.py[line:274] - INFO: epoch 001:  10014 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.4, ups=0.84, wpb=109.4, bsz=40, num_updates=10000, lr=8.64753e-06, gnorm=1.139, clip=70, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=54258
2022-10-12 08:40:02 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 08:40:03 - train.py[line:549] - INFO: 0 / 9351
2022-10-12 08:40:03 - train.py[line:551] - INFO: load:0.78 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 08:41:26 - train.py[line:549] - INFO: 200 / 9351
2022-10-12 08:41:26 - train.py[line:551] - INFO: load:0.80 valid_run:83.71 task_valid:81.13 collect_output:1.48
2022-10-12 08:42:50 - train.py[line:549] - INFO: 400 / 9351
2022-10-12 08:42:50 - train.py[line:551] - INFO: load:0.82 valid_run:167.39 task_valid:162.43 collect_output:2.80
2022-10-12 08:44:12 - train.py[line:549] - INFO: 600 / 9351
2022-10-12 08:44:12 - train.py[line:551] - INFO: load:0.84 valid_run:249.61 task_valid:241.38 collect_output:5.00
2022-10-12 08:45:36 - train.py[line:549] - INFO: 800 / 9351
2022-10-12 08:45:36 - train.py[line:551] - INFO: load:0.86 valid_run:332.97 task_valid:320.40 collect_output:8.25
2022-10-12 08:47:00 - train.py[line:549] - INFO: 1000 / 9351
2022-10-12 08:47:00 - train.py[line:551] - INFO: load:0.89 valid_run:417.25 task_valid:399.61 collect_output:12.26
2022-10-12 08:48:23 - train.py[line:549] - INFO: 1200 / 9351
2022-10-12 08:48:23 - train.py[line:551] - INFO: load:0.91 valid_run:500.51 task_valid:477.61 collect_output:16.45
2022-10-12 08:49:46 - train.py[line:549] - INFO: 1400 / 9351
2022-10-12 08:49:46 - train.py[line:551] - INFO: load:0.93 valid_run:583.52 task_valid:557.69 collect_output:18.32
2022-10-12 08:51:10 - train.py[line:549] - INFO: 1600 / 9351
2022-10-12 08:51:10 - train.py[line:551] - INFO: load:0.95 valid_run:667.41 task_valid:639.58 collect_output:19.24
2022-10-12 08:52:35 - train.py[line:549] - INFO: 1800 / 9351
2022-10-12 08:52:35 - train.py[line:551] - INFO: load:0.97 valid_run:751.97 task_valid:720.09 collect_output:22.24
2022-10-12 08:53:59 - train.py[line:549] - INFO: 2000 / 9351
2022-10-12 08:53:59 - train.py[line:551] - INFO: load:1.00 valid_run:836.06 task_valid:800.63 collect_output:24.70
2022-10-12 08:55:23 - train.py[line:549] - INFO: 2200 / 9351
2022-10-12 08:55:23 - train.py[line:551] - INFO: load:1.02 valid_run:920.21 task_valid:880.60 collect_output:27.78
2022-10-12 08:56:47 - train.py[line:549] - INFO: 2400 / 9351
2022-10-12 08:56:47 - train.py[line:551] - INFO: load:1.04 valid_run:1004.15 task_valid:961.16 collect_output:30.09
2022-10-12 08:58:12 - train.py[line:549] - INFO: 2600 / 9351
2022-10-12 08:58:12 - train.py[line:551] - INFO: load:1.06 valid_run:1089.00 task_valid:1041.23 collect_output:33.83
2022-10-12 08:59:37 - train.py[line:549] - INFO: 2800 / 9351
2022-10-12 08:59:37 - train.py[line:551] - INFO: load:1.08 valid_run:1173.22 task_valid:1120.10 collect_output:38.08
2022-10-12 09:01:01 - train.py[line:549] - INFO: 3000 / 9351
2022-10-12 09:01:01 - train.py[line:551] - INFO: load:1.11 valid_run:1257.43 task_valid:1198.30 collect_output:42.90
2022-10-12 09:02:24 - train.py[line:549] - INFO: 3200 / 9351
2022-10-12 09:02:24 - train.py[line:551] - INFO: load:1.13 valid_run:1340.99 task_valid:1278.27 collect_output:45.26
2022-10-12 09:03:50 - train.py[line:549] - INFO: 3400 / 9351
2022-10-12 09:03:50 - train.py[line:551] - INFO: load:1.15 valid_run:1426.00 task_valid:1358.71 collect_output:48.64
2022-10-12 09:05:14 - train.py[line:549] - INFO: 3600 / 9351
2022-10-12 09:05:14 - train.py[line:551] - INFO: load:1.17 valid_run:1510.37 task_valid:1439.92 collect_output:50.58
2022-10-12 09:06:37 - train.py[line:549] - INFO: 3800 / 9351
2022-10-12 09:06:37 - train.py[line:551] - INFO: load:1.19 valid_run:1593.64 task_valid:1518.30 collect_output:54.37
2022-10-12 09:08:01 - train.py[line:549] - INFO: 4000 / 9351
2022-10-12 09:08:01 - train.py[line:551] - INFO: load:1.23 valid_run:1677.14 task_valid:1598.26 collect_output:56.63
2022-10-12 09:09:26 - train.py[line:549] - INFO: 4200 / 9351
2022-10-12 09:09:26 - train.py[line:551] - INFO: load:1.25 valid_run:1762.17 task_valid:1680.88 collect_output:57.78
2022-10-12 09:10:51 - train.py[line:549] - INFO: 4400 / 9351
2022-10-12 09:10:51 - train.py[line:551] - INFO: load:1.28 valid_run:1847.34 task_valid:1761.95 collect_output:60.56
2022-10-12 09:12:15 - train.py[line:549] - INFO: 4600 / 9351
2022-10-12 09:12:15 - train.py[line:551] - INFO: load:1.30 valid_run:1931.14 task_valid:1841.76 collect_output:63.35
2022-10-12 09:13:40 - train.py[line:549] - INFO: 4800 / 9351
2022-10-12 09:13:40 - train.py[line:551] - INFO: load:1.32 valid_run:2016.19 task_valid:1921.03 collect_output:67.91
2022-10-12 09:15:05 - train.py[line:549] - INFO: 5000 / 9351
2022-10-12 09:15:05 - train.py[line:551] - INFO: load:1.35 valid_run:2101.41 task_valid:2002.88 collect_output:70.01
2022-10-12 09:16:30 - train.py[line:549] - INFO: 5200 / 9351
2022-10-12 09:16:30 - train.py[line:551] - INFO: load:1.37 valid_run:2185.98 task_valid:2083.74 collect_output:72.45
2022-10-12 09:17:54 - train.py[line:549] - INFO: 5400 / 9351
2022-10-12 09:17:54 - train.py[line:551] - INFO: load:1.39 valid_run:2270.16 task_valid:2164.70 collect_output:74.43
2022-10-12 09:19:20 - train.py[line:549] - INFO: 5600 / 9351
2022-10-12 09:19:20 - train.py[line:551] - INFO: load:1.42 valid_run:2355.35 task_valid:2246.70 collect_output:76.36
2022-10-12 09:20:43 - train.py[line:549] - INFO: 5800 / 9351
2022-10-12 09:20:43 - train.py[line:551] - INFO: load:1.44 valid_run:2439.01 task_valid:2326.41 collect_output:79.18
2022-10-12 09:22:07 - train.py[line:549] - INFO: 6000 / 9351
2022-10-12 09:22:07 - train.py[line:551] - INFO: load:1.46 valid_run:2522.47 task_valid:2406.74 collect_output:81.24
2022-10-12 09:23:31 - train.py[line:549] - INFO: 6200 / 9351
2022-10-12 09:23:31 - train.py[line:551] - INFO: load:1.49 valid_run:2606.20 task_valid:2486.98 collect_output:83.66
2022-10-12 09:24:56 - train.py[line:549] - INFO: 6400 / 9351
2022-10-12 09:24:56 - train.py[line:551] - INFO: load:1.51 valid_run:2691.11 task_valid:2568.24 collect_output:86.26
2022-10-12 09:26:20 - train.py[line:549] - INFO: 6600 / 9351
2022-10-12 09:26:20 - train.py[line:551] - INFO: load:1.53 valid_run:2775.18 task_valid:2650.02 collect_output:87.46
2022-10-12 09:27:43 - train.py[line:549] - INFO: 6800 / 9351
2022-10-12 09:27:43 - train.py[line:551] - INFO: load:1.55 valid_run:2858.81 task_valid:2730.36 collect_output:89.60
2022-10-12 09:29:06 - train.py[line:549] - INFO: 7000 / 9351
2022-10-12 09:29:06 - train.py[line:551] - INFO: load:1.58 valid_run:2941.63 task_valid:2809.23 collect_output:92.48
2022-10-12 09:30:29 - train.py[line:549] - INFO: 7200 / 9351
2022-10-12 09:30:29 - train.py[line:551] - INFO: load:1.60 valid_run:3024.53 task_valid:2889.24 collect_output:94.30
2022-10-12 09:31:52 - train.py[line:549] - INFO: 7400 / 9351
2022-10-12 09:31:52 - train.py[line:551] - INFO: load:1.62 valid_run:3107.79 task_valid:2968.19 collect_output:97.55
2022-10-12 09:33:18 - train.py[line:549] - INFO: 7600 / 9351
2022-10-12 09:33:18 - train.py[line:551] - INFO: load:1.65 valid_run:3193.27 task_valid:3048.59 collect_output:101.54
2022-10-12 09:34:43 - train.py[line:549] - INFO: 7800 / 9351
2022-10-12 09:34:43 - train.py[line:551] - INFO: load:1.67 valid_run:3278.07 task_valid:3129.05 collect_output:104.78
2022-10-12 09:36:06 - train.py[line:549] - INFO: 8000 / 9351
2022-10-12 09:36:06 - train.py[line:551] - INFO: load:1.69 valid_run:3361.04 task_valid:3207.59 collect_output:108.13
2022-10-12 09:37:30 - train.py[line:549] - INFO: 8200 / 9351
2022-10-12 09:37:30 - train.py[line:551] - INFO: load:1.71 valid_run:3444.80 task_valid:3288.82 collect_output:109.56
2022-10-12 09:38:54 - train.py[line:549] - INFO: 8400 / 9351
2022-10-12 09:38:54 - train.py[line:551] - INFO: load:1.74 valid_run:3528.61 task_valid:3370.00 collect_output:111.13
2022-10-12 09:40:18 - train.py[line:549] - INFO: 8600 / 9351
2022-10-12 09:40:18 - train.py[line:551] - INFO: load:1.76 valid_run:3612.61 task_valid:3450.24 collect_output:113.82
2022-10-12 09:41:41 - train.py[line:549] - INFO: 8800 / 9351
2022-10-12 09:41:41 - train.py[line:551] - INFO: load:1.78 valid_run:3696.20 task_valid:3529.51 collect_output:117.08
2022-10-12 09:43:05 - train.py[line:549] - INFO: 9000 / 9351
2022-10-12 09:43:05 - train.py[line:551] - INFO: load:1.80 valid_run:3780.12 task_valid:3611.35 collect_output:118.11
2022-10-12 09:44:29 - train.py[line:549] - INFO: 9200 / 9351
2022-10-12 09:44:29 - train.py[line:551] - INFO: load:1.83 valid_run:3863.61 task_valid:3692.26 collect_output:119.61

====================================================================================================
SGG eval:     R @ 50: 0.6616;     R @ 100: 0.6877;     R @ 500: 0.7063;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4466;    mR @ 100: 0.4666;    mR @ 500: 0.5218;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.4355) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9598) (says:0.0000) (sitting on:0.7466) (standing on:0.3927) (using:0.6000) (walking in:0.0000) (walking on:0.6892) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6616;     R @ 100: 0.6877;     R @ 500: 0.7063;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4466;    mR @ 100: 0.4666;    mR @ 500: 0.5218;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.4355) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9598) (says:0.0000) (sitting on:0.7466) (standing on:0.3927) (using:0.6000) (walking in:0.0000) (walking on:0.6892) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-12 09:45:43 - train.py[line:487] - INFO: 0.6876624649859944
2022-10-12 09:45:43 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 09:45:43 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.34 | loss_v1 0 | loss_v2 0 | nll_loss 0.184 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.687662 | ppl 1.14 | vqa_score 0.5901 | wps 113.8 | wpb 48 | bsz 16 | num_updates 10000 | best_R@100 0.69991
2022-10-12 09:45:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2022-10-12 09:45:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_10000.pt
2022-10-12 09:45:49 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_10000.pt
2022-10-12 09:45:52 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.6876624649859944) (writing took 8.36066536931321 seconds)
2022-10-12 09:46:06 - progress_bar.py[line:274] - INFO: epoch 001:  10024 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=0.3, ups=0, wpb=109.5, bsz=40, num_updates=10010, lr=8.65617e-06, gnorm=1.115, clip=90, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58221
2022-10-12 09:46:18 - progress_bar.py[line:274] - INFO: epoch 001:  10034 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.5, ups=0.82, wpb=110.5, bsz=40, num_updates=10020, lr=8.66482e-06, gnorm=1.081, clip=80, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58234
2022-10-12 09:46:30 - progress_bar.py[line:274] - INFO: epoch 001:  10044 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.6, ups=0.83, wpb=111, bsz=40, num_updates=10030, lr=8.67347e-06, gnorm=1.104, clip=70, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58246
2022-10-12 09:46:42 - progress_bar.py[line:274] - INFO: epoch 001:  10054 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.2, ups=0.84, wpb=110.2, bsz=40, num_updates=10040, lr=8.68212e-06, gnorm=1.143, clip=70, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58258
2022-10-12 09:46:53 - progress_bar.py[line:274] - INFO: epoch 001:  10064 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.3, ups=0.86, wpb=111.1, bsz=40, num_updates=10050, lr=8.69076e-06, gnorm=1.038, clip=50, loss_scale=1024, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58270
2022-10-12 09:47:05 - progress_bar.py[line:274] - INFO: epoch 001:  10074 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.86, wpb=109, bsz=40, num_updates=10060, lr=8.69941e-06, gnorm=1.155, clip=80, loss_scale=1024, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58282
2022-10-12 09:47:17 - progress_bar.py[line:274] - INFO: epoch 001:  10084 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.8, ups=0.85, wpb=110.9, bsz=40, num_updates=10070, lr=8.70806e-06, gnorm=1.158, clip=80, loss_scale=1024, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58293
2022-10-12 09:47:29 - progress_bar.py[line:274] - INFO: epoch 001:  10094 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.83, wpb=110.3, bsz=40, num_updates=10080, lr=8.71671e-06, gnorm=1.171, clip=90, loss_scale=1024, train_wall=12, gb_free=23, ema_decay=0.9999, wall=58306
2022-10-12 09:47:31 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-12 09:47:41 - progress_bar.py[line:274] - INFO: epoch 001:  10105 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.4, ups=0.8, wpb=109.4, bsz=40, num_updates=10090, lr=8.72535e-06, gnorm=1.242, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58318
2022-10-12 09:47:53 - progress_bar.py[line:274] - INFO: epoch 001:  10115 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.86, wpb=108.9, bsz=40, num_updates=10100, lr=8.734e-06, gnorm=1.282, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58330
2022-10-12 09:48:05 - progress_bar.py[line:274] - INFO: epoch 001:  10125 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.1, ups=0.84, wpb=109.6, bsz=40, num_updates=10110, lr=8.74265e-06, gnorm=1.244, clip=100, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=58342
2022-10-12 09:48:17 - progress_bar.py[line:274] - INFO: epoch 001:  10135 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.8, ups=0.85, wpb=111, bsz=40, num_updates=10120, lr=8.7513e-06, gnorm=1.037, clip=40, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=58353
2022-10-12 09:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  10145 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.8, ups=0.85, wpb=111, bsz=40, num_updates=10130, lr=8.75994e-06, gnorm=1.172, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58366
2022-10-12 09:48:41 - progress_bar.py[line:274] - INFO: epoch 001:  10155 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.3, ups=0.84, wpb=110.4, bsz=40, num_updates=10140, lr=8.76859e-06, gnorm=1.184, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58378
2022-10-12 09:48:53 - progress_bar.py[line:274] - INFO: epoch 001:  10165 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.6, ups=0.87, wpb=111.6, bsz=40, num_updates=10150, lr=8.77724e-06, gnorm=1.161, clip=80, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=58389
2022-10-12 09:49:04 - progress_bar.py[line:274] - INFO: epoch 001:  10175 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.5, ups=0.84, wpb=110.4, bsz=40, num_updates=10160, lr=8.78589e-06, gnorm=1.194, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58401
2022-10-12 09:49:16 - progress_bar.py[line:274] - INFO: epoch 001:  10185 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.4, ups=0.84, wpb=110.1, bsz=40, num_updates=10170, lr=8.79453e-06, gnorm=1.068, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58413
2022-10-12 09:49:28 - progress_bar.py[line:274] - INFO: epoch 001:  10195 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.2, ups=0.84, wpb=111.5, bsz=40, num_updates=10180, lr=8.80318e-06, gnorm=1.063, clip=40, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=58425
2022-10-12 09:49:40 - progress_bar.py[line:274] - INFO: epoch 001:  10205 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.3, ups=0.85, wpb=111.5, bsz=40, num_updates=10190, lr=8.81183e-06, gnorm=1.136, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58437
2022-10-12 09:49:52 - progress_bar.py[line:274] - INFO: epoch 001:  10215 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.1, ups=0.86, wpb=110.5, bsz=40, num_updates=10200, lr=8.82048e-06, gnorm=1.236, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58449
2022-10-12 09:50:04 - progress_bar.py[line:274] - INFO: epoch 001:  10225 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.6, ups=0.85, wpb=110.1, bsz=40, num_updates=10210, lr=8.82912e-06, gnorm=1.164, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=58460
2022-10-12 09:50:16 - progress_bar.py[line:274] - INFO: epoch 001:  10235 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.6, ups=0.83, wpb=110.3, bsz=40, num_updates=10220, lr=8.83777e-06, gnorm=1.176, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58472
2022-10-12 09:50:28 - progress_bar.py[line:274] - INFO: epoch 001:  10245 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.7, ups=0.84, wpb=110.4, bsz=40, num_updates=10230, lr=8.84642e-06, gnorm=1.106, clip=50, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58484
2022-10-12 09:50:40 - progress_bar.py[line:274] - INFO: epoch 001:  10255 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.8, ups=0.83, wpb=110.7, bsz=40, num_updates=10240, lr=8.85507e-06, gnorm=1.144, clip=60, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58496
2022-10-12 09:50:51 - progress_bar.py[line:274] - INFO: epoch 001:  10265 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.9, ups=0.86, wpb=110.4, bsz=40, num_updates=10250, lr=8.86371e-06, gnorm=1.207, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58508
2022-10-12 09:51:03 - progress_bar.py[line:274] - INFO: epoch 001:  10275 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.4, ups=0.86, wpb=109, bsz=40, num_updates=10260, lr=8.87236e-06, gnorm=1.094, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58520
2022-10-12 09:51:15 - progress_bar.py[line:274] - INFO: epoch 001:  10285 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.9, ups=0.85, wpb=111.7, bsz=40, num_updates=10270, lr=8.88101e-06, gnorm=1.135, clip=80, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=58531
2022-10-12 09:51:26 - progress_bar.py[line:274] - INFO: epoch 001:  10295 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.2, ups=0.86, wpb=110.6, bsz=40, num_updates=10280, lr=8.88966e-06, gnorm=1.122, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58543
2022-10-12 09:51:38 - progress_bar.py[line:274] - INFO: epoch 001:  10305 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.83, wpb=110.8, bsz=40, num_updates=10290, lr=8.89831e-06, gnorm=1.107, clip=50, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58555
2022-10-12 09:51:50 - progress_bar.py[line:274] - INFO: epoch 001:  10315 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.1, ups=0.84, wpb=110.3, bsz=40, num_updates=10300, lr=8.90695e-06, gnorm=1.233, clip=100, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58567
2022-10-12 09:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  10325 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.4, ups=0.84, wpb=110.9, bsz=40, num_updates=10310, lr=8.9156e-06, gnorm=1.119, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58579
2022-10-12 09:52:14 - progress_bar.py[line:274] - INFO: epoch 001:  10335 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95, ups=0.85, wpb=112, bsz=40, num_updates=10320, lr=8.92425e-06, gnorm=1.198, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=58591
2022-10-12 09:52:25 - progress_bar.py[line:274] - INFO: epoch 001:  10345 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=10330, lr=8.9329e-06, gnorm=1.163, clip=70, loss_scale=512, train_wall=11, gb_free=22.9, ema_decay=0.9999, wall=58602
2022-10-12 09:52:37 - progress_bar.py[line:274] - INFO: epoch 001:  10355 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.1, ups=0.85, wpb=110.1, bsz=40, num_updates=10340, lr=8.94154e-06, gnorm=1.288, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58614
2022-10-12 09:52:49 - progress_bar.py[line:274] - INFO: epoch 001:  10365 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.85, wpb=109.6, bsz=40, num_updates=10350, lr=8.95019e-06, gnorm=1.255, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58626
2022-10-12 09:53:01 - progress_bar.py[line:274] - INFO: epoch 001:  10375 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.1, ups=0.86, wpb=108.6, bsz=40, num_updates=10360, lr=8.95884e-06, gnorm=1.267, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58637
2022-10-12 09:53:12 - progress_bar.py[line:274] - INFO: epoch 001:  10385 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.5, ups=0.85, wpb=111.2, bsz=40, num_updates=10370, lr=8.96749e-06, gnorm=1.1, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58649
2022-10-12 09:53:24 - progress_bar.py[line:274] - INFO: epoch 001:  10395 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.4, ups=0.85, wpb=110.7, bsz=40, num_updates=10380, lr=8.97613e-06, gnorm=1.145, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58661
2022-10-12 09:53:36 - progress_bar.py[line:274] - INFO: epoch 001:  10405 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.1, ups=0.85, wpb=109.1, bsz=40, num_updates=10390, lr=8.98478e-06, gnorm=1.148, clip=60, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58673
2022-10-12 09:53:48 - progress_bar.py[line:274] - INFO: epoch 001:  10415 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.6, ups=0.84, wpb=111, bsz=40, num_updates=10400, lr=8.99343e-06, gnorm=1.189, clip=100, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=58684
2022-10-12 09:53:59 - progress_bar.py[line:274] - INFO: epoch 001:  10425 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.1, ups=0.86, wpb=110.4, bsz=40, num_updates=10410, lr=9.00208e-06, gnorm=1.125, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58696
2022-10-12 09:54:11 - progress_bar.py[line:274] - INFO: epoch 001:  10435 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94, ups=0.85, wpb=110.1, bsz=40, num_updates=10420, lr=9.01072e-06, gnorm=1.305, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58708
2022-10-12 09:54:23 - progress_bar.py[line:274] - INFO: epoch 001:  10445 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=94.5, ups=0.85, wpb=111.6, bsz=40, num_updates=10430, lr=9.01937e-06, gnorm=1.096, clip=70, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58720
2022-10-12 09:54:35 - progress_bar.py[line:274] - INFO: epoch 001:  10455 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.3, ups=0.84, wpb=109.7, bsz=40, num_updates=10440, lr=9.02802e-06, gnorm=1.219, clip=100, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58731
2022-10-12 09:54:47 - progress_bar.py[line:274] - INFO: epoch 001:  10465 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.4, ups=0.84, wpb=110.8, bsz=40, num_updates=10450, lr=9.03667e-06, gnorm=1.151, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58743
2022-10-12 09:54:58 - progress_bar.py[line:274] - INFO: epoch 001:  10475 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.4, ups=0.85, wpb=110, bsz=40, num_updates=10460, lr=9.04531e-06, gnorm=1.173, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=58755
2022-10-12 09:55:10 - progress_bar.py[line:274] - INFO: epoch 001:  10485 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.1, ups=0.86, wpb=109.7, bsz=40, num_updates=10470, lr=9.05396e-06, gnorm=1.126, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58767
2022-10-12 09:55:22 - progress_bar.py[line:274] - INFO: epoch 001:  10495 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.2, ups=0.85, wpb=110.7, bsz=40, num_updates=10480, lr=9.06261e-06, gnorm=1.076, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58779
2022-10-12 09:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  10505 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95, ups=0.86, wpb=111, bsz=40, num_updates=10490, lr=9.07126e-06, gnorm=1.163, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58790
2022-10-12 09:55:45 - progress_bar.py[line:274] - INFO: epoch 001:  10515 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.3, ups=0.88, wpb=108.8, bsz=40, num_updates=10500, lr=9.0799e-06, gnorm=1.327, clip=100, loss_scale=512, train_wall=11, gb_free=22.8, ema_decay=0.9999, wall=58802
2022-10-12 09:55:57 - progress_bar.py[line:274] - INFO: epoch 001:  10525 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.7, ups=0.83, wpb=110.7, bsz=40, num_updates=10510, lr=9.08855e-06, gnorm=1.178, clip=80, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=58814
2022-10-12 09:56:09 - progress_bar.py[line:274] - INFO: epoch 001:  10535 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.6, ups=0.83, wpb=110.4, bsz=40, num_updates=10520, lr=9.0972e-06, gnorm=1.154, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58826
2022-10-12 09:56:21 - progress_bar.py[line:274] - INFO: epoch 001:  10545 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.1, ups=0.85, wpb=108.6, bsz=40, num_updates=10530, lr=9.10585e-06, gnorm=1.229, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58838
2022-10-12 09:56:33 - progress_bar.py[line:274] - INFO: epoch 001:  10555 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.6, ups=0.84, wpb=110.2, bsz=40, num_updates=10540, lr=9.11449e-06, gnorm=1.277, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58849
2022-10-12 09:56:45 - progress_bar.py[line:274] - INFO: epoch 001:  10565 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.4, ups=0.85, wpb=111.3, bsz=40, num_updates=10550, lr=9.12314e-06, gnorm=1.166, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58861
2022-10-12 09:56:56 - progress_bar.py[line:274] - INFO: epoch 001:  10575 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.1, ups=0.84, wpb=110.7, bsz=40, num_updates=10560, lr=9.13179e-06, gnorm=1.3, clip=90, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58873
2022-10-12 09:57:08 - progress_bar.py[line:274] - INFO: epoch 001:  10585 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.4, ups=0.86, wpb=109.2, bsz=40, num_updates=10570, lr=9.14044e-06, gnorm=1.326, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58885
2022-10-12 09:57:10 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-10-12 09:57:21 - progress_bar.py[line:274] - INFO: epoch 001:  10596 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=84.4, ups=0.76, wpb=111.7, bsz=40, num_updates=10580, lr=9.14908e-06, gnorm=1.28, clip=100, loss_scale=256, train_wall=13, gb_free=22.9, ema_decay=0.9999, wall=58898
2022-10-12 09:57:33 - progress_bar.py[line:274] - INFO: epoch 001:  10606 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.2, ups=0.86, wpb=110.7, bsz=40, num_updates=10590, lr=9.15773e-06, gnorm=1.209, clip=90, loss_scale=256, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=58910
2022-10-12 09:57:44 - progress_bar.py[line:274] - INFO: epoch 001:  10616 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.6, ups=0.87, wpb=110.6, bsz=40, num_updates=10600, lr=9.16638e-06, gnorm=1.287, clip=100, loss_scale=256, train_wall=11, gb_free=23.1, ema_decay=0.9999, wall=58921
2022-10-12 09:57:56 - progress_bar.py[line:274] - INFO: epoch 001:  10626 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.1, ups=0.84, wpb=109.6, bsz=40, num_updates=10610, lr=9.17503e-06, gnorm=1.305, clip=100, loss_scale=256, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58933
2022-10-12 09:58:08 - progress_bar.py[line:274] - INFO: epoch 001:  10636 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.9, ups=0.85, wpb=109.5, bsz=40, num_updates=10620, lr=9.18367e-06, gnorm=1.287, clip=100, loss_scale=256, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=58945
2022-10-12 09:58:20 - progress_bar.py[line:274] - INFO: epoch 001:  10646 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.1, ups=0.82, wpb=110.6, bsz=40, num_updates=10630, lr=9.19232e-06, gnorm=1.133, clip=60, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58957
2022-10-12 09:58:32 - progress_bar.py[line:274] - INFO: epoch 001:  10656 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.1, ups=0.86, wpb=112.3, bsz=40, num_updates=10640, lr=9.20097e-06, gnorm=1.097, clip=80, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58968
2022-10-12 09:58:44 - progress_bar.py[line:274] - INFO: epoch 001:  10666 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.7, ups=0.85, wpb=110.4, bsz=40, num_updates=10650, lr=9.20962e-06, gnorm=1.119, clip=80, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=58980
2022-10-12 09:58:55 - progress_bar.py[line:274] - INFO: epoch 001:  10676 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.1, ups=0.85, wpb=110.1, bsz=40, num_updates=10660, lr=9.21826e-06, gnorm=1.144, clip=60, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=58992
2022-10-12 09:59:07 - progress_bar.py[line:274] - INFO: epoch 001:  10686 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.84, wpb=110.2, bsz=40, num_updates=10670, lr=9.22691e-06, gnorm=1.331, clip=100, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=59004
2022-10-12 09:59:19 - progress_bar.py[line:274] - INFO: epoch 001:  10696 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.7, ups=0.85, wpb=110.6, bsz=40, num_updates=10680, lr=9.23556e-06, gnorm=1.11, clip=70, loss_scale=256, train_wall=12, gb_free=23, ema_decay=0.9999, wall=59016
2022-10-12 09:59:31 - progress_bar.py[line:274] - INFO: epoch 001:  10706 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.3, ups=0.83, wpb=110.4, bsz=40, num_updates=10690, lr=9.24421e-06, gnorm=1.121, clip=70, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=59028
2022-10-12 09:59:43 - progress_bar.py[line:274] - INFO: epoch 001:  10716 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.5, ups=0.84, wpb=111.8, bsz=40, num_updates=10700, lr=9.25285e-06, gnorm=1.228, clip=90, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59040
2022-10-12 09:59:55 - progress_bar.py[line:274] - INFO: epoch 001:  10726 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.4, ups=0.86, wpb=109.5, bsz=40, num_updates=10710, lr=9.2615e-06, gnorm=1.17, clip=90, loss_scale=256, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=59052
2022-10-12 10:00:07 - progress_bar.py[line:274] - INFO: epoch 001:  10736 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.84, wpb=110.2, bsz=40, num_updates=10720, lr=9.27015e-06, gnorm=1.271, clip=100, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59063
2022-10-12 10:00:19 - progress_bar.py[line:274] - INFO: epoch 001:  10746 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.8, ups=0.84, wpb=110.8, bsz=40, num_updates=10730, lr=9.2788e-06, gnorm=1.123, clip=80, loss_scale=256, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=59075
2022-10-12 10:00:30 - progress_bar.py[line:274] - INFO: epoch 001:  10756 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.6, ups=0.85, wpb=112.2, bsz=40, num_updates=10740, lr=9.28744e-06, gnorm=1.065, clip=70, loss_scale=256, train_wall=12, gb_free=23, ema_decay=0.9999, wall=59087
2022-10-12 10:00:42 - progress_bar.py[line:274] - INFO: epoch 001:  10766 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.6, ups=0.84, wpb=109.8, bsz=40, num_updates=10750, lr=9.29609e-06, gnorm=1.201, clip=100, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59099
2022-10-12 10:00:54 - progress_bar.py[line:274] - INFO: epoch 001:  10776 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.8, ups=0.83, wpb=110.1, bsz=40, num_updates=10760, lr=9.30474e-06, gnorm=1.16, clip=70, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=59111
2022-10-12 10:01:06 - progress_bar.py[line:274] - INFO: epoch 001:  10786 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.3, ups=0.83, wpb=109.9, bsz=40, num_updates=10770, lr=9.31339e-06, gnorm=1.199, clip=70, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=59123
2022-10-12 10:01:18 - progress_bar.py[line:274] - INFO: epoch 001:  10796 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.83, wpb=109.5, bsz=40, num_updates=10780, lr=9.32203e-06, gnorm=1.121, clip=80, loss_scale=256, train_wall=12, gb_free=23, ema_decay=0.9999, wall=59135
2022-10-12 10:01:30 - progress_bar.py[line:274] - INFO: epoch 001:  10806 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.5, ups=0.86, wpb=110.8, bsz=40, num_updates=10790, lr=9.33068e-06, gnorm=1.21, clip=100, loss_scale=256, train_wall=12, gb_free=23, ema_decay=0.9999, wall=59147
2022-10-12 10:01:42 - progress_bar.py[line:274] - INFO: epoch 001:  10816 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.84, wpb=109.6, bsz=40, num_updates=10800, lr=9.33933e-06, gnorm=1.179, clip=90, loss_scale=256, train_wall=12, gb_free=23, ema_decay=0.9999, wall=59159
2022-10-12 10:01:54 - progress_bar.py[line:274] - INFO: epoch 001:  10826 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.6, ups=0.85, wpb=110.3, bsz=40, num_updates=10810, lr=9.34798e-06, gnorm=1.205, clip=80, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=59170
2022-10-12 10:02:05 - progress_bar.py[line:274] - INFO: epoch 001:  10836 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.6, ups=0.86, wpb=110.4, bsz=40, num_updates=10820, lr=9.35662e-06, gnorm=1.157, clip=90, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59182
2022-10-12 10:02:17 - progress_bar.py[line:274] - INFO: epoch 001:  10846 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.4, ups=0.85, wpb=110.8, bsz=40, num_updates=10830, lr=9.36527e-06, gnorm=1.171, clip=80, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=59194
2022-10-12 10:02:29 - progress_bar.py[line:274] - INFO: epoch 001:  10856 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.4, ups=0.85, wpb=111.7, bsz=40, num_updates=10840, lr=9.37392e-06, gnorm=1.034, clip=70, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59206
2022-10-12 10:02:41 - progress_bar.py[line:274] - INFO: epoch 001:  10866 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.9, ups=0.85, wpb=111.5, bsz=40, num_updates=10850, lr=9.38257e-06, gnorm=1.19, clip=90, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=59217
2022-10-12 10:02:52 - progress_bar.py[line:274] - INFO: epoch 001:  10876 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.9, ups=0.86, wpb=110.5, bsz=40, num_updates=10860, lr=9.39121e-06, gnorm=1.215, clip=70, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59229
2022-10-12 10:03:04 - progress_bar.py[line:274] - INFO: epoch 001:  10886 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.9, ups=0.84, wpb=111.2, bsz=40, num_updates=10870, lr=9.39986e-06, gnorm=1.181, clip=70, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59241
2022-10-12 10:03:16 - progress_bar.py[line:274] - INFO: epoch 001:  10896 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.84, wpb=109.2, bsz=40, num_updates=10880, lr=9.40851e-06, gnorm=1.221, clip=90, loss_scale=256, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=59253
2022-10-12 10:03:28 - progress_bar.py[line:274] - INFO: epoch 001:  10906 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.7, ups=0.84, wpb=110.5, bsz=40, num_updates=10890, lr=9.41716e-06, gnorm=1.142, clip=80, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59265
2022-10-12 10:03:40 - progress_bar.py[line:274] - INFO: epoch 001:  10916 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.1, ups=0.82, wpb=109.9, bsz=40, num_updates=10900, lr=9.4258e-06, gnorm=1.222, clip=90, loss_scale=256, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=59277
2022-10-12 10:03:52 - progress_bar.py[line:274] - INFO: epoch 001:  10926 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.7, ups=0.83, wpb=111.1, bsz=40, num_updates=10910, lr=9.43445e-06, gnorm=1.119, clip=70, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59289
2022-10-12 10:04:04 - progress_bar.py[line:274] - INFO: epoch 001:  10936 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.6, ups=0.84, wpb=110.2, bsz=40, num_updates=10920, lr=9.4431e-06, gnorm=1.162, clip=70, loss_scale=256, train_wall=12, gb_free=23, ema_decay=0.9999, wall=59301
2022-10-12 10:04:16 - progress_bar.py[line:274] - INFO: epoch 001:  10946 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.5, ups=0.84, wpb=112, bsz=40, num_updates=10930, lr=9.45175e-06, gnorm=1.304, clip=100, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59313
2022-10-12 10:04:28 - progress_bar.py[line:274] - INFO: epoch 001:  10956 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.4, ups=0.85, wpb=110.4, bsz=40, num_updates=10940, lr=9.46039e-06, gnorm=1.219, clip=100, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59324
2022-10-12 10:04:40 - progress_bar.py[line:274] - INFO: epoch 001:  10966 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.6, ups=0.84, wpb=110.4, bsz=40, num_updates=10950, lr=9.46904e-06, gnorm=1.134, clip=90, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59336
2022-10-12 10:04:51 - progress_bar.py[line:274] - INFO: epoch 001:  10976 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.1, ups=0.84, wpb=112, bsz=40, num_updates=10960, lr=9.47769e-06, gnorm=1.202, clip=80, loss_scale=256, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=59348
2022-10-12 10:05:03 - progress_bar.py[line:274] - INFO: epoch 001:  10986 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.3, ups=0.85, wpb=110.4, bsz=40, num_updates=10970, lr=9.48634e-06, gnorm=1.149, clip=80, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59360
2022-10-12 10:05:15 - progress_bar.py[line:274] - INFO: epoch 001:  10996 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.5, ups=0.86, wpb=110.7, bsz=40, num_updates=10980, lr=9.49498e-06, gnorm=0.976, clip=40, loss_scale=256, train_wall=12, gb_free=23, ema_decay=0.9999, wall=59372
2022-10-12 10:05:27 - progress_bar.py[line:274] - INFO: epoch 001:  11006 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.9, ups=0.84, wpb=108.4, bsz=40, num_updates=10990, lr=9.50363e-06, gnorm=1.163, clip=80, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=59384
2022-10-12 10:05:39 - progress_bar.py[line:274] - INFO: epoch 001:  11016 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94, ups=0.85, wpb=110.8, bsz=40, num_updates=11000, lr=9.51228e-06, gnorm=1.15, clip=80, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=59395
2022-10-12 10:05:39 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-12 10:05:40 - train.py[line:549] - INFO: 0 / 9351
2022-10-12 10:05:40 - train.py[line:551] - INFO: load:0.88 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-12 10:07:04 - train.py[line:549] - INFO: 200 / 9351
2022-10-12 10:07:04 - train.py[line:551] - INFO: load:0.90 valid_run:84.53 task_valid:81.27 collect_output:2.03
2022-10-12 10:08:28 - train.py[line:549] - INFO: 400 / 9351
2022-10-12 10:08:28 - train.py[line:551] - INFO: load:0.92 valid_run:168.60 task_valid:162.78 collect_output:3.39
2022-10-12 10:09:51 - train.py[line:549] - INFO: 600 / 9351
2022-10-12 10:09:51 - train.py[line:551] - INFO: load:0.94 valid_run:251.28 task_valid:241.97 collect_output:5.66
2022-10-12 10:11:15 - train.py[line:549] - INFO: 800 / 9351
2022-10-12 10:11:15 - train.py[line:551] - INFO: load:0.96 valid_run:335.40 task_valid:321.05 collect_output:9.53
2022-10-12 10:12:40 - train.py[line:549] - INFO: 1000 / 9351
2022-10-12 10:12:40 - train.py[line:551] - INFO: load:0.99 valid_run:420.27 task_valid:400.79 collect_output:13.43
2022-10-12 10:14:05 - train.py[line:549] - INFO: 1200 / 9351
2022-10-12 10:14:05 - train.py[line:551] - INFO: load:1.02 valid_run:504.84 task_valid:479.47 collect_output:18.13
2022-10-12 10:15:29 - train.py[line:549] - INFO: 1400 / 9351
2022-10-12 10:15:29 - train.py[line:551] - INFO: load:1.04 valid_run:588.96 task_valid:560.38 collect_output:20.08
2022-10-12 10:16:54 - train.py[line:549] - INFO: 1600 / 9351
2022-10-12 10:16:54 - train.py[line:551] - INFO: load:1.06 valid_run:673.39 task_valid:642.70 collect_output:21.01
2022-10-12 10:18:19 - train.py[line:549] - INFO: 1800 / 9351
2022-10-12 10:18:19 - train.py[line:551] - INFO: load:1.08 valid_run:758.71 task_valid:723.84 collect_output:23.99
2022-10-12 10:19:44 - train.py[line:549] - INFO: 2000 / 9351
2022-10-12 10:19:44 - train.py[line:551] - INFO: load:1.11 valid_run:843.73 task_valid:804.88 collect_output:26.73
2022-10-12 10:21:09 - train.py[line:549] - INFO: 2200 / 9351
2022-10-12 10:21:09 - train.py[line:551] - INFO: load:1.13 valid_run:928.41 task_valid:885.21 collect_output:29.91
2022-10-12 10:22:34 - train.py[line:549] - INFO: 2400 / 9351
2022-10-12 10:22:34 - train.py[line:551] - INFO: load:1.15 valid_run:1013.35 task_valid:966.66 collect_output:32.16
2022-10-12 10:24:00 - train.py[line:549] - INFO: 2600 / 9351
2022-10-12 10:24:00 - train.py[line:551] - INFO: load:1.18 valid_run:1099.21 task_valid:1047.01 collect_output:36.40
2022-10-12 10:25:25 - train.py[line:549] - INFO: 2800 / 9351
2022-10-12 10:25:25 - train.py[line:551] - INFO: load:1.20 valid_run:1184.68 task_valid:1126.54 collect_output:41.06
2022-10-12 10:26:49 - train.py[line:549] - INFO: 3000 / 9351
2022-10-12 10:26:49 - train.py[line:551] - INFO: load:1.22 valid_run:1268.15 task_valid:1204.10 collect_output:45.80
2022-10-12 10:28:11 - train.py[line:549] - INFO: 3200 / 9351
2022-10-12 10:28:11 - train.py[line:551] - INFO: load:1.24 valid_run:1350.78 task_valid:1283.68 collect_output:47.75
2022-10-12 10:29:36 - train.py[line:549] - INFO: 3400 / 9351
2022-10-12 10:29:36 - train.py[line:551] - INFO: load:1.27 valid_run:1435.27 task_valid:1363.86 collect_output:50.96
2022-10-12 10:30:59 - train.py[line:549] - INFO: 3600 / 9351
2022-10-12 10:30:59 - train.py[line:551] - INFO: load:1.29 valid_run:1518.66 task_valid:1444.53 collect_output:52.60
2022-10-12 10:32:22 - train.py[line:549] - INFO: 3800 / 9351
2022-10-12 10:32:22 - train.py[line:551] - INFO: load:1.31 valid_run:1601.05 task_valid:1522.52 collect_output:55.88
2022-10-12 10:33:45 - train.py[line:549] - INFO: 4000 / 9351
2022-10-12 10:33:45 - train.py[line:551] - INFO: load:1.34 valid_run:1683.77 task_valid:1601.92 collect_output:58.11
2022-10-12 10:35:09 - train.py[line:549] - INFO: 4200 / 9351
2022-10-12 10:35:09 - train.py[line:551] - INFO: load:1.36 valid_run:1768.06 task_valid:1684.16 collect_output:59.07
2022-10-12 10:36:33 - train.py[line:549] - INFO: 4400 / 9351
2022-10-12 10:36:33 - train.py[line:551] - INFO: load:1.38 valid_run:1852.00 task_valid:1764.52 collect_output:61.56
2022-10-12 10:37:56 - train.py[line:549] - INFO: 4600 / 9351
2022-10-12 10:37:56 - train.py[line:551] - INFO: load:1.40 valid_run:1934.91 task_valid:1843.82 collect_output:64.14
2022-10-12 10:39:20 - train.py[line:549] - INFO: 4800 / 9351
2022-10-12 10:39:20 - train.py[line:551] - INFO: load:1.43 valid_run:2018.68 task_valid:1922.14 collect_output:68.48
2022-10-12 10:40:44 - train.py[line:549] - INFO: 5000 / 9351
2022-10-12 10:40:44 - train.py[line:551] - INFO: load:1.45 valid_run:2103.05 task_valid:2003.47 collect_output:70.43
2022-10-12 10:42:08 - train.py[line:549] - INFO: 5200 / 9351
2022-10-12 10:42:08 - train.py[line:551] - INFO: load:1.47 valid_run:2186.41 task_valid:2083.83 collect_output:72.40
2022-10-12 10:43:31 - train.py[line:549] - INFO: 5400 / 9351
2022-10-12 10:43:31 - train.py[line:551] - INFO: load:1.50 valid_run:2269.37 task_valid:2163.84 collect_output:74.31
2022-10-12 10:44:55 - train.py[line:549] - INFO: 5600 / 9351
2022-10-12 10:44:55 - train.py[line:551] - INFO: load:1.52 valid_run:2353.39 task_valid:2245.10 collect_output:76.03
2022-10-12 10:46:18 - train.py[line:549] - INFO: 5800 / 9351
2022-10-12 10:46:18 - train.py[line:551] - INFO: load:1.54 valid_run:2436.81 task_valid:2324.48 collect_output:79.00
2022-10-12 10:47:42 - train.py[line:549] - INFO: 6000 / 9351
2022-10-12 10:47:42 - train.py[line:551] - INFO: load:1.57 valid_run:2520.17 task_valid:2404.85 collect_output:80.94
2022-10-12 10:49:05 - train.py[line:549] - INFO: 6200 / 9351
2022-10-12 10:49:05 - train.py[line:551] - INFO: load:1.59 valid_run:2603.78 task_valid:2484.88 collect_output:83.40
2022-10-12 10:50:30 - train.py[line:549] - INFO: 6400 / 9351
2022-10-12 10:50:30 - train.py[line:551] - INFO: load:1.62 valid_run:2688.75 task_valid:2566.35 collect_output:85.82
2022-10-12 10:51:54 - train.py[line:549] - INFO: 6600 / 9351
2022-10-12 10:51:54 - train.py[line:551] - INFO: load:1.64 valid_run:2772.69 task_valid:2647.98 collect_output:87.07
2022-10-12 10:53:18 - train.py[line:549] - INFO: 6800 / 9351
2022-10-12 10:53:18 - train.py[line:551] - INFO: load:1.66 valid_run:2856.23 task_valid:2727.81 collect_output:89.74
2022-10-12 10:54:41 - train.py[line:549] - INFO: 7000 / 9351
2022-10-12 10:54:41 - train.py[line:551] - INFO: load:1.68 valid_run:2939.21 task_valid:2806.65 collect_output:92.81
2022-10-12 10:56:04 - train.py[line:549] - INFO: 7200 / 9351
2022-10-12 10:56:04 - train.py[line:551] - INFO: load:1.71 valid_run:3022.62 task_valid:2886.88 collect_output:94.90
2022-10-12 10:57:28 - train.py[line:549] - INFO: 7400 / 9351
2022-10-12 10:57:28 - train.py[line:551] - INFO: load:1.73 valid_run:3105.90 task_valid:2965.81 collect_output:98.21
2022-10-12 10:58:53 - train.py[line:549] - INFO: 7600 / 9351
2022-10-12 10:58:53 - train.py[line:551] - INFO: load:1.75 valid_run:3190.93 task_valid:3046.37 collect_output:101.59
2022-10-12 11:00:18 - train.py[line:549] - INFO: 7800 / 9351
2022-10-12 11:00:18 - train.py[line:551] - INFO: load:1.78 valid_run:3275.64 task_valid:3126.69 collect_output:104.90
2022-10-12 11:01:41 - train.py[line:549] - INFO: 8000 / 9351
2022-10-12 11:01:41 - train.py[line:551] - INFO: load:1.80 valid_run:3358.97 task_valid:3205.51 collect_output:108.33
2022-10-12 11:03:05 - train.py[line:549] - INFO: 8200 / 9351
2022-10-12 11:03:05 - train.py[line:551] - INFO: load:1.82 valid_run:3442.81 task_valid:3286.81 collect_output:109.77
2022-10-12 11:04:29 - train.py[line:549] - INFO: 8400 / 9351
2022-10-12 11:04:29 - train.py[line:551] - INFO: load:1.85 valid_run:3526.54 task_valid:3367.98 collect_output:111.29
2022-10-12 11:05:53 - train.py[line:549] - INFO: 8600 / 9351
2022-10-12 11:05:53 - train.py[line:551] - INFO: load:1.87 valid_run:3610.61 task_valid:3448.31 collect_output:113.99
2022-10-12 11:07:17 - train.py[line:549] - INFO: 8800 / 9351
2022-10-12 11:07:17 - train.py[line:551] - INFO: load:1.89 valid_run:3694.33 task_valid:3527.83 collect_output:117.12
2022-10-12 11:08:41 - train.py[line:549] - INFO: 9000 / 9351
2022-10-12 11:08:41 - train.py[line:551] - INFO: load:1.92 valid_run:3778.51 task_valid:3610.04 collect_output:118.03
2022-10-12 11:10:04 - train.py[line:549] - INFO: 9200 / 9351
2022-10-12 11:10:04 - train.py[line:551] - INFO: load:1.94 valid_run:3861.99 task_valid:3691.22 collect_output:119.27

====================================================================================================
SGG eval:     R @ 50: 0.6567;     R @ 100: 0.6887;     R @ 500: 0.7073;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4480;    mR @ 100: 0.4683;    mR @ 500: 0.5235;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.4355) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9598) (says:0.0000) (sitting on:0.7466) (standing on:0.3860) (using:0.6000) (walking in:0.0000) (walking on:0.7297) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-12 11:11:19 - train.py[line:487] - INFO: 0.688729131652661

====================================================================================================
SGG eval:     R @ 50: 0.6567;     R @ 100: 0.6887;     R @ 500: 0.7073;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4480;    mR @ 100: 0.4683;    mR @ 500: 0.5235;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.5000) (hanging from:0.4355) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9598) (says:0.0000) (sitting on:0.7466) (standing on:0.3860) (using:0.6000) (walking in:0.0000) (walking on:0.7297) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-12 11:11:19 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-12 11:11:19 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.353 | loss_v1 0 | loss_v2 0 | nll_loss 0.197 | ntokens 47.968 | nsentences 16 | sample_size 47.968 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.688729 | ppl 1.15 | vqa_score 0.5923 | wps 113.9 | wpb 48 | bsz 16 | num_updates 11000 | best_R@100 0.69991
2022-10-12 11:11:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 11000 updates
2022-10-12 11:11:19 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_11000.pt
2022-10-12 11:11:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_11000.pt
2022-10-12 11:11:27 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName0.5/1_B10_A2_E50_0.04_5e-5_480/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 0.688729131652661) (writing took 8.538452995941043 seconds)
2022-10-12 11:11:39 - progress_bar.py[line:274] - INFO: epoch 001:  11026 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=0.3, ups=0, wpb=109.4, bsz=40, num_updates=11010, lr=9.52093e-06, gnorm=1.153, clip=90, loss_scale=256, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=63356
2022-10-12 11:11:51 - progress_bar.py[line:274] - INFO: epoch 001:  11036 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.3, ups=0.84, wpb=110.5, bsz=40, num_updates=11020, lr=9.52957e-06, gnorm=1.186, clip=90, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=63368
2022-10-12 11:12:03 - progress_bar.py[line:274] - INFO: epoch 001:  11046 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.3, ups=0.84, wpb=109.3, bsz=40, num_updates=11030, lr=9.53822e-06, gnorm=1.169, clip=80, loss_scale=256, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=63380
2022-10-12 11:12:15 - progress_bar.py[line:274] - INFO: epoch 001:  11056 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.5, ups=0.85, wpb=109.9, bsz=40, num_updates=11040, lr=9.54687e-06, gnorm=1.215, clip=100, loss_scale=256, train_wall=12, gb_free=23, ema_decay=0.9999, wall=63392
2022-10-12 11:12:27 - progress_bar.py[line:274] - INFO: epoch 001:  11066 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.3, ups=0.86, wpb=110.1, bsz=40, num_updates=11050, lr=9.55552e-06, gnorm=1.317, clip=100, loss_scale=256, train_wall=12, gb_free=23, ema_decay=0.9999, wall=63403
2022-10-12 11:12:38 - progress_bar.py[line:274] - INFO: epoch 001:  11076 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=93.2, ups=0.85, wpb=110.1, bsz=40, num_updates=11060, lr=9.56416e-06, gnorm=1.086, clip=80, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=63415
2022-10-12 11:12:50 - progress_bar.py[line:274] - INFO: epoch 001:  11086 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.9, ups=0.84, wpb=110.7, bsz=40, num_updates=11070, lr=9.57281e-06, gnorm=1.233, clip=90, loss_scale=256, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=63427
2022-10-12 11:13:02 - progress_bar.py[line:274] - INFO: epoch 001:  11096 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.7, ups=0.86, wpb=110.7, bsz=40, num_updates=11080, lr=9.58146e-06, gnorm=1.175, clip=80, loss_scale=256, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=63439
2022-10-12 11:13:14 - progress_bar.py[line:274] - INFO: epoch 001:  11106 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=90.4, ups=0.83, wpb=108.6, bsz=40, num_updates=11090, lr=9.59011e-06, gnorm=1.088, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=63451
2022-10-12 11:13:26 - progress_bar.py[line:274] - INFO: epoch 001:  11116 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.2, ups=0.83, wpb=110.7, bsz=40, num_updates=11100, lr=9.59875e-06, gnorm=1.281, clip=90, loss_scale=512, train_wall=12, gb_free=22.6, ema_decay=0.9999, wall=63463
2022-10-12 11:13:38 - progress_bar.py[line:274] - INFO: epoch 001:  11126 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.9, ups=0.84, wpb=109.8, bsz=40, num_updates=11110, lr=9.6074e-06, gnorm=1.158, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=63475
2022-10-12 11:13:50 - progress_bar.py[line:274] - INFO: epoch 001:  11136 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.5, ups=0.83, wpb=109.7, bsz=40, num_updates=11120, lr=9.61605e-06, gnorm=1.232, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=63487
2022-10-12 11:14:02 - progress_bar.py[line:274] - INFO: epoch 001:  11146 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.1, ups=0.84, wpb=110.5, bsz=40, num_updates=11130, lr=9.6247e-06, gnorm=1.117, clip=60, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=63499
2022-10-12 11:14:14 - progress_bar.py[line:274] - INFO: epoch 001:  11156 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.1, ups=0.84, wpb=110.1, bsz=40, num_updates=11140, lr=9.63334e-06, gnorm=1.221, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=63511
2022-10-12 11:14:26 - progress_bar.py[line:274] - INFO: epoch 001:  11166 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.1, ups=0.84, wpb=110, bsz=40, num_updates=11150, lr=9.64199e-06, gnorm=1.178, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=63523
2022-10-12 11:14:38 - progress_bar.py[line:274] - INFO: epoch 001:  11176 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.7, ups=0.85, wpb=110.4, bsz=40, num_updates=11160, lr=9.65064e-06, gnorm=1.092, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=63534
2022-10-12 11:14:50 - progress_bar.py[line:274] - INFO: epoch 001:  11186 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.7, ups=0.84, wpb=108.3, bsz=40, num_updates=11170, lr=9.65929e-06, gnorm=1.371, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=63546
2022-10-12 11:15:01 - progress_bar.py[line:274] - INFO: epoch 001:  11196 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.7, ups=0.85, wpb=109.4, bsz=40, num_updates=11180, lr=9.66793e-06, gnorm=1.222, clip=80, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=63558
2022-10-12 11:15:13 - progress_bar.py[line:274] - INFO: epoch 001:  11206 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.8, ups=0.84, wpb=110.5, bsz=40, num_updates=11190, lr=9.67658e-06, gnorm=1.172, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=63570
2022-10-12 11:15:25 - progress_bar.py[line:274] - INFO: epoch 001:  11216 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.1, ups=0.86, wpb=110.1, bsz=40, num_updates=11200, lr=9.68523e-06, gnorm=1.186, clip=80, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=63582
2022-10-12 11:15:37 - progress_bar.py[line:274] - INFO: epoch 001:  11226 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=93.2, ups=0.84, wpb=110.7, bsz=40, num_updates=11210, lr=9.69388e-06, gnorm=1.21, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=63594
2022-10-12 11:15:49 - progress_bar.py[line:274] - INFO: epoch 001:  11236 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94, ups=0.85, wpb=110.8, bsz=40, num_updates=11220, lr=9.70253e-06, gnorm=1.202, clip=100, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=63605
2022-10-12 11:16:00 - progress_bar.py[line:274] - INFO: epoch 001:  11246 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=93.3, ups=0.85, wpb=109.5, bsz=40, num_updates=11230, lr=9.71117e-06, gnorm=1.175, clip=80, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=63617
2022-10-12 11:16:12 - progress_bar.py[line:274] - INFO: epoch 001:  11256 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92, ups=0.84, wpb=110, bsz=40, num_updates=11240, lr=9.71982e-06, gnorm=1.197, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=63629
2022-10-12 11:16:24 - progress_bar.py[line:274] - INFO: epoch 001:  11266 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.2, ups=0.85, wpb=110.6, bsz=40, num_updates=11250, lr=9.72847e-06, gnorm=1.259, clip=100, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=63641
2022-10-12 11:16:36 - progress_bar.py[line:274] - INFO: epoch 001:  11276 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.4, ups=0.84, wpb=111.1, bsz=40, num_updates=11260, lr=9.73712e-06, gnorm=1.165, clip=60, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=63653
2022-10-12 11:16:48 - progress_bar.py[line:274] - INFO: epoch 001:  11286 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.82, wpb=110.7, bsz=40, num_updates=11270, lr=9.74576e-06, gnorm=1.18, clip=90, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=63665
2022-10-12 11:17:00 - progress_bar.py[line:274] - INFO: epoch 001:  11296 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.5, ups=0.83, wpb=110.2, bsz=40, num_updates=11280, lr=9.75441e-06, gnorm=1.11, clip=70, loss_scale=512, train_wall=12, gb_free=22.8, ema_decay=0.9999, wall=63677
2022-10-12 11:17:12 - progress_bar.py[line:274] - INFO: epoch 001:  11306 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.9, ups=0.85, wpb=110.8, bsz=40, num_updates=11290, lr=9.76306e-06, gnorm=1.113, clip=90, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=63689
2022-10-12 11:17:24 - progress_bar.py[line:274] - INFO: epoch 001:  11316 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.4, ups=0.84, wpb=109.8, bsz=40, num_updates=11300, lr=9.77171e-06, gnorm=1.282, clip=90, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=63701
2022-10-12 11:17:36 - progress_bar.py[line:274] - INFO: epoch 001:  11326 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.6, ups=0.85, wpb=109.6, bsz=40, num_updates=11310, lr=9.78035e-06, gnorm=1.076, clip=60, loss_scale=512, train_wall=12, gb_free=23, ema_decay=0.9999, wall=63712
2022-10-12 11:17:47 - progress_bar.py[line:274] - INFO: epoch 001:  11336 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93, ups=0.85, wpb=108.9, bsz=40, num_updates=11320, lr=9.789e-06, gnorm=1.159, clip=80, loss_scale=512, train_wall=12, gb_free=23.1, ema_decay=0.9999, wall=63724
2022-10-12 11:17:59 - progress_bar.py[line:274] - INFO: epoch 001:  11346 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.6, ups=0.84, wpb=110, bsz=40, num_updates=11330, lr=9.79765e-06, gnorm=1.108, clip=80, loss_scale=512, train_wall=12, gb_free=22.7, ema_decay=0.9999, wall=63736
2022-10-12 11:18:11 - progress_bar.py[line:274] - INFO: epoch 001:  11356 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.8, ups=0.83, wpb=110, bsz=40, num_updates=11340, lr=9.8063e-06, gnorm=1.188, clip=80, loss_scale=512, train_wall=12, gb_free=22.9, ema_decay=0.9999, wall=63748
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 1660057
Killing subprocess 1660058
Main process received SIGINT, exiting
