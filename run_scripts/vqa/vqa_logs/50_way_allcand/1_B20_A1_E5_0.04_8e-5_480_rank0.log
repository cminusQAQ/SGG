2022-09-28 13:41:58 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-09-28 13:41:58 - utils.py[line:261] - INFO: Start init
2022-09-28 13:41:58 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-09-28 13:41:58 - utils.py[line:261] - INFO: Start init
2022-09-28 13:41:59 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-09-28 13:41:59 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-09-28 13:41:59 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-09-28 13:41:59 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-09-28 13:42:03 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/50_way_allcand', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 6000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [8e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 6000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[8e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480', save_interval=10, save_interval_updates=6000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/50_way_allcand', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=6000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [8e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [8e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-09-28 13:42:03 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-09-28 13:42:03 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-09-28 13:42:08 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-09-28 13:42:08 - train.py[line:118] - INFO: task: VqaGenTask
2022-09-28 13:42:08 - train.py[line:119] - INFO: model: OFAModel
2022-09-28 13:42:08 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-09-28 13:42:08 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-09-28 13:42:08 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_500.tsv slice_id 1 row count 45697 total row count 91394
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_500.tsv slice_id 0 row count 45697 total row count 91394
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-28 13:42:08 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-09-28 13:42:08 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-09-28 13:42:09 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 13:42:09 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 13:42:09 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 13:42:09 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 13:42:09 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-09-28 13:42:09 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-09-28 13:42:09 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-09-28 13:42:16 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 13:42:16 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 13:42:17 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-09-28 13:42:17 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-09-28 13:42:17 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-09-28 13:42:17 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 1 row count 315642 total row count 631284
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 0 row count 315642 total row count 631284
2022-09-28 13:42:18 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 13:42:18 - trainer.py[line:707] - INFO: begin training epoch 1
2022-09-28 13:42:18 - train.py[line:312] - INFO: Start iterating over samples
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 13:42:34 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 15783 loss=1.323, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=86.5, ups=0.84, wpb=102.4, bsz=40, num_updates=10, lr=2.53485e-07, gnorm=14.88, clip=100, loss_scale=128, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=25
2022-09-28 13:42:46 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 15783 loss=1.337, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=86.4, ups=0.86, wpb=100.6, bsz=40, num_updates=20, lr=5.06971e-07, gnorm=13.329, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=37
2022-09-28 13:42:57 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 15783 loss=1.384, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=87.4, ups=0.87, wpb=100.6, bsz=40, num_updates=30, lr=7.60456e-07, gnorm=14.775, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49
2022-09-28 13:43:09 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 15783 loss=1.247, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=86.6, ups=0.85, wpb=102.1, bsz=40, num_updates=40, lr=1.01394e-06, gnorm=10.069, clip=100, loss_scale=128, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=60
2022-09-28 13:43:21 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 15783 loss=1.166, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=87.8, ups=0.86, wpb=102.4, bsz=40, num_updates=50, lr=1.26743e-06, gnorm=9.184, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=72
2022-09-28 13:43:32 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 15783 loss=1.149, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=86.7, ups=0.86, wpb=100.4, bsz=40, num_updates=60, lr=1.52091e-06, gnorm=7.534, clip=100, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=84
2022-09-28 13:43:44 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 15783 loss=1.06, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=90.6, ups=0.88, wpb=102.7, bsz=40, num_updates=70, lr=1.7744e-06, gnorm=6.296, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=95
2022-09-28 13:43:55 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 15783 loss=1.029, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=90, ups=0.87, wpb=103.2, bsz=40, num_updates=80, lr=2.02788e-06, gnorm=5.777, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106
2022-09-28 13:44:07 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 15783 loss=1.052, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=87.9, ups=0.87, wpb=101.2, bsz=40, num_updates=90, lr=2.28137e-06, gnorm=5.063, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=118
2022-09-28 13:44:18 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 15783 loss=1.019, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=87.9, ups=0.87, wpb=101, bsz=40, num_updates=100, lr=2.53485e-06, gnorm=4.434, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=129
2022-09-28 13:44:30 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 15783 loss=1.007, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=88.4, ups=0.87, wpb=101.4, bsz=40, num_updates=110, lr=2.78834e-06, gnorm=4.435, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=141
2022-09-28 13:44:41 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 15783 loss=1.002, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=87.6, ups=0.87, wpb=100.3, bsz=40, num_updates=120, lr=3.04183e-06, gnorm=4.32, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=152
2022-09-28 13:44:52 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 15783 loss=0.995, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=88.2, ups=0.88, wpb=100.4, bsz=40, num_updates=130, lr=3.29531e-06, gnorm=4.024, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=164
2022-09-28 13:45:04 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 15783 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=89.7, ups=0.88, wpb=101.8, bsz=40, num_updates=140, lr=3.5488e-06, gnorm=3.588, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=175
2022-09-28 13:45:15 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 15783 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=90.1, ups=0.88, wpb=102.2, bsz=40, num_updates=150, lr=3.80228e-06, gnorm=3.485, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=186
2022-09-28 13:45:26 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 15783 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.736, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=93.7, ups=0.91, wpb=102.5, bsz=40, num_updates=160, lr=4.05577e-06, gnorm=3.69, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=197
2022-09-28 13:45:38 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 15783 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=86.6, ups=0.86, wpb=100.6, bsz=40, num_updates=170, lr=4.30925e-06, gnorm=3.217, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=209
2022-09-28 13:45:49 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 15783 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.717, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=89.3, ups=0.87, wpb=102.9, bsz=40, num_updates=180, lr=4.56274e-06, gnorm=3.14, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=221
2022-09-28 13:46:01 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 15783 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=86.5, ups=0.87, wpb=99.5, bsz=40, num_updates=190, lr=4.81622e-06, gnorm=3.177, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=232
2022-09-28 13:46:12 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 15783 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=89.4, ups=0.87, wpb=102.6, bsz=40, num_updates=200, lr=5.06971e-06, gnorm=3.199, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=244
2022-09-28 13:46:23 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 15783 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=90.6, ups=0.89, wpb=101.3, bsz=40, num_updates=210, lr=5.32319e-06, gnorm=2.848, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=255
2022-09-28 13:46:35 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 15783 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=90.2, ups=0.88, wpb=102.9, bsz=40, num_updates=220, lr=5.57668e-06, gnorm=2.783, clip=100, loss_scale=128, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=266
2022-09-28 13:46:46 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 15783 loss=0.861, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=88.6, ups=0.86, wpb=103, bsz=40, num_updates=230, lr=5.83016e-06, gnorm=2.75, clip=100, loss_scale=128, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=278
2022-09-28 13:46:58 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 15783 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=240, lr=6.08365e-06, gnorm=2.756, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=289
2022-09-28 13:47:09 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 15783 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=92, ups=0.91, wpb=101.2, bsz=40, num_updates=250, lr=6.33714e-06, gnorm=2.738, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=300
2022-09-28 13:47:19 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 15783 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.727, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=95.2, ups=0.93, wpb=102.3, bsz=40, num_updates=260, lr=6.59062e-06, gnorm=2.777, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=311
2022-09-28 13:47:31 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 15783 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=88.4, ups=0.88, wpb=99.9, bsz=40, num_updates=270, lr=6.84411e-06, gnorm=2.925, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=322
2022-09-28 13:47:42 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 15783 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=280, lr=7.09759e-06, gnorm=2.84, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=333
2022-09-28 13:47:53 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 15783 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.754, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=90.1, ups=0.9, wpb=100.7, bsz=40, num_updates=290, lr=7.35108e-06, gnorm=2.753, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=345
2022-09-28 13:48:04 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 15783 loss=0.968, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=98.1, nsentences=40, sample_size=98.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=87.4, ups=0.89, wpb=98.1, bsz=40, num_updates=300, lr=7.60456e-06, gnorm=2.988, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=356
2022-09-28 13:48:15 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 15783 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=92.6, ups=0.91, wpb=102.1, bsz=40, num_updates=310, lr=7.85805e-06, gnorm=2.804, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=367
2022-09-28 13:48:27 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 15783 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=320, lr=8.11153e-06, gnorm=2.88, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=378
2022-09-28 13:48:38 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 15783 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=95.1, ups=0.93, wpb=102.3, bsz=40, num_updates=330, lr=8.36502e-06, gnorm=3.069, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=389
2022-09-28 13:48:49 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 15783 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.4, ups=0.89, wpb=101, bsz=40, num_updates=340, lr=8.6185e-06, gnorm=2.845, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=400
2022-09-28 13:49:00 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 15783 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=93.2, ups=0.91, wpb=102.9, bsz=40, num_updates=350, lr=8.87199e-06, gnorm=2.711, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=411
2022-09-28 13:49:11 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 15783 loss=0.837, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=89.8, ups=0.88, wpb=102.5, bsz=40, num_updates=360, lr=9.12548e-06, gnorm=2.806, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=423
2022-09-28 13:49:22 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 15783 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.7, ups=0.9, wpb=101.3, bsz=40, num_updates=370, lr=9.37896e-06, gnorm=2.59, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=434
2022-09-28 13:49:34 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 15783 loss=0.835, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=86.9, ups=0.86, wpb=101, bsz=40, num_updates=380, lr=9.63245e-06, gnorm=2.862, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=445
2022-09-28 13:49:45 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 15783 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=90, ups=0.88, wpb=102.5, bsz=40, num_updates=390, lr=9.88593e-06, gnorm=2.648, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=457
2022-09-28 13:49:56 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 15783 loss=0.818, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=92.7, ups=0.92, wpb=100.6, bsz=40, num_updates=400, lr=1.01394e-05, gnorm=2.993, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=468
2022-09-28 13:50:07 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 15783 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=93.8, ups=0.93, wpb=101.2, bsz=40, num_updates=410, lr=1.03929e-05, gnorm=2.914, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=478
2022-09-28 13:50:18 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 15783 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=88.6, ups=0.89, wpb=99.7, bsz=40, num_updates=420, lr=1.06464e-05, gnorm=2.927, clip=100, loss_scale=128, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=490
2022-09-28 13:50:29 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 15783 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=90.5, ups=0.9, wpb=100.6, bsz=40, num_updates=430, lr=1.08999e-05, gnorm=2.748, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=501
2022-09-28 13:50:41 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 15783 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=87, ups=0.87, wpb=100.2, bsz=40, num_updates=440, lr=1.11534e-05, gnorm=2.643, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=512
2022-09-28 13:50:52 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 15783 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.619, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=88.1, ups=0.88, wpb=99.7, bsz=40, num_updates=450, lr=1.14068e-05, gnorm=2.66, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=524
2022-09-28 13:51:04 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 15783 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=87.9, ups=0.87, wpb=100.8, bsz=40, num_updates=460, lr=1.16603e-05, gnorm=2.681, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=535
2022-09-28 13:51:15 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 15783 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.4, ups=0.9, wpb=102, bsz=40, num_updates=470, lr=1.19138e-05, gnorm=2.758, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=546
2022-09-28 13:51:26 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 15783 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.7, ups=0.87, wpb=102.5, bsz=40, num_updates=480, lr=1.21673e-05, gnorm=2.601, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=558
2022-09-28 13:51:37 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 15783 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=490, lr=1.24208e-05, gnorm=2.556, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=569
2022-09-28 13:51:48 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 15783 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.8, ups=0.91, wpb=101.5, bsz=40, num_updates=500, lr=1.26743e-05, gnorm=2.638, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=580
2022-09-28 13:52:00 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 15783 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=86.5, ups=0.86, wpb=100.6, bsz=40, num_updates=510, lr=1.29278e-05, gnorm=2.884, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=591
2022-09-28 13:52:11 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 15783 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88.7, ups=0.87, wpb=101.5, bsz=40, num_updates=520, lr=1.31812e-05, gnorm=2.824, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=603
2022-09-28 13:52:22 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 15783 loss=0.751, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=93.2, ups=0.93, wpb=100.1, bsz=40, num_updates=530, lr=1.34347e-05, gnorm=2.526, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=614
2022-09-28 13:52:34 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 15783 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88, ups=0.87, wpb=100.7, bsz=40, num_updates=540, lr=1.36882e-05, gnorm=2.474, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=625
2022-09-28 13:52:44 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 15783 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.2, ups=0.93, wpb=101.9, bsz=40, num_updates=550, lr=1.39417e-05, gnorm=2.172, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=636
2022-09-28 13:52:56 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 15783 loss=0.736, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.8, ups=0.88, wpb=100.8, bsz=40, num_updates=560, lr=1.41952e-05, gnorm=2.46, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=647
2022-09-28 13:53:07 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 15783 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90, ups=0.88, wpb=102.2, bsz=40, num_updates=570, lr=1.44487e-05, gnorm=2.232, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=659
2022-09-28 13:53:18 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 15783 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92, ups=0.9, wpb=102.5, bsz=40, num_updates=580, lr=1.47022e-05, gnorm=2.277, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=670
2022-09-28 13:53:30 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.89, wpb=103.4, bsz=40, num_updates=590, lr=1.49556e-05, gnorm=2.157, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=681
2022-09-28 13:53:41 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 15783 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.3, ups=0.88, wpb=102.8, bsz=40, num_updates=600, lr=1.52091e-05, gnorm=2.691, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=692
2022-09-28 13:53:52 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 15783 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.9, ups=0.88, wpb=103.4, bsz=40, num_updates=610, lr=1.54626e-05, gnorm=2.429, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=704
2022-09-28 13:54:04 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.9, ups=0.87, wpb=102, bsz=40, num_updates=620, lr=1.57161e-05, gnorm=1.921, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=715
2022-09-28 13:54:15 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 15783 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.8, ups=0.87, wpb=103.1, bsz=40, num_updates=630, lr=1.59696e-05, gnorm=2.293, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=727
2022-09-28 13:54:27 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.2, ups=0.87, wpb=103.4, bsz=40, num_updates=640, lr=1.62231e-05, gnorm=2.116, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=738
2022-09-28 13:54:38 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 15783 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=650, lr=1.64766e-05, gnorm=2.211, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=750
2022-09-28 13:54:49 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 15783 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.4, ups=0.92, wpb=100.7, bsz=40, num_updates=660, lr=1.673e-05, gnorm=2.187, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=760
2022-09-28 13:55:01 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 15783 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88, ups=0.88, wpb=100.2, bsz=40, num_updates=670, lr=1.69835e-05, gnorm=2.189, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=772
2022-09-28 13:55:12 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 15783 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.8, ups=0.87, wpb=101.5, bsz=40, num_updates=680, lr=1.7237e-05, gnorm=2.337, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=783
2022-09-28 13:55:23 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=690, lr=1.74905e-05, gnorm=2.218, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=795
2022-09-28 13:55:34 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 15783 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.8, ups=0.92, wpb=99.9, bsz=40, num_updates=700, lr=1.7744e-05, gnorm=2.297, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=806
2022-09-28 13:55:46 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.2, ups=0.87, wpb=102.3, bsz=40, num_updates=710, lr=1.79975e-05, gnorm=2.072, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=817
2022-09-28 13:55:56 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.3, ups=0.92, wpb=102.5, bsz=40, num_updates=720, lr=1.8251e-05, gnorm=1.944, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=828
2022-09-28 13:56:08 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 15783 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=730, lr=1.85044e-05, gnorm=2.085, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=839
2022-09-28 13:56:19 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.7, ups=0.88, wpb=101.5, bsz=40, num_updates=740, lr=1.87579e-05, gnorm=2.094, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=850
2022-09-28 13:56:30 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.9, ups=0.9, wpb=101.2, bsz=40, num_updates=750, lr=1.90114e-05, gnorm=1.913, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=861
2022-09-28 13:56:41 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.4, ups=0.87, wpb=100.3, bsz=40, num_updates=760, lr=1.92649e-05, gnorm=1.971, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=873
2022-09-28 13:56:53 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.2, ups=0.86, wpb=102.3, bsz=40, num_updates=770, lr=1.95184e-05, gnorm=1.874, clip=100, loss_scale=256, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=884
2022-09-28 13:57:04 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.4, ups=0.89, wpb=102, bsz=40, num_updates=780, lr=1.97719e-05, gnorm=1.876, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=896
2022-09-28 13:57:15 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 15783 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=93, ups=0.93, wpb=100.1, bsz=40, num_updates=790, lr=2.00253e-05, gnorm=2.25, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=907
2022-09-28 13:57:26 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 15783 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.1, ups=0.92, wpb=98.8, bsz=40, num_updates=800, lr=2.02788e-05, gnorm=1.983, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=917
2022-09-28 13:57:38 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88, ups=0.87, wpb=101.6, bsz=40, num_updates=810, lr=2.05323e-05, gnorm=1.953, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=929
2022-09-28 13:57:49 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 15783 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.7, ups=0.9, wpb=101.2, bsz=40, num_updates=820, lr=2.07858e-05, gnorm=1.995, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=940
2022-09-28 13:58:00 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.6, ups=0.91, wpb=101.5, bsz=40, num_updates=830, lr=2.10393e-05, gnorm=1.797, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=952
2022-09-28 13:58:11 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 15783 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=840, lr=2.12928e-05, gnorm=1.911, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=963
2022-09-28 13:58:22 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.5, ups=0.9, wpb=101.2, bsz=40, num_updates=850, lr=2.15463e-05, gnorm=1.626, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=974
2022-09-28 13:58:34 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 15783 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.1, ups=0.89, wpb=102, bsz=40, num_updates=860, lr=2.17997e-05, gnorm=1.94, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=985
2022-09-28 13:58:45 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.4, ups=0.89, wpb=101, bsz=40, num_updates=870, lr=2.20532e-05, gnorm=1.92, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=996
2022-09-28 13:58:56 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 15783 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.2, ups=0.91, wpb=101.6, bsz=40, num_updates=880, lr=2.23067e-05, gnorm=2.038, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1007
2022-09-28 13:59:07 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.8, ups=0.9, wpb=101.8, bsz=40, num_updates=890, lr=2.25602e-05, gnorm=1.697, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1019
2022-09-28 13:59:18 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.5, ups=0.9, wpb=103.1, bsz=40, num_updates=900, lr=2.28137e-05, gnorm=1.847, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1030
2022-09-28 13:59:29 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.1, ups=0.92, wpb=102.3, bsz=40, num_updates=910, lr=2.30672e-05, gnorm=1.96, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1041
2022-09-28 13:59:40 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.7, ups=0.91, wpb=101, bsz=40, num_updates=920, lr=2.33207e-05, gnorm=1.849, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1052
2022-09-28 13:59:52 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=86.3, ups=0.86, wpb=100.4, bsz=40, num_updates=930, lr=2.35741e-05, gnorm=1.706, clip=100, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1063
2022-09-28 14:00:03 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 15783 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=87, ups=0.86, wpb=100.6, bsz=40, num_updates=940, lr=2.38276e-05, gnorm=1.968, clip=100, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1075
2022-09-28 14:00:15 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 15783 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=86.7, ups=0.87, wpb=99.3, bsz=40, num_updates=950, lr=2.40811e-05, gnorm=1.804, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1086
2022-09-28 14:00:26 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 15783 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.4, ups=0.87, wpb=100.3, bsz=40, num_updates=960, lr=2.43346e-05, gnorm=1.871, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1098
2022-09-28 14:00:37 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.6, ups=0.91, wpb=99.7, bsz=40, num_updates=970, lr=2.45881e-05, gnorm=1.859, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1109
2022-09-28 14:00:49 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.1, ups=0.87, wpb=103.3, bsz=40, num_updates=980, lr=2.48416e-05, gnorm=1.829, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1120
2022-09-28 14:01:00 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.8, ups=0.9, wpb=99.8, bsz=40, num_updates=990, lr=2.50951e-05, gnorm=1.948, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1131
2022-09-28 14:01:11 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93, ups=0.9, wpb=103.7, bsz=40, num_updates=1000, lr=2.53485e-05, gnorm=1.828, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1142
2022-09-28 14:01:23 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.87, wpb=102.5, bsz=40, num_updates=1010, lr=2.5602e-05, gnorm=2.043, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1154
2022-09-28 14:01:34 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.88, wpb=103.2, bsz=40, num_updates=1020, lr=2.58555e-05, gnorm=1.961, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1165
2022-09-28 14:01:45 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=1030, lr=2.6109e-05, gnorm=1.617, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1177
2022-09-28 14:01:57 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.3, ups=0.86, wpb=101.2, bsz=40, num_updates=1040, lr=2.63625e-05, gnorm=1.614, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1188
2022-09-28 14:02:08 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.3, ups=0.89, wpb=103.4, bsz=40, num_updates=1050, lr=2.6616e-05, gnorm=1.808, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1200
2022-09-28 14:02:19 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92, ups=0.92, wpb=100.2, bsz=40, num_updates=1060, lr=2.68695e-05, gnorm=1.929, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1211
2022-09-28 14:02:30 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.6, ups=0.89, wpb=98.9, bsz=40, num_updates=1070, lr=2.71229e-05, gnorm=1.726, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1222
2022-09-28 14:02:42 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.4, ups=0.89, wpb=102.7, bsz=40, num_updates=1080, lr=2.73764e-05, gnorm=1.928, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1233
2022-09-28 14:02:53 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=1090, lr=2.76299e-05, gnorm=1.645, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1244
2022-09-28 14:03:04 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91, ups=0.89, wpb=102.2, bsz=40, num_updates=1100, lr=2.78834e-05, gnorm=1.645, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1255
2022-09-28 14:03:15 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.4, ups=0.9, wpb=101, bsz=40, num_updates=1110, lr=2.81369e-05, gnorm=1.852, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1267
2022-09-28 14:03:27 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.5, ups=0.88, wpb=100.6, bsz=40, num_updates=1120, lr=2.83904e-05, gnorm=1.868, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1278
2022-09-28 14:03:38 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.1, ups=0.89, wpb=99.3, bsz=40, num_updates=1130, lr=2.86439e-05, gnorm=1.815, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1289
2022-09-28 14:03:49 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.5, ups=0.9, wpb=101.8, bsz=40, num_updates=1140, lr=2.88973e-05, gnorm=1.773, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1300
2022-09-28 14:04:00 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.6, ups=0.88, wpb=102.3, bsz=40, num_updates=1150, lr=2.91508e-05, gnorm=1.632, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1312
2022-09-28 14:04:12 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.9, ups=0.9, wpb=100.8, bsz=40, num_updates=1160, lr=2.94043e-05, gnorm=1.938, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1323
2022-09-28 14:04:23 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.5, ups=0.89, wpb=101.9, bsz=40, num_updates=1170, lr=2.96578e-05, gnorm=1.983, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1334
2022-09-28 14:04:34 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.4, ups=0.89, wpb=102, bsz=40, num_updates=1180, lr=2.99113e-05, gnorm=1.797, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1345
2022-09-28 14:04:46 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88, ups=0.87, wpb=101.5, bsz=40, num_updates=1190, lr=3.01648e-05, gnorm=1.768, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1357
2022-09-28 14:04:57 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.7, ups=0.87, wpb=101, bsz=40, num_updates=1200, lr=3.04183e-05, gnorm=1.615, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1369
2022-09-28 14:05:08 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.1, ups=0.9, wpb=99.6, bsz=40, num_updates=1210, lr=3.06717e-05, gnorm=1.963, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1380
2022-09-28 14:05:19 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.8, ups=0.89, wpb=102, bsz=40, num_updates=1220, lr=3.09252e-05, gnorm=1.696, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1391
2022-09-28 14:05:31 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.88, wpb=101.2, bsz=40, num_updates=1230, lr=3.11787e-05, gnorm=1.674, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1402
2022-09-28 14:05:42 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.3, ups=0.88, wpb=100, bsz=40, num_updates=1240, lr=3.14322e-05, gnorm=1.65, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1414
2022-09-28 14:05:54 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.1, ups=0.88, wpb=102.3, bsz=40, num_updates=1250, lr=3.16857e-05, gnorm=1.792, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1425
2022-09-28 14:06:05 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=1260, lr=3.19392e-05, gnorm=1.56, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1436
2022-09-28 14:06:16 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.4, ups=0.93, wpb=102, bsz=40, num_updates=1270, lr=3.21926e-05, gnorm=1.752, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1447
2022-09-28 14:06:27 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.88, wpb=102.1, bsz=40, num_updates=1280, lr=3.24461e-05, gnorm=1.574, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1459
2022-09-28 14:06:38 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.91, wpb=100.7, bsz=40, num_updates=1290, lr=3.26996e-05, gnorm=1.646, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1470
2022-09-28 14:06:50 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.6, ups=0.89, wpb=101.4, bsz=40, num_updates=1300, lr=3.29531e-05, gnorm=1.541, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1481
2022-09-28 14:07:01 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.9, ups=0.92, wpb=101.2, bsz=40, num_updates=1310, lr=3.32066e-05, gnorm=1.707, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1492
2022-09-28 14:07:11 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.8, ups=0.92, wpb=101.3, bsz=40, num_updates=1320, lr=3.34601e-05, gnorm=1.792, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1503
2022-09-28 14:07:22 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 15783 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.2, ups=0.93, wpb=100.2, bsz=40, num_updates=1330, lr=3.37136e-05, gnorm=1.783, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1514
2022-09-28 14:07:33 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.9, wpb=101.3, bsz=40, num_updates=1340, lr=3.3967e-05, gnorm=1.545, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1525
2022-09-28 14:07:45 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.88, wpb=101.2, bsz=40, num_updates=1350, lr=3.42205e-05, gnorm=1.56, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1536
2022-09-28 14:07:56 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91, ups=0.9, wpb=101, bsz=40, num_updates=1360, lr=3.4474e-05, gnorm=1.654, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1547
2022-09-28 14:08:06 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.8, ups=0.93, wpb=100.5, bsz=40, num_updates=1370, lr=3.47275e-05, gnorm=1.666, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1558
2022-09-28 14:08:18 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.89, wpb=101.9, bsz=40, num_updates=1380, lr=3.4981e-05, gnorm=1.518, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1569
2022-09-28 14:08:29 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 15783 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=1390, lr=3.52345e-05, gnorm=1.609, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1580
2022-09-28 14:08:40 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.1, ups=0.87, wpb=102.6, bsz=40, num_updates=1400, lr=3.5488e-05, gnorm=1.421, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1592
2022-09-28 14:08:51 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.4, ups=0.9, wpb=103.5, bsz=40, num_updates=1410, lr=3.57414e-05, gnorm=1.374, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1603
2022-09-28 14:09:03 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.2, ups=0.87, wpb=100.8, bsz=40, num_updates=1420, lr=3.59949e-05, gnorm=1.381, clip=90, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1614
2022-09-28 14:09:14 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.5, ups=0.88, wpb=103.7, bsz=40, num_updates=1430, lr=3.62484e-05, gnorm=1.541, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1626
2022-09-28 14:09:26 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.3, ups=0.89, wpb=101, bsz=40, num_updates=1440, lr=3.65019e-05, gnorm=1.541, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1637
2022-09-28 14:09:37 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.7, ups=0.88, wpb=100.9, bsz=40, num_updates=1450, lr=3.67554e-05, gnorm=1.579, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1648
2022-09-28 14:09:48 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.2, ups=0.89, wpb=101, bsz=40, num_updates=1460, lr=3.70089e-05, gnorm=1.734, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1659
2022-09-28 14:09:59 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94, ups=0.92, wpb=102.2, bsz=40, num_updates=1470, lr=3.72624e-05, gnorm=1.488, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1670
2022-09-28 14:10:10 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.9, ups=0.91, wpb=101.6, bsz=40, num_updates=1480, lr=3.75158e-05, gnorm=1.597, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1681
2022-09-28 14:10:21 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.91, wpb=101.8, bsz=40, num_updates=1490, lr=3.77693e-05, gnorm=1.453, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1692
2022-09-28 14:10:32 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.88, wpb=102.5, bsz=40, num_updates=1500, lr=3.80228e-05, gnorm=1.382, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1704
2022-09-28 14:10:43 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.6, ups=0.91, wpb=100.5, bsz=40, num_updates=1510, lr=3.82763e-05, gnorm=1.685, clip=90, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1715
2022-09-28 14:10:55 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.1, ups=0.88, wpb=101.5, bsz=40, num_updates=1520, lr=3.85298e-05, gnorm=1.31, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1726
2022-09-28 14:11:06 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.8, ups=0.88, wpb=100, bsz=40, num_updates=1530, lr=3.87833e-05, gnorm=1.353, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1737
2022-09-28 14:11:15 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 14:11:18 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=85, ups=0.84, wpb=101.3, bsz=40, num_updates=1540, lr=3.90368e-05, gnorm=1.496, clip=100, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=1749
2022-09-28 14:11:29 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92, ups=0.92, wpb=99.5, bsz=40, num_updates=1550, lr=3.92902e-05, gnorm=1.458, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1760
2022-09-28 14:11:40 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.87, wpb=102.6, bsz=40, num_updates=1560, lr=3.95437e-05, gnorm=1.198, clip=90, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1772
2022-09-28 14:11:52 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.88, wpb=101.2, bsz=40, num_updates=1570, lr=3.97972e-05, gnorm=1.421, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1783
2022-09-28 14:12:03 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90, ups=0.9, wpb=99.7, bsz=40, num_updates=1580, lr=4.00507e-05, gnorm=1.496, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1794
2022-09-28 14:12:14 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.6, ups=0.9, wpb=102.3, bsz=40, num_updates=1590, lr=4.03042e-05, gnorm=1.525, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1805
2022-09-28 14:12:25 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=1600, lr=4.05577e-05, gnorm=1.515, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1816
2022-09-28 14:12:36 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.9, wpb=101.3, bsz=40, num_updates=1610, lr=4.08112e-05, gnorm=1.394, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1828
2022-09-28 14:12:47 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=1620, lr=4.10646e-05, gnorm=1.622, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1839
2022-09-28 14:12:59 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.9, ups=0.87, wpb=102.6, bsz=40, num_updates=1630, lr=4.13181e-05, gnorm=1.496, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1850
2022-09-28 14:13:10 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.88, wpb=104.7, bsz=40, num_updates=1640, lr=4.15716e-05, gnorm=1.167, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1862
2022-09-28 14:13:22 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.5, ups=0.88, wpb=100.6, bsz=40, num_updates=1650, lr=4.18251e-05, gnorm=1.427, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1873
2022-09-28 14:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.3, ups=0.88, wpb=101.1, bsz=40, num_updates=1660, lr=4.20786e-05, gnorm=1.41, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1885
2022-09-28 14:13:44 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.5, ups=0.9, wpb=101.5, bsz=40, num_updates=1670, lr=4.23321e-05, gnorm=1.322, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1896
2022-09-28 14:13:55 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.6, ups=0.9, wpb=100.5, bsz=40, num_updates=1680, lr=4.25856e-05, gnorm=1.614, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1907
2022-09-28 14:14:07 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.88, wpb=100.9, bsz=40, num_updates=1690, lr=4.2839e-05, gnorm=1.584, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1918
2022-09-28 14:14:18 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.9, wpb=101, bsz=40, num_updates=1700, lr=4.30925e-05, gnorm=1.309, clip=100, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=1929
2022-09-28 14:14:29 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.1, ups=0.92, wpb=101.5, bsz=40, num_updates=1710, lr=4.3346e-05, gnorm=1.423, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1940
2022-09-28 14:14:40 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92, ups=0.9, wpb=101.9, bsz=40, num_updates=1720, lr=4.35995e-05, gnorm=1.389, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1951
2022-09-28 14:14:51 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 15783 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.3, ups=0.88, wpb=100.1, bsz=40, num_updates=1730, lr=4.3853e-05, gnorm=1.468, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1962
2022-09-28 14:15:02 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.89, wpb=102.4, bsz=40, num_updates=1740, lr=4.41065e-05, gnorm=1.331, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1974
2022-09-28 14:15:14 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.4, ups=0.89, wpb=100.4, bsz=40, num_updates=1750, lr=4.43599e-05, gnorm=1.467, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1985
2022-09-28 14:15:25 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.5, ups=0.87, wpb=100.7, bsz=40, num_updates=1760, lr=4.46134e-05, gnorm=1.334, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1996
2022-09-28 14:15:36 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.88, wpb=101.6, bsz=40, num_updates=1770, lr=4.48669e-05, gnorm=1.266, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2008
2022-09-28 14:15:48 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.8, ups=0.88, wpb=101.8, bsz=40, num_updates=1780, lr=4.51204e-05, gnorm=1.313, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2019
2022-09-28 14:15:59 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.1, ups=0.89, wpb=103.8, bsz=40, num_updates=1790, lr=4.53739e-05, gnorm=1.215, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2030
2022-09-28 14:16:10 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.9, ups=0.91, wpb=103, bsz=40, num_updates=1800, lr=4.56274e-05, gnorm=1.421, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2042
2022-09-28 14:16:22 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.2, ups=0.89, wpb=101.5, bsz=40, num_updates=1810, lr=4.58809e-05, gnorm=1.495, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2053
2022-09-28 14:16:33 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.1, ups=0.89, wpb=99, bsz=40, num_updates=1820, lr=4.61343e-05, gnorm=1.539, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2064
2022-09-28 14:16:44 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 15783 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.4, ups=0.89, wpb=100.7, bsz=40, num_updates=1830, lr=4.63878e-05, gnorm=1.44, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2075
2022-09-28 14:16:55 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.5, ups=0.89, wpb=101.7, bsz=40, num_updates=1840, lr=4.66413e-05, gnorm=1.189, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2087
2022-09-28 14:17:07 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.6, ups=0.89, wpb=101.8, bsz=40, num_updates=1850, lr=4.68948e-05, gnorm=1.351, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2098
2022-09-28 14:17:18 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.89, wpb=103, bsz=40, num_updates=1860, lr=4.71483e-05, gnorm=1.556, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2109
2022-09-28 14:17:29 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.7, ups=0.88, wpb=100.9, bsz=40, num_updates=1870, lr=4.74018e-05, gnorm=1.217, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2121
2022-09-28 14:17:41 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.86, wpb=102.6, bsz=40, num_updates=1880, lr=4.76553e-05, gnorm=1.223, clip=80, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2132
2022-09-28 14:17:52 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.4, ups=0.9, wpb=100.3, bsz=40, num_updates=1890, lr=4.79087e-05, gnorm=1.281, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2143
2022-09-28 14:18:03 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.9, wpb=101.8, bsz=40, num_updates=1900, lr=4.81622e-05, gnorm=1.218, clip=80, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=2154
2022-09-28 14:18:14 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.5, ups=0.91, wpb=101.2, bsz=40, num_updates=1910, lr=4.84157e-05, gnorm=1.116, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2165
2022-09-28 14:18:25 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.88, wpb=101.1, bsz=40, num_updates=1920, lr=4.86692e-05, gnorm=1.313, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2177
2022-09-28 14:18:37 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.5, ups=0.9, wpb=103.5, bsz=40, num_updates=1930, lr=4.89227e-05, gnorm=1.224, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2188
2022-09-28 14:18:48 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=1940, lr=4.91762e-05, gnorm=1.432, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2199
2022-09-28 14:18:59 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=1950, lr=4.94297e-05, gnorm=1.292, clip=90, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2210
2022-09-28 14:19:10 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.88, wpb=100.8, bsz=40, num_updates=1960, lr=4.96831e-05, gnorm=1.213, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2222
2022-09-28 14:19:21 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.2, ups=0.92, wpb=102.9, bsz=40, num_updates=1970, lr=4.99366e-05, gnorm=1.272, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2233
2022-09-28 14:19:32 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.6, ups=0.91, wpb=100.5, bsz=40, num_updates=1980, lr=5.01901e-05, gnorm=1.276, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2244
2022-09-28 14:19:43 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.7, ups=0.89, wpb=99.8, bsz=40, num_updates=1990, lr=5.04436e-05, gnorm=1.244, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2255
2022-09-28 14:19:54 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.3, ups=0.9, wpb=101.1, bsz=40, num_updates=2000, lr=5.06971e-05, gnorm=1.272, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2266
2022-09-28 14:20:06 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.89, wpb=102.6, bsz=40, num_updates=2010, lr=5.09506e-05, gnorm=1.045, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2277
2022-09-28 14:20:17 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.6, ups=0.91, wpb=102.2, bsz=40, num_updates=2020, lr=5.12041e-05, gnorm=1.187, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2288
2022-09-28 14:20:28 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.1, ups=0.9, wpb=103.3, bsz=40, num_updates=2030, lr=5.14575e-05, gnorm=1.209, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2299
2022-09-28 14:20:39 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.3, ups=0.88, wpb=101.3, bsz=40, num_updates=2040, lr=5.1711e-05, gnorm=1.113, clip=70, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2311
2022-09-28 14:20:50 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.4, ups=0.89, wpb=102.5, bsz=40, num_updates=2050, lr=5.19645e-05, gnorm=1.088, clip=80, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2322
2022-09-28 14:20:55 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 14:21:02 - progress_bar.py[line:274] - INFO: epoch 001:   2062 / 15783 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=85, ups=0.85, wpb=100.2, bsz=40, num_updates=2060, lr=5.2218e-05, gnorm=1.325, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=2334
2022-09-28 14:21:14 - progress_bar.py[line:274] - INFO: epoch 001:   2072 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.8, ups=0.89, wpb=102.1, bsz=40, num_updates=2070, lr=5.24715e-05, gnorm=1.285, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2345
2022-09-28 14:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   2082 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94, ups=0.92, wpb=101.9, bsz=40, num_updates=2080, lr=5.2725e-05, gnorm=1.251, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2357
2022-09-28 14:21:37 - progress_bar.py[line:274] - INFO: epoch 001:   2092 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.8, ups=0.87, wpb=100.5, bsz=40, num_updates=2090, lr=5.29785e-05, gnorm=1.195, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2368
2022-09-28 14:21:47 - progress_bar.py[line:274] - INFO: epoch 001:   2102 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94, ups=0.92, wpb=101.7, bsz=40, num_updates=2100, lr=5.32319e-05, gnorm=1.275, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2379
2022-09-28 14:21:59 - progress_bar.py[line:274] - INFO: epoch 001:   2112 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.9, wpb=101.1, bsz=40, num_updates=2110, lr=5.34854e-05, gnorm=1.309, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2390
2022-09-28 14:22:09 - progress_bar.py[line:274] - INFO: epoch 001:   2122 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.1, ups=0.93, wpb=101.6, bsz=40, num_updates=2120, lr=5.37389e-05, gnorm=1.183, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2401
2022-09-28 14:22:21 - progress_bar.py[line:274] - INFO: epoch 001:   2132 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.89, wpb=102.3, bsz=40, num_updates=2130, lr=5.39924e-05, gnorm=1.146, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2412
2022-09-28 14:22:32 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.9, ups=0.87, wpb=101.3, bsz=40, num_updates=2140, lr=5.42459e-05, gnorm=1.298, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2424
2022-09-28 14:22:44 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.8, ups=0.86, wpb=101.7, bsz=40, num_updates=2150, lr=5.44994e-05, gnorm=1.071, clip=80, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=2435
2022-09-28 14:22:55 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.7, ups=0.9, wpb=100.9, bsz=40, num_updates=2160, lr=5.47529e-05, gnorm=1.367, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2446
2022-09-28 14:23:06 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.9, ups=0.89, wpb=103.3, bsz=40, num_updates=2170, lr=5.50063e-05, gnorm=1.332, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2457
2022-09-28 14:23:17 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.89, wpb=102.8, bsz=40, num_updates=2180, lr=5.52598e-05, gnorm=1.169, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2469
2022-09-28 14:23:28 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.3, ups=0.93, wpb=101.7, bsz=40, num_updates=2190, lr=5.55133e-05, gnorm=1.178, clip=90, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2480
2022-09-28 14:23:39 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.91, wpb=101.5, bsz=40, num_updates=2200, lr=5.57668e-05, gnorm=1.28, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2490
2022-09-28 14:23:50 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.3, ups=0.88, wpb=100.5, bsz=40, num_updates=2210, lr=5.60203e-05, gnorm=1.188, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2502
2022-09-28 14:24:02 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=2220, lr=5.62738e-05, gnorm=1.287, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2513
2022-09-28 14:24:13 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.2, ups=0.91, wpb=101.2, bsz=40, num_updates=2230, lr=5.65272e-05, gnorm=1.35, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2524
2022-09-28 14:24:24 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.2, ups=0.89, wpb=102.7, bsz=40, num_updates=2240, lr=5.67807e-05, gnorm=1.264, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2536
2022-09-28 14:24:35 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.9, ups=0.89, wpb=100.1, bsz=40, num_updates=2250, lr=5.70342e-05, gnorm=1.23, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2547
2022-09-28 14:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93, ups=0.91, wpb=102.6, bsz=40, num_updates=2260, lr=5.72877e-05, gnorm=1.138, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2558
2022-09-28 14:24:57 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.5, ups=0.91, wpb=100.5, bsz=40, num_updates=2270, lr=5.75412e-05, gnorm=1.317, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2569
2022-09-28 14:25:09 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=2280, lr=5.77947e-05, gnorm=1.119, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2580
2022-09-28 14:25:20 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.7, ups=0.89, wpb=99.8, bsz=40, num_updates=2290, lr=5.80482e-05, gnorm=1.358, clip=90, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=2591
2022-09-28 14:25:31 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.6, ups=0.89, wpb=99.6, bsz=40, num_updates=2300, lr=5.83016e-05, gnorm=1.436, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2603
2022-09-28 14:25:42 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.89, wpb=102.5, bsz=40, num_updates=2310, lr=5.85551e-05, gnorm=1.107, clip=80, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2614
2022-09-28 14:25:54 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.6, ups=0.88, wpb=102.8, bsz=40, num_updates=2320, lr=5.88086e-05, gnorm=1.078, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2625
2022-09-28 14:26:05 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.1, ups=0.9, wpb=100.1, bsz=40, num_updates=2330, lr=5.90621e-05, gnorm=1.345, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2636
2022-09-28 14:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.9, wpb=102, bsz=40, num_updates=2340, lr=5.93156e-05, gnorm=1.299, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2647
2022-09-28 14:26:27 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.4, ups=0.88, wpb=100.5, bsz=40, num_updates=2350, lr=5.95691e-05, gnorm=1.229, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2659
2022-09-28 14:26:39 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.88, wpb=102.1, bsz=40, num_updates=2360, lr=5.98226e-05, gnorm=1.076, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2670
2022-09-28 14:26:50 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.2, ups=0.89, wpb=99.3, bsz=40, num_updates=2370, lr=6.0076e-05, gnorm=1.193, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2681
2022-09-28 14:27:01 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.89, wpb=102.7, bsz=40, num_updates=2380, lr=6.03295e-05, gnorm=1.262, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2693
2022-09-28 14:27:13 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.8, ups=0.88, wpb=100.8, bsz=40, num_updates=2390, lr=6.0583e-05, gnorm=1.057, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2704
2022-09-28 14:27:25 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.87, wpb=102.4, bsz=40, num_updates=2400, lr=6.08365e-05, gnorm=1.152, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2716
2022-09-28 14:27:36 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.91, wpb=100.5, bsz=40, num_updates=2410, lr=6.109e-05, gnorm=1.116, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2727
2022-09-28 14:27:47 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.91, wpb=101.7, bsz=40, num_updates=2420, lr=6.13435e-05, gnorm=1.247, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2738
2022-09-28 14:27:57 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.9, ups=0.93, wpb=100.5, bsz=40, num_updates=2430, lr=6.1597e-05, gnorm=1.199, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2749
2022-09-28 14:28:09 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87, ups=0.87, wpb=100.3, bsz=40, num_updates=2440, lr=6.18504e-05, gnorm=1.18, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2760
2022-09-28 14:28:20 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.89, wpb=102.1, bsz=40, num_updates=2450, lr=6.21039e-05, gnorm=1.195, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2772
2022-09-28 14:28:31 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.89, wpb=101.5, bsz=40, num_updates=2460, lr=6.23574e-05, gnorm=1.181, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2783
2022-09-28 14:28:43 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.87, wpb=102.3, bsz=40, num_updates=2470, lr=6.26109e-05, gnorm=1.224, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2794
2022-09-28 14:28:54 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.9, ups=0.89, wpb=100.7, bsz=40, num_updates=2480, lr=6.28644e-05, gnorm=1.301, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2806
2022-09-28 14:29:06 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.9, ups=0.88, wpb=101.2, bsz=40, num_updates=2490, lr=6.31179e-05, gnorm=1.237, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2817
2022-09-28 14:29:17 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=2500, lr=6.33714e-05, gnorm=1.065, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2828
2022-09-28 14:29:28 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.89, wpb=103.1, bsz=40, num_updates=2510, lr=6.36248e-05, gnorm=0.983, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2839
2022-09-28 14:29:39 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.5, ups=0.9, wpb=100.1, bsz=40, num_updates=2520, lr=6.38783e-05, gnorm=1.062, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2851
2022-09-28 14:29:50 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 15783 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.9, ups=0.89, wpb=98.8, bsz=40, num_updates=2530, lr=6.41318e-05, gnorm=1.212, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2862
2022-09-28 14:30:01 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91, ups=0.9, wpb=100.8, bsz=40, num_updates=2540, lr=6.43853e-05, gnorm=1.221, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2873
2022-09-28 14:30:13 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.7, ups=0.9, wpb=100.4, bsz=40, num_updates=2550, lr=6.46388e-05, gnorm=1.205, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2884
2022-09-28 14:30:24 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.7, ups=0.9, wpb=99.3, bsz=40, num_updates=2560, lr=6.48923e-05, gnorm=0.989, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2895
2022-09-28 14:30:35 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 14:30:36 - progress_bar.py[line:274] - INFO: epoch 001:   2573 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=80.4, ups=0.81, wpb=99.8, bsz=40, num_updates=2570, lr=6.51458e-05, gnorm=1.293, clip=80, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2907
2022-09-28 14:30:47 - progress_bar.py[line:274] - INFO: epoch 001:   2583 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.6, ups=0.9, wpb=101.8, bsz=40, num_updates=2580, lr=6.53992e-05, gnorm=0.986, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2919
2022-09-28 14:30:59 - progress_bar.py[line:274] - INFO: epoch 001:   2593 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.1, ups=0.88, wpb=100.1, bsz=40, num_updates=2590, lr=6.56527e-05, gnorm=1.11, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2930
2022-09-28 14:31:10 - progress_bar.py[line:274] - INFO: epoch 001:   2603 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.4, ups=0.89, wpb=100.5, bsz=40, num_updates=2600, lr=6.59062e-05, gnorm=1.156, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2941
2022-09-28 14:31:21 - progress_bar.py[line:274] - INFO: epoch 001:   2613 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.7, ups=0.88, wpb=100.9, bsz=40, num_updates=2610, lr=6.61597e-05, gnorm=1.052, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2953
2022-09-28 14:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   2623 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.4, ups=0.92, wpb=101.1, bsz=40, num_updates=2620, lr=6.64132e-05, gnorm=1.037, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2963
2022-09-28 14:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   2633 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.8, ups=0.9, wpb=102.4, bsz=40, num_updates=2630, lr=6.66667e-05, gnorm=1.029, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2975
2022-09-28 14:31:54 - progress_bar.py[line:274] - INFO: epoch 001:   2643 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.3, ups=0.92, wpb=102.7, bsz=40, num_updates=2640, lr=6.69202e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2985
2022-09-28 14:32:05 - progress_bar.py[line:274] - INFO: epoch 001:   2653 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.5, ups=0.91, wpb=103.3, bsz=40, num_updates=2650, lr=6.71736e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2996
2022-09-28 14:32:16 - progress_bar.py[line:274] - INFO: epoch 001:   2663 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90, ups=0.89, wpb=101.2, bsz=40, num_updates=2660, lr=6.74271e-05, gnorm=1.038, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3008
2022-09-28 14:32:27 - progress_bar.py[line:274] - INFO: epoch 001:   2673 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.89, wpb=102.2, bsz=40, num_updates=2670, lr=6.76806e-05, gnorm=1.042, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3019
2022-09-28 14:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   2683 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=2680, lr=6.79341e-05, gnorm=0.997, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3030
2022-09-28 14:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   2693 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.7, ups=0.9, wpb=100, bsz=40, num_updates=2690, lr=6.81876e-05, gnorm=1.053, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3041
2022-09-28 14:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   2703 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=2700, lr=6.84411e-05, gnorm=1.008, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=3053
2022-09-28 14:33:13 - progress_bar.py[line:274] - INFO: epoch 001:   2713 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=2710, lr=6.86946e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3064
2022-09-28 14:33:24 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89, ups=0.89, wpb=100.1, bsz=40, num_updates=2720, lr=6.8948e-05, gnorm=1.108, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3075
2022-09-28 14:33:35 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.1, ups=0.89, wpb=101.1, bsz=40, num_updates=2730, lr=6.92015e-05, gnorm=1.257, clip=70, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=3087
2022-09-28 14:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.89, wpb=103.1, bsz=40, num_updates=2740, lr=6.9455e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3098
2022-09-28 14:33:57 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.5, ups=0.94, wpb=99.9, bsz=40, num_updates=2750, lr=6.97085e-05, gnorm=1.251, clip=90, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3109
2022-09-28 14:34:08 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.1, ups=0.9, wpb=102.3, bsz=40, num_updates=2760, lr=6.9962e-05, gnorm=1.121, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3120
2022-09-28 14:34:19 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.2, ups=0.92, wpb=100.4, bsz=40, num_updates=2770, lr=7.02155e-05, gnorm=1.04, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3131
2022-09-28 14:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=2780, lr=7.04689e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3142
2022-09-28 14:34:42 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=2790, lr=7.07224e-05, gnorm=1.079, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3153
2022-09-28 14:34:53 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 15783 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.7, ups=0.89, wpb=101.6, bsz=40, num_updates=2800, lr=7.09759e-05, gnorm=1.472, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3164
2022-09-28 14:35:04 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.7, ups=0.91, wpb=101.2, bsz=40, num_updates=2810, lr=7.12294e-05, gnorm=0.998, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3175
2022-09-28 14:35:15 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.91, wpb=100.5, bsz=40, num_updates=2820, lr=7.14829e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3186
2022-09-28 14:35:26 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.3, ups=0.93, wpb=102.3, bsz=40, num_updates=2830, lr=7.17364e-05, gnorm=0.966, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=3197
2022-09-28 14:35:37 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.9, wpb=101.9, bsz=40, num_updates=2840, lr=7.19899e-05, gnorm=1.116, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3208
2022-09-28 14:35:48 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.5, ups=0.89, wpb=102.7, bsz=40, num_updates=2850, lr=7.22433e-05, gnorm=1.028, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=3219
2022-09-28 14:35:59 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=2860, lr=7.24968e-05, gnorm=1.287, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3231
2022-09-28 14:36:11 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.9, ups=0.88, wpb=100.8, bsz=40, num_updates=2870, lr=7.27503e-05, gnorm=1.137, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3242
2022-09-28 14:36:22 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89, ups=0.88, wpb=101, bsz=40, num_updates=2880, lr=7.30038e-05, gnorm=1.076, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3253
2022-09-28 14:36:33 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=2890, lr=7.32573e-05, gnorm=0.996, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3265
2022-09-28 14:36:44 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.3, ups=0.92, wpb=101.3, bsz=40, num_updates=2900, lr=7.35108e-05, gnorm=1.083, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3275
2022-09-28 14:36:55 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.6, ups=0.91, wpb=100.2, bsz=40, num_updates=2910, lr=7.37643e-05, gnorm=1.107, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3286
2022-09-28 14:37:06 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93, ups=0.92, wpb=101.3, bsz=40, num_updates=2920, lr=7.40177e-05, gnorm=0.933, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3297
2022-09-28 14:37:17 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.1, ups=0.88, wpb=101.3, bsz=40, num_updates=2930, lr=7.42712e-05, gnorm=1.077, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3309
2022-09-28 14:37:28 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=2940, lr=7.45247e-05, gnorm=1.026, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3320
2022-09-28 14:37:40 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=2950, lr=7.47782e-05, gnorm=0.927, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3331
2022-09-28 14:37:51 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.2, ups=0.89, wpb=102.3, bsz=40, num_updates=2960, lr=7.50317e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3342
2022-09-28 14:38:02 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.4, ups=0.9, wpb=100.2, bsz=40, num_updates=2970, lr=7.52852e-05, gnorm=1.064, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3353
2022-09-28 14:38:13 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=2980, lr=7.55387e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3365
2022-09-28 14:38:25 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=2990, lr=7.57921e-05, gnorm=1.184, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3376
2022-09-28 14:38:36 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.8, ups=0.89, wpb=100.6, bsz=40, num_updates=3000, lr=7.60456e-05, gnorm=0.907, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3387
2022-09-28 14:38:47 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.5, ups=0.88, wpb=100.7, bsz=40, num_updates=3010, lr=7.62991e-05, gnorm=1.137, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3399
2022-09-28 14:38:58 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.4, ups=0.91, wpb=99.6, bsz=40, num_updates=3020, lr=7.65526e-05, gnorm=1.143, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3410
2022-09-28 14:39:09 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.9, ups=0.91, wpb=102.6, bsz=40, num_updates=3030, lr=7.68061e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3421
2022-09-28 14:39:20 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.1, ups=0.91, wpb=101.4, bsz=40, num_updates=3040, lr=7.70596e-05, gnorm=0.983, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3432
2022-09-28 14:39:32 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.1, ups=0.89, wpb=102.3, bsz=40, num_updates=3050, lr=7.73131e-05, gnorm=0.935, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3443
2022-09-28 14:39:42 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.9, ups=0.91, wpb=100.5, bsz=40, num_updates=3060, lr=7.75665e-05, gnorm=1.054, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3454
2022-09-28 14:39:53 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.7, ups=0.93, wpb=101, bsz=40, num_updates=3070, lr=7.782e-05, gnorm=1.044, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3465
2022-09-28 14:40:05 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.2, ups=0.88, wpb=100, bsz=40, num_updates=3080, lr=7.80735e-05, gnorm=1.157, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3476
2022-09-28 14:40:11 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 14:40:17 - progress_bar.py[line:274] - INFO: epoch 001:   3094 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=81.6, ups=0.8, wpb=101.5, bsz=40, num_updates=3090, lr=7.8327e-05, gnorm=1.079, clip=60, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=3488
2022-09-28 14:40:28 - progress_bar.py[line:274] - INFO: epoch 001:   3104 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.1, ups=0.91, wpb=101.7, bsz=40, num_updates=3100, lr=7.85805e-05, gnorm=1.073, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3499
2022-09-28 14:40:39 - progress_bar.py[line:274] - INFO: epoch 001:   3114 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.92, wpb=101, bsz=40, num_updates=3110, lr=7.8834e-05, gnorm=0.972, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3510
2022-09-28 14:40:50 - progress_bar.py[line:274] - INFO: epoch 001:   3124 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.6, ups=0.9, wpb=99.7, bsz=40, num_updates=3120, lr=7.90875e-05, gnorm=1.104, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3521
2022-09-28 14:41:01 - progress_bar.py[line:274] - INFO: epoch 001:   3134 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.5, ups=0.9, wpb=102.1, bsz=40, num_updates=3130, lr=7.93409e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=3532
2022-09-28 14:41:12 - progress_bar.py[line:274] - INFO: epoch 001:   3144 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.3, ups=0.89, wpb=102.1, bsz=40, num_updates=3140, lr=7.95944e-05, gnorm=0.906, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3544
2022-09-28 14:41:23 - progress_bar.py[line:274] - INFO: epoch 001:   3154 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.2, ups=0.91, wpb=102.2, bsz=40, num_updates=3150, lr=7.98479e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3555
2022-09-28 14:41:35 - progress_bar.py[line:274] - INFO: epoch 001:   3164 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.88, wpb=100.4, bsz=40, num_updates=3160, lr=7.99958e-05, gnorm=0.869, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3566
2022-09-28 14:41:46 - progress_bar.py[line:274] - INFO: epoch 001:   3174 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.6, ups=0.89, wpb=102.6, bsz=40, num_updates=3170, lr=7.99852e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3577
2022-09-28 14:41:57 - progress_bar.py[line:274] - INFO: epoch 001:   3184 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.9, ups=0.9, wpb=101.6, bsz=40, num_updates=3180, lr=7.99747e-05, gnorm=0.926, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3588
2022-09-28 14:42:08 - progress_bar.py[line:274] - INFO: epoch 001:   3194 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.89, wpb=100.4, bsz=40, num_updates=3190, lr=7.99641e-05, gnorm=1.048, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3600
2022-09-28 14:42:19 - progress_bar.py[line:274] - INFO: epoch 001:   3204 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.89, wpb=101.7, bsz=40, num_updates=3200, lr=7.99535e-05, gnorm=1.052, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3611
2022-09-28 14:42:31 - progress_bar.py[line:274] - INFO: epoch 001:   3214 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.5, ups=0.88, wpb=100.7, bsz=40, num_updates=3210, lr=7.9943e-05, gnorm=1.04, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3622
2022-09-28 14:42:42 - progress_bar.py[line:274] - INFO: epoch 001:   3224 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.7, ups=0.9, wpb=101.3, bsz=40, num_updates=3220, lr=7.99324e-05, gnorm=0.876, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3633
2022-09-28 14:42:53 - progress_bar.py[line:274] - INFO: epoch 001:   3234 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.6, ups=0.87, wpb=100.6, bsz=40, num_updates=3230, lr=7.99219e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3645
2022-09-28 14:43:05 - progress_bar.py[line:274] - INFO: epoch 001:   3244 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.8, ups=0.87, wpb=100.7, bsz=40, num_updates=3240, lr=7.99113e-05, gnorm=1.022, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3656
2022-09-28 14:43:16 - progress_bar.py[line:274] - INFO: epoch 001:   3254 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.2, ups=0.88, wpb=100.8, bsz=40, num_updates=3250, lr=7.99007e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3668
2022-09-28 14:43:27 - progress_bar.py[line:274] - INFO: epoch 001:   3264 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.9, wpb=100.8, bsz=40, num_updates=3260, lr=7.98902e-05, gnorm=0.925, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3679
2022-09-28 14:43:38 - progress_bar.py[line:274] - INFO: epoch 001:   3274 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.89, wpb=100.6, bsz=40, num_updates=3270, lr=7.98796e-05, gnorm=1.19, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3690
2022-09-28 14:43:49 - progress_bar.py[line:274] - INFO: epoch 001:   3284 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.5, ups=0.95, wpb=100.4, bsz=40, num_updates=3280, lr=7.98691e-05, gnorm=0.99, clip=40, loss_scale=512, train_wall=10, gb_free=10.5, ema_decay=0.9999, wall=3700
2022-09-28 14:44:00 - progress_bar.py[line:274] - INFO: epoch 001:   3294 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.7, ups=0.91, wpb=101.4, bsz=40, num_updates=3290, lr=7.98585e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3711
2022-09-28 14:44:11 - progress_bar.py[line:274] - INFO: epoch 001:   3304 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=3300, lr=7.98479e-05, gnorm=1.059, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3723
2022-09-28 14:44:22 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.5, ups=0.92, wpb=101.2, bsz=40, num_updates=3310, lr=7.98374e-05, gnorm=1.079, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3733
2022-09-28 14:44:33 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.1, ups=0.94, wpb=101.4, bsz=40, num_updates=3320, lr=7.98268e-05, gnorm=0.985, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3744
2022-09-28 14:44:44 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.3, ups=0.89, wpb=99, bsz=40, num_updates=3330, lr=7.98163e-05, gnorm=1.065, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3755
2022-09-28 14:44:55 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.7, ups=0.9, wpb=103.6, bsz=40, num_updates=3340, lr=7.98057e-05, gnorm=0.996, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3766
2022-09-28 14:45:06 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.5, ups=0.91, wpb=101.8, bsz=40, num_updates=3350, lr=7.97951e-05, gnorm=0.888, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3777
2022-09-28 14:45:17 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=3360, lr=7.97846e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3789
2022-09-28 14:45:29 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.1, ups=0.88, wpb=100.8, bsz=40, num_updates=3370, lr=7.9774e-05, gnorm=0.981, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3800
2022-09-28 14:45:40 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.4, ups=0.88, wpb=101.8, bsz=40, num_updates=3380, lr=7.97635e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3811
2022-09-28 14:45:51 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.6, ups=0.9, wpb=99.7, bsz=40, num_updates=3390, lr=7.97529e-05, gnorm=0.917, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3822
2022-09-28 14:46:01 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.2, ups=0.96, wpb=100.8, bsz=40, num_updates=3400, lr=7.97423e-05, gnorm=0.839, clip=30, loss_scale=512, train_wall=10, gb_free=10.9, ema_decay=0.9999, wall=3833
2022-09-28 14:46:13 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 15783 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88, ups=0.88, wpb=100.3, bsz=40, num_updates=3410, lr=7.97318e-05, gnorm=0.912, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=3844
2022-09-28 14:46:24 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.9, wpb=102, bsz=40, num_updates=3420, lr=7.97212e-05, gnorm=0.983, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3855
2022-09-28 14:46:36 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.9, ups=0.88, wpb=101, bsz=40, num_updates=3430, lr=7.97107e-05, gnorm=0.869, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3867
2022-09-28 14:46:47 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.89, wpb=102.5, bsz=40, num_updates=3440, lr=7.97001e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3878
2022-09-28 14:46:58 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.4, ups=0.87, wpb=101.7, bsz=40, num_updates=3450, lr=7.96895e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3890
2022-09-28 14:47:10 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89, ups=0.89, wpb=99.8, bsz=40, num_updates=3460, lr=7.9679e-05, gnorm=1.03, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3901
2022-09-28 14:47:21 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.92, wpb=100.5, bsz=40, num_updates=3470, lr=7.96684e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3912
2022-09-28 14:47:32 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.9, ups=0.9, wpb=102.8, bsz=40, num_updates=3480, lr=7.96579e-05, gnorm=0.843, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3923
2022-09-28 14:47:43 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=3490, lr=7.96473e-05, gnorm=0.873, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3934
2022-09-28 14:47:54 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.6, ups=0.91, wpb=101.3, bsz=40, num_updates=3500, lr=7.96367e-05, gnorm=0.815, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3945
2022-09-28 14:48:05 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.9, ups=0.9, wpb=98.6, bsz=40, num_updates=3510, lr=7.96262e-05, gnorm=0.942, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3956
2022-09-28 14:48:16 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=3520, lr=7.96156e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3968
2022-09-28 14:48:27 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 15783 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.3, ups=0.91, wpb=100.5, bsz=40, num_updates=3530, lr=7.96051e-05, gnorm=1.099, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3979
2022-09-28 14:48:38 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92, ups=0.91, wpb=100.9, bsz=40, num_updates=3540, lr=7.95945e-05, gnorm=0.811, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3990
2022-09-28 14:48:49 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.7, ups=0.89, wpb=100.8, bsz=40, num_updates=3550, lr=7.95839e-05, gnorm=0.928, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4001
2022-09-28 14:49:01 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=101.5, bsz=40, num_updates=3560, lr=7.95734e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4012
2022-09-28 14:49:12 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.88, wpb=102, bsz=40, num_updates=3570, lr=7.95628e-05, gnorm=0.751, clip=0, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4024
2022-09-28 14:49:23 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=3580, lr=7.95523e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4035
2022-09-28 14:49:34 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.9, ups=0.91, wpb=101.9, bsz=40, num_updates=3590, lr=7.95417e-05, gnorm=0.868, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4046
2022-09-28 14:49:45 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.3, ups=0.9, wpb=102.8, bsz=40, num_updates=3600, lr=7.95311e-05, gnorm=1.042, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4057
2022-09-28 14:49:53 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 14:49:58 - progress_bar.py[line:274] - INFO: epoch 001:   3615 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=82.5, ups=0.8, wpb=102.8, bsz=40, num_updates=3610, lr=7.95206e-05, gnorm=0.859, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=4069
2022-09-28 14:50:09 - progress_bar.py[line:274] - INFO: epoch 001:   3625 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.9, ups=0.89, wpb=101.7, bsz=40, num_updates=3620, lr=7.951e-05, gnorm=0.983, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4081
2022-09-28 14:50:20 - progress_bar.py[line:274] - INFO: epoch 001:   3635 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.7, ups=0.89, wpb=100.9, bsz=40, num_updates=3630, lr=7.94995e-05, gnorm=0.847, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4092
2022-09-28 14:50:32 - progress_bar.py[line:274] - INFO: epoch 001:   3645 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.7, ups=0.88, wpb=102.6, bsz=40, num_updates=3640, lr=7.94889e-05, gnorm=0.766, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4103
2022-09-28 14:50:43 - progress_bar.py[line:274] - INFO: epoch 001:   3655 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.89, wpb=101.5, bsz=40, num_updates=3650, lr=7.94783e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4114
2022-09-28 14:50:54 - progress_bar.py[line:274] - INFO: epoch 001:   3665 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93, ups=0.92, wpb=100.8, bsz=40, num_updates=3660, lr=7.94678e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4125
2022-09-28 14:51:05 - progress_bar.py[line:274] - INFO: epoch 001:   3675 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.89, wpb=103, bsz=40, num_updates=3670, lr=7.94572e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4136
2022-09-28 14:51:16 - progress_bar.py[line:274] - INFO: epoch 001:   3685 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.8, ups=0.89, wpb=100, bsz=40, num_updates=3680, lr=7.94467e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4148
2022-09-28 14:51:27 - progress_bar.py[line:274] - INFO: epoch 001:   3695 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.3, ups=0.93, wpb=101, bsz=40, num_updates=3690, lr=7.94361e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4158
2022-09-28 14:51:38 - progress_bar.py[line:274] - INFO: epoch 001:   3705 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.6, ups=0.91, wpb=102.7, bsz=40, num_updates=3700, lr=7.94255e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4169
2022-09-28 14:51:49 - progress_bar.py[line:274] - INFO: epoch 001:   3715 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.88, wpb=104.2, bsz=40, num_updates=3710, lr=7.9415e-05, gnorm=0.76, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4181
2022-09-28 14:52:01 - progress_bar.py[line:274] - INFO: epoch 001:   3725 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.88, wpb=101.6, bsz=40, num_updates=3720, lr=7.94044e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4192
2022-09-28 14:52:12 - progress_bar.py[line:274] - INFO: epoch 001:   3735 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.1, ups=0.87, wpb=100.2, bsz=40, num_updates=3730, lr=7.93939e-05, gnorm=0.869, clip=20, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=4204
2022-09-28 14:52:24 - progress_bar.py[line:274] - INFO: epoch 001:   3745 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.87, wpb=102.4, bsz=40, num_updates=3740, lr=7.93833e-05, gnorm=0.898, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4215
2022-09-28 14:52:35 - progress_bar.py[line:274] - INFO: epoch 001:   3755 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.88, wpb=101.6, bsz=40, num_updates=3750, lr=7.93727e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4227
2022-09-28 14:52:46 - progress_bar.py[line:274] - INFO: epoch 001:   3765 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.2, ups=0.9, wpb=102.7, bsz=40, num_updates=3760, lr=7.93622e-05, gnorm=0.829, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4238
2022-09-28 14:52:58 - progress_bar.py[line:274] - INFO: epoch 001:   3775 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.4, ups=0.9, wpb=100.6, bsz=40, num_updates=3770, lr=7.93516e-05, gnorm=0.96, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4249
2022-09-28 14:53:09 - progress_bar.py[line:274] - INFO: epoch 001:   3785 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.1, ups=0.9, wpb=101, bsz=40, num_updates=3780, lr=7.93411e-05, gnorm=0.878, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4260
2022-09-28 14:53:20 - progress_bar.py[line:274] - INFO: epoch 001:   3795 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.88, wpb=101.6, bsz=40, num_updates=3790, lr=7.93305e-05, gnorm=0.79, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4271
2022-09-28 14:53:31 - progress_bar.py[line:274] - INFO: epoch 001:   3805 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.5, ups=0.88, wpb=102.2, bsz=40, num_updates=3800, lr=7.93199e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4283
2022-09-28 14:53:43 - progress_bar.py[line:274] - INFO: epoch 001:   3815 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.8, ups=0.89, wpb=100.2, bsz=40, num_updates=3810, lr=7.93094e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4294
2022-09-28 14:53:54 - progress_bar.py[line:274] - INFO: epoch 001:   3825 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.5, ups=0.92, wpb=100.7, bsz=40, num_updates=3820, lr=7.92988e-05, gnorm=0.731, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4305
2022-09-28 14:54:05 - progress_bar.py[line:274] - INFO: epoch 001:   3835 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.7, ups=0.88, wpb=101.1, bsz=40, num_updates=3830, lr=7.92883e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4316
2022-09-28 14:54:16 - progress_bar.py[line:274] - INFO: epoch 001:   3845 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.6, ups=0.92, wpb=102.4, bsz=40, num_updates=3840, lr=7.92777e-05, gnorm=0.87, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4327
2022-09-28 14:54:27 - progress_bar.py[line:274] - INFO: epoch 001:   3855 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.87, wpb=103, bsz=40, num_updates=3850, lr=7.92671e-05, gnorm=0.931, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4339
2022-09-28 14:54:39 - progress_bar.py[line:274] - INFO: epoch 001:   3865 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=3860, lr=7.92566e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4350
2022-09-28 14:54:49 - progress_bar.py[line:274] - INFO: epoch 001:   3875 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.7, ups=0.94, wpb=100.8, bsz=40, num_updates=3870, lr=7.9246e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4361
2022-09-28 14:55:01 - progress_bar.py[line:274] - INFO: epoch 001:   3885 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=3880, lr=7.92355e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4372
2022-09-28 14:55:12 - progress_bar.py[line:274] - INFO: epoch 001:   3895 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=3890, lr=7.92249e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4383
2022-09-28 14:55:23 - progress_bar.py[line:274] - INFO: epoch 001:   3905 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=3900, lr=7.92144e-05, gnorm=0.938, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4395
2022-09-28 14:55:35 - progress_bar.py[line:274] - INFO: epoch 001:   3915 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.88, wpb=104.5, bsz=40, num_updates=3910, lr=7.92038e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4406
2022-09-28 14:55:45 - progress_bar.py[line:274] - INFO: epoch 001:   3925 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.3, ups=0.92, wpb=100.9, bsz=40, num_updates=3920, lr=7.91932e-05, gnorm=1.061, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4417
2022-09-28 14:55:57 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.4, ups=0.87, wpb=102.2, bsz=40, num_updates=3930, lr=7.91827e-05, gnorm=0.859, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4428
2022-09-28 14:56:08 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.6, ups=0.89, wpb=99.9, bsz=40, num_updates=3940, lr=7.91721e-05, gnorm=0.952, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4440
2022-09-28 14:56:19 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.2, ups=0.95, wpb=102.7, bsz=40, num_updates=3950, lr=7.91616e-05, gnorm=0.969, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4450
2022-09-28 14:56:30 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.8, ups=0.89, wpb=100.2, bsz=40, num_updates=3960, lr=7.9151e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4461
2022-09-28 14:56:41 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.8, ups=0.88, wpb=99.7, bsz=40, num_updates=3970, lr=7.91404e-05, gnorm=0.981, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4473
2022-09-28 14:56:53 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.8, ups=0.87, wpb=101.1, bsz=40, num_updates=3980, lr=7.91299e-05, gnorm=0.951, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4484
2022-09-28 14:57:04 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.1, ups=0.9, wpb=101.9, bsz=40, num_updates=3990, lr=7.91193e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4495
2022-09-28 14:57:15 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.2, ups=0.91, wpb=99.9, bsz=40, num_updates=4000, lr=7.91088e-05, gnorm=0.775, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4506
2022-09-28 14:57:26 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.7, ups=0.9, wpb=101.1, bsz=40, num_updates=4010, lr=7.90982e-05, gnorm=0.931, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4518
2022-09-28 14:57:38 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.8, ups=0.88, wpb=99.9, bsz=40, num_updates=4020, lr=7.90876e-05, gnorm=0.884, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4529
2022-09-28 14:57:48 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93, ups=0.92, wpb=101.6, bsz=40, num_updates=4030, lr=7.90771e-05, gnorm=0.903, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4540
2022-09-28 14:58:00 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 15783 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.5, ups=0.88, wpb=99.6, bsz=40, num_updates=4040, lr=7.90665e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4551
2022-09-28 14:58:11 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.9, wpb=101.1, bsz=40, num_updates=4050, lr=7.9056e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4562
2022-09-28 14:58:22 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.3, ups=0.93, wpb=103, bsz=40, num_updates=4060, lr=7.90454e-05, gnorm=0.821, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4573
2022-09-28 14:58:33 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87, ups=0.88, wpb=99, bsz=40, num_updates=4070, lr=7.90348e-05, gnorm=0.826, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4584
2022-09-28 14:58:44 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97, ups=0.95, wpb=101.8, bsz=40, num_updates=4080, lr=7.90243e-05, gnorm=0.857, clip=40, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=4595
2022-09-28 14:58:55 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.8, ups=0.89, wpb=100, bsz=40, num_updates=4090, lr=7.90137e-05, gnorm=0.795, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4606
2022-09-28 14:59:06 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.1, ups=0.9, wpb=100.7, bsz=40, num_updates=4100, lr=7.90032e-05, gnorm=0.806, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4617
2022-09-28 14:59:17 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.9, ups=0.89, wpb=100.2, bsz=40, num_updates=4110, lr=7.89926e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4629
2022-09-28 14:59:28 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.3, ups=0.93, wpb=100.4, bsz=40, num_updates=4120, lr=7.8982e-05, gnorm=0.765, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4639
2022-09-28 14:59:39 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.88, wpb=102, bsz=40, num_updates=4130, lr=7.89715e-05, gnorm=0.882, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4651
2022-09-28 14:59:51 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.88, wpb=103.5, bsz=40, num_updates=4140, lr=7.89609e-05, gnorm=0.861, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4662
2022-09-28 15:00:02 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=85.8, ups=0.87, wpb=99.1, bsz=40, num_updates=4150, lr=7.89504e-05, gnorm=0.921, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4674
2022-09-28 15:00:14 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=102.5, bsz=40, num_updates=4160, lr=7.89398e-05, gnorm=0.8, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4685
2022-09-28 15:00:25 - progress_bar.py[line:274] - INFO: epoch 001:   4175 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.1, ups=0.89, wpb=99.9, bsz=40, num_updates=4170, lr=7.89292e-05, gnorm=0.952, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4696
2022-09-28 15:00:36 - progress_bar.py[line:274] - INFO: epoch 001:   4185 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90, ups=0.89, wpb=100.9, bsz=40, num_updates=4180, lr=7.89187e-05, gnorm=0.858, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=4707
2022-09-28 15:00:44 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 15:00:48 - progress_bar.py[line:274] - INFO: epoch 001:   4196 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=82.6, ups=0.81, wpb=101.7, bsz=40, num_updates=4190, lr=7.89081e-05, gnorm=0.928, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4720
2022-09-28 15:00:59 - progress_bar.py[line:274] - INFO: epoch 001:   4206 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.4, ups=0.9, wpb=101.7, bsz=40, num_updates=4200, lr=7.88976e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4731
2022-09-28 15:01:11 - progress_bar.py[line:274] - INFO: epoch 001:   4216 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.3, ups=0.88, wpb=100.7, bsz=40, num_updates=4210, lr=7.8887e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4742
2022-09-28 15:01:22 - progress_bar.py[line:274] - INFO: epoch 001:   4226 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.3, ups=0.88, wpb=100.8, bsz=40, num_updates=4220, lr=7.88764e-05, gnorm=0.875, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4754
2022-09-28 15:01:34 - progress_bar.py[line:274] - INFO: epoch 001:   4236 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=4230, lr=7.88659e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4765
2022-09-28 15:01:45 - progress_bar.py[line:274] - INFO: epoch 001:   4246 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.9, ups=0.87, wpb=101.6, bsz=40, num_updates=4240, lr=7.88553e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4776
2022-09-28 15:01:56 - progress_bar.py[line:274] - INFO: epoch 001:   4256 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92, ups=0.91, wpb=100.7, bsz=40, num_updates=4250, lr=7.88448e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4787
2022-09-28 15:02:07 - progress_bar.py[line:274] - INFO: epoch 001:   4266 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.9, ups=0.89, wpb=102.3, bsz=40, num_updates=4260, lr=7.88342e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4799
2022-09-28 15:02:18 - progress_bar.py[line:274] - INFO: epoch 001:   4276 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.2, ups=0.92, wpb=101.7, bsz=40, num_updates=4270, lr=7.88236e-05, gnorm=0.698, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4810
2022-09-28 15:02:30 - progress_bar.py[line:274] - INFO: epoch 001:   4286 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=4280, lr=7.88131e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4821
2022-09-28 15:02:41 - progress_bar.py[line:274] - INFO: epoch 001:   4296 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=4290, lr=7.88025e-05, gnorm=0.904, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4832
2022-09-28 15:02:52 - progress_bar.py[line:274] - INFO: epoch 001:   4306 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=4300, lr=7.8792e-05, gnorm=0.916, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4843
2022-09-28 15:03:03 - progress_bar.py[line:274] - INFO: epoch 001:   4316 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.5, ups=0.87, wpb=100.8, bsz=40, num_updates=4310, lr=7.87814e-05, gnorm=0.722, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4855
2022-09-28 15:03:14 - progress_bar.py[line:274] - INFO: epoch 001:   4326 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.9, ups=0.91, wpb=99.5, bsz=40, num_updates=4320, lr=7.87708e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4866
2022-09-28 15:03:25 - progress_bar.py[line:274] - INFO: epoch 001:   4336 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.7, ups=0.9, wpb=102.8, bsz=40, num_updates=4330, lr=7.87603e-05, gnorm=0.862, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4877
2022-09-28 15:03:37 - progress_bar.py[line:274] - INFO: epoch 001:   4346 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.7, ups=0.86, wpb=100.5, bsz=40, num_updates=4340, lr=7.87497e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4888
2022-09-28 15:03:48 - progress_bar.py[line:274] - INFO: epoch 001:   4356 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=4350, lr=7.87392e-05, gnorm=0.865, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4900
2022-09-28 15:04:00 - progress_bar.py[line:274] - INFO: epoch 001:   4366 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.6, ups=0.88, wpb=101.2, bsz=40, num_updates=4360, lr=7.87286e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4911
2022-09-28 15:04:11 - progress_bar.py[line:274] - INFO: epoch 001:   4376 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90, ups=0.89, wpb=101.4, bsz=40, num_updates=4370, lr=7.8718e-05, gnorm=0.962, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4922
2022-09-28 15:04:22 - progress_bar.py[line:274] - INFO: epoch 001:   4386 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=4380, lr=7.87075e-05, gnorm=1.001, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4934
2022-09-28 15:04:33 - progress_bar.py[line:274] - INFO: epoch 001:   4396 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.4, ups=0.92, wpb=101.8, bsz=40, num_updates=4390, lr=7.86969e-05, gnorm=1.043, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4945
2022-09-28 15:04:44 - progress_bar.py[line:274] - INFO: epoch 001:   4406 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.9, ups=0.89, wpb=99.9, bsz=40, num_updates=4400, lr=7.86864e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4956
2022-09-28 15:04:56 - progress_bar.py[line:274] - INFO: epoch 001:   4416 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91, ups=0.89, wpb=101.8, bsz=40, num_updates=4410, lr=7.86758e-05, gnorm=0.824, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4967
2022-09-28 15:05:07 - progress_bar.py[line:274] - INFO: epoch 001:   4426 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.3, ups=0.88, wpb=101.5, bsz=40, num_updates=4420, lr=7.86652e-05, gnorm=0.908, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4978
2022-09-28 15:05:18 - progress_bar.py[line:274] - INFO: epoch 001:   4436 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.9, wpb=99.7, bsz=40, num_updates=4430, lr=7.86547e-05, gnorm=0.897, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4989
2022-09-28 15:05:29 - progress_bar.py[line:274] - INFO: epoch 001:   4446 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.2, ups=0.88, wpb=100.8, bsz=40, num_updates=4440, lr=7.86441e-05, gnorm=0.813, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5001
2022-09-28 15:05:40 - progress_bar.py[line:274] - INFO: epoch 001:   4456 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.91, wpb=100.3, bsz=40, num_updates=4450, lr=7.86336e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5012
2022-09-28 15:05:52 - progress_bar.py[line:274] - INFO: epoch 001:   4466 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.3, ups=0.88, wpb=101.4, bsz=40, num_updates=4460, lr=7.8623e-05, gnorm=0.82, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5023
2022-09-28 15:06:03 - progress_bar.py[line:274] - INFO: epoch 001:   4476 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=4470, lr=7.86124e-05, gnorm=0.954, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5034
2022-09-28 15:06:14 - progress_bar.py[line:274] - INFO: epoch 001:   4486 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.9, wpb=100.7, bsz=40, num_updates=4480, lr=7.86019e-05, gnorm=0.806, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5045
2022-09-28 15:06:25 - progress_bar.py[line:274] - INFO: epoch 001:   4496 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90, ups=0.89, wpb=101.1, bsz=40, num_updates=4490, lr=7.85913e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5057
2022-09-28 15:06:37 - progress_bar.py[line:274] - INFO: epoch 001:   4506 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.2, ups=0.89, wpb=101.5, bsz=40, num_updates=4500, lr=7.85808e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5068
2022-09-28 15:06:47 - progress_bar.py[line:274] - INFO: epoch 001:   4516 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.5, ups=0.94, wpb=102.8, bsz=40, num_updates=4510, lr=7.85702e-05, gnorm=0.943, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5079
2022-09-28 15:06:58 - progress_bar.py[line:274] - INFO: epoch 001:   4526 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.1, ups=0.91, wpb=100, bsz=40, num_updates=4520, lr=7.85596e-05, gnorm=0.724, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5090
2022-09-28 15:07:09 - progress_bar.py[line:274] - INFO: epoch 001:   4536 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.1, ups=0.92, wpb=102.6, bsz=40, num_updates=4530, lr=7.85491e-05, gnorm=0.816, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5100
2022-09-28 15:07:20 - progress_bar.py[line:274] - INFO: epoch 001:   4546 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.3, ups=0.9, wpb=102.5, bsz=40, num_updates=4540, lr=7.85385e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5112
2022-09-28 15:07:31 - progress_bar.py[line:274] - INFO: epoch 001:   4556 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.3, ups=0.91, wpb=100.4, bsz=40, num_updates=4550, lr=7.8528e-05, gnorm=0.668, clip=0, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5123
2022-09-28 15:07:42 - progress_bar.py[line:274] - INFO: epoch 001:   4566 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.92, wpb=100.7, bsz=40, num_updates=4560, lr=7.85174e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5133
2022-09-28 15:07:53 - progress_bar.py[line:274] - INFO: epoch 001:   4576 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.9, wpb=102.5, bsz=40, num_updates=4570, lr=7.85068e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5145
2022-09-28 15:08:04 - progress_bar.py[line:274] - INFO: epoch 001:   4586 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.9, wpb=101.9, bsz=40, num_updates=4580, lr=7.84963e-05, gnorm=0.718, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5156
2022-09-28 15:08:16 - progress_bar.py[line:274] - INFO: epoch 001:   4596 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.4, ups=0.89, wpb=100.2, bsz=40, num_updates=4590, lr=7.84857e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5167
2022-09-28 15:08:27 - progress_bar.py[line:274] - INFO: epoch 001:   4606 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.88, wpb=102.6, bsz=40, num_updates=4600, lr=7.84752e-05, gnorm=0.802, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5178
2022-09-28 15:08:38 - progress_bar.py[line:274] - INFO: epoch 001:   4616 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.87, wpb=103.2, bsz=40, num_updates=4610, lr=7.84646e-05, gnorm=0.775, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5190
2022-09-28 15:08:50 - progress_bar.py[line:274] - INFO: epoch 001:   4626 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.3, ups=0.88, wpb=103.1, bsz=40, num_updates=4620, lr=7.8454e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5201
2022-09-28 15:09:01 - progress_bar.py[line:274] - INFO: epoch 001:   4636 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.6, ups=0.92, wpb=101.4, bsz=40, num_updates=4630, lr=7.84435e-05, gnorm=0.913, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5212
2022-09-28 15:09:12 - progress_bar.py[line:274] - INFO: epoch 001:   4646 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=4640, lr=7.84329e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5223
2022-09-28 15:09:23 - progress_bar.py[line:274] - INFO: epoch 001:   4656 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.91, wpb=101, bsz=40, num_updates=4650, lr=7.84224e-05, gnorm=0.725, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5234
2022-09-28 15:09:34 - progress_bar.py[line:274] - INFO: epoch 001:   4666 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.91, wpb=101.3, bsz=40, num_updates=4660, lr=7.84118e-05, gnorm=0.911, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5245
2022-09-28 15:09:45 - progress_bar.py[line:274] - INFO: epoch 001:   4676 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.88, wpb=101.7, bsz=40, num_updates=4670, lr=7.84012e-05, gnorm=0.827, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5257
2022-09-28 15:09:56 - progress_bar.py[line:274] - INFO: epoch 001:   4686 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.9, wpb=101.8, bsz=40, num_updates=4680, lr=7.83907e-05, gnorm=0.792, clip=10, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=5268
2022-09-28 15:10:07 - progress_bar.py[line:274] - INFO: epoch 001:   4696 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.6, ups=0.92, wpb=99.2, bsz=40, num_updates=4690, lr=7.83801e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5279
2022-09-28 15:10:19 - progress_bar.py[line:274] - INFO: epoch 001:   4706 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.89, wpb=101.4, bsz=40, num_updates=4700, lr=7.83696e-05, gnorm=0.861, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5290
2022-09-28 15:10:26 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 15:10:31 - progress_bar.py[line:274] - INFO: epoch 001:   4717 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=83.9, ups=0.83, wpb=101.5, bsz=40, num_updates=4710, lr=7.8359e-05, gnorm=0.883, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5302
2022-09-28 15:10:42 - progress_bar.py[line:274] - INFO: epoch 001:   4727 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.8, ups=0.89, wpb=101.4, bsz=40, num_updates=4720, lr=7.83484e-05, gnorm=0.779, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5313
2022-09-28 15:10:53 - progress_bar.py[line:274] - INFO: epoch 001:   4737 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.6, ups=0.91, wpb=100.4, bsz=40, num_updates=4730, lr=7.83379e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5324
2022-09-28 15:11:05 - progress_bar.py[line:274] - INFO: epoch 001:   4747 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.7, ups=0.87, wpb=101.4, bsz=40, num_updates=4740, lr=7.83273e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=5336
2022-09-28 15:11:16 - progress_bar.py[line:274] - INFO: epoch 001:   4757 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.4, ups=0.88, wpb=101, bsz=40, num_updates=4750, lr=7.83168e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5347
2022-09-28 15:11:27 - progress_bar.py[line:274] - INFO: epoch 001:   4767 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.8, ups=0.89, wpb=102, bsz=40, num_updates=4760, lr=7.83062e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5359
2022-09-28 15:11:38 - progress_bar.py[line:274] - INFO: epoch 001:   4777 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.7, ups=0.9, wpb=101, bsz=40, num_updates=4770, lr=7.82956e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5370
2022-09-28 15:11:49 - progress_bar.py[line:274] - INFO: epoch 001:   4787 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92, ups=0.92, wpb=99.6, bsz=40, num_updates=4780, lr=7.82851e-05, gnorm=0.955, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5381
2022-09-28 15:12:00 - progress_bar.py[line:274] - INFO: epoch 001:   4797 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.4, ups=0.89, wpb=100.5, bsz=40, num_updates=4790, lr=7.82745e-05, gnorm=0.888, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5392
2022-09-28 15:12:12 - progress_bar.py[line:274] - INFO: epoch 001:   4807 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.9, ups=0.9, wpb=103.3, bsz=40, num_updates=4800, lr=7.8264e-05, gnorm=0.905, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5403
2022-09-28 15:12:23 - progress_bar.py[line:274] - INFO: epoch 001:   4817 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89, ups=0.87, wpb=101.7, bsz=40, num_updates=4810, lr=7.82534e-05, gnorm=0.711, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5414
2022-09-28 15:12:34 - progress_bar.py[line:274] - INFO: epoch 001:   4827 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.1, ups=0.87, wpb=100.5, bsz=40, num_updates=4820, lr=7.82428e-05, gnorm=0.714, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5426
2022-09-28 15:12:46 - progress_bar.py[line:274] - INFO: epoch 001:   4837 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.89, wpb=100.2, bsz=40, num_updates=4830, lr=7.82323e-05, gnorm=0.703, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5437
2022-09-28 15:12:57 - progress_bar.py[line:274] - INFO: epoch 001:   4847 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.89, wpb=100.8, bsz=40, num_updates=4840, lr=7.82217e-05, gnorm=0.727, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5448
2022-09-28 15:13:08 - progress_bar.py[line:274] - INFO: epoch 001:   4857 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.9, wpb=99.8, bsz=40, num_updates=4850, lr=7.82112e-05, gnorm=0.798, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5460
2022-09-28 15:13:19 - progress_bar.py[line:274] - INFO: epoch 001:   4867 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.88, wpb=101.5, bsz=40, num_updates=4860, lr=7.82006e-05, gnorm=0.73, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5471
2022-09-28 15:13:31 - progress_bar.py[line:274] - INFO: epoch 001:   4877 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.4, ups=0.9, wpb=100.7, bsz=40, num_updates=4870, lr=7.81901e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5482
2022-09-28 15:13:42 - progress_bar.py[line:274] - INFO: epoch 001:   4887 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.4, ups=0.9, wpb=101.1, bsz=40, num_updates=4880, lr=7.81795e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5493
2022-09-28 15:13:53 - progress_bar.py[line:274] - INFO: epoch 001:   4897 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.8, ups=0.92, wpb=99.8, bsz=40, num_updates=4890, lr=7.81689e-05, gnorm=0.827, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5504
2022-09-28 15:14:04 - progress_bar.py[line:274] - INFO: epoch 001:   4907 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=100.6, bsz=40, num_updates=4900, lr=7.81584e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5515
2022-09-28 15:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   4917 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.4, ups=0.93, wpb=101.8, bsz=40, num_updates=4910, lr=7.81478e-05, gnorm=0.747, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5526
2022-09-28 15:14:26 - progress_bar.py[line:274] - INFO: epoch 001:   4927 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.89, wpb=99.9, bsz=40, num_updates=4920, lr=7.81373e-05, gnorm=0.777, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5537
2022-09-28 15:14:37 - progress_bar.py[line:274] - INFO: epoch 001:   4937 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.92, wpb=99.8, bsz=40, num_updates=4930, lr=7.81267e-05, gnorm=0.854, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5548
2022-09-28 15:14:48 - progress_bar.py[line:274] - INFO: epoch 001:   4947 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.4, ups=0.89, wpb=100.4, bsz=40, num_updates=4940, lr=7.81161e-05, gnorm=0.821, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5559
2022-09-28 15:14:59 - progress_bar.py[line:274] - INFO: epoch 001:   4957 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.1, ups=0.87, wpb=102.7, bsz=40, num_updates=4950, lr=7.81056e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5571
2022-09-28 15:15:10 - progress_bar.py[line:274] - INFO: epoch 001:   4967 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.91, wpb=101.7, bsz=40, num_updates=4960, lr=7.8095e-05, gnorm=0.769, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5582
2022-09-28 15:15:22 - progress_bar.py[line:274] - INFO: epoch 001:   4977 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.87, wpb=101.1, bsz=40, num_updates=4970, lr=7.80845e-05, gnorm=0.751, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5593
2022-09-28 15:15:33 - progress_bar.py[line:274] - INFO: epoch 001:   4987 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.9, wpb=103.4, bsz=40, num_updates=4980, lr=7.80739e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5604
2022-09-28 15:15:45 - progress_bar.py[line:274] - INFO: epoch 001:   4997 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=101.4, bsz=40, num_updates=4990, lr=7.80633e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5616
2022-09-28 15:15:56 - progress_bar.py[line:274] - INFO: epoch 001:   5007 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.5, ups=0.89, wpb=101.7, bsz=40, num_updates=5000, lr=7.80528e-05, gnorm=0.674, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5627
2022-09-28 15:16:07 - progress_bar.py[line:274] - INFO: epoch 001:   5017 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.89, wpb=102.6, bsz=40, num_updates=5010, lr=7.80422e-05, gnorm=0.679, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5639
2022-09-28 15:16:18 - progress_bar.py[line:274] - INFO: epoch 001:   5027 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=5020, lr=7.80317e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5650
2022-09-28 15:16:30 - progress_bar.py[line:274] - INFO: epoch 001:   5037 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=5030, lr=7.80211e-05, gnorm=0.792, clip=10, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=5661
2022-09-28 15:16:41 - progress_bar.py[line:274] - INFO: epoch 001:   5047 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.9, ups=0.92, wpb=101.5, bsz=40, num_updates=5040, lr=7.80105e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5672
2022-09-28 15:16:52 - progress_bar.py[line:274] - INFO: epoch 001:   5057 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.4, ups=0.92, wpb=100.6, bsz=40, num_updates=5050, lr=7.8e-05, gnorm=0.758, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5683
2022-09-28 15:17:03 - progress_bar.py[line:274] - INFO: epoch 001:   5067 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.1, ups=0.88, wpb=100.2, bsz=40, num_updates=5060, lr=7.79894e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5694
2022-09-28 15:17:14 - progress_bar.py[line:274] - INFO: epoch 001:   5077 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.8, ups=0.9, wpb=103, bsz=40, num_updates=5070, lr=7.79789e-05, gnorm=0.733, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5705
2022-09-28 15:17:25 - progress_bar.py[line:274] - INFO: epoch 001:   5087 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92, ups=0.91, wpb=101.3, bsz=40, num_updates=5080, lr=7.79683e-05, gnorm=0.817, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5716
2022-09-28 15:17:36 - progress_bar.py[line:274] - INFO: epoch 001:   5097 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.91, wpb=101.4, bsz=40, num_updates=5090, lr=7.79577e-05, gnorm=0.699, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5728
2022-09-28 15:17:47 - progress_bar.py[line:274] - INFO: epoch 001:   5107 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.1, ups=0.91, wpb=102.1, bsz=40, num_updates=5100, lr=7.79472e-05, gnorm=0.699, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5739
2022-09-28 15:17:58 - progress_bar.py[line:274] - INFO: epoch 001:   5117 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.7, ups=0.91, wpb=101.1, bsz=40, num_updates=5110, lr=7.79366e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5750
2022-09-28 15:18:09 - progress_bar.py[line:274] - INFO: epoch 001:   5127 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.2, ups=0.93, wpb=101.7, bsz=40, num_updates=5120, lr=7.79261e-05, gnorm=0.708, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5760
2022-09-28 15:18:20 - progress_bar.py[line:274] - INFO: epoch 001:   5137 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=86.5, ups=0.88, wpb=98.9, bsz=40, num_updates=5130, lr=7.79155e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5772
2022-09-28 15:18:31 - progress_bar.py[line:274] - INFO: epoch 001:   5147 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.1, ups=0.91, wpb=101.3, bsz=40, num_updates=5140, lr=7.79049e-05, gnorm=0.714, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5783
2022-09-28 15:18:43 - progress_bar.py[line:274] - INFO: epoch 001:   5157 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=5150, lr=7.78944e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5794
2022-09-28 15:18:54 - progress_bar.py[line:274] - INFO: epoch 001:   5167 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.91, wpb=101.4, bsz=40, num_updates=5160, lr=7.78838e-05, gnorm=0.638, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5805
2022-09-28 15:19:05 - progress_bar.py[line:274] - INFO: epoch 001:   5177 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.2, ups=0.89, wpb=102.1, bsz=40, num_updates=5170, lr=7.78733e-05, gnorm=0.83, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5816
2022-09-28 15:19:16 - progress_bar.py[line:274] - INFO: epoch 001:   5187 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.89, wpb=102.1, bsz=40, num_updates=5180, lr=7.78627e-05, gnorm=0.741, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5827
2022-09-28 15:19:27 - progress_bar.py[line:274] - INFO: epoch 001:   5197 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.89, wpb=103.5, bsz=40, num_updates=5190, lr=7.78521e-05, gnorm=0.723, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5839
2022-09-28 15:19:39 - progress_bar.py[line:274] - INFO: epoch 001:   5207 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.88, wpb=101.4, bsz=40, num_updates=5200, lr=7.78416e-05, gnorm=0.698, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5850
2022-09-28 15:19:50 - progress_bar.py[line:274] - INFO: epoch 001:   5217 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.9, wpb=102.1, bsz=40, num_updates=5210, lr=7.7831e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5861
2022-09-28 15:20:01 - progress_bar.py[line:274] - INFO: epoch 001:   5227 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.3, ups=0.92, wpb=102.7, bsz=40, num_updates=5220, lr=7.78205e-05, gnorm=0.779, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5872
2022-09-28 15:20:12 - progress_bar.py[line:274] - INFO: epoch 001:   5237 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.9, ups=0.87, wpb=101.4, bsz=40, num_updates=5230, lr=7.78099e-05, gnorm=0.743, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5884
2022-09-28 15:20:24 - progress_bar.py[line:274] - INFO: epoch 001:   5247 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89, ups=0.88, wpb=101.1, bsz=40, num_updates=5240, lr=7.77993e-05, gnorm=0.727, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5895
2022-09-28 15:20:35 - progress_bar.py[line:274] - INFO: epoch 001:   5257 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91, ups=0.89, wpb=102.1, bsz=40, num_updates=5250, lr=7.77888e-05, gnorm=0.784, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5906
2022-09-28 15:20:46 - progress_bar.py[line:274] - INFO: epoch 001:   5267 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.2, ups=0.93, wpb=100.2, bsz=40, num_updates=5260, lr=7.77782e-05, gnorm=0.805, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5917
2022-09-28 15:20:57 - progress_bar.py[line:274] - INFO: epoch 001:   5277 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.89, wpb=101.3, bsz=40, num_updates=5270, lr=7.77677e-05, gnorm=0.757, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5928
2022-09-28 15:21:08 - progress_bar.py[line:274] - INFO: epoch 001:   5287 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.91, wpb=101.1, bsz=40, num_updates=5280, lr=7.77571e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5939
2022-09-28 15:21:19 - progress_bar.py[line:274] - INFO: epoch 001:   5297 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.89, wpb=103, bsz=40, num_updates=5290, lr=7.77465e-05, gnorm=0.735, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5950
2022-09-28 15:21:30 - progress_bar.py[line:274] - INFO: epoch 001:   5307 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=5300, lr=7.7736e-05, gnorm=0.852, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5962
2022-09-28 15:21:41 - progress_bar.py[line:274] - INFO: epoch 001:   5317 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.1, ups=0.9, wpb=100.7, bsz=40, num_updates=5310, lr=7.77254e-05, gnorm=0.773, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5973
2022-09-28 15:21:52 - progress_bar.py[line:274] - INFO: epoch 001:   5327 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.9, wpb=100.5, bsz=40, num_updates=5320, lr=7.77149e-05, gnorm=0.672, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5984
2022-09-28 15:22:04 - progress_bar.py[line:274] - INFO: epoch 001:   5337 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.5, ups=0.88, wpb=100.6, bsz=40, num_updates=5330, lr=7.77043e-05, gnorm=0.764, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5995
2022-09-28 15:22:15 - progress_bar.py[line:274] - INFO: epoch 001:   5347 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.9, ups=0.88, wpb=98.6, bsz=40, num_updates=5340, lr=7.76937e-05, gnorm=0.76, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6007
2022-09-28 15:22:26 - progress_bar.py[line:274] - INFO: epoch 001:   5357 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=5350, lr=7.76832e-05, gnorm=0.699, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6018
2022-09-28 15:22:37 - progress_bar.py[line:274] - INFO: epoch 001:   5367 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.92, wpb=100.1, bsz=40, num_updates=5360, lr=7.76726e-05, gnorm=0.782, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6029
2022-09-28 15:22:49 - progress_bar.py[line:274] - INFO: epoch 001:   5377 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.8, ups=0.87, wpb=101.2, bsz=40, num_updates=5370, lr=7.76621e-05, gnorm=0.697, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6040
2022-09-28 15:23:00 - progress_bar.py[line:274] - INFO: epoch 001:   5387 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.89, wpb=100, bsz=40, num_updates=5380, lr=7.76515e-05, gnorm=0.937, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6052
2022-09-28 15:23:11 - progress_bar.py[line:274] - INFO: epoch 001:   5397 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.8, ups=0.88, wpb=101.1, bsz=40, num_updates=5390, lr=7.76409e-05, gnorm=0.779, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6063
2022-09-28 15:23:23 - progress_bar.py[line:274] - INFO: epoch 001:   5407 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.9, wpb=100.4, bsz=40, num_updates=5400, lr=7.76304e-05, gnorm=0.819, clip=30, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6074
2022-09-28 15:23:33 - progress_bar.py[line:274] - INFO: epoch 001:   5417 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.4, ups=0.92, wpb=100.2, bsz=40, num_updates=5410, lr=7.76198e-05, gnorm=0.922, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6085
2022-09-28 15:23:45 - progress_bar.py[line:274] - INFO: epoch 001:   5427 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.5, ups=0.88, wpb=100.6, bsz=40, num_updates=5420, lr=7.76093e-05, gnorm=0.841, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6096
2022-09-28 15:23:56 - progress_bar.py[line:274] - INFO: epoch 001:   5437 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93, ups=0.93, wpb=100.2, bsz=40, num_updates=5430, lr=7.75987e-05, gnorm=0.926, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6107
2022-09-28 15:24:07 - progress_bar.py[line:274] - INFO: epoch 001:   5447 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.2, ups=0.89, wpb=100.6, bsz=40, num_updates=5440, lr=7.75881e-05, gnorm=0.72, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6118
2022-09-28 15:24:18 - progress_bar.py[line:274] - INFO: epoch 001:   5457 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.5, ups=0.9, wpb=102.4, bsz=40, num_updates=5450, lr=7.75776e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6129
2022-09-28 15:24:29 - progress_bar.py[line:274] - INFO: epoch 001:   5467 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.91, wpb=101.1, bsz=40, num_updates=5460, lr=7.7567e-05, gnorm=0.782, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6140
2022-09-28 15:24:40 - progress_bar.py[line:274] - INFO: epoch 001:   5477 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=5470, lr=7.75565e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6152
2022-09-28 15:24:52 - progress_bar.py[line:274] - INFO: epoch 001:   5487 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.5, ups=0.87, wpb=100.5, bsz=40, num_updates=5480, lr=7.75459e-05, gnorm=0.74, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6163
2022-09-28 15:25:03 - progress_bar.py[line:274] - INFO: epoch 001:   5497 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.8, ups=0.89, wpb=99.8, bsz=40, num_updates=5490, lr=7.75353e-05, gnorm=0.796, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6175
2022-09-28 15:25:14 - progress_bar.py[line:274] - INFO: epoch 001:   5507 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.7, ups=0.91, wpb=102.7, bsz=40, num_updates=5500, lr=7.75248e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6185
2022-09-28 15:25:25 - progress_bar.py[line:274] - INFO: epoch 001:   5517 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.89, wpb=101.6, bsz=40, num_updates=5510, lr=7.75142e-05, gnorm=0.919, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6197
2022-09-28 15:25:37 - progress_bar.py[line:274] - INFO: epoch 001:   5527 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.88, wpb=101.8, bsz=40, num_updates=5520, lr=7.75037e-05, gnorm=0.776, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6208
2022-09-28 15:25:48 - progress_bar.py[line:274] - INFO: epoch 001:   5537 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92, ups=0.91, wpb=101, bsz=40, num_updates=5530, lr=7.74931e-05, gnorm=0.784, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6219
2022-09-28 15:25:59 - progress_bar.py[line:274] - INFO: epoch 001:   5547 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.4, ups=0.91, wpb=101.8, bsz=40, num_updates=5540, lr=7.74825e-05, gnorm=0.661, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6230
2022-09-28 15:26:10 - progress_bar.py[line:274] - INFO: epoch 001:   5557 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=102, bsz=40, num_updates=5550, lr=7.7472e-05, gnorm=0.78, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6241
2022-09-28 15:26:21 - progress_bar.py[line:274] - INFO: epoch 001:   5567 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=101.4, bsz=40, num_updates=5560, lr=7.74614e-05, gnorm=0.759, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6252
2022-09-28 15:26:32 - progress_bar.py[line:274] - INFO: epoch 001:   5577 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.7, ups=0.88, wpb=101.9, bsz=40, num_updates=5570, lr=7.74509e-05, gnorm=0.808, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6264
2022-09-28 15:26:44 - progress_bar.py[line:274] - INFO: epoch 001:   5587 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=5580, lr=7.74403e-05, gnorm=0.741, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6275
2022-09-28 15:26:55 - progress_bar.py[line:274] - INFO: epoch 001:   5597 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.5, ups=0.87, wpb=100.8, bsz=40, num_updates=5590, lr=7.74297e-05, gnorm=0.761, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6286
2022-09-28 15:27:06 - progress_bar.py[line:274] - INFO: epoch 001:   5607 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.6, ups=0.9, wpb=99.2, bsz=40, num_updates=5600, lr=7.74192e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6297
2022-09-28 15:27:18 - progress_bar.py[line:274] - INFO: epoch 001:   5617 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=5610, lr=7.74086e-05, gnorm=0.746, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6309
2022-09-28 15:27:29 - progress_bar.py[line:274] - INFO: epoch 001:   5627 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.9, wpb=100.5, bsz=40, num_updates=5620, lr=7.73981e-05, gnorm=0.747, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6320
2022-09-28 15:27:40 - progress_bar.py[line:274] - INFO: epoch 001:   5637 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.88, wpb=101, bsz=40, num_updates=5630, lr=7.73875e-05, gnorm=0.7, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6331
2022-09-28 15:27:51 - progress_bar.py[line:274] - INFO: epoch 001:   5647 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.91, wpb=100.7, bsz=40, num_updates=5640, lr=7.73769e-05, gnorm=0.706, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6342
2022-09-28 15:28:02 - progress_bar.py[line:274] - INFO: epoch 001:   5657 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.88, wpb=100.3, bsz=40, num_updates=5650, lr=7.73664e-05, gnorm=0.883, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6354
2022-09-28 15:28:14 - progress_bar.py[line:274] - INFO: epoch 001:   5667 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.89, wpb=102.4, bsz=40, num_updates=5660, lr=7.73558e-05, gnorm=0.797, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6365
2022-09-28 15:28:25 - progress_bar.py[line:274] - INFO: epoch 001:   5677 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89, ups=0.88, wpb=100.9, bsz=40, num_updates=5670, lr=7.73453e-05, gnorm=0.716, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=6376
2022-09-28 15:28:36 - progress_bar.py[line:274] - INFO: epoch 001:   5687 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92, ups=0.91, wpb=101, bsz=40, num_updates=5680, lr=7.73347e-05, gnorm=0.749, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6387
2022-09-28 15:28:47 - progress_bar.py[line:274] - INFO: epoch 001:   5697 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.9, ups=0.93, wpb=103, bsz=40, num_updates=5690, lr=7.73241e-05, gnorm=0.769, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6398
2022-09-28 15:28:58 - progress_bar.py[line:274] - INFO: epoch 001:   5707 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=5700, lr=7.73136e-05, gnorm=0.81, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6409
2022-09-28 15:29:09 - progress_bar.py[line:274] - INFO: epoch 001:   5717 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=5710, lr=7.7303e-05, gnorm=0.743, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6421
2022-09-28 15:29:20 - progress_bar.py[line:274] - INFO: epoch 001:   5727 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.6, ups=0.93, wpb=102.2, bsz=40, num_updates=5720, lr=7.72925e-05, gnorm=0.774, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6431
2022-09-28 15:29:32 - progress_bar.py[line:274] - INFO: epoch 001:   5737 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.91, wpb=101.1, bsz=40, num_updates=5730, lr=7.72819e-05, gnorm=0.73, clip=10, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6442
2022-09-28 15:29:39 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-28 15:29:44 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=83.6, ups=0.81, wpb=102.6, bsz=40, num_updates=5740, lr=7.72713e-05, gnorm=0.763, clip=10, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6455
2022-09-28 15:29:55 - progress_bar.py[line:274] - INFO: epoch 001:   5758 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.5, ups=0.91, wpb=101.7, bsz=40, num_updates=5750, lr=7.72608e-05, gnorm=0.726, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6466
2022-09-28 15:30:06 - progress_bar.py[line:274] - INFO: epoch 001:   5768 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91, ups=0.91, wpb=99.6, bsz=40, num_updates=5760, lr=7.72502e-05, gnorm=0.809, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6477
2022-09-28 15:30:17 - progress_bar.py[line:274] - INFO: epoch 001:   5778 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.2, ups=0.93, wpb=102.7, bsz=40, num_updates=5770, lr=7.72397e-05, gnorm=0.7, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6488
2022-09-28 15:30:28 - progress_bar.py[line:274] - INFO: epoch 001:   5788 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.88, wpb=100.6, bsz=40, num_updates=5780, lr=7.72291e-05, gnorm=0.779, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6499
2022-09-28 15:30:39 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.9, ups=0.92, wpb=101.6, bsz=40, num_updates=5790, lr=7.72185e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6510
2022-09-28 15:30:50 - progress_bar.py[line:274] - INFO: epoch 001:   5808 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.7, ups=0.9, wpb=103.6, bsz=40, num_updates=5800, lr=7.7208e-05, gnorm=0.707, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6521
2022-09-28 15:31:01 - progress_bar.py[line:274] - INFO: epoch 001:   5818 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.7, ups=0.92, wpb=99, bsz=40, num_updates=5810, lr=7.71974e-05, gnorm=0.684, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6532
2022-09-28 15:31:11 - progress_bar.py[line:274] - INFO: epoch 001:   5828 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.3, ups=0.94, wpb=98.9, bsz=40, num_updates=5820, lr=7.71869e-05, gnorm=0.897, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6543
2022-09-28 15:31:23 - progress_bar.py[line:274] - INFO: epoch 001:   5838 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.7, ups=0.89, wpb=100.5, bsz=40, num_updates=5830, lr=7.71763e-05, gnorm=0.777, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6554
2022-09-28 15:31:34 - progress_bar.py[line:274] - INFO: epoch 001:   5848 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.89, wpb=100.3, bsz=40, num_updates=5840, lr=7.71657e-05, gnorm=0.745, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6565
2022-09-28 15:31:45 - progress_bar.py[line:274] - INFO: epoch 001:   5858 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.4, ups=0.91, wpb=102.2, bsz=40, num_updates=5850, lr=7.71552e-05, gnorm=0.673, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6576
2022-09-28 15:31:56 - progress_bar.py[line:274] - INFO: epoch 001:   5868 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.8, ups=0.88, wpb=99.7, bsz=40, num_updates=5860, lr=7.71446e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6588
2022-09-28 15:32:07 - progress_bar.py[line:274] - INFO: epoch 001:   5878 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92, ups=0.92, wpb=100.1, bsz=40, num_updates=5870, lr=7.71341e-05, gnorm=0.741, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6598
2022-09-28 15:32:18 - progress_bar.py[line:274] - INFO: epoch 001:   5888 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.3, ups=0.89, wpb=102.2, bsz=40, num_updates=5880, lr=7.71235e-05, gnorm=0.72, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6610
2022-09-28 15:32:30 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.9, ups=0.87, wpb=101.3, bsz=40, num_updates=5890, lr=7.7113e-05, gnorm=0.683, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6621
2022-09-28 15:32:41 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.4, ups=0.87, wpb=100.8, bsz=40, num_updates=5900, lr=7.71024e-05, gnorm=0.847, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6633
2022-09-28 15:32:53 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.6, ups=0.89, wpb=100.5, bsz=40, num_updates=5910, lr=7.70918e-05, gnorm=0.765, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6644
2022-09-28 15:33:04 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.89, wpb=102.3, bsz=40, num_updates=5920, lr=7.70813e-05, gnorm=0.691, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6655
2022-09-28 15:33:15 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91, ups=0.9, wpb=101.4, bsz=40, num_updates=5930, lr=7.70707e-05, gnorm=0.802, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6666
2022-09-28 15:33:26 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.4, ups=0.89, wpb=102.3, bsz=40, num_updates=5940, lr=7.70602e-05, gnorm=0.729, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6678
2022-09-28 15:33:37 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.9, ups=0.9, wpb=101.7, bsz=40, num_updates=5950, lr=7.70496e-05, gnorm=0.879, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6689
2022-09-28 15:33:49 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90, ups=0.89, wpb=101.2, bsz=40, num_updates=5960, lr=7.7039e-05, gnorm=0.732, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6700
2022-09-28 15:34:00 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.6, ups=0.87, wpb=102.1, bsz=40, num_updates=5970, lr=7.70285e-05, gnorm=0.74, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6711
2022-09-28 15:34:11 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.3, ups=0.89, wpb=102.6, bsz=40, num_updates=5980, lr=7.70179e-05, gnorm=0.919, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6723
2022-09-28 15:34:23 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=5990, lr=7.70074e-05, gnorm=0.793, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6734
2022-09-28 15:34:34 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.1, ups=0.89, wpb=103.2, bsz=40, num_updates=6000, lr=7.69968e-05, gnorm=0.757, clip=20, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6745
2022-09-28 15:34:34 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-28 15:34:34 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-28 15:34:35 - train.py[line:549] - INFO: 0 / 3047
2022-09-28 15:34:35 - train.py[line:551] - INFO: load:1.10 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-28 15:34:38 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 13.05 GiB (GPU 1; 39.59 GiB total capacity; 13.92 GiB already allocated; 10.27 GiB free; 26.84 GiB reserved in total by PyTorch)
2022-09-28 15:34:38 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-28 15:34:38 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 10        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   14255 MB |   16997 MB |    1029 TB |    1029 TB |
|       from large pool |   14109 MB |   16850 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   14255 MB |   16997 MB |    1029 TB |    1029 TB |
|       from large pool |   14109 MB |   16850 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   27480 MB |   37634 MB |  142482 MB |  115002 MB |
|       from large pool |   27334 MB |   37486 MB |  142126 MB |  114792 MB |
|       from small pool |     146 MB |     148 MB |     356 MB |     210 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   13224 MB |   14167 MB |  778286 GB |  778274 GB |
|       from large pool |   13224 MB |   14165 MB |  777517 GB |  777504 GB |
|       from small pool |       0 MB |       2 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    3641    |    3655    |   31921 K  |   31917 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15692 K  |   15689 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3641    |    3655    |   31921 K  |   31917 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15692 K  |   15689 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     205    |     291    |     594    |     389    |
|       from large pool |     132    |     217    |     416    |     284    |
|       from small pool |      73    |      74    |     178    |     105    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     136    |     144    |   17300 K  |   17300 K  |
|       from large pool |      96    |     102    |    9503 K  |    9503 K  |
|       from small pool |      40    |      50    |    7796 K  |    7796 K  |
|===========================================================================|

2022-09-28 15:34:38 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-28 15:34:39 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 14.98 GiB already allocated; 11.19 GiB free; 25.92 GiB reserved in total by PyTorch)
2022-09-28 15:34:39 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15339 MB |   18306 MB |    1029 TB |    1029 TB |
|       from large pool |   15193 MB |   18159 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   15339 MB |   18306 MB |    1029 TB |    1029 TB |
|       from large pool |   15193 MB |   18159 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26542 MB |   37668 MB |  154242 MB |  127700 MB |
|       from large pool |   26394 MB |   37520 MB |  153860 MB |  127466 MB |
|       from small pool |     148 MB |     148 MB |     382 MB |     234 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   11202 MB |   11982 MB |  738434 GB |  738423 GB |
|       from large pool |   11200 MB |   11980 MB |  737664 GB |  737653 GB |
|       from small pool |       2 MB |       2 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    3641    |    3655    |   31921 K  |   31917 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15692 K  |   15689 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3641    |    3655    |   31921 K  |   31917 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15692 K  |   15689 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     204    |     292    |     617    |     413    |
|       from large pool |     130    |     218    |     426    |     296    |
|       from small pool |      74    |      74    |     191    |     117    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     140    |     145    |   17244 K  |   17244 K  |
|       from large pool |     103    |     107    |    9434 K  |    9434 K  |
|       from small pool |      37    |      46    |    7810 K  |    7810 K  |
|===========================================================================|

2022-09-28 15:34:39 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-28 15:34:39 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-28 15:34:39 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 13.05 GiB (GPU 1; 39.59 GiB total capacity; 23.00 GiB already allocated; 13.04 GiB free; 24.07 GiB reserved in total by PyTorch)
2022-09-28 15:34:39 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-28 15:34:39 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   23550 MB |   26292 MB |    1029 TB |    1029 TB |
|       from large pool |   23431 MB |   26172 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   23550 MB |   26292 MB |    1029 TB |    1029 TB |
|       from large pool |   23431 MB |   26172 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   24648 MB |   37634 MB |  163184 MB |  138536 MB |
|       from large pool |   24526 MB |   37486 MB |  162826 MB |  138300 MB |
|       from small pool |     122 MB |     148 MB |     358 MB |     236 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1097 MB |   14167 MB |  778346 GB |  778345 GB |
|       from large pool |    1094 MB |   14165 MB |  777576 GB |  777575 GB |
|       from small pool |       2 MB |       4 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    2997    |    3655    |   31927 K  |   31924 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15696 K  |   15694 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    2997    |    3655    |   31927 K  |   31924 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15696 K  |   15694 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     130    |     291    |     616    |     486    |
|       from large pool |      69    |     217    |     437    |     368    |
|       from small pool |      61    |      74    |     179    |     118    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     120    |     193    |   17305 K  |   17305 K  |
|       from large pool |      58    |     102    |    9504 K  |    9504 K  |
|       from small pool |      62    |     107    |    7800 K  |    7800 K  |
|===========================================================================|

Traceback (most recent call last):
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 13.05 GiB (GPU 1; 39.59 GiB total capacity; 13.92 GiB already allocated; 10.27 GiB free; 26.84 GiB reserved in total by PyTorch)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 630, in <module>
    cli_main()
  File "../../train.py", line 623, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "../../train.py", line 332, in train
    cfg, trainer, task, epoch_itr, valid_subsets, end_of_epoch
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, (pred_scores, pred, sample_ids), time_info = trainer.valid_step(sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1088, in valid_step
    return self.valid_step(sample, raise_oom=True)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1089, in valid_step
    raise e
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 13.05 GiB (GPU 1; 39.59 GiB total capacity; 23.00 GiB already allocated; 13.04 GiB free; 24.07 GiB reserved in total by PyTorch)
2022-09-28 15:34:40 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 25.12 GiB already allocated; 10.81 GiB free; 26.30 GiB reserved in total by PyTorch)
2022-09-28 15:34:40 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 12        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   25719 MB |   28687 MB |    1029 TB |    1029 TB |
|       from large pool |   25600 MB |   28566 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   25719 MB |   28687 MB |    1029 TB |    1029 TB |
|       from large pool |   25600 MB |   28566 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26934 MB |   37748 MB |  175852 MB |  148918 MB |
|       from large pool |   26810 MB |   37624 MB |  175470 MB |  148660 MB |
|       from small pool |     124 MB |     148 MB |     382 MB |     258 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1214 MB |   11982 MB |  738507 GB |  738505 GB |
|       from large pool |    1209 MB |   11980 MB |  737737 GB |  737736 GB |
|       from small pool |       4 MB |       6 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    2997    |    3655    |   31927 K  |   31924 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15696 K  |   15694 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    2997    |    3655    |   31927 K  |   31924 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15696 K  |   15694 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     116    |     292    |     631    |     515    |
|       from large pool |      54    |     218    |     440    |     386    |
|       from small pool |      62    |      74    |     191    |     129    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     117    |     178    |   17249 K  |   17249 K  |
|       from large pool |      57    |     107    |    9435 K  |    9435 K  |
|       from small pool |      60    |     100    |    7814 K  |    7814 K  |
|===========================================================================|

2022-09-28 15:34:40 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

Traceback (most recent call last):
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 14.98 GiB already allocated; 11.19 GiB free; 25.92 GiB reserved in total by PyTorch)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 630, in <module>
    cli_main()
  File "../../train.py", line 623, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "../../train.py", line 332, in train
    cfg, trainer, task, epoch_itr, valid_subsets, end_of_epoch
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, (pred_scores, pred, sample_ids), time_info = trainer.valid_step(sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1088, in valid_step
    return self.valid_step(sample, raise_oom=True)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1089, in valid_step
    raise e
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 25.12 GiB already allocated; 10.81 GiB free; 26.30 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/50_way_allcand', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=15', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=8e-5', '--max-epoch=5', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=6000', '--validate-interval-updates=6000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 330375
Killing subprocess 330380
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 850877
Killing subprocess 850878
Main process received SIGINT, exiting
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 183, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 109, in _get_module_details
    __import__(pkg_name)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/__init__.py", line 196, in <module>
    from torch._C import *
RuntimeError: KeyboardInterrupt: 
2022-09-28 17:50:20 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-09-28 17:50:20 - utils.py[line:261] - INFO: Start init
2022-09-28 17:50:20 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-09-28 17:50:20 - utils.py[line:261] - INFO: Start init
2022-09-28 17:50:20 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-09-28 17:50:20 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-09-28 17:50:20 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-09-28 17:50:20 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-09-28 17:50:24 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/50_way_allcand', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 6000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [8e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 6000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[8e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480', save_interval=10, save_interval_updates=6000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/50_way_allcand', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=6000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [8e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [8e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-09-28 17:50:24 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-09-28 17:50:24 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv slice_id 1 row count 141030 total row count 282060
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-28 17:50:28 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-09-28 17:50:28 - train.py[line:118] - INFO: task: VqaGenTask
2022-09-28 17:50:28 - train.py[line:119] - INFO: model: OFAModel
2022-09-28 17:50:28 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-09-28 17:50:28 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-09-28 17:50:28 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv slice_id 0 row count 141030 total row count 282060
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-28 17:50:29 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-09-28 17:50:29 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-09-28 17:50:29 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 17:50:29 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 17:50:29 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 17:50:29 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 17:50:29 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-09-28 17:50:29 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-09-28 17:50:29 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-09-28 17:50:32 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 17:50:32 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 17:50:32 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-09-28 17:50:32 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-09-28 17:50:32 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-09-28 17:50:32 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 0 row count 315642 total row count 631284
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 1 row count 315642 total row count 631284
2022-09-28 17:50:33 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 17:50:33 - trainer.py[line:707] - INFO: begin training epoch 1
2022-09-28 17:50:33 - train.py[line:312] - INFO: Start iterating over samples
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 17:50:48 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 15783 loss=1.323, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=87.1, ups=0.85, wpb=102.4, bsz=40, num_updates=10, lr=2.53485e-07, gnorm=14.918, clip=100, loss_scale=128, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=20
2022-09-28 17:51:00 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 15783 loss=1.337, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=86, ups=0.86, wpb=100.6, bsz=40, num_updates=20, lr=5.06971e-07, gnorm=13.334, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=31
2022-09-28 17:51:12 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 15783 loss=1.384, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=88.1, ups=0.88, wpb=100.6, bsz=40, num_updates=30, lr=7.60456e-07, gnorm=14.794, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43
2022-09-28 17:51:23 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 15783 loss=1.247, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=87.7, ups=0.86, wpb=102.1, bsz=40, num_updates=40, lr=1.01394e-06, gnorm=10.057, clip=100, loss_scale=128, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=54
2022-09-28 17:51:35 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 15783 loss=1.166, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=89.2, ups=0.87, wpb=102.4, bsz=40, num_updates=50, lr=1.26743e-06, gnorm=9.162, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66
2022-09-28 17:51:46 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 15783 loss=1.149, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=87, ups=0.87, wpb=100.4, bsz=40, num_updates=60, lr=1.52091e-06, gnorm=7.544, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=77
2022-09-28 17:51:58 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 15783 loss=1.06, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=91.8, ups=0.89, wpb=102.7, bsz=40, num_updates=70, lr=1.7744e-06, gnorm=6.298, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=89
2022-09-28 17:52:09 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 15783 loss=1.029, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=90.3, ups=0.87, wpb=103.2, bsz=40, num_updates=80, lr=2.02788e-06, gnorm=5.785, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=100
2022-09-28 17:52:20 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 15783 loss=1.052, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=90, lr=2.28137e-06, gnorm=5.067, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=111
2022-09-28 17:52:32 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 15783 loss=1.019, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=100, lr=2.53485e-06, gnorm=4.453, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123
2022-09-28 17:52:43 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 15783 loss=1.007, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=88.7, ups=0.87, wpb=101.4, bsz=40, num_updates=110, lr=2.78834e-06, gnorm=4.459, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=134
2022-09-28 17:52:55 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 15783 loss=1.002, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=88.2, ups=0.88, wpb=100.3, bsz=40, num_updates=120, lr=3.04183e-06, gnorm=4.323, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=146
2022-09-28 17:53:06 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 15783 loss=0.995, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=88.3, ups=0.88, wpb=100.4, bsz=40, num_updates=130, lr=3.29531e-06, gnorm=3.958, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=157
2022-09-28 17:53:19 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 15783 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=78.2, ups=0.77, wpb=101.8, bsz=40, num_updates=140, lr=3.5488e-06, gnorm=3.583, clip=100, loss_scale=128, train_wall=13, gb_free=9.8, ema_decay=0.9999, wall=170
2022-09-28 17:53:31 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 15783 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=84.1, ups=0.82, wpb=102.2, bsz=40, num_updates=150, lr=3.80228e-06, gnorm=3.49, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=182
2022-09-28 17:53:42 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 15783 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.736, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=94.2, ups=0.92, wpb=102.5, bsz=40, num_updates=160, lr=4.05577e-06, gnorm=3.631, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=193
2022-09-28 17:53:54 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 15783 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=87.5, ups=0.87, wpb=100.6, bsz=40, num_updates=170, lr=4.30925e-06, gnorm=3.273, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=205
2022-09-28 17:54:05 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 15783 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=89.8, ups=0.87, wpb=102.9, bsz=40, num_updates=180, lr=4.56274e-06, gnorm=3.098, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=216
2022-09-28 17:54:17 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 15783 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=82.3, ups=0.83, wpb=99.5, bsz=40, num_updates=190, lr=4.81622e-06, gnorm=3.18, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=228
2022-09-28 17:54:30 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 15783 loss=0.909, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=81.4, ups=0.79, wpb=102.6, bsz=40, num_updates=200, lr=5.06971e-06, gnorm=3.257, clip=100, loss_scale=128, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=241
2022-09-28 17:54:41 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 15783 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=87.5, ups=0.86, wpb=101.3, bsz=40, num_updates=210, lr=5.32319e-06, gnorm=2.863, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=252
2022-09-28 17:54:53 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 15783 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=91.2, ups=0.89, wpb=102.9, bsz=40, num_updates=220, lr=5.57668e-06, gnorm=2.778, clip=100, loss_scale=128, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=264
2022-09-28 17:55:04 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 15783 loss=0.861, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=89.1, ups=0.86, wpb=103, bsz=40, num_updates=230, lr=5.83016e-06, gnorm=2.755, clip=100, loss_scale=128, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=275
2022-09-28 17:55:15 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 15783 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=89.5, ups=0.88, wpb=101.3, bsz=40, num_updates=240, lr=6.08365e-06, gnorm=2.764, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=287
2022-09-28 17:55:26 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 15783 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=92.5, ups=0.91, wpb=101.2, bsz=40, num_updates=250, lr=6.33714e-06, gnorm=2.676, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=297
2022-09-28 17:55:37 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 15783 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.727, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=95.7, ups=0.94, wpb=102.3, bsz=40, num_updates=260, lr=6.59062e-06, gnorm=2.713, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=308
2022-09-28 17:55:48 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 15783 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=89, ups=0.89, wpb=99.9, bsz=40, num_updates=270, lr=6.84411e-06, gnorm=2.844, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=319
2022-09-28 17:56:00 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 15783 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=280, lr=7.09759e-06, gnorm=2.87, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=331
2022-09-28 17:56:11 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 15783 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.754, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=91.2, ups=0.91, wpb=100.7, bsz=40, num_updates=290, lr=7.35108e-06, gnorm=2.792, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=342
2022-09-28 17:56:22 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 15783 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=98.1, nsentences=40, sample_size=98.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=88.4, ups=0.9, wpb=98.1, bsz=40, num_updates=300, lr=7.60456e-06, gnorm=2.962, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=353
2022-09-28 17:56:33 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 15783 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=93.7, ups=0.92, wpb=102.1, bsz=40, num_updates=310, lr=7.85805e-06, gnorm=2.742, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=364
2022-09-28 17:56:44 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 15783 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=88.8, ups=0.88, wpb=100.7, bsz=40, num_updates=320, lr=8.11153e-06, gnorm=2.788, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=375
2022-09-28 17:56:55 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 15783 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=95.8, ups=0.94, wpb=102.3, bsz=40, num_updates=330, lr=8.36502e-06, gnorm=3.093, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=386
2022-09-28 17:57:06 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 15783 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.8, ups=0.9, wpb=101, bsz=40, num_updates=340, lr=8.6185e-06, gnorm=2.835, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=397
2022-09-28 17:57:17 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 15783 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=94.2, ups=0.92, wpb=102.9, bsz=40, num_updates=350, lr=8.87199e-06, gnorm=2.762, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=408
2022-09-28 17:57:28 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 15783 loss=0.837, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.3, ups=0.88, wpb=102.5, bsz=40, num_updates=360, lr=9.12548e-06, gnorm=2.804, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=419
2022-09-28 17:57:39 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 15783 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=91, ups=0.9, wpb=101.3, bsz=40, num_updates=370, lr=9.37896e-06, gnorm=2.617, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=430
2022-09-28 17:57:51 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 15783 loss=0.835, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=87.6, ups=0.87, wpb=101, bsz=40, num_updates=380, lr=9.63245e-06, gnorm=2.859, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=442
2022-09-28 17:58:02 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 15783 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=390, lr=9.88593e-06, gnorm=2.697, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=453
2022-09-28 17:58:13 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 15783 loss=0.817, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=92.9, ups=0.92, wpb=100.6, bsz=40, num_updates=400, lr=1.01394e-05, gnorm=3.025, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=464
2022-09-28 17:58:24 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 15783 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=94.3, ups=0.93, wpb=101.2, bsz=40, num_updates=410, lr=1.03929e-05, gnorm=2.908, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=475
2022-09-28 17:58:35 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 15783 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.1, ups=0.89, wpb=99.7, bsz=40, num_updates=420, lr=1.06464e-05, gnorm=3.019, clip=100, loss_scale=128, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=486
2022-09-28 17:58:46 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 15783 loss=0.829, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=91.2, ups=0.91, wpb=100.6, bsz=40, num_updates=430, lr=1.08999e-05, gnorm=2.826, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=497
2022-09-28 17:58:57 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 15783 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=87.6, ups=0.87, wpb=100.2, bsz=40, num_updates=440, lr=1.11534e-05, gnorm=2.708, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=508
2022-09-28 17:59:08 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 15783 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=88.6, ups=0.89, wpb=99.7, bsz=40, num_updates=450, lr=1.14068e-05, gnorm=2.782, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=519
2022-09-28 17:59:20 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 15783 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.8, ups=0.88, wpb=100.8, bsz=40, num_updates=460, lr=1.16603e-05, gnorm=2.65, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=531
2022-09-28 17:59:31 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 15783 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.9, ups=0.9, wpb=102, bsz=40, num_updates=470, lr=1.19138e-05, gnorm=2.856, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=542
2022-09-28 17:59:42 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 15783 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.2, ups=0.88, wpb=102.5, bsz=40, num_updates=480, lr=1.21673e-05, gnorm=2.603, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=553
2022-09-28 17:59:53 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 15783 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.8, ups=0.91, wpb=101.2, bsz=40, num_updates=490, lr=1.24208e-05, gnorm=2.598, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=564
2022-09-28 18:00:04 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 15783 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.5, ups=0.92, wpb=101.5, bsz=40, num_updates=500, lr=1.26743e-05, gnorm=2.6, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=575
2022-09-28 18:00:16 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 15783 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.2, ups=0.87, wpb=100.6, bsz=40, num_updates=510, lr=1.29278e-05, gnorm=2.922, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=587
2022-09-28 18:00:27 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 15783 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.4, ups=0.88, wpb=101.5, bsz=40, num_updates=520, lr=1.31812e-05, gnorm=2.803, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=598
2022-09-28 18:00:38 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 15783 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=94, ups=0.94, wpb=100.1, bsz=40, num_updates=530, lr=1.34347e-05, gnorm=2.486, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=609
2022-09-28 18:00:49 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 15783 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=540, lr=1.36882e-05, gnorm=2.495, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=620
2022-09-28 18:01:00 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 15783 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.8, ups=0.94, wpb=101.9, bsz=40, num_updates=550, lr=1.39417e-05, gnorm=2.195, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=631
2022-09-28 18:01:11 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 15783 loss=0.735, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.4, ups=0.89, wpb=100.8, bsz=40, num_updates=560, lr=1.41952e-05, gnorm=2.437, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=642
2022-09-28 18:01:22 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 15783 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.2, ups=0.89, wpb=102.2, bsz=40, num_updates=570, lr=1.44487e-05, gnorm=2.296, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=653
2022-09-28 18:01:33 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 15783 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.1, ups=0.9, wpb=102.5, bsz=40, num_updates=580, lr=1.47022e-05, gnorm=2.249, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=664
2022-09-28 18:01:45 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.1, ups=0.89, wpb=103.4, bsz=40, num_updates=590, lr=1.49556e-05, gnorm=2.141, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=676
2022-09-28 18:01:56 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 15783 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.5, ups=0.89, wpb=102.8, bsz=40, num_updates=600, lr=1.52091e-05, gnorm=2.872, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=687
2022-09-28 18:02:07 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 15783 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.9, ups=0.89, wpb=103.4, bsz=40, num_updates=610, lr=1.54626e-05, gnorm=2.428, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=698
2022-09-28 18:02:18 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.8, ups=0.88, wpb=102, bsz=40, num_updates=620, lr=1.57161e-05, gnorm=1.953, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=709
2022-09-28 18:02:30 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.6, ups=0.88, wpb=103.1, bsz=40, num_updates=630, lr=1.59696e-05, gnorm=2.283, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=721
2022-09-28 18:02:41 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.1, ups=0.88, wpb=103.4, bsz=40, num_updates=640, lr=1.62231e-05, gnorm=2.107, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=732
2022-09-28 18:02:52 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 15783 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=650, lr=1.64766e-05, gnorm=2.173, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=743
2022-09-28 18:03:03 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 15783 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=93, ups=0.92, wpb=100.7, bsz=40, num_updates=660, lr=1.673e-05, gnorm=2.219, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=754
2022-09-28 18:03:15 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 15783 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.8, ups=0.88, wpb=100.2, bsz=40, num_updates=670, lr=1.69835e-05, gnorm=2.271, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=766
2022-09-28 18:03:26 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.4, ups=0.88, wpb=101.5, bsz=40, num_updates=680, lr=1.7237e-05, gnorm=2.348, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=777
2022-09-28 18:03:37 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.7, ups=0.89, wpb=101.8, bsz=40, num_updates=690, lr=1.74905e-05, gnorm=2.189, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=788
2022-09-28 18:03:48 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 15783 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.9, ups=0.93, wpb=99.9, bsz=40, num_updates=700, lr=1.7744e-05, gnorm=2.338, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=799
2022-09-28 18:03:59 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.3, ups=0.88, wpb=102.3, bsz=40, num_updates=710, lr=1.79975e-05, gnorm=2.124, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=810
2022-09-28 18:04:10 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.1, ups=0.93, wpb=102.5, bsz=40, num_updates=720, lr=1.8251e-05, gnorm=1.934, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=821
2022-09-28 18:04:21 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 15783 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.6, ups=0.91, wpb=101.3, bsz=40, num_updates=730, lr=1.85044e-05, gnorm=2.098, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=832
2022-09-28 18:04:32 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.5, ups=0.89, wpb=101.5, bsz=40, num_updates=740, lr=1.87579e-05, gnorm=2.138, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=843
2022-09-28 18:04:43 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92, ups=0.91, wpb=101.2, bsz=40, num_updates=750, lr=1.90114e-05, gnorm=1.902, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=854
2022-09-28 18:04:55 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.3, ups=0.88, wpb=100.3, bsz=40, num_updates=760, lr=1.92649e-05, gnorm=1.95, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=866
2022-09-28 18:05:06 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89, ups=0.87, wpb=102.3, bsz=40, num_updates=770, lr=1.95184e-05, gnorm=1.904, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=877
2022-09-28 18:05:17 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.3, ups=0.89, wpb=102, bsz=40, num_updates=780, lr=1.97719e-05, gnorm=1.93, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=888
2022-09-28 18:05:28 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 15783 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=93.9, ups=0.94, wpb=100.1, bsz=40, num_updates=790, lr=2.00253e-05, gnorm=2.3, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=899
2022-09-28 18:05:39 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 15783 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.2, ups=0.93, wpb=98.8, bsz=40, num_updates=800, lr=2.02788e-05, gnorm=2.036, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=910
2022-09-28 18:05:50 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.2, ups=0.88, wpb=101.6, bsz=40, num_updates=810, lr=2.05323e-05, gnorm=1.999, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=921
2022-09-28 18:06:01 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 15783 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.5, ups=0.9, wpb=101.2, bsz=40, num_updates=820, lr=2.07858e-05, gnorm=2.07, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=932
2022-09-28 18:06:12 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.3, ups=0.9, wpb=101.5, bsz=40, num_updates=830, lr=2.10393e-05, gnorm=1.807, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=943
2022-09-28 18:06:24 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 15783 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=840, lr=2.12928e-05, gnorm=1.933, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=955
2022-09-28 18:06:35 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.3, ups=0.91, wpb=101.2, bsz=40, num_updates=850, lr=2.15463e-05, gnorm=1.659, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=966
2022-09-28 18:06:46 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 15783 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=92.4, ups=0.91, wpb=102, bsz=40, num_updates=860, lr=2.17997e-05, gnorm=1.918, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=977
2022-09-28 18:06:57 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 15783 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=870, lr=2.20532e-05, gnorm=1.867, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=988
2022-09-28 18:07:08 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 15783 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.9, ups=0.91, wpb=101.6, bsz=40, num_updates=880, lr=2.23067e-05, gnorm=2.049, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=999
2022-09-28 18:07:19 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.1, ups=0.91, wpb=101.8, bsz=40, num_updates=890, lr=2.25602e-05, gnorm=1.708, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1010
2022-09-28 18:07:30 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.7, ups=0.91, wpb=103.1, bsz=40, num_updates=900, lr=2.28137e-05, gnorm=1.875, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1021
2022-09-28 18:07:40 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.9, ups=0.93, wpb=102.3, bsz=40, num_updates=910, lr=2.30672e-05, gnorm=1.93, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1032
2022-09-28 18:07:51 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.4, ups=0.91, wpb=101, bsz=40, num_updates=920, lr=2.33207e-05, gnorm=1.773, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1042
2022-09-28 18:08:03 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=86.9, ups=0.87, wpb=100.4, bsz=40, num_updates=930, lr=2.35741e-05, gnorm=1.677, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1054
2022-09-28 18:08:14 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 15783 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=87.3, ups=0.87, wpb=100.6, bsz=40, num_updates=940, lr=2.38276e-05, gnorm=1.936, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1066
2022-09-28 18:08:26 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.2, ups=0.88, wpb=99.3, bsz=40, num_updates=950, lr=2.40811e-05, gnorm=1.838, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1077
2022-09-28 18:08:37 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 15783 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.2, ups=0.88, wpb=100.3, bsz=40, num_updates=960, lr=2.43346e-05, gnorm=1.886, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1088
2022-09-28 18:08:48 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.91, wpb=99.7, bsz=40, num_updates=970, lr=2.45881e-05, gnorm=1.854, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1099
2022-09-28 18:09:00 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.7, ups=0.88, wpb=103.3, bsz=40, num_updates=980, lr=2.48416e-05, gnorm=1.854, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1111
2022-09-28 18:09:11 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.91, wpb=99.8, bsz=40, num_updates=990, lr=2.50951e-05, gnorm=2.029, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1122
2022-09-28 18:09:22 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.8, ups=0.9, wpb=103.7, bsz=40, num_updates=1000, lr=2.53485e-05, gnorm=1.842, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1133
2022-09-28 18:09:33 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.6, ups=0.88, wpb=102.5, bsz=40, num_updates=1010, lr=2.5602e-05, gnorm=2.078, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1144
2022-09-28 18:09:46 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.7, ups=0.88, wpb=103.2, bsz=40, num_updates=1020, lr=2.58555e-05, gnorm=1.983, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1155
2022-09-28 18:09:57 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.9, ups=0.9, wpb=101.2, bsz=40, num_updates=1030, lr=2.6109e-05, gnorm=1.672, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1168
2022-09-28 18:10:09 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.9, ups=0.87, wpb=101.2, bsz=40, num_updates=1040, lr=2.63625e-05, gnorm=1.662, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1180
2022-09-28 18:10:20 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.4, ups=0.89, wpb=103.4, bsz=40, num_updates=1050, lr=2.6616e-05, gnorm=1.818, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1191
2022-09-28 18:10:31 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.3, ups=0.92, wpb=100.2, bsz=40, num_updates=1060, lr=2.68695e-05, gnorm=1.935, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1202
2022-09-28 18:10:42 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88, ups=0.89, wpb=98.9, bsz=40, num_updates=1070, lr=2.71229e-05, gnorm=1.687, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1213
2022-09-28 18:10:53 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.4, ups=0.89, wpb=102.7, bsz=40, num_updates=1080, lr=2.73764e-05, gnorm=1.947, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1224
2022-09-28 18:11:04 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.5, ups=0.9, wpb=101.3, bsz=40, num_updates=1090, lr=2.76299e-05, gnorm=1.675, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1235
2022-09-28 18:11:15 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.1, ups=0.89, wpb=102.2, bsz=40, num_updates=1100, lr=2.78834e-05, gnorm=1.69, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1247
2022-09-28 18:11:27 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.5, ups=0.9, wpb=101, bsz=40, num_updates=1110, lr=2.81369e-05, gnorm=1.81, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1258
2022-09-28 18:11:38 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.7, ups=0.88, wpb=100.6, bsz=40, num_updates=1120, lr=2.83904e-05, gnorm=1.813, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1269
2022-09-28 18:11:49 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.4, ups=0.89, wpb=99.3, bsz=40, num_updates=1130, lr=2.86439e-05, gnorm=1.807, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1280
2022-09-28 18:12:00 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.8, ups=0.9, wpb=101.8, bsz=40, num_updates=1140, lr=2.88973e-05, gnorm=1.812, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1291
2022-09-28 18:12:12 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.88, wpb=102.3, bsz=40, num_updates=1150, lr=2.91508e-05, gnorm=1.702, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1303
2022-09-28 18:12:23 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.2, ups=0.9, wpb=100.8, bsz=40, num_updates=1160, lr=2.94043e-05, gnorm=1.93, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1314
2022-09-28 18:12:34 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.8, ups=0.89, wpb=101.9, bsz=40, num_updates=1170, lr=2.96578e-05, gnorm=2.017, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1325
2022-09-28 18:12:45 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.1, ups=0.88, wpb=102, bsz=40, num_updates=1180, lr=2.99113e-05, gnorm=1.825, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1336
2022-09-28 18:12:57 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88, ups=0.87, wpb=101.5, bsz=40, num_updates=1190, lr=3.01648e-05, gnorm=1.737, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1348
2022-09-28 18:13:08 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.7, ups=0.87, wpb=101, bsz=40, num_updates=1200, lr=3.04183e-05, gnorm=1.655, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1359
2022-09-28 18:13:19 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.91, wpb=99.6, bsz=40, num_updates=1210, lr=3.06717e-05, gnorm=1.783, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1371
2022-09-28 18:13:31 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.89, wpb=102, bsz=40, num_updates=1220, lr=3.09252e-05, gnorm=1.663, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1382
2022-09-28 18:13:42 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=1230, lr=3.11787e-05, gnorm=1.733, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1393
2022-09-28 18:13:53 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.1, ups=0.88, wpb=100, bsz=40, num_updates=1240, lr=3.14322e-05, gnorm=1.61, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1404
2022-09-28 18:14:05 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.5, ups=0.88, wpb=102.3, bsz=40, num_updates=1250, lr=3.16857e-05, gnorm=1.925, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1416
2022-09-28 18:14:16 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.5, ups=0.88, wpb=102.1, bsz=40, num_updates=1260, lr=3.19392e-05, gnorm=1.569, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1427
2022-09-28 18:14:27 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.7, ups=0.93, wpb=102, bsz=40, num_updates=1270, lr=3.21926e-05, gnorm=1.67, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1438
2022-09-28 18:14:38 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90, ups=0.88, wpb=102.1, bsz=40, num_updates=1280, lr=3.24461e-05, gnorm=1.669, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1449
2022-09-28 18:14:49 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.91, wpb=100.7, bsz=40, num_updates=1290, lr=3.26996e-05, gnorm=1.64, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1460
2022-09-28 18:15:00 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=1300, lr=3.29531e-05, gnorm=1.614, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1471
2022-09-28 18:15:11 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93, ups=0.92, wpb=101.2, bsz=40, num_updates=1310, lr=3.32066e-05, gnorm=1.616, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1482
2022-09-28 18:15:22 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.92, wpb=101.3, bsz=40, num_updates=1320, lr=3.34601e-05, gnorm=1.649, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1493
2022-09-28 18:15:33 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.6, ups=0.93, wpb=100.2, bsz=40, num_updates=1330, lr=3.37136e-05, gnorm=1.723, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1504
2022-09-28 18:15:44 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.7, ups=0.9, wpb=101.3, bsz=40, num_updates=1340, lr=3.3967e-05, gnorm=1.636, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1515
2022-09-28 18:15:55 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=1350, lr=3.42205e-05, gnorm=1.595, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1526
2022-09-28 18:16:06 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.9, ups=0.9, wpb=101, bsz=40, num_updates=1360, lr=3.4474e-05, gnorm=1.626, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1537
2022-09-28 18:16:17 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.1, ups=0.94, wpb=100.5, bsz=40, num_updates=1370, lr=3.47275e-05, gnorm=1.602, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1548
2022-09-28 18:16:28 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.89, wpb=101.9, bsz=40, num_updates=1380, lr=3.4981e-05, gnorm=1.573, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1559
2022-09-28 18:16:39 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 15783 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.5, ups=0.9, wpb=101.2, bsz=40, num_updates=1390, lr=3.52345e-05, gnorm=1.632, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1570
2022-09-28 18:16:51 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.3, ups=0.87, wpb=102.6, bsz=40, num_updates=1400, lr=3.5488e-05, gnorm=1.409, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1582
2022-09-28 18:17:02 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.8, ups=0.91, wpb=103.5, bsz=40, num_updates=1410, lr=3.57414e-05, gnorm=1.427, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1593
2022-09-28 18:17:13 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.5, ups=0.87, wpb=100.8, bsz=40, num_updates=1420, lr=3.59949e-05, gnorm=1.382, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1604
2022-09-28 18:17:25 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.89, wpb=103.7, bsz=40, num_updates=1430, lr=3.62484e-05, gnorm=1.526, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1616
2022-09-28 18:17:36 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=1440, lr=3.65019e-05, gnorm=1.513, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1627
2022-09-28 18:17:47 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.9, ups=0.88, wpb=100.9, bsz=40, num_updates=1450, lr=3.67554e-05, gnorm=1.564, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1638
2022-09-28 18:17:58 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.5, ups=0.9, wpb=101, bsz=40, num_updates=1460, lr=3.70089e-05, gnorm=1.843, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1649
2022-09-28 18:18:09 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.5, ups=0.92, wpb=102.2, bsz=40, num_updates=1470, lr=3.72624e-05, gnorm=1.489, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1660
2022-09-28 18:18:20 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.8, ups=0.91, wpb=101.6, bsz=40, num_updates=1480, lr=3.75158e-05, gnorm=1.568, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1671
2022-09-28 18:18:31 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.6, ups=0.91, wpb=101.8, bsz=40, num_updates=1490, lr=3.77693e-05, gnorm=1.538, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1682
2022-09-28 18:18:43 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.88, wpb=102.5, bsz=40, num_updates=1500, lr=3.80228e-05, gnorm=1.434, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1694
2022-09-28 18:18:54 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.6, ups=0.91, wpb=100.5, bsz=40, num_updates=1510, lr=3.82763e-05, gnorm=1.754, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1705
2022-09-28 18:19:05 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.9, ups=0.86, wpb=101.5, bsz=40, num_updates=1520, lr=3.85298e-05, gnorm=1.444, clip=90, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1716
2022-09-28 18:19:17 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=86, ups=0.86, wpb=100, bsz=40, num_updates=1530, lr=3.87833e-05, gnorm=1.312, clip=90, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1728
2022-09-28 18:19:26 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 18:19:29 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=82.7, ups=0.82, wpb=101.3, bsz=40, num_updates=1540, lr=3.90368e-05, gnorm=1.357, clip=100, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=1740
2022-09-28 18:19:40 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.9, ups=0.91, wpb=99.5, bsz=40, num_updates=1550, lr=3.92902e-05, gnorm=1.501, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1751
2022-09-28 18:19:52 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.1, ups=0.84, wpb=102.6, bsz=40, num_updates=1560, lr=3.95437e-05, gnorm=1.363, clip=100, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=1763
2022-09-28 18:20:04 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.8, ups=0.86, wpb=101.2, bsz=40, num_updates=1570, lr=3.97972e-05, gnorm=1.397, clip=80, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1775
2022-09-28 18:20:16 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=84.5, ups=0.85, wpb=99.7, bsz=40, num_updates=1580, lr=4.00507e-05, gnorm=1.443, clip=100, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=1787
2022-09-28 18:20:27 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.6, ups=0.89, wpb=102.3, bsz=40, num_updates=1590, lr=4.03042e-05, gnorm=1.501, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1798
2022-09-28 18:20:38 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.6, ups=0.87, wpb=100.8, bsz=40, num_updates=1600, lr=4.05577e-05, gnorm=1.428, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1809
2022-09-28 18:20:50 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.87, wpb=101.3, bsz=40, num_updates=1610, lr=4.08112e-05, gnorm=1.305, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1821
2022-09-28 18:21:02 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.7, ups=0.86, wpb=101.3, bsz=40, num_updates=1620, lr=4.10646e-05, gnorm=1.559, clip=100, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1833
2022-09-28 18:21:13 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88, ups=0.86, wpb=102.6, bsz=40, num_updates=1630, lr=4.13181e-05, gnorm=1.477, clip=100, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1844
2022-09-28 18:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.86, wpb=104.7, bsz=40, num_updates=1640, lr=4.15716e-05, gnorm=1.17, clip=70, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1856
2022-09-28 18:21:36 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.8, ups=0.87, wpb=100.6, bsz=40, num_updates=1650, lr=4.18251e-05, gnorm=1.495, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1868
2022-09-28 18:21:48 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.7, ups=0.86, wpb=101.1, bsz=40, num_updates=1660, lr=4.20786e-05, gnorm=1.501, clip=90, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=1879
2022-09-28 18:21:59 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.8, ups=0.88, wpb=101.5, bsz=40, num_updates=1670, lr=4.23321e-05, gnorm=1.263, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1890
2022-09-28 18:22:11 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.8, ups=0.88, wpb=100.5, bsz=40, num_updates=1680, lr=4.25856e-05, gnorm=1.542, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1902
2022-09-28 18:22:22 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.3, ups=0.85, wpb=100.9, bsz=40, num_updates=1690, lr=4.2839e-05, gnorm=1.546, clip=100, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1914
2022-09-28 18:22:34 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.2, ups=0.88, wpb=101, bsz=40, num_updates=1700, lr=4.30925e-05, gnorm=1.282, clip=90, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=1925
2022-09-28 18:22:45 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.8, ups=0.91, wpb=101.5, bsz=40, num_updates=1710, lr=4.3346e-05, gnorm=1.338, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1936
2022-09-28 18:22:56 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.3, ups=0.9, wpb=101.9, bsz=40, num_updates=1720, lr=4.35995e-05, gnorm=1.348, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1947
2022-09-28 18:23:07 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.1, ups=0.87, wpb=100.1, bsz=40, num_updates=1730, lr=4.3853e-05, gnorm=1.365, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1958
2022-09-28 18:23:19 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.7, ups=0.87, wpb=102.4, bsz=40, num_updates=1740, lr=4.41065e-05, gnorm=1.348, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1970
2022-09-28 18:23:30 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.6, ups=0.87, wpb=100.4, bsz=40, num_updates=1750, lr=4.43599e-05, gnorm=1.335, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1981
2022-09-28 18:23:42 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=85.5, ups=0.85, wpb=100.7, bsz=40, num_updates=1760, lr=4.46134e-05, gnorm=1.335, clip=90, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1993
2022-09-28 18:23:54 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.9, ups=0.86, wpb=101.6, bsz=40, num_updates=1770, lr=4.48669e-05, gnorm=1.277, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=2005
2022-09-28 18:24:06 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.3, ups=0.86, wpb=101.8, bsz=40, num_updates=1780, lr=4.51204e-05, gnorm=1.237, clip=90, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=2017
2022-09-28 18:24:17 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.6, ups=0.85, wpb=103.8, bsz=40, num_updates=1790, lr=4.53739e-05, gnorm=1.221, clip=60, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=2028
2022-09-28 18:24:29 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.3, ups=0.9, wpb=103, bsz=40, num_updates=1800, lr=4.56274e-05, gnorm=1.458, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2040
2022-09-28 18:24:40 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.7, ups=0.87, wpb=101.5, bsz=40, num_updates=1810, lr=4.58809e-05, gnorm=1.395, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2051
2022-09-28 18:24:52 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=83, ups=0.84, wpb=99, bsz=40, num_updates=1820, lr=4.61343e-05, gnorm=1.441, clip=100, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2063
2022-09-28 18:25:04 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 15783 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=85.2, ups=0.85, wpb=100.7, bsz=40, num_updates=1830, lr=4.63878e-05, gnorm=1.335, clip=90, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=2075
2022-09-28 18:25:15 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.9, ups=0.86, wpb=101.7, bsz=40, num_updates=1840, lr=4.66413e-05, gnorm=1.079, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2086
2022-09-28 18:25:27 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.8, ups=0.86, wpb=101.8, bsz=40, num_updates=1850, lr=4.68948e-05, gnorm=1.355, clip=90, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=2098
2022-09-28 18:25:39 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.3, ups=0.86, wpb=103, bsz=40, num_updates=1860, lr=4.71483e-05, gnorm=1.375, clip=100, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=2110
2022-09-28 18:25:50 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=84.5, ups=0.84, wpb=100.9, bsz=40, num_updates=1870, lr=4.74018e-05, gnorm=1.259, clip=90, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=2122
2022-09-28 18:26:03 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=84.7, ups=0.83, wpb=102.6, bsz=40, num_updates=1880, lr=4.76553e-05, gnorm=1.237, clip=80, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2134
2022-09-28 18:26:14 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.7, ups=0.88, wpb=100.3, bsz=40, num_updates=1890, lr=4.79087e-05, gnorm=1.309, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2145
2022-09-28 18:26:25 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.88, wpb=101.8, bsz=40, num_updates=1900, lr=4.81622e-05, gnorm=1.235, clip=70, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=2156
2022-09-28 18:26:37 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=1910, lr=4.84157e-05, gnorm=1.165, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2168
2022-09-28 18:26:49 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.2, ups=0.87, wpb=101.1, bsz=40, num_updates=1920, lr=4.86692e-05, gnorm=1.26, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2179
2022-09-28 18:27:00 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.7, ups=0.9, wpb=103.5, bsz=40, num_updates=1930, lr=4.89227e-05, gnorm=1.277, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2191
2022-09-28 18:27:11 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=1940, lr=4.91762e-05, gnorm=1.392, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2202
2022-09-28 18:27:23 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.3, ups=0.88, wpb=101, bsz=40, num_updates=1950, lr=4.94297e-05, gnorm=1.179, clip=90, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2214
2022-09-28 18:27:34 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.1, ups=0.88, wpb=100.8, bsz=40, num_updates=1960, lr=4.96831e-05, gnorm=1.143, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2225
2022-09-28 18:27:45 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.2, ups=0.92, wpb=102.9, bsz=40, num_updates=1970, lr=4.99366e-05, gnorm=1.209, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2236
2022-09-28 18:27:56 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.7, ups=0.91, wpb=100.5, bsz=40, num_updates=1980, lr=5.01901e-05, gnorm=1.291, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2247
2022-09-28 18:28:07 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.4, ups=0.89, wpb=99.8, bsz=40, num_updates=1990, lr=5.04436e-05, gnorm=1.23, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2258
2022-09-28 18:28:18 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.9, ups=0.9, wpb=101.1, bsz=40, num_updates=2000, lr=5.06971e-05, gnorm=1.294, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2269
2022-09-28 18:28:30 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.89, wpb=102.6, bsz=40, num_updates=2010, lr=5.09506e-05, gnorm=1.058, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2281
2022-09-28 18:28:41 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.7, ups=0.9, wpb=102.2, bsz=40, num_updates=2020, lr=5.12041e-05, gnorm=1.143, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2292
2022-09-28 18:28:52 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.7, ups=0.89, wpb=103.3, bsz=40, num_updates=2030, lr=5.14575e-05, gnorm=1.155, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2304
2022-09-28 18:29:04 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.8, ups=0.86, wpb=101.3, bsz=40, num_updates=2040, lr=5.1711e-05, gnorm=1.111, clip=60, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=2315
2022-09-28 18:29:15 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.89, wpb=102.5, bsz=40, num_updates=2050, lr=5.19645e-05, gnorm=1.083, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2327
2022-09-28 18:29:20 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 18:29:27 - progress_bar.py[line:274] - INFO: epoch 001:   2062 / 15783 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=84.7, ups=0.85, wpb=100.2, bsz=40, num_updates=2060, lr=5.2218e-05, gnorm=1.34, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=2338
2022-09-28 18:29:39 - progress_bar.py[line:274] - INFO: epoch 001:   2072 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.7, ups=0.89, wpb=102.1, bsz=40, num_updates=2070, lr=5.24715e-05, gnorm=1.234, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2350
2022-09-28 18:29:49 - progress_bar.py[line:274] - INFO: epoch 001:   2082 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.5, ups=0.92, wpb=101.9, bsz=40, num_updates=2080, lr=5.2725e-05, gnorm=1.222, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2361
2022-09-28 18:30:01 - progress_bar.py[line:274] - INFO: epoch 001:   2092 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.8, ups=0.87, wpb=100.5, bsz=40, num_updates=2090, lr=5.29785e-05, gnorm=1.214, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2372
2022-09-28 18:30:12 - progress_bar.py[line:274] - INFO: epoch 001:   2102 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.9, ups=0.92, wpb=101.7, bsz=40, num_updates=2100, lr=5.32319e-05, gnorm=1.198, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2383
2022-09-28 18:30:23 - progress_bar.py[line:274] - INFO: epoch 001:   2112 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.8, ups=0.9, wpb=101.1, bsz=40, num_updates=2110, lr=5.34854e-05, gnorm=1.318, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2394
2022-09-28 18:30:34 - progress_bar.py[line:274] - INFO: epoch 001:   2122 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.8, ups=0.92, wpb=101.6, bsz=40, num_updates=2120, lr=5.37389e-05, gnorm=1.16, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2405
2022-09-28 18:30:45 - progress_bar.py[line:274] - INFO: epoch 001:   2132 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.1, ups=0.89, wpb=102.3, bsz=40, num_updates=2130, lr=5.39924e-05, gnorm=1.136, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2416
2022-09-28 18:30:57 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.2, ups=0.86, wpb=101.3, bsz=40, num_updates=2140, lr=5.42459e-05, gnorm=1.183, clip=80, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=2428
2022-09-28 18:31:08 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.1, ups=0.86, wpb=101.7, bsz=40, num_updates=2150, lr=5.44994e-05, gnorm=1.087, clip=60, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=2439
2022-09-28 18:31:19 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.9, ups=0.9, wpb=100.9, bsz=40, num_updates=2160, lr=5.47529e-05, gnorm=1.375, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2450
2022-09-28 18:31:31 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.89, wpb=103.3, bsz=40, num_updates=2170, lr=5.50063e-05, gnorm=1.304, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2462
2022-09-28 18:31:42 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.89, wpb=102.8, bsz=40, num_updates=2180, lr=5.52598e-05, gnorm=1.075, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2473
2022-09-28 18:31:53 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.1, ups=0.93, wpb=101.7, bsz=40, num_updates=2190, lr=5.55133e-05, gnorm=1.166, clip=80, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2484
2022-09-28 18:32:04 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.2, ups=0.92, wpb=101.5, bsz=40, num_updates=2200, lr=5.57668e-05, gnorm=1.193, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2495
2022-09-28 18:32:15 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.2, ups=0.88, wpb=100.5, bsz=40, num_updates=2210, lr=5.60203e-05, gnorm=1.252, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2506
2022-09-28 18:32:26 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.9, ups=0.88, wpb=100.8, bsz=40, num_updates=2220, lr=5.62738e-05, gnorm=1.332, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2517
2022-09-28 18:32:37 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.9, ups=0.91, wpb=101.2, bsz=40, num_updates=2230, lr=5.65272e-05, gnorm=1.261, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2528
2022-09-28 18:32:49 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.1, ups=0.89, wpb=102.7, bsz=40, num_updates=2240, lr=5.67807e-05, gnorm=1.251, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2540
2022-09-28 18:33:00 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.8, ups=0.89, wpb=100.1, bsz=40, num_updates=2250, lr=5.70342e-05, gnorm=1.337, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2551
2022-09-28 18:33:11 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.9, wpb=102.6, bsz=40, num_updates=2260, lr=5.72877e-05, gnorm=1.142, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2562
2022-09-28 18:33:22 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=2270, lr=5.75412e-05, gnorm=1.212, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2573
2022-09-28 18:33:34 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=2280, lr=5.77947e-05, gnorm=1.11, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2585
2022-09-28 18:33:45 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.6, ups=0.89, wpb=99.8, bsz=40, num_updates=2290, lr=5.80482e-05, gnorm=1.353, clip=70, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=2596
2022-09-28 18:33:56 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.2, ups=0.89, wpb=99.6, bsz=40, num_updates=2300, lr=5.83016e-05, gnorm=1.251, clip=90, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2607
2022-09-28 18:34:07 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.89, wpb=102.5, bsz=40, num_updates=2310, lr=5.85551e-05, gnorm=0.999, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2619
2022-09-28 18:34:19 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.6, ups=0.88, wpb=102.8, bsz=40, num_updates=2320, lr=5.88086e-05, gnorm=0.934, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2630
2022-09-28 18:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.5, ups=0.9, wpb=100.1, bsz=40, num_updates=2330, lr=5.90621e-05, gnorm=1.344, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2641
2022-09-28 18:34:41 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.1, ups=0.9, wpb=102, bsz=40, num_updates=2340, lr=5.93156e-05, gnorm=1.2, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2652
2022-09-28 18:34:52 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=2350, lr=5.95691e-05, gnorm=1.173, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2663
2022-09-28 18:35:04 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.7, ups=0.88, wpb=102.1, bsz=40, num_updates=2360, lr=5.98226e-05, gnorm=0.989, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2675
2022-09-28 18:35:15 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 15783 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.4, ups=0.89, wpb=99.3, bsz=40, num_updates=2370, lr=6.0076e-05, gnorm=1.132, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2686
2022-09-28 18:35:26 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.7, ups=0.89, wpb=102.7, bsz=40, num_updates=2380, lr=6.03295e-05, gnorm=1.203, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2697
2022-09-28 18:35:38 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.88, wpb=100.8, bsz=40, num_updates=2390, lr=6.0583e-05, gnorm=1.003, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2709
2022-09-28 18:35:49 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.87, wpb=102.4, bsz=40, num_updates=2400, lr=6.08365e-05, gnorm=1.157, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2720
2022-09-28 18:36:00 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.91, wpb=100.5, bsz=40, num_updates=2410, lr=6.109e-05, gnorm=1.151, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2731
2022-09-28 18:36:11 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.1, ups=0.92, wpb=101.7, bsz=40, num_updates=2420, lr=6.13435e-05, gnorm=1.199, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2742
2022-09-28 18:36:22 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.5, ups=0.93, wpb=100.5, bsz=40, num_updates=2430, lr=6.1597e-05, gnorm=1.309, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2753
2022-09-28 18:36:33 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.9, ups=0.87, wpb=100.3, bsz=40, num_updates=2440, lr=6.18504e-05, gnorm=1.207, clip=80, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2764
2022-09-28 18:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.89, wpb=102.1, bsz=40, num_updates=2450, lr=6.21039e-05, gnorm=1.099, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2776
2022-09-28 18:36:56 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=101.5, bsz=40, num_updates=2460, lr=6.23574e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2787
2022-09-28 18:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.3, ups=0.86, wpb=102.3, bsz=40, num_updates=2470, lr=6.26109e-05, gnorm=1.086, clip=80, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=2799
2022-09-28 18:37:19 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=2480, lr=6.28644e-05, gnorm=1.15, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2810
2022-09-28 18:37:30 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=2490, lr=6.31179e-05, gnorm=1.202, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2821
2022-09-28 18:37:41 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.89, wpb=100.7, bsz=40, num_updates=2500, lr=6.33714e-05, gnorm=1.099, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2832
2022-09-28 18:37:52 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.89, wpb=103.1, bsz=40, num_updates=2510, lr=6.36248e-05, gnorm=0.933, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2843
2022-09-28 18:38:04 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.5, ups=0.9, wpb=100.1, bsz=40, num_updates=2520, lr=6.38783e-05, gnorm=1.069, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2855
2022-09-28 18:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.4, ups=0.88, wpb=98.8, bsz=40, num_updates=2530, lr=6.41318e-05, gnorm=1.159, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2866
2022-09-28 18:38:26 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.9, wpb=100.8, bsz=40, num_updates=2540, lr=6.43853e-05, gnorm=1.11, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2877
2022-09-28 18:38:37 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.4, ups=0.9, wpb=100.4, bsz=40, num_updates=2550, lr=6.46388e-05, gnorm=1.301, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2888
2022-09-28 18:38:48 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.3, ups=0.9, wpb=99.3, bsz=40, num_updates=2560, lr=6.48923e-05, gnorm=1.057, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2899
2022-09-28 18:39:00 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 18:39:01 - progress_bar.py[line:274] - INFO: epoch 001:   2573 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=80.6, ups=0.81, wpb=99.8, bsz=40, num_updates=2570, lr=6.51458e-05, gnorm=1.177, clip=70, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2912
2022-09-28 18:39:12 - progress_bar.py[line:274] - INFO: epoch 001:   2583 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.9, wpb=101.8, bsz=40, num_updates=2580, lr=6.53992e-05, gnorm=0.957, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2923
2022-09-28 18:39:23 - progress_bar.py[line:274] - INFO: epoch 001:   2593 / 15783 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.8, ups=0.88, wpb=100.1, bsz=40, num_updates=2590, lr=6.56527e-05, gnorm=1.045, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2934
2022-09-28 18:39:34 - progress_bar.py[line:274] - INFO: epoch 001:   2603 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.4, ups=0.89, wpb=100.5, bsz=40, num_updates=2600, lr=6.59062e-05, gnorm=1.051, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2945
2022-09-28 18:39:46 - progress_bar.py[line:274] - INFO: epoch 001:   2613 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.5, ups=0.88, wpb=100.9, bsz=40, num_updates=2610, lr=6.61597e-05, gnorm=0.998, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2957
2022-09-28 18:39:57 - progress_bar.py[line:274] - INFO: epoch 001:   2623 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.9, ups=0.92, wpb=101.1, bsz=40, num_updates=2620, lr=6.64132e-05, gnorm=1, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2968
2022-09-28 18:40:08 - progress_bar.py[line:274] - INFO: epoch 001:   2633 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.89, wpb=102.4, bsz=40, num_updates=2630, lr=6.66667e-05, gnorm=1.085, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2979
2022-09-28 18:40:19 - progress_bar.py[line:274] - INFO: epoch 001:   2643 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.5, ups=0.92, wpb=102.7, bsz=40, num_updates=2640, lr=6.69202e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2990
2022-09-28 18:40:30 - progress_bar.py[line:274] - INFO: epoch 001:   2653 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.1, ups=0.91, wpb=103.3, bsz=40, num_updates=2650, lr=6.71736e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3001
2022-09-28 18:40:41 - progress_bar.py[line:274] - INFO: epoch 001:   2663 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=2660, lr=6.74271e-05, gnorm=1.104, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3012
2022-09-28 18:40:52 - progress_bar.py[line:274] - INFO: epoch 001:   2673 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91, ups=0.89, wpb=102.2, bsz=40, num_updates=2670, lr=6.76806e-05, gnorm=1.029, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3023
2022-09-28 18:41:04 - progress_bar.py[line:274] - INFO: epoch 001:   2683 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.88, wpb=102, bsz=40, num_updates=2680, lr=6.79341e-05, gnorm=0.975, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3035
2022-09-28 18:41:15 - progress_bar.py[line:274] - INFO: epoch 001:   2693 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.9, ups=0.9, wpb=100, bsz=40, num_updates=2690, lr=6.81876e-05, gnorm=1.034, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3046
2022-09-28 18:41:26 - progress_bar.py[line:274] - INFO: epoch 001:   2703 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.88, wpb=101.2, bsz=40, num_updates=2700, lr=6.84411e-05, gnorm=0.943, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=3057
2022-09-28 18:41:37 - progress_bar.py[line:274] - INFO: epoch 001:   2713 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=2710, lr=6.86946e-05, gnorm=0.957, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3068
2022-09-28 18:41:49 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.88, wpb=100.1, bsz=40, num_updates=2720, lr=6.8948e-05, gnorm=1.149, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3080
2022-09-28 18:42:00 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.89, wpb=101.1, bsz=40, num_updates=2730, lr=6.92015e-05, gnorm=1.272, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=3091
2022-09-28 18:42:11 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.89, wpb=103.1, bsz=40, num_updates=2740, lr=6.9455e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3102
2022-09-28 18:42:22 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.4, ups=0.93, wpb=99.9, bsz=40, num_updates=2750, lr=6.97085e-05, gnorm=1.128, clip=70, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3113
2022-09-28 18:42:33 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92, ups=0.9, wpb=102.3, bsz=40, num_updates=2760, lr=6.9962e-05, gnorm=1.033, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3124
2022-09-28 18:42:45 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.91, wpb=100.4, bsz=40, num_updates=2770, lr=7.02155e-05, gnorm=1.083, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3135
2022-09-28 18:42:56 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=2780, lr=7.04689e-05, gnorm=0.833, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3147
2022-09-28 18:43:07 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=2790, lr=7.07224e-05, gnorm=1.109, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3158
2022-09-28 18:43:18 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 15783 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.6, ups=0.89, wpb=101.6, bsz=40, num_updates=2800, lr=7.09759e-05, gnorm=1.523, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3170
2022-09-28 18:43:30 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.5, ups=0.9, wpb=101.2, bsz=40, num_updates=2810, lr=7.12294e-05, gnorm=1.137, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3181
2022-09-28 18:43:41 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.4, ups=0.91, wpb=100.5, bsz=40, num_updates=2820, lr=7.14829e-05, gnorm=0.92, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3192
2022-09-28 18:43:51 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.2, ups=0.93, wpb=102.3, bsz=40, num_updates=2830, lr=7.17364e-05, gnorm=0.936, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=3202
2022-09-28 18:44:03 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.6, ups=0.9, wpb=101.9, bsz=40, num_updates=2840, lr=7.19899e-05, gnorm=0.955, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3213
2022-09-28 18:44:14 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.6, ups=0.89, wpb=102.7, bsz=40, num_updates=2850, lr=7.22433e-05, gnorm=1.11, clip=60, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=3225
2022-09-28 18:44:25 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.4, ups=0.89, wpb=100.4, bsz=40, num_updates=2860, lr=7.24968e-05, gnorm=1.192, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3236
2022-09-28 18:44:37 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=2870, lr=7.27503e-05, gnorm=1.083, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3248
2022-09-28 18:44:48 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.1, ups=0.88, wpb=101, bsz=40, num_updates=2880, lr=7.30038e-05, gnorm=1.104, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3259
2022-09-28 18:44:59 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=2890, lr=7.32573e-05, gnorm=0.974, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3270
2022-09-28 18:45:10 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.3, ups=0.92, wpb=101.3, bsz=40, num_updates=2900, lr=7.35108e-05, gnorm=1.001, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3281
2022-09-28 18:45:22 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.92, wpb=100.2, bsz=40, num_updates=2910, lr=7.37643e-05, gnorm=1.11, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3292
2022-09-28 18:45:33 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.6, ups=0.91, wpb=101.3, bsz=40, num_updates=2920, lr=7.40177e-05, gnorm=1.071, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3304
2022-09-28 18:45:44 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89, ups=0.88, wpb=101.3, bsz=40, num_updates=2930, lr=7.42712e-05, gnorm=1.074, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3315
2022-09-28 18:45:55 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=2940, lr=7.45247e-05, gnorm=1.014, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3326
2022-09-28 18:46:07 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=2950, lr=7.47782e-05, gnorm=0.947, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3338
2022-09-28 18:46:18 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.3, ups=0.89, wpb=102.3, bsz=40, num_updates=2960, lr=7.50317e-05, gnorm=1.003, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3349
2022-09-28 18:46:29 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.5, ups=0.9, wpb=100.2, bsz=40, num_updates=2970, lr=7.52852e-05, gnorm=1.156, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3360
2022-09-28 18:46:40 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=2980, lr=7.55387e-05, gnorm=1.038, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3372
2022-09-28 18:46:52 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=2990, lr=7.57921e-05, gnorm=1.128, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3383
2022-09-28 18:47:03 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.8, ups=0.89, wpb=100.6, bsz=40, num_updates=3000, lr=7.60456e-05, gnorm=0.957, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3394
2022-09-28 18:47:14 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.7, ups=0.88, wpb=100.7, bsz=40, num_updates=3010, lr=7.62991e-05, gnorm=1.003, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3405
2022-09-28 18:47:25 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.3, ups=0.91, wpb=99.6, bsz=40, num_updates=3020, lr=7.65526e-05, gnorm=1.231, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3416
2022-09-28 18:47:36 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.9, wpb=102.6, bsz=40, num_updates=3030, lr=7.68061e-05, gnorm=0.947, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3427
2022-09-28 18:47:47 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.91, wpb=101.4, bsz=40, num_updates=3040, lr=7.70596e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3438
2022-09-28 18:47:59 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.2, ups=0.89, wpb=102.3, bsz=40, num_updates=3050, lr=7.73131e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3450
2022-09-28 18:48:10 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 15783 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.9, ups=0.91, wpb=100.5, bsz=40, num_updates=3060, lr=7.75665e-05, gnorm=1.006, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3461
2022-09-28 18:48:20 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.5, ups=0.93, wpb=101, bsz=40, num_updates=3070, lr=7.782e-05, gnorm=1.022, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3471
2022-09-28 18:48:32 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.3, ups=0.88, wpb=100, bsz=40, num_updates=3080, lr=7.80735e-05, gnorm=1.059, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3483
2022-09-28 18:48:38 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 18:48:44 - progress_bar.py[line:274] - INFO: epoch 001:   3094 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=81.6, ups=0.8, wpb=101.5, bsz=40, num_updates=3090, lr=7.8327e-05, gnorm=1.056, clip=50, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=3495
2022-09-28 18:48:55 - progress_bar.py[line:274] - INFO: epoch 001:   3104 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93, ups=0.91, wpb=101.7, bsz=40, num_updates=3100, lr=7.85805e-05, gnorm=0.899, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3506
2022-09-28 18:49:06 - progress_bar.py[line:274] - INFO: epoch 001:   3114 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.9, ups=0.92, wpb=101, bsz=40, num_updates=3110, lr=7.8834e-05, gnorm=1.01, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3517
2022-09-28 18:49:17 - progress_bar.py[line:274] - INFO: epoch 001:   3124 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.4, ups=0.9, wpb=99.7, bsz=40, num_updates=3120, lr=7.90875e-05, gnorm=1.063, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3528
2022-09-28 18:49:28 - progress_bar.py[line:274] - INFO: epoch 001:   3134 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.4, ups=0.9, wpb=102.1, bsz=40, num_updates=3130, lr=7.93409e-05, gnorm=0.94, clip=40, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=3539
2022-09-28 18:49:39 - progress_bar.py[line:274] - INFO: epoch 001:   3144 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.3, ups=0.89, wpb=102.1, bsz=40, num_updates=3140, lr=7.95944e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3551
2022-09-28 18:49:50 - progress_bar.py[line:274] - INFO: epoch 001:   3154 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.9, ups=0.91, wpb=102.2, bsz=40, num_updates=3150, lr=7.98479e-05, gnorm=1.044, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3562
2022-09-28 18:50:02 - progress_bar.py[line:274] - INFO: epoch 001:   3164 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.88, wpb=100.4, bsz=40, num_updates=3160, lr=7.99958e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3573
2022-09-28 18:50:13 - progress_bar.py[line:274] - INFO: epoch 001:   3174 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.89, wpb=102.6, bsz=40, num_updates=3170, lr=7.99852e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3584
2022-09-28 18:50:24 - progress_bar.py[line:274] - INFO: epoch 001:   3184 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.5, ups=0.9, wpb=101.6, bsz=40, num_updates=3180, lr=7.99747e-05, gnorm=0.973, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3595
2022-09-28 18:50:35 - progress_bar.py[line:274] - INFO: epoch 001:   3194 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.89, wpb=100.4, bsz=40, num_updates=3190, lr=7.99641e-05, gnorm=0.995, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3606
2022-09-28 18:50:47 - progress_bar.py[line:274] - INFO: epoch 001:   3204 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.89, wpb=101.7, bsz=40, num_updates=3200, lr=7.99535e-05, gnorm=1.072, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3618
2022-09-28 18:50:58 - progress_bar.py[line:274] - INFO: epoch 001:   3214 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.6, ups=0.88, wpb=100.7, bsz=40, num_updates=3210, lr=7.9943e-05, gnorm=1.022, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3629
2022-09-28 18:51:09 - progress_bar.py[line:274] - INFO: epoch 001:   3224 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.5, ups=0.89, wpb=101.3, bsz=40, num_updates=3220, lr=7.99324e-05, gnorm=0.941, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3640
2022-09-28 18:51:21 - progress_bar.py[line:274] - INFO: epoch 001:   3234 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.4, ups=0.87, wpb=100.6, bsz=40, num_updates=3230, lr=7.99219e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3652
2022-09-28 18:51:32 - progress_bar.py[line:274] - INFO: epoch 001:   3244 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.8, ups=0.87, wpb=100.7, bsz=40, num_updates=3240, lr=7.99113e-05, gnorm=1.227, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3663
2022-09-28 18:51:44 - progress_bar.py[line:274] - INFO: epoch 001:   3254 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.88, wpb=100.8, bsz=40, num_updates=3250, lr=7.99007e-05, gnorm=1.019, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3675
2022-09-28 18:51:55 - progress_bar.py[line:274] - INFO: epoch 001:   3264 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.9, wpb=100.8, bsz=40, num_updates=3260, lr=7.98902e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3686
2022-09-28 18:52:06 - progress_bar.py[line:274] - INFO: epoch 001:   3274 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.89, wpb=100.6, bsz=40, num_updates=3270, lr=7.98796e-05, gnorm=1.013, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3697
2022-09-28 18:52:16 - progress_bar.py[line:274] - INFO: epoch 001:   3284 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.6, ups=0.95, wpb=100.4, bsz=40, num_updates=3280, lr=7.98691e-05, gnorm=1.052, clip=60, loss_scale=512, train_wall=10, gb_free=10.5, ema_decay=0.9999, wall=3707
2022-09-28 18:52:27 - progress_bar.py[line:274] - INFO: epoch 001:   3294 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.7, ups=0.91, wpb=101.4, bsz=40, num_updates=3290, lr=7.98585e-05, gnorm=0.913, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3718
2022-09-28 18:52:38 - progress_bar.py[line:274] - INFO: epoch 001:   3304 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=100.7, bsz=40, num_updates=3300, lr=7.98479e-05, gnorm=1.015, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3730
2022-09-28 18:52:50 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.4, ups=0.87, wpb=101.2, bsz=40, num_updates=3310, lr=7.98374e-05, gnorm=1.138, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3741
2022-09-28 18:53:02 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=84.8, ups=0.84, wpb=101.4, bsz=40, num_updates=3320, lr=7.98268e-05, gnorm=1.007, clip=40, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=3753
2022-09-28 18:53:13 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.1, ups=0.89, wpb=99, bsz=40, num_updates=3330, lr=7.98163e-05, gnorm=1.112, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3764
2022-09-28 18:53:24 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.7, ups=0.9, wpb=103.6, bsz=40, num_updates=3340, lr=7.98057e-05, gnorm=0.983, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3775
2022-09-28 18:53:35 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.4, ups=0.91, wpb=101.8, bsz=40, num_updates=3350, lr=7.97951e-05, gnorm=0.932, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3786
2022-09-28 18:53:46 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=3360, lr=7.97846e-05, gnorm=0.788, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3797
2022-09-28 18:53:58 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.3, ups=0.89, wpb=100.8, bsz=40, num_updates=3370, lr=7.9774e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3809
2022-09-28 18:54:09 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.4, ups=0.88, wpb=101.8, bsz=40, num_updates=3380, lr=7.97635e-05, gnorm=0.831, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3820
2022-09-28 18:54:20 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.3, ups=0.9, wpb=99.7, bsz=40, num_updates=3390, lr=7.97529e-05, gnorm=0.971, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3831
2022-09-28 18:54:31 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.2, ups=0.96, wpb=100.8, bsz=40, num_updates=3400, lr=7.97423e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=10, gb_free=10.9, ema_decay=0.9999, wall=3842
2022-09-28 18:54:42 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 15783 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.3, ups=0.88, wpb=100.3, bsz=40, num_updates=3410, lr=7.97318e-05, gnorm=0.928, clip=40, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=3853
2022-09-28 18:54:53 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.9, wpb=102, bsz=40, num_updates=3420, lr=7.97212e-05, gnorm=0.981, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3864
2022-09-28 18:55:05 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.88, wpb=101, bsz=40, num_updates=3430, lr=7.97107e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3876
2022-09-28 18:55:16 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=3440, lr=7.97001e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3887
2022-09-28 18:55:27 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.87, wpb=101.7, bsz=40, num_updates=3450, lr=7.96895e-05, gnorm=0.781, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3898
2022-09-28 18:55:39 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.3, ups=0.89, wpb=99.8, bsz=40, num_updates=3460, lr=7.9679e-05, gnorm=0.975, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3910
2022-09-28 18:55:49 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.92, wpb=100.5, bsz=40, num_updates=3470, lr=7.96684e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3920
2022-09-28 18:56:01 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.7, ups=0.9, wpb=102.8, bsz=40, num_updates=3480, lr=7.96579e-05, gnorm=0.822, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3932
2022-09-28 18:56:12 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.8, ups=0.89, wpb=100.5, bsz=40, num_updates=3490, lr=7.96473e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3943
2022-09-28 18:56:23 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.9, wpb=101.3, bsz=40, num_updates=3500, lr=7.96367e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3954
2022-09-28 18:56:34 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.7, ups=0.9, wpb=98.6, bsz=40, num_updates=3510, lr=7.96262e-05, gnorm=0.991, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3965
2022-09-28 18:56:45 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.89, wpb=101.3, bsz=40, num_updates=3520, lr=7.96156e-05, gnorm=0.999, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3976
2022-09-28 18:56:56 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 15783 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.9, ups=0.9, wpb=100.5, bsz=40, num_updates=3530, lr=7.96051e-05, gnorm=1.06, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3987
2022-09-28 18:57:07 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.3, ups=0.91, wpb=100.9, bsz=40, num_updates=3540, lr=7.95945e-05, gnorm=0.882, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3998
2022-09-28 18:57:18 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.9, ups=0.89, wpb=100.8, bsz=40, num_updates=3550, lr=7.95839e-05, gnorm=0.945, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4009
2022-09-28 18:57:30 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.87, wpb=101.5, bsz=40, num_updates=3560, lr=7.95734e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4021
2022-09-28 18:57:41 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.88, wpb=102, bsz=40, num_updates=3570, lr=7.95628e-05, gnorm=0.739, clip=0, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4032
2022-09-28 18:57:52 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.9, ups=0.89, wpb=101.6, bsz=40, num_updates=3580, lr=7.95523e-05, gnorm=0.735, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4043
2022-09-28 18:58:03 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.91, wpb=101.9, bsz=40, num_updates=3590, lr=7.95417e-05, gnorm=0.88, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4054
2022-09-28 18:58:14 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.7, ups=0.9, wpb=102.8, bsz=40, num_updates=3600, lr=7.95311e-05, gnorm=0.92, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4066
2022-09-28 18:58:22 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 18:58:27 - progress_bar.py[line:274] - INFO: epoch 001:   3615 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=82.7, ups=0.8, wpb=102.8, bsz=40, num_updates=3610, lr=7.95206e-05, gnorm=0.924, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=4078
2022-09-28 18:58:38 - progress_bar.py[line:274] - INFO: epoch 001:   3625 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.9, wpb=101.7, bsz=40, num_updates=3620, lr=7.951e-05, gnorm=0.961, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4089
2022-09-28 18:58:49 - progress_bar.py[line:274] - INFO: epoch 001:   3635 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.9, ups=0.88, wpb=100.9, bsz=40, num_updates=3630, lr=7.94995e-05, gnorm=0.847, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4100
2022-09-28 18:59:02 - progress_bar.py[line:274] - INFO: epoch 001:   3645 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=83.9, ups=0.82, wpb=102.6, bsz=40, num_updates=3640, lr=7.94889e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=4113
2022-09-28 18:59:15 - progress_bar.py[line:274] - INFO: epoch 001:   3655 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=74, ups=0.73, wpb=101.5, bsz=40, num_updates=3650, lr=7.94783e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=4126
2022-09-28 18:59:29 - progress_bar.py[line:274] - INFO: epoch 001:   3665 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=73.9, ups=0.73, wpb=100.8, bsz=40, num_updates=3660, lr=7.94678e-05, gnorm=0.765, clip=0, loss_scale=512, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=4140
2022-09-28 18:59:41 - progress_bar.py[line:274] - INFO: epoch 001:   3675 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=85.3, ups=0.83, wpb=103, bsz=40, num_updates=3670, lr=7.94572e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=4152
2022-09-28 18:59:52 - progress_bar.py[line:274] - INFO: epoch 001:   3685 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.2, ups=0.89, wpb=100, bsz=40, num_updates=3680, lr=7.94467e-05, gnorm=0.901, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4163
2022-09-28 19:00:03 - progress_bar.py[line:274] - INFO: epoch 001:   3695 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95, ups=0.94, wpb=101, bsz=40, num_updates=3690, lr=7.94361e-05, gnorm=0.83, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4174
2022-09-28 19:00:14 - progress_bar.py[line:274] - INFO: epoch 001:   3705 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.1, ups=0.92, wpb=102.7, bsz=40, num_updates=3700, lr=7.94255e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4185
2022-09-28 19:00:25 - progress_bar.py[line:274] - INFO: epoch 001:   3715 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.88, wpb=104.2, bsz=40, num_updates=3710, lr=7.9415e-05, gnorm=0.768, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4196
2022-09-28 19:00:37 - progress_bar.py[line:274] - INFO: epoch 001:   3725 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=3720, lr=7.94044e-05, gnorm=0.854, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4208
2022-09-28 19:00:48 - progress_bar.py[line:274] - INFO: epoch 001:   3735 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.2, ups=0.87, wpb=100.2, bsz=40, num_updates=3730, lr=7.93939e-05, gnorm=1.1, clip=10, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=4219
2022-09-28 19:00:59 - progress_bar.py[line:274] - INFO: epoch 001:   3745 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.7, ups=0.88, wpb=102.4, bsz=40, num_updates=3740, lr=7.93833e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4230
2022-09-28 19:01:11 - progress_bar.py[line:274] - INFO: epoch 001:   3755 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.88, wpb=101.6, bsz=40, num_updates=3750, lr=7.93727e-05, gnorm=0.865, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4242
2022-09-28 19:01:22 - progress_bar.py[line:274] - INFO: epoch 001:   3765 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.3, ups=0.91, wpb=102.7, bsz=40, num_updates=3760, lr=7.93622e-05, gnorm=0.863, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4253
2022-09-28 19:01:33 - progress_bar.py[line:274] - INFO: epoch 001:   3775 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.8, ups=0.9, wpb=100.6, bsz=40, num_updates=3770, lr=7.93516e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4264
2022-09-28 19:01:44 - progress_bar.py[line:274] - INFO: epoch 001:   3785 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.91, wpb=101, bsz=40, num_updates=3780, lr=7.93411e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4275
2022-09-28 19:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   3795 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.6, ups=0.88, wpb=101.6, bsz=40, num_updates=3790, lr=7.93305e-05, gnorm=0.808, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4286
2022-09-28 19:02:07 - progress_bar.py[line:274] - INFO: epoch 001:   3805 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.2, ups=0.88, wpb=102.2, bsz=40, num_updates=3800, lr=7.93199e-05, gnorm=0.92, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4298
2022-09-28 19:02:18 - progress_bar.py[line:274] - INFO: epoch 001:   3815 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.6, ups=0.87, wpb=100.2, bsz=40, num_updates=3810, lr=7.93094e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4309
2022-09-28 19:02:30 - progress_bar.py[line:274] - INFO: epoch 001:   3825 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.3, ups=0.87, wpb=100.7, bsz=40, num_updates=3820, lr=7.92988e-05, gnorm=0.751, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4321
2022-09-28 19:02:42 - progress_bar.py[line:274] - INFO: epoch 001:   3835 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=83.9, ups=0.83, wpb=101.1, bsz=40, num_updates=3830, lr=7.92883e-05, gnorm=0.992, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=4333
2022-09-28 19:02:52 - progress_bar.py[line:274] - INFO: epoch 001:   3845 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.8, ups=0.93, wpb=102.4, bsz=40, num_updates=3840, lr=7.92777e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4343
2022-09-28 19:03:04 - progress_bar.py[line:274] - INFO: epoch 001:   3855 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90, ups=0.87, wpb=103, bsz=40, num_updates=3850, lr=7.92671e-05, gnorm=0.913, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4355
2022-09-28 19:03:15 - progress_bar.py[line:274] - INFO: epoch 001:   3865 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.89, wpb=102.5, bsz=40, num_updates=3860, lr=7.92566e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4366
2022-09-28 19:03:26 - progress_bar.py[line:274] - INFO: epoch 001:   3875 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.2, ups=0.94, wpb=100.8, bsz=40, num_updates=3870, lr=7.9246e-05, gnorm=0.875, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4377
2022-09-28 19:03:37 - progress_bar.py[line:274] - INFO: epoch 001:   3885 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=3880, lr=7.92355e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4388
2022-09-28 19:03:49 - progress_bar.py[line:274] - INFO: epoch 001:   3895 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=85.6, ups=0.85, wpb=100.8, bsz=40, num_updates=3890, lr=7.92249e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=4400
2022-09-28 19:04:00 - progress_bar.py[line:274] - INFO: epoch 001:   3905 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.9, ups=0.87, wpb=100.9, bsz=40, num_updates=3900, lr=7.92144e-05, gnorm=0.983, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4411
2022-09-28 19:04:12 - progress_bar.py[line:274] - INFO: epoch 001:   3915 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.1, ups=0.88, wpb=104.5, bsz=40, num_updates=3910, lr=7.92038e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4423
2022-09-28 19:04:22 - progress_bar.py[line:274] - INFO: epoch 001:   3925 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.8, ups=0.92, wpb=100.9, bsz=40, num_updates=3920, lr=7.91932e-05, gnorm=1.058, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4433
2022-09-28 19:04:34 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.88, wpb=102.2, bsz=40, num_updates=3930, lr=7.91827e-05, gnorm=0.894, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4445
2022-09-28 19:04:45 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.1, ups=0.89, wpb=99.9, bsz=40, num_updates=3940, lr=7.91721e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4456
2022-09-28 19:04:56 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97, ups=0.94, wpb=102.7, bsz=40, num_updates=3950, lr=7.91616e-05, gnorm=0.951, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4467
2022-09-28 19:05:07 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.3, ups=0.88, wpb=100.2, bsz=40, num_updates=3960, lr=7.9151e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4478
2022-09-28 19:05:19 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=79.9, ups=0.8, wpb=99.7, bsz=40, num_updates=3970, lr=7.91404e-05, gnorm=0.894, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4490
2022-09-28 19:05:35 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=66.7, ups=0.66, wpb=101.1, bsz=40, num_updates=3980, lr=7.91299e-05, gnorm=0.977, clip=50, loss_scale=512, train_wall=15, gb_free=10.4, ema_decay=0.9999, wall=4506
2022-09-28 19:05:48 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=76.2, ups=0.75, wpb=101.9, bsz=40, num_updates=3990, lr=7.91193e-05, gnorm=0.953, clip=60, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=4519
2022-09-28 19:06:00 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 15783 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=83.9, ups=0.84, wpb=99.9, bsz=40, num_updates=4000, lr=7.91088e-05, gnorm=0.806, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=4531
2022-09-28 19:06:11 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.2, ups=0.9, wpb=101.1, bsz=40, num_updates=4010, lr=7.90982e-05, gnorm=0.869, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4542
2022-09-28 19:06:23 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 15783 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=84.7, ups=0.85, wpb=99.9, bsz=40, num_updates=4020, lr=7.90876e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=4554
2022-09-28 19:06:34 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.6, ups=0.86, wpb=101.6, bsz=40, num_updates=4030, lr=7.90771e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=4565
2022-09-28 19:06:47 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 15783 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=79.8, ups=0.8, wpb=99.6, bsz=40, num_updates=4040, lr=7.90665e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4578
2022-09-28 19:06:58 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.5, ups=0.91, wpb=101.1, bsz=40, num_updates=4050, lr=7.9056e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4589
2022-09-28 19:07:09 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.7, ups=0.94, wpb=103, bsz=40, num_updates=4060, lr=7.90454e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4600
2022-09-28 19:07:20 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.3, ups=0.88, wpb=99, bsz=40, num_updates=4070, lr=7.90348e-05, gnorm=0.86, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4611
2022-09-28 19:07:30 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.1, ups=0.95, wpb=101.8, bsz=40, num_updates=4080, lr=7.90243e-05, gnorm=0.97, clip=40, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=4621
2022-09-28 19:07:42 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.89, wpb=100, bsz=40, num_updates=4090, lr=7.90137e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4633
2022-09-28 19:07:53 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.3, ups=0.91, wpb=100.7, bsz=40, num_updates=4100, lr=7.90032e-05, gnorm=0.88, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4644
2022-09-28 19:08:04 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.1, ups=0.89, wpb=100.2, bsz=40, num_updates=4110, lr=7.89926e-05, gnorm=0.944, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4655
2022-09-28 19:08:15 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.6, ups=0.93, wpb=100.4, bsz=40, num_updates=4120, lr=7.8982e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4666
2022-09-28 19:08:26 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90, ups=0.88, wpb=102, bsz=40, num_updates=4130, lr=7.89715e-05, gnorm=0.92, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4677
2022-09-28 19:08:37 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.88, wpb=103.5, bsz=40, num_updates=4140, lr=7.89609e-05, gnorm=0.793, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4688
2022-09-28 19:08:50 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=81.6, ups=0.82, wpb=99.1, bsz=40, num_updates=4150, lr=7.89504e-05, gnorm=0.83, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=4701
2022-09-28 19:09:02 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=84.3, ups=0.82, wpb=102.5, bsz=40, num_updates=4160, lr=7.89398e-05, gnorm=0.757, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4713
2022-09-28 19:09:14 - progress_bar.py[line:274] - INFO: epoch 001:   4175 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=82.4, ups=0.83, wpb=99.9, bsz=40, num_updates=4170, lr=7.89292e-05, gnorm=0.86, clip=30, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=4725
2022-09-28 19:09:21 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 19:09:26 - progress_bar.py[line:274] - INFO: epoch 001:   4186 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=84.5, ups=0.83, wpb=101.7, bsz=40, num_updates=4180, lr=7.89187e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=4737
2022-09-28 19:09:37 - progress_bar.py[line:274] - INFO: epoch 001:   4196 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.7, ups=0.88, wpb=101.7, bsz=40, num_updates=4190, lr=7.89081e-05, gnorm=1.078, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4748
2022-09-28 19:09:48 - progress_bar.py[line:274] - INFO: epoch 001:   4206 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.9, ups=0.89, wpb=101.7, bsz=40, num_updates=4200, lr=7.88976e-05, gnorm=0.761, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4759
2022-09-28 19:10:00 - progress_bar.py[line:274] - INFO: epoch 001:   4216 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.8, ups=0.88, wpb=100.7, bsz=40, num_updates=4210, lr=7.8887e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4771
2022-09-28 19:10:11 - progress_bar.py[line:274] - INFO: epoch 001:   4226 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=4220, lr=7.88764e-05, gnorm=0.898, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4782
2022-09-28 19:10:22 - progress_bar.py[line:274] - INFO: epoch 001:   4236 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.2, ups=0.89, wpb=101, bsz=40, num_updates=4230, lr=7.88659e-05, gnorm=0.774, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4793
2022-09-28 19:10:34 - progress_bar.py[line:274] - INFO: epoch 001:   4246 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.1, ups=0.88, wpb=101.6, bsz=40, num_updates=4240, lr=7.88553e-05, gnorm=0.874, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4805
2022-09-28 19:10:45 - progress_bar.py[line:274] - INFO: epoch 001:   4256 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.5, ups=0.92, wpb=100.7, bsz=40, num_updates=4250, lr=7.88448e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4816
2022-09-28 19:10:56 - progress_bar.py[line:274] - INFO: epoch 001:   4266 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.1, ups=0.89, wpb=102.3, bsz=40, num_updates=4260, lr=7.88342e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4827
2022-09-28 19:11:07 - progress_bar.py[line:274] - INFO: epoch 001:   4276 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.4, ups=0.92, wpb=101.7, bsz=40, num_updates=4270, lr=7.88236e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4838
2022-09-28 19:11:18 - progress_bar.py[line:274] - INFO: epoch 001:   4286 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.7, ups=0.88, wpb=100.5, bsz=40, num_updates=4280, lr=7.88131e-05, gnorm=0.829, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4849
2022-09-28 19:11:29 - progress_bar.py[line:274] - INFO: epoch 001:   4296 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.1, ups=0.91, wpb=101.2, bsz=40, num_updates=4290, lr=7.88025e-05, gnorm=0.915, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4860
2022-09-28 19:11:40 - progress_bar.py[line:274] - INFO: epoch 001:   4306 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.6, ups=0.89, wpb=101.2, bsz=40, num_updates=4300, lr=7.8792e-05, gnorm=0.99, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4871
2022-09-28 19:11:53 - progress_bar.py[line:274] - INFO: epoch 001:   4316 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=82, ups=0.81, wpb=100.8, bsz=40, num_updates=4310, lr=7.87814e-05, gnorm=0.754, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4884
2022-09-28 19:12:05 - progress_bar.py[line:274] - INFO: epoch 001:   4326 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=79.1, ups=0.8, wpb=99.5, bsz=40, num_updates=4320, lr=7.87708e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=4896
2022-09-28 19:12:16 - progress_bar.py[line:274] - INFO: epoch 001:   4336 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.89, wpb=102.8, bsz=40, num_updates=4330, lr=7.87603e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4908
2022-09-28 19:12:29 - progress_bar.py[line:274] - INFO: epoch 001:   4346 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.8, ups=0.86, wpb=100.5, bsz=40, num_updates=4340, lr=7.87497e-05, gnorm=0.861, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4919
2022-09-28 19:12:40 - progress_bar.py[line:274] - INFO: epoch 001:   4356 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.7, ups=0.89, wpb=101.8, bsz=40, num_updates=4350, lr=7.87392e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4931
2022-09-28 19:12:52 - progress_bar.py[line:274] - INFO: epoch 001:   4366 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=85.6, ups=0.85, wpb=101.2, bsz=40, num_updates=4360, lr=7.87286e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4943
2022-09-28 19:13:03 - progress_bar.py[line:274] - INFO: epoch 001:   4376 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87, ups=0.86, wpb=101.4, bsz=40, num_updates=4370, lr=7.8718e-05, gnorm=0.899, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4954
2022-09-28 19:13:15 - progress_bar.py[line:274] - INFO: epoch 001:   4386 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=86, ups=0.84, wpb=101.8, bsz=40, num_updates=4380, lr=7.87075e-05, gnorm=1.002, clip=60, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=4966
2022-09-28 19:13:26 - progress_bar.py[line:274] - INFO: epoch 001:   4396 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.3, ups=0.92, wpb=101.8, bsz=40, num_updates=4390, lr=7.86969e-05, gnorm=1.051, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4977
2022-09-28 19:13:38 - progress_bar.py[line:274] - INFO: epoch 001:   4406 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.5, ups=0.87, wpb=99.9, bsz=40, num_updates=4400, lr=7.86864e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=4989
2022-09-28 19:13:49 - progress_bar.py[line:274] - INFO: epoch 001:   4416 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.3, ups=0.9, wpb=101.8, bsz=40, num_updates=4410, lr=7.86758e-05, gnorm=0.818, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5000
2022-09-28 19:14:01 - progress_bar.py[line:274] - INFO: epoch 001:   4426 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.5, ups=0.88, wpb=101.5, bsz=40, num_updates=4420, lr=7.86652e-05, gnorm=0.879, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5012
2022-09-28 19:14:12 - progress_bar.py[line:274] - INFO: epoch 001:   4436 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.9, wpb=99.7, bsz=40, num_updates=4430, lr=7.86547e-05, gnorm=0.939, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5023
2022-09-28 19:14:23 - progress_bar.py[line:274] - INFO: epoch 001:   4446 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=4440, lr=7.86441e-05, gnorm=0.854, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5034
2022-09-28 19:14:34 - progress_bar.py[line:274] - INFO: epoch 001:   4456 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92, ups=0.92, wpb=100.3, bsz=40, num_updates=4450, lr=7.86336e-05, gnorm=0.808, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5045
2022-09-28 19:14:45 - progress_bar.py[line:274] - INFO: epoch 001:   4466 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.6, ups=0.88, wpb=101.4, bsz=40, num_updates=4460, lr=7.8623e-05, gnorm=0.822, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5056
2022-09-28 19:14:57 - progress_bar.py[line:274] - INFO: epoch 001:   4476 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.9, wpb=100.8, bsz=40, num_updates=4470, lr=7.86124e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5068
2022-09-28 19:15:08 - progress_bar.py[line:274] - INFO: epoch 001:   4486 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.5, ups=0.91, wpb=100.7, bsz=40, num_updates=4480, lr=7.86019e-05, gnorm=0.802, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5079
2022-09-28 19:15:19 - progress_bar.py[line:274] - INFO: epoch 001:   4496 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.89, wpb=101.1, bsz=40, num_updates=4490, lr=7.85913e-05, gnorm=0.839, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5090
2022-09-28 19:15:30 - progress_bar.py[line:274] - INFO: epoch 001:   4506 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.89, wpb=101.5, bsz=40, num_updates=4500, lr=7.85808e-05, gnorm=0.795, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5101
2022-09-28 19:15:41 - progress_bar.py[line:274] - INFO: epoch 001:   4516 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.8, ups=0.94, wpb=102.8, bsz=40, num_updates=4510, lr=7.85702e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5112
2022-09-28 19:15:51 - progress_bar.py[line:274] - INFO: epoch 001:   4526 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.4, ups=0.91, wpb=100, bsz=40, num_updates=4520, lr=7.85596e-05, gnorm=0.792, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5123
2022-09-28 19:16:02 - progress_bar.py[line:274] - INFO: epoch 001:   4536 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.4, ups=0.92, wpb=102.6, bsz=40, num_updates=4530, lr=7.85491e-05, gnorm=0.795, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5133
2022-09-28 19:16:13 - progress_bar.py[line:274] - INFO: epoch 001:   4546 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.7, ups=0.9, wpb=102.5, bsz=40, num_updates=4540, lr=7.85385e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5144
2022-09-28 19:16:24 - progress_bar.py[line:274] - INFO: epoch 001:   4556 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92, ups=0.92, wpb=100.4, bsz=40, num_updates=4550, lr=7.8528e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5155
2022-09-28 19:16:35 - progress_bar.py[line:274] - INFO: epoch 001:   4566 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.92, wpb=100.7, bsz=40, num_updates=4560, lr=7.85174e-05, gnorm=0.742, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5166
2022-09-28 19:16:46 - progress_bar.py[line:274] - INFO: epoch 001:   4576 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.3, ups=0.9, wpb=102.5, bsz=40, num_updates=4570, lr=7.85068e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5177
2022-09-28 19:16:58 - progress_bar.py[line:274] - INFO: epoch 001:   4586 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.5, ups=0.91, wpb=101.9, bsz=40, num_updates=4580, lr=7.84963e-05, gnorm=0.732, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5188
2022-09-28 19:17:09 - progress_bar.py[line:274] - INFO: epoch 001:   4596 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=84.3, ups=0.84, wpb=100.2, bsz=40, num_updates=4590, lr=7.84857e-05, gnorm=0.742, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=5201
2022-09-28 19:17:22 - progress_bar.py[line:274] - INFO: epoch 001:   4606 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=83.2, ups=0.81, wpb=102.6, bsz=40, num_updates=4600, lr=7.84752e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=5213
2022-09-28 19:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   4616 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.7, ups=0.85, wpb=103.2, bsz=40, num_updates=4610, lr=7.84646e-05, gnorm=0.771, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5225
2022-09-28 19:17:45 - progress_bar.py[line:274] - INFO: epoch 001:   4626 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.88, wpb=103.1, bsz=40, num_updates=4620, lr=7.8454e-05, gnorm=0.759, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5236
2022-09-28 19:17:56 - progress_bar.py[line:274] - INFO: epoch 001:   4636 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.9, ups=0.93, wpb=101.4, bsz=40, num_updates=4630, lr=7.84435e-05, gnorm=0.867, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5247
2022-09-28 19:18:07 - progress_bar.py[line:274] - INFO: epoch 001:   4646 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.6, ups=0.89, wpb=101.3, bsz=40, num_updates=4640, lr=7.84329e-05, gnorm=0.721, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5258
2022-09-28 19:18:18 - progress_bar.py[line:274] - INFO: epoch 001:   4656 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.5, ups=0.92, wpb=101, bsz=40, num_updates=4650, lr=7.84224e-05, gnorm=0.718, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5269
2022-09-28 19:18:29 - progress_bar.py[line:274] - INFO: epoch 001:   4666 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.91, wpb=101.3, bsz=40, num_updates=4660, lr=7.84118e-05, gnorm=0.863, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5280
2022-09-28 19:18:40 - progress_bar.py[line:274] - INFO: epoch 001:   4676 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.88, wpb=101.7, bsz=40, num_updates=4670, lr=7.84012e-05, gnorm=0.844, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5291
2022-09-28 19:18:51 - progress_bar.py[line:274] - INFO: epoch 001:   4686 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.7, ups=0.9, wpb=101.8, bsz=40, num_updates=4680, lr=7.83907e-05, gnorm=0.828, clip=20, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=5302
2022-09-28 19:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   4696 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=84.8, ups=0.86, wpb=99.2, bsz=40, num_updates=4690, lr=7.83801e-05, gnorm=0.867, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=5314
2022-09-28 19:19:15 - progress_bar.py[line:274] - INFO: epoch 001:   4706 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=83.8, ups=0.83, wpb=101.4, bsz=40, num_updates=4700, lr=7.83696e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=5326
2022-09-28 19:19:26 - progress_bar.py[line:274] - INFO: epoch 001:   4716 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=4710, lr=7.8359e-05, gnorm=0.89, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5337
2022-09-28 19:19:37 - progress_bar.py[line:274] - INFO: epoch 001:   4726 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.9, wpb=101.5, bsz=40, num_updates=4720, lr=7.83484e-05, gnorm=0.762, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5348
2022-09-28 19:19:48 - progress_bar.py[line:274] - INFO: epoch 001:   4736 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.7, ups=0.91, wpb=100.4, bsz=40, num_updates=4730, lr=7.83379e-05, gnorm=0.667, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5359
2022-09-28 19:20:00 - progress_bar.py[line:274] - INFO: epoch 001:   4746 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.9, ups=0.87, wpb=101.3, bsz=40, num_updates=4740, lr=7.83273e-05, gnorm=0.696, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5371
2022-09-28 19:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   4756 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=101.2, bsz=40, num_updates=4750, lr=7.83168e-05, gnorm=0.807, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5382
2022-09-28 19:20:18 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 19:20:23 - progress_bar.py[line:274] - INFO: epoch 001:   4767 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=84.1, ups=0.83, wpb=101.6, bsz=40, num_updates=4760, lr=7.83062e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=5395
2022-09-28 19:20:35 - progress_bar.py[line:274] - INFO: epoch 001:   4777 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.9, wpb=101, bsz=40, num_updates=4770, lr=7.82956e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5406
2022-09-28 19:20:46 - progress_bar.py[line:274] - INFO: epoch 001:   4787 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.5, ups=0.93, wpb=99.6, bsz=40, num_updates=4780, lr=7.82851e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5417
2022-09-28 19:20:57 - progress_bar.py[line:274] - INFO: epoch 001:   4797 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.89, wpb=100.5, bsz=40, num_updates=4790, lr=7.82745e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5428
2022-09-28 19:21:08 - progress_bar.py[line:274] - INFO: epoch 001:   4807 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.2, ups=0.9, wpb=103.3, bsz=40, num_updates=4800, lr=7.8264e-05, gnorm=1.037, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5439
2022-09-28 19:21:19 - progress_bar.py[line:274] - INFO: epoch 001:   4817 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.3, ups=0.88, wpb=101.7, bsz=40, num_updates=4810, lr=7.82534e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5450
2022-09-28 19:21:31 - progress_bar.py[line:274] - INFO: epoch 001:   4827 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.5, ups=0.87, wpb=100.5, bsz=40, num_updates=4820, lr=7.82428e-05, gnorm=0.772, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5462
2022-09-28 19:21:42 - progress_bar.py[line:274] - INFO: epoch 001:   4837 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.89, wpb=100.2, bsz=40, num_updates=4830, lr=7.82323e-05, gnorm=0.738, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5473
2022-09-28 19:21:53 - progress_bar.py[line:274] - INFO: epoch 001:   4847 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.9, wpb=100.8, bsz=40, num_updates=4840, lr=7.82217e-05, gnorm=0.814, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5484
2022-09-28 19:22:04 - progress_bar.py[line:274] - INFO: epoch 001:   4857 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.9, wpb=99.8, bsz=40, num_updates=4850, lr=7.82112e-05, gnorm=0.759, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5495
2022-09-28 19:22:16 - progress_bar.py[line:274] - INFO: epoch 001:   4867 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.5, ups=0.88, wpb=101.5, bsz=40, num_updates=4860, lr=7.82006e-05, gnorm=0.768, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5507
2022-09-28 19:22:27 - progress_bar.py[line:274] - INFO: epoch 001:   4877 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.1, ups=0.89, wpb=100.7, bsz=40, num_updates=4870, lr=7.81901e-05, gnorm=0.888, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5518
2022-09-28 19:22:38 - progress_bar.py[line:274] - INFO: epoch 001:   4887 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.9, wpb=101.1, bsz=40, num_updates=4880, lr=7.81795e-05, gnorm=0.811, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5529
2022-09-28 19:22:49 - progress_bar.py[line:274] - INFO: epoch 001:   4897 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.7, ups=0.92, wpb=99.8, bsz=40, num_updates=4890, lr=7.81689e-05, gnorm=0.796, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5540
2022-09-28 19:23:00 - progress_bar.py[line:274] - INFO: epoch 001:   4907 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=100.6, bsz=40, num_updates=4900, lr=7.81584e-05, gnorm=0.788, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5551
2022-09-28 19:23:11 - progress_bar.py[line:274] - INFO: epoch 001:   4917 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.7, ups=0.93, wpb=101.8, bsz=40, num_updates=4910, lr=7.81478e-05, gnorm=0.745, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5562
2022-09-28 19:23:22 - progress_bar.py[line:274] - INFO: epoch 001:   4927 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.89, wpb=99.9, bsz=40, num_updates=4920, lr=7.81373e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5573
2022-09-28 19:23:33 - progress_bar.py[line:274] - INFO: epoch 001:   4937 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.4, ups=0.92, wpb=99.8, bsz=40, num_updates=4930, lr=7.81267e-05, gnorm=0.792, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5584
2022-09-28 19:23:44 - progress_bar.py[line:274] - INFO: epoch 001:   4947 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.6, ups=0.89, wpb=100.4, bsz=40, num_updates=4940, lr=7.81161e-05, gnorm=0.877, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5595
2022-09-28 19:23:56 - progress_bar.py[line:274] - INFO: epoch 001:   4957 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.87, wpb=102.7, bsz=40, num_updates=4950, lr=7.81056e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5607
2022-09-28 19:24:07 - progress_bar.py[line:274] - INFO: epoch 001:   4967 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.1, ups=0.89, wpb=101.7, bsz=40, num_updates=4960, lr=7.8095e-05, gnorm=0.755, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5618
2022-09-28 19:24:19 - progress_bar.py[line:274] - INFO: epoch 001:   4977 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.3, ups=0.86, wpb=101.1, bsz=40, num_updates=4970, lr=7.80845e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=5630
2022-09-28 19:24:30 - progress_bar.py[line:274] - INFO: epoch 001:   4987 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.9, wpb=103.4, bsz=40, num_updates=4980, lr=7.80739e-05, gnorm=0.755, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5641
2022-09-28 19:24:41 - progress_bar.py[line:274] - INFO: epoch 001:   4997 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.7, ups=0.87, wpb=101.4, bsz=40, num_updates=4990, lr=7.80633e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5652
2022-09-28 19:24:53 - progress_bar.py[line:274] - INFO: epoch 001:   5007 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=5000, lr=7.80528e-05, gnorm=0.668, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5664
2022-09-28 19:25:04 - progress_bar.py[line:274] - INFO: epoch 001:   5017 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=5010, lr=7.80422e-05, gnorm=0.688, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5675
2022-09-28 19:25:15 - progress_bar.py[line:274] - INFO: epoch 001:   5027 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=5020, lr=7.80317e-05, gnorm=0.75, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5686
2022-09-28 19:25:27 - progress_bar.py[line:274] - INFO: epoch 001:   5037 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89, ups=0.88, wpb=101.2, bsz=40, num_updates=5030, lr=7.80211e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=5698
2022-09-28 19:25:37 - progress_bar.py[line:274] - INFO: epoch 001:   5047 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.2, ups=0.92, wpb=101.5, bsz=40, num_updates=5040, lr=7.80105e-05, gnorm=0.691, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5709
2022-09-28 19:25:48 - progress_bar.py[line:274] - INFO: epoch 001:   5057 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.4, ups=0.92, wpb=100.6, bsz=40, num_updates=5050, lr=7.8e-05, gnorm=0.754, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5719
2022-09-28 19:26:00 - progress_bar.py[line:274] - INFO: epoch 001:   5067 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.2, ups=0.88, wpb=100.2, bsz=40, num_updates=5060, lr=7.79894e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5731
2022-09-28 19:26:11 - progress_bar.py[line:274] - INFO: epoch 001:   5077 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93, ups=0.9, wpb=103, bsz=40, num_updates=5070, lr=7.79789e-05, gnorm=0.798, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5742
2022-09-28 19:26:22 - progress_bar.py[line:274] - INFO: epoch 001:   5087 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.91, wpb=101.3, bsz=40, num_updates=5080, lr=7.79683e-05, gnorm=0.77, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5753
2022-09-28 19:26:33 - progress_bar.py[line:274] - INFO: epoch 001:   5097 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.7, ups=0.9, wpb=101.4, bsz=40, num_updates=5090, lr=7.79577e-05, gnorm=0.743, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5764
2022-09-28 19:26:44 - progress_bar.py[line:274] - INFO: epoch 001:   5107 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.3, ups=0.91, wpb=102.1, bsz=40, num_updates=5100, lr=7.79472e-05, gnorm=0.718, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5775
2022-09-28 19:26:55 - progress_bar.py[line:274] - INFO: epoch 001:   5117 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.5, ups=0.93, wpb=101.1, bsz=40, num_updates=5110, lr=7.79366e-05, gnorm=0.774, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5786
2022-09-28 19:27:06 - progress_bar.py[line:274] - INFO: epoch 001:   5127 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.9, ups=0.92, wpb=101.7, bsz=40, num_updates=5120, lr=7.79261e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5797
2022-09-28 19:27:17 - progress_bar.py[line:274] - INFO: epoch 001:   5137 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=86.8, ups=0.88, wpb=98.9, bsz=40, num_updates=5130, lr=7.79155e-05, gnorm=0.864, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5808
2022-09-28 19:27:28 - progress_bar.py[line:274] - INFO: epoch 001:   5147 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.91, wpb=101.3, bsz=40, num_updates=5140, lr=7.79049e-05, gnorm=0.726, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5819
2022-09-28 19:27:39 - progress_bar.py[line:274] - INFO: epoch 001:   5157 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.89, wpb=101.2, bsz=40, num_updates=5150, lr=7.78944e-05, gnorm=0.685, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5830
2022-09-28 19:27:50 - progress_bar.py[line:274] - INFO: epoch 001:   5167 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.1, ups=0.91, wpb=101.4, bsz=40, num_updates=5160, lr=7.78838e-05, gnorm=0.658, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5841
2022-09-28 19:28:02 - progress_bar.py[line:274] - INFO: epoch 001:   5177 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91, ups=0.89, wpb=102.1, bsz=40, num_updates=5170, lr=7.78733e-05, gnorm=0.795, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5853
2022-09-28 19:28:13 - progress_bar.py[line:274] - INFO: epoch 001:   5187 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=5180, lr=7.78627e-05, gnorm=0.711, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5864
2022-09-28 19:28:25 - progress_bar.py[line:274] - INFO: epoch 001:   5197 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.89, wpb=103.5, bsz=40, num_updates=5190, lr=7.78521e-05, gnorm=0.702, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5876
2022-09-28 19:28:36 - progress_bar.py[line:274] - INFO: epoch 001:   5207 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.88, wpb=101.4, bsz=40, num_updates=5200, lr=7.78416e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5887
2022-09-28 19:28:47 - progress_bar.py[line:274] - INFO: epoch 001:   5217 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.1, ups=0.9, wpb=102.1, bsz=40, num_updates=5210, lr=7.7831e-05, gnorm=0.804, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5898
2022-09-28 19:28:58 - progress_bar.py[line:274] - INFO: epoch 001:   5227 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.8, ups=0.92, wpb=102.7, bsz=40, num_updates=5220, lr=7.78205e-05, gnorm=0.736, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5909
2022-09-28 19:29:10 - progress_bar.py[line:274] - INFO: epoch 001:   5237 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.87, wpb=101.4, bsz=40, num_updates=5230, lr=7.78099e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5921
2022-09-28 19:29:21 - progress_bar.py[line:274] - INFO: epoch 001:   5247 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.1, ups=0.85, wpb=101.1, bsz=40, num_updates=5240, lr=7.77993e-05, gnorm=0.687, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5932
2022-09-28 19:29:33 - progress_bar.py[line:274] - INFO: epoch 001:   5257 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=84.5, ups=0.83, wpb=102.1, bsz=40, num_updates=5250, lr=7.77888e-05, gnorm=0.787, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5944
2022-09-28 19:29:45 - progress_bar.py[line:274] - INFO: epoch 001:   5267 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.89, wpb=100.2, bsz=40, num_updates=5260, lr=7.77782e-05, gnorm=0.828, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5956
2022-09-28 19:29:56 - progress_bar.py[line:274] - INFO: epoch 001:   5277 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=101.3, bsz=40, num_updates=5270, lr=7.77677e-05, gnorm=0.764, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5967
2022-09-28 19:30:07 - progress_bar.py[line:274] - INFO: epoch 001:   5287 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.91, wpb=101.1, bsz=40, num_updates=5280, lr=7.77571e-05, gnorm=0.851, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5978
2022-09-28 19:30:18 - progress_bar.py[line:274] - INFO: epoch 001:   5297 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.9, wpb=103, bsz=40, num_updates=5290, lr=7.77465e-05, gnorm=0.788, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5989
2022-09-28 19:30:29 - progress_bar.py[line:274] - INFO: epoch 001:   5307 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.5, ups=0.89, wpb=101.3, bsz=40, num_updates=5300, lr=7.7736e-05, gnorm=0.841, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6000
2022-09-28 19:30:40 - progress_bar.py[line:274] - INFO: epoch 001:   5317 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.9, wpb=100.7, bsz=40, num_updates=5310, lr=7.77254e-05, gnorm=0.749, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6011
2022-09-28 19:30:52 - progress_bar.py[line:274] - INFO: epoch 001:   5327 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.9, wpb=100.5, bsz=40, num_updates=5320, lr=7.77149e-05, gnorm=0.681, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6023
2022-09-28 19:31:03 - progress_bar.py[line:274] - INFO: epoch 001:   5337 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.9, ups=0.87, wpb=100.6, bsz=40, num_updates=5330, lr=7.77043e-05, gnorm=0.782, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6034
2022-09-28 19:31:14 - progress_bar.py[line:274] - INFO: epoch 001:   5347 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87, ups=0.88, wpb=98.6, bsz=40, num_updates=5340, lr=7.76937e-05, gnorm=0.734, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6045
2022-09-28 19:31:26 - progress_bar.py[line:274] - INFO: epoch 001:   5357 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.88, wpb=101.3, bsz=40, num_updates=5350, lr=7.76832e-05, gnorm=0.71, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6057
2022-09-28 19:31:37 - progress_bar.py[line:274] - INFO: epoch 001:   5367 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.3, ups=0.91, wpb=100.1, bsz=40, num_updates=5360, lr=7.76726e-05, gnorm=0.75, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6068
2022-09-28 19:31:48 - progress_bar.py[line:274] - INFO: epoch 001:   5377 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.9, ups=0.87, wpb=101.2, bsz=40, num_updates=5370, lr=7.76621e-05, gnorm=0.702, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6079
2022-09-28 19:31:59 - progress_bar.py[line:274] - INFO: epoch 001:   5387 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.89, wpb=100, bsz=40, num_updates=5380, lr=7.76515e-05, gnorm=0.874, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6090
2022-09-28 19:32:11 - progress_bar.py[line:274] - INFO: epoch 001:   5397 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.88, wpb=101.1, bsz=40, num_updates=5390, lr=7.76409e-05, gnorm=0.748, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6102
2022-09-28 19:32:22 - progress_bar.py[line:274] - INFO: epoch 001:   5407 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.3, ups=0.9, wpb=100.4, bsz=40, num_updates=5400, lr=7.76304e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6113
2022-09-28 19:32:33 - progress_bar.py[line:274] - INFO: epoch 001:   5417 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.92, wpb=100.2, bsz=40, num_updates=5410, lr=7.76198e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6124
2022-09-28 19:32:44 - progress_bar.py[line:274] - INFO: epoch 001:   5427 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.2, ups=0.88, wpb=100.6, bsz=40, num_updates=5420, lr=7.76093e-05, gnorm=0.719, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6135
2022-09-28 19:32:55 - progress_bar.py[line:274] - INFO: epoch 001:   5437 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.8, ups=0.93, wpb=100.2, bsz=40, num_updates=5430, lr=7.75987e-05, gnorm=1.072, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6146
2022-09-28 19:33:06 - progress_bar.py[line:274] - INFO: epoch 001:   5447 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=100.6, bsz=40, num_updates=5440, lr=7.75881e-05, gnorm=0.735, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6157
2022-09-28 19:33:17 - progress_bar.py[line:274] - INFO: epoch 001:   5457 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.4, ups=0.9, wpb=102.4, bsz=40, num_updates=5450, lr=7.75776e-05, gnorm=0.75, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6168
2022-09-28 19:33:28 - progress_bar.py[line:274] - INFO: epoch 001:   5467 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.1, ups=0.91, wpb=101.1, bsz=40, num_updates=5460, lr=7.7567e-05, gnorm=0.7, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6179
2022-09-28 19:33:40 - progress_bar.py[line:274] - INFO: epoch 001:   5477 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.8, ups=0.87, wpb=100.5, bsz=40, num_updates=5470, lr=7.75565e-05, gnorm=0.805, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6191
2022-09-28 19:33:51 - progress_bar.py[line:274] - INFO: epoch 001:   5487 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.1, ups=0.87, wpb=100.5, bsz=40, num_updates=5480, lr=7.75459e-05, gnorm=0.782, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6202
2022-09-28 19:34:03 - progress_bar.py[line:274] - INFO: epoch 001:   5497 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.5, ups=0.89, wpb=99.8, bsz=40, num_updates=5490, lr=7.75353e-05, gnorm=0.761, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6214
2022-09-28 19:34:14 - progress_bar.py[line:274] - INFO: epoch 001:   5507 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.3, ups=0.91, wpb=102.7, bsz=40, num_updates=5500, lr=7.75248e-05, gnorm=0.824, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6225
2022-09-28 19:34:25 - progress_bar.py[line:274] - INFO: epoch 001:   5517 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.89, wpb=101.6, bsz=40, num_updates=5510, lr=7.75142e-05, gnorm=0.855, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6236
2022-09-28 19:34:36 - progress_bar.py[line:274] - INFO: epoch 001:   5527 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.2, ups=0.88, wpb=101.8, bsz=40, num_updates=5520, lr=7.75037e-05, gnorm=0.75, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6247
2022-09-28 19:34:48 - progress_bar.py[line:274] - INFO: epoch 001:   5537 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.3, ups=0.9, wpb=101, bsz=40, num_updates=5530, lr=7.74931e-05, gnorm=0.816, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6259
2022-09-28 19:34:59 - progress_bar.py[line:274] - INFO: epoch 001:   5547 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.1, ups=0.9, wpb=101.8, bsz=40, num_updates=5540, lr=7.74825e-05, gnorm=0.683, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6270
2022-09-28 19:35:10 - progress_bar.py[line:274] - INFO: epoch 001:   5557 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=102, bsz=40, num_updates=5550, lr=7.7472e-05, gnorm=0.795, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6281
2022-09-28 19:35:21 - progress_bar.py[line:274] - INFO: epoch 001:   5567 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.89, wpb=101.4, bsz=40, num_updates=5560, lr=7.74614e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6292
2022-09-28 19:35:32 - progress_bar.py[line:274] - INFO: epoch 001:   5577 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.6, ups=0.88, wpb=101.9, bsz=40, num_updates=5570, lr=7.74509e-05, gnorm=0.778, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6303
2022-09-28 19:35:44 - progress_bar.py[line:274] - INFO: epoch 001:   5587 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.5, ups=0.9, wpb=100.4, bsz=40, num_updates=5580, lr=7.74403e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6315
2022-09-28 19:35:55 - progress_bar.py[line:274] - INFO: epoch 001:   5597 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.1, ups=0.86, wpb=100.8, bsz=40, num_updates=5590, lr=7.74297e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=6326
2022-09-28 19:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   5607 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.89, wpb=99.2, bsz=40, num_updates=5600, lr=7.74192e-05, gnorm=0.799, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6337
2022-09-28 19:36:18 - progress_bar.py[line:274] - INFO: epoch 001:   5617 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=84.8, ups=0.84, wpb=101.2, bsz=40, num_updates=5610, lr=7.74086e-05, gnorm=0.691, clip=0, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=6349
2022-09-28 19:36:30 - progress_bar.py[line:274] - INFO: epoch 001:   5627 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=84.9, ups=0.84, wpb=100.5, bsz=40, num_updates=5620, lr=7.73981e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6361
2022-09-28 19:36:42 - progress_bar.py[line:274] - INFO: epoch 001:   5637 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.9, ups=0.86, wpb=101, bsz=40, num_updates=5630, lr=7.73875e-05, gnorm=0.727, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=6373
2022-09-28 19:36:53 - progress_bar.py[line:274] - INFO: epoch 001:   5647 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.7, ups=0.9, wpb=100.7, bsz=40, num_updates=5640, lr=7.73769e-05, gnorm=0.723, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6384
2022-09-28 19:37:04 - progress_bar.py[line:274] - INFO: epoch 001:   5657 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.3, ups=0.87, wpb=100.3, bsz=40, num_updates=5650, lr=7.73664e-05, gnorm=0.883, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6395
2022-09-28 19:37:16 - progress_bar.py[line:274] - INFO: epoch 001:   5667 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.89, wpb=102.4, bsz=40, num_updates=5660, lr=7.73558e-05, gnorm=0.775, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6407
2022-09-28 19:37:27 - progress_bar.py[line:274] - INFO: epoch 001:   5677 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.88, wpb=100.9, bsz=40, num_updates=5670, lr=7.73453e-05, gnorm=0.689, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=6418
2022-09-28 19:37:38 - progress_bar.py[line:274] - INFO: epoch 001:   5687 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.91, wpb=101, bsz=40, num_updates=5680, lr=7.73347e-05, gnorm=0.783, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6429
2022-09-28 19:37:49 - progress_bar.py[line:274] - INFO: epoch 001:   5697 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.9, ups=0.93, wpb=103, bsz=40, num_updates=5690, lr=7.73241e-05, gnorm=0.738, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6440
2022-09-28 19:38:00 - progress_bar.py[line:274] - INFO: epoch 001:   5707 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=5700, lr=7.73136e-05, gnorm=0.885, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6451
2022-09-28 19:38:11 - progress_bar.py[line:274] - INFO: epoch 001:   5717 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.89, wpb=101, bsz=40, num_updates=5710, lr=7.7303e-05, gnorm=0.719, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6462
2022-09-28 19:38:22 - progress_bar.py[line:274] - INFO: epoch 001:   5727 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.2, ups=0.92, wpb=102.2, bsz=40, num_updates=5720, lr=7.72925e-05, gnorm=0.748, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6473
2022-09-28 19:38:33 - progress_bar.py[line:274] - INFO: epoch 001:   5737 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.91, wpb=101.1, bsz=40, num_updates=5730, lr=7.72819e-05, gnorm=0.794, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6484
2022-09-28 19:38:45 - progress_bar.py[line:274] - INFO: epoch 001:   5747 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=5740, lr=7.72713e-05, gnorm=0.796, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6496
2022-09-28 19:38:56 - progress_bar.py[line:274] - INFO: epoch 001:   5757 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.89, wpb=101.3, bsz=40, num_updates=5750, lr=7.72608e-05, gnorm=0.745, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6507
2022-09-28 19:39:07 - progress_bar.py[line:274] - INFO: epoch 001:   5767 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.6, ups=0.93, wpb=99.5, bsz=40, num_updates=5760, lr=7.72502e-05, gnorm=0.773, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6518
2022-09-28 19:39:18 - progress_bar.py[line:274] - INFO: epoch 001:   5777 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.1, ups=0.91, wpb=103.3, bsz=40, num_updates=5770, lr=7.72397e-05, gnorm=0.727, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6529
2022-09-28 19:39:29 - progress_bar.py[line:274] - INFO: epoch 001:   5787 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.89, wpb=100.5, bsz=40, num_updates=5780, lr=7.72291e-05, gnorm=0.816, clip=20, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6540
2022-09-28 19:39:32 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-28 19:39:41 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=85.1, ups=0.84, wpb=100.8, bsz=40, num_updates=5790, lr=7.72185e-05, gnorm=0.938, clip=20, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=6552
2022-09-28 19:39:52 - progress_bar.py[line:274] - INFO: epoch 001:   5808 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.8, ups=0.91, wpb=103.6, bsz=40, num_updates=5800, lr=7.7208e-05, gnorm=0.835, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6563
2022-09-28 19:40:03 - progress_bar.py[line:274] - INFO: epoch 001:   5818 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.92, wpb=99, bsz=40, num_updates=5810, lr=7.71974e-05, gnorm=0.73, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6574
2022-09-28 19:40:13 - progress_bar.py[line:274] - INFO: epoch 001:   5828 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93, ups=0.94, wpb=98.9, bsz=40, num_updates=5820, lr=7.71869e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6584
2022-09-28 19:40:24 - progress_bar.py[line:274] - INFO: epoch 001:   5838 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.89, wpb=100.5, bsz=40, num_updates=5830, lr=7.71763e-05, gnorm=0.762, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6596
2022-09-28 19:40:36 - progress_bar.py[line:274] - INFO: epoch 001:   5848 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89, ups=0.89, wpb=100.3, bsz=40, num_updates=5840, lr=7.71657e-05, gnorm=0.763, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6607
2022-09-28 19:40:47 - progress_bar.py[line:274] - INFO: epoch 001:   5858 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.91, wpb=102.2, bsz=40, num_updates=5850, lr=7.71552e-05, gnorm=0.71, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6618
2022-09-28 19:40:59 - progress_bar.py[line:274] - INFO: epoch 001:   5868 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.4, ups=0.88, wpb=99.7, bsz=40, num_updates=5860, lr=7.71446e-05, gnorm=0.814, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6630
2022-09-28 19:41:10 - progress_bar.py[line:274] - INFO: epoch 001:   5878 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.92, wpb=100.1, bsz=40, num_updates=5870, lr=7.71341e-05, gnorm=0.695, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6641
2022-09-28 19:41:21 - progress_bar.py[line:274] - INFO: epoch 001:   5888 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.1, ups=0.89, wpb=102.2, bsz=40, num_updates=5880, lr=7.71235e-05, gnorm=0.733, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6652
2022-09-28 19:41:33 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.1, ups=0.86, wpb=101.3, bsz=40, num_updates=5890, lr=7.7113e-05, gnorm=0.678, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=6664
2022-09-28 19:41:44 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87, ups=0.86, wpb=100.8, bsz=40, num_updates=5900, lr=7.71024e-05, gnorm=0.788, clip=20, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=6675
2022-09-28 19:41:55 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.89, wpb=100.5, bsz=40, num_updates=5910, lr=7.70918e-05, gnorm=0.746, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6686
2022-09-28 19:42:07 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=84.6, ups=0.83, wpb=102.3, bsz=40, num_updates=5920, lr=7.70813e-05, gnorm=0.691, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6699
2022-09-28 19:42:19 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.5, ups=0.85, wpb=101.4, bsz=40, num_updates=5930, lr=7.70707e-05, gnorm=0.72, clip=10, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=6710
2022-09-28 19:42:31 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.5, ups=0.86, wpb=102.3, bsz=40, num_updates=5940, lr=7.70602e-05, gnorm=0.777, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=6722
2022-09-28 19:42:42 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.9, wpb=101.7, bsz=40, num_updates=5950, lr=7.70496e-05, gnorm=0.842, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6733
2022-09-28 19:42:53 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=5960, lr=7.7039e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6744
2022-09-28 19:43:05 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.2, ups=0.86, wpb=102.1, bsz=40, num_updates=5970, lr=7.70285e-05, gnorm=0.682, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6756
2022-09-28 19:43:16 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.1, ups=0.89, wpb=102.6, bsz=40, num_updates=5980, lr=7.70179e-05, gnorm=0.796, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6767
2022-09-28 19:43:27 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.1, ups=0.89, wpb=101.8, bsz=40, num_updates=5990, lr=7.70074e-05, gnorm=0.757, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6779
2022-09-28 19:43:39 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.89, wpb=103.2, bsz=40, num_updates=6000, lr=7.69968e-05, gnorm=0.766, clip=10, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6790
2022-09-28 19:43:39 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-28 19:43:39 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-28 19:43:40 - train.py[line:549] - INFO: 0 / 9402
2022-09-28 19:43:40 - train.py[line:551] - INFO: load:1.02 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-28 19:43:43 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 12.37 GiB (GPU 1; 39.59 GiB total capacity; 13.53 GiB already allocated; 11.38 GiB free; 25.73 GiB reserved in total by PyTorch)
2022-09-28 19:43:43 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-28 19:43:43 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 10        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13857 MB |   16526 MB |    1029 TB |    1029 TB |
|       from large pool |   13711 MB |   16379 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13857 MB |   16526 MB |    1029 TB |    1029 TB |
|       from large pool |   13711 MB |   16379 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26344 MB |   37714 MB |  141742 MB |  115398 MB |
|       from large pool |   26198 MB |   37566 MB |  141386 MB |  115188 MB |
|       from small pool |     146 MB |     148 MB |     356 MB |     210 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   12486 MB |   13165 MB |  754892 GB |  754879 GB |
|       from large pool |   12486 MB |   13163 MB |  754122 GB |  754110 GB |
|       from small pool |       0 MB |       2 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    3641    |    3655    |   31921 K  |   31917 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15692 K  |   15689 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3641    |    3655    |   31921 K  |   31917 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15692 K  |   15689 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     206    |     292    |     597    |     391    |
|       from large pool |     133    |     218    |     419    |     286    |
|       from small pool |      73    |      74    |     178    |     105    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     139    |     145    |   17557 K  |   17557 K  |
|       from large pool |      97    |     101    |    9760 K  |    9759 K  |
|       from small pool |      42    |      50    |    7797 K  |    7797 K  |
|===========================================================================|

2022-09-28 19:43:43 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-28 19:43:43 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 14.98 GiB already allocated; 11.19 GiB free; 25.92 GiB reserved in total by PyTorch)
2022-09-28 19:43:43 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15339 MB |   18306 MB |    1029 TB |    1029 TB |
|       from large pool |   15193 MB |   18159 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   15339 MB |   18306 MB |    1029 TB |    1029 TB |
|       from large pool |   15193 MB |   18159 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26542 MB |   37668 MB |  154242 MB |  127700 MB |
|       from large pool |   26394 MB |   37520 MB |  153860 MB |  127466 MB |
|       from small pool |     148 MB |     148 MB |     382 MB |     234 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   11202 MB |   11982 MB |  736743 GB |  736732 GB |
|       from large pool |   11200 MB |   11980 MB |  735973 GB |  735962 GB |
|       from small pool |       2 MB |       2 MB |     770 GB |     770 GB |
|---------------------------------------------------------------------------|
| Allocations           |    3641    |    3655    |   31921 K  |   31917 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15692 K  |   15689 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3641    |    3655    |   31921 K  |   31917 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15692 K  |   15689 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     204    |     292    |     617    |     413    |
|       from large pool |     130    |     218    |     426    |     296    |
|       from small pool |      74    |      74    |     191    |     117    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     142    |     147    |   17250 K  |   17249 K  |
|       from large pool |     103    |     107    |    9440 K  |    9440 K  |
|       from small pool |      39    |      49    |    7809 K  |    7809 K  |
|===========================================================================|

2022-09-28 19:43:43 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-28 19:43:43 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-28 19:43:45 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 25.12 GiB already allocated; 10.81 GiB free; 26.30 GiB reserved in total by PyTorch)
2022-09-28 19:43:45 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 12        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   25719 MB |   28687 MB |    1029 TB |    1029 TB |
|       from large pool |   25600 MB |   28566 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   25719 MB |   28687 MB |    1029 TB |    1029 TB |
|       from large pool |   25600 MB |   28566 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26934 MB |   37748 MB |  175852 MB |  148918 MB |
|       from large pool |   26810 MB |   37624 MB |  175470 MB |  148660 MB |
|       from small pool |     124 MB |     148 MB |     382 MB |     258 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1214 MB |   11982 MB |  736816 GB |  736815 GB |
|       from large pool |    1209 MB |   11980 MB |  736046 GB |  736045 GB |
|       from small pool |       4 MB |       6 MB |     770 GB |     770 GB |
|---------------------------------------------------------------------------|
| Allocations           |    2997    |    3655    |   31927 K  |   31924 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15696 K  |   15694 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    2997    |    3655    |   31927 K  |   31924 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15696 K  |   15694 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     116    |     292    |     631    |     515    |
|       from large pool |      54    |     218    |     440    |     386    |
|       from small pool |      62    |      74    |     191    |     129    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     124    |     183    |   17254 K  |   17254 K  |
|       from large pool |      57    |     107    |    9441 K  |    9441 K  |
|       from small pool |      67    |     105    |    7813 K  |    7813 K  |
|===========================================================================|

2022-09-28 19:43:45 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

Traceback (most recent call last):
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 14.98 GiB already allocated; 11.19 GiB free; 25.92 GiB reserved in total by PyTorch)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 630, in <module>
    cli_main()
  File "../../train.py", line 623, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "../../train.py", line 332, in train
    cfg, trainer, task, epoch_itr, valid_subsets, end_of_epoch
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, (pred_scores, pred, sample_ids), time_info = trainer.valid_step(sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1088, in valid_step
    return self.valid_step(sample, raise_oom=True)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1089, in valid_step
    raise e
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 25.12 GiB already allocated; 10.81 GiB free; 26.30 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/50_way_allcand', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=15', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=8e-5', '--max-epoch=5', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=6000', '--validate-interval-updates=6000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 1448200
Killing subprocess 1448201
2022-09-30 08:30:53 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-09-30 08:30:53 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-09-30 08:30:53 - utils.py[line:261] - INFO: Start init
2022-09-30 08:30:53 - utils.py[line:261] - INFO: Start init
2022-09-30 08:30:54 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-09-30 08:30:54 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-09-30 08:30:54 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-09-30 08:30:54 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-09-30 08:30:58 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/50_way_allcand', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 6000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [8e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 6000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='10', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[8e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480', save_interval=10, save_interval_updates=6000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/50_way_allcand', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=26, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=6000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 26, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [8e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [8e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-09-30 08:30:58 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-09-30 08:30:58 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-09-30 08:31:02 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-09-30 08:31:02 - train.py[line:118] - INFO: task: VqaGenTask
2022-09-30 08:31:02 - train.py[line:119] - INFO: model: OFAModel
2022-09-30 08:31:02 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-09-30 08:31:02 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-09-30 08:31:02 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv slice_id 1 row count 141030 total row count 282060
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv slice_id 0 row count 141030 total row count 282060
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-30 08:31:03 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-09-30 08:31:03 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-09-30 08:31:03 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-30 08:31:03 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-30 08:31:03 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-30 08:31:03 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-30 08:31:03 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-09-30 08:31:03 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-09-30 08:31:03 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-09-30 08:31:12 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-30 08:31:12 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-30 08:31:12 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-09-30 08:31:12 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-09-30 08:31:13 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-09-30 08:31:13 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 1 row count 315642 total row count 631284
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 0 row count 315642 total row count 631284
2022-09-30 08:31:14 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-30 08:31:14 - trainer.py[line:707] - INFO: begin training epoch 1
2022-09-30 08:31:14 - train.py[line:312] - INFO: Start iterating over samples
2022-09-30 08:31:30 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 15783 loss=1.322, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=87.4, ups=0.85, wpb=102.4, bsz=40, num_updates=10, lr=2.53485e-07, gnorm=14.894, clip=100, loss_scale=128, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=27
2022-09-30 08:31:42 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 15783 loss=1.337, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=86, ups=0.85, wpb=100.6, bsz=40, num_updates=20, lr=5.06971e-07, gnorm=13.322, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=39
2022-09-30 08:31:53 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 15783 loss=1.383, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=87.9, ups=0.87, wpb=100.6, bsz=40, num_updates=30, lr=7.60456e-07, gnorm=14.785, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50
2022-09-30 08:32:05 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 15783 loss=1.247, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=88, ups=0.86, wpb=102.1, bsz=40, num_updates=40, lr=1.01394e-06, gnorm=10.063, clip=100, loss_scale=128, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=62
2022-09-30 08:32:16 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 15783 loss=1.166, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=88.7, ups=0.87, wpb=102.4, bsz=40, num_updates=50, lr=1.26743e-06, gnorm=9.167, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73
2022-09-30 08:32:28 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 15783 loss=1.149, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=87.2, ups=0.87, wpb=100.4, bsz=40, num_updates=60, lr=1.52091e-06, gnorm=7.539, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85
2022-09-30 08:32:39 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 15783 loss=1.06, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=91.1, ups=0.89, wpb=102.7, bsz=40, num_updates=70, lr=1.7744e-06, gnorm=6.295, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=96
2022-09-30 08:32:51 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 15783 loss=1.029, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=90.3, ups=0.88, wpb=103.2, bsz=40, num_updates=80, lr=2.02788e-06, gnorm=5.764, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107
2022-09-30 08:33:02 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 15783 loss=1.052, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=87.8, ups=0.87, wpb=101.2, bsz=40, num_updates=90, lr=2.28137e-06, gnorm=5.083, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=119
2022-09-30 08:33:14 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 15783 loss=1.019, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=88.6, ups=0.88, wpb=101, bsz=40, num_updates=100, lr=2.53485e-06, gnorm=4.439, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=130
2022-09-30 08:33:25 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 15783 loss=1.007, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=89.2, ups=0.88, wpb=101.4, bsz=40, num_updates=110, lr=2.78834e-06, gnorm=4.443, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=142
2022-09-30 08:33:36 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 15783 loss=1.002, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=88.2, ups=0.88, wpb=100.3, bsz=40, num_updates=120, lr=3.04183e-06, gnorm=4.346, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=153
2022-09-30 08:33:48 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 15783 loss=0.995, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=89.6, ups=0.89, wpb=100.4, bsz=40, num_updates=130, lr=3.29531e-06, gnorm=4.016, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=164
2022-09-30 08:33:59 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 15783 loss=0.919, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=90.4, ups=0.89, wpb=101.8, bsz=40, num_updates=140, lr=3.5488e-06, gnorm=3.612, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=176
2022-09-30 08:34:10 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 15783 loss=0.935, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=90.9, ups=0.89, wpb=102.2, bsz=40, num_updates=150, lr=3.80228e-06, gnorm=3.49, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=187
2022-09-30 08:34:21 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 15783 loss=0.899, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=94.5, ups=0.92, wpb=102.5, bsz=40, num_updates=160, lr=4.05577e-06, gnorm=3.623, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=198
2022-09-30 08:34:32 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 15783 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=87.5, ups=0.87, wpb=100.6, bsz=40, num_updates=170, lr=4.30925e-06, gnorm=3.229, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=209
2022-09-30 08:34:44 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 15783 loss=0.882, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=90.3, ups=0.88, wpb=102.9, bsz=40, num_updates=180, lr=4.56274e-06, gnorm=3.141, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=221
2022-09-30 08:34:55 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 15783 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=87.6, ups=0.88, wpb=99.5, bsz=40, num_updates=190, lr=4.81622e-06, gnorm=3.175, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=232
2022-09-30 08:35:07 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 15783 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=90.4, ups=0.88, wpb=102.6, bsz=40, num_updates=200, lr=5.06971e-06, gnorm=3.236, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=243
2022-09-30 08:35:18 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 15783 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=90.4, ups=0.89, wpb=101.3, bsz=40, num_updates=210, lr=5.32319e-06, gnorm=2.832, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=255
2022-09-30 08:35:29 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 15783 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=91.4, ups=0.89, wpb=102.9, bsz=40, num_updates=220, lr=5.57668e-06, gnorm=2.779, clip=100, loss_scale=128, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=266
2022-09-30 08:35:41 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 15783 loss=0.861, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=89.3, ups=0.87, wpb=103, bsz=40, num_updates=230, lr=5.83016e-06, gnorm=2.762, clip=100, loss_scale=128, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=277
2022-09-30 08:35:52 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 15783 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=90.8, ups=0.9, wpb=101.3, bsz=40, num_updates=240, lr=6.08365e-06, gnorm=2.715, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=289
2022-09-30 08:36:03 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 15783 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=92.5, ups=0.91, wpb=101.2, bsz=40, num_updates=250, lr=6.33714e-06, gnorm=2.735, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=299
2022-09-30 08:36:13 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 15783 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.727, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=95.8, ups=0.94, wpb=102.3, bsz=40, num_updates=260, lr=6.59062e-06, gnorm=2.721, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=310
2022-09-30 08:36:25 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 15783 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=88.9, ups=0.89, wpb=99.9, bsz=40, num_updates=270, lr=6.84411e-06, gnorm=2.932, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=321
2022-09-30 08:36:36 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 15783 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=90.3, ups=0.89, wpb=101, bsz=40, num_updates=280, lr=7.09759e-06, gnorm=2.87, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=333
2022-09-30 08:36:47 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 15783 loss=0.917, loss_v1=0, loss_v2=0, nll_loss=0.754, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=91, ups=0.9, wpb=100.7, bsz=40, num_updates=290, lr=7.35108e-06, gnorm=2.76, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=344
2022-09-30 08:36:58 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 15783 loss=0.968, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=98.1, nsentences=40, sample_size=98.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=88.4, ups=0.9, wpb=98.1, bsz=40, num_updates=300, lr=7.60456e-06, gnorm=2.973, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=355
2022-09-30 08:37:09 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 15783 loss=0.853, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=94, ups=0.92, wpb=102.1, bsz=40, num_updates=310, lr=7.85805e-06, gnorm=2.788, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=366
2022-09-30 08:37:21 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 15783 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=89, ups=0.88, wpb=100.7, bsz=40, num_updates=320, lr=8.11153e-06, gnorm=2.859, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=377
2022-09-30 08:37:31 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 15783 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=95.4, ups=0.93, wpb=102.3, bsz=40, num_updates=330, lr=8.36502e-06, gnorm=3.086, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=388
2022-09-30 08:37:42 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 15783 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=91.3, ups=0.9, wpb=101, bsz=40, num_updates=340, lr=8.6185e-06, gnorm=2.848, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=399
2022-09-30 08:37:53 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 15783 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=94.4, ups=0.92, wpb=102.9, bsz=40, num_updates=350, lr=8.87199e-06, gnorm=2.853, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=410
2022-09-30 08:38:05 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 15783 loss=0.838, loss_v1=0, loss_v2=0, nll_loss=0.66, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.4, ups=0.88, wpb=102.5, bsz=40, num_updates=360, lr=9.12548e-06, gnorm=2.873, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=421
2022-09-30 08:38:16 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 15783 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=91.5, ups=0.9, wpb=101.3, bsz=40, num_updates=370, lr=9.37896e-06, gnorm=2.586, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=433
2022-09-30 08:38:27 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 15783 loss=0.835, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=87.6, ups=0.87, wpb=101, bsz=40, num_updates=380, lr=9.63245e-06, gnorm=2.849, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=444
2022-09-30 08:38:39 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 15783 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=90.8, ups=0.89, wpb=102.5, bsz=40, num_updates=390, lr=9.88593e-06, gnorm=2.681, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=455
2022-09-30 08:38:49 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 15783 loss=0.818, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=93.4, ups=0.93, wpb=100.6, bsz=40, num_updates=400, lr=1.01394e-05, gnorm=3.01, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=466
2022-09-30 08:39:00 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 15783 loss=0.773, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=94.5, ups=0.93, wpb=101.2, bsz=40, num_updates=410, lr=1.03929e-05, gnorm=2.843, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=477
2022-09-30 08:39:11 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 15783 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.3, ups=0.9, wpb=99.7, bsz=40, num_updates=420, lr=1.06464e-05, gnorm=2.97, clip=100, loss_scale=128, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=488
2022-09-30 08:39:22 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 15783 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=91.3, ups=0.91, wpb=100.6, bsz=40, num_updates=430, lr=1.08999e-05, gnorm=2.842, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=499
2022-09-30 08:39:34 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 15783 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=87.6, ups=0.87, wpb=100.2, bsz=40, num_updates=440, lr=1.11534e-05, gnorm=2.68, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=510
2022-09-30 08:39:45 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 15783 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.619, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=87.9, ups=0.88, wpb=99.7, bsz=40, num_updates=450, lr=1.14068e-05, gnorm=2.769, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=522
2022-09-30 08:39:56 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 15783 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=88.8, ups=0.88, wpb=100.8, bsz=40, num_updates=460, lr=1.16603e-05, gnorm=2.753, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=533
2022-09-30 08:40:07 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 15783 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.5, ups=0.91, wpb=102, bsz=40, num_updates=470, lr=1.19138e-05, gnorm=2.736, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=544
2022-09-30 08:40:19 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 15783 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.3, ups=0.88, wpb=102.5, bsz=40, num_updates=480, lr=1.21673e-05, gnorm=2.59, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=556
2022-09-30 08:40:30 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 15783 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.8, ups=0.91, wpb=101.2, bsz=40, num_updates=490, lr=1.24208e-05, gnorm=2.565, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=567
2022-09-30 08:40:41 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 15783 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.5, ups=0.92, wpb=101.5, bsz=40, num_updates=500, lr=1.26743e-05, gnorm=2.602, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=577
2022-09-30 08:40:52 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 15783 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.2, ups=0.87, wpb=100.6, bsz=40, num_updates=510, lr=1.29278e-05, gnorm=2.94, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=589
2022-09-30 08:41:04 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 15783 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=89.5, ups=0.88, wpb=101.5, bsz=40, num_updates=520, lr=1.31812e-05, gnorm=2.786, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=600
2022-09-30 08:41:14 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 15783 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=94, ups=0.94, wpb=100.1, bsz=40, num_updates=530, lr=1.34347e-05, gnorm=2.504, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=611
2022-09-30 08:41:26 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 15783 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=540, lr=1.36882e-05, gnorm=2.449, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=622
2022-09-30 08:41:36 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 15783 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.1, ups=0.94, wpb=101.9, bsz=40, num_updates=550, lr=1.39417e-05, gnorm=2.205, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=633
2022-09-30 08:41:48 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 15783 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=560, lr=1.41952e-05, gnorm=2.445, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=644
2022-09-30 08:41:59 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 15783 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.2, ups=0.88, wpb=102.2, bsz=40, num_updates=570, lr=1.44487e-05, gnorm=2.293, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=656
2022-09-30 08:42:10 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.5, ups=0.9, wpb=102.5, bsz=40, num_updates=580, lr=1.47022e-05, gnorm=2.17, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=667
2022-09-30 08:42:21 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.6, ups=0.9, wpb=103.4, bsz=40, num_updates=590, lr=1.49556e-05, gnorm=2.046, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=678
2022-09-30 08:42:32 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 15783 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.2, ups=0.89, wpb=102.8, bsz=40, num_updates=600, lr=1.52091e-05, gnorm=2.752, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=689
2022-09-30 08:42:44 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 15783 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.2, ups=0.89, wpb=103.4, bsz=40, num_updates=610, lr=1.54626e-05, gnorm=2.436, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=700
2022-09-30 08:42:55 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.7, ups=0.88, wpb=102, bsz=40, num_updates=620, lr=1.57161e-05, gnorm=1.914, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=712
2022-09-30 08:43:06 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 15783 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.8, ups=0.88, wpb=103.1, bsz=40, num_updates=630, lr=1.59696e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=723
2022-09-30 08:43:18 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.8, ups=0.88, wpb=103.4, bsz=40, num_updates=640, lr=1.62231e-05, gnorm=2, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=734
2022-09-30 08:43:29 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 15783 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=650, lr=1.64766e-05, gnorm=2.042, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=746
2022-09-30 08:43:40 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 15783 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=93.4, ups=0.93, wpb=100.7, bsz=40, num_updates=660, lr=1.673e-05, gnorm=2.046, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=756
2022-09-30 08:43:51 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 15783 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.4, ups=0.88, wpb=100.2, bsz=40, num_updates=670, lr=1.69835e-05, gnorm=2.082, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=768
2022-09-30 08:44:02 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.6, ups=0.88, wpb=101.5, bsz=40, num_updates=680, lr=1.7237e-05, gnorm=2.25, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=779
2022-09-30 08:44:14 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.9, ups=0.9, wpb=101.8, bsz=40, num_updates=690, lr=1.74905e-05, gnorm=2.123, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=790
2022-09-30 08:44:24 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 15783 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.7, ups=0.92, wpb=99.9, bsz=40, num_updates=700, lr=1.7744e-05, gnorm=2.213, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=801
2022-09-30 08:44:36 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.1, ups=0.88, wpb=102.3, bsz=40, num_updates=710, lr=1.79975e-05, gnorm=2.059, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=813
2022-09-30 08:44:47 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.2, ups=0.93, wpb=102.5, bsz=40, num_updates=720, lr=1.8251e-05, gnorm=1.927, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=823
2022-09-30 08:44:58 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 15783 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=92.3, ups=0.91, wpb=101.3, bsz=40, num_updates=730, lr=1.85044e-05, gnorm=2.023, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=834
2022-09-30 08:45:09 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.3, ups=0.89, wpb=101.5, bsz=40, num_updates=740, lr=1.87579e-05, gnorm=2.04, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=846
2022-09-30 08:45:20 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.8, ups=0.91, wpb=101.2, bsz=40, num_updates=750, lr=1.90114e-05, gnorm=1.967, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=857
2022-09-30 08:45:31 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.2, ups=0.88, wpb=100.3, bsz=40, num_updates=760, lr=1.92649e-05, gnorm=1.956, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=868
2022-09-30 08:45:43 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.9, ups=0.87, wpb=102.3, bsz=40, num_updates=770, lr=1.95184e-05, gnorm=1.883, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=879
2022-09-30 08:45:54 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.2, ups=0.89, wpb=102, bsz=40, num_updates=780, lr=1.97719e-05, gnorm=1.844, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=891
2022-09-30 08:46:05 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 15783 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93.9, ups=0.94, wpb=100.1, bsz=40, num_updates=790, lr=2.00253e-05, gnorm=2.227, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=901
2022-09-30 08:46:15 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 15783 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.9, ups=0.93, wpb=98.8, bsz=40, num_updates=800, lr=2.02788e-05, gnorm=2.011, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=912
2022-09-30 08:46:27 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90, ups=0.89, wpb=101.6, bsz=40, num_updates=810, lr=2.05323e-05, gnorm=1.918, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=923
2022-09-30 08:46:38 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 15783 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.7, ups=0.9, wpb=101.2, bsz=40, num_updates=820, lr=2.07858e-05, gnorm=1.973, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=935
2022-09-30 08:46:49 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.6, ups=0.9, wpb=101.5, bsz=40, num_updates=830, lr=2.10393e-05, gnorm=1.755, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=946
2022-09-30 08:47:00 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 15783 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.2, ups=0.89, wpb=101, bsz=40, num_updates=840, lr=2.12928e-05, gnorm=1.898, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=957
2022-09-30 08:47:11 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.6, ups=0.91, wpb=101.2, bsz=40, num_updates=850, lr=2.15463e-05, gnorm=1.654, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=968
2022-09-30 08:47:22 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 15783 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=92.1, ups=0.9, wpb=102, bsz=40, num_updates=860, lr=2.17997e-05, gnorm=1.908, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=979
2022-09-30 08:47:34 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 15783 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.2, ups=0.89, wpb=101, bsz=40, num_updates=870, lr=2.20532e-05, gnorm=1.871, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=990
2022-09-30 08:47:44 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 15783 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=93, ups=0.92, wpb=101.6, bsz=40, num_updates=880, lr=2.23067e-05, gnorm=2.053, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1001
2022-09-30 08:47:56 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.9, ups=0.91, wpb=101.8, bsz=40, num_updates=890, lr=2.25602e-05, gnorm=1.677, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1012
2022-09-30 08:48:07 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.2, ups=0.92, wpb=103.1, bsz=40, num_updates=900, lr=2.28137e-05, gnorm=1.843, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1023
2022-09-30 08:48:17 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.2, ups=0.93, wpb=102.3, bsz=40, num_updates=910, lr=2.30672e-05, gnorm=1.972, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1034
2022-09-30 08:48:28 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.5, ups=0.92, wpb=101, bsz=40, num_updates=920, lr=2.33207e-05, gnorm=1.792, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1045
2022-09-30 08:48:40 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.8, ups=0.87, wpb=100.4, bsz=40, num_updates=930, lr=2.35741e-05, gnorm=1.671, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1056
2022-09-30 08:48:51 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 15783 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=86.9, ups=0.86, wpb=100.6, bsz=40, num_updates=940, lr=2.38276e-05, gnorm=1.93, clip=100, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1068
2022-09-30 08:49:03 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 15783 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.2, ups=0.89, wpb=99.3, bsz=40, num_updates=950, lr=2.40811e-05, gnorm=1.807, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1079
2022-09-30 08:49:14 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 15783 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.9, ups=0.89, wpb=100.3, bsz=40, num_updates=960, lr=2.43346e-05, gnorm=1.926, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1091
2022-09-30 08:49:25 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.4, ups=0.92, wpb=99.7, bsz=40, num_updates=970, lr=2.45881e-05, gnorm=1.819, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1102
2022-09-30 08:49:36 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.3, ups=0.88, wpb=103.3, bsz=40, num_updates=980, lr=2.48416e-05, gnorm=1.839, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1113
2022-09-30 08:49:47 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.91, wpb=99.8, bsz=40, num_updates=990, lr=2.50951e-05, gnorm=1.859, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1124
2022-09-30 08:49:59 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.9, ups=0.91, wpb=103.7, bsz=40, num_updates=1000, lr=2.53485e-05, gnorm=1.792, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1135
2022-09-30 08:50:10 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.88, wpb=102.5, bsz=40, num_updates=1010, lr=2.5602e-05, gnorm=2.07, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1147
2022-09-30 08:50:21 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.7, ups=0.88, wpb=103.2, bsz=40, num_updates=1020, lr=2.58555e-05, gnorm=1.932, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1158
2022-09-30 08:50:33 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=1030, lr=2.6109e-05, gnorm=1.658, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1169
2022-09-30 08:50:45 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.8, ups=0.87, wpb=101.2, bsz=40, num_updates=1040, lr=2.63625e-05, gnorm=1.616, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1181
2022-09-30 08:50:56 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.4, ups=0.91, wpb=103.4, bsz=40, num_updates=1050, lr=2.6616e-05, gnorm=1.83, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1192
2022-09-30 08:51:07 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.2, ups=0.92, wpb=100.2, bsz=40, num_updates=1060, lr=2.68695e-05, gnorm=1.954, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1203
2022-09-30 08:51:18 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88, ups=0.89, wpb=98.9, bsz=40, num_updates=1070, lr=2.71229e-05, gnorm=1.727, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1214
2022-09-30 08:51:29 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.6, ups=0.89, wpb=102.7, bsz=40, num_updates=1080, lr=2.73764e-05, gnorm=1.995, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1226
2022-09-30 08:51:40 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.6, ups=0.9, wpb=101.3, bsz=40, num_updates=1090, lr=2.76299e-05, gnorm=1.676, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1237
2022-09-30 08:51:51 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.89, wpb=102.2, bsz=40, num_updates=1100, lr=2.78834e-05, gnorm=1.654, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1248
2022-09-30 08:52:03 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.2, ups=0.89, wpb=101, bsz=40, num_updates=1110, lr=2.81369e-05, gnorm=1.817, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1259
2022-09-30 08:52:14 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.5, ups=0.88, wpb=100.6, bsz=40, num_updates=1120, lr=2.83904e-05, gnorm=1.9, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1271
2022-09-30 08:52:25 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.9, ups=0.9, wpb=99.3, bsz=40, num_updates=1130, lr=2.86439e-05, gnorm=1.81, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1282
2022-09-30 08:52:36 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.3, ups=0.91, wpb=101.8, bsz=40, num_updates=1140, lr=2.88973e-05, gnorm=1.827, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1293
2022-09-30 08:52:48 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.88, wpb=102.3, bsz=40, num_updates=1150, lr=2.91508e-05, gnorm=1.711, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1304
2022-09-30 08:52:59 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.2, ups=0.9, wpb=100.8, bsz=40, num_updates=1160, lr=2.94043e-05, gnorm=1.912, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1316
2022-09-30 08:53:10 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=1170, lr=2.96578e-05, gnorm=1.919, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1327
2022-09-30 08:53:21 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.2, ups=0.88, wpb=102, bsz=40, num_updates=1180, lr=2.99113e-05, gnorm=1.765, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1338
2022-09-30 08:53:33 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.1, ups=0.87, wpb=101.5, bsz=40, num_updates=1190, lr=3.01648e-05, gnorm=1.799, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1350
2022-09-30 08:53:44 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.8, ups=0.87, wpb=101, bsz=40, num_updates=1200, lr=3.04183e-05, gnorm=1.577, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1361
2022-09-30 08:53:56 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 15783 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.4, ups=0.91, wpb=99.6, bsz=40, num_updates=1210, lr=3.06717e-05, gnorm=1.751, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1372
2022-09-30 08:54:07 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.89, wpb=102, bsz=40, num_updates=1220, lr=3.09252e-05, gnorm=1.65, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1383
2022-09-30 08:54:18 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.9, ups=0.88, wpb=101.2, bsz=40, num_updates=1230, lr=3.11787e-05, gnorm=1.675, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1395
2022-09-30 08:54:30 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.5, ups=0.88, wpb=100, bsz=40, num_updates=1240, lr=3.14322e-05, gnorm=1.574, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1406
2022-09-30 08:54:41 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.88, wpb=102.3, bsz=40, num_updates=1250, lr=3.16857e-05, gnorm=1.775, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1418
2022-09-30 08:54:52 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.5, ups=0.88, wpb=102.1, bsz=40, num_updates=1260, lr=3.19392e-05, gnorm=1.43, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1429
2022-09-30 08:55:03 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.5, ups=0.93, wpb=102, bsz=40, num_updates=1270, lr=3.21926e-05, gnorm=1.609, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1440
2022-09-30 08:55:15 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.88, wpb=102.1, bsz=40, num_updates=1280, lr=3.24461e-05, gnorm=1.574, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1451
2022-09-30 08:55:26 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.3, ups=0.91, wpb=100.7, bsz=40, num_updates=1290, lr=3.26996e-05, gnorm=1.541, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1462
2022-09-30 08:55:37 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.8, ups=0.9, wpb=101.4, bsz=40, num_updates=1300, lr=3.29531e-05, gnorm=1.512, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1474
2022-09-30 08:55:48 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.2, ups=0.92, wpb=101.2, bsz=40, num_updates=1310, lr=3.32066e-05, gnorm=1.622, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1484
2022-09-30 08:55:59 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.92, wpb=101.3, bsz=40, num_updates=1320, lr=3.34601e-05, gnorm=1.574, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1495
2022-09-30 08:56:09 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.2, ups=0.93, wpb=100.2, bsz=40, num_updates=1330, lr=3.37136e-05, gnorm=1.688, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1506
2022-09-30 08:56:21 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.9, wpb=101.3, bsz=40, num_updates=1340, lr=3.3967e-05, gnorm=1.549, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1517
2022-09-30 08:56:32 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90, ups=0.89, wpb=101.2, bsz=40, num_updates=1350, lr=3.42205e-05, gnorm=1.527, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1529
2022-09-30 08:56:43 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.1, ups=0.9, wpb=101, bsz=40, num_updates=1360, lr=3.4474e-05, gnorm=1.687, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1540
2022-09-30 08:56:54 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.9, ups=0.93, wpb=100.5, bsz=40, num_updates=1370, lr=3.47275e-05, gnorm=1.628, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1550
2022-09-30 08:57:05 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=1380, lr=3.4981e-05, gnorm=1.505, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1562
2022-09-30 08:57:16 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 15783 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.5, ups=0.9, wpb=101.2, bsz=40, num_updates=1390, lr=3.52345e-05, gnorm=1.606, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1573
2022-09-30 08:57:28 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.2, ups=0.87, wpb=102.6, bsz=40, num_updates=1400, lr=3.5488e-05, gnorm=1.422, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1584
2022-09-30 08:57:39 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.7, ups=0.91, wpb=103.5, bsz=40, num_updates=1410, lr=3.57414e-05, gnorm=1.426, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1595
2022-09-30 08:57:50 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.2, ups=0.87, wpb=100.8, bsz=40, num_updates=1420, lr=3.59949e-05, gnorm=1.376, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1607
2022-09-30 08:58:01 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92, ups=0.89, wpb=103.7, bsz=40, num_updates=1430, lr=3.62484e-05, gnorm=1.571, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1618
2022-09-30 08:58:13 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.9, wpb=101, bsz=40, num_updates=1440, lr=3.65019e-05, gnorm=1.568, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1629
2022-09-30 08:58:25 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.9, ups=0.88, wpb=100.9, bsz=40, num_updates=1450, lr=3.67554e-05, gnorm=1.595, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1641
2022-09-30 08:58:36 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.9, ups=0.9, wpb=101, bsz=40, num_updates=1460, lr=3.70089e-05, gnorm=1.788, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1652
2022-09-30 08:58:47 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.1, ups=0.92, wpb=102.2, bsz=40, num_updates=1470, lr=3.72624e-05, gnorm=1.489, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1663
2022-09-30 08:58:58 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.9, ups=0.91, wpb=101.6, bsz=40, num_updates=1480, lr=3.75158e-05, gnorm=1.543, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1674
2022-09-30 08:59:08 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.7, ups=0.92, wpb=101.8, bsz=40, num_updates=1490, lr=3.77693e-05, gnorm=1.332, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1685
2022-09-30 08:59:20 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.88, wpb=102.5, bsz=40, num_updates=1500, lr=3.80228e-05, gnorm=1.356, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1697
2022-09-30 08:59:31 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.8, ups=0.91, wpb=100.5, bsz=40, num_updates=1510, lr=3.82763e-05, gnorm=1.74, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1708
2022-09-30 08:59:42 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.7, ups=0.87, wpb=101.5, bsz=40, num_updates=1520, lr=3.85298e-05, gnorm=1.326, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1719
2022-09-30 08:59:54 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.6, ups=0.88, wpb=100, bsz=40, num_updates=1530, lr=3.87833e-05, gnorm=1.268, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1730
2022-09-30 09:00:02 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 09:00:06 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=85.7, ups=0.85, wpb=101.3, bsz=40, num_updates=1540, lr=3.90368e-05, gnorm=1.326, clip=100, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=1742
2022-09-30 09:00:17 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.92, wpb=99.5, bsz=40, num_updates=1550, lr=3.92902e-05, gnorm=1.403, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1753
2022-09-30 09:00:28 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.87, wpb=102.6, bsz=40, num_updates=1560, lr=3.95437e-05, gnorm=1.223, clip=80, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1765
2022-09-30 09:00:39 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=1570, lr=3.97972e-05, gnorm=1.341, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1776
2022-09-30 09:00:51 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.7, ups=0.9, wpb=99.7, bsz=40, num_updates=1580, lr=4.00507e-05, gnorm=1.384, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1787
2022-09-30 09:01:02 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.3, ups=0.89, wpb=102.3, bsz=40, num_updates=1590, lr=4.03042e-05, gnorm=1.471, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1798
2022-09-30 09:01:13 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 15783 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.7, ups=0.89, wpb=100.8, bsz=40, num_updates=1600, lr=4.05577e-05, gnorm=1.455, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1810
2022-09-30 09:01:24 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=1610, lr=4.08112e-05, gnorm=1.351, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1821
2022-09-30 09:01:35 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.9, ups=0.89, wpb=101.3, bsz=40, num_updates=1620, lr=4.10646e-05, gnorm=1.589, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1832
2022-09-30 09:01:47 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.1, ups=0.87, wpb=102.6, bsz=40, num_updates=1630, lr=4.13181e-05, gnorm=1.552, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1844
2022-09-30 09:01:58 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.88, wpb=104.7, bsz=40, num_updates=1640, lr=4.15716e-05, gnorm=1.17, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1855
2022-09-30 09:02:10 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.7, ups=0.87, wpb=100.6, bsz=40, num_updates=1650, lr=4.18251e-05, gnorm=1.446, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1867
2022-09-30 09:02:21 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.7, ups=0.89, wpb=101.1, bsz=40, num_updates=1660, lr=4.20786e-05, gnorm=1.472, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1878
2022-09-30 09:02:32 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.4, ups=0.89, wpb=101.5, bsz=40, num_updates=1670, lr=4.23321e-05, gnorm=1.321, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1889
2022-09-30 09:02:44 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.9, wpb=100.5, bsz=40, num_updates=1680, lr=4.25856e-05, gnorm=1.542, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1900
2022-09-30 09:02:55 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.3, ups=0.88, wpb=100.9, bsz=40, num_updates=1690, lr=4.2839e-05, gnorm=1.519, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1912
2022-09-30 09:03:06 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.89, wpb=101, bsz=40, num_updates=1700, lr=4.30925e-05, gnorm=1.282, clip=70, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=1923
2022-09-30 09:03:17 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.5, ups=0.91, wpb=101.5, bsz=40, num_updates=1710, lr=4.3346e-05, gnorm=1.354, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1934
2022-09-30 09:03:28 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.6, ups=0.9, wpb=101.9, bsz=40, num_updates=1720, lr=4.35995e-05, gnorm=1.352, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1945
2022-09-30 09:03:40 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 15783 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.2, ups=0.88, wpb=100.1, bsz=40, num_updates=1730, lr=4.3853e-05, gnorm=1.438, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1956
2022-09-30 09:03:51 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.89, wpb=102.4, bsz=40, num_updates=1740, lr=4.41065e-05, gnorm=1.291, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1968
2022-09-30 09:04:02 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.3, ups=0.89, wpb=100.4, bsz=40, num_updates=1750, lr=4.43599e-05, gnorm=1.319, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1979
2022-09-30 09:04:14 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.3, ups=0.87, wpb=100.7, bsz=40, num_updates=1760, lr=4.46134e-05, gnorm=1.336, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1990
2022-09-30 09:04:25 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.88, wpb=101.6, bsz=40, num_updates=1770, lr=4.48669e-05, gnorm=1.259, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2002
2022-09-30 09:04:36 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.88, wpb=101.8, bsz=40, num_updates=1780, lr=4.51204e-05, gnorm=1.242, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2013
2022-09-30 09:04:48 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.88, wpb=103.8, bsz=40, num_updates=1790, lr=4.53739e-05, gnorm=1.2, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2024
2022-09-30 09:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.7, ups=0.91, wpb=103, bsz=40, num_updates=1800, lr=4.56274e-05, gnorm=1.477, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2035
2022-09-30 09:05:10 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90, ups=0.89, wpb=101.5, bsz=40, num_updates=1810, lr=4.58809e-05, gnorm=1.421, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2047
2022-09-30 09:05:21 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 15783 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.9, ups=0.89, wpb=99, bsz=40, num_updates=1820, lr=4.61343e-05, gnorm=1.423, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2058
2022-09-30 09:05:33 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 15783 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.2, ups=0.89, wpb=100.7, bsz=40, num_updates=1830, lr=4.63878e-05, gnorm=1.446, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2069
2022-09-30 09:05:44 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.5, ups=0.89, wpb=101.7, bsz=40, num_updates=1840, lr=4.66413e-05, gnorm=1.087, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2081
2022-09-30 09:05:55 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.89, wpb=101.8, bsz=40, num_updates=1850, lr=4.68948e-05, gnorm=1.376, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2092
2022-09-30 09:06:06 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.89, wpb=103, bsz=40, num_updates=1860, lr=4.71483e-05, gnorm=1.386, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2103
2022-09-30 09:06:18 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.4, ups=0.88, wpb=100.9, bsz=40, num_updates=1870, lr=4.74018e-05, gnorm=1.217, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2115
2022-09-30 09:06:29 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.7, ups=0.86, wpb=102.6, bsz=40, num_updates=1880, lr=4.76553e-05, gnorm=1.219, clip=80, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2126
2022-09-30 09:06:41 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90, ups=0.9, wpb=100.3, bsz=40, num_updates=1890, lr=4.79087e-05, gnorm=1.293, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2137
2022-09-30 09:06:52 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.89, wpb=101.8, bsz=40, num_updates=1900, lr=4.81622e-05, gnorm=1.177, clip=70, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=2149
2022-09-30 09:07:03 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.4, ups=0.92, wpb=101.2, bsz=40, num_updates=1910, lr=4.84157e-05, gnorm=1.122, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2159
2022-09-30 09:07:14 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.88, wpb=101.1, bsz=40, num_updates=1920, lr=4.86692e-05, gnorm=1.267, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2171
2022-09-30 09:07:25 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.2, ups=0.9, wpb=103.5, bsz=40, num_updates=1930, lr=4.89227e-05, gnorm=1.241, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2182
2022-09-30 09:07:36 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.6, ups=0.89, wpb=101.4, bsz=40, num_updates=1940, lr=4.91762e-05, gnorm=1.359, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2193
2022-09-30 09:07:48 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=1950, lr=4.94297e-05, gnorm=1.252, clip=70, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=2204
2022-09-30 09:07:59 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.88, wpb=100.8, bsz=40, num_updates=1960, lr=4.96831e-05, gnorm=1.144, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2216
2022-09-30 09:08:10 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.1, ups=0.91, wpb=102.9, bsz=40, num_updates=1970, lr=4.99366e-05, gnorm=1.217, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2227
2022-09-30 09:08:21 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.91, wpb=100.5, bsz=40, num_updates=1980, lr=5.01901e-05, gnorm=1.206, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2238
2022-09-30 09:08:32 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.2, ups=0.88, wpb=99.8, bsz=40, num_updates=1990, lr=5.04436e-05, gnorm=1.193, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2249
2022-09-30 09:08:43 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.9, wpb=101.1, bsz=40, num_updates=2000, lr=5.06971e-05, gnorm=1.248, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2260
2022-09-30 09:08:55 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.5, ups=0.89, wpb=102.6, bsz=40, num_updates=2010, lr=5.09506e-05, gnorm=1.057, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2271
2022-09-30 09:09:06 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.4, ups=0.9, wpb=102.2, bsz=40, num_updates=2020, lr=5.12041e-05, gnorm=1.15, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2282
2022-09-30 09:09:17 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.9, ups=0.9, wpb=103.3, bsz=40, num_updates=2030, lr=5.14575e-05, gnorm=1.207, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2293
2022-09-30 09:09:28 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.9, ups=0.88, wpb=101.3, bsz=40, num_updates=2040, lr=5.1711e-05, gnorm=1.118, clip=60, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2305
2022-09-30 09:09:39 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.89, wpb=102.5, bsz=40, num_updates=2050, lr=5.19645e-05, gnorm=1.14, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2316
2022-09-30 09:09:41 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 09:09:51 - progress_bar.py[line:274] - INFO: epoch 001:   2062 / 15783 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=84.9, ups=0.85, wpb=100.5, bsz=40, num_updates=2060, lr=5.2218e-05, gnorm=1.369, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=2328
2022-09-30 09:10:02 - progress_bar.py[line:274] - INFO: epoch 001:   2072 / 15783 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.7, ups=0.89, wpb=102.1, bsz=40, num_updates=2070, lr=5.24715e-05, gnorm=1.306, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2339
2022-09-30 09:10:13 - progress_bar.py[line:274] - INFO: epoch 001:   2082 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.9, ups=0.92, wpb=101.9, bsz=40, num_updates=2080, lr=5.2725e-05, gnorm=1.275, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2350
2022-09-30 09:10:25 - progress_bar.py[line:274] - INFO: epoch 001:   2092 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.9, ups=0.87, wpb=100.5, bsz=40, num_updates=2090, lr=5.29785e-05, gnorm=1.295, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2362
2022-09-30 09:10:36 - progress_bar.py[line:274] - INFO: epoch 001:   2102 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.8, ups=0.92, wpb=101.7, bsz=40, num_updates=2100, lr=5.32319e-05, gnorm=1.261, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2372
2022-09-30 09:10:47 - progress_bar.py[line:274] - INFO: epoch 001:   2112 / 15783 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.4, ups=0.89, wpb=101.1, bsz=40, num_updates=2110, lr=5.34854e-05, gnorm=1.399, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2384
2022-09-30 09:10:58 - progress_bar.py[line:274] - INFO: epoch 001:   2122 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.5, ups=0.92, wpb=101.6, bsz=40, num_updates=2120, lr=5.37389e-05, gnorm=1.257, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2394
2022-09-30 09:11:09 - progress_bar.py[line:274] - INFO: epoch 001:   2132 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.8, ups=0.89, wpb=102.3, bsz=40, num_updates=2130, lr=5.39924e-05, gnorm=1.2, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2406
2022-09-30 09:11:21 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.1, ups=0.86, wpb=101.3, bsz=40, num_updates=2140, lr=5.42459e-05, gnorm=1.277, clip=80, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=2417
2022-09-30 09:11:32 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88, ups=0.87, wpb=101.7, bsz=40, num_updates=2150, lr=5.44994e-05, gnorm=1.093, clip=80, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=2429
2022-09-30 09:11:43 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.9, ups=0.89, wpb=100.9, bsz=40, num_updates=2160, lr=5.47529e-05, gnorm=1.391, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2440
2022-09-30 09:11:55 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.7, ups=0.89, wpb=103.3, bsz=40, num_updates=2170, lr=5.50063e-05, gnorm=1.327, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2451
2022-09-30 09:12:06 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.3, ups=0.89, wpb=102.8, bsz=40, num_updates=2180, lr=5.52598e-05, gnorm=1.218, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2463
2022-09-30 09:12:17 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.8, ups=0.92, wpb=101.7, bsz=40, num_updates=2190, lr=5.55133e-05, gnorm=1.229, clip=90, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2473
2022-09-30 09:12:28 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.8, ups=0.91, wpb=101.5, bsz=40, num_updates=2200, lr=5.57668e-05, gnorm=1.243, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2484
2022-09-30 09:12:39 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=2210, lr=5.60203e-05, gnorm=1.267, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2496
2022-09-30 09:12:50 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=2220, lr=5.62738e-05, gnorm=1.429, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2507
2022-09-30 09:13:01 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.9, ups=0.91, wpb=101.2, bsz=40, num_updates=2230, lr=5.65272e-05, gnorm=1.425, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2518
2022-09-30 09:13:13 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.89, wpb=102.7, bsz=40, num_updates=2240, lr=5.67807e-05, gnorm=1.271, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2530
2022-09-30 09:13:24 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.5, ups=0.88, wpb=100.1, bsz=40, num_updates=2250, lr=5.70342e-05, gnorm=1.255, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2541
2022-09-30 09:13:35 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93, ups=0.91, wpb=102.6, bsz=40, num_updates=2260, lr=5.72877e-05, gnorm=1.133, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2552
2022-09-30 09:13:46 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 15783 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.7, ups=0.91, wpb=100.5, bsz=40, num_updates=2270, lr=5.75412e-05, gnorm=1.249, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2563
2022-09-30 09:13:58 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.88, wpb=101.3, bsz=40, num_updates=2280, lr=5.77947e-05, gnorm=1.195, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2574
2022-09-30 09:14:09 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.7, ups=0.89, wpb=99.8, bsz=40, num_updates=2290, lr=5.80482e-05, gnorm=1.365, clip=80, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=2585
2022-09-30 09:14:20 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.2, ups=0.89, wpb=99.6, bsz=40, num_updates=2300, lr=5.83016e-05, gnorm=1.297, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2597
2022-09-30 09:14:31 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.89, wpb=102.5, bsz=40, num_updates=2310, lr=5.85551e-05, gnorm=1.047, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2608
2022-09-30 09:14:43 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.88, wpb=102.8, bsz=40, num_updates=2320, lr=5.88086e-05, gnorm=1.009, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2619
2022-09-30 09:14:54 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.8, ups=0.9, wpb=100.1, bsz=40, num_updates=2330, lr=5.90621e-05, gnorm=1.307, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2631
2022-09-30 09:15:05 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.5, ups=0.9, wpb=102, bsz=40, num_updates=2340, lr=5.93156e-05, gnorm=1.233, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2642
2022-09-30 09:15:16 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=2350, lr=5.95691e-05, gnorm=1.15, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2653
2022-09-30 09:15:28 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.3, ups=0.87, wpb=102.1, bsz=40, num_updates=2360, lr=5.98226e-05, gnorm=1.049, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2665
2022-09-30 09:15:39 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 15783 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88, ups=0.89, wpb=99.3, bsz=40, num_updates=2370, lr=6.0076e-05, gnorm=1.162, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2676
2022-09-30 09:15:50 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=2380, lr=6.03295e-05, gnorm=1.241, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2687
2022-09-30 09:16:02 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=2390, lr=6.0583e-05, gnorm=1.095, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2698
2022-09-30 09:16:13 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.87, wpb=102.4, bsz=40, num_updates=2400, lr=6.08365e-05, gnorm=1.092, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2710
2022-09-30 09:16:24 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.9, ups=0.9, wpb=100.5, bsz=40, num_updates=2410, lr=6.109e-05, gnorm=1.099, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2721
2022-09-30 09:16:35 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.5, ups=0.91, wpb=101.7, bsz=40, num_updates=2420, lr=6.13435e-05, gnorm=1.209, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2732
2022-09-30 09:16:46 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.6, ups=0.93, wpb=100.5, bsz=40, num_updates=2430, lr=6.1597e-05, gnorm=1.223, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2743
2022-09-30 09:16:58 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.6, ups=0.86, wpb=100.3, bsz=40, num_updates=2440, lr=6.18504e-05, gnorm=1.196, clip=70, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=2754
2022-09-30 09:17:09 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.4, ups=0.89, wpb=102.1, bsz=40, num_updates=2450, lr=6.21039e-05, gnorm=1.108, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2766
2022-09-30 09:17:20 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.89, wpb=101.5, bsz=40, num_updates=2460, lr=6.23574e-05, gnorm=1.062, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2777
2022-09-30 09:17:32 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.3, ups=0.86, wpb=102.3, bsz=40, num_updates=2470, lr=6.26109e-05, gnorm=1.146, clip=70, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=2789
2022-09-30 09:17:43 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.6, ups=0.89, wpb=100.7, bsz=40, num_updates=2480, lr=6.28644e-05, gnorm=1.126, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2800
2022-09-30 09:17:54 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=101.2, bsz=40, num_updates=2490, lr=6.31179e-05, gnorm=1.344, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2811
2022-09-30 09:18:06 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=2500, lr=6.33714e-05, gnorm=1.335, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2822
2022-09-30 09:18:17 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.8, ups=0.89, wpb=103.1, bsz=40, num_updates=2510, lr=6.36248e-05, gnorm=1.081, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2834
2022-09-30 09:18:28 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90, ups=0.9, wpb=100.1, bsz=40, num_updates=2520, lr=6.38783e-05, gnorm=1.131, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2845
2022-09-30 09:18:39 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.1, ups=0.88, wpb=98.8, bsz=40, num_updates=2530, lr=6.41318e-05, gnorm=1.25, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2856
2022-09-30 09:18:51 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.9, wpb=100.8, bsz=40, num_updates=2540, lr=6.43853e-05, gnorm=1.281, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2867
2022-09-30 09:19:02 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.5, ups=0.9, wpb=100.4, bsz=40, num_updates=2550, lr=6.46388e-05, gnorm=1.292, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2878
2022-09-30 09:19:13 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.9, wpb=99.3, bsz=40, num_updates=2560, lr=6.48923e-05, gnorm=0.97, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2889
2022-09-30 09:19:24 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 09:19:25 - progress_bar.py[line:274] - INFO: epoch 001:   2573 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=80.6, ups=0.81, wpb=99.8, bsz=40, num_updates=2570, lr=6.51458e-05, gnorm=1.23, clip=90, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2902
2022-09-30 09:19:36 - progress_bar.py[line:274] - INFO: epoch 001:   2583 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.9, wpb=101.8, bsz=40, num_updates=2580, lr=6.53992e-05, gnorm=0.967, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2913
2022-09-30 09:19:48 - progress_bar.py[line:274] - INFO: epoch 001:   2593 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.4, ups=0.87, wpb=100.1, bsz=40, num_updates=2590, lr=6.56527e-05, gnorm=1.11, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2924
2022-09-30 09:19:59 - progress_bar.py[line:274] - INFO: epoch 001:   2603 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=2600, lr=6.59062e-05, gnorm=1.233, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2936
2022-09-30 09:20:10 - progress_bar.py[line:274] - INFO: epoch 001:   2613 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.3, ups=0.88, wpb=100.9, bsz=40, num_updates=2610, lr=6.61597e-05, gnorm=1.009, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2947
2022-09-30 09:20:21 - progress_bar.py[line:274] - INFO: epoch 001:   2623 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.1, ups=0.92, wpb=101.1, bsz=40, num_updates=2620, lr=6.64132e-05, gnorm=1.059, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2958
2022-09-30 09:20:32 - progress_bar.py[line:274] - INFO: epoch 001:   2633 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.8, ups=0.9, wpb=102.4, bsz=40, num_updates=2630, lr=6.66667e-05, gnorm=1.073, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2969
2022-09-30 09:20:43 - progress_bar.py[line:274] - INFO: epoch 001:   2643 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.5, ups=0.92, wpb=102.7, bsz=40, num_updates=2640, lr=6.69202e-05, gnorm=0.944, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2980
2022-09-30 09:20:54 - progress_bar.py[line:274] - INFO: epoch 001:   2653 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.4, ups=0.9, wpb=103.3, bsz=40, num_updates=2650, lr=6.71736e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2991
2022-09-30 09:21:06 - progress_bar.py[line:274] - INFO: epoch 001:   2663 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.89, wpb=101.2, bsz=40, num_updates=2660, lr=6.74271e-05, gnorm=1.1, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3002
2022-09-30 09:21:17 - progress_bar.py[line:274] - INFO: epoch 001:   2673 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.6, ups=0.89, wpb=102.2, bsz=40, num_updates=2670, lr=6.76806e-05, gnorm=1.101, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3014
2022-09-30 09:21:28 - progress_bar.py[line:274] - INFO: epoch 001:   2683 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89, ups=0.87, wpb=102, bsz=40, num_updates=2680, lr=6.79341e-05, gnorm=0.985, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3025
2022-09-30 09:21:40 - progress_bar.py[line:274] - INFO: epoch 001:   2693 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.9, ups=0.89, wpb=100, bsz=40, num_updates=2690, lr=6.81876e-05, gnorm=1.125, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3036
2022-09-30 09:21:51 - progress_bar.py[line:274] - INFO: epoch 001:   2703 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.5, ups=0.87, wpb=101.2, bsz=40, num_updates=2700, lr=6.84411e-05, gnorm=1.09, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=3048
2022-09-30 09:22:02 - progress_bar.py[line:274] - INFO: epoch 001:   2713 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=2710, lr=6.86946e-05, gnorm=0.996, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3059
2022-09-30 09:22:14 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.88, wpb=100.1, bsz=40, num_updates=2720, lr=6.8948e-05, gnorm=1.202, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3070
2022-09-30 09:22:25 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.89, wpb=101.1, bsz=40, num_updates=2730, lr=6.92015e-05, gnorm=1.312, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=3082
2022-09-30 09:22:36 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.3, ups=0.89, wpb=103.1, bsz=40, num_updates=2740, lr=6.9455e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3093
2022-09-30 09:22:47 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.4, ups=0.94, wpb=99.9, bsz=40, num_updates=2750, lr=6.97085e-05, gnorm=1.254, clip=80, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3104
2022-09-30 09:22:58 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.5, ups=0.89, wpb=102.3, bsz=40, num_updates=2760, lr=6.9962e-05, gnorm=1.09, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3115
2022-09-30 09:23:09 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.8, ups=0.9, wpb=100.4, bsz=40, num_updates=2770, lr=7.02155e-05, gnorm=1.267, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3126
2022-09-30 09:23:20 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=2780, lr=7.04689e-05, gnorm=0.93, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3137
2022-09-30 09:23:32 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=2790, lr=7.07224e-05, gnorm=1.24, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3148
2022-09-30 09:23:43 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 15783 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.6, ups=0.89, wpb=101.6, bsz=40, num_updates=2800, lr=7.09759e-05, gnorm=1.468, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3160
2022-09-30 09:23:54 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=2810, lr=7.12294e-05, gnorm=1.043, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3171
2022-09-30 09:24:05 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.91, wpb=100.5, bsz=40, num_updates=2820, lr=7.14829e-05, gnorm=1.014, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3182
2022-09-30 09:24:16 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.1, ups=0.93, wpb=102.3, bsz=40, num_updates=2830, lr=7.17364e-05, gnorm=1.054, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=3192
2022-09-30 09:24:27 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.9, wpb=101.9, bsz=40, num_updates=2840, lr=7.19899e-05, gnorm=1.02, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3204
2022-09-30 09:24:38 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.89, wpb=102.7, bsz=40, num_updates=2850, lr=7.22433e-05, gnorm=1.138, clip=70, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=3215
2022-09-30 09:24:49 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.2, ups=0.89, wpb=100.4, bsz=40, num_updates=2860, lr=7.24968e-05, gnorm=1.287, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3226
2022-09-30 09:25:01 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=2870, lr=7.27503e-05, gnorm=1.104, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3237
2022-09-30 09:25:12 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=2880, lr=7.30038e-05, gnorm=1.143, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3249
2022-09-30 09:25:23 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.5, ups=0.88, wpb=102.6, bsz=40, num_updates=2890, lr=7.32573e-05, gnorm=1.022, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3260
2022-09-30 09:25:34 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.1, ups=0.92, wpb=101.3, bsz=40, num_updates=2900, lr=7.35108e-05, gnorm=1.038, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3271
2022-09-30 09:25:46 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.5, ups=0.91, wpb=100.2, bsz=40, num_updates=2910, lr=7.37643e-05, gnorm=1.034, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3282
2022-09-30 09:25:57 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.1, ups=0.92, wpb=101.3, bsz=40, num_updates=2920, lr=7.40177e-05, gnorm=0.988, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3294
2022-09-30 09:26:08 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.2, ups=0.88, wpb=101.3, bsz=40, num_updates=2930, lr=7.42712e-05, gnorm=0.977, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3305
2022-09-30 09:26:19 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.1, ups=0.9, wpb=100.9, bsz=40, num_updates=2940, lr=7.45247e-05, gnorm=1.086, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3316
2022-09-30 09:26:30 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=2950, lr=7.47782e-05, gnorm=0.883, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3327
2022-09-30 09:26:42 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.89, wpb=102.3, bsz=40, num_updates=2960, lr=7.50317e-05, gnorm=0.947, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3338
2022-09-30 09:26:53 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.8, ups=0.91, wpb=100.2, bsz=40, num_updates=2970, lr=7.52852e-05, gnorm=1.064, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3349
2022-09-30 09:27:04 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.8, ups=0.88, wpb=100.8, bsz=40, num_updates=2980, lr=7.55387e-05, gnorm=1.061, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3361
2022-09-30 09:27:15 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.6, ups=0.89, wpb=100.5, bsz=40, num_updates=2990, lr=7.57921e-05, gnorm=1.276, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3372
2022-09-30 09:27:26 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.7, ups=0.9, wpb=100.6, bsz=40, num_updates=3000, lr=7.60456e-05, gnorm=0.898, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3383
2022-09-30 09:27:38 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.9, ups=0.87, wpb=100.7, bsz=40, num_updates=3010, lr=7.62991e-05, gnorm=1.011, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3395
2022-09-30 09:27:49 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.91, wpb=99.6, bsz=40, num_updates=3020, lr=7.65526e-05, gnorm=1.242, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3406
2022-09-30 09:28:00 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.9, ups=0.91, wpb=102.6, bsz=40, num_updates=3030, lr=7.68061e-05, gnorm=0.957, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3417
2022-09-30 09:28:11 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.9, ups=0.91, wpb=101.4, bsz=40, num_updates=3040, lr=7.70596e-05, gnorm=0.89, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3428
2022-09-30 09:28:22 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.89, wpb=102.3, bsz=40, num_updates=3050, lr=7.73131e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3439
2022-09-30 09:28:33 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92, ups=0.92, wpb=100.5, bsz=40, num_updates=3060, lr=7.75665e-05, gnorm=1.068, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3450
2022-09-30 09:28:44 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.6, ups=0.93, wpb=101, bsz=40, num_updates=3070, lr=7.782e-05, gnorm=0.997, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3461
2022-09-30 09:28:55 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.1, ups=0.88, wpb=100, bsz=40, num_updates=3080, lr=7.80735e-05, gnorm=1.045, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3472
2022-09-30 09:29:02 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 09:29:08 - progress_bar.py[line:274] - INFO: epoch 001:   3094 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=81.6, ups=0.8, wpb=101.5, bsz=40, num_updates=3090, lr=7.8327e-05, gnorm=1.177, clip=80, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=3484
2022-09-30 09:29:19 - progress_bar.py[line:274] - INFO: epoch 001:   3104 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93, ups=0.91, wpb=101.7, bsz=40, num_updates=3100, lr=7.85805e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3495
2022-09-30 09:29:29 - progress_bar.py[line:274] - INFO: epoch 001:   3114 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.92, wpb=101, bsz=40, num_updates=3110, lr=7.8834e-05, gnorm=0.94, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3506
2022-09-30 09:29:41 - progress_bar.py[line:274] - INFO: epoch 001:   3124 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.7, ups=0.9, wpb=99.7, bsz=40, num_updates=3120, lr=7.90875e-05, gnorm=1.085, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3517
2022-09-30 09:29:52 - progress_bar.py[line:274] - INFO: epoch 001:   3134 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.5, ups=0.91, wpb=102.1, bsz=40, num_updates=3130, lr=7.93409e-05, gnorm=0.975, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=3528
2022-09-30 09:30:03 - progress_bar.py[line:274] - INFO: epoch 001:   3144 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.89, wpb=102.1, bsz=40, num_updates=3140, lr=7.95944e-05, gnorm=0.984, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3540
2022-09-30 09:30:14 - progress_bar.py[line:274] - INFO: epoch 001:   3154 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.9, ups=0.91, wpb=102.2, bsz=40, num_updates=3150, lr=7.98479e-05, gnorm=1.057, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3551
2022-09-30 09:30:25 - progress_bar.py[line:274] - INFO: epoch 001:   3164 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.88, wpb=100.4, bsz=40, num_updates=3160, lr=7.99958e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3562
2022-09-30 09:30:36 - progress_bar.py[line:274] - INFO: epoch 001:   3174 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.5, ups=0.89, wpb=102.6, bsz=40, num_updates=3170, lr=7.99852e-05, gnorm=0.886, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3573
2022-09-30 09:30:47 - progress_bar.py[line:274] - INFO: epoch 001:   3184 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.7, ups=0.9, wpb=101.6, bsz=40, num_updates=3180, lr=7.99747e-05, gnorm=1.003, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3584
2022-09-30 09:30:59 - progress_bar.py[line:274] - INFO: epoch 001:   3194 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.3, ups=0.89, wpb=100.4, bsz=40, num_updates=3190, lr=7.99641e-05, gnorm=1.038, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3595
2022-09-30 09:31:10 - progress_bar.py[line:274] - INFO: epoch 001:   3204 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.89, wpb=101.7, bsz=40, num_updates=3200, lr=7.99535e-05, gnorm=1.097, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3607
2022-09-30 09:31:21 - progress_bar.py[line:274] - INFO: epoch 001:   3214 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.5, ups=0.88, wpb=100.7, bsz=40, num_updates=3210, lr=7.9943e-05, gnorm=0.983, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3618
2022-09-30 09:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   3224 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.7, ups=0.9, wpb=101.3, bsz=40, num_updates=3220, lr=7.99324e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3629
2022-09-30 09:31:44 - progress_bar.py[line:274] - INFO: epoch 001:   3234 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.6, ups=0.87, wpb=100.6, bsz=40, num_updates=3230, lr=7.99219e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3641
2022-09-30 09:31:55 - progress_bar.py[line:274] - INFO: epoch 001:   3244 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.7, ups=0.87, wpb=100.7, bsz=40, num_updates=3240, lr=7.99113e-05, gnorm=1.026, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3652
2022-09-30 09:32:07 - progress_bar.py[line:274] - INFO: epoch 001:   3254 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.8, ups=0.88, wpb=100.8, bsz=40, num_updates=3250, lr=7.99007e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3664
2022-09-30 09:32:18 - progress_bar.py[line:274] - INFO: epoch 001:   3264 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.3, ups=0.91, wpb=100.8, bsz=40, num_updates=3260, lr=7.98902e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3675
2022-09-30 09:32:29 - progress_bar.py[line:274] - INFO: epoch 001:   3274 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=3270, lr=7.98796e-05, gnorm=0.94, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3686
2022-09-30 09:32:40 - progress_bar.py[line:274] - INFO: epoch 001:   3284 / 15783 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.8, ups=0.95, wpb=100.4, bsz=40, num_updates=3280, lr=7.98691e-05, gnorm=1.007, clip=40, loss_scale=512, train_wall=10, gb_free=10.5, ema_decay=0.9999, wall=3696
2022-09-30 09:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   3294 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.8, ups=0.92, wpb=101.4, bsz=40, num_updates=3290, lr=7.98585e-05, gnorm=0.916, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3707
2022-09-30 09:33:02 - progress_bar.py[line:274] - INFO: epoch 001:   3304 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=3300, lr=7.98479e-05, gnorm=1.126, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3718
2022-09-30 09:33:13 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.5, ups=0.92, wpb=101.2, bsz=40, num_updates=3310, lr=7.98374e-05, gnorm=1.142, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3729
2022-09-30 09:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.9, ups=0.94, wpb=101.4, bsz=40, num_updates=3320, lr=7.98268e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3740
2022-09-30 09:33:34 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.6, ups=0.89, wpb=99, bsz=40, num_updates=3330, lr=7.98163e-05, gnorm=1.113, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3751
2022-09-30 09:33:45 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.6, ups=0.9, wpb=103.6, bsz=40, num_updates=3340, lr=7.98057e-05, gnorm=0.999, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3762
2022-09-30 09:33:56 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.3, ups=0.91, wpb=101.8, bsz=40, num_updates=3350, lr=7.97951e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3773
2022-09-30 09:34:08 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=3360, lr=7.97846e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3784
2022-09-30 09:34:19 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.9, ups=0.89, wpb=100.8, bsz=40, num_updates=3370, lr=7.9774e-05, gnorm=0.993, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3796
2022-09-30 09:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.8, ups=0.87, wpb=101.8, bsz=40, num_updates=3380, lr=7.97635e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3807
2022-09-30 09:34:42 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.4, ups=0.9, wpb=99.7, bsz=40, num_updates=3390, lr=7.97529e-05, gnorm=0.963, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3818
2022-09-30 09:34:52 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.1, ups=0.96, wpb=100.8, bsz=40, num_updates=3400, lr=7.97423e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=10, gb_free=10.9, ema_decay=0.9999, wall=3829
2022-09-30 09:35:03 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 15783 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.2, ups=0.88, wpb=100.3, bsz=40, num_updates=3410, lr=7.97318e-05, gnorm=0.988, clip=60, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=3840
2022-09-30 09:35:14 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.8, ups=0.9, wpb=102, bsz=40, num_updates=3420, lr=7.97212e-05, gnorm=1.172, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3851
2022-09-30 09:35:26 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=3430, lr=7.97107e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3863
2022-09-30 09:35:37 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=102.5, bsz=40, num_updates=3440, lr=7.97001e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3874
2022-09-30 09:35:49 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.5, ups=0.87, wpb=101.7, bsz=40, num_updates=3450, lr=7.96895e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3885
2022-09-30 09:36:00 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.8, ups=0.89, wpb=99.8, bsz=40, num_updates=3460, lr=7.9679e-05, gnorm=0.941, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3897
2022-09-30 09:36:11 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.92, wpb=100.5, bsz=40, num_updates=3470, lr=7.96684e-05, gnorm=0.908, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3907
2022-09-30 09:36:22 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.8, ups=0.9, wpb=102.8, bsz=40, num_updates=3480, lr=7.96579e-05, gnorm=0.822, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3919
2022-09-30 09:36:33 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.6, ups=0.9, wpb=100.5, bsz=40, num_updates=3490, lr=7.96473e-05, gnorm=0.823, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3930
2022-09-30 09:36:44 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.2, ups=0.91, wpb=101.3, bsz=40, num_updates=3500, lr=7.96367e-05, gnorm=0.858, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3941
2022-09-30 09:36:55 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89, ups=0.9, wpb=98.6, bsz=40, num_updates=3510, lr=7.96262e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3952
2022-09-30 09:37:06 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=3520, lr=7.96156e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3963
2022-09-30 09:37:17 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 15783 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.3, ups=0.91, wpb=100.5, bsz=40, num_updates=3530, lr=7.96051e-05, gnorm=1.179, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3974
2022-09-30 09:37:28 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.91, wpb=100.9, bsz=40, num_updates=3540, lr=7.95945e-05, gnorm=0.82, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3985
2022-09-30 09:37:39 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 15783 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90, ups=0.89, wpb=100.8, bsz=40, num_updates=3550, lr=7.95839e-05, gnorm=0.885, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3996
2022-09-30 09:37:51 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.89, wpb=101.5, bsz=40, num_updates=3560, lr=7.95734e-05, gnorm=0.788, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4007
2022-09-30 09:38:02 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.88, wpb=102, bsz=40, num_updates=3570, lr=7.95628e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4019
2022-09-30 09:38:13 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.9, ups=0.89, wpb=101.6, bsz=40, num_updates=3580, lr=7.95523e-05, gnorm=0.735, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4030
2022-09-30 09:38:24 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.3, ups=0.92, wpb=101.9, bsz=40, num_updates=3590, lr=7.95417e-05, gnorm=0.831, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4041
2022-09-30 09:38:35 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93, ups=0.9, wpb=102.8, bsz=40, num_updates=3600, lr=7.95311e-05, gnorm=0.896, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4052
2022-09-30 09:38:43 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 09:38:47 - progress_bar.py[line:274] - INFO: epoch 001:   3615 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=83.6, ups=0.81, wpb=102.8, bsz=40, num_updates=3610, lr=7.95206e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=4064
2022-09-30 09:38:59 - progress_bar.py[line:274] - INFO: epoch 001:   3625 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.9, ups=0.88, wpb=101.7, bsz=40, num_updates=3620, lr=7.951e-05, gnorm=1.028, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4076
2022-09-30 09:39:10 - progress_bar.py[line:274] - INFO: epoch 001:   3635 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90, ups=0.89, wpb=100.9, bsz=40, num_updates=3630, lr=7.94995e-05, gnorm=1.001, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4087
2022-09-30 09:39:21 - progress_bar.py[line:274] - INFO: epoch 001:   3645 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=3640, lr=7.94889e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4098
2022-09-30 09:39:32 - progress_bar.py[line:274] - INFO: epoch 001:   3655 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.7, ups=0.89, wpb=101.5, bsz=40, num_updates=3650, lr=7.94783e-05, gnorm=0.816, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4109
2022-09-30 09:39:43 - progress_bar.py[line:274] - INFO: epoch 001:   3665 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.3, ups=0.93, wpb=100.8, bsz=40, num_updates=3660, lr=7.94678e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4120
2022-09-30 09:39:54 - progress_bar.py[line:274] - INFO: epoch 001:   3675 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.9, ups=0.89, wpb=103, bsz=40, num_updates=3670, lr=7.94572e-05, gnorm=0.768, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4131
2022-09-30 09:40:06 - progress_bar.py[line:274] - INFO: epoch 001:   3685 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89, ups=0.89, wpb=100, bsz=40, num_updates=3680, lr=7.94467e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4142
2022-09-30 09:40:16 - progress_bar.py[line:274] - INFO: epoch 001:   3695 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.8, ups=0.94, wpb=101, bsz=40, num_updates=3690, lr=7.94361e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4153
2022-09-30 09:40:27 - progress_bar.py[line:274] - INFO: epoch 001:   3705 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.3, ups=0.92, wpb=102.7, bsz=40, num_updates=3700, lr=7.94255e-05, gnorm=0.802, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4164
2022-09-30 09:40:39 - progress_bar.py[line:274] - INFO: epoch 001:   3715 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.6, ups=0.88, wpb=104.2, bsz=40, num_updates=3710, lr=7.9415e-05, gnorm=0.784, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4175
2022-09-30 09:40:50 - progress_bar.py[line:274] - INFO: epoch 001:   3725 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.6, ups=0.89, wpb=101.6, bsz=40, num_updates=3720, lr=7.94044e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4187
2022-09-30 09:41:01 - progress_bar.py[line:274] - INFO: epoch 001:   3735 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.4, ups=0.87, wpb=100.2, bsz=40, num_updates=3730, lr=7.93939e-05, gnorm=0.922, clip=30, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=4198
2022-09-30 09:41:13 - progress_bar.py[line:274] - INFO: epoch 001:   3745 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.4, ups=0.87, wpb=102.4, bsz=40, num_updates=3740, lr=7.93833e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4210
2022-09-30 09:41:24 - progress_bar.py[line:274] - INFO: epoch 001:   3755 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.88, wpb=101.6, bsz=40, num_updates=3750, lr=7.93727e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4221
2022-09-30 09:41:35 - progress_bar.py[line:274] - INFO: epoch 001:   3765 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.9, ups=0.9, wpb=102.7, bsz=40, num_updates=3760, lr=7.93622e-05, gnorm=0.914, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4232
2022-09-30 09:41:46 - progress_bar.py[line:274] - INFO: epoch 001:   3775 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.7, ups=0.9, wpb=100.6, bsz=40, num_updates=3770, lr=7.93516e-05, gnorm=0.916, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4243
2022-09-30 09:41:57 - progress_bar.py[line:274] - INFO: epoch 001:   3785 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.91, wpb=101, bsz=40, num_updates=3780, lr=7.93411e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4254
2022-09-30 09:42:09 - progress_bar.py[line:274] - INFO: epoch 001:   3795 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.88, wpb=101.6, bsz=40, num_updates=3790, lr=7.93305e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4265
2022-09-30 09:42:20 - progress_bar.py[line:274] - INFO: epoch 001:   3805 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.7, ups=0.88, wpb=102.2, bsz=40, num_updates=3800, lr=7.93199e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4277
2022-09-30 09:42:32 - progress_bar.py[line:274] - INFO: epoch 001:   3815 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.4, ups=0.89, wpb=100.2, bsz=40, num_updates=3810, lr=7.93094e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4288
2022-09-30 09:42:42 - progress_bar.py[line:274] - INFO: epoch 001:   3825 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94, ups=0.93, wpb=100.7, bsz=40, num_updates=3820, lr=7.92988e-05, gnorm=0.734, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4299
2022-09-30 09:42:54 - progress_bar.py[line:274] - INFO: epoch 001:   3835 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.88, wpb=101.1, bsz=40, num_updates=3830, lr=7.92883e-05, gnorm=0.981, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4311
2022-09-30 09:43:05 - progress_bar.py[line:274] - INFO: epoch 001:   3845 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95, ups=0.93, wpb=102.4, bsz=40, num_updates=3840, lr=7.92777e-05, gnorm=0.865, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4321
2022-09-30 09:43:16 - progress_bar.py[line:274] - INFO: epoch 001:   3855 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.9, ups=0.87, wpb=103, bsz=40, num_updates=3850, lr=7.92671e-05, gnorm=0.957, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4333
2022-09-30 09:43:27 - progress_bar.py[line:274] - INFO: epoch 001:   3865 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.8, ups=0.89, wpb=102.5, bsz=40, num_updates=3860, lr=7.92566e-05, gnorm=0.916, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4344
2022-09-30 09:43:38 - progress_bar.py[line:274] - INFO: epoch 001:   3875 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95, ups=0.94, wpb=100.8, bsz=40, num_updates=3870, lr=7.9246e-05, gnorm=0.82, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4355
2022-09-30 09:43:49 - progress_bar.py[line:274] - INFO: epoch 001:   3885 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.89, wpb=101.7, bsz=40, num_updates=3880, lr=7.92355e-05, gnorm=0.898, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4366
2022-09-30 09:44:01 - progress_bar.py[line:274] - INFO: epoch 001:   3895 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=3890, lr=7.92249e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4377
2022-09-30 09:44:12 - progress_bar.py[line:274] - INFO: epoch 001:   3905 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.9, wpb=100.9, bsz=40, num_updates=3900, lr=7.92144e-05, gnorm=0.973, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4388
2022-09-30 09:44:23 - progress_bar.py[line:274] - INFO: epoch 001:   3915 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92, ups=0.88, wpb=104.5, bsz=40, num_updates=3910, lr=7.92038e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4400
2022-09-30 09:44:34 - progress_bar.py[line:274] - INFO: epoch 001:   3925 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.5, ups=0.92, wpb=100.9, bsz=40, num_updates=3920, lr=7.91932e-05, gnorm=1.136, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4411
2022-09-30 09:44:45 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.88, wpb=102.2, bsz=40, num_updates=3930, lr=7.91827e-05, gnorm=0.87, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4422
2022-09-30 09:44:57 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.2, ups=0.89, wpb=99.9, bsz=40, num_updates=3940, lr=7.91721e-05, gnorm=0.939, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4433
2022-09-30 09:45:07 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97, ups=0.94, wpb=102.7, bsz=40, num_updates=3950, lr=7.91616e-05, gnorm=0.97, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4444
2022-09-30 09:45:18 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.2, ups=0.89, wpb=100.2, bsz=40, num_updates=3960, lr=7.9151e-05, gnorm=0.861, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4455
2022-09-30 09:45:30 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.89, wpb=99.7, bsz=40, num_updates=3970, lr=7.91404e-05, gnorm=0.988, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4466
2022-09-30 09:45:41 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89, ups=0.88, wpb=101.1, bsz=40, num_updates=3980, lr=7.91299e-05, gnorm=1.079, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4478
2022-09-30 09:45:52 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.3, ups=0.9, wpb=101.9, bsz=40, num_updates=3990, lr=7.91193e-05, gnorm=0.971, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4489
2022-09-30 09:46:03 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.4, ups=0.92, wpb=99.9, bsz=40, num_updates=4000, lr=7.91088e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4500
2022-09-30 09:46:14 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 15783 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.1, ups=0.9, wpb=101.1, bsz=40, num_updates=4010, lr=7.90982e-05, gnorm=0.966, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4511
2022-09-30 09:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.8, ups=0.88, wpb=99.9, bsz=40, num_updates=4020, lr=7.90876e-05, gnorm=0.888, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4522
2022-09-30 09:46:37 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.4, ups=0.92, wpb=101.6, bsz=40, num_updates=4030, lr=7.90771e-05, gnorm=0.989, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4533
2022-09-30 09:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 15783 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.6, ups=0.88, wpb=99.6, bsz=40, num_updates=4040, lr=7.90665e-05, gnorm=0.891, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4545
2022-09-30 09:46:59 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.9, wpb=101.1, bsz=40, num_updates=4050, lr=7.9056e-05, gnorm=0.913, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4556
2022-09-30 09:47:10 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.5, ups=0.94, wpb=103, bsz=40, num_updates=4060, lr=7.90454e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4566
2022-09-30 09:47:21 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.3, ups=0.88, wpb=99, bsz=40, num_updates=4070, lr=7.90348e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4578
2022-09-30 09:47:32 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.2, ups=0.96, wpb=101.8, bsz=40, num_updates=4080, lr=7.90243e-05, gnorm=0.871, clip=40, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=4588
2022-09-30 09:47:43 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.8, ups=0.89, wpb=100, bsz=40, num_updates=4090, lr=7.90137e-05, gnorm=0.826, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4600
2022-09-30 09:47:54 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.4, ups=0.92, wpb=100.7, bsz=40, num_updates=4100, lr=7.90032e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4610
2022-09-30 09:48:05 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.2, ups=0.88, wpb=100.2, bsz=40, num_updates=4110, lr=7.89926e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4622
2022-09-30 09:48:16 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.5, ups=0.93, wpb=100.4, bsz=40, num_updates=4120, lr=7.8982e-05, gnorm=0.785, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4633
2022-09-30 09:48:27 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90, ups=0.88, wpb=102, bsz=40, num_updates=4130, lr=7.89715e-05, gnorm=0.898, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4644
2022-09-30 09:48:39 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.88, wpb=103.5, bsz=40, num_updates=4140, lr=7.89609e-05, gnorm=0.918, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4655
2022-09-30 09:48:41 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 09:48:51 - progress_bar.py[line:274] - INFO: epoch 001:   4156 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=78.9, ups=0.8, wpb=98.9, bsz=40, num_updates=4150, lr=7.89504e-05, gnorm=0.914, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=4668
2022-09-30 09:49:02 - progress_bar.py[line:274] - INFO: epoch 001:   4166 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.89, wpb=102.7, bsz=40, num_updates=4160, lr=7.89398e-05, gnorm=0.848, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4679
2022-09-30 09:49:13 - progress_bar.py[line:274] - INFO: epoch 001:   4176 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.91, wpb=100.5, bsz=40, num_updates=4170, lr=7.89292e-05, gnorm=0.977, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=4690
2022-09-30 09:49:24 - progress_bar.py[line:274] - INFO: epoch 001:   4186 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.4, ups=0.9, wpb=100.8, bsz=40, num_updates=4180, lr=7.89187e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4701
2022-09-30 09:49:36 - progress_bar.py[line:274] - INFO: epoch 001:   4196 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.6, ups=0.88, wpb=101.7, bsz=40, num_updates=4190, lr=7.89081e-05, gnorm=1.078, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4713
2022-09-30 09:49:47 - progress_bar.py[line:274] - INFO: epoch 001:   4206 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.9, ups=0.9, wpb=101.7, bsz=40, num_updates=4200, lr=7.88976e-05, gnorm=0.89, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4724
2022-09-30 09:49:58 - progress_bar.py[line:274] - INFO: epoch 001:   4216 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=4210, lr=7.8887e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=4735
2022-09-30 09:50:10 - progress_bar.py[line:274] - INFO: epoch 001:   4226 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=4220, lr=7.88764e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4746
2022-09-30 09:50:21 - progress_bar.py[line:274] - INFO: epoch 001:   4236 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=4230, lr=7.88659e-05, gnorm=0.768, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4758
2022-09-30 09:50:32 - progress_bar.py[line:274] - INFO: epoch 001:   4246 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.9, ups=0.87, wpb=101.6, bsz=40, num_updates=4240, lr=7.88553e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4769
2022-09-30 09:50:43 - progress_bar.py[line:274] - INFO: epoch 001:   4256 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92, ups=0.91, wpb=100.7, bsz=40, num_updates=4250, lr=7.88448e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4780
2022-09-30 09:50:55 - progress_bar.py[line:274] - INFO: epoch 001:   4266 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.9, ups=0.89, wpb=102.3, bsz=40, num_updates=4260, lr=7.88342e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4791
2022-09-30 09:51:05 - progress_bar.py[line:274] - INFO: epoch 001:   4276 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.5, ups=0.92, wpb=101.7, bsz=40, num_updates=4270, lr=7.88236e-05, gnorm=0.741, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4802
2022-09-30 09:51:17 - progress_bar.py[line:274] - INFO: epoch 001:   4286 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=4280, lr=7.88131e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4814
2022-09-30 09:51:28 - progress_bar.py[line:274] - INFO: epoch 001:   4296 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.5, ups=0.9, wpb=101.2, bsz=40, num_updates=4290, lr=7.88025e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4825
2022-09-30 09:51:39 - progress_bar.py[line:274] - INFO: epoch 001:   4306 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.8, ups=0.89, wpb=101.2, bsz=40, num_updates=4300, lr=7.8792e-05, gnorm=0.915, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4836
2022-09-30 09:51:51 - progress_bar.py[line:274] - INFO: epoch 001:   4316 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.7, ups=0.87, wpb=100.8, bsz=40, num_updates=4310, lr=7.87814e-05, gnorm=0.772, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4847
2022-09-30 09:52:02 - progress_bar.py[line:274] - INFO: epoch 001:   4326 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.3, ups=0.92, wpb=99.5, bsz=40, num_updates=4320, lr=7.87708e-05, gnorm=0.875, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4858
2022-09-30 09:52:13 - progress_bar.py[line:274] - INFO: epoch 001:   4336 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.8, ups=0.9, wpb=102.8, bsz=40, num_updates=4330, lr=7.87603e-05, gnorm=0.839, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4869
2022-09-30 09:52:24 - progress_bar.py[line:274] - INFO: epoch 001:   4346 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.6, ups=0.87, wpb=100.5, bsz=40, num_updates=4340, lr=7.87497e-05, gnorm=0.853, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4881
2022-09-30 09:52:36 - progress_bar.py[line:274] - INFO: epoch 001:   4356 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.9, ups=0.88, wpb=101.8, bsz=40, num_updates=4350, lr=7.87392e-05, gnorm=0.899, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4892
2022-09-30 09:52:47 - progress_bar.py[line:274] - INFO: epoch 001:   4366 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=4360, lr=7.87286e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4904
2022-09-30 09:52:58 - progress_bar.py[line:274] - INFO: epoch 001:   4376 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.4, ups=0.89, wpb=101.4, bsz=40, num_updates=4370, lr=7.8718e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4915
2022-09-30 09:53:09 - progress_bar.py[line:274] - INFO: epoch 001:   4386 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.8, ups=0.89, wpb=101.8, bsz=40, num_updates=4380, lr=7.87075e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4926
2022-09-30 09:53:20 - progress_bar.py[line:274] - INFO: epoch 001:   4396 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.7, ups=0.92, wpb=101.8, bsz=40, num_updates=4390, lr=7.86969e-05, gnorm=1.006, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4937
2022-09-30 09:53:31 - progress_bar.py[line:274] - INFO: epoch 001:   4406 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.89, wpb=99.9, bsz=40, num_updates=4400, lr=7.86864e-05, gnorm=0.788, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4948
2022-09-30 09:53:43 - progress_bar.py[line:274] - INFO: epoch 001:   4416 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.4, ups=0.9, wpb=101.8, bsz=40, num_updates=4410, lr=7.86758e-05, gnorm=0.835, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4959
2022-09-30 09:53:54 - progress_bar.py[line:274] - INFO: epoch 001:   4426 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.3, ups=0.88, wpb=101.5, bsz=40, num_updates=4420, lr=7.86652e-05, gnorm=0.91, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4971
2022-09-30 09:54:05 - progress_bar.py[line:274] - INFO: epoch 001:   4436 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.9, wpb=99.7, bsz=40, num_updates=4430, lr=7.86547e-05, gnorm=0.941, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4982
2022-09-30 09:54:16 - progress_bar.py[line:274] - INFO: epoch 001:   4446 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=4440, lr=7.86441e-05, gnorm=0.809, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4993
2022-09-30 09:54:27 - progress_bar.py[line:274] - INFO: epoch 001:   4456 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.5, ups=0.91, wpb=100.3, bsz=40, num_updates=4450, lr=7.86336e-05, gnorm=0.821, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5004
2022-09-30 09:54:39 - progress_bar.py[line:274] - INFO: epoch 001:   4466 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.88, wpb=101.4, bsz=40, num_updates=4460, lr=7.8623e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5015
2022-09-30 09:54:50 - progress_bar.py[line:274] - INFO: epoch 001:   4476 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.4, ups=0.9, wpb=100.8, bsz=40, num_updates=4470, lr=7.86124e-05, gnorm=0.858, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5027
2022-09-30 09:55:01 - progress_bar.py[line:274] - INFO: epoch 001:   4486 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.91, wpb=100.7, bsz=40, num_updates=4480, lr=7.86019e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5038
2022-09-30 09:55:12 - progress_bar.py[line:274] - INFO: epoch 001:   4496 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.9, wpb=101.1, bsz=40, num_updates=4490, lr=7.85913e-05, gnorm=0.827, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5049
2022-09-30 09:55:23 - progress_bar.py[line:274] - INFO: epoch 001:   4506 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=101.5, bsz=40, num_updates=4500, lr=7.85808e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5060
2022-09-30 09:55:34 - progress_bar.py[line:274] - INFO: epoch 001:   4516 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.2, ups=0.95, wpb=102.8, bsz=40, num_updates=4510, lr=7.85702e-05, gnorm=0.92, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5071
2022-09-30 09:55:45 - progress_bar.py[line:274] - INFO: epoch 001:   4526 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.5, ups=0.92, wpb=100, bsz=40, num_updates=4520, lr=7.85596e-05, gnorm=0.814, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5081
2022-09-30 09:55:56 - progress_bar.py[line:274] - INFO: epoch 001:   4536 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.4, ups=0.92, wpb=102.6, bsz=40, num_updates=4530, lr=7.85491e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5092
2022-09-30 09:56:07 - progress_bar.py[line:274] - INFO: epoch 001:   4546 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.6, ups=0.9, wpb=102.5, bsz=40, num_updates=4540, lr=7.85385e-05, gnorm=0.781, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5103
2022-09-30 09:56:18 - progress_bar.py[line:274] - INFO: epoch 001:   4556 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.8, ups=0.91, wpb=100.4, bsz=40, num_updates=4550, lr=7.8528e-05, gnorm=0.67, clip=0, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5114
2022-09-30 09:56:29 - progress_bar.py[line:274] - INFO: epoch 001:   4566 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.8, ups=0.92, wpb=100.7, bsz=40, num_updates=4560, lr=7.85174e-05, gnorm=0.768, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5125
2022-09-30 09:56:40 - progress_bar.py[line:274] - INFO: epoch 001:   4576 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.9, ups=0.9, wpb=102.5, bsz=40, num_updates=4570, lr=7.85068e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5136
2022-09-30 09:56:51 - progress_bar.py[line:274] - INFO: epoch 001:   4586 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.6, ups=0.91, wpb=101.9, bsz=40, num_updates=4580, lr=7.84963e-05, gnorm=0.716, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5147
2022-09-30 09:57:02 - progress_bar.py[line:274] - INFO: epoch 001:   4596 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89, ups=0.89, wpb=100.2, bsz=40, num_updates=4590, lr=7.84857e-05, gnorm=0.825, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5159
2022-09-30 09:57:13 - progress_bar.py[line:274] - INFO: epoch 001:   4606 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.3, ups=0.88, wpb=102.6, bsz=40, num_updates=4600, lr=7.84752e-05, gnorm=0.806, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5170
2022-09-30 09:57:25 - progress_bar.py[line:274] - INFO: epoch 001:   4616 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.6, ups=0.88, wpb=103.2, bsz=40, num_updates=4610, lr=7.84646e-05, gnorm=0.763, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5181
2022-09-30 09:57:36 - progress_bar.py[line:274] - INFO: epoch 001:   4626 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.9, ups=0.88, wpb=103.1, bsz=40, num_updates=4620, lr=7.8454e-05, gnorm=0.743, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5193
2022-09-30 09:57:47 - progress_bar.py[line:274] - INFO: epoch 001:   4636 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.7, ups=0.92, wpb=101.4, bsz=40, num_updates=4630, lr=7.84435e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5204
2022-09-30 09:57:58 - progress_bar.py[line:274] - INFO: epoch 001:   4646 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.6, ups=0.89, wpb=101.3, bsz=40, num_updates=4640, lr=7.84329e-05, gnorm=0.751, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5215
2022-09-30 09:58:09 - progress_bar.py[line:274] - INFO: epoch 001:   4656 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.92, wpb=101, bsz=40, num_updates=4650, lr=7.84224e-05, gnorm=0.783, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5226
2022-09-30 09:58:20 - progress_bar.py[line:274] - INFO: epoch 001:   4666 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.1, ups=0.91, wpb=101.3, bsz=40, num_updates=4660, lr=7.84118e-05, gnorm=0.893, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5237
2022-09-30 09:58:23 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 09:58:32 - progress_bar.py[line:274] - INFO: epoch 001:   4677 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=82.5, ups=0.81, wpb=102, bsz=40, num_updates=4670, lr=7.84012e-05, gnorm=0.859, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=5249
2022-09-30 09:58:44 - progress_bar.py[line:274] - INFO: epoch 001:   4687 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.7, ups=0.9, wpb=101.8, bsz=40, num_updates=4680, lr=7.83907e-05, gnorm=0.749, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5260
2022-09-30 09:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   4697 / 15783 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92, ups=0.93, wpb=99.2, bsz=40, num_updates=4690, lr=7.83801e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5271
2022-09-30 09:59:06 - progress_bar.py[line:274] - INFO: epoch 001:   4707 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.89, wpb=101.4, bsz=40, num_updates=4700, lr=7.83696e-05, gnorm=0.904, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5282
2022-09-30 09:59:17 - progress_bar.py[line:274] - INFO: epoch 001:   4717 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.1, ups=0.9, wpb=101.9, bsz=40, num_updates=4710, lr=7.8359e-05, gnorm=0.878, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5293
2022-09-30 09:59:28 - progress_bar.py[line:274] - INFO: epoch 001:   4727 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.88, wpb=101.4, bsz=40, num_updates=4720, lr=7.83484e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5305
2022-09-30 09:59:39 - progress_bar.py[line:274] - INFO: epoch 001:   4737 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.7, ups=0.91, wpb=100.4, bsz=40, num_updates=4730, lr=7.83379e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5316
2022-09-30 09:59:51 - progress_bar.py[line:274] - INFO: epoch 001:   4747 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88, ups=0.87, wpb=101.4, bsz=40, num_updates=4740, lr=7.83273e-05, gnorm=0.684, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5327
2022-09-30 10:00:02 - progress_bar.py[line:274] - INFO: epoch 001:   4757 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=4750, lr=7.83168e-05, gnorm=0.788, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5339
2022-09-30 10:00:13 - progress_bar.py[line:274] - INFO: epoch 001:   4767 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.89, wpb=102, bsz=40, num_updates=4760, lr=7.83062e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5350
2022-09-30 10:00:24 - progress_bar.py[line:274] - INFO: epoch 001:   4777 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.2, ups=0.9, wpb=101, bsz=40, num_updates=4770, lr=7.82956e-05, gnorm=0.685, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5361
2022-09-30 10:00:35 - progress_bar.py[line:274] - INFO: epoch 001:   4787 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.4, ups=0.93, wpb=99.6, bsz=40, num_updates=4780, lr=7.82851e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5372
2022-09-30 10:00:46 - progress_bar.py[line:274] - INFO: epoch 001:   4797 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.89, wpb=100.5, bsz=40, num_updates=4790, lr=7.82745e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5383
2022-09-30 10:00:57 - progress_bar.py[line:274] - INFO: epoch 001:   4807 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.2, ups=0.9, wpb=103.3, bsz=40, num_updates=4800, lr=7.8264e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5394
2022-09-30 10:01:09 - progress_bar.py[line:274] - INFO: epoch 001:   4817 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.88, wpb=101.7, bsz=40, num_updates=4810, lr=7.82534e-05, gnorm=0.704, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5406
2022-09-30 10:01:20 - progress_bar.py[line:274] - INFO: epoch 001:   4827 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.4, ups=0.87, wpb=100.5, bsz=40, num_updates=4820, lr=7.82428e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5417
2022-09-30 10:01:31 - progress_bar.py[line:274] - INFO: epoch 001:   4837 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.8, ups=0.9, wpb=100.2, bsz=40, num_updates=4830, lr=7.82323e-05, gnorm=0.707, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5428
2022-09-30 10:01:43 - progress_bar.py[line:274] - INFO: epoch 001:   4847 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.2, ups=0.89, wpb=100.8, bsz=40, num_updates=4840, lr=7.82217e-05, gnorm=0.702, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5440
2022-09-30 10:01:54 - progress_bar.py[line:274] - INFO: epoch 001:   4857 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.9, wpb=99.8, bsz=40, num_updates=4850, lr=7.82112e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5451
2022-09-30 10:02:05 - progress_bar.py[line:274] - INFO: epoch 001:   4867 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.6, ups=0.88, wpb=101.5, bsz=40, num_updates=4860, lr=7.82006e-05, gnorm=0.787, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5462
2022-09-30 10:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   4877 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.5, ups=0.9, wpb=100.7, bsz=40, num_updates=4870, lr=7.81901e-05, gnorm=0.849, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5473
2022-09-30 10:02:28 - progress_bar.py[line:274] - INFO: epoch 001:   4887 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.4, ups=0.9, wpb=101.1, bsz=40, num_updates=4880, lr=7.81795e-05, gnorm=0.878, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5484
2022-09-30 10:02:38 - progress_bar.py[line:274] - INFO: epoch 001:   4897 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.92, wpb=99.8, bsz=40, num_updates=4890, lr=7.81689e-05, gnorm=0.835, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5495
2022-09-30 10:02:50 - progress_bar.py[line:274] - INFO: epoch 001:   4907 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=4900, lr=7.81584e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5506
2022-09-30 10:03:00 - progress_bar.py[line:274] - INFO: epoch 001:   4917 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.9, ups=0.93, wpb=101.8, bsz=40, num_updates=4910, lr=7.81478e-05, gnorm=0.709, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5517
2022-09-30 10:03:12 - progress_bar.py[line:274] - INFO: epoch 001:   4927 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.89, wpb=99.9, bsz=40, num_updates=4920, lr=7.81373e-05, gnorm=0.754, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5528
2022-09-30 10:03:23 - progress_bar.py[line:274] - INFO: epoch 001:   4937 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.4, ups=0.92, wpb=99.8, bsz=40, num_updates=4930, lr=7.81267e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5539
2022-09-30 10:03:34 - progress_bar.py[line:274] - INFO: epoch 001:   4947 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.4, ups=0.89, wpb=100.4, bsz=40, num_updates=4940, lr=7.81161e-05, gnorm=0.878, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5550
2022-09-30 10:03:45 - progress_bar.py[line:274] - INFO: epoch 001:   4957 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.87, wpb=102.7, bsz=40, num_updates=4950, lr=7.81056e-05, gnorm=0.867, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5562
2022-09-30 10:03:56 - progress_bar.py[line:274] - INFO: epoch 001:   4967 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.9, wpb=101.7, bsz=40, num_updates=4960, lr=7.8095e-05, gnorm=0.821, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5573
2022-09-30 10:04:08 - progress_bar.py[line:274] - INFO: epoch 001:   4977 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.8, ups=0.87, wpb=101.1, bsz=40, num_updates=4970, lr=7.80845e-05, gnorm=0.833, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5585
2022-09-30 10:04:19 - progress_bar.py[line:274] - INFO: epoch 001:   4987 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.5, ups=0.89, wpb=103.4, bsz=40, num_updates=4980, lr=7.80739e-05, gnorm=0.769, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5596
2022-09-30 10:04:31 - progress_bar.py[line:274] - INFO: epoch 001:   4997 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.8, ups=0.87, wpb=101.4, bsz=40, num_updates=4990, lr=7.80633e-05, gnorm=0.848, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5607
2022-09-30 10:04:42 - progress_bar.py[line:274] - INFO: epoch 001:   5007 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=5000, lr=7.80528e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5619
2022-09-30 10:04:53 - progress_bar.py[line:274] - INFO: epoch 001:   5017 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=5010, lr=7.80422e-05, gnorm=0.754, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5630
2022-09-30 10:05:04 - progress_bar.py[line:274] - INFO: epoch 001:   5027 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=5020, lr=7.80317e-05, gnorm=0.695, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5641
2022-09-30 10:05:16 - progress_bar.py[line:274] - INFO: epoch 001:   5037 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.2, ups=0.88, wpb=101.2, bsz=40, num_updates=5030, lr=7.80211e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=5653
2022-09-30 10:05:27 - progress_bar.py[line:274] - INFO: epoch 001:   5047 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93, ups=0.92, wpb=101.5, bsz=40, num_updates=5040, lr=7.80105e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5663
2022-09-30 10:05:38 - progress_bar.py[line:274] - INFO: epoch 001:   5057 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.6, ups=0.92, wpb=100.6, bsz=40, num_updates=5050, lr=7.8e-05, gnorm=0.777, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5674
2022-09-30 10:05:49 - progress_bar.py[line:274] - INFO: epoch 001:   5067 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88, ups=0.88, wpb=100.2, bsz=40, num_updates=5060, lr=7.79894e-05, gnorm=0.957, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5686
2022-09-30 10:06:00 - progress_bar.py[line:274] - INFO: epoch 001:   5077 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.8, ups=0.9, wpb=103, bsz=40, num_updates=5070, lr=7.79789e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5697
2022-09-30 10:06:11 - progress_bar.py[line:274] - INFO: epoch 001:   5087 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.1, ups=0.91, wpb=101.3, bsz=40, num_updates=5080, lr=7.79683e-05, gnorm=0.733, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5708
2022-09-30 10:06:22 - progress_bar.py[line:274] - INFO: epoch 001:   5097 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.9, ups=0.91, wpb=101.4, bsz=40, num_updates=5090, lr=7.79577e-05, gnorm=0.701, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5719
2022-09-30 10:06:33 - progress_bar.py[line:274] - INFO: epoch 001:   5107 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.7, ups=0.92, wpb=102.1, bsz=40, num_updates=5100, lr=7.79472e-05, gnorm=0.767, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5730
2022-09-30 10:06:44 - progress_bar.py[line:274] - INFO: epoch 001:   5117 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.9, ups=0.91, wpb=101.1, bsz=40, num_updates=5110, lr=7.79366e-05, gnorm=0.778, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5741
2022-09-30 10:06:55 - progress_bar.py[line:274] - INFO: epoch 001:   5127 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.2, ups=0.93, wpb=101.7, bsz=40, num_updates=5120, lr=7.79261e-05, gnorm=0.718, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5752
2022-09-30 10:07:06 - progress_bar.py[line:274] - INFO: epoch 001:   5137 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=86.7, ups=0.88, wpb=98.9, bsz=40, num_updates=5130, lr=7.79155e-05, gnorm=0.876, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5763
2022-09-30 10:07:17 - progress_bar.py[line:274] - INFO: epoch 001:   5147 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.4, ups=0.91, wpb=101.3, bsz=40, num_updates=5140, lr=7.79049e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5774
2022-09-30 10:07:29 - progress_bar.py[line:274] - INFO: epoch 001:   5157 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=5150, lr=7.78944e-05, gnorm=0.676, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5785
2022-09-30 10:07:40 - progress_bar.py[line:274] - INFO: epoch 001:   5167 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92, ups=0.91, wpb=101.4, bsz=40, num_updates=5160, lr=7.78838e-05, gnorm=0.645, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5796
2022-09-30 10:07:51 - progress_bar.py[line:274] - INFO: epoch 001:   5177 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=5170, lr=7.78733e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5808
2022-09-30 10:08:02 - progress_bar.py[line:274] - INFO: epoch 001:   5187 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.89, wpb=102.1, bsz=40, num_updates=5180, lr=7.78627e-05, gnorm=0.667, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5819
2022-09-30 10:08:14 - progress_bar.py[line:274] - INFO: epoch 001:   5197 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.4, ups=0.88, wpb=103.5, bsz=40, num_updates=5190, lr=7.78521e-05, gnorm=0.718, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5830
2022-09-30 10:08:25 - progress_bar.py[line:274] - INFO: epoch 001:   5207 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.88, wpb=101.4, bsz=40, num_updates=5200, lr=7.78416e-05, gnorm=0.773, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5842
2022-09-30 10:08:29 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 10:08:37 - progress_bar.py[line:274] - INFO: epoch 001:   5218 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=84.4, ups=0.82, wpb=102.3, bsz=40, num_updates=5210, lr=7.7831e-05, gnorm=0.827, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5854
2022-09-30 10:08:48 - progress_bar.py[line:274] - INFO: epoch 001:   5228 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.6, ups=0.91, wpb=102.4, bsz=40, num_updates=5220, lr=7.78205e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5865
2022-09-30 10:09:00 - progress_bar.py[line:274] - INFO: epoch 001:   5238 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88, ups=0.87, wpb=101.5, bsz=40, num_updates=5230, lr=7.78099e-05, gnorm=0.71, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5876
2022-09-30 10:09:11 - progress_bar.py[line:274] - INFO: epoch 001:   5248 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.7, ups=0.88, wpb=100.9, bsz=40, num_updates=5240, lr=7.77993e-05, gnorm=0.744, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5888
2022-09-30 10:09:22 - progress_bar.py[line:274] - INFO: epoch 001:   5258 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.8, ups=0.9, wpb=102.4, bsz=40, num_updates=5250, lr=7.77888e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5899
2022-09-30 10:09:33 - progress_bar.py[line:274] - INFO: epoch 001:   5268 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92, ups=0.92, wpb=100.2, bsz=40, num_updates=5260, lr=7.77782e-05, gnorm=0.813, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5910
2022-09-30 10:09:44 - progress_bar.py[line:274] - INFO: epoch 001:   5278 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.9, wpb=101.5, bsz=40, num_updates=5270, lr=7.77677e-05, gnorm=0.714, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5921
2022-09-30 10:09:55 - progress_bar.py[line:274] - INFO: epoch 001:   5288 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.9, wpb=101.5, bsz=40, num_updates=5280, lr=7.77571e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5932
2022-09-30 10:10:07 - progress_bar.py[line:274] - INFO: epoch 001:   5298 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.88, wpb=102, bsz=40, num_updates=5290, lr=7.77465e-05, gnorm=0.796, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5944
2022-09-30 10:10:18 - progress_bar.py[line:274] - INFO: epoch 001:   5308 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.1, ups=0.89, wpb=101.5, bsz=40, num_updates=5300, lr=7.7736e-05, gnorm=0.931, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5955
2022-09-30 10:10:29 - progress_bar.py[line:274] - INFO: epoch 001:   5318 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.1, ups=0.9, wpb=100.9, bsz=40, num_updates=5310, lr=7.77254e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5966
2022-09-30 10:10:40 - progress_bar.py[line:274] - INFO: epoch 001:   5328 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.9, wpb=100.4, bsz=40, num_updates=5320, lr=7.77149e-05, gnorm=0.769, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5977
2022-09-30 10:10:52 - progress_bar.py[line:274] - INFO: epoch 001:   5338 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.88, wpb=100.6, bsz=40, num_updates=5330, lr=7.77043e-05, gnorm=0.854, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5989
2022-09-30 10:11:03 - progress_bar.py[line:274] - INFO: epoch 001:   5348 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.8, ups=0.89, wpb=98.9, bsz=40, num_updates=5340, lr=7.76937e-05, gnorm=0.887, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6000
2022-09-30 10:11:14 - progress_bar.py[line:274] - INFO: epoch 001:   5358 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=5350, lr=7.76832e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6011
2022-09-30 10:11:26 - progress_bar.py[line:274] - INFO: epoch 001:   5368 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.6, ups=0.9, wpb=100, bsz=40, num_updates=5360, lr=7.76726e-05, gnorm=0.755, clip=0, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=6022
2022-09-30 10:11:37 - progress_bar.py[line:274] - INFO: epoch 001:   5378 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.1, ups=0.86, wpb=101, bsz=40, num_updates=5370, lr=7.76621e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6034
2022-09-30 10:11:48 - progress_bar.py[line:274] - INFO: epoch 001:   5388 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.8, ups=0.89, wpb=100.1, bsz=40, num_updates=5380, lr=7.76515e-05, gnorm=0.828, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6045
2022-09-30 10:12:00 - progress_bar.py[line:274] - INFO: epoch 001:   5398 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.88, wpb=101.1, bsz=40, num_updates=5390, lr=7.76409e-05, gnorm=0.813, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6057
2022-09-30 10:12:11 - progress_bar.py[line:274] - INFO: epoch 001:   5408 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.9, wpb=100.4, bsz=40, num_updates=5400, lr=7.76304e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6068
2022-09-30 10:12:22 - progress_bar.py[line:274] - INFO: epoch 001:   5418 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.3, ups=0.92, wpb=100.7, bsz=40, num_updates=5410, lr=7.76198e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6079
2022-09-30 10:12:33 - progress_bar.py[line:274] - INFO: epoch 001:   5428 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.89, wpb=100.6, bsz=40, num_updates=5420, lr=7.76093e-05, gnorm=0.792, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6090
2022-09-30 10:12:44 - progress_bar.py[line:274] - INFO: epoch 001:   5438 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.2, ups=0.91, wpb=100.2, bsz=40, num_updates=5430, lr=7.75987e-05, gnorm=0.917, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6101
2022-09-30 10:12:55 - progress_bar.py[line:274] - INFO: epoch 001:   5448 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.9, wpb=100.1, bsz=40, num_updates=5440, lr=7.75881e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6112
2022-09-30 10:13:06 - progress_bar.py[line:274] - INFO: epoch 001:   5458 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.8, ups=0.89, wpb=102.6, bsz=40, num_updates=5450, lr=7.75776e-05, gnorm=0.791, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6123
2022-09-30 10:13:18 - progress_bar.py[line:274] - INFO: epoch 001:   5468 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=101.1, bsz=40, num_updates=5460, lr=7.7567e-05, gnorm=0.717, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6134
2022-09-30 10:13:30 - progress_bar.py[line:274] - INFO: epoch 001:   5478 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89, ups=0.88, wpb=100.7, bsz=40, num_updates=5470, lr=7.75565e-05, gnorm=0.795, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6146
2022-09-30 10:13:41 - progress_bar.py[line:274] - INFO: epoch 001:   5488 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.4, ups=0.87, wpb=99.8, bsz=40, num_updates=5480, lr=7.75459e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6158
2022-09-30 10:13:52 - progress_bar.py[line:274] - INFO: epoch 001:   5498 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=100.3, bsz=40, num_updates=5490, lr=7.75353e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6169
2022-09-30 10:14:03 - progress_bar.py[line:274] - INFO: epoch 001:   5508 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.3, ups=0.91, wpb=102.7, bsz=40, num_updates=5500, lr=7.75248e-05, gnorm=0.798, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6180
2022-09-30 10:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   5518 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.7, ups=0.88, wpb=101.5, bsz=40, num_updates=5510, lr=7.75142e-05, gnorm=0.802, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6192
2022-09-30 10:14:26 - progress_bar.py[line:274] - INFO: epoch 001:   5528 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.88, wpb=101.5, bsz=40, num_updates=5520, lr=7.75037e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6203
2022-09-30 10:14:37 - progress_bar.py[line:274] - INFO: epoch 001:   5538 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.7, ups=0.91, wpb=102.2, bsz=40, num_updates=5530, lr=7.74931e-05, gnorm=0.767, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6214
2022-09-30 10:14:48 - progress_bar.py[line:274] - INFO: epoch 001:   5548 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.3, ups=0.9, wpb=100.9, bsz=40, num_updates=5540, lr=7.74825e-05, gnorm=0.703, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6225
2022-09-30 10:14:59 - progress_bar.py[line:274] - INFO: epoch 001:   5558 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.2, ups=0.9, wpb=102.3, bsz=40, num_updates=5550, lr=7.7472e-05, gnorm=0.812, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6236
2022-09-30 10:15:11 - progress_bar.py[line:274] - INFO: epoch 001:   5568 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.6, ups=0.88, wpb=101, bsz=40, num_updates=5560, lr=7.74614e-05, gnorm=0.8, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6248
2022-09-30 10:15:23 - progress_bar.py[line:274] - INFO: epoch 001:   5578 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.8, ups=0.87, wpb=102, bsz=40, num_updates=5570, lr=7.74509e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6259
2022-09-30 10:15:34 - progress_bar.py[line:274] - INFO: epoch 001:   5588 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.9, ups=0.9, wpb=100.3, bsz=40, num_updates=5580, lr=7.74403e-05, gnorm=0.756, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6271
2022-09-30 10:15:45 - progress_bar.py[line:274] - INFO: epoch 001:   5598 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.6, ups=0.88, wpb=101.2, bsz=40, num_updates=5590, lr=7.74297e-05, gnorm=0.739, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6282
2022-09-30 10:15:57 - progress_bar.py[line:274] - INFO: epoch 001:   5608 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.8, ups=0.89, wpb=99, bsz=40, num_updates=5600, lr=7.74192e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6293
2022-09-30 10:16:08 - progress_bar.py[line:274] - INFO: epoch 001:   5618 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.88, wpb=100.7, bsz=40, num_updates=5610, lr=7.74086e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6305
2022-09-30 10:16:19 - progress_bar.py[line:274] - INFO: epoch 001:   5628 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=5620, lr=7.73981e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6316
2022-09-30 10:16:30 - progress_bar.py[line:274] - INFO: epoch 001:   5638 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.5, ups=0.88, wpb=101, bsz=40, num_updates=5630, lr=7.73875e-05, gnorm=0.762, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6327
2022-09-30 10:16:42 - progress_bar.py[line:274] - INFO: epoch 001:   5648 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.89, wpb=100.8, bsz=40, num_updates=5640, lr=7.73769e-05, gnorm=0.736, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6339
2022-09-30 10:16:53 - progress_bar.py[line:274] - INFO: epoch 001:   5658 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.7, ups=0.87, wpb=100.4, bsz=40, num_updates=5650, lr=7.73664e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6350
2022-09-30 10:17:04 - progress_bar.py[line:274] - INFO: epoch 001:   5668 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.89, wpb=101.9, bsz=40, num_updates=5660, lr=7.73558e-05, gnorm=0.761, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6361
2022-09-30 10:17:16 - progress_bar.py[line:274] - INFO: epoch 001:   5678 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.1, ups=0.88, wpb=101.1, bsz=40, num_updates=5670, lr=7.73453e-05, gnorm=0.648, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6373
2022-09-30 10:17:27 - progress_bar.py[line:274] - INFO: epoch 001:   5688 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.92, wpb=101.3, bsz=40, num_updates=5680, lr=7.73347e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6383
2022-09-30 10:17:38 - progress_bar.py[line:274] - INFO: epoch 001:   5698 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.4, ups=0.92, wpb=103, bsz=40, num_updates=5690, lr=7.73241e-05, gnorm=0.759, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6394
2022-09-30 10:17:49 - progress_bar.py[line:274] - INFO: epoch 001:   5708 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.7, ups=0.9, wpb=101.3, bsz=40, num_updates=5700, lr=7.73136e-05, gnorm=0.815, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6406
2022-09-30 10:18:00 - progress_bar.py[line:274] - INFO: epoch 001:   5718 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.87, wpb=101.2, bsz=40, num_updates=5710, lr=7.7303e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6417
2022-09-30 10:18:11 - progress_bar.py[line:274] - INFO: epoch 001:   5728 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.7, ups=0.93, wpb=102.4, bsz=40, num_updates=5720, lr=7.72925e-05, gnorm=0.763, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6428
2022-09-30 10:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   5738 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=5730, lr=7.72819e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6439
2022-09-30 10:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=102, bsz=40, num_updates=5740, lr=7.72713e-05, gnorm=0.822, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6450
2022-09-30 10:18:45 - progress_bar.py[line:274] - INFO: epoch 001:   5758 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92, ups=0.9, wpb=101.7, bsz=40, num_updates=5750, lr=7.72608e-05, gnorm=0.756, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6461
2022-09-30 10:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   5768 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.8, ups=0.91, wpb=99.6, bsz=40, num_updates=5760, lr=7.72502e-05, gnorm=0.741, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6472
2022-09-30 10:19:06 - progress_bar.py[line:274] - INFO: epoch 001:   5778 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.8, ups=0.92, wpb=102.7, bsz=40, num_updates=5770, lr=7.72397e-05, gnorm=0.668, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6483
2022-09-30 10:19:18 - progress_bar.py[line:274] - INFO: epoch 001:   5788 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.9, ups=0.87, wpb=100.6, bsz=40, num_updates=5780, lr=7.72291e-05, gnorm=0.836, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6495
2022-09-30 10:19:29 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.6, ups=0.92, wpb=101.6, bsz=40, num_updates=5790, lr=7.72185e-05, gnorm=0.873, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6506
2022-09-30 10:19:40 - progress_bar.py[line:274] - INFO: epoch 001:   5808 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.1, ups=0.9, wpb=103.6, bsz=40, num_updates=5800, lr=7.7208e-05, gnorm=0.801, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6517
2022-09-30 10:19:51 - progress_bar.py[line:274] - INFO: epoch 001:   5818 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.9, wpb=99, bsz=40, num_updates=5810, lr=7.71974e-05, gnorm=0.654, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6528
2022-09-30 10:20:02 - progress_bar.py[line:274] - INFO: epoch 001:   5828 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93, ups=0.94, wpb=98.9, bsz=40, num_updates=5820, lr=7.71869e-05, gnorm=0.818, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6538
2022-09-30 10:20:13 - progress_bar.py[line:274] - INFO: epoch 001:   5838 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.9, ups=0.89, wpb=100.5, bsz=40, num_updates=5830, lr=7.71763e-05, gnorm=0.76, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6550
2022-09-30 10:20:24 - progress_bar.py[line:274] - INFO: epoch 001:   5848 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.2, ups=0.89, wpb=100.3, bsz=40, num_updates=5840, lr=7.71657e-05, gnorm=0.738, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6561
2022-09-30 10:20:35 - progress_bar.py[line:274] - INFO: epoch 001:   5858 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.91, wpb=102.2, bsz=40, num_updates=5850, lr=7.71552e-05, gnorm=0.683, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6572
2022-09-30 10:20:47 - progress_bar.py[line:274] - INFO: epoch 001:   5868 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.3, ups=0.88, wpb=99.7, bsz=40, num_updates=5860, lr=7.71446e-05, gnorm=0.83, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6583
2022-09-30 10:20:58 - progress_bar.py[line:274] - INFO: epoch 001:   5878 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.4, ups=0.91, wpb=100.1, bsz=40, num_updates=5870, lr=7.71341e-05, gnorm=0.76, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6594
2022-09-30 10:21:09 - progress_bar.py[line:274] - INFO: epoch 001:   5888 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.7, ups=0.89, wpb=102.2, bsz=40, num_updates=5880, lr=7.71235e-05, gnorm=0.715, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6606
2022-09-30 10:21:20 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.4, ups=0.86, wpb=101.3, bsz=40, num_updates=5890, lr=7.7113e-05, gnorm=0.699, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=6617
2022-09-30 10:21:32 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.9, ups=0.86, wpb=100.8, bsz=40, num_updates=5900, lr=7.71024e-05, gnorm=0.894, clip=40, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=6629
2022-09-30 10:21:43 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.89, wpb=100.5, bsz=40, num_updates=5910, lr=7.70918e-05, gnorm=0.743, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6640
2022-09-30 10:21:55 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90, ups=0.88, wpb=102.3, bsz=40, num_updates=5920, lr=7.70813e-05, gnorm=0.656, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6651
2022-09-30 10:22:06 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=5930, lr=7.70707e-05, gnorm=0.709, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6663
2022-09-30 10:22:17 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.6, ups=0.89, wpb=102.3, bsz=40, num_updates=5940, lr=7.70602e-05, gnorm=0.727, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6674
2022-09-30 10:22:28 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.9, wpb=101.7, bsz=40, num_updates=5950, lr=7.70496e-05, gnorm=0.819, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6685
2022-09-30 10:22:40 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=5960, lr=7.7039e-05, gnorm=0.746, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6696
2022-09-30 10:22:51 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.86, wpb=102.1, bsz=40, num_updates=5970, lr=7.70285e-05, gnorm=0.791, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6708
2022-09-30 10:23:03 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.88, wpb=102.6, bsz=40, num_updates=5980, lr=7.70179e-05, gnorm=0.749, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6719
2022-09-30 10:23:14 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.2, ups=0.89, wpb=101.8, bsz=40, num_updates=5990, lr=7.70074e-05, gnorm=0.756, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6731
2022-09-30 10:23:25 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.89, wpb=103.2, bsz=40, num_updates=6000, lr=7.69968e-05, gnorm=0.706, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6742
2022-09-30 10:23:25 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-30 10:23:25 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-30 10:23:26 - train.py[line:549] - INFO: 0 / 14103
2022-09-30 10:23:26 - train.py[line:551] - INFO: load:0.74 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-30 10:26:43 - train.py[line:549] - INFO: 200 / 14103
2022-09-30 10:26:43 - train.py[line:551] - INFO: load:0.76 valid_run:197.04 task_valid:188.12 collect_output:7.73
2022-09-30 10:29:52 - train.py[line:549] - INFO: 400 / 14103
2022-09-30 10:29:52 - train.py[line:551] - INFO: load:0.78 valid_run:385.64 task_valid:371.86 collect_output:11.33
2022-09-30 10:33:01 - train.py[line:549] - INFO: 600 / 14103
2022-09-30 10:33:01 - train.py[line:551] - INFO: load:0.80 valid_run:574.78 task_valid:554.93 collect_output:16.23
2022-09-30 10:36:10 - train.py[line:549] - INFO: 800 / 14103
2022-09-30 10:36:10 - train.py[line:551] - INFO: load:0.83 valid_run:763.82 task_valid:739.72 collect_output:19.34
2022-09-30 10:39:20 - train.py[line:549] - INFO: 1000 / 14103
2022-09-30 10:39:20 - train.py[line:551] - INFO: load:0.85 valid_run:953.96 task_valid:925.19 collect_output:22.94
2022-09-30 10:42:33 - train.py[line:549] - INFO: 1200 / 14103
2022-09-30 10:42:33 - train.py[line:551] - INFO: load:0.87 valid_run:1146.66 task_valid:1112.00 collect_output:27.72
2022-09-30 10:45:46 - train.py[line:549] - INFO: 1400 / 14103
2022-09-30 10:45:46 - train.py[line:551] - INFO: load:0.89 valid_run:1339.79 task_valid:1300.37 collect_output:31.24
2022-09-30 10:48:58 - train.py[line:549] - INFO: 1600 / 14103
2022-09-30 10:48:58 - train.py[line:551] - INFO: load:0.92 valid_run:1531.77 task_valid:1488.44 collect_output:34.06
2022-09-30 10:52:11 - train.py[line:549] - INFO: 1800 / 14103
2022-09-30 10:52:11 - train.py[line:551] - INFO: load:0.94 valid_run:1723.81 task_valid:1673.80 collect_output:39.62
2022-09-30 10:55:19 - train.py[line:549] - INFO: 2000 / 14103
2022-09-30 10:55:19 - train.py[line:551] - INFO: load:0.96 valid_run:1911.89 task_valid:1858.74 collect_output:41.66
2022-09-30 10:58:27 - train.py[line:549] - INFO: 2200 / 14103
2022-09-30 10:58:27 - train.py[line:551] - INFO: load:0.98 valid_run:2099.94 task_valid:2043.02 collect_output:44.27
2022-09-30 11:01:38 - train.py[line:549] - INFO: 2400 / 14103
2022-09-30 11:01:38 - train.py[line:551] - INFO: load:1.01 valid_run:2290.67 task_valid:2227.16 collect_output:49.71
2022-09-30 11:04:50 - train.py[line:549] - INFO: 2600 / 14103
2022-09-30 11:04:50 - train.py[line:551] - INFO: load:1.03 valid_run:2482.92 task_valid:2415.79 collect_output:52.26
2022-09-30 11:07:59 - train.py[line:549] - INFO: 2800 / 14103
2022-09-30 11:07:59 - train.py[line:551] - INFO: load:1.05 valid_run:2671.92 task_valid:2599.64 collect_output:56.38
2022-09-30 11:11:12 - train.py[line:549] - INFO: 3000 / 14103
2022-09-30 11:11:12 - train.py[line:551] - INFO: load:1.08 valid_run:2864.66 task_valid:2785.44 collect_output:62.19
2022-09-30 11:14:21 - train.py[line:549] - INFO: 3200 / 14103
2022-09-30 11:14:21 - train.py[line:551] - INFO: load:1.10 valid_run:3053.49 task_valid:2967.86 collect_output:67.39
2022-09-30 11:17:33 - train.py[line:549] - INFO: 3400 / 14103
2022-09-30 11:17:33 - train.py[line:551] - INFO: load:1.12 valid_run:3245.90 task_valid:3151.82 collect_output:74.64
2022-09-30 11:20:46 - train.py[line:549] - INFO: 3600 / 14103
2022-09-30 11:20:46 - train.py[line:551] - INFO: load:1.14 valid_run:3438.35 task_valid:3337.30 collect_output:80.42
2022-09-30 11:23:56 - train.py[line:549] - INFO: 3800 / 14103
2022-09-30 11:23:56 - train.py[line:551] - INFO: load:1.17 valid_run:3629.11 task_valid:3519.72 collect_output:87.56
2022-09-30 11:27:04 - train.py[line:549] - INFO: 4000 / 14103
2022-09-30 11:27:04 - train.py[line:551] - INFO: load:1.19 valid_run:3817.06 task_valid:3702.55 collect_output:91.49
2022-09-30 11:30:16 - train.py[line:549] - INFO: 4200 / 14103
2022-09-30 11:30:16 - train.py[line:551] - INFO: load:1.21 valid_run:4008.19 task_valid:3891.00 collect_output:93.02
2022-09-30 11:33:24 - train.py[line:549] - INFO: 4400 / 14103
2022-09-30 11:33:24 - train.py[line:551] - INFO: load:1.24 valid_run:4196.02 task_valid:4071.70 collect_output:98.89
2022-09-30 11:36:35 - train.py[line:549] - INFO: 4600 / 14103
2022-09-30 11:36:35 - train.py[line:551] - INFO: load:1.26 valid_run:4387.60 task_valid:4256.63 collect_output:104.34
2022-09-30 11:39:43 - train.py[line:549] - INFO: 4800 / 14103
2022-09-30 11:39:43 - train.py[line:551] - INFO: load:1.28 valid_run:4575.79 task_valid:4439.86 collect_output:108.09
2022-09-30 11:42:53 - train.py[line:549] - INFO: 5000 / 14103
2022-09-30 11:42:53 - train.py[line:551] - INFO: load:1.31 valid_run:4765.32 task_valid:4624.49 collect_output:111.72
2022-09-30 11:46:02 - train.py[line:549] - INFO: 5200 / 14103
2022-09-30 11:46:02 - train.py[line:551] - INFO: load:1.33 valid_run:4953.85 task_valid:4807.80 collect_output:115.83
2022-09-30 11:49:13 - train.py[line:549] - INFO: 5400 / 14103
2022-09-30 11:49:13 - train.py[line:551] - INFO: load:1.36 valid_run:5145.28 task_valid:4996.05 collect_output:117.89
2022-09-30 11:52:24 - train.py[line:549] - INFO: 5600 / 14103
2022-09-30 11:52:24 - train.py[line:551] - INFO: load:1.38 valid_run:5335.91 task_valid:5182.67 collect_output:120.83
2022-09-30 11:55:36 - train.py[line:549] - INFO: 5800 / 14103
2022-09-30 11:55:36 - train.py[line:551] - INFO: load:1.40 valid_run:5528.32 task_valid:5368.67 collect_output:126.08
2022-09-30 11:58:43 - train.py[line:549] - INFO: 6000 / 14103
2022-09-30 11:58:43 - train.py[line:551] - INFO: load:1.42 valid_run:5715.02 task_valid:5548.91 collect_output:131.47
2022-09-30 12:01:54 - train.py[line:549] - INFO: 6200 / 14103
2022-09-30 12:01:54 - train.py[line:551] - INFO: load:1.45 valid_run:5905.95 task_valid:5733.71 collect_output:136.49
2022-09-30 12:05:03 - train.py[line:549] - INFO: 6400 / 14103
2022-09-30 12:05:03 - train.py[line:551] - INFO: load:1.47 valid_run:6094.90 task_valid:5918.32 collect_output:139.71
2022-09-30 12:08:11 - train.py[line:549] - INFO: 6600 / 14103
2022-09-30 12:08:11 - train.py[line:551] - INFO: load:1.49 valid_run:6282.84 task_valid:6099.03 collect_output:145.81
2022-09-30 12:11:23 - train.py[line:549] - INFO: 6800 / 14103
2022-09-30 12:11:23 - train.py[line:551] - INFO: load:1.52 valid_run:6474.65 task_valid:6282.36 collect_output:153.12
2022-09-30 12:14:35 - train.py[line:549] - INFO: 7000 / 14103
2022-09-30 12:14:35 - train.py[line:551] - INFO: load:1.54 valid_run:6666.73 task_valid:6470.65 collect_output:155.67
2022-09-30 12:17:47 - train.py[line:549] - INFO: 7200 / 14103
2022-09-30 12:17:47 - train.py[line:551] - INFO: load:1.57 valid_run:6858.76 task_valid:6659.55 collect_output:157.63
2022-09-30 12:20:57 - train.py[line:549] - INFO: 7400 / 14103
2022-09-30 12:20:57 - train.py[line:551] - INFO: load:1.59 valid_run:7048.63 task_valid:6840.94 collect_output:164.90
2022-09-30 12:24:05 - train.py[line:549] - INFO: 7600 / 14103
2022-09-30 12:24:05 - train.py[line:551] - INFO: load:1.61 valid_run:7236.51 task_valid:7021.13 collect_output:171.40
2022-09-30 12:27:19 - train.py[line:549] - INFO: 7800 / 14103
2022-09-30 12:27:19 - train.py[line:551] - INFO: load:1.64 valid_run:7430.16 task_valid:7207.34 collect_output:177.69
2022-09-30 12:30:27 - train.py[line:549] - INFO: 8000 / 14103
2022-09-30 12:30:27 - train.py[line:551] - INFO: load:1.66 valid_run:7618.90 task_valid:7386.31 collect_output:186.31
2022-09-30 12:33:36 - train.py[line:549] - INFO: 8200 / 14103
2022-09-30 12:33:36 - train.py[line:551] - INFO: load:1.68 valid_run:7807.56 task_valid:7569.73 collect_output:190.34
2022-09-30 12:36:44 - train.py[line:549] - INFO: 8400 / 14103
2022-09-30 12:36:44 - train.py[line:551] - INFO: load:1.71 valid_run:7995.45 task_valid:7752.33 collect_output:194.43
2022-09-30 12:39:55 - train.py[line:549] - INFO: 8600 / 14103
2022-09-30 12:39:55 - train.py[line:551] - INFO: load:1.74 valid_run:8185.77 task_valid:7937.03 collect_output:198.81
2022-09-30 12:43:03 - train.py[line:549] - INFO: 8800 / 14103
2022-09-30 12:43:03 - train.py[line:551] - INFO: load:1.76 valid_run:8374.51 task_valid:8122.17 collect_output:201.25
2022-09-30 12:46:14 - train.py[line:549] - INFO: 9000 / 14103
2022-09-30 12:46:14 - train.py[line:551] - INFO: load:1.78 valid_run:8565.06 task_valid:8305.79 collect_output:207.06
2022-09-30 12:49:27 - train.py[line:549] - INFO: 9200 / 14103
2022-09-30 12:49:27 - train.py[line:551] - INFO: load:1.81 valid_run:8758.45 task_valid:8488.72 collect_output:216.42
2022-09-30 12:52:40 - train.py[line:549] - INFO: 9400 / 14103
2022-09-30 12:52:40 - train.py[line:551] - INFO: load:1.83 valid_run:8950.95 task_valid:8675.58 collect_output:220.86
2022-09-30 12:55:50 - train.py[line:549] - INFO: 9600 / 14103
2022-09-30 12:55:50 - train.py[line:551] - INFO: load:1.86 valid_run:9140.72 task_valid:8858.95 collect_output:226.18
2022-09-30 12:59:00 - train.py[line:549] - INFO: 9800 / 14103
2022-09-30 12:59:00 - train.py[line:551] - INFO: load:1.88 valid_run:9330.56 task_valid:9046.39 collect_output:227.54
2022-09-30 13:02:10 - train.py[line:549] - INFO: 10000 / 14103
2022-09-30 13:02:10 - train.py[line:551] - INFO: load:1.90 valid_run:9520.99 task_valid:9233.87 collect_output:229.45
2022-09-30 13:05:20 - train.py[line:549] - INFO: 10200 / 14103
2022-09-30 13:05:20 - train.py[line:551] - INFO: load:1.92 valid_run:9710.28 task_valid:9416.14 collect_output:235.41
2022-09-30 13:08:30 - train.py[line:549] - INFO: 10400 / 14103
2022-09-30 13:08:30 - train.py[line:551] - INFO: load:1.95 valid_run:9900.95 task_valid:9599.39 collect_output:241.74
2022-09-30 13:11:42 - train.py[line:549] - INFO: 10600 / 14103
2022-09-30 13:11:42 - train.py[line:551] - INFO: load:1.97 valid_run:10092.16 task_valid:9781.12 collect_output:250.06
2022-09-30 13:14:53 - train.py[line:549] - INFO: 10800 / 14103
2022-09-30 13:14:53 - train.py[line:551] - INFO: load:1.99 valid_run:10283.19 task_valid:9964.45 collect_output:256.57
2022-09-30 13:18:07 - train.py[line:549] - INFO: 11000 / 14103
2022-09-30 13:18:07 - train.py[line:551] - INFO: load:2.02 valid_run:10477.70 task_valid:10150.87 collect_output:263.39
2022-09-30 13:21:25 - train.py[line:549] - INFO: 11200 / 14103
2022-09-30 13:21:25 - train.py[line:551] - INFO: load:2.04 valid_run:10675.08 task_valid:10339.35 collect_output:270.93
2022-09-30 13:24:49 - train.py[line:549] - INFO: 11400 / 14103
2022-09-30 13:24:49 - train.py[line:551] - INFO: load:2.08 valid_run:10879.33 task_valid:10537.12 collect_output:275.99
2022-09-30 13:28:09 - train.py[line:549] - INFO: 11600 / 14103
2022-09-30 13:28:09 - train.py[line:551] - INFO: load:2.11 valid_run:11079.15 task_valid:10727.81 collect_output:283.64
2022-09-30 13:31:29 - train.py[line:549] - INFO: 11800 / 14103
2022-09-30 13:31:29 - train.py[line:551] - INFO: load:2.14 valid_run:11279.24 task_valid:10918.07 collect_output:292.14
2022-09-30 13:34:46 - train.py[line:549] - INFO: 12000 / 14103
2022-09-30 13:34:46 - train.py[line:551] - INFO: load:2.18 valid_run:11476.43 task_valid:11108.77 collect_output:297.24
2022-09-30 13:38:05 - train.py[line:549] - INFO: 12200 / 14103
2022-09-30 13:38:05 - train.py[line:551] - INFO: load:2.22 valid_run:11674.73 task_valid:11299.69 collect_output:303.26
2022-09-30 13:41:26 - train.py[line:549] - INFO: 12400 / 14103
2022-09-30 13:41:26 - train.py[line:551] - INFO: load:2.26 valid_run:11876.48 task_valid:11491.83 collect_output:311.32
2022-09-30 13:44:47 - train.py[line:549] - INFO: 12600 / 14103
2022-09-30 13:44:47 - train.py[line:551] - INFO: load:2.29 valid_run:12076.81 task_valid:11682.37 collect_output:319.53
2022-09-30 13:48:05 - train.py[line:549] - INFO: 12800 / 14103
2022-09-30 13:48:05 - train.py[line:551] - INFO: load:2.33 valid_run:12274.79 task_valid:11871.61 collect_output:326.62
2022-09-30 13:51:21 - train.py[line:549] - INFO: 13000 / 14103
2022-09-30 13:51:21 - train.py[line:551] - INFO: load:2.36 valid_run:12471.17 task_valid:12060.56 collect_output:332.86
2022-09-30 13:54:41 - train.py[line:549] - INFO: 13200 / 14103
2022-09-30 13:54:41 - train.py[line:551] - INFO: load:2.43 valid_run:12670.34 task_valid:12248.89 collect_output:342.36
2022-09-30 13:58:03 - train.py[line:549] - INFO: 13400 / 14103
2022-09-30 13:58:03 - train.py[line:551] - INFO: load:2.45 valid_run:12872.22 task_valid:12436.75 collect_output:355.18
2022-09-30 14:01:12 - train.py[line:549] - INFO: 13600 / 14103
2022-09-30 14:01:12 - train.py[line:551] - INFO: load:2.48 valid_run:13061.85 task_valid:12618.21 collect_output:362.25
2022-09-30 14:04:26 - train.py[line:549] - INFO: 13800 / 14103
2022-09-30 14:04:26 - train.py[line:551] - INFO: load:2.51 valid_run:13255.41 task_valid:12805.93 collect_output:367.00
2022-09-30 14:07:37 - train.py[line:549] - INFO: 14000 / 14103
2022-09-30 14:07:37 - train.py[line:551] - INFO: load:2.54 valid_run:13446.28 task_valid:12990.72 collect_output:372.01
2022-09-30 14:09:13 - train.py[line:572] - INFO: scores:torch.Size([282060]) preds:torch.Size([282060]) sample_ids:torch.Size([282060])

====================================================================================================
SGG eval:     R @ 50: 0.5977;     R @ 100: 0.6267;     R @ 500: 0.6422;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1215;    mR @ 100: 0.1454;    mR @ 500: 0.1746;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0252) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2821) (attached to:0.0000) (behind:0.3167) (belonging to:0.0000) (between:0.0000) (carrying:0.6488) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.7270) (holding:0.2674) (in:0.3043) (in front of:0.0588) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3775) (of:0.3935) (on:0.9104) (on back of:0.0000) (over:0.0556) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1667) (says:0.0000) (sitting on:0.1885) (standing on:0.0000) (to:0.0000) (under:0.2315) (using:1.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.9806) (wears:0.0000) (with:0.0845) 
--------------------------------------------------------
====================================================================================================

2022-09-30 14:09:33 - train.py[line:486] - INFO: 0.6267049316041607

====================================================================================================
SGG eval:     R @ 50: 0.5977;     R @ 100: 0.6267;     R @ 500: 0.6422;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1215;    mR @ 100: 0.1454;    mR @ 500: 0.1746;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0252) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2821) (attached to:0.0000) (behind:0.3167) (belonging to:0.0000) (between:0.0000) (carrying:0.6488) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.7270) (holding:0.2674) (in:0.3043) (in front of:0.0588) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3775) (of:0.3935) (on:0.9104) (on back of:0.0000) (over:0.0556) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1667) (says:0.0000) (sitting on:0.1885) (standing on:0.0000) (to:0.0000) (under:0.2315) (using:1.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.9806) (wears:0.0000) (with:0.0845) 
--------------------------------------------------------
====================================================================================================

2022-09-30 14:09:33 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.302 | loss_v1 0 | loss_v2 0 | nll_loss 0.103 | ntokens 59.526 | nsentences 20 | sample_size 59.526 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.626705 | ppl 1.07 | vqa_score 0.8971 | wps 61.9 | wpb 59.5 | bsz 20 | num_updates 6000
2022-09-30 14:09:33 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-09-30 14:09:33 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480/checkpoint_1_6000.pt
2022-09-30 14:09:38 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480/checkpoint_1_6000.pt
2022-09-30 14:09:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6267049316041607) (writing took 10.039182140957564 seconds)
2022-09-30 14:09:54 - progress_bar.py[line:274] - INFO: epoch 001:   6018 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=0.1, ups=0, wpb=100.9, bsz=40, num_updates=6010, lr=7.69862e-05, gnorm=0.858, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20331
2022-09-30 14:10:05 - progress_bar.py[line:274] - INFO: epoch 001:   6028 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.4, ups=0.89, wpb=102.2, bsz=40, num_updates=6020, lr=7.69757e-05, gnorm=0.731, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20342
2022-09-30 14:10:17 - progress_bar.py[line:274] - INFO: epoch 001:   6038 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.2, ups=0.87, wpb=101.8, bsz=40, num_updates=6030, lr=7.69651e-05, gnorm=0.684, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20354
2022-09-30 14:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   6048 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=6040, lr=7.69546e-05, gnorm=0.8, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20365
2022-09-30 14:10:39 - progress_bar.py[line:274] - INFO: epoch 001:   6058 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=6050, lr=7.6944e-05, gnorm=0.843, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20376
2022-09-30 14:10:51 - progress_bar.py[line:274] - INFO: epoch 001:   6068 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.7, ups=0.89, wpb=101.8, bsz=40, num_updates=6060, lr=7.69334e-05, gnorm=0.717, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20387
2022-09-30 14:11:02 - progress_bar.py[line:274] - INFO: epoch 001:   6078 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.88, wpb=100, bsz=40, num_updates=6070, lr=7.69229e-05, gnorm=0.85, clip=10, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20399
2022-09-30 14:11:13 - progress_bar.py[line:274] - INFO: epoch 001:   6088 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.91, wpb=100.9, bsz=40, num_updates=6080, lr=7.69123e-05, gnorm=0.727, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20410
2022-09-30 14:11:24 - progress_bar.py[line:274] - INFO: epoch 001:   6098 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.88, wpb=103.1, bsz=40, num_updates=6090, lr=7.69018e-05, gnorm=0.63, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20421
2022-09-30 14:11:36 - progress_bar.py[line:274] - INFO: epoch 001:   6108 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.2, ups=0.89, wpb=100.1, bsz=40, num_updates=6100, lr=7.68912e-05, gnorm=0.717, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20432
2022-09-30 14:11:47 - progress_bar.py[line:274] - INFO: epoch 001:   6118 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.5, ups=0.88, wpb=99.9, bsz=40, num_updates=6110, lr=7.68806e-05, gnorm=0.776, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20444
2022-09-30 14:11:58 - progress_bar.py[line:274] - INFO: epoch 001:   6128 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.6, ups=0.87, wpb=99.6, bsz=40, num_updates=6120, lr=7.68701e-05, gnorm=0.771, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20455
2022-09-30 14:12:10 - progress_bar.py[line:274] - INFO: epoch 001:   6138 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.87, wpb=103, bsz=40, num_updates=6130, lr=7.68595e-05, gnorm=0.676, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20467
2022-09-30 14:12:21 - progress_bar.py[line:274] - INFO: epoch 001:   6148 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.9, wpb=101.3, bsz=40, num_updates=6140, lr=7.6849e-05, gnorm=0.675, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20478
2022-09-30 14:12:32 - progress_bar.py[line:274] - INFO: epoch 001:   6158 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.3, ups=0.89, wpb=99.2, bsz=40, num_updates=6150, lr=7.68384e-05, gnorm=0.719, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20489
2022-09-30 14:12:44 - progress_bar.py[line:274] - INFO: epoch 001:   6168 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.3, ups=0.89, wpb=102.8, bsz=40, num_updates=6160, lr=7.68278e-05, gnorm=0.682, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=20500
2022-09-30 14:12:55 - progress_bar.py[line:274] - INFO: epoch 001:   6178 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.2, ups=0.89, wpb=101, bsz=40, num_updates=6170, lr=7.68173e-05, gnorm=0.754, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20512
2022-09-30 14:13:06 - progress_bar.py[line:274] - INFO: epoch 001:   6188 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.7, ups=0.91, wpb=103.4, bsz=40, num_updates=6180, lr=7.68067e-05, gnorm=0.716, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20523
2022-09-30 14:13:17 - progress_bar.py[line:274] - INFO: epoch 001:   6198 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.88, wpb=103.5, bsz=40, num_updates=6190, lr=7.67962e-05, gnorm=0.681, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20534
2022-09-30 14:13:28 - progress_bar.py[line:274] - INFO: epoch 001:   6208 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.89, wpb=101.1, bsz=40, num_updates=6200, lr=7.67856e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20545
2022-09-30 14:13:40 - progress_bar.py[line:274] - INFO: epoch 001:   6218 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.89, wpb=99.2, bsz=40, num_updates=6210, lr=7.6775e-05, gnorm=0.766, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20556
2022-09-30 14:13:51 - progress_bar.py[line:274] - INFO: epoch 001:   6228 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.6, ups=0.92, wpb=101.7, bsz=40, num_updates=6220, lr=7.67645e-05, gnorm=0.735, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20567
2022-09-30 14:14:02 - progress_bar.py[line:274] - INFO: epoch 001:   6238 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.7, ups=0.87, wpb=101.9, bsz=40, num_updates=6230, lr=7.67539e-05, gnorm=0.766, clip=10, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20579
2022-09-30 14:14:08 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 14:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   6249 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=80.9, ups=0.8, wpb=101.7, bsz=40, num_updates=6240, lr=7.67434e-05, gnorm=0.713, clip=0, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=20591
2022-09-30 14:14:26 - progress_bar.py[line:274] - INFO: epoch 001:   6259 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.1, ups=0.92, wpb=102.5, bsz=40, num_updates=6250, lr=7.67328e-05, gnorm=0.837, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=20602
2022-09-30 14:14:37 - progress_bar.py[line:274] - INFO: epoch 001:   6269 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.6, ups=0.88, wpb=100.6, bsz=40, num_updates=6260, lr=7.67222e-05, gnorm=0.68, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20614
2022-09-30 14:14:48 - progress_bar.py[line:274] - INFO: epoch 001:   6279 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.89, wpb=101.7, bsz=40, num_updates=6270, lr=7.67117e-05, gnorm=0.61, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=20625
2022-09-30 14:14:59 - progress_bar.py[line:274] - INFO: epoch 001:   6289 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.88, wpb=101.4, bsz=40, num_updates=6280, lr=7.67011e-05, gnorm=0.733, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20636
2022-09-30 14:15:10 - progress_bar.py[line:274] - INFO: epoch 001:   6299 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.2, ups=0.92, wpb=100.3, bsz=40, num_updates=6290, lr=7.66906e-05, gnorm=0.818, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20647
2022-09-30 14:15:21 - progress_bar.py[line:274] - INFO: epoch 001:   6309 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.8, ups=0.93, wpb=99.7, bsz=40, num_updates=6300, lr=7.668e-05, gnorm=0.751, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20658
2022-09-30 14:15:32 - progress_bar.py[line:274] - INFO: epoch 001:   6319 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.2, ups=0.92, wpb=101.7, bsz=40, num_updates=6310, lr=7.66694e-05, gnorm=0.712, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20669
2022-09-30 14:15:38 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 14:15:44 - progress_bar.py[line:274] - INFO: epoch 001:   6330 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=84.5, ups=0.83, wpb=102.2, bsz=40, num_updates=6320, lr=7.66589e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=20681
2022-09-30 14:15:55 - progress_bar.py[line:274] - INFO: epoch 001:   6340 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.2, ups=0.89, wpb=101.4, bsz=40, num_updates=6330, lr=7.66483e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20692
2022-09-30 14:16:07 - progress_bar.py[line:274] - INFO: epoch 001:   6350 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91, ups=0.89, wpb=102.3, bsz=40, num_updates=6340, lr=7.66378e-05, gnorm=0.701, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20703
2022-09-30 14:16:18 - progress_bar.py[line:274] - INFO: epoch 001:   6360 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.91, wpb=100, bsz=40, num_updates=6350, lr=7.66272e-05, gnorm=0.658, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20714
2022-09-30 14:16:29 - progress_bar.py[line:274] - INFO: epoch 001:   6370 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.9, wpb=100.4, bsz=40, num_updates=6360, lr=7.66166e-05, gnorm=0.838, clip=20, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=20725
2022-09-30 14:16:40 - progress_bar.py[line:274] - INFO: epoch 001:   6380 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.89, wpb=100, bsz=40, num_updates=6370, lr=7.66061e-05, gnorm=0.712, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20737
2022-09-30 14:16:50 - progress_bar.py[line:274] - INFO: epoch 001:   6390 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.8, ups=0.94, wpb=102.5, bsz=40, num_updates=6380, lr=7.65955e-05, gnorm=0.688, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=20747
2022-09-30 14:17:01 - progress_bar.py[line:274] - INFO: epoch 001:   6400 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.1, ups=0.91, wpb=100.3, bsz=40, num_updates=6390, lr=7.6585e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20758
2022-09-30 14:17:13 - progress_bar.py[line:274] - INFO: epoch 001:   6410 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.89, wpb=102.1, bsz=40, num_updates=6400, lr=7.65744e-05, gnorm=0.792, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20769
2022-09-30 14:17:23 - progress_bar.py[line:274] - INFO: epoch 001:   6420 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.1, ups=0.93, wpb=101.3, bsz=40, num_updates=6410, lr=7.65638e-05, gnorm=0.638, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20780
2022-09-30 14:17:35 - progress_bar.py[line:274] - INFO: epoch 001:   6430 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.7, ups=0.89, wpb=99.2, bsz=40, num_updates=6420, lr=7.65533e-05, gnorm=0.738, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20791
2022-09-30 14:17:45 - progress_bar.py[line:274] - INFO: epoch 001:   6440 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.1, ups=0.93, wpb=99.3, bsz=40, num_updates=6430, lr=7.65427e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20802
2022-09-30 14:17:56 - progress_bar.py[line:274] - INFO: epoch 001:   6450 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.3, ups=0.91, wpb=101.1, bsz=40, num_updates=6440, lr=7.65322e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20813
2022-09-30 14:18:07 - progress_bar.py[line:274] - INFO: epoch 001:   6460 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.9, wpb=101.1, bsz=40, num_updates=6450, lr=7.65216e-05, gnorm=0.725, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=20824
2022-09-30 14:18:19 - progress_bar.py[line:274] - INFO: epoch 001:   6470 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.7, ups=0.89, wpb=98.8, bsz=40, num_updates=6460, lr=7.6511e-05, gnorm=0.64, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=20835
2022-09-30 14:18:30 - progress_bar.py[line:274] - INFO: epoch 001:   6480 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.89, wpb=102.5, bsz=40, num_updates=6470, lr=7.65005e-05, gnorm=0.76, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20847
2022-09-30 14:18:41 - progress_bar.py[line:274] - INFO: epoch 001:   6490 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.9, ups=0.91, wpb=100.5, bsz=40, num_updates=6480, lr=7.64899e-05, gnorm=0.715, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20858
2022-09-30 14:18:52 - progress_bar.py[line:274] - INFO: epoch 001:   6500 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.1, ups=0.9, wpb=101, bsz=40, num_updates=6490, lr=7.64794e-05, gnorm=0.703, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20869
2022-09-30 14:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   6510 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.5, ups=0.9, wpb=101.6, bsz=40, num_updates=6500, lr=7.64688e-05, gnorm=0.719, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20880
2022-09-30 14:19:14 - progress_bar.py[line:274] - INFO: epoch 001:   6520 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.3, ups=0.94, wpb=101.4, bsz=40, num_updates=6510, lr=7.64582e-05, gnorm=0.732, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20890
2022-09-30 14:19:25 - progress_bar.py[line:274] - INFO: epoch 001:   6530 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.4, ups=0.92, wpb=101, bsz=40, num_updates=6520, lr=7.64477e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20901
2022-09-30 14:19:36 - progress_bar.py[line:274] - INFO: epoch 001:   6540 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.6, ups=0.91, wpb=101.7, bsz=40, num_updates=6530, lr=7.64371e-05, gnorm=0.69, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20912
2022-09-30 14:19:47 - progress_bar.py[line:274] - INFO: epoch 001:   6550 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90, ups=0.89, wpb=100.9, bsz=40, num_updates=6540, lr=7.64266e-05, gnorm=0.686, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20924
2022-09-30 14:19:58 - progress_bar.py[line:274] - INFO: epoch 001:   6560 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.88, wpb=102, bsz=40, num_updates=6550, lr=7.6416e-05, gnorm=0.745, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20935
2022-09-30 14:20:09 - progress_bar.py[line:274] - INFO: epoch 001:   6570 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.1, ups=0.93, wpb=100.6, bsz=40, num_updates=6560, lr=7.64054e-05, gnorm=0.831, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20946
2022-09-30 14:20:20 - progress_bar.py[line:274] - INFO: epoch 001:   6580 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.89, wpb=100.9, bsz=40, num_updates=6570, lr=7.63949e-05, gnorm=0.716, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20957
2022-09-30 14:20:32 - progress_bar.py[line:274] - INFO: epoch 001:   6590 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.1, ups=0.84, wpb=102, bsz=40, num_updates=6580, lr=7.63843e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20969
2022-09-30 14:20:43 - progress_bar.py[line:274] - INFO: epoch 001:   6600 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.9, ups=0.89, wpb=100.9, bsz=40, num_updates=6590, lr=7.63738e-05, gnorm=0.769, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20980
2022-09-30 14:20:55 - progress_bar.py[line:274] - INFO: epoch 001:   6610 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.5, ups=0.88, wpb=99.6, bsz=40, num_updates=6600, lr=7.63632e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20992
2022-09-30 14:21:06 - progress_bar.py[line:274] - INFO: epoch 001:   6620 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=98.3, nsentences=40, sample_size=98.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.3, ups=0.88, wpb=98.3, bsz=40, num_updates=6610, lr=7.63526e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21003
2022-09-30 14:21:17 - progress_bar.py[line:274] - INFO: epoch 001:   6630 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.3, ups=0.92, wpb=100.5, bsz=40, num_updates=6620, lr=7.63421e-05, gnorm=0.759, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21014
2022-09-30 14:21:28 - progress_bar.py[line:274] - INFO: epoch 001:   6640 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.9, wpb=100.7, bsz=40, num_updates=6630, lr=7.63315e-05, gnorm=0.754, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21025
2022-09-30 14:21:40 - progress_bar.py[line:274] - INFO: epoch 001:   6650 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.9, ups=0.87, wpb=102.4, bsz=40, num_updates=6640, lr=7.6321e-05, gnorm=0.723, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21036
2022-09-30 14:21:51 - progress_bar.py[line:274] - INFO: epoch 001:   6660 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.9, ups=0.93, wpb=102, bsz=40, num_updates=6650, lr=7.63104e-05, gnorm=0.829, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21047
2022-09-30 14:22:02 - progress_bar.py[line:274] - INFO: epoch 001:   6670 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.3, ups=0.88, wpb=100.2, bsz=40, num_updates=6660, lr=7.62998e-05, gnorm=0.72, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21059
2022-09-30 14:22:14 - progress_bar.py[line:274] - INFO: epoch 001:   6680 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.6, ups=0.85, wpb=101.9, bsz=40, num_updates=6670, lr=7.62893e-05, gnorm=0.776, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21070
2022-09-30 14:22:26 - progress_bar.py[line:274] - INFO: epoch 001:   6690 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=81.2, ups=0.81, wpb=100.8, bsz=40, num_updates=6680, lr=7.62787e-05, gnorm=0.623, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=21083
2022-09-30 14:22:38 - progress_bar.py[line:274] - INFO: epoch 001:   6700 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.2, ups=0.86, wpb=99.2, bsz=40, num_updates=6690, lr=7.62682e-05, gnorm=0.685, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21094
2022-09-30 14:22:49 - progress_bar.py[line:274] - INFO: epoch 001:   6710 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.1, ups=0.88, wpb=102.3, bsz=40, num_updates=6700, lr=7.62576e-05, gnorm=0.721, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21106
2022-09-30 14:23:00 - progress_bar.py[line:274] - INFO: epoch 001:   6720 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.88, wpb=101.1, bsz=40, num_updates=6710, lr=7.6247e-05, gnorm=0.707, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21117
2022-09-30 14:23:11 - progress_bar.py[line:274] - INFO: epoch 001:   6730 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.4, ups=0.91, wpb=101.3, bsz=40, num_updates=6720, lr=7.62365e-05, gnorm=0.701, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21128
2022-09-30 14:23:23 - progress_bar.py[line:274] - INFO: epoch 001:   6740 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.3, ups=0.89, wpb=102.4, bsz=40, num_updates=6730, lr=7.62259e-05, gnorm=0.745, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=21139
2022-09-30 14:23:34 - progress_bar.py[line:274] - INFO: epoch 001:   6750 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.9, wpb=101.3, bsz=40, num_updates=6740, lr=7.62154e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21150
2022-09-30 14:23:45 - progress_bar.py[line:274] - INFO: epoch 001:   6760 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.4, ups=0.89, wpb=101.1, bsz=40, num_updates=6750, lr=7.62048e-05, gnorm=0.747, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21162
2022-09-30 14:23:56 - progress_bar.py[line:274] - INFO: epoch 001:   6770 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.91, wpb=101.5, bsz=40, num_updates=6760, lr=7.61942e-05, gnorm=0.696, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21173
2022-09-30 14:24:07 - progress_bar.py[line:274] - INFO: epoch 001:   6780 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.7, ups=0.92, wpb=101.4, bsz=40, num_updates=6770, lr=7.61837e-05, gnorm=0.722, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21183
2022-09-30 14:24:18 - progress_bar.py[line:274] - INFO: epoch 001:   6790 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.91, wpb=101, bsz=40, num_updates=6780, lr=7.61731e-05, gnorm=0.596, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=21195
2022-09-30 14:24:29 - progress_bar.py[line:274] - INFO: epoch 001:   6800 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=6790, lr=7.61626e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=21206
2022-09-30 14:24:40 - progress_bar.py[line:274] - INFO: epoch 001:   6810 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.2, ups=0.9, wpb=102, bsz=40, num_updates=6800, lr=7.6152e-05, gnorm=0.778, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=21217
2022-09-30 14:24:51 - progress_bar.py[line:274] - INFO: epoch 001:   6820 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.91, wpb=101, bsz=40, num_updates=6810, lr=7.61414e-05, gnorm=0.747, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21228
2022-09-30 14:25:02 - progress_bar.py[line:274] - INFO: epoch 001:   6830 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.9, wpb=101.6, bsz=40, num_updates=6820, lr=7.61309e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21239
2022-09-30 14:25:14 - progress_bar.py[line:274] - INFO: epoch 001:   6840 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.89, wpb=102.2, bsz=40, num_updates=6830, lr=7.61203e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21250
2022-09-30 14:25:25 - progress_bar.py[line:274] - INFO: epoch 001:   6850 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91, ups=0.9, wpb=101, bsz=40, num_updates=6840, lr=7.61098e-05, gnorm=0.718, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21261
2022-09-30 14:25:36 - progress_bar.py[line:274] - INFO: epoch 001:   6860 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.88, wpb=101.2, bsz=40, num_updates=6850, lr=7.60992e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21273
2022-09-30 14:25:47 - progress_bar.py[line:274] - INFO: epoch 001:   6870 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.1, ups=0.87, wpb=101.3, bsz=40, num_updates=6860, lr=7.60886e-05, gnorm=0.683, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21284
2022-09-30 14:25:58 - progress_bar.py[line:274] - INFO: epoch 001:   6880 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.6, ups=0.92, wpb=101.4, bsz=40, num_updates=6870, lr=7.60781e-05, gnorm=0.672, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21295
2022-09-30 14:26:09 - progress_bar.py[line:274] - INFO: epoch 001:   6890 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.7, ups=0.9, wpb=104.2, bsz=40, num_updates=6880, lr=7.60675e-05, gnorm=0.69, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21306
2022-09-30 14:26:21 - progress_bar.py[line:274] - INFO: epoch 001:   6900 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.8, ups=0.86, wpb=101.8, bsz=40, num_updates=6890, lr=7.6057e-05, gnorm=0.831, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21318
2022-09-30 14:26:32 - progress_bar.py[line:274] - INFO: epoch 001:   6910 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=100.3, bsz=40, num_updates=6900, lr=7.60464e-05, gnorm=0.664, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21329
2022-09-30 14:26:43 - progress_bar.py[line:274] - INFO: epoch 001:   6920 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=6910, lr=7.60359e-05, gnorm=0.692, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=21340
2022-09-30 14:26:55 - progress_bar.py[line:274] - INFO: epoch 001:   6930 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.7, ups=0.89, wpb=99, bsz=40, num_updates=6920, lr=7.60253e-05, gnorm=0.776, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21351
2022-09-30 14:27:07 - progress_bar.py[line:274] - INFO: epoch 001:   6940 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=83.1, ups=0.83, wpb=100.1, bsz=40, num_updates=6930, lr=7.60147e-05, gnorm=0.642, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=21364
2022-09-30 14:27:19 - progress_bar.py[line:274] - INFO: epoch 001:   6950 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=85.6, ups=0.83, wpb=102.5, bsz=40, num_updates=6940, lr=7.60042e-05, gnorm=0.71, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=21375
2022-09-30 14:27:30 - progress_bar.py[line:274] - INFO: epoch 001:   6960 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.3, ups=0.87, wpb=100.5, bsz=40, num_updates=6950, lr=7.59936e-05, gnorm=0.688, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=21387
2022-09-30 14:27:41 - progress_bar.py[line:274] - INFO: epoch 001:   6970 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91, ups=0.9, wpb=100.8, bsz=40, num_updates=6960, lr=7.59831e-05, gnorm=0.685, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21398
2022-09-30 14:27:53 - progress_bar.py[line:274] - INFO: epoch 001:   6980 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87, ups=0.87, wpb=100.4, bsz=40, num_updates=6970, lr=7.59725e-05, gnorm=0.721, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21410
2022-09-30 14:28:04 - progress_bar.py[line:274] - INFO: epoch 001:   6990 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.89, wpb=99.9, bsz=40, num_updates=6980, lr=7.59619e-05, gnorm=0.724, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=21421
2022-09-30 14:28:15 - progress_bar.py[line:274] - INFO: epoch 001:   7000 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=6990, lr=7.59514e-05, gnorm=0.647, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21432
2022-09-30 14:28:27 - progress_bar.py[line:274] - INFO: epoch 001:   7010 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.9, ups=0.87, wpb=102.4, bsz=40, num_updates=7000, lr=7.59408e-05, gnorm=0.654, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21444
2022-09-30 14:28:38 - progress_bar.py[line:274] - INFO: epoch 001:   7020 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.88, wpb=101.9, bsz=40, num_updates=7010, lr=7.59303e-05, gnorm=0.656, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=21455
2022-09-30 14:28:50 - progress_bar.py[line:274] - INFO: epoch 001:   7030 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=7020, lr=7.59197e-05, gnorm=0.685, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21466
2022-09-30 14:29:01 - progress_bar.py[line:274] - INFO: epoch 001:   7040 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=7030, lr=7.59091e-05, gnorm=0.711, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21477
2022-09-30 14:29:12 - progress_bar.py[line:274] - INFO: epoch 001:   7050 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.7, ups=0.89, wpb=103.6, bsz=40, num_updates=7040, lr=7.58986e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21489
2022-09-30 14:29:23 - progress_bar.py[line:274] - INFO: epoch 001:   7060 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.6, ups=0.88, wpb=102.2, bsz=40, num_updates=7050, lr=7.5888e-05, gnorm=0.716, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21500
2022-09-30 14:29:35 - progress_bar.py[line:274] - INFO: epoch 001:   7070 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.86, wpb=102.6, bsz=40, num_updates=7060, lr=7.58775e-05, gnorm=0.637, clip=0, loss_scale=1024, train_wall=12, gb_free=10, ema_decay=0.9999, wall=21512
2022-09-30 14:29:48 - progress_bar.py[line:274] - INFO: epoch 001:   7080 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=80.7, ups=0.78, wpb=103.2, bsz=40, num_updates=7070, lr=7.58669e-05, gnorm=0.681, clip=0, loss_scale=1024, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=21525
2022-09-30 14:29:59 - progress_bar.py[line:274] - INFO: epoch 001:   7090 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.6, ups=0.9, wpb=100.3, bsz=40, num_updates=7080, lr=7.58563e-05, gnorm=0.663, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21536
2022-09-30 14:30:10 - progress_bar.py[line:274] - INFO: epoch 001:   7100 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.9, ups=0.93, wpb=102.1, bsz=40, num_updates=7090, lr=7.58458e-05, gnorm=0.636, clip=10, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=21546
2022-09-30 14:30:21 - progress_bar.py[line:274] - INFO: epoch 001:   7110 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.9, ups=0.87, wpb=101.2, bsz=40, num_updates=7100, lr=7.58352e-05, gnorm=0.706, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21558
2022-09-30 14:30:32 - progress_bar.py[line:274] - INFO: epoch 001:   7120 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=101, bsz=40, num_updates=7110, lr=7.58247e-05, gnorm=0.762, clip=0, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=21569
2022-09-30 14:30:44 - progress_bar.py[line:274] - INFO: epoch 001:   7130 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.5, ups=0.88, wpb=99.4, bsz=40, num_updates=7120, lr=7.58141e-05, gnorm=0.767, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21580
2022-09-30 14:30:55 - progress_bar.py[line:274] - INFO: epoch 001:   7140 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.1, ups=0.89, wpb=100.2, bsz=40, num_updates=7130, lr=7.58035e-05, gnorm=0.639, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=21592
2022-09-30 14:31:07 - progress_bar.py[line:274] - INFO: epoch 001:   7150 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.3, ups=0.86, wpb=101.6, bsz=40, num_updates=7140, lr=7.5793e-05, gnorm=0.698, clip=10, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=21603
2022-09-30 14:31:18 - progress_bar.py[line:274] - INFO: epoch 001:   7160 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.2, ups=0.91, wpb=102.1, bsz=40, num_updates=7150, lr=7.57824e-05, gnorm=0.709, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=21614
2022-09-30 14:31:29 - progress_bar.py[line:274] - INFO: epoch 001:   7170 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.88, wpb=102.3, bsz=40, num_updates=7160, lr=7.57719e-05, gnorm=0.655, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21626
2022-09-30 14:31:40 - progress_bar.py[line:274] - INFO: epoch 001:   7180 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.88, wpb=101, bsz=40, num_updates=7170, lr=7.57613e-05, gnorm=0.701, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21637
2022-09-30 14:31:52 - progress_bar.py[line:274] - INFO: epoch 001:   7190 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=85.6, ups=0.86, wpb=99.7, bsz=40, num_updates=7180, lr=7.57507e-05, gnorm=0.784, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=21649
2022-09-30 14:32:05 - progress_bar.py[line:274] - INFO: epoch 001:   7200 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=80.9, ups=0.79, wpb=101.9, bsz=40, num_updates=7190, lr=7.57402e-05, gnorm=0.676, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=21661
2022-09-30 14:32:16 - progress_bar.py[line:274] - INFO: epoch 001:   7210 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.1, ups=0.85, wpb=101, bsz=40, num_updates=7200, lr=7.57296e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=21673
2022-09-30 14:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   7220 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.8, ups=0.89, wpb=101.9, bsz=40, num_updates=7210, lr=7.57191e-05, gnorm=0.651, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21684
2022-09-30 14:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   7230 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.9, ups=0.87, wpb=101.9, bsz=40, num_updates=7220, lr=7.57085e-05, gnorm=0.674, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21696
2022-09-30 14:32:51 - progress_bar.py[line:274] - INFO: epoch 001:   7240 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=83.1, ups=0.81, wpb=102.2, bsz=40, num_updates=7230, lr=7.56979e-05, gnorm=0.706, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=21708
2022-09-30 14:33:03 - progress_bar.py[line:274] - INFO: epoch 001:   7250 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=84.2, ups=0.83, wpb=101.2, bsz=40, num_updates=7240, lr=7.56874e-05, gnorm=0.727, clip=10, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=21720
2022-09-30 14:33:15 - progress_bar.py[line:274] - INFO: epoch 001:   7260 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.9, wpb=101.3, bsz=40, num_updates=7250, lr=7.56768e-05, gnorm=0.654, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21731
2022-09-30 14:33:26 - progress_bar.py[line:274] - INFO: epoch 001:   7270 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.89, wpb=100.2, bsz=40, num_updates=7260, lr=7.56663e-05, gnorm=0.641, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=21743
2022-09-30 14:33:37 - progress_bar.py[line:274] - INFO: epoch 001:   7280 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=7270, lr=7.56557e-05, gnorm=0.721, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21754
2022-09-30 14:33:49 - progress_bar.py[line:274] - INFO: epoch 001:   7290 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.8, ups=0.88, wpb=99.9, bsz=40, num_updates=7280, lr=7.56451e-05, gnorm=0.681, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=21765
2022-09-30 14:34:00 - progress_bar.py[line:274] - INFO: epoch 001:   7300 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.88, wpb=101, bsz=40, num_updates=7290, lr=7.56346e-05, gnorm=0.741, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21777
2022-09-30 14:34:11 - progress_bar.py[line:274] - INFO: epoch 001:   7310 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.3, ups=0.89, wpb=100.1, bsz=40, num_updates=7300, lr=7.5624e-05, gnorm=0.788, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21788
2022-09-30 14:34:22 - progress_bar.py[line:274] - INFO: epoch 001:   7320 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.8, ups=0.89, wpb=99.8, bsz=40, num_updates=7310, lr=7.56135e-05, gnorm=0.744, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21799
2022-09-30 14:34:34 - progress_bar.py[line:274] - INFO: epoch 001:   7330 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.9, wpb=99.8, bsz=40, num_updates=7320, lr=7.56029e-05, gnorm=0.637, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21810
2022-09-30 14:34:45 - progress_bar.py[line:274] - INFO: epoch 001:   7340 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.8, ups=0.87, wpb=102.3, bsz=40, num_updates=7330, lr=7.55923e-05, gnorm=0.619, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21822
2022-09-30 14:34:56 - progress_bar.py[line:274] - INFO: epoch 001:   7350 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=7340, lr=7.55818e-05, gnorm=0.74, clip=10, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=21833
2022-09-30 14:35:04 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 14:35:09 - progress_bar.py[line:274] - INFO: epoch 001:   7361 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=82.1, ups=0.81, wpb=101, bsz=40, num_updates=7350, lr=7.55712e-05, gnorm=0.705, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=21845
2022-09-30 14:35:20 - progress_bar.py[line:274] - INFO: epoch 001:   7371 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.5, ups=0.92, wpb=101, bsz=40, num_updates=7360, lr=7.55607e-05, gnorm=0.652, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21856
2022-09-30 14:35:31 - progress_bar.py[line:274] - INFO: epoch 001:   7381 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.88, wpb=101.6, bsz=40, num_updates=7370, lr=7.55501e-05, gnorm=0.754, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21868
2022-09-30 14:35:42 - progress_bar.py[line:274] - INFO: epoch 001:   7391 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.89, wpb=102.6, bsz=40, num_updates=7380, lr=7.55395e-05, gnorm=0.622, clip=0, loss_scale=1024, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=21879
2022-09-30 14:35:53 - progress_bar.py[line:274] - INFO: epoch 001:   7401 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.4, ups=0.91, wpb=103, bsz=40, num_updates=7390, lr=7.5529e-05, gnorm=0.695, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21890
2022-09-30 14:36:03 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 14:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   7412 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=82.3, ups=0.81, wpb=101.8, bsz=40, num_updates=7400, lr=7.55184e-05, gnorm=0.734, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21902
2022-09-30 14:36:17 - progress_bar.py[line:274] - INFO: epoch 001:   7422 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88, ups=0.88, wpb=100.1, bsz=40, num_updates=7410, lr=7.55079e-05, gnorm=0.733, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21914
2022-09-30 14:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   7432 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.5, ups=0.9, wpb=101.5, bsz=40, num_updates=7420, lr=7.54973e-05, gnorm=0.698, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21925
2022-09-30 14:36:39 - progress_bar.py[line:274] - INFO: epoch 001:   7442 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.5, ups=0.9, wpb=102.2, bsz=40, num_updates=7430, lr=7.54867e-05, gnorm=0.677, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=21936
2022-09-30 14:36:50 - progress_bar.py[line:274] - INFO: epoch 001:   7452 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=101.1, bsz=40, num_updates=7440, lr=7.54762e-05, gnorm=0.714, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21947
2022-09-30 14:37:02 - progress_bar.py[line:274] - INFO: epoch 001:   7462 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.6, ups=0.88, wpb=101.4, bsz=40, num_updates=7450, lr=7.54656e-05, gnorm=0.703, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21959
2022-09-30 14:37:13 - progress_bar.py[line:274] - INFO: epoch 001:   7472 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.9, ups=0.9, wpb=102.2, bsz=40, num_updates=7460, lr=7.54551e-05, gnorm=0.645, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21970
2022-09-30 14:37:25 - progress_bar.py[line:274] - INFO: epoch 001:   7482 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=84.3, ups=0.84, wpb=100.6, bsz=40, num_updates=7470, lr=7.54445e-05, gnorm=0.709, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=21982
2022-09-30 14:37:36 - progress_bar.py[line:274] - INFO: epoch 001:   7492 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.5, ups=0.9, wpb=101.2, bsz=40, num_updates=7480, lr=7.54339e-05, gnorm=0.705, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21993
2022-09-30 14:37:47 - progress_bar.py[line:274] - INFO: epoch 001:   7502 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.6, ups=0.91, wpb=101.9, bsz=40, num_updates=7490, lr=7.54234e-05, gnorm=0.67, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=22004
2022-09-30 14:37:59 - progress_bar.py[line:274] - INFO: epoch 001:   7512 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.8, ups=0.86, wpb=100.5, bsz=40, num_updates=7500, lr=7.54128e-05, gnorm=0.646, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=22015
2022-09-30 14:38:10 - progress_bar.py[line:274] - INFO: epoch 001:   7522 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.88, wpb=100.7, bsz=40, num_updates=7510, lr=7.54023e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22027
2022-09-30 14:38:21 - progress_bar.py[line:274] - INFO: epoch 001:   7532 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.8, ups=0.88, wpb=99.9, bsz=40, num_updates=7520, lr=7.53917e-05, gnorm=0.692, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22038
2022-09-30 14:38:33 - progress_bar.py[line:274] - INFO: epoch 001:   7542 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.9, ups=0.9, wpb=102.9, bsz=40, num_updates=7530, lr=7.53811e-05, gnorm=0.669, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22049
2022-09-30 14:38:43 - progress_bar.py[line:274] - INFO: epoch 001:   7552 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.2, ups=0.94, wpb=102.3, bsz=40, num_updates=7540, lr=7.53706e-05, gnorm=0.725, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22060
2022-09-30 14:38:55 - progress_bar.py[line:274] - INFO: epoch 001:   7562 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.88, wpb=100.8, bsz=40, num_updates=7550, lr=7.536e-05, gnorm=0.649, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22071
2022-09-30 14:39:05 - progress_bar.py[line:274] - INFO: epoch 001:   7572 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.92, wpb=100, bsz=40, num_updates=7560, lr=7.53495e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22082
2022-09-30 14:39:17 - progress_bar.py[line:274] - INFO: epoch 001:   7582 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.88, wpb=100.2, bsz=40, num_updates=7570, lr=7.53389e-05, gnorm=0.739, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22094
2022-09-30 14:39:28 - progress_bar.py[line:274] - INFO: epoch 001:   7592 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.4, ups=0.87, wpb=101.8, bsz=40, num_updates=7580, lr=7.53283e-05, gnorm=0.776, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22105
2022-09-30 14:39:39 - progress_bar.py[line:274] - INFO: epoch 001:   7602 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.3, ups=0.94, wpb=102.2, bsz=40, num_updates=7590, lr=7.53178e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22116
2022-09-30 14:39:50 - progress_bar.py[line:274] - INFO: epoch 001:   7612 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.2, ups=0.91, wpb=100.1, bsz=40, num_updates=7600, lr=7.53072e-05, gnorm=0.605, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=22127
2022-09-30 14:40:01 - progress_bar.py[line:274] - INFO: epoch 001:   7622 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.92, wpb=99.8, bsz=40, num_updates=7610, lr=7.52967e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22138
2022-09-30 14:40:12 - progress_bar.py[line:274] - INFO: epoch 001:   7632 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88, ups=0.87, wpb=100.9, bsz=40, num_updates=7620, lr=7.52861e-05, gnorm=0.72, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=22149
2022-09-30 14:40:24 - progress_bar.py[line:274] - INFO: epoch 001:   7642 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.88, wpb=102.8, bsz=40, num_updates=7630, lr=7.52755e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22160
2022-09-30 14:40:35 - progress_bar.py[line:274] - INFO: epoch 001:   7652 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92, ups=0.9, wpb=101.7, bsz=40, num_updates=7640, lr=7.5265e-05, gnorm=0.73, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22172
2022-09-30 14:40:46 - progress_bar.py[line:274] - INFO: epoch 001:   7662 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.89, wpb=104.2, bsz=40, num_updates=7650, lr=7.52544e-05, gnorm=0.657, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22183
2022-09-30 14:40:57 - progress_bar.py[line:274] - INFO: epoch 001:   7672 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.9, wpb=101.3, bsz=40, num_updates=7660, lr=7.52439e-05, gnorm=0.707, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=22194
2022-09-30 14:41:09 - progress_bar.py[line:274] - INFO: epoch 001:   7682 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.4, ups=0.86, wpb=101.3, bsz=40, num_updates=7670, lr=7.52333e-05, gnorm=0.67, clip=10, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=22205
2022-09-30 14:41:22 - progress_bar.py[line:274] - INFO: epoch 001:   7692 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=79.7, ups=0.78, wpb=101.7, bsz=40, num_updates=7680, lr=7.52227e-05, gnorm=0.671, clip=0, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=22218
2022-09-30 14:41:33 - progress_bar.py[line:274] - INFO: epoch 001:   7702 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.4, ups=0.87, wpb=100.3, bsz=40, num_updates=7690, lr=7.52122e-05, gnorm=0.699, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22230
2022-09-30 14:41:44 - progress_bar.py[line:274] - INFO: epoch 001:   7712 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.9, ups=0.91, wpb=101.7, bsz=40, num_updates=7700, lr=7.52016e-05, gnorm=0.623, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22241
2022-09-30 14:41:55 - progress_bar.py[line:274] - INFO: epoch 001:   7722 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=7710, lr=7.51911e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22252
2022-09-30 14:42:07 - progress_bar.py[line:274] - INFO: epoch 001:   7732 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.9, ups=0.87, wpb=102.3, bsz=40, num_updates=7720, lr=7.51805e-05, gnorm=0.662, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22264
2022-09-30 14:42:18 - progress_bar.py[line:274] - INFO: epoch 001:   7742 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.6, ups=0.91, wpb=100.3, bsz=40, num_updates=7730, lr=7.51699e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22275
2022-09-30 14:42:29 - progress_bar.py[line:274] - INFO: epoch 001:   7752 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.88, wpb=102.1, bsz=40, num_updates=7740, lr=7.51594e-05, gnorm=0.676, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=22286
2022-09-30 14:42:40 - progress_bar.py[line:274] - INFO: epoch 001:   7762 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=7750, lr=7.51488e-05, gnorm=0.702, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22297
2022-09-30 14:42:51 - progress_bar.py[line:274] - INFO: epoch 001:   7772 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.3, ups=0.94, wpb=100.7, bsz=40, num_updates=7760, lr=7.51383e-05, gnorm=0.616, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22308
2022-09-30 14:43:02 - progress_bar.py[line:274] - INFO: epoch 001:   7782 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.9, ups=0.89, wpb=100.1, bsz=40, num_updates=7770, lr=7.51277e-05, gnorm=0.723, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22319
2022-09-30 14:43:13 - progress_bar.py[line:274] - INFO: epoch 001:   7792 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=7780, lr=7.51171e-05, gnorm=0.696, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22330
2022-09-30 14:43:25 - progress_bar.py[line:274] - INFO: epoch 001:   7802 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=7790, lr=7.51066e-05, gnorm=0.625, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22341
2022-09-30 14:43:36 - progress_bar.py[line:274] - INFO: epoch 001:   7812 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.7, ups=0.88, wpb=100.6, bsz=40, num_updates=7800, lr=7.5096e-05, gnorm=0.737, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22353
2022-09-30 14:43:47 - progress_bar.py[line:274] - INFO: epoch 001:   7822 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.88, wpb=102.1, bsz=40, num_updates=7810, lr=7.50855e-05, gnorm=0.676, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22364
2022-09-30 14:43:58 - progress_bar.py[line:274] - INFO: epoch 001:   7832 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.9, ups=0.9, wpb=101.1, bsz=40, num_updates=7820, lr=7.50749e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22375
2022-09-30 14:44:10 - progress_bar.py[line:274] - INFO: epoch 001:   7842 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.6, ups=0.88, wpb=103, bsz=40, num_updates=7830, lr=7.50643e-05, gnorm=0.632, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22387
2022-09-30 14:44:21 - progress_bar.py[line:274] - INFO: epoch 001:   7852 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.1, ups=0.92, wpb=101.3, bsz=40, num_updates=7840, lr=7.50538e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=22397
2022-09-30 14:44:32 - progress_bar.py[line:274] - INFO: epoch 001:   7862 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.6, ups=0.92, wpb=100, bsz=40, num_updates=7850, lr=7.50432e-05, gnorm=0.682, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22408
2022-09-30 14:44:43 - progress_bar.py[line:274] - INFO: epoch 001:   7872 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.9, wpb=102, bsz=40, num_updates=7860, lr=7.50327e-05, gnorm=0.613, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22419
2022-09-30 14:44:54 - progress_bar.py[line:274] - INFO: epoch 001:   7882 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.88, wpb=100.3, bsz=40, num_updates=7870, lr=7.50221e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22431
2022-09-30 14:45:05 - progress_bar.py[line:274] - INFO: epoch 001:   7892 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=7880, lr=7.50115e-05, gnorm=0.601, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22442
2022-09-30 14:45:16 - progress_bar.py[line:274] - INFO: epoch 001:   7902 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.2, ups=0.91, wpb=103.2, bsz=40, num_updates=7890, lr=7.5001e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=22453
2022-09-30 14:45:28 - progress_bar.py[line:274] - INFO: epoch 001:   7912 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=7900, lr=7.49904e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22464
2022-09-30 14:45:39 - progress_bar.py[line:274] - INFO: epoch 001:   7922 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.2, ups=0.9, wpb=103.1, bsz=40, num_updates=7910, lr=7.49799e-05, gnorm=0.722, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22475
2022-09-30 14:45:50 - progress_bar.py[line:274] - INFO: epoch 001:   7932 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=100.7, bsz=40, num_updates=7920, lr=7.49693e-05, gnorm=0.647, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22486
2022-09-30 14:46:01 - progress_bar.py[line:274] - INFO: epoch 001:   7942 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.1, ups=0.92, wpb=101.6, bsz=40, num_updates=7930, lr=7.49588e-05, gnorm=0.669, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=22497
2022-09-30 14:46:12 - progress_bar.py[line:274] - INFO: epoch 001:   7952 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.9, wpb=101.4, bsz=40, num_updates=7940, lr=7.49482e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22509
2022-09-30 14:46:22 - progress_bar.py[line:274] - INFO: epoch 001:   7962 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=96.6, ups=0.94, wpb=102.3, bsz=40, num_updates=7950, lr=7.49376e-05, gnorm=0.59, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22519
2022-09-30 14:46:33 - progress_bar.py[line:274] - INFO: epoch 001:   7972 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.8, ups=0.93, wpb=101.6, bsz=40, num_updates=7960, lr=7.49271e-05, gnorm=0.802, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=22530
2022-09-30 14:46:44 - progress_bar.py[line:274] - INFO: epoch 001:   7982 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=7970, lr=7.49165e-05, gnorm=0.683, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22541
2022-09-30 14:46:55 - progress_bar.py[line:274] - INFO: epoch 001:   7992 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.9, ups=0.93, wpb=100.5, bsz=40, num_updates=7980, lr=7.4906e-05, gnorm=0.697, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22552
2022-09-30 14:47:06 - progress_bar.py[line:274] - INFO: epoch 001:   8002 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.89, wpb=103.6, bsz=40, num_updates=7990, lr=7.48954e-05, gnorm=0.738, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22563
2022-09-30 14:47:17 - progress_bar.py[line:274] - INFO: epoch 001:   8012 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.7, ups=0.92, wpb=103.2, bsz=40, num_updates=8000, lr=7.48848e-05, gnorm=0.649, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22574
2022-09-30 14:47:28 - progress_bar.py[line:274] - INFO: epoch 001:   8022 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.2, ups=0.92, wpb=101.4, bsz=40, num_updates=8010, lr=7.48743e-05, gnorm=0.694, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22585
2022-09-30 14:47:39 - progress_bar.py[line:274] - INFO: epoch 001:   8032 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.7, ups=0.93, wpb=102.3, bsz=40, num_updates=8020, lr=7.48637e-05, gnorm=0.697, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22596
2022-09-30 14:47:50 - progress_bar.py[line:274] - INFO: epoch 001:   8042 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.9, wpb=102.8, bsz=40, num_updates=8030, lr=7.48532e-05, gnorm=0.779, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22607
2022-09-30 14:48:01 - progress_bar.py[line:274] - INFO: epoch 001:   8052 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.91, wpb=99.7, bsz=40, num_updates=8040, lr=7.48426e-05, gnorm=0.812, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22618
2022-09-30 14:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   8062 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.8, ups=0.87, wpb=101.1, bsz=40, num_updates=8050, lr=7.4832e-05, gnorm=0.658, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22630
2022-09-30 14:48:24 - progress_bar.py[line:274] - INFO: epoch 001:   8072 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.1, ups=0.91, wpb=102.5, bsz=40, num_updates=8060, lr=7.48215e-05, gnorm=0.708, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22641
2022-09-30 14:48:35 - progress_bar.py[line:274] - INFO: epoch 001:   8082 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88, ups=0.88, wpb=99.5, bsz=40, num_updates=8070, lr=7.48109e-05, gnorm=0.759, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22652
2022-09-30 14:48:47 - progress_bar.py[line:274] - INFO: epoch 001:   8092 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.87, wpb=100.9, bsz=40, num_updates=8080, lr=7.48004e-05, gnorm=0.748, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22663
2022-09-30 14:48:58 - progress_bar.py[line:274] - INFO: epoch 001:   8102 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.9, ups=0.9, wpb=101.8, bsz=40, num_updates=8090, lr=7.47898e-05, gnorm=0.619, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22674
2022-09-30 14:49:09 - progress_bar.py[line:274] - INFO: epoch 001:   8112 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.9, wpb=100.6, bsz=40, num_updates=8100, lr=7.47792e-05, gnorm=0.639, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22685
2022-09-30 14:49:20 - progress_bar.py[line:274] - INFO: epoch 001:   8122 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.7, ups=0.88, wpb=100.5, bsz=40, num_updates=8110, lr=7.47687e-05, gnorm=0.752, clip=0, loss_scale=1024, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=22697
2022-09-30 14:49:31 - progress_bar.py[line:274] - INFO: epoch 001:   8132 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=8120, lr=7.47581e-05, gnorm=0.672, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22708
2022-09-30 14:49:42 - progress_bar.py[line:274] - INFO: epoch 001:   8142 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.9, wpb=100.8, bsz=40, num_updates=8130, lr=7.47476e-05, gnorm=0.605, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22719
2022-09-30 14:49:53 - progress_bar.py[line:274] - INFO: epoch 001:   8152 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96, ups=0.94, wpb=102.5, bsz=40, num_updates=8140, lr=7.4737e-05, gnorm=0.684, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22730
2022-09-30 14:50:04 - progress_bar.py[line:274] - INFO: epoch 001:   8162 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.6, ups=0.89, wpb=102.9, bsz=40, num_updates=8150, lr=7.47264e-05, gnorm=0.579, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=22741
2022-09-30 14:50:12 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 14:50:16 - progress_bar.py[line:274] - INFO: epoch 001:   8173 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=83.3, ups=0.82, wpb=101.2, bsz=40, num_updates=8160, lr=7.47159e-05, gnorm=0.746, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=22753
2022-09-30 14:50:28 - progress_bar.py[line:274] - INFO: epoch 001:   8183 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.1, ups=0.85, wpb=101.4, bsz=40, num_updates=8170, lr=7.47053e-05, gnorm=0.717, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=22765
2022-09-30 14:50:39 - progress_bar.py[line:274] - INFO: epoch 001:   8193 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.7, ups=0.9, wpb=101.1, bsz=40, num_updates=8180, lr=7.46948e-05, gnorm=0.76, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22776
2022-09-30 14:50:51 - progress_bar.py[line:274] - INFO: epoch 001:   8203 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.4, ups=0.9, wpb=100.6, bsz=40, num_updates=8190, lr=7.46842e-05, gnorm=0.688, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22787
2022-09-30 14:51:01 - progress_bar.py[line:274] - INFO: epoch 001:   8213 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.92, wpb=101, bsz=40, num_updates=8200, lr=7.46736e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=22798
2022-09-30 14:51:12 - progress_bar.py[line:274] - INFO: epoch 001:   8223 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.3, ups=0.92, wpb=102.5, bsz=40, num_updates=8210, lr=7.46631e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22809
2022-09-30 14:51:23 - progress_bar.py[line:274] - INFO: epoch 001:   8233 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.92, wpb=99.5, bsz=40, num_updates=8220, lr=7.46525e-05, gnorm=0.642, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22820
2022-09-30 14:51:35 - progress_bar.py[line:274] - INFO: epoch 001:   8243 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.87, wpb=101.9, bsz=40, num_updates=8230, lr=7.4642e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22831
2022-09-30 14:51:46 - progress_bar.py[line:274] - INFO: epoch 001:   8253 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=8240, lr=7.46314e-05, gnorm=0.715, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22843
2022-09-30 14:51:57 - progress_bar.py[line:274] - INFO: epoch 001:   8263 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.1, ups=0.92, wpb=101.2, bsz=40, num_updates=8250, lr=7.46208e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22854
2022-09-30 14:52:08 - progress_bar.py[line:274] - INFO: epoch 001:   8273 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.3, ups=0.86, wpb=100, bsz=40, num_updates=8260, lr=7.46103e-05, gnorm=0.768, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=22865
2022-09-30 14:52:19 - progress_bar.py[line:274] - INFO: epoch 001:   8283 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.91, wpb=100.3, bsz=40, num_updates=8270, lr=7.45997e-05, gnorm=0.656, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22876
2022-09-30 14:52:31 - progress_bar.py[line:274] - INFO: epoch 001:   8293 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.87, wpb=103, bsz=40, num_updates=8280, lr=7.45892e-05, gnorm=0.764, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22887
2022-09-30 14:52:42 - progress_bar.py[line:274] - INFO: epoch 001:   8303 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.87, wpb=102.2, bsz=40, num_updates=8290, lr=7.45786e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22899
2022-09-30 14:52:54 - progress_bar.py[line:274] - INFO: epoch 001:   8313 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.9, ups=0.89, wpb=98.7, bsz=40, num_updates=8300, lr=7.4568e-05, gnorm=0.726, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=22910
2022-09-30 14:53:04 - progress_bar.py[line:274] - INFO: epoch 001:   8323 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.9, ups=0.92, wpb=101.4, bsz=40, num_updates=8310, lr=7.45575e-05, gnorm=0.61, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=22921
2022-09-30 14:53:15 - progress_bar.py[line:274] - INFO: epoch 001:   8333 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.2, ups=0.9, wpb=103.1, bsz=40, num_updates=8320, lr=7.45469e-05, gnorm=0.586, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22932
2022-09-30 14:53:27 - progress_bar.py[line:274] - INFO: epoch 001:   8343 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.5, ups=0.88, wpb=99.8, bsz=40, num_updates=8330, lr=7.45364e-05, gnorm=0.638, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22944
2022-09-30 14:53:38 - progress_bar.py[line:274] - INFO: epoch 001:   8353 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.6, ups=0.9, wpb=100.2, bsz=40, num_updates=8340, lr=7.45258e-05, gnorm=0.71, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22955
2022-09-30 14:53:50 - progress_bar.py[line:274] - INFO: epoch 001:   8363 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.2, ups=0.86, wpb=102.1, bsz=40, num_updates=8350, lr=7.45152e-05, gnorm=0.708, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=22966
2022-09-30 14:54:01 - progress_bar.py[line:274] - INFO: epoch 001:   8373 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=85.8, ups=0.86, wpb=99.9, bsz=40, num_updates=8360, lr=7.45047e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=22978
2022-09-30 14:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   8383 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.88, wpb=102.7, bsz=40, num_updates=8370, lr=7.44941e-05, gnorm=0.714, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22989
2022-09-30 14:54:24 - progress_bar.py[line:274] - INFO: epoch 001:   8393 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.3, ups=0.9, wpb=100.4, bsz=40, num_updates=8380, lr=7.44836e-05, gnorm=0.717, clip=0, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=23000
2022-09-30 14:54:35 - progress_bar.py[line:274] - INFO: epoch 001:   8403 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.9, wpb=101.6, bsz=40, num_updates=8390, lr=7.4473e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23012
2022-09-30 14:54:46 - progress_bar.py[line:274] - INFO: epoch 001:   8413 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.3, ups=0.88, wpb=99.5, bsz=40, num_updates=8400, lr=7.44624e-05, gnorm=0.654, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23023
2022-09-30 14:54:58 - progress_bar.py[line:274] - INFO: epoch 001:   8423 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.88, wpb=102.2, bsz=40, num_updates=8410, lr=7.44519e-05, gnorm=0.626, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23034
2022-09-30 14:55:09 - progress_bar.py[line:274] - INFO: epoch 001:   8433 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.6, ups=0.88, wpb=99.7, bsz=40, num_updates=8420, lr=7.44413e-05, gnorm=0.771, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23046
2022-09-30 14:55:20 - progress_bar.py[line:274] - INFO: epoch 001:   8443 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.88, wpb=101.8, bsz=40, num_updates=8430, lr=7.44308e-05, gnorm=0.626, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23057
2022-09-30 14:55:32 - progress_bar.py[line:274] - INFO: epoch 001:   8453 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.1, ups=0.89, wpb=100.3, bsz=40, num_updates=8440, lr=7.44202e-05, gnorm=0.76, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23068
2022-09-30 14:55:43 - progress_bar.py[line:274] - INFO: epoch 001:   8463 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.88, wpb=102.3, bsz=40, num_updates=8450, lr=7.44096e-05, gnorm=0.627, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23080
2022-09-30 14:55:54 - progress_bar.py[line:274] - INFO: epoch 001:   8473 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.4, ups=0.93, wpb=101.4, bsz=40, num_updates=8460, lr=7.43991e-05, gnorm=0.688, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23091
2022-09-30 14:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   8483 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.2, ups=0.88, wpb=100.9, bsz=40, num_updates=8470, lr=7.43885e-05, gnorm=0.642, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23102
2022-09-30 14:56:16 - progress_bar.py[line:274] - INFO: epoch 001:   8493 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.3, ups=0.91, wpb=100.6, bsz=40, num_updates=8480, lr=7.4378e-05, gnorm=0.634, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23113
2022-09-30 14:56:27 - progress_bar.py[line:274] - INFO: epoch 001:   8503 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.8, ups=0.88, wpb=99.5, bsz=40, num_updates=8490, lr=7.43674e-05, gnorm=0.676, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23124
2022-09-30 14:56:38 - progress_bar.py[line:274] - INFO: epoch 001:   8513 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.6, ups=0.91, wpb=102.6, bsz=40, num_updates=8500, lr=7.43568e-05, gnorm=0.615, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=23135
2022-09-30 14:56:50 - progress_bar.py[line:274] - INFO: epoch 001:   8523 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.9, wpb=102.2, bsz=40, num_updates=8510, lr=7.43463e-05, gnorm=0.663, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23146
2022-09-30 14:57:01 - progress_bar.py[line:274] - INFO: epoch 001:   8533 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.88, wpb=100.4, bsz=40, num_updates=8520, lr=7.43357e-05, gnorm=0.659, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23158
2022-09-30 14:57:12 - progress_bar.py[line:274] - INFO: epoch 001:   8543 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.88, wpb=101.6, bsz=40, num_updates=8530, lr=7.43252e-05, gnorm=0.707, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23169
2022-09-30 14:57:23 - progress_bar.py[line:274] - INFO: epoch 001:   8553 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.4, ups=0.91, wpb=102.1, bsz=40, num_updates=8540, lr=7.43146e-05, gnorm=0.568, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23180
2022-09-30 14:57:34 - progress_bar.py[line:274] - INFO: epoch 001:   8563 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.9, wpb=101.1, bsz=40, num_updates=8550, lr=7.4304e-05, gnorm=0.628, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23191
2022-09-30 14:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   8573 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.2, ups=0.89, wpb=99.5, bsz=40, num_updates=8560, lr=7.42935e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=23202
2022-09-30 14:57:56 - progress_bar.py[line:274] - INFO: epoch 001:   8583 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.91, wpb=100, bsz=40, num_updates=8570, lr=7.42829e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23213
2022-09-30 14:58:07 - progress_bar.py[line:274] - INFO: epoch 001:   8593 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.6, ups=0.91, wpb=101.2, bsz=40, num_updates=8580, lr=7.42724e-05, gnorm=0.695, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23224
2022-09-30 14:58:18 - progress_bar.py[line:274] - INFO: epoch 001:   8603 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.8, ups=0.91, wpb=102.9, bsz=40, num_updates=8590, lr=7.42618e-05, gnorm=0.73, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23235
2022-09-30 14:58:30 - progress_bar.py[line:274] - INFO: epoch 001:   8613 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.1, ups=0.89, wpb=102.9, bsz=40, num_updates=8600, lr=7.42512e-05, gnorm=0.672, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23246
2022-09-30 14:58:41 - progress_bar.py[line:274] - INFO: epoch 001:   8623 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.3, ups=0.89, wpb=100.7, bsz=40, num_updates=8610, lr=7.42407e-05, gnorm=0.664, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23258
2022-09-30 14:58:52 - progress_bar.py[line:274] - INFO: epoch 001:   8633 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.88, wpb=102.9, bsz=40, num_updates=8620, lr=7.42301e-05, gnorm=0.675, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23269
2022-09-30 14:59:04 - progress_bar.py[line:274] - INFO: epoch 001:   8643 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.89, wpb=101, bsz=40, num_updates=8630, lr=7.42196e-05, gnorm=0.696, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23280
2022-09-30 14:59:15 - progress_bar.py[line:274] - INFO: epoch 001:   8653 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.5, ups=0.91, wpb=101.2, bsz=40, num_updates=8640, lr=7.4209e-05, gnorm=0.762, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23291
2022-09-30 14:59:26 - progress_bar.py[line:274] - INFO: epoch 001:   8663 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.9, wpb=101.5, bsz=40, num_updates=8650, lr=7.41984e-05, gnorm=0.631, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23302
2022-09-30 14:59:37 - progress_bar.py[line:274] - INFO: epoch 001:   8673 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.88, wpb=101.4, bsz=40, num_updates=8660, lr=7.41879e-05, gnorm=0.667, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23314
2022-09-30 14:59:50 - progress_bar.py[line:274] - INFO: epoch 001:   8683 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=80, ups=0.8, wpb=100.5, bsz=40, num_updates=8670, lr=7.41773e-05, gnorm=0.719, clip=0, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=23326
2022-09-30 15:00:02 - progress_bar.py[line:274] - INFO: epoch 001:   8693 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=83.1, ups=0.82, wpb=101.7, bsz=40, num_updates=8680, lr=7.41668e-05, gnorm=0.652, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=23339
2022-09-30 15:00:13 - progress_bar.py[line:274] - INFO: epoch 001:   8703 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.87, wpb=102.9, bsz=40, num_updates=8690, lr=7.41562e-05, gnorm=0.632, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23350
2022-09-30 15:00:25 - progress_bar.py[line:274] - INFO: epoch 001:   8713 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.87, wpb=103.2, bsz=40, num_updates=8700, lr=7.41456e-05, gnorm=0.728, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23362
2022-09-30 15:00:36 - progress_bar.py[line:274] - INFO: epoch 001:   8723 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.1, ups=0.93, wpb=103.3, bsz=40, num_updates=8710, lr=7.41351e-05, gnorm=0.628, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=23372
2022-09-30 15:00:47 - progress_bar.py[line:274] - INFO: epoch 001:   8733 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.8, ups=0.86, wpb=102.2, bsz=40, num_updates=8720, lr=7.41245e-05, gnorm=0.715, clip=10, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=23384
2022-09-30 15:00:58 - progress_bar.py[line:274] - INFO: epoch 001:   8743 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=101, bsz=40, num_updates=8730, lr=7.4114e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23395
2022-09-30 15:01:10 - progress_bar.py[line:274] - INFO: epoch 001:   8753 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.89, wpb=99.7, bsz=40, num_updates=8740, lr=7.41034e-05, gnorm=0.766, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23406
2022-09-30 15:01:21 - progress_bar.py[line:274] - INFO: epoch 001:   8763 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.89, wpb=101.1, bsz=40, num_updates=8750, lr=7.40928e-05, gnorm=0.621, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23418
2022-09-30 15:01:32 - progress_bar.py[line:274] - INFO: epoch 001:   8773 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=8760, lr=7.40823e-05, gnorm=0.656, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23429
2022-09-30 15:01:43 - progress_bar.py[line:274] - INFO: epoch 001:   8783 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.4, ups=0.92, wpb=100.5, bsz=40, num_updates=8770, lr=7.40717e-05, gnorm=0.742, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23440
2022-09-30 15:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   8793 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.2, ups=0.87, wpb=100.1, bsz=40, num_updates=8780, lr=7.40612e-05, gnorm=0.731, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23451
2022-09-30 15:02:06 - progress_bar.py[line:274] - INFO: epoch 001:   8803 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.88, wpb=101.4, bsz=40, num_updates=8790, lr=7.40506e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23463
2022-09-30 15:02:17 - progress_bar.py[line:274] - INFO: epoch 001:   8813 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.9, wpb=101.3, bsz=40, num_updates=8800, lr=7.404e-05, gnorm=0.751, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23474
2022-09-30 15:02:29 - progress_bar.py[line:274] - INFO: epoch 001:   8823 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.89, wpb=100.9, bsz=40, num_updates=8810, lr=7.40295e-05, gnorm=0.682, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23485
2022-09-30 15:02:40 - progress_bar.py[line:274] - INFO: epoch 001:   8833 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.2, ups=0.9, wpb=102.7, bsz=40, num_updates=8820, lr=7.40189e-05, gnorm=0.671, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23496
2022-09-30 15:02:50 - progress_bar.py[line:274] - INFO: epoch 001:   8843 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.3, ups=0.95, wpb=102.5, bsz=40, num_updates=8830, lr=7.40084e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=23507
2022-09-30 15:03:02 - progress_bar.py[line:274] - INFO: epoch 001:   8853 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.5, ups=0.86, wpb=102.1, bsz=40, num_updates=8840, lr=7.39978e-05, gnorm=0.657, clip=0, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=23519
2022-09-30 15:03:15 - progress_bar.py[line:274] - INFO: epoch 001:   8863 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=77.2, ups=0.77, wpb=100.7, bsz=40, num_updates=8850, lr=7.39872e-05, gnorm=0.759, clip=20, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=23532
2022-09-30 15:03:23 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 15:03:28 - progress_bar.py[line:274] - INFO: epoch 001:   8874 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=78.2, ups=0.77, wpb=102, bsz=40, num_updates=8860, lr=7.39767e-05, gnorm=0.732, clip=10, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=23545
2022-09-30 15:03:40 - progress_bar.py[line:274] - INFO: epoch 001:   8884 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.9, ups=0.87, wpb=100.3, bsz=40, num_updates=8870, lr=7.39661e-05, gnorm=0.67, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23556
2022-09-30 15:03:50 - progress_bar.py[line:274] - INFO: epoch 001:   8894 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.5, ups=0.94, wpb=101, bsz=40, num_updates=8880, lr=7.39556e-05, gnorm=0.811, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23567
2022-09-30 15:04:02 - progress_bar.py[line:274] - INFO: epoch 001:   8904 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.9, ups=0.88, wpb=101.5, bsz=40, num_updates=8890, lr=7.3945e-05, gnorm=0.647, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23578
2022-09-30 15:04:13 - progress_bar.py[line:274] - INFO: epoch 001:   8914 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.87, wpb=103, bsz=40, num_updates=8900, lr=7.39345e-05, gnorm=0.656, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23590
2022-09-30 15:04:25 - progress_bar.py[line:274] - INFO: epoch 001:   8924 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.4, ups=0.88, wpb=99.7, bsz=40, num_updates=8910, lr=7.39239e-05, gnorm=0.704, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23601
2022-09-30 15:04:36 - progress_bar.py[line:274] - INFO: epoch 001:   8934 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.2, ups=0.87, wpb=101.9, bsz=40, num_updates=8920, lr=7.39133e-05, gnorm=0.717, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=23613
2022-09-30 15:04:47 - progress_bar.py[line:274] - INFO: epoch 001:   8944 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.2, ups=0.89, wpb=104.1, bsz=40, num_updates=8930, lr=7.39028e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23624
2022-09-30 15:05:00 - progress_bar.py[line:274] - INFO: epoch 001:   8954 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=80.1, ups=0.8, wpb=100.2, bsz=40, num_updates=8940, lr=7.38922e-05, gnorm=0.616, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=23637
2022-09-30 15:05:12 - progress_bar.py[line:274] - INFO: epoch 001:   8964 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=81.9, ups=0.81, wpb=101.5, bsz=40, num_updates=8950, lr=7.38817e-05, gnorm=0.67, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=23649
2022-09-30 15:05:23 - progress_bar.py[line:274] - INFO: epoch 001:   8974 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.9, wpb=100.1, bsz=40, num_updates=8960, lr=7.38711e-05, gnorm=0.792, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23660
2022-09-30 15:05:34 - progress_bar.py[line:274] - INFO: epoch 001:   8984 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.6, ups=0.91, wpb=101.8, bsz=40, num_updates=8970, lr=7.38605e-05, gnorm=0.647, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23671
2022-09-30 15:05:46 - progress_bar.py[line:274] - INFO: epoch 001:   8994 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.4, ups=0.9, wpb=102.8, bsz=40, num_updates=8980, lr=7.385e-05, gnorm=0.569, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23682
2022-09-30 15:05:57 - progress_bar.py[line:274] - INFO: epoch 001:   9004 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=8990, lr=7.38394e-05, gnorm=0.74, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23694
2022-09-30 15:06:08 - progress_bar.py[line:274] - INFO: epoch 001:   9014 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.7, ups=0.9, wpb=101.9, bsz=40, num_updates=9000, lr=7.38289e-05, gnorm=0.565, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23705
2022-09-30 15:06:19 - progress_bar.py[line:274] - INFO: epoch 001:   9024 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.4, ups=0.92, wpb=101.4, bsz=40, num_updates=9010, lr=7.38183e-05, gnorm=0.608, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23716
2022-09-30 15:06:30 - progress_bar.py[line:274] - INFO: epoch 001:   9034 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.93, wpb=101, bsz=40, num_updates=9020, lr=7.38077e-05, gnorm=0.709, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23726
2022-09-30 15:06:40 - progress_bar.py[line:274] - INFO: epoch 001:   9044 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.4, ups=0.92, wpb=101.1, bsz=40, num_updates=9030, lr=7.37972e-05, gnorm=0.7, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23737
2022-09-30 15:06:52 - progress_bar.py[line:274] - INFO: epoch 001:   9054 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.4, ups=0.86, wpb=100.2, bsz=40, num_updates=9040, lr=7.37866e-05, gnorm=0.68, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=23749
2022-09-30 15:07:03 - progress_bar.py[line:274] - INFO: epoch 001:   9064 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.4, ups=0.92, wpb=100.9, bsz=40, num_updates=9050, lr=7.37761e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23760
2022-09-30 15:07:14 - progress_bar.py[line:274] - INFO: epoch 001:   9074 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=9060, lr=7.37655e-05, gnorm=0.598, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23771
2022-09-30 15:07:25 - progress_bar.py[line:274] - INFO: epoch 001:   9084 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.9, wpb=101.2, bsz=40, num_updates=9070, lr=7.37549e-05, gnorm=0.731, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23782
2022-09-30 15:07:37 - progress_bar.py[line:274] - INFO: epoch 001:   9094 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.3, ups=0.86, wpb=100.3, bsz=40, num_updates=9080, lr=7.37444e-05, gnorm=0.628, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=23794
2022-09-30 15:07:48 - progress_bar.py[line:274] - INFO: epoch 001:   9104 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.88, wpb=100, bsz=40, num_updates=9090, lr=7.37338e-05, gnorm=0.574, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23805
2022-09-30 15:08:00 - progress_bar.py[line:274] - INFO: epoch 001:   9114 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.9, ups=0.87, wpb=101.7, bsz=40, num_updates=9100, lr=7.37233e-05, gnorm=0.656, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23817
2022-09-30 15:08:11 - progress_bar.py[line:274] - INFO: epoch 001:   9124 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=9110, lr=7.37127e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23828
2022-09-30 15:08:23 - progress_bar.py[line:274] - INFO: epoch 001:   9134 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=84.9, ups=0.84, wpb=100.7, bsz=40, num_updates=9120, lr=7.37021e-05, gnorm=0.725, clip=10, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=23840
2022-09-30 15:08:34 - progress_bar.py[line:274] - INFO: epoch 001:   9144 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=9130, lr=7.36916e-05, gnorm=0.642, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23851
2022-09-30 15:08:46 - progress_bar.py[line:274] - INFO: epoch 001:   9154 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.87, wpb=101.3, bsz=40, num_updates=9140, lr=7.3681e-05, gnorm=0.807, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23862
2022-09-30 15:08:57 - progress_bar.py[line:274] - INFO: epoch 001:   9164 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.4, bsz=40, num_updates=9150, lr=7.36705e-05, gnorm=0.569, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23874
2022-09-30 15:09:08 - progress_bar.py[line:274] - INFO: epoch 001:   9174 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.9, wpb=101.6, bsz=40, num_updates=9160, lr=7.36599e-05, gnorm=0.618, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23885
2022-09-30 15:09:19 - progress_bar.py[line:274] - INFO: epoch 001:   9184 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.6, ups=0.89, wpb=102.9, bsz=40, num_updates=9170, lr=7.36493e-05, gnorm=0.623, clip=0, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=23896
2022-09-30 15:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   9194 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.5, ups=0.9, wpb=102.9, bsz=40, num_updates=9180, lr=7.36388e-05, gnorm=0.612, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23907
2022-09-30 15:09:42 - progress_bar.py[line:274] - INFO: epoch 001:   9204 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.88, wpb=103.1, bsz=40, num_updates=9190, lr=7.36282e-05, gnorm=0.665, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23919
2022-09-30 15:09:53 - progress_bar.py[line:274] - INFO: epoch 001:   9214 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.87, wpb=100.9, bsz=40, num_updates=9200, lr=7.36177e-05, gnorm=0.727, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23930
2022-09-30 15:10:05 - progress_bar.py[line:274] - INFO: epoch 001:   9224 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.88, wpb=102.1, bsz=40, num_updates=9210, lr=7.36071e-05, gnorm=0.647, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23941
2022-09-30 15:10:16 - progress_bar.py[line:274] - INFO: epoch 001:   9234 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.89, wpb=99.4, bsz=40, num_updates=9220, lr=7.35965e-05, gnorm=0.707, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23953
2022-09-30 15:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   9244 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=82.6, ups=0.82, wpb=100.4, bsz=40, num_updates=9230, lr=7.3586e-05, gnorm=0.683, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=23965
2022-09-30 15:10:40 - progress_bar.py[line:274] - INFO: epoch 001:   9254 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.6, ups=0.85, wpb=101.9, bsz=40, num_updates=9240, lr=7.35754e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=23977
2022-09-30 15:10:51 - progress_bar.py[line:274] - INFO: epoch 001:   9264 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.9, wpb=100, bsz=40, num_updates=9250, lr=7.35649e-05, gnorm=0.687, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23988
2022-09-30 15:11:02 - progress_bar.py[line:274] - INFO: epoch 001:   9274 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.8, ups=0.89, wpb=101.4, bsz=40, num_updates=9260, lr=7.35543e-05, gnorm=0.691, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23999
2022-09-30 15:11:14 - progress_bar.py[line:274] - INFO: epoch 001:   9284 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.9, ups=0.87, wpb=99.4, bsz=40, num_updates=9270, lr=7.35437e-05, gnorm=0.601, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24010
2022-09-30 15:11:25 - progress_bar.py[line:274] - INFO: epoch 001:   9294 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93, ups=0.91, wpb=102.4, bsz=40, num_updates=9280, lr=7.35332e-05, gnorm=0.618, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24021
2022-09-30 15:11:36 - progress_bar.py[line:274] - INFO: epoch 001:   9304 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.87, wpb=102.8, bsz=40, num_updates=9290, lr=7.35226e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24033
2022-09-30 15:11:49 - progress_bar.py[line:274] - INFO: epoch 001:   9314 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=80.6, ups=0.79, wpb=102.4, bsz=40, num_updates=9300, lr=7.35121e-05, gnorm=0.651, clip=0, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=24046
2022-09-30 15:12:01 - progress_bar.py[line:274] - INFO: epoch 001:   9324 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=84.7, ups=0.83, wpb=101.8, bsz=40, num_updates=9310, lr=7.35015e-05, gnorm=0.625, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=24058
2022-09-30 15:12:13 - progress_bar.py[line:274] - INFO: epoch 001:   9334 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.1, ups=0.86, wpb=102.9, bsz=40, num_updates=9320, lr=7.34909e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=24069
2022-09-30 15:12:24 - progress_bar.py[line:274] - INFO: epoch 001:   9344 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.3, ups=0.9, wpb=100.4, bsz=40, num_updates=9330, lr=7.34804e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24080
2022-09-30 15:12:35 - progress_bar.py[line:274] - INFO: epoch 001:   9354 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.5, ups=0.87, wpb=100, bsz=40, num_updates=9340, lr=7.34698e-05, gnorm=0.675, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24092
2022-09-30 15:12:46 - progress_bar.py[line:274] - INFO: epoch 001:   9364 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.6, ups=0.89, wpb=100.9, bsz=40, num_updates=9350, lr=7.34593e-05, gnorm=0.663, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24103
2022-09-30 15:12:58 - progress_bar.py[line:274] - INFO: epoch 001:   9374 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=101.8, bsz=40, num_updates=9360, lr=7.34487e-05, gnorm=0.611, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24114
2022-09-30 15:13:09 - progress_bar.py[line:274] - INFO: epoch 001:   9384 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=101.3, bsz=40, num_updates=9370, lr=7.34381e-05, gnorm=0.659, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24126
2022-09-30 15:13:22 - progress_bar.py[line:274] - INFO: epoch 001:   9394 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=80.1, ups=0.79, wpb=101.6, bsz=40, num_updates=9380, lr=7.34276e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=24138
2022-09-30 15:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   9404 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85, ups=0.85, wpb=100.6, bsz=40, num_updates=9390, lr=7.3417e-05, gnorm=0.627, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=24150
2022-09-30 15:13:45 - progress_bar.py[line:274] - INFO: epoch 001:   9414 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.89, wpb=101, bsz=40, num_updates=9400, lr=7.34065e-05, gnorm=0.654, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24161
2022-09-30 15:13:56 - progress_bar.py[line:274] - INFO: epoch 001:   9424 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.9, wpb=101.7, bsz=40, num_updates=9410, lr=7.33959e-05, gnorm=0.675, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24173
2022-09-30 15:14:07 - progress_bar.py[line:274] - INFO: epoch 001:   9434 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.88, wpb=102.7, bsz=40, num_updates=9420, lr=7.33853e-05, gnorm=0.612, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24184
2022-09-30 15:14:19 - progress_bar.py[line:274] - INFO: epoch 001:   9444 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.2, ups=0.88, wpb=99.5, bsz=40, num_updates=9430, lr=7.33748e-05, gnorm=0.702, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24195
2022-09-30 15:14:30 - progress_bar.py[line:274] - INFO: epoch 001:   9454 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=9440, lr=7.33642e-05, gnorm=0.639, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24207
2022-09-30 15:14:41 - progress_bar.py[line:274] - INFO: epoch 001:   9464 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=9450, lr=7.33537e-05, gnorm=0.585, clip=0, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=24218
2022-09-30 15:14:53 - progress_bar.py[line:274] - INFO: epoch 001:   9474 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.88, wpb=100.5, bsz=40, num_updates=9460, lr=7.33431e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24229
2022-09-30 15:15:04 - progress_bar.py[line:274] - INFO: epoch 001:   9484 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=9470, lr=7.33325e-05, gnorm=0.688, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24241
2022-09-30 15:15:15 - progress_bar.py[line:274] - INFO: epoch 001:   9494 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.88, wpb=101.9, bsz=40, num_updates=9480, lr=7.3322e-05, gnorm=0.633, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24252
2022-09-30 15:15:27 - progress_bar.py[line:274] - INFO: epoch 001:   9504 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.88, wpb=101.2, bsz=40, num_updates=9490, lr=7.33114e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24263
2022-09-30 15:15:38 - progress_bar.py[line:274] - INFO: epoch 001:   9514 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.4, ups=0.91, wpb=102.1, bsz=40, num_updates=9500, lr=7.33009e-05, gnorm=0.629, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24274
2022-09-30 15:15:48 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 15:15:50 - progress_bar.py[line:274] - INFO: epoch 001:   9525 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=83.1, ups=0.81, wpb=102, bsz=40, num_updates=9510, lr=7.32903e-05, gnorm=0.511, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=24287
2022-09-30 15:16:01 - progress_bar.py[line:274] - INFO: epoch 001:   9535 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.2, ups=0.91, wpb=102, bsz=40, num_updates=9520, lr=7.32797e-05, gnorm=0.58, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24298
2022-09-30 15:16:12 - progress_bar.py[line:274] - INFO: epoch 001:   9545 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101.5, bsz=40, num_updates=9530, lr=7.32692e-05, gnorm=0.683, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24309
2022-09-30 15:16:23 - progress_bar.py[line:274] - INFO: epoch 001:   9555 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.88, wpb=101.4, bsz=40, num_updates=9540, lr=7.32586e-05, gnorm=0.657, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24320
2022-09-30 15:16:35 - progress_bar.py[line:274] - INFO: epoch 001:   9565 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.87, wpb=101.8, bsz=40, num_updates=9550, lr=7.32481e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24332
2022-09-30 15:16:46 - progress_bar.py[line:274] - INFO: epoch 001:   9575 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=9560, lr=7.32375e-05, gnorm=0.601, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24343
2022-09-30 15:16:58 - progress_bar.py[line:274] - INFO: epoch 001:   9585 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.88, wpb=102, bsz=40, num_updates=9570, lr=7.32269e-05, gnorm=0.625, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24354
2022-09-30 15:17:09 - progress_bar.py[line:274] - INFO: epoch 001:   9595 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.9, ups=0.88, wpb=100, bsz=40, num_updates=9580, lr=7.32164e-05, gnorm=0.653, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24366
2022-09-30 15:17:20 - progress_bar.py[line:274] - INFO: epoch 001:   9605 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.8, ups=0.9, wpb=103.1, bsz=40, num_updates=9590, lr=7.32058e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24377
2022-09-30 15:17:31 - progress_bar.py[line:274] - INFO: epoch 001:   9615 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=9600, lr=7.31953e-05, gnorm=0.566, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=24388
2022-09-30 15:17:42 - progress_bar.py[line:274] - INFO: epoch 001:   9625 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.8, ups=0.9, wpb=101.6, bsz=40, num_updates=9610, lr=7.31847e-05, gnorm=0.503, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24399
2022-09-30 15:17:53 - progress_bar.py[line:274] - INFO: epoch 001:   9635 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.89, wpb=101, bsz=40, num_updates=9620, lr=7.31741e-05, gnorm=0.578, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24410
2022-09-30 15:18:05 - progress_bar.py[line:274] - INFO: epoch 001:   9645 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.2, ups=0.89, wpb=100.7, bsz=40, num_updates=9630, lr=7.31636e-05, gnorm=0.632, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24421
2022-09-30 15:18:16 - progress_bar.py[line:274] - INFO: epoch 001:   9655 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.7, ups=0.88, wpb=99.5, bsz=40, num_updates=9640, lr=7.3153e-05, gnorm=0.66, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24433
2022-09-30 15:18:27 - progress_bar.py[line:274] - INFO: epoch 001:   9665 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.9, wpb=101.3, bsz=40, num_updates=9650, lr=7.31425e-05, gnorm=0.632, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24444
2022-09-30 15:18:38 - progress_bar.py[line:274] - INFO: epoch 001:   9675 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=9660, lr=7.31319e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24455
2022-09-30 15:18:49 - progress_bar.py[line:274] - INFO: epoch 001:   9685 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.3, ups=0.92, wpb=101.4, bsz=40, num_updates=9670, lr=7.31213e-05, gnorm=0.588, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24466
2022-09-30 15:19:01 - progress_bar.py[line:274] - INFO: epoch 001:   9695 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=9680, lr=7.31108e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24477
2022-09-30 15:19:12 - progress_bar.py[line:274] - INFO: epoch 001:   9705 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.8, ups=0.9, wpb=99.7, bsz=40, num_updates=9690, lr=7.31002e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24488
2022-09-30 15:19:23 - progress_bar.py[line:274] - INFO: epoch 001:   9715 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87, ups=0.86, wpb=101.5, bsz=40, num_updates=9700, lr=7.30897e-05, gnorm=0.587, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=24500
2022-09-30 15:19:35 - progress_bar.py[line:274] - INFO: epoch 001:   9725 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.8, ups=0.87, wpb=102.4, bsz=40, num_updates=9710, lr=7.30791e-05, gnorm=0.598, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24512
2022-09-30 15:19:46 - progress_bar.py[line:274] - INFO: epoch 001:   9735 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=9720, lr=7.30685e-05, gnorm=0.586, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24523
2022-09-30 15:19:57 - progress_bar.py[line:274] - INFO: epoch 001:   9745 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.8, ups=0.9, wpb=102.6, bsz=40, num_updates=9730, lr=7.3058e-05, gnorm=0.692, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24534
2022-09-30 15:20:08 - progress_bar.py[line:274] - INFO: epoch 001:   9755 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.9, ups=0.92, wpb=99.5, bsz=40, num_updates=9740, lr=7.30474e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24545
2022-09-30 15:20:19 - progress_bar.py[line:274] - INFO: epoch 001:   9765 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.4, ups=0.88, wpb=99.2, bsz=40, num_updates=9750, lr=7.30369e-05, gnorm=0.607, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24556
2022-09-30 15:20:31 - progress_bar.py[line:274] - INFO: epoch 001:   9775 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.89, wpb=102.1, bsz=40, num_updates=9760, lr=7.30263e-05, gnorm=0.634, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24567
2022-09-30 15:20:42 - progress_bar.py[line:274] - INFO: epoch 001:   9785 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=101.3, bsz=40, num_updates=9770, lr=7.30157e-05, gnorm=0.593, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24579
2022-09-30 15:20:53 - progress_bar.py[line:274] - INFO: epoch 001:   9795 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.3, ups=0.88, wpb=100.8, bsz=40, num_updates=9780, lr=7.30052e-05, gnorm=0.633, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24590
2022-09-30 15:21:05 - progress_bar.py[line:274] - INFO: epoch 001:   9805 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.1, ups=0.89, wpb=99.4, bsz=40, num_updates=9790, lr=7.29946e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24601
2022-09-30 15:21:16 - progress_bar.py[line:274] - INFO: epoch 001:   9815 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.9, wpb=100.5, bsz=40, num_updates=9800, lr=7.29841e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24612
2022-09-30 15:21:27 - progress_bar.py[line:274] - INFO: epoch 001:   9825 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.7, ups=0.91, wpb=100.3, bsz=40, num_updates=9810, lr=7.29735e-05, gnorm=0.696, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24623
2022-09-30 15:21:38 - progress_bar.py[line:274] - INFO: epoch 001:   9835 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.9, ups=0.9, wpb=102.6, bsz=40, num_updates=9820, lr=7.29629e-05, gnorm=0.609, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24635
2022-09-30 15:21:49 - progress_bar.py[line:274] - INFO: epoch 001:   9845 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.88, wpb=101, bsz=40, num_updates=9830, lr=7.29524e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24646
2022-09-30 15:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   9855 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.7, ups=0.9, wpb=99.7, bsz=40, num_updates=9840, lr=7.29418e-05, gnorm=0.683, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24657
2022-09-30 15:22:11 - progress_bar.py[line:274] - INFO: epoch 001:   9865 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.9, wpb=102.3, bsz=40, num_updates=9850, lr=7.29313e-05, gnorm=0.622, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24668
2022-09-30 15:22:22 - progress_bar.py[line:274] - INFO: epoch 001:   9875 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.3, ups=0.9, wpb=104.3, bsz=40, num_updates=9860, lr=7.29207e-05, gnorm=0.65, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24679
2022-09-30 15:22:34 - progress_bar.py[line:274] - INFO: epoch 001:   9885 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.88, wpb=99.7, bsz=40, num_updates=9870, lr=7.29101e-05, gnorm=0.725, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24691
2022-09-30 15:22:45 - progress_bar.py[line:274] - INFO: epoch 001:   9895 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.7, ups=0.93, wpb=101.1, bsz=40, num_updates=9880, lr=7.28996e-05, gnorm=0.643, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24701
2022-09-30 15:22:56 - progress_bar.py[line:274] - INFO: epoch 001:   9905 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.3, ups=0.88, wpb=99.1, bsz=40, num_updates=9890, lr=7.2889e-05, gnorm=0.712, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24713
2022-09-30 15:23:07 - progress_bar.py[line:274] - INFO: epoch 001:   9915 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=9900, lr=7.28785e-05, gnorm=0.654, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24724
2022-09-30 15:23:18 - progress_bar.py[line:274] - INFO: epoch 001:   9925 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.2, ups=0.91, wpb=103.2, bsz=40, num_updates=9910, lr=7.28679e-05, gnorm=0.593, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24735
2022-09-30 15:23:29 - progress_bar.py[line:274] - INFO: epoch 001:   9935 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=9920, lr=7.28574e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24746
2022-09-30 15:23:40 - progress_bar.py[line:274] - INFO: epoch 001:   9945 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.8, ups=0.92, wpb=101.6, bsz=40, num_updates=9930, lr=7.28468e-05, gnorm=0.702, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24757
2022-09-30 15:23:52 - progress_bar.py[line:274] - INFO: epoch 001:   9955 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.2, ups=0.86, wpb=101.3, bsz=40, num_updates=9940, lr=7.28362e-05, gnorm=0.667, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=24768
2022-09-30 15:24:02 - progress_bar.py[line:274] - INFO: epoch 001:   9965 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.9, ups=0.92, wpb=100.2, bsz=40, num_updates=9950, lr=7.28257e-05, gnorm=0.704, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24779
2022-09-30 15:24:14 - progress_bar.py[line:274] - INFO: epoch 001:   9975 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.5, ups=0.89, wpb=100.9, bsz=40, num_updates=9960, lr=7.28151e-05, gnorm=0.713, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24790
2022-09-30 15:24:25 - progress_bar.py[line:274] - INFO: epoch 001:   9985 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=9970, lr=7.28046e-05, gnorm=0.706, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24802
2022-09-30 15:24:36 - progress_bar.py[line:274] - INFO: epoch 001:   9995 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.91, wpb=101.1, bsz=40, num_updates=9980, lr=7.2794e-05, gnorm=0.657, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24813
2022-09-30 15:24:47 - progress_bar.py[line:274] - INFO: epoch 001:  10005 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.5, ups=0.9, wpb=101.7, bsz=40, num_updates=9990, lr=7.27834e-05, gnorm=0.642, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24824
2022-09-30 15:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  10015 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.3, ups=0.89, wpb=102.1, bsz=40, num_updates=10000, lr=7.27729e-05, gnorm=0.683, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24835
2022-09-30 15:25:09 - progress_bar.py[line:274] - INFO: epoch 001:  10025 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94, ups=0.91, wpb=103.2, bsz=40, num_updates=10010, lr=7.27623e-05, gnorm=0.598, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24846
2022-09-30 15:25:20 - progress_bar.py[line:274] - INFO: epoch 001:  10035 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=10020, lr=7.27518e-05, gnorm=0.546, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24857
2022-09-30 15:25:31 - progress_bar.py[line:274] - INFO: epoch 001:  10045 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.5, ups=0.93, wpb=101.1, bsz=40, num_updates=10030, lr=7.27412e-05, gnorm=0.687, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24868
2022-09-30 15:25:43 - progress_bar.py[line:274] - INFO: epoch 001:  10055 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=10040, lr=7.27306e-05, gnorm=0.567, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24879
2022-09-30 15:25:54 - progress_bar.py[line:274] - INFO: epoch 001:  10065 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.91, wpb=102, bsz=40, num_updates=10050, lr=7.27201e-05, gnorm=0.626, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24890
2022-09-30 15:26:05 - progress_bar.py[line:274] - INFO: epoch 001:  10075 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.9, wpb=101, bsz=40, num_updates=10060, lr=7.27095e-05, gnorm=0.636, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24901
2022-09-30 15:26:16 - progress_bar.py[line:274] - INFO: epoch 001:  10085 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=10070, lr=7.2699e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24913
2022-09-30 15:26:28 - progress_bar.py[line:274] - INFO: epoch 001:  10095 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.5, ups=0.86, wpb=101.8, bsz=40, num_updates=10080, lr=7.26884e-05, gnorm=0.711, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=24924
2022-09-30 15:26:40 - progress_bar.py[line:274] - INFO: epoch 001:  10105 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=80.1, ups=0.79, wpb=101.5, bsz=40, num_updates=10090, lr=7.26778e-05, gnorm=0.657, clip=0, loss_scale=1024, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=24937
2022-09-30 15:26:52 - progress_bar.py[line:274] - INFO: epoch 001:  10115 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.5, ups=0.86, wpb=100.7, bsz=40, num_updates=10100, lr=7.26673e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=24949
2022-09-30 15:27:03 - progress_bar.py[line:274] - INFO: epoch 001:  10125 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.6, ups=0.89, wpb=102.4, bsz=40, num_updates=10110, lr=7.26567e-05, gnorm=0.569, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24960
2022-09-30 15:27:14 - progress_bar.py[line:274] - INFO: epoch 001:  10135 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.4, ups=0.91, wpb=100.9, bsz=40, num_updates=10120, lr=7.26462e-05, gnorm=0.687, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24971
2022-09-30 15:27:26 - progress_bar.py[line:274] - INFO: epoch 001:  10145 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.87, wpb=102, bsz=40, num_updates=10130, lr=7.26356e-05, gnorm=0.641, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24983
2022-09-30 15:27:37 - progress_bar.py[line:274] - INFO: epoch 001:  10155 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=10140, lr=7.2625e-05, gnorm=0.638, clip=0, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=24994
2022-09-30 15:27:48 - progress_bar.py[line:274] - INFO: epoch 001:  10165 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.1, ups=0.91, wpb=102, bsz=40, num_updates=10150, lr=7.26145e-05, gnorm=0.615, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25005
2022-09-30 15:27:59 - progress_bar.py[line:274] - INFO: epoch 001:  10175 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.89, wpb=99.6, bsz=40, num_updates=10160, lr=7.26039e-05, gnorm=0.621, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25016
2022-09-30 15:28:10 - progress_bar.py[line:274] - INFO: epoch 001:  10185 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.89, wpb=101.1, bsz=40, num_updates=10170, lr=7.25934e-05, gnorm=0.654, clip=0, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=25027
2022-09-30 15:28:22 - progress_bar.py[line:274] - INFO: epoch 001:  10195 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.9, wpb=101.7, bsz=40, num_updates=10180, lr=7.25828e-05, gnorm=0.613, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25038
2022-09-30 15:28:33 - progress_bar.py[line:274] - INFO: epoch 001:  10205 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.91, wpb=102, bsz=40, num_updates=10190, lr=7.25722e-05, gnorm=0.573, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25049
2022-09-30 15:28:44 - progress_bar.py[line:274] - INFO: epoch 001:  10215 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.89, wpb=101.7, bsz=40, num_updates=10200, lr=7.25617e-05, gnorm=0.625, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25061
2022-09-30 15:28:55 - progress_bar.py[line:274] - INFO: epoch 001:  10225 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=10210, lr=7.25511e-05, gnorm=0.635, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25072
2022-09-30 15:29:07 - progress_bar.py[line:274] - INFO: epoch 001:  10235 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.4, ups=0.87, wpb=100.7, bsz=40, num_updates=10220, lr=7.25406e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25084
2022-09-30 15:29:18 - progress_bar.py[line:274] - INFO: epoch 001:  10245 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.88, wpb=101.9, bsz=40, num_updates=10230, lr=7.253e-05, gnorm=0.647, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25095
2022-09-30 15:29:29 - progress_bar.py[line:274] - INFO: epoch 001:  10255 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.3, ups=0.89, wpb=99.9, bsz=40, num_updates=10240, lr=7.25194e-05, gnorm=0.679, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25106
2022-09-30 15:29:41 - progress_bar.py[line:274] - INFO: epoch 001:  10265 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.4, ups=0.87, wpb=101.8, bsz=40, num_updates=10250, lr=7.25089e-05, gnorm=0.769, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25118
2022-09-30 15:29:52 - progress_bar.py[line:274] - INFO: epoch 001:  10275 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.1, ups=0.9, wpb=102, bsz=40, num_updates=10260, lr=7.24983e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25129
2022-09-30 15:30:03 - progress_bar.py[line:274] - INFO: epoch 001:  10285 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.9, wpb=99.9, bsz=40, num_updates=10270, lr=7.24878e-05, gnorm=0.671, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25140
2022-09-30 15:30:14 - progress_bar.py[line:274] - INFO: epoch 001:  10295 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=10280, lr=7.24772e-05, gnorm=0.741, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25151
2022-09-30 15:30:25 - progress_bar.py[line:274] - INFO: epoch 001:  10305 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.7, ups=0.93, wpb=101.2, bsz=40, num_updates=10290, lr=7.24666e-05, gnorm=0.617, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25162
2022-09-30 15:30:36 - progress_bar.py[line:274] - INFO: epoch 001:  10315 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.2, ups=0.89, wpb=101.4, bsz=40, num_updates=10300, lr=7.24561e-05, gnorm=0.743, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25173
2022-09-30 15:30:47 - progress_bar.py[line:274] - INFO: epoch 001:  10325 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.5, ups=0.93, wpb=102.6, bsz=40, num_updates=10310, lr=7.24455e-05, gnorm=0.566, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25184
2022-09-30 15:30:58 - progress_bar.py[line:274] - INFO: epoch 001:  10335 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=10320, lr=7.2435e-05, gnorm=0.604, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25195
2022-09-30 15:31:10 - progress_bar.py[line:274] - INFO: epoch 001:  10345 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.7, ups=0.87, wpb=100.8, bsz=40, num_updates=10330, lr=7.24244e-05, gnorm=0.602, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25207
2022-09-30 15:31:21 - progress_bar.py[line:274] - INFO: epoch 001:  10355 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.89, wpb=102.8, bsz=40, num_updates=10340, lr=7.24138e-05, gnorm=0.624, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25218
2022-09-30 15:31:32 - progress_bar.py[line:274] - INFO: epoch 001:  10365 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.9, wpb=101.8, bsz=40, num_updates=10350, lr=7.24033e-05, gnorm=0.749, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25229
2022-09-30 15:31:44 - progress_bar.py[line:274] - INFO: epoch 001:  10375 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.2, ups=0.87, wpb=99.8, bsz=40, num_updates=10360, lr=7.23927e-05, gnorm=0.688, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25240
2022-09-30 15:31:55 - progress_bar.py[line:274] - INFO: epoch 001:  10385 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.5, ups=0.89, wpb=99.7, bsz=40, num_updates=10370, lr=7.23822e-05, gnorm=0.679, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25252
2022-09-30 15:32:07 - progress_bar.py[line:274] - INFO: epoch 001:  10395 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.7, ups=0.87, wpb=102.3, bsz=40, num_updates=10380, lr=7.23716e-05, gnorm=0.598, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25263
2022-09-30 15:32:18 - progress_bar.py[line:274] - INFO: epoch 001:  10405 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.9, wpb=101, bsz=40, num_updates=10390, lr=7.2361e-05, gnorm=0.638, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25274
2022-09-30 15:32:29 - progress_bar.py[line:274] - INFO: epoch 001:  10415 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.88, wpb=101.4, bsz=40, num_updates=10400, lr=7.23505e-05, gnorm=0.755, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25286
2022-09-30 15:32:40 - progress_bar.py[line:274] - INFO: epoch 001:  10425 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=10410, lr=7.23399e-05, gnorm=0.58, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25297
2022-09-30 15:32:52 - progress_bar.py[line:274] - INFO: epoch 001:  10435 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=83.9, ups=0.83, wpb=101.7, bsz=40, num_updates=10420, lr=7.23294e-05, gnorm=0.599, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=25309
2022-09-30 15:33:05 - progress_bar.py[line:274] - INFO: epoch 001:  10445 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=84, ups=0.83, wpb=101.7, bsz=40, num_updates=10430, lr=7.23188e-05, gnorm=0.706, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=25321
2022-09-30 15:33:16 - progress_bar.py[line:274] - INFO: epoch 001:  10455 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.4, ups=0.89, wpb=102.7, bsz=40, num_updates=10440, lr=7.23082e-05, gnorm=0.735, clip=0, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=25332
2022-09-30 15:33:27 - progress_bar.py[line:274] - INFO: epoch 001:  10465 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=85.6, ups=0.86, wpb=99.4, bsz=40, num_updates=10450, lr=7.22977e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=25344
2022-09-30 15:33:40 - progress_bar.py[line:274] - INFO: epoch 001:  10475 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=81, ups=0.8, wpb=100.9, bsz=40, num_updates=10460, lr=7.22871e-05, gnorm=0.654, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=25357
2022-09-30 15:33:51 - progress_bar.py[line:274] - INFO: epoch 001:  10485 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.6, ups=0.89, wpb=101.4, bsz=40, num_updates=10470, lr=7.22766e-05, gnorm=0.718, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25368
2022-09-30 15:34:03 - progress_bar.py[line:274] - INFO: epoch 001:  10495 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.1, ups=0.91, wpb=99.4, bsz=40, num_updates=10480, lr=7.2266e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25379
2022-09-30 15:34:13 - progress_bar.py[line:274] - INFO: epoch 001:  10505 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.92, wpb=99.5, bsz=40, num_updates=10490, lr=7.22554e-05, gnorm=0.643, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25390
2022-09-30 15:34:25 - progress_bar.py[line:274] - INFO: epoch 001:  10515 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.3, ups=0.89, wpb=102.1, bsz=40, num_updates=10500, lr=7.22449e-05, gnorm=0.662, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25401
2022-09-30 15:34:36 - progress_bar.py[line:274] - INFO: epoch 001:  10525 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.9, wpb=102.5, bsz=40, num_updates=10510, lr=7.22343e-05, gnorm=0.66, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25412
2022-09-30 15:34:47 - progress_bar.py[line:274] - INFO: epoch 001:  10535 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=10520, lr=7.22238e-05, gnorm=0.644, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25424
2022-09-30 15:34:58 - progress_bar.py[line:274] - INFO: epoch 001:  10545 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.9, wpb=101.3, bsz=40, num_updates=10530, lr=7.22132e-05, gnorm=0.743, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25435
2022-09-30 15:35:09 - progress_bar.py[line:274] - INFO: epoch 001:  10555 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.91, wpb=101.9, bsz=40, num_updates=10540, lr=7.22026e-05, gnorm=0.582, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25446
2022-09-30 15:35:20 - progress_bar.py[line:274] - INFO: epoch 001:  10565 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.88, wpb=102.5, bsz=40, num_updates=10550, lr=7.21921e-05, gnorm=0.577, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25457
2022-09-30 15:35:31 - progress_bar.py[line:274] - INFO: epoch 001:  10575 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.92, wpb=101.9, bsz=40, num_updates=10560, lr=7.21815e-05, gnorm=0.608, clip=0, loss_scale=2048, train_wall=11, gb_free=9.2, ema_decay=0.9999, wall=25468
2022-09-30 15:35:41 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 15:35:44 - progress_bar.py[line:274] - INFO: epoch 001:  10586 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=83.4, ups=0.82, wpb=101.6, bsz=40, num_updates=10570, lr=7.2171e-05, gnorm=0.649, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=25480
2022-09-30 15:35:55 - progress_bar.py[line:274] - INFO: epoch 001:  10596 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=102, bsz=40, num_updates=10580, lr=7.21604e-05, gnorm=0.648, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25492
2022-09-30 15:36:06 - progress_bar.py[line:274] - INFO: epoch 001:  10606 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.6, ups=0.88, wpb=99.3, bsz=40, num_updates=10590, lr=7.21498e-05, gnorm=0.694, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25503
2022-09-30 15:36:17 - progress_bar.py[line:274] - INFO: epoch 001:  10616 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.1, ups=0.89, wpb=100.9, bsz=40, num_updates=10600, lr=7.21393e-05, gnorm=0.653, clip=0, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=25514
2022-09-30 15:36:29 - progress_bar.py[line:274] - INFO: epoch 001:  10626 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=102, bsz=40, num_updates=10610, lr=7.21287e-05, gnorm=0.61, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25525
2022-09-30 15:36:39 - progress_bar.py[line:274] - INFO: epoch 001:  10636 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.9, ups=0.91, wpb=100.5, bsz=40, num_updates=10620, lr=7.21182e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25536
2022-09-30 15:36:50 - progress_bar.py[line:274] - INFO: epoch 001:  10646 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.5, ups=0.92, wpb=102.2, bsz=40, num_updates=10630, lr=7.21076e-05, gnorm=0.745, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25547
2022-09-30 15:37:01 - progress_bar.py[line:274] - INFO: epoch 001:  10656 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.9, wpb=101.8, bsz=40, num_updates=10640, lr=7.2097e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25558
2022-09-30 15:37:13 - progress_bar.py[line:274] - INFO: epoch 001:  10666 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.89, wpb=101.5, bsz=40, num_updates=10650, lr=7.20865e-05, gnorm=0.612, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25569
2022-09-30 15:37:24 - progress_bar.py[line:274] - INFO: epoch 001:  10676 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92, ups=0.91, wpb=100.6, bsz=40, num_updates=10660, lr=7.20759e-05, gnorm=0.6, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25580
2022-09-30 15:37:35 - progress_bar.py[line:274] - INFO: epoch 001:  10686 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=10670, lr=7.20654e-05, gnorm=0.667, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25592
2022-09-30 15:37:46 - progress_bar.py[line:274] - INFO: epoch 001:  10696 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.9, wpb=101.7, bsz=40, num_updates=10680, lr=7.20548e-05, gnorm=0.613, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25603
2022-09-30 15:37:58 - progress_bar.py[line:274] - INFO: epoch 001:  10706 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.88, wpb=103.7, bsz=40, num_updates=10690, lr=7.20442e-05, gnorm=0.685, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25614
2022-09-30 15:38:09 - progress_bar.py[line:274] - INFO: epoch 001:  10716 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=10700, lr=7.20337e-05, gnorm=0.687, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25626
2022-09-30 15:38:20 - progress_bar.py[line:274] - INFO: epoch 001:  10726 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=10710, lr=7.20231e-05, gnorm=0.666, clip=0, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=25637
2022-09-30 15:38:31 - progress_bar.py[line:274] - INFO: epoch 001:  10736 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=101.4, bsz=40, num_updates=10720, lr=7.20126e-05, gnorm=0.653, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25648
2022-09-30 15:38:43 - progress_bar.py[line:274] - INFO: epoch 001:  10746 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.9, wpb=100, bsz=40, num_updates=10730, lr=7.2002e-05, gnorm=0.61, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25659
2022-09-30 15:38:54 - progress_bar.py[line:274] - INFO: epoch 001:  10756 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.2, ups=0.89, wpb=101.1, bsz=40, num_updates=10740, lr=7.19914e-05, gnorm=0.709, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25671
2022-09-30 15:39:05 - progress_bar.py[line:274] - INFO: epoch 001:  10766 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92, ups=0.91, wpb=101.4, bsz=40, num_updates=10750, lr=7.19809e-05, gnorm=0.61, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25682
2022-09-30 15:39:16 - progress_bar.py[line:274] - INFO: epoch 001:  10776 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.91, wpb=100.3, bsz=40, num_updates=10760, lr=7.19703e-05, gnorm=0.626, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25692
2022-09-30 15:39:27 - progress_bar.py[line:274] - INFO: epoch 001:  10786 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.2, ups=0.92, wpb=100.5, bsz=40, num_updates=10770, lr=7.19598e-05, gnorm=0.605, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25703
2022-09-30 15:39:38 - progress_bar.py[line:274] - INFO: epoch 001:  10796 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=10780, lr=7.19492e-05, gnorm=0.645, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25714
2022-09-30 15:39:49 - progress_bar.py[line:274] - INFO: epoch 001:  10806 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.89, wpb=101.7, bsz=40, num_updates=10790, lr=7.19386e-05, gnorm=0.609, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25726
2022-09-30 15:40:00 - progress_bar.py[line:274] - INFO: epoch 001:  10816 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=10800, lr=7.19281e-05, gnorm=0.688, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25737
2022-09-30 15:40:11 - progress_bar.py[line:274] - INFO: epoch 001:  10826 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.8, ups=0.92, wpb=101.4, bsz=40, num_updates=10810, lr=7.19175e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25748
2022-09-30 15:40:22 - progress_bar.py[line:274] - INFO: epoch 001:  10836 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.9, wpb=99.2, bsz=40, num_updates=10820, lr=7.1907e-05, gnorm=0.606, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25759
2022-09-30 15:40:31 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 15:40:34 - progress_bar.py[line:274] - INFO: epoch 001:  10847 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=84.7, ups=0.82, wpb=102.8, bsz=40, num_updates=10830, lr=7.18964e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=25771
2022-09-30 15:40:46 - progress_bar.py[line:274] - INFO: epoch 001:  10857 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=84.4, ups=0.83, wpb=101.4, bsz=40, num_updates=10840, lr=7.18858e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=25783
2022-09-30 15:40:59 - progress_bar.py[line:274] - INFO: epoch 001:  10867 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=81.9, ups=0.82, wpb=100.1, bsz=40, num_updates=10850, lr=7.18753e-05, gnorm=0.568, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=25795
2022-09-30 15:41:10 - progress_bar.py[line:274] - INFO: epoch 001:  10877 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.88, wpb=101.8, bsz=40, num_updates=10860, lr=7.18647e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25807
2022-09-30 15:41:21 - progress_bar.py[line:274] - INFO: epoch 001:  10887 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.5, ups=0.92, wpb=102.7, bsz=40, num_updates=10870, lr=7.18542e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25818
2022-09-30 15:41:32 - progress_bar.py[line:274] - INFO: epoch 001:  10897 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.9, wpb=100.8, bsz=40, num_updates=10880, lr=7.18436e-05, gnorm=0.714, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25829
2022-09-30 15:41:43 - progress_bar.py[line:274] - INFO: epoch 001:  10907 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.9, wpb=102.3, bsz=40, num_updates=10890, lr=7.1833e-05, gnorm=0.66, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25840
2022-09-30 15:41:54 - progress_bar.py[line:274] - INFO: epoch 001:  10917 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92, ups=0.9, wpb=101.9, bsz=40, num_updates=10900, lr=7.18225e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25851
2022-09-30 15:42:06 - progress_bar.py[line:274] - INFO: epoch 001:  10927 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.5, ups=0.87, wpb=101.7, bsz=40, num_updates=10910, lr=7.18119e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25862
2022-09-30 15:42:17 - progress_bar.py[line:274] - INFO: epoch 001:  10937 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=10920, lr=7.18014e-05, gnorm=0.541, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25874
2022-09-30 15:42:28 - progress_bar.py[line:274] - INFO: epoch 001:  10947 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.8, ups=0.91, wpb=102.8, bsz=40, num_updates=10930, lr=7.17908e-05, gnorm=0.689, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25885
2022-09-30 15:42:39 - progress_bar.py[line:274] - INFO: epoch 001:  10957 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.89, wpb=101.1, bsz=40, num_updates=10940, lr=7.17803e-05, gnorm=0.608, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25896
2022-09-30 15:42:50 - progress_bar.py[line:274] - INFO: epoch 001:  10967 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.3, ups=0.92, wpb=102.6, bsz=40, num_updates=10950, lr=7.17697e-05, gnorm=0.626, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25907
2022-09-30 15:43:01 - progress_bar.py[line:274] - INFO: epoch 001:  10977 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.89, wpb=102.8, bsz=40, num_updates=10960, lr=7.17591e-05, gnorm=0.601, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25918
2022-09-30 15:43:13 - progress_bar.py[line:274] - INFO: epoch 001:  10987 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.6, ups=0.89, wpb=100.5, bsz=40, num_updates=10970, lr=7.17486e-05, gnorm=0.718, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25929
2022-09-30 15:43:24 - progress_bar.py[line:274] - INFO: epoch 001:  10997 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94, ups=0.91, wpb=102.9, bsz=40, num_updates=10980, lr=7.1738e-05, gnorm=0.659, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25940
2022-09-30 15:43:35 - progress_bar.py[line:274] - INFO: epoch 001:  11007 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92, ups=0.9, wpb=102, bsz=40, num_updates=10990, lr=7.17275e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25951
2022-09-30 15:43:46 - progress_bar.py[line:274] - INFO: epoch 001:  11017 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.9, wpb=100.6, bsz=40, num_updates=11000, lr=7.17169e-05, gnorm=0.602, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25963
2022-09-30 15:43:57 - progress_bar.py[line:274] - INFO: epoch 001:  11027 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.88, wpb=102.1, bsz=40, num_updates=11010, lr=7.17063e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25974
2022-09-30 15:44:08 - progress_bar.py[line:274] - INFO: epoch 001:  11037 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=11020, lr=7.16958e-05, gnorm=0.578, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25985
2022-09-30 15:44:19 - progress_bar.py[line:274] - INFO: epoch 001:  11047 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.9, ups=0.92, wpb=101.2, bsz=40, num_updates=11030, lr=7.16852e-05, gnorm=0.569, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25996
2022-09-30 15:44:30 - progress_bar.py[line:274] - INFO: epoch 001:  11057 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.92, wpb=102.2, bsz=40, num_updates=11040, lr=7.16747e-05, gnorm=0.511, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26007
2022-09-30 15:44:41 - progress_bar.py[line:274] - INFO: epoch 001:  11067 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.9, ups=0.94, wpb=100.9, bsz=40, num_updates=11050, lr=7.16641e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26018
2022-09-30 15:44:52 - progress_bar.py[line:274] - INFO: epoch 001:  11077 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.88, wpb=104.1, bsz=40, num_updates=11060, lr=7.16535e-05, gnorm=0.558, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26029
2022-09-30 15:45:05 - progress_bar.py[line:274] - INFO: epoch 001:  11087 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=80.7, ups=0.79, wpb=102.6, bsz=40, num_updates=11070, lr=7.1643e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=26042
2022-09-30 15:45:17 - progress_bar.py[line:274] - INFO: epoch 001:  11097 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86, ups=0.84, wpb=102.4, bsz=40, num_updates=11080, lr=7.16324e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=26054
2022-09-30 15:45:28 - progress_bar.py[line:274] - INFO: epoch 001:  11107 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.7, ups=0.87, wpb=100.5, bsz=40, num_updates=11090, lr=7.16219e-05, gnorm=0.596, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26065
2022-09-30 15:45:39 - progress_bar.py[line:274] - INFO: epoch 001:  11117 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.2, ups=0.92, wpb=102.6, bsz=40, num_updates=11100, lr=7.16113e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26076
2022-09-30 15:45:50 - progress_bar.py[line:274] - INFO: epoch 001:  11127 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.4, ups=0.9, wpb=103.6, bsz=40, num_updates=11110, lr=7.16007e-05, gnorm=0.501, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26087
2022-09-30 15:46:01 - progress_bar.py[line:274] - INFO: epoch 001:  11137 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.5, ups=0.9, wpb=101.4, bsz=40, num_updates=11120, lr=7.15902e-05, gnorm=0.603, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26098
2022-09-30 15:46:13 - progress_bar.py[line:274] - INFO: epoch 001:  11147 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88, ups=0.89, wpb=98.7, bsz=40, num_updates=11130, lr=7.15796e-05, gnorm=0.688, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26109
2022-09-30 15:46:24 - progress_bar.py[line:274] - INFO: epoch 001:  11157 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.5, ups=0.92, wpb=100.8, bsz=40, num_updates=11140, lr=7.15691e-05, gnorm=0.592, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26120
2022-09-30 15:46:34 - progress_bar.py[line:274] - INFO: epoch 001:  11167 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.5, ups=0.95, wpb=99.8, bsz=40, num_updates=11150, lr=7.15585e-05, gnorm=0.653, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26131
2022-09-30 15:46:45 - progress_bar.py[line:274] - INFO: epoch 001:  11177 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=100.1, bsz=40, num_updates=11160, lr=7.15479e-05, gnorm=0.605, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26142
2022-09-30 15:46:57 - progress_bar.py[line:274] - INFO: epoch 001:  11187 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.7, ups=0.87, wpb=101.2, bsz=40, num_updates=11170, lr=7.15374e-05, gnorm=0.661, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26154
2022-09-30 15:47:08 - progress_bar.py[line:274] - INFO: epoch 001:  11197 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.3, ups=0.91, wpb=99.8, bsz=40, num_updates=11180, lr=7.15268e-05, gnorm=0.603, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26165
2022-09-30 15:47:19 - progress_bar.py[line:274] - INFO: epoch 001:  11207 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92, ups=0.9, wpb=101.8, bsz=40, num_updates=11190, lr=7.15163e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26176
2022-09-30 15:47:30 - progress_bar.py[line:274] - INFO: epoch 001:  11217 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.89, wpb=102.4, bsz=40, num_updates=11200, lr=7.15057e-05, gnorm=0.574, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26187
2022-09-30 15:47:42 - progress_bar.py[line:274] - INFO: epoch 001:  11227 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.88, wpb=103.3, bsz=40, num_updates=11210, lr=7.14951e-05, gnorm=0.527, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26198
2022-09-30 15:47:53 - progress_bar.py[line:274] - INFO: epoch 001:  11237 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.9, ups=0.87, wpb=99.9, bsz=40, num_updates=11220, lr=7.14846e-05, gnorm=0.663, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26210
2022-09-30 15:48:04 - progress_bar.py[line:274] - INFO: epoch 001:  11247 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.3, ups=0.93, wpb=101.9, bsz=40, num_updates=11230, lr=7.1474e-05, gnorm=0.576, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26221
2022-09-30 15:48:15 - progress_bar.py[line:274] - INFO: epoch 001:  11257 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.88, wpb=102.6, bsz=40, num_updates=11240, lr=7.14635e-05, gnorm=0.565, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26232
2022-09-30 15:48:26 - progress_bar.py[line:274] - INFO: epoch 001:  11267 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.8, ups=0.9, wpb=102.9, bsz=40, num_updates=11250, lr=7.14529e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26243
2022-09-30 15:48:37 - progress_bar.py[line:274] - INFO: epoch 001:  11277 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93, ups=0.91, wpb=101.9, bsz=40, num_updates=11260, lr=7.14423e-05, gnorm=0.616, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26254
2022-09-30 15:48:49 - progress_bar.py[line:274] - INFO: epoch 001:  11287 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.89, wpb=101.5, bsz=40, num_updates=11270, lr=7.14318e-05, gnorm=0.661, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26265
2022-09-30 15:49:00 - progress_bar.py[line:274] - INFO: epoch 001:  11297 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.89, wpb=100.6, bsz=40, num_updates=11280, lr=7.14212e-05, gnorm=0.622, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26276
2022-09-30 15:49:11 - progress_bar.py[line:274] - INFO: epoch 001:  11307 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=11290, lr=7.14107e-05, gnorm=0.587, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26288
2022-09-30 15:49:23 - progress_bar.py[line:274] - INFO: epoch 001:  11317 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=83.5, ups=0.81, wpb=103.2, bsz=40, num_updates=11300, lr=7.14001e-05, gnorm=0.662, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=26300
2022-09-30 15:49:36 - progress_bar.py[line:274] - INFO: epoch 001:  11327 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=82.5, ups=0.82, wpb=100.2, bsz=40, num_updates=11310, lr=7.13895e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=26312
2022-09-30 15:49:48 - progress_bar.py[line:274] - INFO: epoch 001:  11337 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=81.1, ups=0.79, wpb=102.2, bsz=40, num_updates=11320, lr=7.1379e-05, gnorm=0.633, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=26325
2022-09-30 15:50:00 - progress_bar.py[line:274] - INFO: epoch 001:  11347 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.8, ups=0.87, wpb=101.8, bsz=40, num_updates=11330, lr=7.13684e-05, gnorm=0.587, clip=0, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=26336
2022-09-30 15:50:11 - progress_bar.py[line:274] - INFO: epoch 001:  11357 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.89, wpb=101.9, bsz=40, num_updates=11340, lr=7.13579e-05, gnorm=0.786, clip=20, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=26348
2022-09-30 15:50:22 - progress_bar.py[line:274] - INFO: epoch 001:  11367 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.2, ups=0.91, wpb=102.3, bsz=40, num_updates=11350, lr=7.13473e-05, gnorm=0.635, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26359
2022-09-30 15:50:33 - progress_bar.py[line:274] - INFO: epoch 001:  11377 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.9, wpb=102, bsz=40, num_updates=11360, lr=7.13367e-05, gnorm=0.626, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26370
2022-09-30 15:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  11387 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.6, bsz=40, num_updates=11370, lr=7.13262e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26381
2022-09-30 15:50:55 - progress_bar.py[line:274] - INFO: epoch 001:  11397 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.91, wpb=102.3, bsz=40, num_updates=11380, lr=7.13156e-05, gnorm=0.648, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=26392
2022-09-30 15:51:06 - progress_bar.py[line:274] - INFO: epoch 001:  11407 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.3, ups=0.93, wpb=101.2, bsz=40, num_updates=11390, lr=7.13051e-05, gnorm=0.666, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26403
2022-09-30 15:51:17 - progress_bar.py[line:274] - INFO: epoch 001:  11417 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.87, wpb=102.1, bsz=40, num_updates=11400, lr=7.12945e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26414
2022-09-30 15:51:29 - progress_bar.py[line:274] - INFO: epoch 001:  11427 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.8, ups=0.87, wpb=100.9, bsz=40, num_updates=11410, lr=7.12839e-05, gnorm=0.51, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26426
2022-09-30 15:51:40 - progress_bar.py[line:274] - INFO: epoch 001:  11437 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.5, ups=0.9, wpb=101.4, bsz=40, num_updates=11420, lr=7.12734e-05, gnorm=0.637, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26437
2022-09-30 15:51:51 - progress_bar.py[line:274] - INFO: epoch 001:  11447 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=101.6, bsz=40, num_updates=11430, lr=7.12628e-05, gnorm=0.61, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=26448
2022-09-30 15:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  11457 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.6, ups=0.89, wpb=99.1, bsz=40, num_updates=11440, lr=7.12523e-05, gnorm=0.705, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26459
2022-09-30 15:52:13 - progress_bar.py[line:274] - INFO: epoch 001:  11467 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.1, ups=0.91, wpb=102.2, bsz=40, num_updates=11450, lr=7.12417e-05, gnorm=0.586, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=26470
2022-09-30 15:52:25 - progress_bar.py[line:274] - INFO: epoch 001:  11477 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.89, wpb=101.8, bsz=40, num_updates=11460, lr=7.12311e-05, gnorm=0.618, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26481
2022-09-30 15:52:35 - progress_bar.py[line:274] - INFO: epoch 001:  11487 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.2, ups=0.92, wpb=100.4, bsz=40, num_updates=11470, lr=7.12206e-05, gnorm=0.653, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26492
2022-09-30 15:52:47 - progress_bar.py[line:274] - INFO: epoch 001:  11497 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.9, wpb=101.1, bsz=40, num_updates=11480, lr=7.121e-05, gnorm=0.642, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26503
2022-09-30 15:52:58 - progress_bar.py[line:274] - INFO: epoch 001:  11507 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=11490, lr=7.11995e-05, gnorm=0.615, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26514
2022-09-30 15:53:09 - progress_bar.py[line:274] - INFO: epoch 001:  11517 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=98.5, nsentences=40, sample_size=98.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.8, ups=0.88, wpb=98.5, bsz=40, num_updates=11500, lr=7.11889e-05, gnorm=0.693, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26526
2022-09-30 15:53:20 - progress_bar.py[line:274] - INFO: epoch 001:  11527 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=11510, lr=7.11783e-05, gnorm=0.653, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26537
2022-09-30 15:53:31 - progress_bar.py[line:274] - INFO: epoch 001:  11537 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.89, wpb=101.6, bsz=40, num_updates=11520, lr=7.11678e-05, gnorm=0.632, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26548
2022-09-30 15:53:42 - progress_bar.py[line:274] - INFO: epoch 001:  11547 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.1, ups=0.92, wpb=103.4, bsz=40, num_updates=11530, lr=7.11572e-05, gnorm=0.626, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26559
2022-09-30 15:53:53 - progress_bar.py[line:274] - INFO: epoch 001:  11557 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.7, ups=0.89, wpb=101.7, bsz=40, num_updates=11540, lr=7.11467e-05, gnorm=0.645, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26570
2022-09-30 15:54:04 - progress_bar.py[line:274] - INFO: epoch 001:  11567 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=11550, lr=7.11361e-05, gnorm=0.684, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26581
2022-09-30 15:54:16 - progress_bar.py[line:274] - INFO: epoch 001:  11577 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.87, wpb=102.3, bsz=40, num_updates=11560, lr=7.11255e-05, gnorm=0.693, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26593
2022-09-30 15:54:27 - progress_bar.py[line:274] - INFO: epoch 001:  11587 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.89, wpb=102.8, bsz=40, num_updates=11570, lr=7.1115e-05, gnorm=0.572, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26604
2022-09-30 15:54:39 - progress_bar.py[line:274] - INFO: epoch 001:  11597 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.88, wpb=102, bsz=40, num_updates=11580, lr=7.11044e-05, gnorm=0.638, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26615
2022-09-30 15:54:50 - progress_bar.py[line:274] - INFO: epoch 001:  11607 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.89, wpb=102.2, bsz=40, num_updates=11590, lr=7.10939e-05, gnorm=0.628, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26626
2022-09-30 15:55:01 - progress_bar.py[line:274] - INFO: epoch 001:  11617 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.2, ups=0.88, wpb=101.1, bsz=40, num_updates=11600, lr=7.10833e-05, gnorm=0.622, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26638
2022-09-30 15:55:12 - progress_bar.py[line:274] - INFO: epoch 001:  11627 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.4, ups=0.9, wpb=102.5, bsz=40, num_updates=11610, lr=7.10727e-05, gnorm=0.585, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26649
2022-09-30 15:55:23 - progress_bar.py[line:274] - INFO: epoch 001:  11637 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.5, ups=0.93, wpb=101, bsz=40, num_updates=11620, lr=7.10622e-05, gnorm=0.608, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=26660
2022-09-30 15:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  11647 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=11630, lr=7.10516e-05, gnorm=0.592, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26671
2022-09-30 15:55:46 - progress_bar.py[line:274] - INFO: epoch 001:  11657 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.1, ups=0.88, wpb=101.3, bsz=40, num_updates=11640, lr=7.10411e-05, gnorm=0.697, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26682
2022-09-30 15:55:57 - progress_bar.py[line:274] - INFO: epoch 001:  11667 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93, ups=0.91, wpb=101.8, bsz=40, num_updates=11650, lr=7.10305e-05, gnorm=0.466, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=26693
2022-09-30 15:56:07 - progress_bar.py[line:274] - INFO: epoch 001:  11677 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.3, ups=0.93, wpb=100.7, bsz=40, num_updates=11660, lr=7.10199e-05, gnorm=0.578, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26704
2022-09-30 15:56:19 - progress_bar.py[line:274] - INFO: epoch 001:  11687 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=100.4, bsz=40, num_updates=11670, lr=7.10094e-05, gnorm=0.545, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26715
2022-09-30 15:56:29 - progress_bar.py[line:274] - INFO: epoch 001:  11697 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.7, ups=0.92, wpb=100.7, bsz=40, num_updates=11680, lr=7.09988e-05, gnorm=0.621, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26726
2022-09-30 15:56:41 - progress_bar.py[line:274] - INFO: epoch 001:  11707 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.4, ups=0.87, wpb=99.3, bsz=40, num_updates=11690, lr=7.09883e-05, gnorm=0.677, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26738
2022-09-30 15:56:52 - progress_bar.py[line:274] - INFO: epoch 001:  11717 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.89, wpb=101.9, bsz=40, num_updates=11700, lr=7.09777e-05, gnorm=0.519, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26749
2022-09-30 15:57:03 - progress_bar.py[line:274] - INFO: epoch 001:  11727 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.9, wpb=102.1, bsz=40, num_updates=11710, lr=7.09671e-05, gnorm=0.607, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26760
2022-09-30 15:57:15 - progress_bar.py[line:274] - INFO: epoch 001:  11737 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=85.3, ups=0.85, wpb=100.7, bsz=40, num_updates=11720, lr=7.09566e-05, gnorm=0.601, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=26772
2022-09-30 15:57:27 - progress_bar.py[line:274] - INFO: epoch 001:  11747 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.4, ups=0.86, wpb=100.4, bsz=40, num_updates=11730, lr=7.0946e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=26783
2022-09-30 15:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  11757 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.89, wpb=102.2, bsz=40, num_updates=11740, lr=7.09355e-05, gnorm=0.552, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26795
2022-09-30 15:57:49 - progress_bar.py[line:274] - INFO: epoch 001:  11767 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.4, ups=0.9, wpb=102.5, bsz=40, num_updates=11750, lr=7.09249e-05, gnorm=0.55, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26806
2022-09-30 15:58:00 - progress_bar.py[line:274] - INFO: epoch 001:  11777 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.5, ups=0.9, wpb=104.7, bsz=40, num_updates=11760, lr=7.09143e-05, gnorm=0.535, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26817
2022-09-30 15:58:12 - progress_bar.py[line:274] - INFO: epoch 001:  11787 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86, ups=0.86, wpb=100.2, bsz=40, num_updates=11770, lr=7.09038e-05, gnorm=0.552, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=26829
2022-09-30 15:58:24 - progress_bar.py[line:274] - INFO: epoch 001:  11797 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=84.1, ups=0.82, wpb=102.6, bsz=40, num_updates=11780, lr=7.08932e-05, gnorm=0.58, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=26841
2022-09-30 15:58:36 - progress_bar.py[line:274] - INFO: epoch 001:  11807 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=85.6, ups=0.84, wpb=102.1, bsz=40, num_updates=11790, lr=7.08827e-05, gnorm=0.582, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=26853
2022-09-30 15:58:48 - progress_bar.py[line:274] - INFO: epoch 001:  11817 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.1, ups=0.86, wpb=101, bsz=40, num_updates=11800, lr=7.08721e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=26864
2022-09-30 15:58:59 - progress_bar.py[line:274] - INFO: epoch 001:  11827 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.89, wpb=102.6, bsz=40, num_updates=11810, lr=7.08615e-05, gnorm=0.644, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26875
2022-09-30 15:59:10 - progress_bar.py[line:274] - INFO: epoch 001:  11837 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.89, wpb=101.8, bsz=40, num_updates=11820, lr=7.0851e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26887
2022-09-30 15:59:21 - progress_bar.py[line:274] - INFO: epoch 001:  11847 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.91, wpb=100.8, bsz=40, num_updates=11830, lr=7.08404e-05, gnorm=0.68, clip=10, loss_scale=1024, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=26898
2022-09-30 15:59:32 - progress_bar.py[line:274] - INFO: epoch 001:  11857 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.89, wpb=102.4, bsz=40, num_updates=11840, lr=7.08299e-05, gnorm=0.582, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26909
2022-09-30 15:59:43 - progress_bar.py[line:274] - INFO: epoch 001:  11867 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.9, wpb=101.6, bsz=40, num_updates=11850, lr=7.08193e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26920
2022-09-30 15:59:55 - progress_bar.py[line:274] - INFO: epoch 001:  11877 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.1, ups=0.88, wpb=100.2, bsz=40, num_updates=11860, lr=7.08087e-05, gnorm=0.565, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26932
2022-09-30 16:00:06 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 16:00:07 - progress_bar.py[line:274] - INFO: epoch 001:  11888 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=83.6, ups=0.83, wpb=100.9, bsz=40, num_updates=11870, lr=7.07982e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=26944
2022-09-30 16:00:18 - progress_bar.py[line:274] - INFO: epoch 001:  11898 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.5, ups=0.9, wpb=102.5, bsz=40, num_updates=11880, lr=7.07876e-05, gnorm=0.616, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26955
2022-09-30 16:00:29 - progress_bar.py[line:274] - INFO: epoch 001:  11908 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=11890, lr=7.07771e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26966
2022-09-30 16:00:40 - progress_bar.py[line:274] - INFO: epoch 001:  11918 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.3, ups=0.92, wpb=100.5, bsz=40, num_updates=11900, lr=7.07665e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=26977
2022-09-30 16:00:51 - progress_bar.py[line:274] - INFO: epoch 001:  11928 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.89, wpb=101.5, bsz=40, num_updates=11910, lr=7.07559e-05, gnorm=0.58, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26988
2022-09-30 16:01:02 - progress_bar.py[line:274] - INFO: epoch 001:  11938 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.1, ups=0.92, wpb=102.7, bsz=40, num_updates=11920, lr=7.07454e-05, gnorm=0.641, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26999
2022-09-30 16:01:14 - progress_bar.py[line:274] - INFO: epoch 001:  11948 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.2, ups=0.88, wpb=101.2, bsz=40, num_updates=11930, lr=7.07348e-05, gnorm=0.589, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=27010
2022-09-30 16:01:25 - progress_bar.py[line:274] - INFO: epoch 001:  11958 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=11940, lr=7.07243e-05, gnorm=0.57, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=27022
2022-09-30 16:01:36 - progress_bar.py[line:274] - INFO: epoch 001:  11968 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.8, ups=0.92, wpb=102.5, bsz=40, num_updates=11950, lr=7.07137e-05, gnorm=0.505, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=27032
2022-09-30 16:01:47 - progress_bar.py[line:274] - INFO: epoch 001:  11978 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.9, wpb=101.9, bsz=40, num_updates=11960, lr=7.07032e-05, gnorm=0.667, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27044
2022-09-30 16:01:58 - progress_bar.py[line:274] - INFO: epoch 001:  11988 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94, ups=0.92, wpb=101.7, bsz=40, num_updates=11970, lr=7.06926e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27054
2022-09-30 16:02:09 - progress_bar.py[line:274] - INFO: epoch 001:  11998 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.3, ups=0.9, wpb=103, bsz=40, num_updates=11980, lr=7.0682e-05, gnorm=0.632, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=27066
2022-09-30 16:02:21 - progress_bar.py[line:274] - INFO: epoch 001:  12008 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=83.9, ups=0.82, wpb=102.2, bsz=40, num_updates=11990, lr=7.06715e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=27078
2022-09-30 16:02:34 - progress_bar.py[line:274] - INFO: epoch 001:  12018 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=79.7, ups=0.78, wpb=101.9, bsz=40, num_updates=12000, lr=7.06609e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=27091
2022-09-30 16:02:34 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-30 16:02:35 - train.py[line:549] - INFO: 0 / 14103
2022-09-30 16:02:35 - train.py[line:551] - INFO: load:0.68 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-30 16:05:52 - train.py[line:549] - INFO: 200 / 14103
2022-09-30 16:05:52 - train.py[line:551] - INFO: load:0.71 valid_run:196.54 task_valid:188.48 collect_output:6.74
2022-09-30 16:09:06 - train.py[line:549] - INFO: 400 / 14103
2022-09-30 16:09:06 - train.py[line:551] - INFO: load:0.74 valid_run:391.27 task_valid:376.44 collect_output:12.09
2022-09-30 16:12:16 - train.py[line:549] - INFO: 600 / 14103
2022-09-30 16:12:16 - train.py[line:551] - INFO: load:0.76 valid_run:580.91 task_valid:559.99 collect_output:16.93
2022-09-30 16:15:30 - train.py[line:549] - INFO: 800 / 14103
2022-09-30 16:15:30 - train.py[line:551] - INFO: load:0.79 valid_run:774.35 task_valid:747.40 collect_output:21.77
2022-09-30 16:18:41 - train.py[line:549] - INFO: 1000 / 14103
2022-09-30 16:18:41 - train.py[line:551] - INFO: load:0.81 valid_run:966.10 task_valid:934.54 collect_output:25.08
2022-09-30 16:19:04 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.26 GiB (GPU 0; 39.59 GiB total capacity; 13.62 GiB already allocated; 5.22 GiB free; 31.89 GiB reserved in total by PyTorch)
2022-09-30 16:19:04 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 30        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13948 MB |   19334 MB |    3837 TB |    3837 TB |
|       from large pool |   13803 MB |   19190 MB |    3836 TB |    3836 TB |
|       from small pool |     144 MB |     159 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13948 MB |   19334 MB |    3837 TB |    3837 TB |
|       from large pool |   13803 MB |   19190 MB |    3836 TB |    3836 TB |
|       from small pool |     144 MB |     159 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32656 MB |   37988 MB |  350912 MB |  318256 MB |
|       from large pool |   32510 MB |   37842 MB |  350468 MB |  317958 MB |
|       from small pool |     146 MB |     162 MB |     444 MB |     298 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   18707 MB |   25452 MB |    3414 TB |    3414 TB |
|       from large pool |   18706 MB |   25450 MB |    3412 TB |    3412 TB |
|       from small pool |       1 MB |       6 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3671    |    3695    |  186968 K  |  186964 K  |
|       from large pool |     564    |     585    |   60379 K  |   60378 K  |
|       from small pool |    3107    |    3119    |  126589 K  |  126586 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3671    |    3695    |  186968 K  |  186964 K  |
|       from large pool |     564    |     585    |   60379 K  |   60378 K  |
|       from small pool |    3107    |    3119    |  126589 K  |  126586 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     184    |     210    |     692    |     508    |
|       from large pool |     111    |     129    |     470    |     359    |
|       from small pool |      73    |      81    |     222    |     149    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     125    |     141    |  132041 K  |  132041 K  |
|       from large pool |      86    |      95    |   27341 K  |   27341 K  |
|       from small pool |      39    |      51    |  104700 K  |  104700 K  |
|===========================================================================|

2022-09-30 16:19:04 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-30 16:19:04 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-30 16:21:58 - train.py[line:549] - INFO: 1200 / 14103
2022-09-30 16:21:58 - train.py[line:551] - INFO: load:0.83 valid_run:1162.54 task_valid:1123.79 collect_output:29.85
2022-09-30 16:25:12 - train.py[line:549] - INFO: 1400 / 14103
2022-09-30 16:25:12 - train.py[line:551] - INFO: load:0.86 valid_run:1356.56 task_valid:1313.34 collect_output:33.02
2022-09-30 16:28:25 - train.py[line:549] - INFO: 1600 / 14103
2022-09-30 16:28:25 - train.py[line:551] - INFO: load:0.88 valid_run:1549.83 task_valid:1502.42 collect_output:36.03
2022-09-30 16:31:40 - train.py[line:549] - INFO: 1800 / 14103
2022-09-30 16:31:40 - train.py[line:551] - INFO: load:0.91 valid_run:1744.91 task_valid:1690.41 collect_output:41.82
2022-09-30 16:34:50 - train.py[line:549] - INFO: 2000 / 14103
2022-09-30 16:34:50 - train.py[line:551] - INFO: load:0.94 valid_run:1934.01 task_valid:1876.10 collect_output:44.11
2022-09-30 16:37:58 - train.py[line:549] - INFO: 2200 / 14103
2022-09-30 16:37:58 - train.py[line:551] - INFO: load:0.96 valid_run:2122.67 task_valid:2060.64 collect_output:47.03
2022-09-30 16:41:14 - train.py[line:549] - INFO: 2400 / 14103
2022-09-30 16:41:14 - train.py[line:551] - INFO: load:0.99 valid_run:2318.38 task_valid:2247.50 collect_output:54.65
2022-09-30 16:44:25 - train.py[line:549] - INFO: 2600 / 14103
2022-09-30 16:44:25 - train.py[line:551] - INFO: load:1.01 valid_run:2509.64 task_valid:2435.10 collect_output:57.26
2022-09-30 16:47:35 - train.py[line:549] - INFO: 2800 / 14103
2022-09-30 16:47:35 - train.py[line:551] - INFO: load:1.03 valid_run:2699.09 task_valid:2619.44 collect_output:61.27
2022-09-30 16:50:49 - train.py[line:549] - INFO: 3000 / 14103
2022-09-30 16:50:49 - train.py[line:551] - INFO: load:1.06 valid_run:2893.60 task_valid:2806.23 collect_output:67.84
2022-09-30 16:53:58 - train.py[line:549] - INFO: 3200 / 14103
2022-09-30 16:53:58 - train.py[line:551] - INFO: load:1.08 valid_run:3082.17 task_valid:2988.42 collect_output:73.14
2022-09-30 16:57:16 - train.py[line:549] - INFO: 3400 / 14103
2022-09-30 16:57:16 - train.py[line:551] - INFO: load:1.11 valid_run:3279.75 task_valid:3175.22 collect_output:82.57
2022-09-30 17:00:28 - train.py[line:549] - INFO: 3600 / 14103
2022-09-30 17:00:28 - train.py[line:551] - INFO: load:1.13 valid_run:3471.96 task_valid:3360.72 collect_output:88.21
2022-09-30 17:03:42 - train.py[line:549] - INFO: 3800 / 14103
2022-09-30 17:03:42 - train.py[line:551] - INFO: load:1.16 valid_run:3665.45 task_valid:3544.90 collect_output:96.35
2022-09-30 17:06:49 - train.py[line:549] - INFO: 4000 / 14103
2022-09-30 17:06:49 - train.py[line:551] - INFO: load:1.19 valid_run:3852.96 task_valid:3727.46 collect_output:100.20
2022-09-30 17:10:00 - train.py[line:549] - INFO: 4200 / 14103
2022-09-30 17:10:00 - train.py[line:551] - INFO: load:1.21 valid_run:4043.68 task_valid:3915.29 collect_output:101.97
2022-09-30 17:13:10 - train.py[line:549] - INFO: 4400 / 14103
2022-09-30 17:13:10 - train.py[line:551] - INFO: load:1.24 valid_run:4233.69 task_valid:4096.77 collect_output:109.32
2022-09-30 17:16:22 - train.py[line:549] - INFO: 4600 / 14103
2022-09-30 17:16:22 - train.py[line:551] - INFO: load:1.26 valid_run:4425.44 task_valid:4281.64 collect_output:115.05
2022-09-30 17:19:32 - train.py[line:549] - INFO: 4800 / 14103
2022-09-30 17:19:32 - train.py[line:551] - INFO: load:1.30 valid_run:4615.64 task_valid:4466.62 collect_output:118.97
2022-09-30 17:22:42 - train.py[line:549] - INFO: 5000 / 14103
2022-09-30 17:22:42 - train.py[line:551] - INFO: load:1.32 valid_run:4805.15 task_valid:4651.23 collect_output:122.66
2022-09-30 17:25:59 - train.py[line:549] - INFO: 5200 / 14103
2022-09-30 17:25:59 - train.py[line:551] - INFO: load:1.35 valid_run:5002.03 task_valid:4842.81 collect_output:126.50
2022-09-30 17:29:15 - train.py[line:549] - INFO: 5400 / 14103
2022-09-30 17:29:15 - train.py[line:551] - INFO: load:1.39 valid_run:5198.06 task_valid:5033.79 collect_output:130.31
2022-09-30 17:32:26 - train.py[line:549] - INFO: 5600 / 14103
2022-09-30 17:32:26 - train.py[line:551] - INFO: load:1.41 valid_run:5389.26 task_valid:5220.78 collect_output:133.33
2022-09-30 17:35:39 - train.py[line:549] - INFO: 5800 / 14103
2022-09-30 17:35:39 - train.py[line:551] - INFO: load:1.44 valid_run:5582.30 task_valid:5407.12 collect_output:138.90
2022-09-30 17:38:47 - train.py[line:549] - INFO: 6000 / 14103
2022-09-30 17:38:47 - train.py[line:551] - INFO: load:1.46 valid_run:5769.75 task_valid:5587.95 collect_output:144.24
2022-09-30 17:41:59 - train.py[line:549] - INFO: 6200 / 14103
2022-09-30 17:41:59 - train.py[line:551] - INFO: load:1.48 valid_run:5961.69 task_valid:5773.69 collect_output:149.12
2022-09-30 17:45:08 - train.py[line:549] - INFO: 6400 / 14103
2022-09-30 17:45:08 - train.py[line:551] - INFO: load:1.51 valid_run:6150.93 task_valid:5958.53 collect_output:152.39
2022-09-30 17:48:16 - train.py[line:549] - INFO: 6600 / 14103
2022-09-30 17:48:16 - train.py[line:551] - INFO: load:1.53 valid_run:6338.75 task_valid:6139.30 collect_output:158.27
2022-09-30 17:51:31 - train.py[line:549] - INFO: 6800 / 14103
2022-09-30 17:51:31 - train.py[line:551] - INFO: load:1.56 valid_run:6533.60 task_valid:6324.89 collect_output:166.33
2022-09-30 17:54:42 - train.py[line:549] - INFO: 7000 / 14103
2022-09-30 17:54:42 - train.py[line:551] - INFO: load:1.59 valid_run:6725.30 task_valid:6512.96 collect_output:168.88
2022-09-30 17:57:55 - train.py[line:549] - INFO: 7200 / 14103
2022-09-30 17:57:55 - train.py[line:551] - INFO: load:1.61 valid_run:6917.38 task_valid:6701.87 collect_output:170.96
2022-09-30 18:01:04 - train.py[line:549] - INFO: 7400 / 14103
2022-09-30 18:01:04 - train.py[line:551] - INFO: load:1.63 valid_run:7107.14 task_valid:6883.06 collect_output:178.44
2022-09-30 18:04:13 - train.py[line:549] - INFO: 7600 / 14103
2022-09-30 18:04:13 - train.py[line:551] - INFO: load:1.66 valid_run:7295.19 task_valid:7063.12 collect_output:185.35
2022-09-30 18:07:26 - train.py[line:549] - INFO: 7800 / 14103
2022-09-30 18:07:26 - train.py[line:551] - INFO: load:1.68 valid_run:7489.11 task_valid:7249.41 collect_output:191.87
2022-09-30 18:10:35 - train.py[line:549] - INFO: 8000 / 14103
2022-09-30 18:10:35 - train.py[line:551] - INFO: load:1.70 valid_run:7677.85 task_valid:7428.23 collect_output:200.57
2022-09-30 18:13:45 - train.py[line:549] - INFO: 8200 / 14103
2022-09-30 18:13:45 - train.py[line:551] - INFO: load:1.73 valid_run:7867.64 task_valid:7612.55 collect_output:204.73
2022-09-30 18:16:53 - train.py[line:549] - INFO: 8400 / 14103
2022-09-30 18:16:53 - train.py[line:551] - INFO: load:1.75 valid_run:8055.52 task_valid:7795.02 collect_output:208.94
2022-09-30 18:20:03 - train.py[line:549] - INFO: 8600 / 14103
2022-09-30 18:20:03 - train.py[line:551] - INFO: load:1.78 valid_run:8245.54 task_valid:7979.42 collect_output:213.38
2022-09-30 18:23:14 - train.py[line:549] - INFO: 8800 / 14103
2022-09-30 18:23:14 - train.py[line:551] - INFO: load:1.80 valid_run:8435.89 task_valid:8165.61 collect_output:216.36
2022-09-30 18:26:27 - train.py[line:549] - INFO: 9000 / 14103
2022-09-30 18:26:27 - train.py[line:551] - INFO: load:1.84 valid_run:8629.28 task_valid:8351.90 collect_output:222.16
2022-09-30 18:29:41 - train.py[line:549] - INFO: 9200 / 14103
2022-09-30 18:29:41 - train.py[line:551] - INFO: load:1.86 valid_run:8823.33 task_valid:8534.99 collect_output:231.84
2022-09-30 18:32:54 - train.py[line:549] - INFO: 9400 / 14103
2022-09-30 18:32:54 - train.py[line:551] - INFO: load:1.89 valid_run:9016.56 task_valid:8722.35 collect_output:236.52
2022-09-30 18:36:09 - train.py[line:549] - INFO: 9600 / 14103
2022-09-30 18:36:09 - train.py[line:551] - INFO: load:1.94 valid_run:9210.73 task_valid:8908.99 collect_output:242.70
2022-09-30 18:39:21 - train.py[line:549] - INFO: 9800 / 14103
2022-09-30 18:39:21 - train.py[line:551] - INFO: load:1.97 valid_run:9403.47 task_valid:9098.70 collect_output:244.48
2022-09-30 18:42:33 - train.py[line:549] - INFO: 10000 / 14103
2022-09-30 18:42:33 - train.py[line:551] - INFO: load:1.99 valid_run:9595.00 task_valid:9286.89 collect_output:246.64
2022-09-30 18:45:43 - train.py[line:549] - INFO: 10200 / 14103
2022-09-30 18:45:43 - train.py[line:551] - INFO: load:2.01 valid_run:9784.97 task_valid:9470.01 collect_output:252.35
2022-09-30 18:48:55 - train.py[line:549] - INFO: 10400 / 14103
2022-09-30 18:48:55 - train.py[line:551] - INFO: load:2.04 valid_run:9976.56 task_valid:9653.94 collect_output:258.84
2022-09-30 18:52:07 - train.py[line:549] - INFO: 10600 / 14103
2022-09-30 18:52:07 - train.py[line:551] - INFO: load:2.06 valid_run:10168.86 task_valid:9836.26 collect_output:267.74
2022-09-30 18:55:18 - train.py[line:549] - INFO: 10800 / 14103
2022-09-30 18:55:18 - train.py[line:551] - INFO: load:2.08 valid_run:10359.67 task_valid:10019.44 collect_output:274.24
2022-09-30 18:58:28 - train.py[line:549] - INFO: 11000 / 14103
2022-09-30 18:58:28 - train.py[line:551] - INFO: load:2.11 valid_run:10550.08 task_valid:10203.82 collect_output:279.18
2022-09-30 19:01:42 - train.py[line:549] - INFO: 11200 / 14103
2022-09-30 19:01:42 - train.py[line:551] - INFO: load:2.13 valid_run:10743.83 task_valid:10389.39 collect_output:286.19
2022-09-30 19:04:57 - train.py[line:549] - INFO: 11400 / 14103
2022-09-30 19:04:57 - train.py[line:551] - INFO: load:2.16 valid_run:10938.74 task_valid:10580.91 collect_output:288.53
2022-09-30 19:08:07 - train.py[line:549] - INFO: 11600 / 14103
2022-09-30 19:08:07 - train.py[line:551] - INFO: load:2.18 valid_run:11128.50 task_valid:10765.85 collect_output:292.22
2022-09-30 19:11:18 - train.py[line:549] - INFO: 11800 / 14103
2022-09-30 19:11:18 - train.py[line:551] - INFO: load:2.20 valid_run:11319.19 task_valid:10951.95 collect_output:295.70
2022-09-30 19:14:26 - train.py[line:549] - INFO: 12000 / 14103
2022-09-30 19:14:26 - train.py[line:551] - INFO: load:2.23 valid_run:11507.41 task_valid:11134.67 collect_output:300.01
2022-09-30 19:17:38 - train.py[line:549] - INFO: 12200 / 14103
2022-09-30 19:17:38 - train.py[line:551] - INFO: load:2.25 valid_run:11699.46 task_valid:11321.24 collect_output:304.22
2022-09-30 19:20:48 - train.py[line:549] - INFO: 12400 / 14103
2022-09-30 19:20:48 - train.py[line:551] - INFO: load:2.28 valid_run:11889.29 task_valid:11505.78 collect_output:308.37
2022-09-30 19:23:57 - train.py[line:549] - INFO: 12600 / 14103
2022-09-30 19:23:57 - train.py[line:551] - INFO: load:2.30 valid_run:12078.57 task_valid:11689.04 collect_output:313.23
2022-09-30 19:27:04 - train.py[line:549] - INFO: 12800 / 14103
2022-09-30 19:27:04 - train.py[line:551] - INFO: load:2.33 valid_run:12264.89 task_valid:11871.07 collect_output:316.39
2022-09-30 19:30:24 - train.py[line:549] - INFO: 13000 / 14103
2022-09-30 19:30:24 - train.py[line:551] - INFO: load:2.36 valid_run:12464.91 task_valid:12060.79 collect_output:325.11
2022-09-30 19:33:35 - train.py[line:549] - INFO: 13200 / 14103
2022-09-30 19:33:35 - train.py[line:551] - INFO: load:2.38 valid_run:12655.99 task_valid:12243.98 collect_output:331.75
2022-09-30 19:36:47 - train.py[line:549] - INFO: 13400 / 14103
2022-09-30 19:36:47 - train.py[line:551] - INFO: load:2.41 valid_run:12848.19 task_valid:12426.25 collect_output:340.52
2022-09-30 19:39:57 - train.py[line:549] - INFO: 13600 / 14103
2022-09-30 19:39:57 - train.py[line:551] - INFO: load:2.43 valid_run:13037.84 task_valid:12607.79 collect_output:347.45
2022-09-30 19:43:09 - train.py[line:549] - INFO: 13800 / 14103
2022-09-30 19:43:09 - train.py[line:551] - INFO: load:2.46 valid_run:13229.81 task_valid:12794.48 collect_output:351.55
2022-09-30 19:46:21 - train.py[line:549] - INFO: 14000 / 14103
2022-09-30 19:46:21 - train.py[line:551] - INFO: load:2.48 valid_run:13421.47 task_valid:12979.95 collect_output:356.57
2022-09-30 19:47:57 - train.py[line:572] - INFO: scores:torch.Size([282060]) preds:torch.Size([282060]) sample_ids:torch.Size([282060])

====================================================================================================
SGG eval:     R @ 50: 0.6284;     R @ 100: 0.6511;     R @ 500: 0.6605;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1702;    mR @ 100: 0.1869;    mR @ 500: 0.2147;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0647) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2083) (attached to:0.0000) (behind:0.3900) (belonging to:0.0000) (between:0.0000) (carrying:0.7202) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.7604) (holding:0.2907) (in:0.3371) (in front of:0.0651) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5655) (of:0.4753) (on:0.8837) (on back of:0.0000) (over:0.1111) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6667) (says:0.0000) (sitting on:0.3415) (standing on:0.0000) (to:0.0000) (under:0.2870) (using:1.0000) (walking in:0.0000) (walking on:0.5009) (watching:0.3333) (wearing:0.9879) (wears:0.0000) (with:0.1045) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6284;     R @ 100: 0.6511;     R @ 500: 0.6605;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1702;    mR @ 100: 0.1869;    mR @ 500: 0.2147;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0647) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2083) (attached to:0.0000) (behind:0.3900) (belonging to:0.0000) (between:0.0000) (carrying:0.7202) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.7604) (holding:0.2907) (in:0.3371) (in front of:0.0651) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5655) (of:0.4753) (on:0.8837) (on back of:0.0000) (over:0.1111) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6667) (says:0.0000) (sitting on:0.3415) (standing on:0.0000) (to:0.0000) (under:0.2870) (using:1.0000) (walking in:0.0000) (walking on:0.5009) (watching:0.3333) (wearing:0.9879) (wears:0.0000) (with:0.1045) 
--------------------------------------------------------
====================================================================================================

2022-09-30 19:48:17 - train.py[line:486] - INFO: 0.6510949987947803
2022-09-30 19:48:18 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.311 | loss_v1 0 | loss_v2 0 | nll_loss 0.113 | ntokens 59.526 | nsentences 20 | sample_size 59.526 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.651095 | ppl 1.08 | vqa_score 0.8654 | wps 62 | wpb 59.5 | bsz 20 | num_updates 12000 | best_R@100 0.651095
2022-09-30 19:48:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2022-09-30 19:48:18 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480/checkpoint_1_12000.pt
2022-09-30 19:48:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480/checkpoint_1_12000.pt
2022-09-30 19:48:28 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.6510949987947803) (writing took 10.558968137949705 seconds)
2022-09-30 19:48:39 - progress_bar.py[line:274] - INFO: epoch 001:  12028 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=0.1, ups=0, wpb=102.1, bsz=40, num_updates=12010, lr=7.06504e-05, gnorm=0.602, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40656
2022-09-30 19:48:50 - progress_bar.py[line:274] - INFO: epoch 001:  12038 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=12020, lr=7.06398e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=40667
2022-09-30 19:49:02 - progress_bar.py[line:274] - INFO: epoch 001:  12048 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.5, ups=0.89, wpb=102.3, bsz=40, num_updates=12030, lr=7.06292e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=40678
2022-09-30 19:49:12 - progress_bar.py[line:274] - INFO: epoch 001:  12058 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.1, ups=0.91, wpb=102.3, bsz=40, num_updates=12040, lr=7.06187e-05, gnorm=0.56, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40689
2022-09-30 19:49:23 - progress_bar.py[line:274] - INFO: epoch 001:  12068 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.6, ups=0.92, wpb=102.2, bsz=40, num_updates=12050, lr=7.06081e-05, gnorm=0.548, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40700
2022-09-30 19:49:35 - progress_bar.py[line:274] - INFO: epoch 001:  12078 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.88, wpb=102.4, bsz=40, num_updates=12060, lr=7.05976e-05, gnorm=0.607, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40712
2022-09-30 19:49:46 - progress_bar.py[line:274] - INFO: epoch 001:  12088 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.2, ups=0.9, wpb=102.4, bsz=40, num_updates=12070, lr=7.0587e-05, gnorm=0.513, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40723
2022-09-30 19:49:57 - progress_bar.py[line:274] - INFO: epoch 001:  12098 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.6, ups=0.87, wpb=101.3, bsz=40, num_updates=12080, lr=7.05764e-05, gnorm=0.584, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=40734
2022-09-30 19:50:08 - progress_bar.py[line:274] - INFO: epoch 001:  12108 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.6, ups=0.91, wpb=102.3, bsz=40, num_updates=12090, lr=7.05659e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40745
2022-09-30 19:50:20 - progress_bar.py[line:274] - INFO: epoch 001:  12118 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=12100, lr=7.05553e-05, gnorm=0.622, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40756
2022-09-30 19:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  12128 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.88, wpb=101.1, bsz=40, num_updates=12110, lr=7.05448e-05, gnorm=0.574, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40768
2022-09-30 19:50:42 - progress_bar.py[line:274] - INFO: epoch 001:  12138 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.6, ups=0.9, wpb=101.3, bsz=40, num_updates=12120, lr=7.05342e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40779
2022-09-30 19:50:53 - progress_bar.py[line:274] - INFO: epoch 001:  12148 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.1, ups=0.89, wpb=101.8, bsz=40, num_updates=12130, lr=7.05236e-05, gnorm=0.633, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40790
2022-09-30 19:51:05 - progress_bar.py[line:274] - INFO: epoch 001:  12158 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.89, wpb=102.7, bsz=40, num_updates=12140, lr=7.05131e-05, gnorm=0.557, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=40801
2022-09-30 19:51:16 - progress_bar.py[line:274] - INFO: epoch 001:  12168 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.88, wpb=103.6, bsz=40, num_updates=12150, lr=7.05025e-05, gnorm=0.627, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=40813
2022-09-30 19:51:27 - progress_bar.py[line:274] - INFO: epoch 001:  12178 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.1, ups=0.9, wpb=102.4, bsz=40, num_updates=12160, lr=7.0492e-05, gnorm=0.599, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40824
2022-09-30 19:51:38 - progress_bar.py[line:274] - INFO: epoch 001:  12188 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.88, wpb=102, bsz=40, num_updates=12170, lr=7.04814e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40835
2022-09-30 19:51:50 - progress_bar.py[line:274] - INFO: epoch 001:  12198 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=85.8, ups=0.84, wpb=102.1, bsz=40, num_updates=12180, lr=7.04708e-05, gnorm=0.506, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=40847
2022-09-30 19:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  12208 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.7, ups=0.87, wpb=99.7, bsz=40, num_updates=12190, lr=7.04603e-05, gnorm=0.598, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40859
2022-09-30 19:52:13 - progress_bar.py[line:274] - INFO: epoch 001:  12218 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.9, wpb=100.3, bsz=40, num_updates=12200, lr=7.04497e-05, gnorm=0.62, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40870
2022-09-30 19:52:24 - progress_bar.py[line:274] - INFO: epoch 001:  12228 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.87, wpb=101.9, bsz=40, num_updates=12210, lr=7.04392e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40881
2022-09-30 19:52:36 - progress_bar.py[line:274] - INFO: epoch 001:  12238 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.89, wpb=100.8, bsz=40, num_updates=12220, lr=7.04286e-05, gnorm=0.617, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40892
2022-09-30 19:52:47 - progress_bar.py[line:274] - INFO: epoch 001:  12248 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.89, wpb=101.5, bsz=40, num_updates=12230, lr=7.0418e-05, gnorm=0.636, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40904
2022-09-30 19:52:58 - progress_bar.py[line:274] - INFO: epoch 001:  12258 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.9, wpb=99.8, bsz=40, num_updates=12240, lr=7.04075e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40915
2022-09-30 19:53:10 - progress_bar.py[line:274] - INFO: epoch 001:  12268 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.5, ups=0.87, wpb=101, bsz=40, num_updates=12250, lr=7.03969e-05, gnorm=0.663, clip=10, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=40926
2022-09-30 19:53:21 - progress_bar.py[line:274] - INFO: epoch 001:  12278 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.9, wpb=102, bsz=40, num_updates=12260, lr=7.03864e-05, gnorm=0.725, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=40937
2022-09-30 19:53:32 - progress_bar.py[line:274] - INFO: epoch 001:  12288 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.9, wpb=101.5, bsz=40, num_updates=12270, lr=7.03758e-05, gnorm=0.67, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=40949
2022-09-30 19:53:43 - progress_bar.py[line:274] - INFO: epoch 001:  12298 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.9, wpb=100.5, bsz=40, num_updates=12280, lr=7.03652e-05, gnorm=0.645, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40960
2022-09-30 19:53:54 - progress_bar.py[line:274] - INFO: epoch 001:  12308 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.89, wpb=101.7, bsz=40, num_updates=12290, lr=7.03547e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=40971
2022-09-30 19:54:05 - progress_bar.py[line:274] - INFO: epoch 001:  12318 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.5, ups=0.9, wpb=102.9, bsz=40, num_updates=12300, lr=7.03441e-05, gnorm=0.629, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40982
2022-09-30 19:54:17 - progress_bar.py[line:274] - INFO: epoch 001:  12328 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=12310, lr=7.03336e-05, gnorm=0.633, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=40993
2022-09-30 19:54:28 - progress_bar.py[line:274] - INFO: epoch 001:  12338 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.89, wpb=100.5, bsz=40, num_updates=12320, lr=7.0323e-05, gnorm=0.674, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41005
2022-09-30 19:54:39 - progress_bar.py[line:274] - INFO: epoch 001:  12348 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.89, wpb=101.4, bsz=40, num_updates=12330, lr=7.03124e-05, gnorm=0.529, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41016
2022-09-30 19:54:50 - progress_bar.py[line:274] - INFO: epoch 001:  12358 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.8, ups=0.89, wpb=99.1, bsz=40, num_updates=12340, lr=7.03019e-05, gnorm=0.783, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41027
2022-09-30 19:55:02 - progress_bar.py[line:274] - INFO: epoch 001:  12368 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89, ups=0.87, wpb=102.7, bsz=40, num_updates=12350, lr=7.02913e-05, gnorm=0.669, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=41039
2022-09-30 19:55:13 - progress_bar.py[line:274] - INFO: epoch 001:  12378 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.6, ups=0.92, wpb=100.7, bsz=40, num_updates=12360, lr=7.02808e-05, gnorm=0.635, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41050
2022-09-30 19:55:24 - progress_bar.py[line:274] - INFO: epoch 001:  12388 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.2, ups=0.88, wpb=100.6, bsz=40, num_updates=12370, lr=7.02702e-05, gnorm=0.728, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=41061
2022-09-30 19:55:36 - progress_bar.py[line:274] - INFO: epoch 001:  12398 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.88, wpb=102.7, bsz=40, num_updates=12380, lr=7.02596e-05, gnorm=0.599, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=41072
2022-09-30 19:55:47 - progress_bar.py[line:274] - INFO: epoch 001:  12408 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.89, wpb=101.1, bsz=40, num_updates=12390, lr=7.02491e-05, gnorm=0.624, clip=10, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41084
2022-09-30 19:55:58 - progress_bar.py[line:274] - INFO: epoch 001:  12418 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.89, wpb=101.3, bsz=40, num_updates=12400, lr=7.02385e-05, gnorm=0.56, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41095
2022-09-30 19:56:10 - progress_bar.py[line:274] - INFO: epoch 001:  12428 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.5, ups=0.88, wpb=98.7, bsz=40, num_updates=12410, lr=7.0228e-05, gnorm=0.594, clip=0, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=41106
2022-09-30 19:56:13 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 19:56:22 - progress_bar.py[line:274] - INFO: epoch 001:  12439 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=83.7, ups=0.83, wpb=101.4, bsz=40, num_updates=12420, lr=7.02174e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=41118
2022-09-30 19:56:33 - progress_bar.py[line:274] - INFO: epoch 001:  12449 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.9, wpb=102.2, bsz=40, num_updates=12430, lr=7.02068e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41130
2022-09-30 19:56:44 - progress_bar.py[line:274] - INFO: epoch 001:  12459 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.9, ups=0.9, wpb=101, bsz=40, num_updates=12440, lr=7.01963e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41141
2022-09-30 19:56:55 - progress_bar.py[line:274] - INFO: epoch 001:  12469 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.89, wpb=100.4, bsz=40, num_updates=12450, lr=7.01857e-05, gnorm=0.664, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41152
2022-09-30 19:57:06 - progress_bar.py[line:274] - INFO: epoch 001:  12479 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.89, wpb=101.8, bsz=40, num_updates=12460, lr=7.01752e-05, gnorm=0.557, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41163
2022-09-30 19:57:18 - progress_bar.py[line:274] - INFO: epoch 001:  12489 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.89, wpb=101.2, bsz=40, num_updates=12470, lr=7.01646e-05, gnorm=0.806, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41174
2022-09-30 19:57:29 - progress_bar.py[line:274] - INFO: epoch 001:  12499 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90, ups=0.89, wpb=101.4, bsz=40, num_updates=12480, lr=7.0154e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41186
2022-09-30 19:57:40 - progress_bar.py[line:274] - INFO: epoch 001:  12509 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.89, wpb=102.4, bsz=40, num_updates=12490, lr=7.01435e-05, gnorm=0.642, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=41197
2022-09-30 19:57:51 - progress_bar.py[line:274] - INFO: epoch 001:  12519 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.6, ups=0.89, wpb=99.8, bsz=40, num_updates=12500, lr=7.01329e-05, gnorm=0.633, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=41208
2022-09-30 19:58:03 - progress_bar.py[line:274] - INFO: epoch 001:  12529 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.88, wpb=101.3, bsz=40, num_updates=12510, lr=7.01224e-05, gnorm=0.645, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41220
2022-09-30 19:58:14 - progress_bar.py[line:274] - INFO: epoch 001:  12539 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.89, wpb=102.9, bsz=40, num_updates=12520, lr=7.01118e-05, gnorm=0.649, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41231
2022-09-30 19:58:26 - progress_bar.py[line:274] - INFO: epoch 001:  12549 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.3, ups=0.86, wpb=101.1, bsz=40, num_updates=12530, lr=7.01012e-05, gnorm=0.522, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=41242
2022-09-30 19:58:37 - progress_bar.py[line:274] - INFO: epoch 001:  12559 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.6, ups=0.89, wpb=99.6, bsz=40, num_updates=12540, lr=7.00907e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41254
2022-09-30 19:58:48 - progress_bar.py[line:274] - INFO: epoch 001:  12569 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.7, ups=0.9, wpb=102.7, bsz=40, num_updates=12550, lr=7.00801e-05, gnorm=0.574, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41265
2022-09-30 19:58:59 - progress_bar.py[line:274] - INFO: epoch 001:  12579 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=12560, lr=7.00696e-05, gnorm=0.661, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41276
2022-09-30 19:59:10 - progress_bar.py[line:274] - INFO: epoch 001:  12589 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.91, wpb=100.1, bsz=40, num_updates=12570, lr=7.0059e-05, gnorm=0.625, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41287
2022-09-30 19:59:22 - progress_bar.py[line:274] - INFO: epoch 001:  12599 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.9, wpb=100, bsz=40, num_updates=12580, lr=7.00484e-05, gnorm=0.665, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41298
2022-09-30 19:59:33 - progress_bar.py[line:274] - INFO: epoch 001:  12609 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.91, wpb=102.3, bsz=40, num_updates=12590, lr=7.00379e-05, gnorm=0.623, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41309
2022-09-30 19:59:44 - progress_bar.py[line:274] - INFO: epoch 001:  12619 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.88, wpb=101.8, bsz=40, num_updates=12600, lr=7.00273e-05, gnorm=0.659, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41321
2022-09-30 19:59:55 - progress_bar.py[line:274] - INFO: epoch 001:  12629 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.88, wpb=103, bsz=40, num_updates=12610, lr=7.00168e-05, gnorm=0.617, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41332
2022-09-30 20:00:07 - progress_bar.py[line:274] - INFO: epoch 001:  12639 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.4, ups=0.89, wpb=100.9, bsz=40, num_updates=12620, lr=7.00062e-05, gnorm=0.692, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=41343
2022-09-30 20:00:18 - progress_bar.py[line:274] - INFO: epoch 001:  12649 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=12630, lr=6.99956e-05, gnorm=0.645, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41355
2022-09-30 20:00:29 - progress_bar.py[line:274] - INFO: epoch 001:  12659 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.3, ups=0.9, wpb=102.9, bsz=40, num_updates=12640, lr=6.99851e-05, gnorm=0.58, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41366
2022-09-30 20:00:40 - progress_bar.py[line:274] - INFO: epoch 001:  12669 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.92, wpb=101.2, bsz=40, num_updates=12650, lr=6.99745e-05, gnorm=0.558, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=41377
2022-09-30 20:00:51 - progress_bar.py[line:274] - INFO: epoch 001:  12679 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=100.8, bsz=40, num_updates=12660, lr=6.9964e-05, gnorm=0.585, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41388
2022-09-30 20:01:02 - progress_bar.py[line:274] - INFO: epoch 001:  12689 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.89, wpb=103.2, bsz=40, num_updates=12670, lr=6.99534e-05, gnorm=0.613, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=41399
2022-09-30 20:01:14 - progress_bar.py[line:274] - INFO: epoch 001:  12699 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=12680, lr=6.99428e-05, gnorm=0.652, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41410
2022-09-30 20:01:25 - progress_bar.py[line:274] - INFO: epoch 001:  12709 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.88, wpb=103, bsz=40, num_updates=12690, lr=6.99323e-05, gnorm=0.638, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41422
2022-09-30 20:01:36 - progress_bar.py[line:274] - INFO: epoch 001:  12719 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=12700, lr=6.99217e-05, gnorm=0.611, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41433
2022-09-30 20:01:47 - progress_bar.py[line:274] - INFO: epoch 001:  12729 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.9, wpb=101.1, bsz=40, num_updates=12710, lr=6.99112e-05, gnorm=0.638, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41444
2022-09-30 20:01:58 - progress_bar.py[line:274] - INFO: epoch 001:  12739 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.92, wpb=101, bsz=40, num_updates=12720, lr=6.99006e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41455
2022-09-30 20:02:09 - progress_bar.py[line:274] - INFO: epoch 001:  12749 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.91, wpb=102.1, bsz=40, num_updates=12730, lr=6.989e-05, gnorm=0.637, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41466
2022-09-30 20:02:20 - progress_bar.py[line:274] - INFO: epoch 001:  12759 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.89, wpb=100, bsz=40, num_updates=12740, lr=6.98795e-05, gnorm=0.648, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41477
2022-09-30 20:02:32 - progress_bar.py[line:274] - INFO: epoch 001:  12769 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=84.3, ups=0.83, wpb=101.8, bsz=40, num_updates=12750, lr=6.98689e-05, gnorm=0.643, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=41489
2022-09-30 20:02:45 - progress_bar.py[line:274] - INFO: epoch 001:  12779 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=78.8, ups=0.79, wpb=100, bsz=40, num_updates=12760, lr=6.98584e-05, gnorm=0.707, clip=10, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=41502
2022-09-30 20:02:57 - progress_bar.py[line:274] - INFO: epoch 001:  12789 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=82.9, ups=0.81, wpb=102, bsz=40, num_updates=12770, lr=6.98478e-05, gnorm=0.624, clip=10, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=41514
2022-09-30 20:03:09 - progress_bar.py[line:274] - INFO: epoch 001:  12799 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.4, ups=0.84, wpb=101.3, bsz=40, num_updates=12780, lr=6.98372e-05, gnorm=0.624, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=41526
2022-09-30 20:03:21 - progress_bar.py[line:274] - INFO: epoch 001:  12809 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.6, ups=0.87, wpb=99.7, bsz=40, num_updates=12790, lr=6.98267e-05, gnorm=0.607, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41537
2022-09-30 20:03:31 - progress_bar.py[line:274] - INFO: epoch 001:  12819 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.2, ups=0.92, wpb=101.4, bsz=40, num_updates=12800, lr=6.98161e-05, gnorm=0.579, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41548
2022-09-30 20:03:42 - progress_bar.py[line:274] - INFO: epoch 001:  12829 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.6, ups=0.92, wpb=102.4, bsz=40, num_updates=12810, lr=6.98056e-05, gnorm=0.582, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41559
2022-09-30 20:03:54 - progress_bar.py[line:274] - INFO: epoch 001:  12839 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.87, wpb=101.9, bsz=40, num_updates=12820, lr=6.9795e-05, gnorm=0.574, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41570
2022-09-30 20:04:05 - progress_bar.py[line:274] - INFO: epoch 001:  12849 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=101.8, bsz=40, num_updates=12830, lr=6.97844e-05, gnorm=0.599, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=41582
2022-09-30 20:04:16 - progress_bar.py[line:274] - INFO: epoch 001:  12859 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.7, ups=0.87, wpb=99.9, bsz=40, num_updates=12840, lr=6.97739e-05, gnorm=0.582, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41593
2022-09-30 20:04:27 - progress_bar.py[line:274] - INFO: epoch 001:  12869 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94, ups=0.93, wpb=101.2, bsz=40, num_updates=12850, lr=6.97633e-05, gnorm=0.613, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41604
2022-09-30 20:04:39 - progress_bar.py[line:274] - INFO: epoch 001:  12879 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.8, ups=0.88, wpb=101, bsz=40, num_updates=12860, lr=6.97528e-05, gnorm=0.604, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41615
2022-09-30 20:04:50 - progress_bar.py[line:274] - INFO: epoch 001:  12889 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.89, wpb=100, bsz=40, num_updates=12870, lr=6.97422e-05, gnorm=0.613, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41627
2022-09-30 20:05:01 - progress_bar.py[line:274] - INFO: epoch 001:  12899 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.6, ups=0.88, wpb=101.4, bsz=40, num_updates=12880, lr=6.97316e-05, gnorm=0.656, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41638
2022-09-30 20:05:12 - progress_bar.py[line:274] - INFO: epoch 001:  12909 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.89, wpb=100.6, bsz=40, num_updates=12890, lr=6.97211e-05, gnorm=0.615, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=41649
2022-09-30 20:05:24 - progress_bar.py[line:274] - INFO: epoch 001:  12919 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=12900, lr=6.97105e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=41660
2022-09-30 20:05:35 - progress_bar.py[line:274] - INFO: epoch 001:  12929 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.2, ups=0.88, wpb=101.7, bsz=40, num_updates=12910, lr=6.97e-05, gnorm=0.583, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41672
2022-09-30 20:05:46 - progress_bar.py[line:274] - INFO: epoch 001:  12939 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.88, wpb=102.2, bsz=40, num_updates=12920, lr=6.96894e-05, gnorm=0.573, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41683
2022-09-30 20:05:58 - progress_bar.py[line:274] - INFO: epoch 001:  12949 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.6, ups=0.88, wpb=100.9, bsz=40, num_updates=12930, lr=6.96789e-05, gnorm=0.601, clip=10, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41695
2022-09-30 20:06:09 - progress_bar.py[line:274] - INFO: epoch 001:  12959 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=12940, lr=6.96683e-05, gnorm=0.526, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=41706
2022-09-30 20:06:20 - progress_bar.py[line:274] - INFO: epoch 001:  12969 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89, ups=0.88, wpb=101.3, bsz=40, num_updates=12950, lr=6.96577e-05, gnorm=0.537, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41717
2022-09-30 20:06:25 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 20:06:32 - progress_bar.py[line:274] - INFO: epoch 001:  12980 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.9, ups=0.85, wpb=102.6, bsz=40, num_updates=12960, lr=6.96472e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=41729
2022-09-30 20:06:43 - progress_bar.py[line:274] - INFO: epoch 001:  12990 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.9, ups=0.89, wpb=103.3, bsz=40, num_updates=12970, lr=6.96366e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41740
2022-09-30 20:06:55 - progress_bar.py[line:274] - INFO: epoch 001:  13000 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.4, ups=0.87, wpb=100.9, bsz=40, num_updates=12980, lr=6.96261e-05, gnorm=0.569, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=41752
2022-09-30 20:07:06 - progress_bar.py[line:274] - INFO: epoch 001:  13010 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.89, wpb=102.8, bsz=40, num_updates=12990, lr=6.96155e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=41763
2022-09-30 20:07:18 - progress_bar.py[line:274] - INFO: epoch 001:  13020 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.89, wpb=102.5, bsz=40, num_updates=13000, lr=6.96049e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41774
2022-09-30 20:07:29 - progress_bar.py[line:274] - INFO: epoch 001:  13030 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.5, ups=0.91, wpb=102.7, bsz=40, num_updates=13010, lr=6.95944e-05, gnorm=0.591, clip=0, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=41786
2022-09-30 20:07:41 - progress_bar.py[line:274] - INFO: epoch 001:  13040 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88, ups=0.88, wpb=100.3, bsz=40, num_updates=13020, lr=6.95838e-05, gnorm=0.609, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41797
2022-09-30 20:07:52 - progress_bar.py[line:274] - INFO: epoch 001:  13050 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.9, wpb=101.4, bsz=40, num_updates=13030, lr=6.95733e-05, gnorm=0.67, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41808
2022-09-30 20:08:03 - progress_bar.py[line:274] - INFO: epoch 001:  13060 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.88, wpb=103.2, bsz=40, num_updates=13040, lr=6.95627e-05, gnorm=0.658, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41820
2022-09-30 20:08:14 - progress_bar.py[line:274] - INFO: epoch 001:  13070 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.8, ups=0.88, wpb=100.1, bsz=40, num_updates=13050, lr=6.95521e-05, gnorm=0.6, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41831
2022-09-30 20:08:25 - progress_bar.py[line:274] - INFO: epoch 001:  13080 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.91, wpb=100.8, bsz=40, num_updates=13060, lr=6.95416e-05, gnorm=0.623, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41842
2022-09-30 20:08:37 - progress_bar.py[line:274] - INFO: epoch 001:  13090 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=13070, lr=6.9531e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=41853
2022-09-30 20:08:48 - progress_bar.py[line:274] - INFO: epoch 001:  13100 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.89, wpb=102.1, bsz=40, num_updates=13080, lr=6.95205e-05, gnorm=0.699, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41865
2022-09-30 20:08:59 - progress_bar.py[line:274] - INFO: epoch 001:  13110 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.4, ups=0.91, wpb=102.3, bsz=40, num_updates=13090, lr=6.95099e-05, gnorm=0.613, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=41876
2022-09-30 20:09:10 - progress_bar.py[line:274] - INFO: epoch 001:  13120 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.1, ups=0.93, wpb=100.8, bsz=40, num_updates=13100, lr=6.94993e-05, gnorm=0.619, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41886
2022-09-30 20:09:21 - progress_bar.py[line:274] - INFO: epoch 001:  13130 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=13110, lr=6.94888e-05, gnorm=0.575, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41898
2022-09-30 20:09:32 - progress_bar.py[line:274] - INFO: epoch 001:  13140 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.87, wpb=102.1, bsz=40, num_updates=13120, lr=6.94782e-05, gnorm=0.597, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41909
2022-09-30 20:09:44 - progress_bar.py[line:274] - INFO: epoch 001:  13150 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92, ups=0.9, wpb=101.8, bsz=40, num_updates=13130, lr=6.94677e-05, gnorm=0.587, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41920
2022-09-30 20:09:55 - progress_bar.py[line:274] - INFO: epoch 001:  13160 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.4, ups=0.9, wpb=102.4, bsz=40, num_updates=13140, lr=6.94571e-05, gnorm=0.578, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41931
2022-09-30 20:10:06 - progress_bar.py[line:274] - INFO: epoch 001:  13170 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.9, wpb=101.6, bsz=40, num_updates=13150, lr=6.94465e-05, gnorm=0.626, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41942
2022-09-30 20:10:17 - progress_bar.py[line:274] - INFO: epoch 001:  13180 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.91, wpb=102.2, bsz=40, num_updates=13160, lr=6.9436e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=41954
2022-09-30 20:10:28 - progress_bar.py[line:274] - INFO: epoch 001:  13190 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.8, ups=0.91, wpb=102.1, bsz=40, num_updates=13170, lr=6.94254e-05, gnorm=0.598, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=41965
2022-09-30 20:10:39 - progress_bar.py[line:274] - INFO: epoch 001:  13200 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90, ups=0.9, wpb=99.7, bsz=40, num_updates=13180, lr=6.94149e-05, gnorm=0.647, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41976
2022-09-30 20:10:50 - progress_bar.py[line:274] - INFO: epoch 001:  13210 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.6, ups=0.88, wpb=99.8, bsz=40, num_updates=13190, lr=6.94043e-05, gnorm=0.71, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=41987
2022-09-30 20:11:02 - progress_bar.py[line:274] - INFO: epoch 001:  13220 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.88, wpb=102.1, bsz=40, num_updates=13200, lr=6.93937e-05, gnorm=0.556, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41998
2022-09-30 20:11:13 - progress_bar.py[line:274] - INFO: epoch 001:  13230 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.3, ups=0.9, wpb=103.2, bsz=40, num_updates=13210, lr=6.93832e-05, gnorm=0.612, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42009
2022-09-30 20:11:24 - progress_bar.py[line:274] - INFO: epoch 001:  13240 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.9, wpb=99.9, bsz=40, num_updates=13220, lr=6.93726e-05, gnorm=0.649, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42021
2022-09-30 20:11:35 - progress_bar.py[line:274] - INFO: epoch 001:  13250 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.88, wpb=103, bsz=40, num_updates=13230, lr=6.93621e-05, gnorm=0.604, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42032
2022-09-30 20:11:46 - progress_bar.py[line:274] - INFO: epoch 001:  13260 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.9, wpb=101, bsz=40, num_updates=13240, lr=6.93515e-05, gnorm=0.668, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42043
2022-09-30 20:11:57 - progress_bar.py[line:274] - INFO: epoch 001:  13270 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.9, wpb=101, bsz=40, num_updates=13250, lr=6.93409e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42054
2022-09-30 20:12:09 - progress_bar.py[line:274] - INFO: epoch 001:  13280 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.2, ups=0.86, wpb=102.6, bsz=40, num_updates=13260, lr=6.93304e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=42066
2022-09-30 20:12:22 - progress_bar.py[line:274] - INFO: epoch 001:  13290 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=80.8, ups=0.8, wpb=100.7, bsz=40, num_updates=13270, lr=6.93198e-05, gnorm=0.648, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=42078
2022-09-30 20:12:34 - progress_bar.py[line:274] - INFO: epoch 001:  13300 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=84.6, ups=0.83, wpb=101.5, bsz=40, num_updates=13280, lr=6.93093e-05, gnorm=0.63, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=42090
2022-09-30 20:12:45 - progress_bar.py[line:274] - INFO: epoch 001:  13310 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.8, ups=0.89, wpb=100.2, bsz=40, num_updates=13290, lr=6.92987e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42102
2022-09-30 20:12:56 - progress_bar.py[line:274] - INFO: epoch 001:  13320 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.89, wpb=101, bsz=40, num_updates=13300, lr=6.92881e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42113
2022-09-30 20:13:08 - progress_bar.py[line:274] - INFO: epoch 001:  13330 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.5, ups=0.88, wpb=99.5, bsz=40, num_updates=13310, lr=6.92776e-05, gnorm=0.622, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42124
2022-09-30 20:13:19 - progress_bar.py[line:274] - INFO: epoch 001:  13340 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=13320, lr=6.9267e-05, gnorm=0.6, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42135
2022-09-30 20:13:30 - progress_bar.py[line:274] - INFO: epoch 001:  13350 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.5, ups=0.89, wpb=99.4, bsz=40, num_updates=13330, lr=6.92565e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42147
2022-09-30 20:13:41 - progress_bar.py[line:274] - INFO: epoch 001:  13360 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.88, wpb=101.9, bsz=40, num_updates=13340, lr=6.92459e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42158
2022-09-30 20:13:53 - progress_bar.py[line:274] - INFO: epoch 001:  13370 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88, ups=0.87, wpb=101.4, bsz=40, num_updates=13350, lr=6.92353e-05, gnorm=0.532, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42170
2022-09-30 20:14:04 - progress_bar.py[line:274] - INFO: epoch 001:  13380 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=13360, lr=6.92248e-05, gnorm=0.605, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42181
2022-09-30 20:14:15 - progress_bar.py[line:274] - INFO: epoch 001:  13390 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.9, wpb=101, bsz=40, num_updates=13370, lr=6.92142e-05, gnorm=0.623, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42192
2022-09-30 20:14:27 - progress_bar.py[line:274] - INFO: epoch 001:  13400 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.88, wpb=102.4, bsz=40, num_updates=13380, lr=6.92037e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42203
2022-09-30 20:14:37 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 20:14:39 - progress_bar.py[line:274] - INFO: epoch 001:  13411 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=82.6, ups=0.82, wpb=100.2, bsz=40, num_updates=13390, lr=6.91931e-05, gnorm=0.56, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=42215
2022-09-30 20:14:50 - progress_bar.py[line:274] - INFO: epoch 001:  13421 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.9, wpb=100.8, bsz=40, num_updates=13400, lr=6.91825e-05, gnorm=0.636, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42227
2022-09-30 20:15:01 - progress_bar.py[line:274] - INFO: epoch 001:  13431 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.9, wpb=101.4, bsz=40, num_updates=13410, lr=6.9172e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42238
2022-09-30 20:15:12 - progress_bar.py[line:274] - INFO: epoch 001:  13441 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.91, wpb=101.5, bsz=40, num_updates=13420, lr=6.91614e-05, gnorm=0.618, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42249
2022-09-30 20:15:23 - progress_bar.py[line:274] - INFO: epoch 001:  13451 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.5, ups=0.92, wpb=100.9, bsz=40, num_updates=13430, lr=6.91509e-05, gnorm=0.615, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42260
2022-09-30 20:15:34 - progress_bar.py[line:274] - INFO: epoch 001:  13461 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.92, wpb=101.5, bsz=40, num_updates=13440, lr=6.91403e-05, gnorm=0.5, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42270
2022-09-30 20:15:45 - progress_bar.py[line:274] - INFO: epoch 001:  13471 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.6, ups=0.91, wpb=102.3, bsz=40, num_updates=13450, lr=6.91297e-05, gnorm=0.54, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42281
2022-09-30 20:15:56 - progress_bar.py[line:274] - INFO: epoch 001:  13481 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.9, wpb=102, bsz=40, num_updates=13460, lr=6.91192e-05, gnorm=0.542, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42292
2022-09-30 20:16:07 - progress_bar.py[line:274] - INFO: epoch 001:  13491 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.9, wpb=100.8, bsz=40, num_updates=13470, lr=6.91086e-05, gnorm=0.588, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42304
2022-09-30 20:16:18 - progress_bar.py[line:274] - INFO: epoch 001:  13501 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.92, wpb=101.5, bsz=40, num_updates=13480, lr=6.90981e-05, gnorm=0.606, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42314
2022-09-30 20:16:29 - progress_bar.py[line:274] - INFO: epoch 001:  13511 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.9, wpb=100.8, bsz=40, num_updates=13490, lr=6.90875e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42325
2022-09-30 20:16:40 - progress_bar.py[line:274] - INFO: epoch 001:  13521 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.2, ups=0.92, wpb=101.1, bsz=40, num_updates=13500, lr=6.90769e-05, gnorm=0.571, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42336
2022-09-30 20:16:51 - progress_bar.py[line:274] - INFO: epoch 001:  13531 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.4, ups=0.88, wpb=100.6, bsz=40, num_updates=13510, lr=6.90664e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42348
2022-09-30 20:17:02 - progress_bar.py[line:274] - INFO: epoch 001:  13541 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.2, ups=0.87, wpb=99.3, bsz=40, num_updates=13520, lr=6.90558e-05, gnorm=0.618, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42359
2022-09-30 20:17:14 - progress_bar.py[line:274] - INFO: epoch 001:  13551 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.3, ups=0.87, wpb=101.6, bsz=40, num_updates=13530, lr=6.90453e-05, gnorm=0.64, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42371
2022-09-30 20:17:25 - progress_bar.py[line:274] - INFO: epoch 001:  13561 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.3, ups=0.9, wpb=100.6, bsz=40, num_updates=13540, lr=6.90347e-05, gnorm=0.716, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42382
2022-09-30 20:17:36 - progress_bar.py[line:274] - INFO: epoch 001:  13571 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.9, wpb=99.2, bsz=40, num_updates=13550, lr=6.90241e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42393
2022-09-30 20:17:47 - progress_bar.py[line:274] - INFO: epoch 001:  13581 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=13560, lr=6.90136e-05, gnorm=0.634, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42404
2022-09-30 20:17:59 - progress_bar.py[line:274] - INFO: epoch 001:  13591 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.89, wpb=102.4, bsz=40, num_updates=13570, lr=6.9003e-05, gnorm=0.515, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=42415
2022-09-30 20:18:09 - progress_bar.py[line:274] - INFO: epoch 001:  13601 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.91, wpb=100.8, bsz=40, num_updates=13580, lr=6.89925e-05, gnorm=0.671, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42426
2022-09-30 20:18:21 - progress_bar.py[line:274] - INFO: epoch 001:  13611 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=13590, lr=6.89819e-05, gnorm=0.723, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42437
2022-09-30 20:18:32 - progress_bar.py[line:274] - INFO: epoch 001:  13621 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.91, wpb=102.1, bsz=40, num_updates=13600, lr=6.89713e-05, gnorm=0.636, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42448
2022-09-30 20:18:43 - progress_bar.py[line:274] - INFO: epoch 001:  13631 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.89, wpb=101.1, bsz=40, num_updates=13610, lr=6.89608e-05, gnorm=0.65, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42460
2022-09-30 20:18:54 - progress_bar.py[line:274] - INFO: epoch 001:  13641 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.87, wpb=101.2, bsz=40, num_updates=13620, lr=6.89502e-05, gnorm=0.663, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42471
2022-09-30 20:19:05 - progress_bar.py[line:274] - INFO: epoch 001:  13651 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.9, ups=0.91, wpb=100.2, bsz=40, num_updates=13630, lr=6.89397e-05, gnorm=0.632, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42482
2022-09-30 20:19:17 - progress_bar.py[line:274] - INFO: epoch 001:  13661 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.2, ups=0.87, wpb=101.3, bsz=40, num_updates=13640, lr=6.89291e-05, gnorm=0.535, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42494
2022-09-30 20:19:28 - progress_bar.py[line:274] - INFO: epoch 001:  13671 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.6, ups=0.91, wpb=100.2, bsz=40, num_updates=13650, lr=6.89185e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42505
2022-09-30 20:19:39 - progress_bar.py[line:274] - INFO: epoch 001:  13681 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.9, wpb=99.9, bsz=40, num_updates=13660, lr=6.8908e-05, gnorm=0.61, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42516
2022-09-30 20:19:50 - progress_bar.py[line:274] - INFO: epoch 001:  13691 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.9, ups=0.92, wpb=103.5, bsz=40, num_updates=13670, lr=6.88974e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=42526
2022-09-30 20:20:01 - progress_bar.py[line:274] - INFO: epoch 001:  13701 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.91, wpb=100.4, bsz=40, num_updates=13680, lr=6.88869e-05, gnorm=0.559, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42538
2022-09-30 20:20:12 - progress_bar.py[line:274] - INFO: epoch 001:  13711 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.88, wpb=101, bsz=40, num_updates=13690, lr=6.88763e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42549
2022-09-30 20:20:24 - progress_bar.py[line:274] - INFO: epoch 001:  13721 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=82.6, ups=0.83, wpb=99.9, bsz=40, num_updates=13700, lr=6.88657e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=42561
2022-09-30 20:20:36 - progress_bar.py[line:274] - INFO: epoch 001:  13731 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=83.3, ups=0.82, wpb=101.6, bsz=40, num_updates=13710, lr=6.88552e-05, gnorm=0.556, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=42573
2022-09-30 20:20:48 - progress_bar.py[line:274] - INFO: epoch 001:  13741 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.89, wpb=101.9, bsz=40, num_updates=13720, lr=6.88446e-05, gnorm=0.606, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42584
2022-09-30 20:20:59 - progress_bar.py[line:274] - INFO: epoch 001:  13751 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.8, ups=0.86, wpb=101.7, bsz=40, num_updates=13730, lr=6.88341e-05, gnorm=0.61, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=42596
2022-09-30 20:21:12 - progress_bar.py[line:274] - INFO: epoch 001:  13761 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=81.7, ups=0.8, wpb=102.7, bsz=40, num_updates=13740, lr=6.88235e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=42609
2022-09-30 20:21:24 - progress_bar.py[line:274] - INFO: epoch 001:  13771 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.9, ups=0.84, wpb=102.1, bsz=40, num_updates=13750, lr=6.88129e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=42621
2022-09-30 20:21:35 - progress_bar.py[line:274] - INFO: epoch 001:  13781 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.91, wpb=102.1, bsz=40, num_updates=13760, lr=6.88024e-05, gnorm=0.588, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42632
2022-09-30 20:21:46 - progress_bar.py[line:274] - INFO: epoch 001:  13791 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.2, ups=0.89, wpb=101.2, bsz=40, num_updates=13770, lr=6.87918e-05, gnorm=0.553, clip=0, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=42643
2022-09-30 20:21:57 - progress_bar.py[line:274] - INFO: epoch 001:  13801 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.89, wpb=101.6, bsz=40, num_updates=13780, lr=6.87813e-05, gnorm=0.603, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42654
2022-09-30 20:22:09 - progress_bar.py[line:274] - INFO: epoch 001:  13811 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.9, wpb=101.5, bsz=40, num_updates=13790, lr=6.87707e-05, gnorm=0.548, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42665
2022-09-30 20:22:20 - progress_bar.py[line:274] - INFO: epoch 001:  13821 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=13800, lr=6.87601e-05, gnorm=0.591, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42677
2022-09-30 20:22:31 - progress_bar.py[line:274] - INFO: epoch 001:  13831 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.3, ups=0.88, wpb=101.7, bsz=40, num_updates=13810, lr=6.87496e-05, gnorm=0.535, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=42688
2022-09-30 20:22:42 - progress_bar.py[line:274] - INFO: epoch 001:  13841 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.2, ups=0.91, wpb=100.9, bsz=40, num_updates=13820, lr=6.8739e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42699
2022-09-30 20:22:53 - progress_bar.py[line:274] - INFO: epoch 001:  13851 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.91, wpb=99.3, bsz=40, num_updates=13830, lr=6.87285e-05, gnorm=0.571, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42710
2022-09-30 20:23:04 - progress_bar.py[line:274] - INFO: epoch 001:  13861 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.9, wpb=100.6, bsz=40, num_updates=13840, lr=6.87179e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42721
2022-09-30 20:23:16 - progress_bar.py[line:274] - INFO: epoch 001:  13871 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89, ups=0.87, wpb=101.9, bsz=40, num_updates=13850, lr=6.87073e-05, gnorm=0.61, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42732
2022-09-30 20:23:27 - progress_bar.py[line:274] - INFO: epoch 001:  13881 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.88, wpb=102.2, bsz=40, num_updates=13860, lr=6.86968e-05, gnorm=0.578, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42744
2022-09-30 20:23:39 - progress_bar.py[line:274] - INFO: epoch 001:  13891 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=83.8, ups=0.83, wpb=100.8, bsz=40, num_updates=13870, lr=6.86862e-05, gnorm=0.556, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=42756
2022-09-30 20:23:50 - progress_bar.py[line:274] - INFO: epoch 001:  13901 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.6, ups=0.89, wpb=102.5, bsz=40, num_updates=13880, lr=6.86757e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42767
2022-09-30 20:24:01 - progress_bar.py[line:274] - INFO: epoch 001:  13911 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.9, wpb=102, bsz=40, num_updates=13890, lr=6.86651e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42778
2022-09-30 20:24:13 - progress_bar.py[line:274] - INFO: epoch 001:  13921 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=13900, lr=6.86545e-05, gnorm=0.633, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42789
2022-09-30 20:24:24 - progress_bar.py[line:274] - INFO: epoch 001:  13931 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.89, wpb=102.4, bsz=40, num_updates=13910, lr=6.8644e-05, gnorm=0.622, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42801
2022-09-30 20:24:35 - progress_bar.py[line:274] - INFO: epoch 001:  13941 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.88, wpb=102.7, bsz=40, num_updates=13920, lr=6.86334e-05, gnorm=0.617, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42812
2022-09-30 20:24:47 - progress_bar.py[line:274] - INFO: epoch 001:  13951 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.88, wpb=102.2, bsz=40, num_updates=13930, lr=6.86229e-05, gnorm=0.475, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42823
2022-09-30 20:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  13961 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.9, wpb=100.3, bsz=40, num_updates=13940, lr=6.86123e-05, gnorm=0.581, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42835
2022-09-30 20:25:09 - progress_bar.py[line:274] - INFO: epoch 001:  13971 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.89, wpb=100, bsz=40, num_updates=13950, lr=6.86018e-05, gnorm=0.565, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42846
2022-09-30 20:25:20 - progress_bar.py[line:274] - INFO: epoch 001:  13981 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.9, ups=0.89, wpb=99.7, bsz=40, num_updates=13960, lr=6.85912e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42857
2022-09-30 20:25:32 - progress_bar.py[line:274] - INFO: epoch 001:  13991 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.88, wpb=102.1, bsz=40, num_updates=13970, lr=6.85806e-05, gnorm=0.611, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=42868
2022-09-30 20:25:43 - progress_bar.py[line:274] - INFO: epoch 001:  14001 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.6, ups=0.87, wpb=100.6, bsz=40, num_updates=13980, lr=6.85701e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42880
2022-09-30 20:25:54 - progress_bar.py[line:274] - INFO: epoch 001:  14011 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.8, ups=0.89, wpb=102.8, bsz=40, num_updates=13990, lr=6.85595e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42891
2022-09-30 20:26:06 - progress_bar.py[line:274] - INFO: epoch 001:  14021 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.9, wpb=101.1, bsz=40, num_updates=14000, lr=6.8549e-05, gnorm=0.569, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42902
2022-09-30 20:26:17 - progress_bar.py[line:274] - INFO: epoch 001:  14031 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=14010, lr=6.85384e-05, gnorm=0.564, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42914
2022-09-30 20:26:28 - progress_bar.py[line:274] - INFO: epoch 001:  14041 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.9, wpb=101, bsz=40, num_updates=14020, lr=6.85278e-05, gnorm=0.606, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=42925
2022-09-30 20:26:39 - progress_bar.py[line:274] - INFO: epoch 001:  14051 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.7, ups=0.9, wpb=101.5, bsz=40, num_updates=14030, lr=6.85173e-05, gnorm=0.616, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42936
2022-09-30 20:26:50 - progress_bar.py[line:274] - INFO: epoch 001:  14061 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.7, ups=0.89, wpb=100, bsz=40, num_updates=14040, lr=6.85067e-05, gnorm=0.646, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42947
2022-09-30 20:27:03 - progress_bar.py[line:274] - INFO: epoch 001:  14071 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=78.8, ups=0.79, wpb=99.3, bsz=40, num_updates=14050, lr=6.84962e-05, gnorm=0.606, clip=0, loss_scale=1024, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=42960
2022-09-30 20:27:15 - progress_bar.py[line:274] - INFO: epoch 001:  14081 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=83.2, ups=0.84, wpb=99.2, bsz=40, num_updates=14060, lr=6.84856e-05, gnorm=0.585, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=42971
2022-09-30 20:27:26 - progress_bar.py[line:274] - INFO: epoch 001:  14091 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.9, wpb=100, bsz=40, num_updates=14070, lr=6.8475e-05, gnorm=0.569, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42983
2022-09-30 20:27:37 - progress_bar.py[line:274] - INFO: epoch 001:  14101 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=14080, lr=6.84645e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42994
2022-09-30 20:27:48 - progress_bar.py[line:274] - INFO: epoch 001:  14111 / 15783 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.3, ups=0.9, wpb=102.2, bsz=40, num_updates=14090, lr=6.84539e-05, gnorm=0.556, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43005
2022-09-30 20:28:00 - progress_bar.py[line:274] - INFO: epoch 001:  14121 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.88, wpb=101.8, bsz=40, num_updates=14100, lr=6.84434e-05, gnorm=0.613, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43016
2022-09-30 20:28:12 - progress_bar.py[line:274] - INFO: epoch 001:  14131 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=84.1, ups=0.82, wpb=102.3, bsz=40, num_updates=14110, lr=6.84328e-05, gnorm=0.544, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=43028
2022-09-30 20:28:24 - progress_bar.py[line:274] - INFO: epoch 001:  14141 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=83.4, ups=0.81, wpb=102.7, bsz=40, num_updates=14120, lr=6.84222e-05, gnorm=0.614, clip=10, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=43041
2022-09-30 20:28:36 - progress_bar.py[line:274] - INFO: epoch 001:  14151 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=84, ups=0.84, wpb=99.6, bsz=40, num_updates=14130, lr=6.84117e-05, gnorm=0.573, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=43053
2022-09-30 20:28:47 - progress_bar.py[line:274] - INFO: epoch 001:  14161 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=14140, lr=6.84011e-05, gnorm=0.685, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43064
2022-09-30 20:28:58 - progress_bar.py[line:274] - INFO: epoch 001:  14171 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.9, wpb=100.1, bsz=40, num_updates=14150, lr=6.83906e-05, gnorm=0.664, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43075
2022-09-30 20:29:11 - progress_bar.py[line:274] - INFO: epoch 001:  14181 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=81.8, ups=0.8, wpb=102.5, bsz=40, num_updates=14160, lr=6.838e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=43087
2022-09-30 20:29:23 - progress_bar.py[line:274] - INFO: epoch 001:  14191 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=80.8, ups=0.81, wpb=99.4, bsz=40, num_updates=14170, lr=6.83694e-05, gnorm=0.617, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=43100
2022-09-30 20:29:34 - progress_bar.py[line:274] - INFO: epoch 001:  14201 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.9, ups=0.89, wpb=103.2, bsz=40, num_updates=14180, lr=6.83589e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43111
2022-09-30 20:29:46 - progress_bar.py[line:274] - INFO: epoch 001:  14211 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.89, wpb=101.2, bsz=40, num_updates=14190, lr=6.83483e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=43122
2022-09-30 20:29:57 - progress_bar.py[line:274] - INFO: epoch 001:  14221 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92, ups=0.91, wpb=101.3, bsz=40, num_updates=14200, lr=6.83378e-05, gnorm=0.6, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43133
2022-09-30 20:30:08 - progress_bar.py[line:274] - INFO: epoch 001:  14231 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=14210, lr=6.83272e-05, gnorm=0.558, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43145
2022-09-30 20:30:19 - progress_bar.py[line:274] - INFO: epoch 001:  14241 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88, ups=0.87, wpb=101.5, bsz=40, num_updates=14220, lr=6.83166e-05, gnorm=0.504, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43156
2022-09-30 20:30:31 - progress_bar.py[line:274] - INFO: epoch 001:  14251 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.89, wpb=102.5, bsz=40, num_updates=14230, lr=6.83061e-05, gnorm=0.688, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43167
2022-09-30 20:30:42 - progress_bar.py[line:274] - INFO: epoch 001:  14261 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.89, wpb=102.4, bsz=40, num_updates=14240, lr=6.82955e-05, gnorm=0.53, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43178
2022-09-30 20:30:51 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 20:30:54 - progress_bar.py[line:274] - INFO: epoch 001:  14272 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=81.5, ups=0.81, wpb=100.4, bsz=40, num_updates=14250, lr=6.8285e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=43191
2022-09-30 20:31:05 - progress_bar.py[line:274] - INFO: epoch 001:  14282 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.88, wpb=101.1, bsz=40, num_updates=14260, lr=6.82744e-05, gnorm=0.557, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43202
2022-09-30 20:31:16 - progress_bar.py[line:274] - INFO: epoch 001:  14292 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.3, ups=0.92, wpb=102.8, bsz=40, num_updates=14270, lr=6.82638e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43213
2022-09-30 20:31:28 - progress_bar.py[line:274] - INFO: epoch 001:  14302 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=14280, lr=6.82533e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43224
2022-09-30 20:31:39 - progress_bar.py[line:274] - INFO: epoch 001:  14312 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.91, wpb=101.7, bsz=40, num_updates=14290, lr=6.82427e-05, gnorm=0.589, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43235
2022-09-30 20:31:50 - progress_bar.py[line:274] - INFO: epoch 001:  14322 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92, ups=0.92, wpb=100.5, bsz=40, num_updates=14300, lr=6.82322e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43246
2022-09-30 20:32:01 - progress_bar.py[line:274] - INFO: epoch 001:  14332 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.89, wpb=103.4, bsz=40, num_updates=14310, lr=6.82216e-05, gnorm=0.605, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43257
2022-09-30 20:32:12 - progress_bar.py[line:274] - INFO: epoch 001:  14342 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.9, wpb=100, bsz=40, num_updates=14320, lr=6.8211e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43269
2022-09-30 20:32:23 - progress_bar.py[line:274] - INFO: epoch 001:  14352 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.9, wpb=100.6, bsz=40, num_updates=14330, lr=6.82005e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43280
2022-09-30 20:32:34 - progress_bar.py[line:274] - INFO: epoch 001:  14362 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=101.3, bsz=40, num_updates=14340, lr=6.81899e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43291
2022-09-30 20:32:46 - progress_bar.py[line:274] - INFO: epoch 001:  14372 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.87, wpb=103.6, bsz=40, num_updates=14350, lr=6.81794e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43302
2022-09-30 20:32:58 - progress_bar.py[line:274] - INFO: epoch 001:  14382 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=81.4, ups=0.8, wpb=101.3, bsz=40, num_updates=14360, lr=6.81688e-05, gnorm=0.555, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=43315
2022-09-30 20:33:10 - progress_bar.py[line:274] - INFO: epoch 001:  14392 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=83.7, ups=0.83, wpb=101.3, bsz=40, num_updates=14370, lr=6.81582e-05, gnorm=0.629, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=43327
2022-09-30 20:33:21 - progress_bar.py[line:274] - INFO: epoch 001:  14402 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.6, ups=0.92, wpb=102, bsz=40, num_updates=14380, lr=6.81477e-05, gnorm=0.52, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43338
2022-09-30 20:33:32 - progress_bar.py[line:274] - INFO: epoch 001:  14412 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.89, wpb=101.1, bsz=40, num_updates=14390, lr=6.81371e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43349
2022-09-30 20:33:44 - progress_bar.py[line:274] - INFO: epoch 001:  14422 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=14400, lr=6.81266e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43360
2022-09-30 20:33:55 - progress_bar.py[line:274] - INFO: epoch 001:  14432 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93, ups=0.91, wpb=101.8, bsz=40, num_updates=14410, lr=6.8116e-05, gnorm=0.568, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43371
2022-09-30 20:34:06 - progress_bar.py[line:274] - INFO: epoch 001:  14442 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.91, wpb=100.7, bsz=40, num_updates=14420, lr=6.81054e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43382
2022-09-30 20:34:17 - progress_bar.py[line:274] - INFO: epoch 001:  14452 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.89, wpb=102.3, bsz=40, num_updates=14430, lr=6.80949e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43394
2022-09-30 20:34:28 - progress_bar.py[line:274] - INFO: epoch 001:  14462 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.9, wpb=101.1, bsz=40, num_updates=14440, lr=6.80843e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43405
2022-09-30 20:34:39 - progress_bar.py[line:274] - INFO: epoch 001:  14472 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.88, wpb=100.6, bsz=40, num_updates=14450, lr=6.80738e-05, gnorm=0.543, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43416
2022-09-30 20:34:50 - progress_bar.py[line:274] - INFO: epoch 001:  14482 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94, ups=0.92, wpb=102.3, bsz=40, num_updates=14460, lr=6.80632e-05, gnorm=0.598, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43427
2022-09-30 20:35:02 - progress_bar.py[line:274] - INFO: epoch 001:  14492 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.3, ups=0.88, wpb=102.8, bsz=40, num_updates=14470, lr=6.80526e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43438
2022-09-30 20:35:13 - progress_bar.py[line:274] - INFO: epoch 001:  14502 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.6, ups=0.9, wpb=102.2, bsz=40, num_updates=14480, lr=6.80421e-05, gnorm=0.606, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=43450
2022-09-30 20:35:24 - progress_bar.py[line:274] - INFO: epoch 001:  14512 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.88, wpb=102.6, bsz=40, num_updates=14490, lr=6.80315e-05, gnorm=0.627, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43461
2022-09-30 20:35:35 - progress_bar.py[line:274] - INFO: epoch 001:  14522 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.9, wpb=101.2, bsz=40, num_updates=14500, lr=6.8021e-05, gnorm=0.623, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43472
2022-09-30 20:35:47 - progress_bar.py[line:274] - INFO: epoch 001:  14532 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.4, ups=0.89, wpb=99.5, bsz=40, num_updates=14510, lr=6.80104e-05, gnorm=0.636, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43483
2022-09-30 20:35:57 - progress_bar.py[line:274] - INFO: epoch 001:  14542 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.9, ups=0.93, wpb=101.4, bsz=40, num_updates=14520, lr=6.79998e-05, gnorm=0.634, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43494
2022-09-30 20:36:08 - progress_bar.py[line:274] - INFO: epoch 001:  14552 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.91, wpb=101.2, bsz=40, num_updates=14530, lr=6.79893e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43505
2022-09-30 20:36:19 - progress_bar.py[line:274] - INFO: epoch 001:  14562 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93, ups=0.91, wpb=101.9, bsz=40, num_updates=14540, lr=6.79787e-05, gnorm=0.657, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43516
2022-09-30 20:36:31 - progress_bar.py[line:274] - INFO: epoch 001:  14572 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.6, ups=0.88, wpb=100.6, bsz=40, num_updates=14550, lr=6.79682e-05, gnorm=0.579, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43527
2022-09-30 20:36:42 - progress_bar.py[line:274] - INFO: epoch 001:  14582 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.6, ups=0.89, wpb=103.7, bsz=40, num_updates=14560, lr=6.79576e-05, gnorm=0.606, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43539
2022-09-30 20:36:53 - progress_bar.py[line:274] - INFO: epoch 001:  14592 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.2, ups=0.89, wpb=99.2, bsz=40, num_updates=14570, lr=6.7947e-05, gnorm=0.527, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=43550
2022-09-30 20:37:04 - progress_bar.py[line:274] - INFO: epoch 001:  14602 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.4, ups=0.89, wpb=100, bsz=40, num_updates=14580, lr=6.79365e-05, gnorm=0.65, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43561
2022-09-30 20:37:16 - progress_bar.py[line:274] - INFO: epoch 001:  14612 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.7, ups=0.86, wpb=102.1, bsz=40, num_updates=14590, lr=6.79259e-05, gnorm=0.525, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=43573
2022-09-30 20:37:28 - progress_bar.py[line:274] - INFO: epoch 001:  14622 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.5, ups=0.86, wpb=101.2, bsz=40, num_updates=14600, lr=6.79154e-05, gnorm=0.62, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43584
2022-09-30 20:37:39 - progress_bar.py[line:274] - INFO: epoch 001:  14632 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.88, wpb=101.4, bsz=40, num_updates=14610, lr=6.79048e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43596
2022-09-30 20:37:50 - progress_bar.py[line:274] - INFO: epoch 001:  14642 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90, ups=0.89, wpb=100.8, bsz=40, num_updates=14620, lr=6.78942e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43607
2022-09-30 20:38:01 - progress_bar.py[line:274] - INFO: epoch 001:  14652 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.91, wpb=101.5, bsz=40, num_updates=14630, lr=6.78837e-05, gnorm=0.606, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43618
2022-09-30 20:38:12 - progress_bar.py[line:274] - INFO: epoch 001:  14662 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.1, ups=0.93, wpb=99.5, bsz=40, num_updates=14640, lr=6.78731e-05, gnorm=0.634, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43629
2022-09-30 20:38:23 - progress_bar.py[line:274] - INFO: epoch 001:  14672 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.88, wpb=101.4, bsz=40, num_updates=14650, lr=6.78626e-05, gnorm=0.56, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43640
2022-09-30 20:38:34 - progress_bar.py[line:274] - INFO: epoch 001:  14682 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.9, wpb=101, bsz=40, num_updates=14660, lr=6.7852e-05, gnorm=0.593, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43651
2022-09-30 20:38:45 - progress_bar.py[line:274] - INFO: epoch 001:  14692 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.91, wpb=101.5, bsz=40, num_updates=14670, lr=6.78414e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43662
2022-09-30 20:38:57 - progress_bar.py[line:274] - INFO: epoch 001:  14702 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.9, ups=0.89, wpb=101.1, bsz=40, num_updates=14680, lr=6.78309e-05, gnorm=0.576, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43673
2022-09-30 20:39:08 - progress_bar.py[line:274] - INFO: epoch 001:  14712 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.5, ups=0.88, wpb=102.2, bsz=40, num_updates=14690, lr=6.78203e-05, gnorm=0.661, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43685
2022-09-30 20:39:19 - progress_bar.py[line:274] - INFO: epoch 001:  14722 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.9, bsz=40, num_updates=14700, lr=6.78098e-05, gnorm=0.627, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43696
2022-09-30 20:39:30 - progress_bar.py[line:274] - INFO: epoch 001:  14732 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=14710, lr=6.77992e-05, gnorm=0.576, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43707
2022-09-30 20:39:42 - progress_bar.py[line:274] - INFO: epoch 001:  14742 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.89, wpb=102.5, bsz=40, num_updates=14720, lr=6.77886e-05, gnorm=0.527, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43718
2022-09-30 20:39:53 - progress_bar.py[line:274] - INFO: epoch 001:  14752 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.2, ups=0.88, wpb=100.9, bsz=40, num_updates=14730, lr=6.77781e-05, gnorm=0.604, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43730
2022-09-30 20:40:04 - progress_bar.py[line:274] - INFO: epoch 001:  14762 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.91, wpb=100.7, bsz=40, num_updates=14740, lr=6.77675e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=43741
2022-09-30 20:40:15 - progress_bar.py[line:274] - INFO: epoch 001:  14772 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.88, wpb=102.3, bsz=40, num_updates=14750, lr=6.7757e-05, gnorm=0.556, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43752
2022-09-30 20:40:26 - progress_bar.py[line:274] - INFO: epoch 001:  14782 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93, ups=0.91, wpb=101.9, bsz=40, num_updates=14760, lr=6.77464e-05, gnorm=0.501, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43763
2022-09-30 20:40:37 - progress_bar.py[line:274] - INFO: epoch 001:  14792 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.9, ups=0.89, wpb=102.8, bsz=40, num_updates=14770, lr=6.77358e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43774
2022-09-30 20:40:49 - progress_bar.py[line:274] - INFO: epoch 001:  14802 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.91, wpb=101.1, bsz=40, num_updates=14780, lr=6.77253e-05, gnorm=0.565, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43785
2022-09-30 20:41:00 - progress_bar.py[line:274] - INFO: epoch 001:  14812 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.8, ups=0.89, wpb=103.7, bsz=40, num_updates=14790, lr=6.77147e-05, gnorm=0.463, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43796
2022-09-30 20:41:11 - progress_bar.py[line:274] - INFO: epoch 001:  14822 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.9, wpb=101.8, bsz=40, num_updates=14800, lr=6.77042e-05, gnorm=0.511, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43808
2022-09-30 20:41:21 - progress_bar.py[line:274] - INFO: epoch 001:  14832 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95, ups=0.94, wpb=100.8, bsz=40, num_updates=14810, lr=6.76936e-05, gnorm=0.626, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43818
2022-09-30 20:41:33 - progress_bar.py[line:274] - INFO: epoch 001:  14842 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=14820, lr=6.7683e-05, gnorm=0.531, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43829
2022-09-30 20:41:44 - progress_bar.py[line:274] - INFO: epoch 001:  14852 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.2, ups=0.86, wpb=100.2, bsz=40, num_updates=14830, lr=6.76725e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=43841
2022-09-30 20:41:56 - progress_bar.py[line:274] - INFO: epoch 001:  14862 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.5, ups=0.88, wpb=100.6, bsz=40, num_updates=14840, lr=6.76619e-05, gnorm=0.635, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43852
2022-09-30 20:42:07 - progress_bar.py[line:274] - INFO: epoch 001:  14872 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.91, wpb=100.8, bsz=40, num_updates=14850, lr=6.76514e-05, gnorm=0.62, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43863
2022-09-30 20:42:18 - progress_bar.py[line:274] - INFO: epoch 001:  14882 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.7, ups=0.88, wpb=99.5, bsz=40, num_updates=14860, lr=6.76408e-05, gnorm=0.597, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43875
2022-09-30 20:42:29 - progress_bar.py[line:274] - INFO: epoch 001:  14892 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.88, wpb=100.4, bsz=40, num_updates=14870, lr=6.76302e-05, gnorm=0.653, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43886
2022-09-30 20:42:40 - progress_bar.py[line:274] - INFO: epoch 001:  14902 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.4, ups=0.9, wpb=102.2, bsz=40, num_updates=14880, lr=6.76197e-05, gnorm=0.648, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43897
2022-09-30 20:42:52 - progress_bar.py[line:274] - INFO: epoch 001:  14912 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.88, wpb=103.4, bsz=40, num_updates=14890, lr=6.76091e-05, gnorm=0.505, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43909
2022-09-30 20:43:03 - progress_bar.py[line:274] - INFO: epoch 001:  14922 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.9, wpb=102.1, bsz=40, num_updates=14900, lr=6.75986e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43920
2022-09-30 20:43:14 - progress_bar.py[line:274] - INFO: epoch 001:  14932 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.2, ups=0.88, wpb=101.1, bsz=40, num_updates=14910, lr=6.7588e-05, gnorm=0.543, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43931
2022-09-30 20:43:26 - progress_bar.py[line:274] - INFO: epoch 001:  14942 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.6, ups=0.89, wpb=100.9, bsz=40, num_updates=14920, lr=6.75774e-05, gnorm=0.585, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43942
2022-09-30 20:43:37 - progress_bar.py[line:274] - INFO: epoch 001:  14952 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.9, wpb=100.5, bsz=40, num_updates=14930, lr=6.75669e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43953
2022-09-30 20:43:48 - progress_bar.py[line:274] - INFO: epoch 001:  14962 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.89, wpb=100.8, bsz=40, num_updates=14940, lr=6.75563e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43965
2022-09-30 20:43:59 - progress_bar.py[line:274] - INFO: epoch 001:  14972 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=14950, lr=6.75458e-05, gnorm=0.541, clip=0, loss_scale=1024, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=43976
2022-09-30 20:44:10 - progress_bar.py[line:274] - INFO: epoch 001:  14982 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=14960, lr=6.75352e-05, gnorm=0.654, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43987
2022-09-30 20:44:21 - progress_bar.py[line:274] - INFO: epoch 001:  14992 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=14970, lr=6.75247e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43998
2022-09-30 20:44:32 - progress_bar.py[line:274] - INFO: epoch 001:  15002 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.89, wpb=101.5, bsz=40, num_updates=14980, lr=6.75141e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44009
2022-09-30 20:44:44 - progress_bar.py[line:274] - INFO: epoch 001:  15012 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.6, ups=0.87, wpb=101.3, bsz=40, num_updates=14990, lr=6.75035e-05, gnorm=0.601, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=44021
2022-09-30 20:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  15022 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.6, ups=0.87, wpb=102, bsz=40, num_updates=15000, lr=6.7493e-05, gnorm=0.522, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44032
2022-09-30 20:45:07 - progress_bar.py[line:274] - INFO: epoch 001:  15032 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.89, wpb=101, bsz=40, num_updates=15010, lr=6.74824e-05, gnorm=0.548, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44044
2022-09-30 20:45:18 - progress_bar.py[line:274] - INFO: epoch 001:  15042 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.2, ups=0.88, wpb=101.7, bsz=40, num_updates=15020, lr=6.74719e-05, gnorm=0.499, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44055
2022-09-30 20:45:29 - progress_bar.py[line:274] - INFO: epoch 001:  15052 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.4, ups=0.93, wpb=101, bsz=40, num_updates=15030, lr=6.74613e-05, gnorm=0.548, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44066
2022-09-30 20:45:40 - progress_bar.py[line:274] - INFO: epoch 001:  15062 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.5, ups=0.93, wpb=101.9, bsz=40, num_updates=15040, lr=6.74507e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44077
2022-09-30 20:45:51 - progress_bar.py[line:274] - INFO: epoch 001:  15072 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.92, wpb=101.2, bsz=40, num_updates=15050, lr=6.74402e-05, gnorm=0.581, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44087
2022-09-30 20:46:02 - progress_bar.py[line:274] - INFO: epoch 001:  15082 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=15060, lr=6.74296e-05, gnorm=0.541, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44099
2022-09-30 20:46:13 - progress_bar.py[line:274] - INFO: epoch 001:  15092 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.6, ups=0.92, wpb=100.6, bsz=40, num_updates=15070, lr=6.74191e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44109
2022-09-30 20:46:24 - progress_bar.py[line:274] - INFO: epoch 001:  15102 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.87, wpb=101.6, bsz=40, num_updates=15080, lr=6.74085e-05, gnorm=0.581, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44121
2022-09-30 20:46:36 - progress_bar.py[line:274] - INFO: epoch 001:  15112 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.9, ups=0.85, wpb=102.3, bsz=40, num_updates=15090, lr=6.73979e-05, gnorm=0.566, clip=0, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=44133
2022-09-30 20:46:49 - progress_bar.py[line:274] - INFO: epoch 001:  15122 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=80.6, ups=0.79, wpb=101.9, bsz=40, num_updates=15100, lr=6.73874e-05, gnorm=0.658, clip=10, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=44145
2022-09-30 20:47:00 - progress_bar.py[line:274] - INFO: epoch 001:  15132 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.88, wpb=103.4, bsz=40, num_updates=15110, lr=6.73768e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44157
2022-09-30 20:47:11 - progress_bar.py[line:274] - INFO: epoch 001:  15142 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.9, wpb=101.7, bsz=40, num_updates=15120, lr=6.73663e-05, gnorm=0.519, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44168
2022-09-30 20:47:23 - progress_bar.py[line:274] - INFO: epoch 001:  15152 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=84.3, ups=0.81, wpb=103.5, bsz=40, num_updates=15130, lr=6.73557e-05, gnorm=0.497, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=44180
2022-09-30 20:47:36 - progress_bar.py[line:274] - INFO: epoch 001:  15162 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=80.1, ups=0.79, wpb=101.7, bsz=40, num_updates=15140, lr=6.73451e-05, gnorm=0.507, clip=0, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=44193
2022-09-30 20:47:48 - progress_bar.py[line:274] - INFO: epoch 001:  15172 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=83.2, ups=0.84, wpb=99.1, bsz=40, num_updates=15150, lr=6.73346e-05, gnorm=0.574, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=44205
2022-09-30 20:47:59 - progress_bar.py[line:274] - INFO: epoch 001:  15182 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.6, ups=0.91, wpb=101.6, bsz=40, num_updates=15160, lr=6.7324e-05, gnorm=0.681, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44216
2022-09-30 20:48:10 - progress_bar.py[line:274] - INFO: epoch 001:  15192 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.88, wpb=101.4, bsz=40, num_updates=15170, lr=6.73135e-05, gnorm=0.742, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44227
2022-09-30 20:48:21 - progress_bar.py[line:274] - INFO: epoch 001:  15202 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.4, ups=0.93, wpb=100.9, bsz=40, num_updates=15180, lr=6.73029e-05, gnorm=0.564, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44238
2022-09-30 20:48:33 - progress_bar.py[line:274] - INFO: epoch 001:  15212 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.89, wpb=100.6, bsz=40, num_updates=15190, lr=6.72923e-05, gnorm=0.503, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44249
2022-09-30 20:48:44 - progress_bar.py[line:274] - INFO: epoch 001:  15222 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.9, wpb=101.5, bsz=40, num_updates=15200, lr=6.72818e-05, gnorm=0.58, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44260
2022-09-30 20:48:55 - progress_bar.py[line:274] - INFO: epoch 001:  15232 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.89, wpb=99.9, bsz=40, num_updates=15210, lr=6.72712e-05, gnorm=0.539, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44272
2022-09-30 20:49:06 - progress_bar.py[line:274] - INFO: epoch 001:  15242 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.88, wpb=101.5, bsz=40, num_updates=15220, lr=6.72607e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=44283
2022-09-30 20:49:17 - progress_bar.py[line:274] - INFO: epoch 001:  15252 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.1, ups=0.89, wpb=102, bsz=40, num_updates=15230, lr=6.72501e-05, gnorm=0.599, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44294
2022-09-30 20:49:29 - progress_bar.py[line:274] - INFO: epoch 001:  15262 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.2, ups=0.91, wpb=101.9, bsz=40, num_updates=15240, lr=6.72395e-05, gnorm=0.687, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44305
2022-09-30 20:49:40 - progress_bar.py[line:274] - INFO: epoch 001:  15272 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.89, wpb=100.1, bsz=40, num_updates=15250, lr=6.7229e-05, gnorm=0.616, clip=0, loss_scale=1024, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=44317
2022-09-30 20:49:51 - progress_bar.py[line:274] - INFO: epoch 001:  15282 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=15260, lr=6.72184e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44328
2022-09-30 20:49:54 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 20:50:03 - progress_bar.py[line:274] - INFO: epoch 001:  15293 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=83.8, ups=0.83, wpb=100.7, bsz=40, num_updates=15270, lr=6.72079e-05, gnorm=0.559, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=44340
2022-09-30 20:50:14 - progress_bar.py[line:274] - INFO: epoch 001:  15303 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89, ups=0.89, wpb=99.6, bsz=40, num_updates=15280, lr=6.71973e-05, gnorm=0.585, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44351
2022-09-30 20:50:26 - progress_bar.py[line:274] - INFO: epoch 001:  15313 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.2, ups=0.88, wpb=101, bsz=40, num_updates=15290, lr=6.71867e-05, gnorm=0.641, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44362
2022-09-30 20:50:37 - progress_bar.py[line:274] - INFO: epoch 001:  15323 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101, bsz=40, num_updates=15300, lr=6.71762e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=44374
2022-09-30 20:50:48 - progress_bar.py[line:274] - INFO: epoch 001:  15333 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.9, wpb=100.8, bsz=40, num_updates=15310, lr=6.71656e-05, gnorm=0.738, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44385
2022-09-30 20:50:59 - progress_bar.py[line:274] - INFO: epoch 001:  15343 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.4, ups=0.87, wpb=101.6, bsz=40, num_updates=15320, lr=6.71551e-05, gnorm=0.568, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44396
2022-09-30 20:51:10 - progress_bar.py[line:274] - INFO: epoch 001:  15353 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.2, ups=0.94, wpb=101.6, bsz=40, num_updates=15330, lr=6.71445e-05, gnorm=0.691, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44407
2022-09-30 20:51:21 - progress_bar.py[line:274] - INFO: epoch 001:  15363 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.9, wpb=101.7, bsz=40, num_updates=15340, lr=6.71339e-05, gnorm=0.514, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44418
2022-09-30 20:51:32 - progress_bar.py[line:274] - INFO: epoch 001:  15373 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93, ups=0.92, wpb=100.7, bsz=40, num_updates=15350, lr=6.71234e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44429
2022-09-30 20:51:43 - progress_bar.py[line:274] - INFO: epoch 001:  15383 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.9, ups=0.89, wpb=100.3, bsz=40, num_updates=15360, lr=6.71128e-05, gnorm=0.566, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44440
2022-09-30 20:51:55 - progress_bar.py[line:274] - INFO: epoch 001:  15393 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.89, wpb=99.8, bsz=40, num_updates=15370, lr=6.71023e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44451
2022-09-30 20:52:06 - progress_bar.py[line:274] - INFO: epoch 001:  15403 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.89, wpb=102, bsz=40, num_updates=15380, lr=6.70917e-05, gnorm=0.68, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44463
2022-09-30 20:52:17 - progress_bar.py[line:274] - INFO: epoch 001:  15413 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.2, ups=0.89, wpb=101.7, bsz=40, num_updates=15390, lr=6.70811e-05, gnorm=0.61, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44474
2022-09-30 20:52:28 - progress_bar.py[line:274] - INFO: epoch 001:  15423 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.7, ups=0.89, wpb=99.1, bsz=40, num_updates=15400, lr=6.70706e-05, gnorm=0.644, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44485
2022-09-30 20:52:40 - progress_bar.py[line:274] - INFO: epoch 001:  15433 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.2, ups=0.84, wpb=102.1, bsz=40, num_updates=15410, lr=6.706e-05, gnorm=0.523, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=44497
2022-09-30 20:52:53 - progress_bar.py[line:274] - INFO: epoch 001:  15443 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=80.7, ups=0.8, wpb=101.2, bsz=40, num_updates=15420, lr=6.70495e-05, gnorm=0.524, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=44510
2022-09-30 20:53:05 - progress_bar.py[line:274] - INFO: epoch 001:  15453 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.8, ups=0.85, wpb=102.4, bsz=40, num_updates=15430, lr=6.70389e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=44521
2022-09-30 20:53:16 - progress_bar.py[line:274] - INFO: epoch 001:  15463 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.7, ups=0.89, wpb=103.1, bsz=40, num_updates=15440, lr=6.70283e-05, gnorm=0.585, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44533
2022-09-30 20:53:27 - progress_bar.py[line:274] - INFO: epoch 001:  15473 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.8, ups=0.88, wpb=100.2, bsz=40, num_updates=15450, lr=6.70178e-05, gnorm=0.538, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44544
2022-09-30 20:53:39 - progress_bar.py[line:274] - INFO: epoch 001:  15483 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.88, wpb=101.8, bsz=40, num_updates=15460, lr=6.70072e-05, gnorm=0.606, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44555
2022-09-30 20:53:50 - progress_bar.py[line:274] - INFO: epoch 001:  15493 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.87, wpb=101.9, bsz=40, num_updates=15470, lr=6.69967e-05, gnorm=0.649, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44567
2022-09-30 20:54:01 - progress_bar.py[line:274] - INFO: epoch 001:  15503 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.9, wpb=102.6, bsz=40, num_updates=15480, lr=6.69861e-05, gnorm=0.516, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44578
2022-09-30 20:54:13 - progress_bar.py[line:274] - INFO: epoch 001:  15513 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.88, wpb=102.6, bsz=40, num_updates=15490, lr=6.69755e-05, gnorm=0.574, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44589
2022-09-30 20:54:24 - progress_bar.py[line:274] - INFO: epoch 001:  15523 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.87, wpb=101.6, bsz=40, num_updates=15500, lr=6.6965e-05, gnorm=0.545, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44601
2022-09-30 20:54:35 - progress_bar.py[line:274] - INFO: epoch 001:  15533 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.89, wpb=102.9, bsz=40, num_updates=15510, lr=6.69544e-05, gnorm=0.561, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44612
2022-09-30 20:54:47 - progress_bar.py[line:274] - INFO: epoch 001:  15543 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.88, wpb=102.2, bsz=40, num_updates=15520, lr=6.69439e-05, gnorm=0.511, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44623
2022-09-30 20:54:57 - progress_bar.py[line:274] - INFO: epoch 001:  15553 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.7, ups=0.93, wpb=100.5, bsz=40, num_updates=15530, lr=6.69333e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44634
2022-09-30 20:55:08 - progress_bar.py[line:274] - INFO: epoch 001:  15563 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.9, wpb=101.5, bsz=40, num_updates=15540, lr=6.69227e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44645
2022-09-30 20:55:20 - progress_bar.py[line:274] - INFO: epoch 001:  15573 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.89, wpb=101.1, bsz=40, num_updates=15550, lr=6.69122e-05, gnorm=0.655, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44657
2022-09-30 20:55:32 - progress_bar.py[line:274] - INFO: epoch 001:  15583 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=82.8, ups=0.82, wpb=100.6, bsz=40, num_updates=15560, lr=6.69016e-05, gnorm=0.543, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=44669
2022-09-30 20:55:45 - progress_bar.py[line:274] - INFO: epoch 001:  15593 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=76.7, ups=0.76, wpb=101.5, bsz=40, num_updates=15570, lr=6.68911e-05, gnorm=0.573, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=44682
2022-09-30 20:55:58 - progress_bar.py[line:274] - INFO: epoch 001:  15603 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=80, ups=0.8, wpb=100.5, bsz=40, num_updates=15580, lr=6.68805e-05, gnorm=0.59, clip=0, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=44694
2022-09-30 20:56:09 - progress_bar.py[line:274] - INFO: epoch 001:  15613 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.8, ups=0.87, wpb=102.3, bsz=40, num_updates=15590, lr=6.68699e-05, gnorm=0.561, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44706
2022-09-30 20:56:20 - progress_bar.py[line:274] - INFO: epoch 001:  15623 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=15600, lr=6.68594e-05, gnorm=0.545, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44717
2022-09-30 20:56:32 - progress_bar.py[line:274] - INFO: epoch 001:  15633 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.3, ups=0.88, wpb=99.1, bsz=40, num_updates=15610, lr=6.68488e-05, gnorm=0.578, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44728
2022-09-30 20:56:43 - progress_bar.py[line:274] - INFO: epoch 001:  15643 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.87, wpb=101.3, bsz=40, num_updates=15620, lr=6.68383e-05, gnorm=0.574, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44740
2022-09-30 20:56:54 - progress_bar.py[line:274] - INFO: epoch 001:  15653 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.9, ups=0.91, wpb=102.2, bsz=40, num_updates=15630, lr=6.68277e-05, gnorm=0.606, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44751
2022-09-30 20:57:05 - progress_bar.py[line:274] - INFO: epoch 001:  15663 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.8, ups=0.9, wpb=100.8, bsz=40, num_updates=15640, lr=6.68171e-05, gnorm=0.624, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44762
2022-09-30 20:57:18 - progress_bar.py[line:274] - INFO: epoch 001:  15673 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=82, ups=0.82, wpb=100.5, bsz=40, num_updates=15650, lr=6.68066e-05, gnorm=0.577, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=44774
2022-09-30 20:57:30 - progress_bar.py[line:274] - INFO: epoch 001:  15683 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=80.1, ups=0.78, wpb=102.5, bsz=40, num_updates=15660, lr=6.6796e-05, gnorm=0.621, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=44787
2022-09-30 20:57:42 - progress_bar.py[line:274] - INFO: epoch 001:  15693 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.7, ups=0.86, wpb=101.3, bsz=40, num_updates=15670, lr=6.67855e-05, gnorm=0.488, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=44799
2022-09-30 20:57:54 - progress_bar.py[line:274] - INFO: epoch 001:  15703 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.3, ups=0.88, wpb=100.8, bsz=40, num_updates=15680, lr=6.67749e-05, gnorm=0.525, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44810
2022-09-30 20:58:05 - progress_bar.py[line:274] - INFO: epoch 001:  15713 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.89, wpb=102.4, bsz=40, num_updates=15690, lr=6.67643e-05, gnorm=0.599, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44822
2022-09-30 20:58:16 - progress_bar.py[line:274] - INFO: epoch 001:  15723 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.6, ups=0.86, wpb=101.6, bsz=40, num_updates=15700, lr=6.67538e-05, gnorm=0.577, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=44833
2022-09-30 20:58:28 - progress_bar.py[line:274] - INFO: epoch 001:  15733 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.88, wpb=101.8, bsz=40, num_updates=15710, lr=6.67432e-05, gnorm=0.654, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44845
2022-09-30 20:58:39 - progress_bar.py[line:274] - INFO: epoch 001:  15743 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.91, wpb=101, bsz=40, num_updates=15720, lr=6.67327e-05, gnorm=0.6, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44856
2022-09-30 20:58:49 - progress_bar.py[line:274] - INFO: epoch 001:  15753 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95, ups=0.94, wpb=101.1, bsz=40, num_updates=15730, lr=6.67221e-05, gnorm=0.579, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44866
2022-09-30 20:59:01 - progress_bar.py[line:274] - INFO: epoch 001:  15763 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=85.4, ups=0.86, wpb=99.2, bsz=40, num_updates=15740, lr=6.67115e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=44878
2022-09-30 20:59:12 - progress_bar.py[line:274] - INFO: epoch 001:  15773 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.9, wpb=101.9, bsz=40, num_updates=15750, lr=6.6701e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44889
2022-09-30 20:59:23 - progress_bar.py[line:274] - INFO: epoch 001:  15783 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=92.5, nsentences=36.4, sample_size=92.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.7, ups=0.94, wpb=92.5, bsz=36.4, num_updates=15760, lr=6.66904e-05, gnorm=0.685, clip=10, loss_scale=512, train_wall=11, gb_free=33, ema_decay=0.9999, wall=44900
2022-09-30 20:59:23 - train.py[line:339] - INFO: end of epoch 1 (average epoch stats below)
2022-09-30 20:59:23 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.619 | loss_v1 0 | loss_v2 0 | nll_loss 0.415 | ntokens 101.339 | nsentences 39.998 | sample_size 101.339 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.33 | wps 35.6 | ups 0.35 | wpb 101.3 | bsz 40 | num_updates 15760 | lr 6.66904e-05 | gnorm 0.924 | clip 22.5 | loss_scale 512 | train_wall 17651 | gb_free 33 | ema_decay 0.9999 | wall 44900
2022-09-30 20:59:23 - trainer.py[line:643] - INFO: loading train data for epoch 2
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv slice_id 0 row count 315642 total row count 631284
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv slice_id 1 row count 315642 total row count 631284
2022-09-30 20:59:24 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-30 20:59:25 - trainer.py[line:707] - INFO: begin training epoch 2
2022-09-30 20:59:25 - train.py[line:312] - INFO: Start iterating over samples
2022-09-30 20:59:37 - progress_bar.py[line:274] - INFO: epoch 002:     10 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=72.5, ups=0.72, wpb=100.8, bsz=40, num_updates=15770, lr=6.66799e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44913
2022-09-30 20:59:48 - progress_bar.py[line:274] - INFO: epoch 002:     20 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=15780, lr=6.66693e-05, gnorm=0.592, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44925
2022-09-30 20:59:59 - progress_bar.py[line:274] - INFO: epoch 002:     30 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.6, ups=0.89, wpb=100, bsz=40, num_updates=15790, lr=6.66587e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44936
2022-09-30 21:00:10 - progress_bar.py[line:274] - INFO: epoch 002:     40 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.4, ups=0.91, wpb=102.1, bsz=40, num_updates=15800, lr=6.66482e-05, gnorm=0.663, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44947
2022-09-30 21:00:22 - progress_bar.py[line:274] - INFO: epoch 002:     50 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.88, wpb=103, bsz=40, num_updates=15810, lr=6.66376e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44958
2022-09-30 21:00:33 - progress_bar.py[line:274] - INFO: epoch 002:     60 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.88, wpb=101.5, bsz=40, num_updates=15820, lr=6.66271e-05, gnorm=0.575, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44970
2022-09-30 21:00:44 - progress_bar.py[line:274] - INFO: epoch 002:     70 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.88, wpb=102.5, bsz=40, num_updates=15830, lr=6.66165e-05, gnorm=0.606, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44981
2022-09-30 21:00:56 - progress_bar.py[line:274] - INFO: epoch 002:     80 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.6, ups=0.88, wpb=102.8, bsz=40, num_updates=15840, lr=6.66059e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44992
2022-09-30 21:01:07 - progress_bar.py[line:274] - INFO: epoch 002:     90 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.2, ups=0.88, wpb=100.9, bsz=40, num_updates=15850, lr=6.65954e-05, gnorm=0.612, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45004
2022-09-30 21:01:18 - progress_bar.py[line:274] - INFO: epoch 002:    100 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.91, wpb=100.1, bsz=40, num_updates=15860, lr=6.65848e-05, gnorm=0.584, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45015
2022-09-30 21:01:29 - progress_bar.py[line:274] - INFO: epoch 002:    110 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.88, wpb=100.9, bsz=40, num_updates=15870, lr=6.65743e-05, gnorm=0.607, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45026
2022-09-30 21:01:41 - progress_bar.py[line:274] - INFO: epoch 002:    120 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.88, wpb=100.4, bsz=40, num_updates=15880, lr=6.65637e-05, gnorm=0.626, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45038
2022-09-30 21:01:52 - progress_bar.py[line:274] - INFO: epoch 002:    130 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.4, ups=0.88, wpb=100, bsz=40, num_updates=15890, lr=6.65531e-05, gnorm=0.601, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45049
2022-09-30 21:02:04 - progress_bar.py[line:274] - INFO: epoch 002:    140 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.87, wpb=102.9, bsz=40, num_updates=15900, lr=6.65426e-05, gnorm=0.641, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45060
2022-09-30 21:02:15 - progress_bar.py[line:274] - INFO: epoch 002:    150 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.5, ups=0.88, wpb=102.3, bsz=40, num_updates=15910, lr=6.6532e-05, gnorm=0.546, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45072
2022-09-30 21:02:26 - progress_bar.py[line:274] - INFO: epoch 002:    160 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=15920, lr=6.65215e-05, gnorm=0.565, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45083
2022-09-30 21:02:37 - progress_bar.py[line:274] - INFO: epoch 002:    170 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.9, wpb=100.4, bsz=40, num_updates=15930, lr=6.65109e-05, gnorm=0.703, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45094
2022-09-30 21:02:49 - progress_bar.py[line:274] - INFO: epoch 002:    180 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.4, ups=0.86, wpb=101.6, bsz=40, num_updates=15940, lr=6.65003e-05, gnorm=0.637, clip=10, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=45106
2022-09-30 21:03:02 - progress_bar.py[line:274] - INFO: epoch 002:    190 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=80.5, ups=0.79, wpb=101.4, bsz=40, num_updates=15950, lr=6.64898e-05, gnorm=0.599, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=45118
2022-09-30 21:03:14 - progress_bar.py[line:274] - INFO: epoch 002:    200 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=80, ups=0.78, wpb=102.8, bsz=40, num_updates=15960, lr=6.64792e-05, gnorm=0.532, clip=0, loss_scale=1024, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=45131
2022-09-30 21:03:26 - progress_bar.py[line:274] - INFO: epoch 002:    210 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.89, wpb=102.9, bsz=40, num_updates=15970, lr=6.64687e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45142
2022-09-30 21:03:37 - progress_bar.py[line:274] - INFO: epoch 002:    220 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.5, ups=0.86, wpb=101.2, bsz=40, num_updates=15980, lr=6.64581e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45154
2022-09-30 21:03:49 - progress_bar.py[line:274] - INFO: epoch 002:    230 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.8, ups=0.89, wpb=100.3, bsz=40, num_updates=15990, lr=6.64476e-05, gnorm=0.568, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45165
2022-09-30 21:04:00 - progress_bar.py[line:274] - INFO: epoch 002:    240 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.2, ups=0.86, wpb=101.3, bsz=40, num_updates=16000, lr=6.6437e-05, gnorm=0.642, clip=10, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=45177
2022-09-30 21:04:12 - progress_bar.py[line:274] - INFO: epoch 002:    250 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.88, wpb=102.1, bsz=40, num_updates=16010, lr=6.64264e-05, gnorm=0.581, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45188
2022-09-30 21:04:23 - progress_bar.py[line:274] - INFO: epoch 002:    260 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.6, ups=0.88, wpb=102.7, bsz=40, num_updates=16020, lr=6.64159e-05, gnorm=0.503, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45200
2022-09-30 21:04:34 - progress_bar.py[line:274] - INFO: epoch 002:    270 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.88, wpb=101.9, bsz=40, num_updates=16030, lr=6.64053e-05, gnorm=0.523, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45211
2022-09-30 21:04:45 - progress_bar.py[line:274] - INFO: epoch 002:    280 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.6, ups=0.89, wpb=101.7, bsz=40, num_updates=16040, lr=6.63948e-05, gnorm=0.565, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45222
2022-09-30 21:04:57 - progress_bar.py[line:274] - INFO: epoch 002:    290 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.4, ups=0.87, wpb=99.8, bsz=40, num_updates=16050, lr=6.63842e-05, gnorm=0.625, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45234
2022-09-30 21:05:08 - progress_bar.py[line:274] - INFO: epoch 002:    300 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=101, bsz=40, num_updates=16060, lr=6.63736e-05, gnorm=0.62, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45245
2022-09-30 21:05:20 - progress_bar.py[line:274] - INFO: epoch 002:    310 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.9, wpb=101.7, bsz=40, num_updates=16070, lr=6.63631e-05, gnorm=0.682, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45256
2022-09-30 21:05:31 - progress_bar.py[line:274] - INFO: epoch 002:    320 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.4, ups=0.86, wpb=101.3, bsz=40, num_updates=16080, lr=6.63525e-05, gnorm=0.601, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=45268
2022-09-30 21:05:42 - progress_bar.py[line:274] - INFO: epoch 002:    330 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=98.2, nsentences=40, sample_size=98.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.2, ups=0.9, wpb=98.2, bsz=40, num_updates=16090, lr=6.6342e-05, gnorm=0.668, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45279
2022-09-30 21:05:54 - progress_bar.py[line:274] - INFO: epoch 002:    340 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.7, ups=0.87, wpb=100.7, bsz=40, num_updates=16100, lr=6.63314e-05, gnorm=0.546, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45290
2022-09-30 21:06:05 - progress_bar.py[line:274] - INFO: epoch 002:    350 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.89, wpb=102.2, bsz=40, num_updates=16110, lr=6.63208e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45302
2022-09-30 21:06:16 - progress_bar.py[line:274] - INFO: epoch 002:    360 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.6, ups=0.89, wpb=101.6, bsz=40, num_updates=16120, lr=6.63103e-05, gnorm=0.541, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45313
2022-09-30 21:06:28 - progress_bar.py[line:274] - INFO: epoch 002:    370 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.8, ups=0.87, wpb=102.7, bsz=40, num_updates=16130, lr=6.62997e-05, gnorm=0.562, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45324
2022-09-30 21:06:39 - progress_bar.py[line:274] - INFO: epoch 002:    380 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.9, wpb=100.1, bsz=40, num_updates=16140, lr=6.62892e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45336
2022-09-30 21:06:50 - progress_bar.py[line:274] - INFO: epoch 002:    390 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.9, wpb=102.2, bsz=40, num_updates=16150, lr=6.62786e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45347
2022-09-30 21:07:01 - progress_bar.py[line:274] - INFO: epoch 002:    400 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=101.9, bsz=40, num_updates=16160, lr=6.6268e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45358
2022-09-30 21:07:13 - progress_bar.py[line:274] - INFO: epoch 002:    410 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.5, ups=0.87, wpb=100.3, bsz=40, num_updates=16170, lr=6.62575e-05, gnorm=0.594, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45369
2022-09-30 21:07:24 - progress_bar.py[line:274] - INFO: epoch 002:    420 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.89, wpb=100.8, bsz=40, num_updates=16180, lr=6.62469e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45381
2022-09-30 21:07:35 - progress_bar.py[line:274] - INFO: epoch 002:    430 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.7, ups=0.88, wpb=101.3, bsz=40, num_updates=16190, lr=6.62364e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45392
2022-09-30 21:07:47 - progress_bar.py[line:274] - INFO: epoch 002:    440 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=101.1, bsz=40, num_updates=16200, lr=6.62258e-05, gnorm=0.602, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45403
2022-09-30 21:07:58 - progress_bar.py[line:274] - INFO: epoch 002:    450 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=85.3, ups=0.85, wpb=99.9, bsz=40, num_updates=16210, lr=6.62152e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=45415
2022-09-30 21:08:09 - progress_bar.py[line:274] - INFO: epoch 002:    460 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.9, wpb=100.6, bsz=40, num_updates=16220, lr=6.62047e-05, gnorm=0.615, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45426
2022-09-30 21:08:20 - progress_bar.py[line:274] - INFO: epoch 002:    470 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.91, wpb=100.4, bsz=40, num_updates=16230, lr=6.61941e-05, gnorm=0.499, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45437
2022-09-30 21:08:32 - progress_bar.py[line:274] - INFO: epoch 002:    480 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.6, ups=0.9, wpb=100.6, bsz=40, num_updates=16240, lr=6.61836e-05, gnorm=0.627, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45448
2022-09-30 21:08:43 - progress_bar.py[line:274] - INFO: epoch 002:    490 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.8, ups=0.91, wpb=102.1, bsz=40, num_updates=16250, lr=6.6173e-05, gnorm=0.507, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45459
2022-09-30 21:08:54 - progress_bar.py[line:274] - INFO: epoch 002:    500 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.89, wpb=102.3, bsz=40, num_updates=16260, lr=6.61624e-05, gnorm=0.53, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45471
2022-09-30 21:09:05 - progress_bar.py[line:274] - INFO: epoch 002:    510 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.88, wpb=101.6, bsz=40, num_updates=16270, lr=6.61519e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45482
2022-09-30 21:09:16 - progress_bar.py[line:274] - INFO: epoch 002:    520 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.88, wpb=102.9, bsz=40, num_updates=16280, lr=6.61413e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45493
2022-09-30 21:09:28 - progress_bar.py[line:274] - INFO: epoch 002:    530 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.8, ups=0.87, wpb=101.2, bsz=40, num_updates=16290, lr=6.61308e-05, gnorm=0.58, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45505
2022-09-30 21:09:40 - progress_bar.py[line:274] - INFO: epoch 002:    540 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86, ups=0.85, wpb=100.6, bsz=40, num_updates=16300, lr=6.61202e-05, gnorm=0.576, clip=0, loss_scale=2048, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=45516
2022-09-30 21:09:46 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 21:09:52 - progress_bar.py[line:274] - INFO: epoch 002:    551 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=82.5, ups=0.8, wpb=102.7, bsz=40, num_updates=16310, lr=6.61096e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=45529
2022-09-30 21:10:04 - progress_bar.py[line:274] - INFO: epoch 002:    561 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.9, ups=0.86, wpb=101, bsz=40, num_updates=16320, lr=6.60991e-05, gnorm=0.56, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=45541
2022-09-30 21:10:15 - progress_bar.py[line:274] - INFO: epoch 002:    571 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.89, wpb=102, bsz=40, num_updates=16330, lr=6.60885e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45552
2022-09-30 21:10:27 - progress_bar.py[line:274] - INFO: epoch 002:    581 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.4, ups=0.86, wpb=100.7, bsz=40, num_updates=16340, lr=6.6078e-05, gnorm=0.577, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=45563
2022-09-30 21:10:39 - progress_bar.py[line:274] - INFO: epoch 002:    591 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=80.2, ups=0.8, wpb=100.6, bsz=40, num_updates=16350, lr=6.60674e-05, gnorm=0.61, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=45576
2022-09-30 21:10:51 - progress_bar.py[line:274] - INFO: epoch 002:    601 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=85.8, ups=0.86, wpb=100.3, bsz=40, num_updates=16360, lr=6.60568e-05, gnorm=0.64, clip=10, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=45588
2022-09-30 21:11:02 - progress_bar.py[line:274] - INFO: epoch 002:    611 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.9, ups=0.91, wpb=100.7, bsz=40, num_updates=16370, lr=6.60463e-05, gnorm=0.653, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=45599
2022-09-30 21:11:14 - progress_bar.py[line:274] - INFO: epoch 002:    621 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87, ups=0.86, wpb=101.2, bsz=40, num_updates=16380, lr=6.60357e-05, gnorm=0.53, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=45610
2022-09-30 21:11:25 - progress_bar.py[line:274] - INFO: epoch 002:    631 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.89, wpb=102, bsz=40, num_updates=16390, lr=6.60252e-05, gnorm=0.514, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45621
2022-09-30 21:11:36 - progress_bar.py[line:274] - INFO: epoch 002:    641 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=16400, lr=6.60146e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=45633
2022-09-30 21:11:48 - progress_bar.py[line:274] - INFO: epoch 002:    651 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.1, ups=0.86, wpb=102.9, bsz=40, num_updates=16410, lr=6.6004e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=45644
2022-09-30 21:11:59 - progress_bar.py[line:274] - INFO: epoch 002:    661 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.9, wpb=101.5, bsz=40, num_updates=16420, lr=6.59935e-05, gnorm=0.562, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45655
2022-09-30 21:12:10 - progress_bar.py[line:274] - INFO: epoch 002:    671 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=16430, lr=6.59829e-05, gnorm=0.558, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45667
2022-09-30 21:12:21 - progress_bar.py[line:274] - INFO: epoch 002:    681 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.9, ups=0.92, wpb=100.7, bsz=40, num_updates=16440, lr=6.59724e-05, gnorm=0.558, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45678
2022-09-30 21:12:32 - progress_bar.py[line:274] - INFO: epoch 002:    691 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.9, wpb=100.6, bsz=40, num_updates=16450, lr=6.59618e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45689
2022-09-30 21:12:43 - progress_bar.py[line:274] - INFO: epoch 002:    701 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.91, wpb=100.5, bsz=40, num_updates=16460, lr=6.59512e-05, gnorm=0.694, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45700
2022-09-30 21:12:54 - progress_bar.py[line:274] - INFO: epoch 002:    711 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.4, ups=0.9, wpb=102.7, bsz=40, num_updates=16470, lr=6.59407e-05, gnorm=0.608, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45711
2022-09-30 21:13:05 - progress_bar.py[line:274] - INFO: epoch 002:    721 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.9, wpb=100.4, bsz=40, num_updates=16480, lr=6.59301e-05, gnorm=0.589, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45722
2022-09-30 21:13:16 - progress_bar.py[line:274] - INFO: epoch 002:    731 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.8, ups=0.93, wpb=101.6, bsz=40, num_updates=16490, lr=6.59196e-05, gnorm=0.501, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45733
2022-09-30 21:13:27 - progress_bar.py[line:274] - INFO: epoch 002:    741 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.89, wpb=101.1, bsz=40, num_updates=16500, lr=6.5909e-05, gnorm=0.638, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45744
2022-09-30 21:13:39 - progress_bar.py[line:274] - INFO: epoch 002:    751 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.2, ups=0.87, wpb=100.4, bsz=40, num_updates=16510, lr=6.58984e-05, gnorm=0.594, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45755
2022-09-30 21:13:50 - progress_bar.py[line:274] - INFO: epoch 002:    761 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.4, ups=0.92, wpb=102.5, bsz=40, num_updates=16520, lr=6.58879e-05, gnorm=0.591, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45766
2022-09-30 21:14:01 - progress_bar.py[line:274] - INFO: epoch 002:    771 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.88, wpb=103.3, bsz=40, num_updates=16530, lr=6.58773e-05, gnorm=0.617, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45778
2022-09-30 21:14:12 - progress_bar.py[line:274] - INFO: epoch 002:    781 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.3, ups=0.87, wpb=101, bsz=40, num_updates=16540, lr=6.58668e-05, gnorm=0.524, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45789
2022-09-30 21:14:24 - progress_bar.py[line:274] - INFO: epoch 002:    791 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.9, wpb=100.2, bsz=40, num_updates=16550, lr=6.58562e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45800
2022-09-30 21:14:35 - progress_bar.py[line:274] - INFO: epoch 002:    801 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.4, ups=0.87, wpb=101.4, bsz=40, num_updates=16560, lr=6.58456e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45812
2022-09-30 21:14:46 - progress_bar.py[line:274] - INFO: epoch 002:    811 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.1, ups=0.92, wpb=101.4, bsz=40, num_updates=16570, lr=6.58351e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45823
2022-09-30 21:14:57 - progress_bar.py[line:274] - INFO: epoch 002:    821 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93, ups=0.91, wpb=102.4, bsz=40, num_updates=16580, lr=6.58245e-05, gnorm=0.574, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=45834
2022-09-30 21:15:08 - progress_bar.py[line:274] - INFO: epoch 002:    831 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.6, ups=0.89, wpb=98.7, bsz=40, num_updates=16590, lr=6.5814e-05, gnorm=0.634, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45845
2022-09-30 21:15:19 - progress_bar.py[line:274] - INFO: epoch 002:    841 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.89, wpb=102.5, bsz=40, num_updates=16600, lr=6.58034e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45856
2022-09-30 21:15:31 - progress_bar.py[line:274] - INFO: epoch 002:    851 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.88, wpb=102.2, bsz=40, num_updates=16610, lr=6.57928e-05, gnorm=0.552, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45868
2022-09-30 21:15:42 - progress_bar.py[line:274] - INFO: epoch 002:    861 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.88, wpb=101.3, bsz=40, num_updates=16620, lr=6.57823e-05, gnorm=0.525, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45879
2022-09-30 21:15:53 - progress_bar.py[line:274] - INFO: epoch 002:    871 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.89, wpb=101.5, bsz=40, num_updates=16630, lr=6.57717e-05, gnorm=0.521, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45890
2022-09-30 21:16:04 - progress_bar.py[line:274] - INFO: epoch 002:    881 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.8, ups=0.92, wpb=101, bsz=40, num_updates=16640, lr=6.57612e-05, gnorm=0.577, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45901
2022-09-30 21:16:16 - progress_bar.py[line:274] - INFO: epoch 002:    891 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88, ups=0.87, wpb=101.3, bsz=40, num_updates=16650, lr=6.57506e-05, gnorm=0.65, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45913
2022-09-30 21:16:27 - progress_bar.py[line:274] - INFO: epoch 002:    901 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.9, wpb=99.6, bsz=40, num_updates=16660, lr=6.574e-05, gnorm=0.651, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45924
2022-09-30 21:16:38 - progress_bar.py[line:274] - INFO: epoch 002:    911 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.5, ups=0.87, wpb=102.5, bsz=40, num_updates=16670, lr=6.57295e-05, gnorm=0.52, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45935
2022-09-30 21:16:49 - progress_bar.py[line:274] - INFO: epoch 002:    921 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.4, ups=0.93, wpb=102.2, bsz=40, num_updates=16680, lr=6.57189e-05, gnorm=0.544, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45946
2022-09-30 21:17:00 - progress_bar.py[line:274] - INFO: epoch 002:    931 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.9, wpb=102.1, bsz=40, num_updates=16690, lr=6.57084e-05, gnorm=0.578, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45957
2022-09-30 21:17:13 - progress_bar.py[line:274] - INFO: epoch 002:    941 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=76.5, ups=0.76, wpb=100.5, bsz=40, num_updates=16700, lr=6.56978e-05, gnorm=0.639, clip=0, loss_scale=1024, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=45970
2022-09-30 21:17:26 - progress_bar.py[line:274] - INFO: epoch 002:    951 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=79.7, ups=0.78, wpb=102, bsz=40, num_updates=16710, lr=6.56872e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=45983
2022-09-30 21:17:38 - progress_bar.py[line:274] - INFO: epoch 002:    961 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.9, ups=0.88, wpb=100.2, bsz=40, num_updates=16720, lr=6.56767e-05, gnorm=0.667, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45994
2022-09-30 21:17:49 - progress_bar.py[line:274] - INFO: epoch 002:    971 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.9, wpb=102.8, bsz=40, num_updates=16730, lr=6.56661e-05, gnorm=0.589, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46005
2022-09-30 21:18:00 - progress_bar.py[line:274] - INFO: epoch 002:    981 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=16740, lr=6.56556e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46017
2022-09-30 21:18:11 - progress_bar.py[line:274] - INFO: epoch 002:    991 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.88, wpb=100.9, bsz=40, num_updates=16750, lr=6.5645e-05, gnorm=0.589, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46028
2022-09-30 21:18:23 - progress_bar.py[line:274] - INFO: epoch 002:   1001 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=16760, lr=6.56344e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=46039
2022-09-30 21:18:34 - progress_bar.py[line:274] - INFO: epoch 002:   1011 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.2, ups=0.89, wpb=100.2, bsz=40, num_updates=16770, lr=6.56239e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46051
2022-09-30 21:18:45 - progress_bar.py[line:274] - INFO: epoch 002:   1021 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.9, ups=0.87, wpb=101.2, bsz=40, num_updates=16780, lr=6.56133e-05, gnorm=0.585, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46062
2022-09-30 21:18:56 - progress_bar.py[line:274] - INFO: epoch 002:   1031 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.5, ups=0.91, wpb=101.2, bsz=40, num_updates=16790, lr=6.56028e-05, gnorm=0.626, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46073
2022-09-30 21:19:08 - progress_bar.py[line:274] - INFO: epoch 002:   1041 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.2, ups=0.87, wpb=101.8, bsz=40, num_updates=16800, lr=6.55922e-05, gnorm=0.666, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46085
2022-09-30 21:19:19 - progress_bar.py[line:274] - INFO: epoch 002:   1051 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.89, wpb=100.6, bsz=40, num_updates=16810, lr=6.55816e-05, gnorm=0.623, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46096
2022-09-30 21:19:31 - progress_bar.py[line:274] - INFO: epoch 002:   1061 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.4, ups=0.87, wpb=101.2, bsz=40, num_updates=16820, lr=6.55711e-05, gnorm=0.633, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46107
2022-09-30 21:19:42 - progress_bar.py[line:274] - INFO: epoch 002:   1071 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.88, wpb=101.5, bsz=40, num_updates=16830, lr=6.55605e-05, gnorm=0.582, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46119
2022-09-30 21:19:53 - progress_bar.py[line:274] - INFO: epoch 002:   1081 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.3, ups=0.86, wpb=102.3, bsz=40, num_updates=16840, lr=6.555e-05, gnorm=0.609, clip=0, loss_scale=2048, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=46130
2022-09-30 21:20:05 - progress_bar.py[line:274] - INFO: epoch 002:   1091 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.2, ups=0.87, wpb=101, bsz=40, num_updates=16850, lr=6.55394e-05, gnorm=0.536, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46142
2022-09-30 21:20:15 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 21:20:18 - progress_bar.py[line:274] - INFO: epoch 002:   1102 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=74.9, ups=0.75, wpb=99.7, bsz=40, num_updates=16860, lr=6.55288e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=46155
2022-09-30 21:20:31 - progress_bar.py[line:274] - INFO: epoch 002:   1112 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=81.8, ups=0.81, wpb=100.7, bsz=40, num_updates=16870, lr=6.55183e-05, gnorm=0.634, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=46167
2022-09-30 21:20:43 - progress_bar.py[line:274] - INFO: epoch 002:   1122 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=83.7, ups=0.83, wpb=101.2, bsz=40, num_updates=16880, lr=6.55077e-05, gnorm=0.556, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=46179
2022-09-30 21:20:55 - progress_bar.py[line:274] - INFO: epoch 002:   1132 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=81.2, ups=0.8, wpb=102, bsz=40, num_updates=16890, lr=6.54972e-05, gnorm=0.579, clip=0, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=46192
2022-09-30 21:21:07 - progress_bar.py[line:274] - INFO: epoch 002:   1142 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86, ups=0.85, wpb=101.6, bsz=40, num_updates=16900, lr=6.54866e-05, gnorm=0.619, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=46204
2022-09-30 21:21:18 - progress_bar.py[line:274] - INFO: epoch 002:   1152 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90, ups=0.89, wpb=100.9, bsz=40, num_updates=16910, lr=6.5476e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46215
2022-09-30 21:21:30 - progress_bar.py[line:274] - INFO: epoch 002:   1162 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.6, ups=0.88, wpb=100.4, bsz=40, num_updates=16920, lr=6.54655e-05, gnorm=0.645, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46226
2022-09-30 21:21:43 - progress_bar.py[line:274] - INFO: epoch 002:   1172 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=78.9, ups=0.78, wpb=101.3, bsz=40, num_updates=16930, lr=6.54549e-05, gnorm=0.566, clip=0, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=46239
2022-09-30 21:21:54 - progress_bar.py[line:274] - INFO: epoch 002:   1182 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.87, wpb=100.9, bsz=40, num_updates=16940, lr=6.54444e-05, gnorm=0.605, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46251
2022-09-30 21:22:07 - progress_bar.py[line:274] - INFO: epoch 002:   1192 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=81.4, ups=0.79, wpb=102.5, bsz=40, num_updates=16950, lr=6.54338e-05, gnorm=0.556, clip=0, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=46263
2022-09-30 21:22:19 - progress_bar.py[line:274] - INFO: epoch 002:   1202 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.5, ups=0.85, wpb=101.1, bsz=40, num_updates=16960, lr=6.54233e-05, gnorm=0.567, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=46275
2022-09-30 21:22:30 - progress_bar.py[line:274] - INFO: epoch 002:   1212 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.5, ups=0.89, wpb=101.4, bsz=40, num_updates=16970, lr=6.54127e-05, gnorm=0.585, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46286
2022-09-30 21:22:41 - progress_bar.py[line:274] - INFO: epoch 002:   1222 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.3, ups=0.91, wpb=101.9, bsz=40, num_updates=16980, lr=6.54021e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46298
2022-09-30 21:22:52 - progress_bar.py[line:274] - INFO: epoch 002:   1232 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=105.3, nsentences=40, sample_size=105.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.7, ups=0.88, wpb=105.3, bsz=40, num_updates=16990, lr=6.53916e-05, gnorm=0.538, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=46309
2022-09-30 21:23:04 - progress_bar.py[line:274] - INFO: epoch 002:   1242 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=84.4, ups=0.82, wpb=102.9, bsz=40, num_updates=17000, lr=6.5381e-05, gnorm=0.655, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=46321
2022-09-30 21:23:15 - progress_bar.py[line:274] - INFO: epoch 002:   1252 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94, ups=0.92, wpb=101.7, bsz=40, num_updates=17010, lr=6.53705e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46332
2022-09-30 21:23:27 - progress_bar.py[line:274] - INFO: epoch 002:   1262 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87, ups=0.86, wpb=100.8, bsz=40, num_updates=17020, lr=6.53599e-05, gnorm=0.665, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=46344
2022-09-30 21:23:38 - progress_bar.py[line:274] - INFO: epoch 002:   1272 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.88, wpb=101.6, bsz=40, num_updates=17030, lr=6.53493e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46355
2022-09-30 21:23:49 - progress_bar.py[line:274] - INFO: epoch 002:   1282 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=17040, lr=6.53388e-05, gnorm=0.535, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46366
2022-09-30 21:24:00 - progress_bar.py[line:274] - INFO: epoch 002:   1292 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.91, wpb=99.5, bsz=40, num_updates=17050, lr=6.53282e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46377
2022-09-30 21:24:12 - progress_bar.py[line:274] - INFO: epoch 002:   1302 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=17060, lr=6.53177e-05, gnorm=0.627, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46388
2022-09-30 21:24:23 - progress_bar.py[line:274] - INFO: epoch 002:   1312 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.4, ups=0.88, wpb=102, bsz=40, num_updates=17070, lr=6.53071e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46400
2022-09-30 21:24:35 - progress_bar.py[line:274] - INFO: epoch 002:   1322 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=85.9, ups=0.87, wpb=98.7, bsz=40, num_updates=17080, lr=6.52965e-05, gnorm=0.63, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46411
2022-09-30 21:24:46 - progress_bar.py[line:274] - INFO: epoch 002:   1332 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=17090, lr=6.5286e-05, gnorm=0.557, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46423
2022-09-30 21:24:57 - progress_bar.py[line:274] - INFO: epoch 002:   1342 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.9, wpb=101.7, bsz=40, num_updates=17100, lr=6.52754e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46434
2022-09-30 21:25:08 - progress_bar.py[line:274] - INFO: epoch 002:   1352 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.88, wpb=102.4, bsz=40, num_updates=17110, lr=6.52649e-05, gnorm=0.634, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46445
2022-09-30 21:25:20 - progress_bar.py[line:274] - INFO: epoch 002:   1362 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.89, wpb=103.3, bsz=40, num_updates=17120, lr=6.52543e-05, gnorm=0.635, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46456
2022-09-30 21:25:31 - progress_bar.py[line:274] - INFO: epoch 002:   1372 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.7, ups=0.91, wpb=101, bsz=40, num_updates=17130, lr=6.52437e-05, gnorm=0.66, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46467
2022-09-30 21:25:42 - progress_bar.py[line:274] - INFO: epoch 002:   1382 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=17140, lr=6.52332e-05, gnorm=0.621, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46479
2022-09-30 21:25:53 - progress_bar.py[line:274] - INFO: epoch 002:   1392 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.89, wpb=104.7, bsz=40, num_updates=17150, lr=6.52226e-05, gnorm=0.557, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46490
2022-09-30 21:26:04 - progress_bar.py[line:274] - INFO: epoch 002:   1402 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.88, wpb=102.1, bsz=40, num_updates=17160, lr=6.52121e-05, gnorm=0.62, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46501
2022-09-30 21:26:16 - progress_bar.py[line:274] - INFO: epoch 002:   1412 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=17170, lr=6.52015e-05, gnorm=0.543, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46513
2022-09-30 21:26:27 - progress_bar.py[line:274] - INFO: epoch 002:   1422 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.91, wpb=100.8, bsz=40, num_updates=17180, lr=6.51909e-05, gnorm=0.541, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46524
2022-09-30 21:26:38 - progress_bar.py[line:274] - INFO: epoch 002:   1432 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.92, wpb=99.9, bsz=40, num_updates=17190, lr=6.51804e-05, gnorm=0.509, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46534
2022-09-30 21:26:49 - progress_bar.py[line:274] - INFO: epoch 002:   1442 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.7, ups=0.88, wpb=99.5, bsz=40, num_updates=17200, lr=6.51698e-05, gnorm=0.525, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46546
2022-09-30 21:27:00 - progress_bar.py[line:274] - INFO: epoch 002:   1452 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.7, ups=0.89, wpb=102.4, bsz=40, num_updates=17210, lr=6.51593e-05, gnorm=0.565, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46557
2022-09-30 21:27:12 - progress_bar.py[line:274] - INFO: epoch 002:   1462 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.9, ups=0.87, wpb=100.6, bsz=40, num_updates=17220, lr=6.51487e-05, gnorm=0.613, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46569
2022-09-30 21:27:23 - progress_bar.py[line:274] - INFO: epoch 002:   1472 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.88, wpb=103.3, bsz=40, num_updates=17230, lr=6.51381e-05, gnorm=0.616, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46580
2022-09-30 21:27:35 - progress_bar.py[line:274] - INFO: epoch 002:   1482 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=84, ups=0.83, wpb=100.9, bsz=40, num_updates=17240, lr=6.51276e-05, gnorm=0.578, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=46592
2022-09-30 21:27:46 - progress_bar.py[line:274] - INFO: epoch 002:   1492 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.9, wpb=102, bsz=40, num_updates=17250, lr=6.5117e-05, gnorm=0.623, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46603
2022-09-30 21:27:58 - progress_bar.py[line:274] - INFO: epoch 002:   1502 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=17260, lr=6.51065e-05, gnorm=0.584, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=46614
2022-09-30 21:28:09 - progress_bar.py[line:274] - INFO: epoch 002:   1512 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.89, wpb=101.8, bsz=40, num_updates=17270, lr=6.50959e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46626
2022-09-30 21:28:20 - progress_bar.py[line:274] - INFO: epoch 002:   1522 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=17280, lr=6.50853e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46637
2022-09-30 21:28:31 - progress_bar.py[line:274] - INFO: epoch 002:   1532 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.1, ups=0.91, wpb=101, bsz=40, num_updates=17290, lr=6.50748e-05, gnorm=0.543, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46648
2022-09-30 21:28:43 - progress_bar.py[line:274] - INFO: epoch 002:   1542 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.7, ups=0.87, wpb=100.1, bsz=40, num_updates=17300, lr=6.50642e-05, gnorm=0.611, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=46659
2022-09-30 21:28:54 - progress_bar.py[line:274] - INFO: epoch 002:   1552 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=101.8, bsz=40, num_updates=17310, lr=6.50537e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46671
2022-09-30 21:29:05 - progress_bar.py[line:274] - INFO: epoch 002:   1562 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.91, wpb=101.1, bsz=40, num_updates=17320, lr=6.50431e-05, gnorm=0.531, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=46682
2022-09-30 21:29:17 - progress_bar.py[line:274] - INFO: epoch 002:   1572 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=84.3, ups=0.82, wpb=102.9, bsz=40, num_updates=17330, lr=6.50325e-05, gnorm=0.49, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=46694
2022-09-30 21:29:29 - progress_bar.py[line:274] - INFO: epoch 002:   1582 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=83.4, ups=0.81, wpb=103, bsz=40, num_updates=17340, lr=6.5022e-05, gnorm=0.598, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=46706
2022-09-30 21:29:41 - progress_bar.py[line:274] - INFO: epoch 002:   1592 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.6, ups=0.87, wpb=100.2, bsz=40, num_updates=17350, lr=6.50114e-05, gnorm=0.609, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46718
2022-09-30 21:29:52 - progress_bar.py[line:274] - INFO: epoch 002:   1602 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.88, wpb=102.5, bsz=40, num_updates=17360, lr=6.50009e-05, gnorm=0.543, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46729
2022-09-30 21:30:04 - progress_bar.py[line:274] - INFO: epoch 002:   1612 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.5, ups=0.87, wpb=100.1, bsz=40, num_updates=17370, lr=6.49903e-05, gnorm=0.645, clip=10, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46740
2022-09-30 21:30:15 - progress_bar.py[line:274] - INFO: epoch 002:   1622 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.6, ups=0.92, wpb=102.9, bsz=40, num_updates=17380, lr=6.49797e-05, gnorm=0.596, clip=0, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46751
2022-09-30 21:30:25 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 21:30:27 - progress_bar.py[line:274] - INFO: epoch 002:   1633 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.1, ups=0.84, wpb=101.9, bsz=40, num_updates=17390, lr=6.49692e-05, gnorm=0.6, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=46763
2022-09-30 21:30:38 - progress_bar.py[line:274] - INFO: epoch 002:   1643 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.88, wpb=102.3, bsz=40, num_updates=17400, lr=6.49586e-05, gnorm=0.474, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=46775
2022-09-30 21:30:49 - progress_bar.py[line:274] - INFO: epoch 002:   1653 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.89, wpb=99.9, bsz=40, num_updates=17410, lr=6.49481e-05, gnorm=0.638, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=46786
2022-09-30 21:31:01 - progress_bar.py[line:274] - INFO: epoch 002:   1663 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88, ups=0.87, wpb=101.3, bsz=40, num_updates=17420, lr=6.49375e-05, gnorm=0.607, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=46797
2022-09-30 21:31:12 - progress_bar.py[line:274] - INFO: epoch 002:   1673 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.4, ups=0.93, wpb=102, bsz=40, num_updates=17430, lr=6.49269e-05, gnorm=0.6, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46808
2022-09-30 21:31:23 - progress_bar.py[line:274] - INFO: epoch 002:   1683 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.89, wpb=102.7, bsz=40, num_updates=17440, lr=6.49164e-05, gnorm=0.569, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46819
2022-09-30 21:31:34 - progress_bar.py[line:274] - INFO: epoch 002:   1693 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.1, ups=0.91, wpb=101.7, bsz=40, num_updates=17450, lr=6.49058e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46831
2022-09-30 21:31:45 - progress_bar.py[line:274] - INFO: epoch 002:   1703 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90, ups=0.89, wpb=101.4, bsz=40, num_updates=17460, lr=6.48953e-05, gnorm=0.667, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46842
2022-09-30 21:31:56 - progress_bar.py[line:274] - INFO: epoch 002:   1713 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.1, ups=0.88, wpb=101.6, bsz=40, num_updates=17470, lr=6.48847e-05, gnorm=0.552, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46853
2022-09-30 21:32:08 - progress_bar.py[line:274] - INFO: epoch 002:   1723 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.88, wpb=101, bsz=40, num_updates=17480, lr=6.48741e-05, gnorm=0.627, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46865
2022-09-30 21:32:19 - progress_bar.py[line:274] - INFO: epoch 002:   1733 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.87, wpb=103.9, bsz=40, num_updates=17490, lr=6.48636e-05, gnorm=0.548, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46876
2022-09-30 21:32:31 - progress_bar.py[line:274] - INFO: epoch 002:   1743 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=82.6, ups=0.82, wpb=100.4, bsz=40, num_updates=17500, lr=6.4853e-05, gnorm=0.597, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=46888
2022-09-30 21:32:44 - progress_bar.py[line:274] - INFO: epoch 002:   1753 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=81.9, ups=0.8, wpb=102.7, bsz=40, num_updates=17510, lr=6.48425e-05, gnorm=0.647, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=46901
2022-09-30 21:32:56 - progress_bar.py[line:274] - INFO: epoch 002:   1763 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=83.9, ups=0.83, wpb=101.2, bsz=40, num_updates=17520, lr=6.48319e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=46913
2022-09-30 21:33:07 - progress_bar.py[line:274] - INFO: epoch 002:   1773 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.92, wpb=99.3, bsz=40, num_updates=17530, lr=6.48213e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46924
2022-09-30 21:33:18 - progress_bar.py[line:274] - INFO: epoch 002:   1783 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=17540, lr=6.48108e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46935
2022-09-30 21:33:29 - progress_bar.py[line:274] - INFO: epoch 002:   1793 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92, ups=0.91, wpb=100.8, bsz=40, num_updates=17550, lr=6.48002e-05, gnorm=0.638, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46946
2022-09-30 21:33:40 - progress_bar.py[line:274] - INFO: epoch 002:   1803 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92, ups=0.92, wpb=100.5, bsz=40, num_updates=17560, lr=6.47897e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46957
2022-09-30 21:33:51 - progress_bar.py[line:274] - INFO: epoch 002:   1813 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=17570, lr=6.47791e-05, gnorm=0.67, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46968
2022-09-30 21:34:02 - progress_bar.py[line:274] - INFO: epoch 002:   1823 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.4, ups=0.91, wpb=101.3, bsz=40, num_updates=17580, lr=6.47685e-05, gnorm=0.605, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=46979
2022-09-30 21:34:14 - progress_bar.py[line:274] - INFO: epoch 002:   1833 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=17590, lr=6.4758e-05, gnorm=0.63, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46990
2022-09-30 21:34:25 - progress_bar.py[line:274] - INFO: epoch 002:   1843 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.4, ups=0.88, wpb=101.9, bsz=40, num_updates=17600, lr=6.47474e-05, gnorm=0.57, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=47002
2022-09-30 21:34:36 - progress_bar.py[line:274] - INFO: epoch 002:   1853 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.89, wpb=101.2, bsz=40, num_updates=17610, lr=6.47369e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=47013
2022-09-30 21:34:47 - progress_bar.py[line:274] - INFO: epoch 002:   1863 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.9, ups=0.92, wpb=101.5, bsz=40, num_updates=17620, lr=6.47263e-05, gnorm=0.508, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=47024
2022-09-30 21:34:58 - progress_bar.py[line:274] - INFO: epoch 002:   1873 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.9, wpb=102, bsz=40, num_updates=17630, lr=6.47157e-05, gnorm=0.524, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47035
2022-09-30 21:35:09 - progress_bar.py[line:274] - INFO: epoch 002:   1883 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.9, ups=0.89, wpb=99, bsz=40, num_updates=17640, lr=6.47052e-05, gnorm=0.658, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=47046
2022-09-30 21:35:21 - progress_bar.py[line:274] - INFO: epoch 002:   1893 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.9, wpb=100.3, bsz=40, num_updates=17650, lr=6.46946e-05, gnorm=0.567, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47057
2022-09-30 21:35:32 - progress_bar.py[line:274] - INFO: epoch 002:   1903 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=98.5, nsentences=40, sample_size=98.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.5, ups=0.88, wpb=98.5, bsz=40, num_updates=17660, lr=6.46841e-05, gnorm=0.646, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=47069
2022-09-30 21:35:43 - progress_bar.py[line:274] - INFO: epoch 002:   1913 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.91, wpb=101.3, bsz=40, num_updates=17670, lr=6.46735e-05, gnorm=0.565, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47080
2022-09-30 21:35:54 - progress_bar.py[line:274] - INFO: epoch 002:   1923 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.2, ups=0.9, wpb=103.6, bsz=40, num_updates=17680, lr=6.46629e-05, gnorm=0.566, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=47091
2022-09-30 21:36:05 - progress_bar.py[line:274] - INFO: epoch 002:   1933 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.92, wpb=101.2, bsz=40, num_updates=17690, lr=6.46524e-05, gnorm=0.644, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47102
2022-09-30 21:36:16 - progress_bar.py[line:274] - INFO: epoch 002:   1943 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.7, ups=0.9, wpb=100.7, bsz=40, num_updates=17700, lr=6.46418e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=47113
2022-09-30 21:36:27 - progress_bar.py[line:274] - INFO: epoch 002:   1953 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.89, wpb=100.9, bsz=40, num_updates=17710, lr=6.46313e-05, gnorm=0.611, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47124
2022-09-30 21:36:39 - progress_bar.py[line:274] - INFO: epoch 002:   1963 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.3, ups=0.86, wpb=101.1, bsz=40, num_updates=17720, lr=6.46207e-05, gnorm=0.598, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=47136
2022-09-30 21:36:50 - progress_bar.py[line:274] - INFO: epoch 002:   1973 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.8, ups=0.89, wpb=101.9, bsz=40, num_updates=17730, lr=6.46101e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47147
2022-09-30 21:37:01 - progress_bar.py[line:274] - INFO: epoch 002:   1983 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.9, wpb=99.8, bsz=40, num_updates=17740, lr=6.45996e-05, gnorm=0.632, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=47158
2022-09-30 21:37:13 - progress_bar.py[line:274] - INFO: epoch 002:   1993 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.6, ups=0.87, wpb=100.6, bsz=40, num_updates=17750, lr=6.4589e-05, gnorm=0.627, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47169
2022-09-30 21:37:24 - progress_bar.py[line:274] - INFO: epoch 002:   2003 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=17760, lr=6.45785e-05, gnorm=0.584, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=47181
2022-09-30 21:37:35 - progress_bar.py[line:274] - INFO: epoch 002:   2013 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.9, wpb=102, bsz=40, num_updates=17770, lr=6.45679e-05, gnorm=0.608, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=47192
2022-09-30 21:37:47 - progress_bar.py[line:274] - INFO: epoch 002:   2023 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=17780, lr=6.45573e-05, gnorm=0.517, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47203
2022-09-30 21:37:58 - progress_bar.py[line:274] - INFO: epoch 002:   2033 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=100.4, bsz=40, num_updates=17790, lr=6.45468e-05, gnorm=0.63, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47215
2022-09-30 21:38:09 - progress_bar.py[line:274] - INFO: epoch 002:   2043 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.5, ups=0.9, wpb=101.6, bsz=40, num_updates=17800, lr=6.45362e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47226
2022-09-30 21:38:20 - progress_bar.py[line:274] - INFO: epoch 002:   2053 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.89, wpb=101.1, bsz=40, num_updates=17810, lr=6.45257e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47237
2022-09-30 21:38:31 - progress_bar.py[line:274] - INFO: epoch 002:   2063 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90, ups=0.9, wpb=100, bsz=40, num_updates=17820, lr=6.45151e-05, gnorm=0.536, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47248
2022-09-30 21:38:43 - progress_bar.py[line:274] - INFO: epoch 002:   2073 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.6, ups=0.87, wpb=100.6, bsz=40, num_updates=17830, lr=6.45045e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=47259
2022-09-30 21:38:54 - progress_bar.py[line:274] - INFO: epoch 002:   2083 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.89, wpb=102.9, bsz=40, num_updates=17840, lr=6.4494e-05, gnorm=0.535, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=47271
2022-09-30 21:39:05 - progress_bar.py[line:274] - INFO: epoch 002:   2093 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88, ups=0.87, wpb=100.7, bsz=40, num_updates=17850, lr=6.44834e-05, gnorm=0.594, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47282
2022-09-30 21:39:17 - progress_bar.py[line:274] - INFO: epoch 002:   2103 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.87, wpb=102.3, bsz=40, num_updates=17860, lr=6.44729e-05, gnorm=0.584, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47294
2022-09-30 21:39:28 - progress_bar.py[line:274] - INFO: epoch 002:   2113 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.1, ups=0.88, wpb=101.8, bsz=40, num_updates=17870, lr=6.44623e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47305
2022-09-30 21:39:39 - progress_bar.py[line:274] - INFO: epoch 002:   2123 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.7, ups=0.91, wpb=102.7, bsz=40, num_updates=17880, lr=6.44517e-05, gnorm=0.474, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47316
2022-09-30 21:39:51 - progress_bar.py[line:274] - INFO: epoch 002:   2133 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.88, wpb=100.8, bsz=40, num_updates=17890, lr=6.44412e-05, gnorm=0.597, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=47327
2022-09-30 21:40:02 - progress_bar.py[line:274] - INFO: epoch 002:   2143 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=17900, lr=6.44306e-05, gnorm=0.628, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47338
2022-09-30 21:40:10 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 21:40:14 - progress_bar.py[line:274] - INFO: epoch 002:   2154 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=82.6, ups=0.82, wpb=100.6, bsz=40, num_updates=17910, lr=6.44201e-05, gnorm=0.612, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=47351
2022-09-30 21:40:25 - progress_bar.py[line:274] - INFO: epoch 002:   2164 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.9, wpb=100.7, bsz=40, num_updates=17920, lr=6.44095e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47362
2022-09-30 21:40:36 - progress_bar.py[line:274] - INFO: epoch 002:   2174 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.89, wpb=102.2, bsz=40, num_updates=17930, lr=6.43989e-05, gnorm=0.627, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47373
2022-09-30 21:40:47 - progress_bar.py[line:274] - INFO: epoch 002:   2184 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.89, wpb=100.8, bsz=40, num_updates=17940, lr=6.43884e-05, gnorm=0.644, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47384
2022-09-30 21:40:58 - progress_bar.py[line:274] - INFO: epoch 002:   2194 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.91, wpb=100.2, bsz=40, num_updates=17950, lr=6.43778e-05, gnorm=0.587, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47395
2022-09-30 21:41:10 - progress_bar.py[line:274] - INFO: epoch 002:   2204 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.9, wpb=102.3, bsz=40, num_updates=17960, lr=6.43673e-05, gnorm=0.585, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47406
2022-09-30 21:41:21 - progress_bar.py[line:274] - INFO: epoch 002:   2214 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.91, wpb=101.2, bsz=40, num_updates=17970, lr=6.43567e-05, gnorm=0.569, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47417
2022-09-30 21:41:31 - progress_bar.py[line:274] - INFO: epoch 002:   2224 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.1, ups=0.91, wpb=101, bsz=40, num_updates=17980, lr=6.43462e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47428
2022-09-30 21:41:43 - progress_bar.py[line:274] - INFO: epoch 002:   2234 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88, ups=0.88, wpb=99.9, bsz=40, num_updates=17990, lr=6.43356e-05, gnorm=0.585, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47440
2022-09-30 21:41:54 - progress_bar.py[line:274] - INFO: epoch 002:   2244 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.6, ups=0.88, wpb=100.2, bsz=40, num_updates=18000, lr=6.4325e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47451
2022-09-30 21:41:54 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-30 21:41:56 - train.py[line:549] - INFO: 0 / 14103
2022-09-30 21:41:56 - train.py[line:551] - INFO: load:0.86 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-30 21:41:59 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.87 GiB (GPU 0; 39.59 GiB total capacity; 12.96 GiB already allocated; 1.46 GiB free; 35.65 GiB reserved in total by PyTorch)
2022-09-30 21:41:59 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 31        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13276 MB |   18117 MB |    6406 TB |    6406 TB |
|       from large pool |   13131 MB |   17972 MB |    6403 TB |    6403 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13276 MB |   18117 MB |    6406 TB |    6406 TB |
|       from large pool |   13131 MB |   17972 MB |    6403 TB |    6403 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36506 MB |   36618 MB |  370908 MB |  334402 MB |
|       from large pool |   36360 MB |   36360 MB |  370328 MB |  333968 MB |
|       from small pool |     146 MB |     258 MB |     580 MB |     434 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23229 MB |   26273 MB |    6063 TB |    6063 TB |
|       from large pool |   23228 MB |   26271 MB |    6060 TB |    6060 TB |
|       from small pool |       1 MB |       1 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3670    |    3694    |  325384 K  |  325380 K  |
|       from large pool |     564    |     585    |  100755 K  |  100754 K  |
|       from small pool |    3106    |    3114    |  224629 K  |  224626 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3670    |    3694    |  325384 K  |  325380 K  |
|       from large pool |     564    |     585    |  100755 K  |  100754 K  |
|       from small pool |    3106    |    3114    |  224629 K  |  224626 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     128    |     184    |     768    |     640    |
|       from large pool |      55    |      55    |     478    |     423    |
|       from small pool |      73    |     129    |     290    |     217    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      97    |     106    |  239050 K  |  239049 K  |
|       from large pool |      54    |      60    |   49115 K  |   49115 K  |
|       from small pool |      43    |      55    |  189934 K  |  189934 K  |
|===========================================================================|

2022-09-30 21:41:59 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-30 21:41:59 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-30 21:45:10 - train.py[line:549] - INFO: 200 / 14103
2022-09-30 21:45:10 - train.py[line:551] - INFO: load:0.89 valid_run:194.84 task_valid:184.71 collect_output:6.73
2022-09-30 21:48:22 - train.py[line:549] - INFO: 400 / 14103
2022-09-30 21:48:22 - train.py[line:551] - INFO: load:0.92 valid_run:386.25 task_valid:369.42 collect_output:12.09
2022-09-30 21:51:32 - train.py[line:549] - INFO: 600 / 14103
2022-09-30 21:51:32 - train.py[line:551] - INFO: load:0.95 valid_run:576.20 task_valid:552.83 collect_output:17.28
2022-09-30 21:54:43 - train.py[line:549] - INFO: 800 / 14103
2022-09-30 21:54:43 - train.py[line:551] - INFO: load:0.99 valid_run:766.97 task_valid:738.61 collect_output:20.95
2022-09-30 21:57:53 - train.py[line:549] - INFO: 1000 / 14103
2022-09-30 21:57:53 - train.py[line:551] - INFO: load:1.02 valid_run:956.68 task_valid:923.57 collect_output:24.40
2022-09-30 22:01:06 - train.py[line:549] - INFO: 1200 / 14103
2022-09-30 22:01:06 - train.py[line:551] - INFO: load:1.06 valid_run:1149.63 task_valid:1110.54 collect_output:29.05
2022-09-30 22:04:25 - train.py[line:549] - INFO: 1400 / 14103
2022-09-30 22:04:25 - train.py[line:551] - INFO: load:1.09 valid_run:1349.16 task_valid:1303.06 collect_output:34.58
2022-09-30 22:07:38 - train.py[line:549] - INFO: 1600 / 14103
2022-09-30 22:07:38 - train.py[line:551] - INFO: load:1.12 valid_run:1542.12 task_valid:1492.20 collect_output:36.93
2022-09-30 22:08:39 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.26 GiB (GPU 1; 39.59 GiB total capacity; 13.62 GiB already allocated; 972.19 MiB free; 36.16 GiB reserved in total by PyTorch)
2022-09-30 22:08:39 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-30 22:08:39 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 27        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13950 MB |   19337 MB |    6629 TB |    6629 TB |
|       from large pool |   13806 MB |   19192 MB |    6626 TB |    6626 TB |
|       from small pool |     144 MB |     159 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13950 MB |   19337 MB |    6629 TB |    6629 TB |
|       from large pool |   13806 MB |   19192 MB |    6626 TB |    6626 TB |
|       from small pool |     144 MB |     159 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   37024 MB |   37174 MB |  282234 MB |  245210 MB |
|       from large pool |   36878 MB |   36926 MB |  281630 MB |  244752 MB |
|       from small pool |     146 MB |     248 MB |     604 MB |     458 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23073 MB |   25618 MB |    6410 TB |    6410 TB |
|       from large pool |   23071 MB |   25616 MB |    6407 TB |    6407 TB |
|       from small pool |       1 MB |       6 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3671    |    3695    |  338892 K  |  338889 K  |
|       from large pool |     564    |     585    |  103831 K  |  103830 K  |
|       from small pool |    3107    |    3119    |  235061 K  |  235058 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3671    |    3695    |  338892 K  |  338889 K  |
|       from large pool |     564    |     585    |  103831 K  |  103830 K  |
|       from small pool |    3107    |    3119    |  235061 K  |  235058 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     182    |     239    |     743    |     561    |
|       from large pool |     109    |     115    |     441    |     332    |
|       from small pool |      73    |     124    |     302    |     229    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     112    |     122    |  240995 K  |  240995 K  |
|       from large pool |      83    |      86    |   42401 K  |   42401 K  |
|       from small pool |      29    |      40    |  198593 K  |  198593 K  |
|===========================================================================|

2022-09-30 22:08:39 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-30 22:10:53 - train.py[line:549] - INFO: 1800 / 14103
2022-09-30 22:10:53 - train.py[line:551] - INFO: load:1.16 valid_run:1737.14 task_valid:1679.02 collect_output:43.71
2022-09-30 22:14:03 - train.py[line:549] - INFO: 2000 / 14103
2022-09-30 22:14:03 - train.py[line:551] - INFO: load:1.19 valid_run:1926.49 task_valid:1865.05 collect_output:45.66
2022-09-30 22:17:16 - train.py[line:549] - INFO: 2200 / 14103
2022-09-30 22:17:16 - train.py[line:551] - INFO: load:1.22 valid_run:2119.99 task_valid:2051.87 collect_output:50.97
2022-09-30 22:20:28 - train.py[line:549] - INFO: 2400 / 14103
2022-09-30 22:20:28 - train.py[line:551] - INFO: load:1.26 valid_run:2311.93 task_valid:2237.38 collect_output:55.95
2022-09-30 22:23:45 - train.py[line:549] - INFO: 2600 / 14103
2022-09-30 22:23:45 - train.py[line:551] - INFO: load:1.29 valid_run:2508.13 task_valid:2429.05 collect_output:59.05
2022-09-30 22:26:55 - train.py[line:549] - INFO: 2800 / 14103
2022-09-30 22:26:55 - train.py[line:551] - INFO: load:1.33 valid_run:2698.29 task_valid:2613.61 collect_output:63.32
2022-09-30 22:30:10 - train.py[line:549] - INFO: 3000 / 14103
2022-09-30 22:30:10 - train.py[line:551] - INFO: load:1.36 valid_run:2893.47 task_valid:2800.90 collect_output:69.96
2022-09-30 22:36:36 - train.py[line:549] - INFO: 3200 / 14103
2022-09-30 22:36:36 - train.py[line:551] - INFO: load:11.10 valid_run:3269.17 task_valid:3142.37 collect_output:95.59
2022-09-30 22:39:50 - train.py[line:549] - INFO: 3400 / 14103
2022-09-30 22:39:50 - train.py[line:551] - INFO: load:11.12 valid_run:3463.13 task_valid:3327.11 collect_output:103.74
2022-09-30 22:43:05 - train.py[line:549] - INFO: 3600 / 14103
2022-09-30 22:43:05 - train.py[line:551] - INFO: load:11.14 valid_run:3658.40 task_valid:3514.34 collect_output:110.69
2022-09-30 22:46:15 - train.py[line:549] - INFO: 3800 / 14103
2022-09-30 22:46:15 - train.py[line:551] - INFO: load:11.17 valid_run:3847.93 task_valid:3696.46 collect_output:117.04
2022-09-30 22:49:22 - train.py[line:549] - INFO: 4000 / 14103
2022-09-30 22:49:22 - train.py[line:551] - INFO: load:11.19 valid_run:4035.54 task_valid:3879.53 collect_output:120.49
2022-09-30 22:52:37 - train.py[line:549] - INFO: 4200 / 14103
2022-09-30 22:52:37 - train.py[line:551] - INFO: load:11.22 valid_run:4229.97 task_valid:4071.69 collect_output:121.65
2022-09-30 22:55:44 - train.py[line:549] - INFO: 4400 / 14103
2022-09-30 22:55:44 - train.py[line:551] - INFO: load:11.24 valid_run:4417.07 task_valid:4251.78 collect_output:127.58
2022-09-30 22:58:55 - train.py[line:549] - INFO: 4600 / 14103
2022-09-30 22:58:55 - train.py[line:551] - INFO: load:11.27 valid_run:4608.12 task_valid:4436.43 collect_output:132.90
2022-09-30 23:02:05 - train.py[line:549] - INFO: 4800 / 14103
2022-09-30 23:02:05 - train.py[line:551] - INFO: load:11.29 valid_run:4798.33 task_valid:4621.88 collect_output:136.54
2022-09-30 23:05:14 - train.py[line:549] - INFO: 5000 / 14103
2022-09-30 23:05:14 - train.py[line:551] - INFO: load:11.31 valid_run:4986.91 task_valid:4805.80 collect_output:140.14
2022-09-30 23:08:25 - train.py[line:549] - INFO: 5200 / 14103
2022-09-30 23:08:25 - train.py[line:551] - INFO: load:11.34 valid_run:5177.47 task_valid:4990.43 collect_output:145.00
2022-09-30 23:11:36 - train.py[line:549] - INFO: 5400 / 14103
2022-09-30 23:11:36 - train.py[line:551] - INFO: load:11.37 valid_run:5368.81 task_valid:5178.65 collect_output:147.09
2022-09-30 23:14:48 - train.py[line:549] - INFO: 5600 / 14103
2022-09-30 23:14:48 - train.py[line:551] - INFO: load:11.39 valid_run:5561.27 task_valid:5367.03 collect_output:150.01
2022-09-30 23:18:02 - train.py[line:549] - INFO: 5800 / 14103
2022-09-30 23:18:02 - train.py[line:551] - INFO: load:11.42 valid_run:5755.22 task_valid:5554.16 collect_output:155.74
2022-09-30 23:21:10 - train.py[line:549] - INFO: 6000 / 14103
2022-09-30 23:21:10 - train.py[line:551] - INFO: load:11.44 valid_run:5943.04 task_valid:5734.98 collect_output:161.57
2022-09-30 23:24:24 - train.py[line:549] - INFO: 6200 / 14103
2022-09-30 23:24:24 - train.py[line:551] - INFO: load:11.46 valid_run:6136.22 task_valid:5922.40 collect_output:166.20
2022-09-30 23:27:33 - train.py[line:549] - INFO: 6400 / 14103
2022-09-30 23:27:33 - train.py[line:551] - INFO: load:11.49 valid_run:6325.99 task_valid:6107.83 collect_output:169.35
2022-09-30 23:30:42 - train.py[line:549] - INFO: 6600 / 14103
2022-09-30 23:30:42 - train.py[line:551] - INFO: load:11.52 valid_run:6514.89 task_valid:6289.28 collect_output:175.63
2022-09-30 23:33:57 - train.py[line:549] - INFO: 6800 / 14103
2022-09-30 23:33:57 - train.py[line:551] - INFO: load:11.54 valid_run:6709.04 task_valid:6474.20 collect_output:183.61
2022-09-30 23:37:11 - train.py[line:549] - INFO: 7000 / 14103
2022-09-30 23:37:11 - train.py[line:551] - INFO: load:11.58 valid_run:6902.92 task_valid:6664.05 collect_output:186.43
2022-09-30 23:40:27 - train.py[line:549] - INFO: 7200 / 14103
2022-09-30 23:40:27 - train.py[line:551] - INFO: load:11.63 valid_run:7099.39 task_valid:6855.37 collect_output:190.36
2022-09-30 23:43:36 - train.py[line:549] - INFO: 7400 / 14103
2022-09-30 23:43:36 - train.py[line:551] - INFO: load:11.65 valid_run:7288.48 task_valid:7036.33 collect_output:197.47
2022-09-30 23:46:44 - train.py[line:549] - INFO: 7600 / 14103
2022-09-30 23:46:44 - train.py[line:551] - INFO: load:11.68 valid_run:7475.99 task_valid:7216.23 collect_output:204.00
2022-09-30 23:49:59 - train.py[line:549] - INFO: 7800 / 14103
2022-09-30 23:49:59 - train.py[line:551] - INFO: load:11.72 valid_run:7671.46 task_valid:7404.17 collect_output:210.43
2022-09-30 23:53:08 - train.py[line:549] - INFO: 8000 / 14103
2022-09-30 23:53:08 - train.py[line:551] - INFO: load:11.75 valid_run:7859.69 task_valid:7582.77 collect_output:218.99
2022-09-30 23:56:17 - train.py[line:549] - INFO: 8200 / 14103
2022-09-30 23:56:17 - train.py[line:551] - INFO: load:11.77 valid_run:8049.44 task_valid:7766.51 collect_output:223.90
2022-09-30 23:59:25 - train.py[line:549] - INFO: 8400 / 14103
2022-09-30 23:59:25 - train.py[line:551] - INFO: load:11.79 valid_run:8236.75 task_valid:7948.39 collect_output:228.27
2022-10-01 00:02:35 - train.py[line:549] - INFO: 8600 / 14103
2022-10-01 00:02:35 - train.py[line:551] - INFO: load:11.82 valid_run:8426.47 task_valid:8132.32 collect_output:233.01
2022-10-01 00:05:42 - train.py[line:549] - INFO: 8800 / 14103
2022-10-01 00:05:42 - train.py[line:551] - INFO: load:11.84 valid_run:8613.92 task_valid:8316.31 collect_output:235.43
2022-10-01 00:08:52 - train.py[line:549] - INFO: 9000 / 14103
2022-10-01 00:08:52 - train.py[line:551] - INFO: load:11.87 valid_run:8803.45 task_valid:8498.99 collect_output:241.23
2022-10-01 00:12:05 - train.py[line:549] - INFO: 9200 / 14103
2022-10-01 00:12:05 - train.py[line:551] - INFO: load:11.89 valid_run:8996.93 task_valid:8681.60 collect_output:251.07
2022-10-01 00:15:18 - train.py[line:549] - INFO: 9400 / 14103
2022-10-01 00:15:18 - train.py[line:551] - INFO: load:11.92 valid_run:9189.17 task_valid:8867.95 collect_output:255.91
2022-10-01 00:18:27 - train.py[line:549] - INFO: 9600 / 14103
2022-10-01 00:18:27 - train.py[line:551] - INFO: load:11.94 valid_run:9378.71 task_valid:9051.23 collect_output:261.09
2022-10-01 00:21:37 - train.py[line:549] - INFO: 9800 / 14103
2022-10-01 00:21:37 - train.py[line:551] - INFO: load:11.97 valid_run:9568.59 task_valid:9238.68 collect_output:262.48
2022-10-01 00:24:48 - train.py[line:549] - INFO: 10000 / 14103
2022-10-01 00:24:48 - train.py[line:551] - INFO: load:11.99 valid_run:9759.84 task_valid:9426.60 collect_output:264.74
2022-10-01 00:28:00 - train.py[line:549] - INFO: 10200 / 14103
2022-10-01 00:28:00 - train.py[line:551] - INFO: load:12.01 valid_run:9951.49 task_valid:9611.48 collect_output:270.32
2022-10-01 00:32:09 - train.py[line:549] - INFO: 10400 / 14103
2022-10-01 00:32:09 - train.py[line:551] - INFO: load:12.04 valid_run:10200.03 task_valid:9835.59 collect_output:281.02
2022-10-01 00:35:21 - train.py[line:549] - INFO: 10600 / 14103
2022-10-01 00:35:21 - train.py[line:551] - INFO: load:12.07 valid_run:10391.75 task_valid:10017.54 collect_output:289.68
2022-10-01 00:38:32 - train.py[line:549] - INFO: 10800 / 14103
2022-10-01 00:38:32 - train.py[line:551] - INFO: load:12.10 valid_run:10583.27 task_valid:10201.38 collect_output:296.22
2022-10-01 00:41:46 - train.py[line:549] - INFO: 11000 / 14103
2022-10-01 00:41:46 - train.py[line:551] - INFO: load:12.12 valid_run:10776.85 task_valid:10387.40 collect_output:302.59
2022-10-01 00:44:58 - train.py[line:549] - INFO: 11200 / 14103
2022-10-01 00:44:58 - train.py[line:551] - INFO: load:12.15 valid_run:10969.38 task_valid:10572.94 collect_output:308.42
2022-10-01 00:48:13 - train.py[line:549] - INFO: 11400 / 14103
2022-10-01 00:48:13 - train.py[line:551] - INFO: load:12.17 valid_run:11164.14 task_valid:10764.36 collect_output:310.60
2022-10-01 00:51:22 - train.py[line:549] - INFO: 11600 / 14103
2022-10-01 00:51:22 - train.py[line:551] - INFO: load:12.20 valid_run:11352.89 task_valid:10948.93 collect_output:313.68
2022-10-01 00:54:32 - train.py[line:549] - INFO: 11800 / 14103
2022-10-01 00:54:32 - train.py[line:551] - INFO: load:12.22 valid_run:11543.21 task_valid:11134.79 collect_output:317.05
2022-10-01 00:57:41 - train.py[line:549] - INFO: 12000 / 14103
2022-10-01 00:57:41 - train.py[line:551] - INFO: load:12.24 valid_run:11732.00 task_valid:11317.78 collect_output:321.78
2022-10-01 01:00:51 - train.py[line:549] - INFO: 12200 / 14103
2022-10-01 01:00:51 - train.py[line:551] - INFO: load:12.27 valid_run:11921.66 task_valid:11502.45 collect_output:325.69
2022-10-01 01:04:01 - train.py[line:549] - INFO: 12400 / 14103
2022-10-01 01:04:01 - train.py[line:551] - INFO: load:12.29 valid_run:12111.89 task_valid:11686.90 collect_output:330.41
2022-10-01 01:07:11 - train.py[line:549] - INFO: 12600 / 14103
2022-10-01 01:07:11 - train.py[line:551] - INFO: load:12.32 valid_run:12301.14 task_valid:11869.69 collect_output:335.77
2022-10-01 01:10:17 - train.py[line:549] - INFO: 12800 / 14103
2022-10-01 01:10:17 - train.py[line:551] - INFO: load:12.34 valid_run:12487.25 task_valid:12051.12 collect_output:339.41
2022-10-01 01:13:26 - train.py[line:549] - INFO: 13000 / 14103
2022-10-01 01:13:26 - train.py[line:551] - INFO: load:12.36 valid_run:12676.60 task_valid:12234.37 collect_output:344.42
2022-10-01 01:16:34 - train.py[line:549] - INFO: 13200 / 14103
2022-10-01 01:16:34 - train.py[line:551] - INFO: load:12.39 valid_run:12864.64 task_valid:12414.80 collect_output:350.96
2022-10-01 01:19:47 - train.py[line:549] - INFO: 13400 / 14103
2022-10-01 01:19:47 - train.py[line:551] - INFO: load:12.42 valid_run:13057.03 task_valid:12596.88 collect_output:360.19
2022-10-01 01:22:57 - train.py[line:549] - INFO: 13600 / 14103
2022-10-01 01:22:57 - train.py[line:551] - INFO: load:12.44 valid_run:13246.92 task_valid:12777.74 collect_output:368.13
2022-10-01 01:26:09 - train.py[line:549] - INFO: 13800 / 14103
2022-10-01 01:26:09 - train.py[line:551] - INFO: load:12.47 valid_run:13439.71 task_valid:12964.58 collect_output:372.97
2022-10-01 01:29:20 - train.py[line:549] - INFO: 14000 / 14103
2022-10-01 01:29:20 - train.py[line:551] - INFO: load:12.49 valid_run:13630.39 task_valid:13149.02 collect_output:378.16
2022-10-01 01:30:56 - train.py[line:572] - INFO: scores:torch.Size([282060]) preds:torch.Size([282060]) sample_ids:torch.Size([282060])

====================================================================================================
SGG eval:     R @ 50: 0.6430;     R @ 100: 0.6625;     R @ 500: 0.6685;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1784;    mR @ 100: 0.2133;    mR @ 500: 0.2195;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0647) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1624) (attached to:0.0000) (behind:0.4033) (belonging to:0.0000) (between:0.0000) (carrying:0.7083) (covered in:0.0000) (covering:0.0000) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0577) (has:0.7730) (holding:0.3140) (in:0.3460) (in front of:0.1394) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5925) (of:0.4939) (on:0.8839) (on back of:0.0000) (over:0.1111) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.5833) (says:0.0000) (sitting on:0.3552) (standing on:0.0385) (to:0.0000) (under:0.3426) (using:1.0000) (walking in:0.0000) (walking on:0.5845) (watching:0.3333) (wearing:0.9879) (wears:0.0000) (with:0.1379) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6430;     R @ 100: 0.6625;     R @ 500: 0.6685;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1784;    mR @ 100: 0.2133;    mR @ 500: 0.2195;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0647) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1624) (attached to:0.0000) (behind:0.4033) (belonging to:0.0000) (between:0.0000) (carrying:0.7083) (covered in:0.0000) (covering:0.0000) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0577) (has:0.7730) (holding:0.3140) (in:0.3460) (in front of:0.1394) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5925) (of:0.4939) (on:0.8839) (on back of:0.0000) (over:0.1111) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.5833) (says:0.0000) (sitting on:0.3552) (standing on:0.0385) (to:0.0000) (under:0.3426) (using:1.0000) (walking in:0.0000) (walking on:0.5845) (watching:0.3333) (wearing:0.9879) (wears:0.0000) (with:0.1379) 
--------------------------------------------------------
====================================================================================================

2022-10-01 01:31:17 - train.py[line:486] - INFO: 0.6624675804675889
2022-10-01 01:31:17 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.322 | loss_v1 0 | loss_v2 0 | nll_loss 0.131 | ntokens 59.526 | nsentences 20 | sample_size 59.526 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.662468 | ppl 1.1 | vqa_score 0.8881 | wps 61 | wpb 59.5 | bsz 20 | num_updates 18000 | best_R@100 0.662468
2022-10-01 01:31:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 18000 updates
2022-10-01 01:31:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480/checkpoint_2_18000.pt
2022-10-01 01:31:24 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480/checkpoint_2_18000.pt
2022-10-01 01:31:44 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480/checkpoint_2_18000.pt (epoch 2 @ 18000 updates, score 0.6624675804675889) (writing took 26.844929724000394 seconds)
2022-10-01 01:31:56 - progress_bar.py[line:274] - INFO: epoch 002:   2254 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=0.1, ups=0, wpb=100.5, bsz=40, num_updates=18010, lr=6.43145e-05, gnorm=0.592, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=61252
2022-10-01 01:32:07 - progress_bar.py[line:274] - INFO: epoch 002:   2264 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.4, ups=0.88, wpb=101.7, bsz=40, num_updates=18020, lr=6.43039e-05, gnorm=0.498, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61264
2022-10-01 01:32:18 - progress_bar.py[line:274] - INFO: epoch 002:   2274 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.2, ups=0.87, wpb=100.8, bsz=40, num_updates=18030, lr=6.42934e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61275
2022-10-01 01:32:30 - progress_bar.py[line:274] - INFO: epoch 002:   2284 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.1, ups=0.88, wpb=99.9, bsz=40, num_updates=18040, lr=6.42828e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61287
2022-10-01 01:32:41 - progress_bar.py[line:274] - INFO: epoch 002:   2294 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.89, wpb=102.4, bsz=40, num_updates=18050, lr=6.42722e-05, gnorm=0.532, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61298
2022-10-01 01:32:53 - progress_bar.py[line:274] - INFO: epoch 002:   2304 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.4, ups=0.91, wpb=98.8, bsz=40, num_updates=18060, lr=6.42617e-05, gnorm=0.641, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61309
2022-10-01 01:33:05 - progress_bar.py[line:274] - INFO: epoch 002:   2314 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=82.5, ups=0.82, wpb=100.1, bsz=40, num_updates=18070, lr=6.42511e-05, gnorm=0.635, clip=10, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=61321
2022-10-01 01:33:17 - progress_bar.py[line:274] - INFO: epoch 002:   2324 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=84.4, ups=0.84, wpb=100.5, bsz=40, num_updates=18080, lr=6.42406e-05, gnorm=0.541, clip=0, loss_scale=1024, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=61333
2022-10-01 01:33:28 - progress_bar.py[line:274] - INFO: epoch 002:   2334 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.88, wpb=101.8, bsz=40, num_updates=18090, lr=6.423e-05, gnorm=0.599, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61345
2022-10-01 01:33:39 - progress_bar.py[line:274] - INFO: epoch 002:   2344 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=18100, lr=6.42194e-05, gnorm=0.621, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61356
2022-10-01 01:33:51 - progress_bar.py[line:274] - INFO: epoch 002:   2354 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.88, wpb=100.3, bsz=40, num_updates=18110, lr=6.42089e-05, gnorm=0.617, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61367
2022-10-01 01:34:02 - progress_bar.py[line:274] - INFO: epoch 002:   2364 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.88, wpb=100.3, bsz=40, num_updates=18120, lr=6.41983e-05, gnorm=0.695, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61379
2022-10-01 01:34:13 - progress_bar.py[line:274] - INFO: epoch 002:   2374 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.7, ups=0.91, wpb=101.8, bsz=40, num_updates=18130, lr=6.41878e-05, gnorm=0.601, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61390
2022-10-01 01:34:24 - progress_bar.py[line:274] - INFO: epoch 002:   2384 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92, ups=0.91, wpb=101, bsz=40, num_updates=18140, lr=6.41772e-05, gnorm=0.556, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61401
2022-10-01 01:34:35 - progress_bar.py[line:274] - INFO: epoch 002:   2394 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.89, wpb=100.4, bsz=40, num_updates=18150, lr=6.41666e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61412
2022-10-01 01:34:47 - progress_bar.py[line:274] - INFO: epoch 002:   2404 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.89, wpb=101.5, bsz=40, num_updates=18160, lr=6.41561e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61423
2022-10-01 01:34:58 - progress_bar.py[line:274] - INFO: epoch 002:   2414 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.9, wpb=100, bsz=40, num_updates=18170, lr=6.41455e-05, gnorm=0.531, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61434
2022-10-01 01:35:09 - progress_bar.py[line:274] - INFO: epoch 002:   2424 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.7, ups=0.9, wpb=102.7, bsz=40, num_updates=18180, lr=6.4135e-05, gnorm=0.492, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61446
2022-10-01 01:35:20 - progress_bar.py[line:274] - INFO: epoch 002:   2434 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.2, ups=0.89, wpb=99.3, bsz=40, num_updates=18190, lr=6.41244e-05, gnorm=0.538, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61457
2022-10-01 01:35:31 - progress_bar.py[line:274] - INFO: epoch 002:   2444 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.89, wpb=103.6, bsz=40, num_updates=18200, lr=6.41138e-05, gnorm=0.61, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61468
2022-10-01 01:35:43 - progress_bar.py[line:274] - INFO: epoch 002:   2454 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.9, wpb=99.6, bsz=40, num_updates=18210, lr=6.41033e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61479
2022-10-01 01:35:54 - progress_bar.py[line:274] - INFO: epoch 002:   2464 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=18220, lr=6.40927e-05, gnorm=0.521, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61490
2022-10-01 01:36:05 - progress_bar.py[line:274] - INFO: epoch 002:   2474 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=100.9, bsz=40, num_updates=18230, lr=6.40822e-05, gnorm=0.623, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61501
2022-10-01 01:36:16 - progress_bar.py[line:274] - INFO: epoch 002:   2484 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.9, ups=0.91, wpb=102, bsz=40, num_updates=18240, lr=6.40716e-05, gnorm=0.62, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61512
2022-10-01 01:36:27 - progress_bar.py[line:274] - INFO: epoch 002:   2494 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.88, wpb=101.3, bsz=40, num_updates=18250, lr=6.4061e-05, gnorm=0.621, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61524
2022-10-01 01:36:38 - progress_bar.py[line:274] - INFO: epoch 002:   2504 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.4, ups=0.93, wpb=101.1, bsz=40, num_updates=18260, lr=6.40505e-05, gnorm=0.694, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61535
2022-10-01 01:36:49 - progress_bar.py[line:274] - INFO: epoch 002:   2514 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=18270, lr=6.40399e-05, gnorm=0.591, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61546
2022-10-01 01:37:00 - progress_bar.py[line:274] - INFO: epoch 002:   2524 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=18280, lr=6.40294e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61557
2022-10-01 01:37:11 - progress_bar.py[line:274] - INFO: epoch 002:   2534 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.8, ups=0.9, wpb=102.4, bsz=40, num_updates=18290, lr=6.40188e-05, gnorm=0.615, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61568
2022-10-01 01:37:23 - progress_bar.py[line:274] - INFO: epoch 002:   2544 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.9, ups=0.9, wpb=102.4, bsz=40, num_updates=18300, lr=6.40082e-05, gnorm=0.556, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61579
2022-10-01 01:37:34 - progress_bar.py[line:274] - INFO: epoch 002:   2554 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.7, ups=0.88, wpb=101.3, bsz=40, num_updates=18310, lr=6.39977e-05, gnorm=0.526, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61591
2022-10-01 01:37:45 - progress_bar.py[line:274] - INFO: epoch 002:   2564 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.4, ups=0.92, wpb=102.1, bsz=40, num_updates=18320, lr=6.39871e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=61601
2022-10-01 01:37:56 - progress_bar.py[line:274] - INFO: epoch 002:   2574 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=18330, lr=6.39766e-05, gnorm=0.68, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61613
2022-10-01 01:38:07 - progress_bar.py[line:274] - INFO: epoch 002:   2584 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.9, ups=0.91, wpb=102.1, bsz=40, num_updates=18340, lr=6.3966e-05, gnorm=0.602, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61624
2022-10-01 01:38:19 - progress_bar.py[line:274] - INFO: epoch 002:   2594 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.1, ups=0.87, wpb=101.7, bsz=40, num_updates=18350, lr=6.39554e-05, gnorm=0.584, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61635
2022-10-01 01:38:30 - progress_bar.py[line:274] - INFO: epoch 002:   2604 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.4, ups=0.9, wpb=101.5, bsz=40, num_updates=18360, lr=6.39449e-05, gnorm=0.629, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61646
2022-10-01 01:38:41 - progress_bar.py[line:274] - INFO: epoch 002:   2614 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.7, ups=0.88, wpb=103.4, bsz=40, num_updates=18370, lr=6.39343e-05, gnorm=0.572, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61658
2022-10-01 01:38:52 - progress_bar.py[line:274] - INFO: epoch 002:   2624 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.9, wpb=101.6, bsz=40, num_updates=18380, lr=6.39238e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61669
2022-10-01 01:39:04 - progress_bar.py[line:274] - INFO: epoch 002:   2634 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.87, wpb=102.3, bsz=40, num_updates=18390, lr=6.39132e-05, gnorm=0.525, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61680
2022-10-01 01:39:15 - progress_bar.py[line:274] - INFO: epoch 002:   2644 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.4, ups=0.87, wpb=101.1, bsz=40, num_updates=18400, lr=6.39026e-05, gnorm=0.609, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61692
2022-10-01 01:39:26 - progress_bar.py[line:274] - INFO: epoch 002:   2654 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.9, wpb=100.2, bsz=40, num_updates=18410, lr=6.38921e-05, gnorm=0.567, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61703
2022-10-01 01:39:38 - progress_bar.py[line:274] - INFO: epoch 002:   2664 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=18420, lr=6.38815e-05, gnorm=0.557, clip=0, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61714
2022-10-01 01:39:49 - progress_bar.py[line:274] - INFO: epoch 002:   2674 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.8, ups=0.89, wpb=103, bsz=40, num_updates=18430, lr=6.3871e-05, gnorm=0.565, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61726
2022-10-01 01:40:01 - progress_bar.py[line:274] - INFO: epoch 002:   2684 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=82.6, ups=0.81, wpb=102.1, bsz=40, num_updates=18440, lr=6.38604e-05, gnorm=0.579, clip=0, loss_scale=2048, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=61738
2022-10-01 01:40:13 - progress_bar.py[line:274] - INFO: epoch 002:   2694 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=85.5, ups=0.85, wpb=101.1, bsz=40, num_updates=18450, lr=6.38498e-05, gnorm=0.53, clip=0, loss_scale=2048, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=61750
2022-10-01 01:40:22 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 01:40:25 - progress_bar.py[line:274] - INFO: epoch 002:   2705 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=82.9, ups=0.81, wpb=102.9, bsz=40, num_updates=18460, lr=6.38393e-05, gnorm=0.615, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=61762
2022-10-01 01:40:37 - progress_bar.py[line:274] - INFO: epoch 002:   2715 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.8, ups=0.86, wpb=101.3, bsz=40, num_updates=18470, lr=6.38287e-05, gnorm=0.521, clip=0, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=61774
2022-10-01 01:40:48 - progress_bar.py[line:274] - INFO: epoch 002:   2725 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89, ups=0.88, wpb=100.6, bsz=40, num_updates=18480, lr=6.38182e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61785
2022-10-01 01:41:00 - progress_bar.py[line:274] - INFO: epoch 002:   2735 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.9, wpb=102.3, bsz=40, num_updates=18490, lr=6.38076e-05, gnorm=0.602, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61796
2022-10-01 01:41:10 - progress_bar.py[line:274] - INFO: epoch 002:   2745 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.4, ups=0.92, wpb=101.5, bsz=40, num_updates=18500, lr=6.3797e-05, gnorm=0.598, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61807
2022-10-01 01:41:22 - progress_bar.py[line:274] - INFO: epoch 002:   2755 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.9, wpb=102, bsz=40, num_updates=18510, lr=6.37865e-05, gnorm=0.587, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61818
2022-10-01 01:41:33 - progress_bar.py[line:274] - INFO: epoch 002:   2765 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.6, ups=0.9, wpb=103.7, bsz=40, num_updates=18520, lr=6.37759e-05, gnorm=0.498, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61829
2022-10-01 01:41:44 - progress_bar.py[line:274] - INFO: epoch 002:   2775 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=85.6, ups=0.85, wpb=100.9, bsz=40, num_updates=18530, lr=6.37654e-05, gnorm=0.538, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=61841
2022-10-01 01:41:56 - progress_bar.py[line:274] - INFO: epoch 002:   2785 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.8, ups=0.86, wpb=102, bsz=40, num_updates=18540, lr=6.37548e-05, gnorm=0.597, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=61853
2022-10-01 01:42:08 - progress_bar.py[line:274] - INFO: epoch 002:   2795 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=85.3, ups=0.83, wpb=102.6, bsz=40, num_updates=18550, lr=6.37442e-05, gnorm=0.606, clip=0, loss_scale=1024, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=61865
2022-10-01 01:42:19 - progress_bar.py[line:274] - INFO: epoch 002:   2805 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.9, wpb=100.7, bsz=40, num_updates=18560, lr=6.37337e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61876
2022-10-01 01:42:31 - progress_bar.py[line:274] - INFO: epoch 002:   2815 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.3, ups=0.88, wpb=101.9, bsz=40, num_updates=18570, lr=6.37231e-05, gnorm=0.492, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61887
2022-10-01 01:42:42 - progress_bar.py[line:274] - INFO: epoch 002:   2825 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=100.9, bsz=40, num_updates=18580, lr=6.37126e-05, gnorm=0.647, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61899
2022-10-01 01:42:53 - progress_bar.py[line:274] - INFO: epoch 002:   2835 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.9, wpb=101.1, bsz=40, num_updates=18590, lr=6.3702e-05, gnorm=0.517, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61910
2022-10-01 01:43:04 - progress_bar.py[line:274] - INFO: epoch 002:   2845 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.7, ups=0.86, wpb=100.6, bsz=40, num_updates=18600, lr=6.36914e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=61921
2022-10-01 01:43:15 - progress_bar.py[line:274] - INFO: epoch 002:   2855 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.2, ups=0.93, wpb=101.2, bsz=40, num_updates=18610, lr=6.36809e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61932
2022-10-01 01:43:27 - progress_bar.py[line:274] - INFO: epoch 002:   2865 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.86, wpb=101.6, bsz=40, num_updates=18620, lr=6.36703e-05, gnorm=0.578, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61944
2022-10-01 01:43:39 - progress_bar.py[line:274] - INFO: epoch 002:   2875 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.5, ups=0.85, wpb=103, bsz=40, num_updates=18630, lr=6.36598e-05, gnorm=0.558, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=61955
2022-10-01 01:43:51 - progress_bar.py[line:274] - INFO: epoch 002:   2885 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=83.5, ups=0.84, wpb=99.6, bsz=40, num_updates=18640, lr=6.36492e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=61967
2022-10-01 01:44:02 - progress_bar.py[line:274] - INFO: epoch 002:   2895 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.3, ups=0.86, wpb=101, bsz=40, num_updates=18650, lr=6.36386e-05, gnorm=0.584, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=61979
2022-10-01 01:44:14 - progress_bar.py[line:274] - INFO: epoch 002:   2905 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.1, ups=0.87, wpb=100.9, bsz=40, num_updates=18660, lr=6.36281e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61990
2022-10-01 01:44:25 - progress_bar.py[line:274] - INFO: epoch 002:   2915 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.88, wpb=100.2, bsz=40, num_updates=18670, lr=6.36175e-05, gnorm=0.575, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62002
2022-10-01 01:44:36 - progress_bar.py[line:274] - INFO: epoch 002:   2925 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.88, wpb=102.9, bsz=40, num_updates=18680, lr=6.3607e-05, gnorm=0.568, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=62013
2022-10-01 01:44:48 - progress_bar.py[line:274] - INFO: epoch 002:   2935 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.88, wpb=101.1, bsz=40, num_updates=18690, lr=6.35964e-05, gnorm=0.622, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62024
2022-10-01 01:44:59 - progress_bar.py[line:274] - INFO: epoch 002:   2945 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.9, wpb=101.4, bsz=40, num_updates=18700, lr=6.35858e-05, gnorm=0.605, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62036
2022-10-01 01:45:10 - progress_bar.py[line:274] - INFO: epoch 002:   2955 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.88, wpb=101.5, bsz=40, num_updates=18710, lr=6.35753e-05, gnorm=0.545, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62047
2022-10-01 01:45:22 - progress_bar.py[line:274] - INFO: epoch 002:   2965 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.8, ups=0.88, wpb=100.7, bsz=40, num_updates=18720, lr=6.35647e-05, gnorm=0.679, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62058
2022-10-01 01:45:33 - progress_bar.py[line:274] - INFO: epoch 002:   2975 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.9, wpb=101.1, bsz=40, num_updates=18730, lr=6.35542e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62069
2022-10-01 01:45:44 - progress_bar.py[line:274] - INFO: epoch 002:   2985 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.7, ups=0.88, wpb=102.8, bsz=40, num_updates=18740, lr=6.35436e-05, gnorm=0.558, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62081
2022-10-01 01:45:55 - progress_bar.py[line:274] - INFO: epoch 002:   2995 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.4, ups=0.9, wpb=101.6, bsz=40, num_updates=18750, lr=6.3533e-05, gnorm=0.558, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62092
2022-10-01 01:46:06 - progress_bar.py[line:274] - INFO: epoch 002:   3005 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.5, ups=0.92, wpb=102.8, bsz=40, num_updates=18760, lr=6.35225e-05, gnorm=0.539, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=62103
2022-10-01 01:46:17 - progress_bar.py[line:274] - INFO: epoch 002:   3015 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.89, wpb=102, bsz=40, num_updates=18770, lr=6.35119e-05, gnorm=0.541, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62114
2022-10-01 01:46:28 - progress_bar.py[line:274] - INFO: epoch 002:   3025 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.3, ups=0.94, wpb=103.5, bsz=40, num_updates=18780, lr=6.35014e-05, gnorm=0.587, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=62125
2022-10-01 01:46:39 - progress_bar.py[line:274] - INFO: epoch 002:   3035 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.91, wpb=101.2, bsz=40, num_updates=18790, lr=6.34908e-05, gnorm=0.61, clip=10, loss_scale=1024, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=62136
2022-10-01 01:46:50 - progress_bar.py[line:274] - INFO: epoch 002:   3045 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.4, ups=0.87, wpb=100, bsz=40, num_updates=18800, lr=6.34802e-05, gnorm=0.625, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62147
2022-10-01 01:47:02 - progress_bar.py[line:274] - INFO: epoch 002:   3055 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.7, ups=0.87, wpb=102.3, bsz=40, num_updates=18810, lr=6.34697e-05, gnorm=0.564, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62159
2022-10-01 01:47:13 - progress_bar.py[line:274] - INFO: epoch 002:   3065 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.7, ups=0.89, wpb=99, bsz=40, num_updates=18820, lr=6.34591e-05, gnorm=0.706, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62170
2022-10-01 01:47:24 - progress_bar.py[line:274] - INFO: epoch 002:   3075 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101.1, bsz=40, num_updates=18830, lr=6.34486e-05, gnorm=0.56, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=62181
2022-10-01 01:47:35 - progress_bar.py[line:274] - INFO: epoch 002:   3085 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.7, ups=0.91, wpb=101.8, bsz=40, num_updates=18840, lr=6.3438e-05, gnorm=0.615, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62192
2022-10-01 01:47:47 - progress_bar.py[line:274] - INFO: epoch 002:   3095 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.88, wpb=102.2, bsz=40, num_updates=18850, lr=6.34274e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62203
2022-10-01 01:47:58 - progress_bar.py[line:274] - INFO: epoch 002:   3105 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.9, wpb=101.4, bsz=40, num_updates=18860, lr=6.34169e-05, gnorm=0.624, clip=0, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=62215
2022-10-01 01:48:09 - progress_bar.py[line:274] - INFO: epoch 002:   3115 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.91, wpb=101.7, bsz=40, num_updates=18870, lr=6.34063e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62226
2022-10-01 01:48:20 - progress_bar.py[line:274] - INFO: epoch 002:   3125 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.91, wpb=100.5, bsz=40, num_updates=18880, lr=6.33958e-05, gnorm=0.552, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62237
2022-10-01 01:48:31 - progress_bar.py[line:274] - INFO: epoch 002:   3135 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.89, wpb=99.8, bsz=40, num_updates=18890, lr=6.33852e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62248
2022-10-01 01:48:42 - progress_bar.py[line:274] - INFO: epoch 002:   3145 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.9, wpb=102.3, bsz=40, num_updates=18900, lr=6.33746e-05, gnorm=0.508, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62259
2022-10-01 01:48:54 - progress_bar.py[line:274] - INFO: epoch 002:   3155 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.88, wpb=101.7, bsz=40, num_updates=18910, lr=6.33641e-05, gnorm=0.628, clip=0, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=62270
2022-10-01 01:49:05 - progress_bar.py[line:274] - INFO: epoch 002:   3165 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.7, ups=0.9, wpb=103.2, bsz=40, num_updates=18920, lr=6.33535e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62282
2022-10-01 01:49:16 - progress_bar.py[line:274] - INFO: epoch 002:   3175 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.9, wpb=101.1, bsz=40, num_updates=18930, lr=6.3343e-05, gnorm=0.674, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62293
2022-10-01 01:49:27 - progress_bar.py[line:274] - INFO: epoch 002:   3185 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=18940, lr=6.33324e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62304
2022-10-01 01:49:38 - progress_bar.py[line:274] - INFO: epoch 002:   3195 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.1, ups=0.9, wpb=102.1, bsz=40, num_updates=18950, lr=6.33218e-05, gnorm=0.515, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62315
2022-10-01 01:49:49 - progress_bar.py[line:274] - INFO: epoch 002:   3205 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=18960, lr=6.33113e-05, gnorm=0.573, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62326
2022-10-01 01:50:00 - progress_bar.py[line:274] - INFO: epoch 002:   3215 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.6, ups=0.92, wpb=101.5, bsz=40, num_updates=18970, lr=6.33007e-05, gnorm=0.565, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62337
2022-10-01 01:50:12 - progress_bar.py[line:274] - INFO: epoch 002:   3225 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.2, ups=0.87, wpb=100.8, bsz=40, num_updates=18980, lr=6.32902e-05, gnorm=0.663, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62349
2022-10-01 01:50:18 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 01:50:25 - progress_bar.py[line:274] - INFO: epoch 002:   3236 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=78.3, ups=0.77, wpb=102, bsz=40, num_updates=18990, lr=6.32796e-05, gnorm=0.627, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=62362
2022-10-01 01:50:36 - progress_bar.py[line:274] - INFO: epoch 002:   3246 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.4, ups=0.87, wpb=100.7, bsz=40, num_updates=19000, lr=6.32691e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62373
2022-10-01 01:50:48 - progress_bar.py[line:274] - INFO: epoch 002:   3256 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.89, wpb=101.2, bsz=40, num_updates=19010, lr=6.32585e-05, gnorm=0.573, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=62384
2022-10-01 01:50:58 - progress_bar.py[line:274] - INFO: epoch 002:   3266 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.1, ups=0.94, wpb=101, bsz=40, num_updates=19020, lr=6.32479e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62395
2022-10-01 01:51:09 - progress_bar.py[line:274] - INFO: epoch 002:   3276 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.91, wpb=99, bsz=40, num_updates=19030, lr=6.32374e-05, gnorm=0.529, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62406
2022-10-01 01:51:21 - progress_bar.py[line:274] - INFO: epoch 002:   3286 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.4, ups=0.88, wpb=101.1, bsz=40, num_updates=19040, lr=6.32268e-05, gnorm=0.527, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62417
2022-10-01 01:51:32 - progress_bar.py[line:274] - INFO: epoch 002:   3296 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.89, wpb=102, bsz=40, num_updates=19050, lr=6.32163e-05, gnorm=0.536, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62428
2022-10-01 01:51:43 - progress_bar.py[line:274] - INFO: epoch 002:   3306 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.9, ups=0.9, wpb=102.4, bsz=40, num_updates=19060, lr=6.32057e-05, gnorm=0.497, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62440
2022-10-01 01:51:54 - progress_bar.py[line:274] - INFO: epoch 002:   3316 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.3, ups=0.92, wpb=101.4, bsz=40, num_updates=19070, lr=6.31951e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62450
2022-10-01 01:52:05 - progress_bar.py[line:274] - INFO: epoch 002:   3326 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.89, wpb=101.3, bsz=40, num_updates=19080, lr=6.31846e-05, gnorm=0.568, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62462
2022-10-01 01:52:16 - progress_bar.py[line:274] - INFO: epoch 002:   3336 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.89, wpb=102.8, bsz=40, num_updates=19090, lr=6.3174e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62473
2022-10-01 01:52:27 - progress_bar.py[line:274] - INFO: epoch 002:   3346 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=19100, lr=6.31635e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62484
2022-10-01 01:52:38 - progress_bar.py[line:274] - INFO: epoch 002:   3356 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.9, wpb=101, bsz=40, num_updates=19110, lr=6.31529e-05, gnorm=0.591, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62495
2022-10-01 01:52:50 - progress_bar.py[line:274] - INFO: epoch 002:   3366 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.88, wpb=102.4, bsz=40, num_updates=19120, lr=6.31423e-05, gnorm=0.718, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62507
2022-10-01 01:53:01 - progress_bar.py[line:274] - INFO: epoch 002:   3376 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.9, wpb=99.9, bsz=40, num_updates=19130, lr=6.31318e-05, gnorm=0.589, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62518
2022-10-01 01:53:12 - progress_bar.py[line:274] - INFO: epoch 002:   3386 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101.8, bsz=40, num_updates=19140, lr=6.31212e-05, gnorm=0.521, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62529
2022-10-01 01:53:23 - progress_bar.py[line:274] - INFO: epoch 002:   3396 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=19150, lr=6.31107e-05, gnorm=0.58, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62540
2022-10-01 01:53:35 - progress_bar.py[line:274] - INFO: epoch 002:   3406 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.9, wpb=100.3, bsz=40, num_updates=19160, lr=6.31001e-05, gnorm=0.575, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62551
2022-10-01 01:53:46 - progress_bar.py[line:274] - INFO: epoch 002:   3416 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.6, ups=0.88, wpb=99.6, bsz=40, num_updates=19170, lr=6.30895e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62563
2022-10-01 01:53:57 - progress_bar.py[line:274] - INFO: epoch 002:   3426 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.9, ups=0.9, wpb=101.8, bsz=40, num_updates=19180, lr=6.3079e-05, gnorm=0.643, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=62574
2022-10-01 01:54:08 - progress_bar.py[line:274] - INFO: epoch 002:   3436 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=19190, lr=6.30684e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62585
2022-10-01 01:54:20 - progress_bar.py[line:274] - INFO: epoch 002:   3446 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.88, wpb=101, bsz=40, num_updates=19200, lr=6.30579e-05, gnorm=0.577, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62596
2022-10-01 01:54:31 - progress_bar.py[line:274] - INFO: epoch 002:   3456 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.4, ups=0.87, wpb=100.3, bsz=40, num_updates=19210, lr=6.30473e-05, gnorm=0.539, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=62608
2022-10-01 01:54:42 - progress_bar.py[line:274] - INFO: epoch 002:   3466 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.8, ups=0.9, wpb=101.5, bsz=40, num_updates=19220, lr=6.30367e-05, gnorm=0.509, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62619
2022-10-01 01:54:53 - progress_bar.py[line:274] - INFO: epoch 002:   3476 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=19230, lr=6.30262e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62630
2022-10-01 01:55:05 - progress_bar.py[line:274] - INFO: epoch 002:   3486 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.9, wpb=101.1, bsz=40, num_updates=19240, lr=6.30156e-05, gnorm=0.487, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62641
2022-10-01 01:55:16 - progress_bar.py[line:274] - INFO: epoch 002:   3496 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=19250, lr=6.30051e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62653
2022-10-01 01:55:27 - progress_bar.py[line:274] - INFO: epoch 002:   3506 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94, ups=0.93, wpb=101.6, bsz=40, num_updates=19260, lr=6.29945e-05, gnorm=0.496, clip=0, loss_scale=1024, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=62663
2022-10-01 01:55:38 - progress_bar.py[line:274] - INFO: epoch 002:   3516 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.88, wpb=102.2, bsz=40, num_updates=19270, lr=6.29839e-05, gnorm=0.581, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62675
2022-10-01 01:55:49 - progress_bar.py[line:274] - INFO: epoch 002:   3526 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.6, ups=0.92, wpb=101.4, bsz=40, num_updates=19280, lr=6.29734e-05, gnorm=0.557, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62686
2022-10-01 01:56:00 - progress_bar.py[line:274] - INFO: epoch 002:   3536 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89, ups=0.88, wpb=101, bsz=40, num_updates=19290, lr=6.29628e-05, gnorm=0.603, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62697
2022-10-01 01:56:12 - progress_bar.py[line:274] - INFO: epoch 002:   3546 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.5, ups=0.88, wpb=101.2, bsz=40, num_updates=19300, lr=6.29523e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62708
2022-10-01 01:56:23 - progress_bar.py[line:274] - INFO: epoch 002:   3556 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.88, wpb=102.5, bsz=40, num_updates=19310, lr=6.29417e-05, gnorm=0.507, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=62720
2022-10-01 01:56:34 - progress_bar.py[line:274] - INFO: epoch 002:   3566 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.5, ups=0.89, wpb=99.3, bsz=40, num_updates=19320, lr=6.29311e-05, gnorm=0.541, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62731
2022-10-01 01:56:45 - progress_bar.py[line:274] - INFO: epoch 002:   3576 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.89, wpb=100.2, bsz=40, num_updates=19330, lr=6.29206e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62742
2022-10-01 01:56:57 - progress_bar.py[line:274] - INFO: epoch 002:   3586 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=100.5, bsz=40, num_updates=19340, lr=6.291e-05, gnorm=0.569, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62753
2022-10-01 01:57:08 - progress_bar.py[line:274] - INFO: epoch 002:   3596 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.3, ups=0.88, wpb=102.4, bsz=40, num_updates=19350, lr=6.28995e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62765
2022-10-01 01:57:19 - progress_bar.py[line:274] - INFO: epoch 002:   3606 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.1, ups=0.93, wpb=100.6, bsz=40, num_updates=19360, lr=6.28889e-05, gnorm=0.583, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62775
2022-10-01 01:57:30 - progress_bar.py[line:274] - INFO: epoch 002:   3616 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.8, ups=0.88, wpb=100.4, bsz=40, num_updates=19370, lr=6.28783e-05, gnorm=0.599, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=62787
2022-10-01 01:57:41 - progress_bar.py[line:274] - INFO: epoch 002:   3626 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.88, wpb=102.2, bsz=40, num_updates=19380, lr=6.28678e-05, gnorm=0.499, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62798
2022-10-01 01:57:53 - progress_bar.py[line:274] - INFO: epoch 002:   3636 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.9, ups=0.89, wpb=100.1, bsz=40, num_updates=19390, lr=6.28572e-05, gnorm=0.625, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62809
2022-10-01 01:58:04 - progress_bar.py[line:274] - INFO: epoch 002:   3646 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.1, ups=0.88, wpb=100.6, bsz=40, num_updates=19400, lr=6.28467e-05, gnorm=0.622, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62821
2022-10-01 01:58:15 - progress_bar.py[line:274] - INFO: epoch 002:   3656 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101, bsz=40, num_updates=19410, lr=6.28361e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62832
2022-10-01 01:58:26 - progress_bar.py[line:274] - INFO: epoch 002:   3666 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.9, wpb=100.4, bsz=40, num_updates=19420, lr=6.28255e-05, gnorm=0.572, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=62843
2022-10-01 01:58:38 - progress_bar.py[line:274] - INFO: epoch 002:   3676 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.89, wpb=101.9, bsz=40, num_updates=19430, lr=6.2815e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=62854
2022-10-01 01:58:49 - progress_bar.py[line:274] - INFO: epoch 002:   3686 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.1, ups=0.9, wpb=100.1, bsz=40, num_updates=19440, lr=6.28044e-05, gnorm=0.573, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62866
2022-10-01 01:59:00 - progress_bar.py[line:274] - INFO: epoch 002:   3696 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.88, wpb=102, bsz=40, num_updates=19450, lr=6.27939e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=62877
2022-10-01 01:59:11 - progress_bar.py[line:274] - INFO: epoch 002:   3706 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.9, ups=0.91, wpb=101.8, bsz=40, num_updates=19460, lr=6.27833e-05, gnorm=0.552, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62888
2022-10-01 01:59:22 - progress_bar.py[line:274] - INFO: epoch 002:   3716 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.9, wpb=101.6, bsz=40, num_updates=19470, lr=6.27727e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62899
2022-10-01 01:59:33 - progress_bar.py[line:274] - INFO: epoch 002:   3726 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.92, wpb=99.2, bsz=40, num_updates=19480, lr=6.27622e-05, gnorm=0.627, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62910
2022-10-01 01:59:44 - progress_bar.py[line:274] - INFO: epoch 002:   3736 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=19490, lr=6.27516e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62921
2022-10-01 01:59:56 - progress_bar.py[line:274] - INFO: epoch 002:   3746 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.9, wpb=101, bsz=40, num_updates=19500, lr=6.27411e-05, gnorm=0.616, clip=0, loss_scale=2048, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=62932
2022-10-01 02:00:00 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 02:00:08 - progress_bar.py[line:274] - INFO: epoch 002:   3757 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=81.7, ups=0.82, wpb=100.1, bsz=40, num_updates=19510, lr=6.27305e-05, gnorm=0.566, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=62945
2022-10-01 02:00:19 - progress_bar.py[line:274] - INFO: epoch 002:   3767 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.6, ups=0.89, wpb=102.2, bsz=40, num_updates=19520, lr=6.27199e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62956
2022-10-01 02:00:30 - progress_bar.py[line:274] - INFO: epoch 002:   3777 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.5, ups=0.9, wpb=102.5, bsz=40, num_updates=19530, lr=6.27094e-05, gnorm=0.529, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62967
2022-10-01 02:00:41 - progress_bar.py[line:274] - INFO: epoch 002:   3787 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.9, ups=0.9, wpb=101.2, bsz=40, num_updates=19540, lr=6.26988e-05, gnorm=0.651, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62978
2022-10-01 02:00:54 - progress_bar.py[line:274] - INFO: epoch 002:   3797 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.2, ups=0.87, wpb=100.3, bsz=40, num_updates=19550, lr=6.26883e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62990
2022-10-01 02:01:04 - progress_bar.py[line:274] - INFO: epoch 002:   3807 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.5, ups=0.94, wpb=100.2, bsz=40, num_updates=19560, lr=6.26777e-05, gnorm=0.6, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63001
2022-10-01 02:01:16 - progress_bar.py[line:274] - INFO: epoch 002:   3817 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.9, ups=0.87, wpb=100.8, bsz=40, num_updates=19570, lr=6.26671e-05, gnorm=0.597, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63012
2022-10-01 02:01:27 - progress_bar.py[line:274] - INFO: epoch 002:   3827 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.89, wpb=102.8, bsz=40, num_updates=19580, lr=6.26566e-05, gnorm=0.505, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63024
2022-10-01 02:01:38 - progress_bar.py[line:274] - INFO: epoch 002:   3837 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.1, ups=0.91, wpb=102.3, bsz=40, num_updates=19590, lr=6.2646e-05, gnorm=0.51, clip=0, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=63035
2022-10-01 02:01:49 - progress_bar.py[line:274] - INFO: epoch 002:   3847 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.3, ups=0.89, wpb=103.4, bsz=40, num_updates=19600, lr=6.26355e-05, gnorm=0.526, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63046
2022-10-01 02:02:00 - progress_bar.py[line:274] - INFO: epoch 002:   3857 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.89, wpb=100.7, bsz=40, num_updates=19610, lr=6.26249e-05, gnorm=0.612, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63057
2022-10-01 02:02:12 - progress_bar.py[line:274] - INFO: epoch 002:   3867 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88, ups=0.89, wpb=99, bsz=40, num_updates=19620, lr=6.26143e-05, gnorm=0.537, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63068
2022-10-01 02:02:23 - progress_bar.py[line:274] - INFO: epoch 002:   3877 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=19630, lr=6.26038e-05, gnorm=0.538, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=63080
2022-10-01 02:02:34 - progress_bar.py[line:274] - INFO: epoch 002:   3887 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.9, wpb=101.7, bsz=40, num_updates=19640, lr=6.25932e-05, gnorm=0.507, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63091
2022-10-01 02:02:45 - progress_bar.py[line:274] - INFO: epoch 002:   3897 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=102.1, bsz=40, num_updates=19650, lr=6.25827e-05, gnorm=0.572, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=63102
2022-10-01 02:02:56 - progress_bar.py[line:274] - INFO: epoch 002:   3907 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.3, ups=0.92, wpb=103, bsz=40, num_updates=19660, lr=6.25721e-05, gnorm=0.467, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63113
2022-10-01 02:03:07 - progress_bar.py[line:274] - INFO: epoch 002:   3917 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.9, wpb=102.1, bsz=40, num_updates=19670, lr=6.25615e-05, gnorm=0.461, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=63124
2022-10-01 02:03:19 - progress_bar.py[line:274] - INFO: epoch 002:   3927 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87, ups=0.87, wpb=100.5, bsz=40, num_updates=19680, lr=6.2551e-05, gnorm=0.561, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=63136
2022-10-01 02:03:30 - progress_bar.py[line:274] - INFO: epoch 002:   3937 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.8, ups=0.86, wpb=101.1, bsz=40, num_updates=19690, lr=6.25404e-05, gnorm=0.581, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=63147
2022-10-01 02:03:42 - progress_bar.py[line:274] - INFO: epoch 002:   3947 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.9, ups=0.88, wpb=101.3, bsz=40, num_updates=19700, lr=6.25299e-05, gnorm=0.572, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63159
2022-10-01 02:03:53 - progress_bar.py[line:274] - INFO: epoch 002:   3957 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=19710, lr=6.25193e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63170
2022-10-01 02:04:04 - progress_bar.py[line:274] - INFO: epoch 002:   3967 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=100.9, bsz=40, num_updates=19720, lr=6.25087e-05, gnorm=0.557, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63181
2022-10-01 02:04:15 - progress_bar.py[line:274] - INFO: epoch 002:   3977 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=19730, lr=6.24982e-05, gnorm=0.591, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63192
2022-10-01 02:04:26 - progress_bar.py[line:274] - INFO: epoch 002:   3987 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93, ups=0.92, wpb=100.6, bsz=40, num_updates=19740, lr=6.24876e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63203
2022-10-01 02:04:37 - progress_bar.py[line:274] - INFO: epoch 002:   3997 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=19750, lr=6.24771e-05, gnorm=0.507, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63214
2022-10-01 02:04:49 - progress_bar.py[line:274] - INFO: epoch 002:   4007 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.7, ups=0.87, wpb=100, bsz=40, num_updates=19760, lr=6.24665e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63226
2022-10-01 02:05:01 - progress_bar.py[line:274] - INFO: epoch 002:   4017 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.1, ups=0.86, wpb=102.1, bsz=40, num_updates=19770, lr=6.24559e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=63237
2022-10-01 02:05:12 - progress_bar.py[line:274] - INFO: epoch 002:   4027 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.3, ups=0.89, wpb=101.2, bsz=40, num_updates=19780, lr=6.24454e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63249
2022-10-01 02:05:23 - progress_bar.py[line:274] - INFO: epoch 002:   4037 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=19790, lr=6.24348e-05, gnorm=0.555, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63260
2022-10-01 02:05:34 - progress_bar.py[line:274] - INFO: epoch 002:   4047 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.87, wpb=102.5, bsz=40, num_updates=19800, lr=6.24243e-05, gnorm=0.515, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63271
2022-10-01 02:05:46 - progress_bar.py[line:274] - INFO: epoch 002:   4057 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.89, wpb=99.7, bsz=40, num_updates=19810, lr=6.24137e-05, gnorm=0.625, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63283
2022-10-01 02:05:57 - progress_bar.py[line:274] - INFO: epoch 002:   4067 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.9, wpb=101.6, bsz=40, num_updates=19820, lr=6.24031e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63294
2022-10-01 02:06:08 - progress_bar.py[line:274] - INFO: epoch 002:   4077 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.6, ups=0.88, wpb=101.1, bsz=40, num_updates=19830, lr=6.23926e-05, gnorm=0.597, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63305
2022-10-01 02:06:20 - progress_bar.py[line:274] - INFO: epoch 002:   4087 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.88, wpb=102.6, bsz=40, num_updates=19840, lr=6.2382e-05, gnorm=0.578, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63316
2022-10-01 02:06:31 - progress_bar.py[line:274] - INFO: epoch 002:   4097 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=19850, lr=6.23715e-05, gnorm=0.594, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63328
2022-10-01 02:06:43 - progress_bar.py[line:274] - INFO: epoch 002:   4107 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=85.8, ups=0.86, wpb=99.8, bsz=40, num_updates=19860, lr=6.23609e-05, gnorm=0.667, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=63339
2022-10-01 02:06:55 - progress_bar.py[line:274] - INFO: epoch 002:   4117 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=82.4, ups=0.82, wpb=100.2, bsz=40, num_updates=19870, lr=6.23503e-05, gnorm=0.573, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=63351
2022-10-01 02:07:07 - progress_bar.py[line:274] - INFO: epoch 002:   4127 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86, ups=0.85, wpb=101.3, bsz=40, num_updates=19880, lr=6.23398e-05, gnorm=0.535, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=63363
2022-10-01 02:07:18 - progress_bar.py[line:274] - INFO: epoch 002:   4137 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90, ups=0.89, wpb=101.1, bsz=40, num_updates=19890, lr=6.23292e-05, gnorm=0.6, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63374
2022-10-01 02:07:29 - progress_bar.py[line:274] - INFO: epoch 002:   4147 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.91, wpb=102.4, bsz=40, num_updates=19900, lr=6.23187e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63385
2022-10-01 02:07:40 - progress_bar.py[line:274] - INFO: epoch 002:   4157 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.9, wpb=100.1, bsz=40, num_updates=19910, lr=6.23081e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=63397
2022-10-01 02:07:51 - progress_bar.py[line:274] - INFO: epoch 002:   4167 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.88, wpb=101.2, bsz=40, num_updates=19920, lr=6.22975e-05, gnorm=0.505, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63408
2022-10-01 02:08:03 - progress_bar.py[line:274] - INFO: epoch 002:   4177 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.7, ups=0.88, wpb=100.9, bsz=40, num_updates=19930, lr=6.2287e-05, gnorm=0.557, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63419
2022-10-01 02:08:13 - progress_bar.py[line:274] - INFO: epoch 002:   4187 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.93, wpb=100.4, bsz=40, num_updates=19940, lr=6.22764e-05, gnorm=0.558, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63430
2022-10-01 02:08:25 - progress_bar.py[line:274] - INFO: epoch 002:   4197 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.9, wpb=100.7, bsz=40, num_updates=19950, lr=6.22659e-05, gnorm=0.601, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63441
2022-10-01 02:08:35 - progress_bar.py[line:274] - INFO: epoch 002:   4207 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.91, wpb=101.6, bsz=40, num_updates=19960, lr=6.22553e-05, gnorm=0.598, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63452
2022-10-01 02:08:47 - progress_bar.py[line:274] - INFO: epoch 002:   4217 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.8, ups=0.87, wpb=100.3, bsz=40, num_updates=19970, lr=6.22447e-05, gnorm=0.575, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63464
2022-10-01 02:08:58 - progress_bar.py[line:274] - INFO: epoch 002:   4227 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.89, wpb=102.6, bsz=40, num_updates=19980, lr=6.22342e-05, gnorm=0.535, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63475
2022-10-01 02:09:09 - progress_bar.py[line:274] - INFO: epoch 002:   4237 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.9, wpb=103.6, bsz=40, num_updates=19990, lr=6.22236e-05, gnorm=0.521, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63486
2022-10-01 02:09:21 - progress_bar.py[line:274] - INFO: epoch 002:   4247 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.88, wpb=102.3, bsz=40, num_updates=20000, lr=6.22131e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63497
2022-10-01 02:09:32 - progress_bar.py[line:274] - INFO: epoch 002:   4257 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.4, ups=0.89, wpb=99.6, bsz=40, num_updates=20010, lr=6.22025e-05, gnorm=0.626, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63509
2022-10-01 02:09:42 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 02:09:44 - progress_bar.py[line:274] - INFO: epoch 002:   4268 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=82.2, ups=0.81, wpb=101, bsz=40, num_updates=20020, lr=6.2192e-05, gnorm=0.608, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=63521
2022-10-01 02:09:56 - progress_bar.py[line:274] - INFO: epoch 002:   4278 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.89, wpb=101.4, bsz=40, num_updates=20030, lr=6.21814e-05, gnorm=0.57, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63532
2022-10-01 02:10:06 - progress_bar.py[line:274] - INFO: epoch 002:   4288 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.92, wpb=101.2, bsz=40, num_updates=20040, lr=6.21708e-05, gnorm=0.588, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=63543
2022-10-01 02:10:18 - progress_bar.py[line:274] - INFO: epoch 002:   4298 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.89, wpb=101.7, bsz=40, num_updates=20050, lr=6.21603e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63554
2022-10-01 02:10:29 - progress_bar.py[line:274] - INFO: epoch 002:   4308 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.9, ups=0.88, wpb=100.3, bsz=40, num_updates=20060, lr=6.21497e-05, gnorm=0.594, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63566
2022-10-01 02:10:40 - progress_bar.py[line:274] - INFO: epoch 002:   4318 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89, ups=0.88, wpb=101.3, bsz=40, num_updates=20070, lr=6.21392e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63577
2022-10-01 02:10:52 - progress_bar.py[line:274] - INFO: epoch 002:   4328 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.88, wpb=102.9, bsz=40, num_updates=20080, lr=6.21286e-05, gnorm=0.647, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63589
2022-10-01 02:11:03 - progress_bar.py[line:274] - INFO: epoch 002:   4338 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=20090, lr=6.2118e-05, gnorm=0.635, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63600
2022-10-01 02:11:14 - progress_bar.py[line:274] - INFO: epoch 002:   4348 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.5, ups=0.88, wpb=101.9, bsz=40, num_updates=20100, lr=6.21075e-05, gnorm=0.546, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63611
2022-10-01 02:11:26 - progress_bar.py[line:274] - INFO: epoch 002:   4358 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.89, wpb=100.8, bsz=40, num_updates=20110, lr=6.20969e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63622
2022-10-01 02:11:37 - progress_bar.py[line:274] - INFO: epoch 002:   4368 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.91, wpb=99.9, bsz=40, num_updates=20120, lr=6.20864e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=63633
2022-10-01 02:11:48 - progress_bar.py[line:274] - INFO: epoch 002:   4378 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93, ups=0.9, wpb=103.2, bsz=40, num_updates=20130, lr=6.20758e-05, gnorm=0.526, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63645
2022-10-01 02:11:59 - progress_bar.py[line:274] - INFO: epoch 002:   4388 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=20140, lr=6.20652e-05, gnorm=0.492, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63656
2022-10-01 02:12:10 - progress_bar.py[line:274] - INFO: epoch 002:   4398 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.89, wpb=102.2, bsz=40, num_updates=20150, lr=6.20547e-05, gnorm=0.647, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63667
2022-10-01 02:12:22 - progress_bar.py[line:274] - INFO: epoch 002:   4408 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.87, wpb=102.6, bsz=40, num_updates=20160, lr=6.20441e-05, gnorm=0.522, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63679
2022-10-01 02:12:33 - progress_bar.py[line:274] - INFO: epoch 002:   4418 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.87, wpb=101.1, bsz=40, num_updates=20170, lr=6.20336e-05, gnorm=0.659, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63690
2022-10-01 02:12:45 - progress_bar.py[line:274] - INFO: epoch 002:   4428 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.4, ups=0.88, wpb=101.6, bsz=40, num_updates=20180, lr=6.2023e-05, gnorm=0.592, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63701
2022-10-01 02:12:56 - progress_bar.py[line:274] - INFO: epoch 002:   4438 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.6, ups=0.89, wpb=101.8, bsz=40, num_updates=20190, lr=6.20124e-05, gnorm=0.539, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63713
2022-10-01 02:13:07 - progress_bar.py[line:274] - INFO: epoch 002:   4448 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.92, wpb=100.4, bsz=40, num_updates=20200, lr=6.20019e-05, gnorm=0.579, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63724
2022-10-01 02:13:19 - progress_bar.py[line:274] - INFO: epoch 002:   4458 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=84.2, ups=0.83, wpb=102, bsz=40, num_updates=20210, lr=6.19913e-05, gnorm=0.564, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=63736
2022-10-01 02:13:30 - progress_bar.py[line:274] - INFO: epoch 002:   4468 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.6, ups=0.92, wpb=100.8, bsz=40, num_updates=20220, lr=6.19808e-05, gnorm=0.492, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63747
2022-10-01 02:13:41 - progress_bar.py[line:274] - INFO: epoch 002:   4478 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.2, ups=0.88, wpb=99.7, bsz=40, num_updates=20230, lr=6.19702e-05, gnorm=0.56, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63758
2022-10-01 02:13:53 - progress_bar.py[line:274] - INFO: epoch 002:   4488 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.4, ups=0.88, wpb=100.4, bsz=40, num_updates=20240, lr=6.19596e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63770
2022-10-01 02:14:04 - progress_bar.py[line:274] - INFO: epoch 002:   4498 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.2, ups=0.9, wpb=102.3, bsz=40, num_updates=20250, lr=6.19491e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63781
2022-10-01 02:14:15 - progress_bar.py[line:274] - INFO: epoch 002:   4508 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.2, ups=0.91, wpb=101.1, bsz=40, num_updates=20260, lr=6.19385e-05, gnorm=0.523, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63792
2022-10-01 02:14:26 - progress_bar.py[line:274] - INFO: epoch 002:   4518 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=20270, lr=6.1928e-05, gnorm=0.511, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63803
2022-10-01 02:14:37 - progress_bar.py[line:274] - INFO: epoch 002:   4528 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.2, ups=0.9, wpb=102.8, bsz=40, num_updates=20280, lr=6.19174e-05, gnorm=0.491, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63814
2022-10-01 02:14:48 - progress_bar.py[line:274] - INFO: epoch 002:   4538 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.9, wpb=101.4, bsz=40, num_updates=20290, lr=6.19068e-05, gnorm=0.529, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63825
2022-10-01 02:15:00 - progress_bar.py[line:274] - INFO: epoch 002:   4548 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.1, ups=0.87, wpb=103.8, bsz=40, num_updates=20300, lr=6.18963e-05, gnorm=0.545, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63837
2022-10-01 02:15:11 - progress_bar.py[line:274] - INFO: epoch 002:   4558 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.88, wpb=103.7, bsz=40, num_updates=20310, lr=6.18857e-05, gnorm=0.518, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63848
2022-10-01 02:15:23 - progress_bar.py[line:274] - INFO: epoch 002:   4568 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.6, ups=0.88, wpb=99.9, bsz=40, num_updates=20320, lr=6.18752e-05, gnorm=0.709, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63859
2022-10-01 02:15:34 - progress_bar.py[line:274] - INFO: epoch 002:   4578 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=20330, lr=6.18646e-05, gnorm=0.562, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63871
2022-10-01 02:15:45 - progress_bar.py[line:274] - INFO: epoch 002:   4588 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=20340, lr=6.1854e-05, gnorm=0.582, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63882
2022-10-01 02:15:56 - progress_bar.py[line:274] - INFO: epoch 002:   4598 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.89, wpb=102.5, bsz=40, num_updates=20350, lr=6.18435e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63893
2022-10-01 02:16:07 - progress_bar.py[line:274] - INFO: epoch 002:   4608 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.1, ups=0.95, wpb=102.7, bsz=40, num_updates=20360, lr=6.18329e-05, gnorm=0.522, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63904
2022-10-01 02:16:18 - progress_bar.py[line:274] - INFO: epoch 002:   4618 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.1, ups=0.87, wpb=101.9, bsz=40, num_updates=20370, lr=6.18224e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63915
2022-10-01 02:16:30 - progress_bar.py[line:274] - INFO: epoch 002:   4628 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.89, wpb=100, bsz=40, num_updates=20380, lr=6.18118e-05, gnorm=0.651, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63926
2022-10-01 02:16:41 - progress_bar.py[line:274] - INFO: epoch 002:   4638 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.9, wpb=102.3, bsz=40, num_updates=20390, lr=6.18012e-05, gnorm=0.544, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=63937
2022-10-01 02:16:52 - progress_bar.py[line:274] - INFO: epoch 002:   4648 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.8, ups=0.9, wpb=100.3, bsz=40, num_updates=20400, lr=6.17907e-05, gnorm=0.704, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=63949
2022-10-01 02:17:04 - progress_bar.py[line:274] - INFO: epoch 002:   4658 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87, ups=0.86, wpb=101.2, bsz=40, num_updates=20410, lr=6.17801e-05, gnorm=0.56, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=63960
2022-10-01 02:17:15 - progress_bar.py[line:274] - INFO: epoch 002:   4668 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=100.4, bsz=40, num_updates=20420, lr=6.17696e-05, gnorm=0.567, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63972
2022-10-01 02:17:26 - progress_bar.py[line:274] - INFO: epoch 002:   4678 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.89, wpb=102.4, bsz=40, num_updates=20430, lr=6.1759e-05, gnorm=0.522, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63983
2022-10-01 02:17:37 - progress_bar.py[line:274] - INFO: epoch 002:   4688 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.9, wpb=101.2, bsz=40, num_updates=20440, lr=6.17484e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63994
2022-10-01 02:17:48 - progress_bar.py[line:274] - INFO: epoch 002:   4698 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=20450, lr=6.17379e-05, gnorm=0.508, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64005
2022-10-01 02:18:00 - progress_bar.py[line:274] - INFO: epoch 002:   4708 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.6, ups=0.87, wpb=100.3, bsz=40, num_updates=20460, lr=6.17273e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64017
2022-10-01 02:18:11 - progress_bar.py[line:274] - INFO: epoch 002:   4718 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.1, ups=0.9, wpb=102.4, bsz=40, num_updates=20470, lr=6.17168e-05, gnorm=0.579, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64028
2022-10-01 02:18:23 - progress_bar.py[line:274] - INFO: epoch 002:   4728 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=83.3, ups=0.83, wpb=100.2, bsz=40, num_updates=20480, lr=6.17062e-05, gnorm=0.583, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=64040
2022-10-01 02:18:35 - progress_bar.py[line:274] - INFO: epoch 002:   4738 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.2, ups=0.86, wpb=102.2, bsz=40, num_updates=20490, lr=6.16956e-05, gnorm=0.583, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64051
2022-10-01 02:18:46 - progress_bar.py[line:274] - INFO: epoch 002:   4748 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.6, ups=0.9, wpb=101.8, bsz=40, num_updates=20500, lr=6.16851e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64062
2022-10-01 02:18:57 - progress_bar.py[line:274] - INFO: epoch 002:   4758 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.89, wpb=100.1, bsz=40, num_updates=20510, lr=6.16745e-05, gnorm=0.586, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64074
2022-10-01 02:19:08 - progress_bar.py[line:274] - INFO: epoch 002:   4768 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.1, ups=0.9, wpb=102.5, bsz=40, num_updates=20520, lr=6.1664e-05, gnorm=0.607, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64085
2022-10-01 02:19:19 - progress_bar.py[line:274] - INFO: epoch 002:   4778 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.5, ups=0.92, wpb=100.9, bsz=40, num_updates=20530, lr=6.16534e-05, gnorm=0.567, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64096
2022-10-01 02:19:31 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 02:19:32 - progress_bar.py[line:274] - INFO: epoch 002:   4789 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=80.1, ups=0.79, wpb=101.8, bsz=40, num_updates=20540, lr=6.16428e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=64108
2022-10-01 02:19:43 - progress_bar.py[line:274] - INFO: epoch 002:   4799 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.88, wpb=103.2, bsz=40, num_updates=20550, lr=6.16323e-05, gnorm=0.611, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64120
2022-10-01 02:19:55 - progress_bar.py[line:274] - INFO: epoch 002:   4809 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.7, ups=0.88, wpb=103.1, bsz=40, num_updates=20560, lr=6.16217e-05, gnorm=0.47, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64131
2022-10-01 02:20:05 - progress_bar.py[line:274] - INFO: epoch 002:   4819 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.91, wpb=99.4, bsz=40, num_updates=20570, lr=6.16112e-05, gnorm=0.529, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64142
2022-10-01 02:20:17 - progress_bar.py[line:274] - INFO: epoch 002:   4829 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.9, wpb=100.9, bsz=40, num_updates=20580, lr=6.16006e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64153
2022-10-01 02:20:28 - progress_bar.py[line:274] - INFO: epoch 002:   4839 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.88, wpb=99.9, bsz=40, num_updates=20590, lr=6.159e-05, gnorm=0.558, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64165
2022-10-01 02:20:39 - progress_bar.py[line:274] - INFO: epoch 002:   4849 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.88, wpb=101.7, bsz=40, num_updates=20600, lr=6.15795e-05, gnorm=0.562, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64176
2022-10-01 02:20:51 - progress_bar.py[line:274] - INFO: epoch 002:   4859 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.6, ups=0.88, wpb=99.8, bsz=40, num_updates=20610, lr=6.15689e-05, gnorm=0.539, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64187
2022-10-01 02:21:02 - progress_bar.py[line:274] - INFO: epoch 002:   4869 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.3, ups=0.91, wpb=102.1, bsz=40, num_updates=20620, lr=6.15584e-05, gnorm=0.504, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64198
2022-10-01 02:21:13 - progress_bar.py[line:274] - INFO: epoch 002:   4879 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.6, ups=0.88, wpb=102.2, bsz=40, num_updates=20630, lr=6.15478e-05, gnorm=0.501, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64210
2022-10-01 02:21:24 - progress_bar.py[line:274] - INFO: epoch 002:   4889 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.7, ups=0.9, wpb=103.1, bsz=40, num_updates=20640, lr=6.15372e-05, gnorm=0.624, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64221
2022-10-01 02:21:35 - progress_bar.py[line:274] - INFO: epoch 002:   4899 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.89, wpb=101.2, bsz=40, num_updates=20650, lr=6.15267e-05, gnorm=0.505, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64232
2022-10-01 02:21:46 - progress_bar.py[line:274] - INFO: epoch 002:   4909 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.4, ups=0.91, wpb=101.9, bsz=40, num_updates=20660, lr=6.15161e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64243
2022-10-01 02:21:58 - progress_bar.py[line:274] - INFO: epoch 002:   4919 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.4, ups=0.87, wpb=102.5, bsz=40, num_updates=20670, lr=6.15056e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64255
2022-10-01 02:22:09 - progress_bar.py[line:274] - INFO: epoch 002:   4929 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.92, wpb=101.6, bsz=40, num_updates=20680, lr=6.1495e-05, gnorm=0.529, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64266
2022-10-01 02:22:20 - progress_bar.py[line:274] - INFO: epoch 002:   4939 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.89, wpb=100.7, bsz=40, num_updates=20690, lr=6.14844e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64277
2022-10-01 02:22:31 - progress_bar.py[line:274] - INFO: epoch 002:   4949 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.91, wpb=99.5, bsz=40, num_updates=20700, lr=6.14739e-05, gnorm=0.51, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64288
2022-10-01 02:22:42 - progress_bar.py[line:274] - INFO: epoch 002:   4959 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.9, wpb=102, bsz=40, num_updates=20710, lr=6.14633e-05, gnorm=0.518, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64299
2022-10-01 02:22:53 - progress_bar.py[line:274] - INFO: epoch 002:   4969 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.89, wpb=103, bsz=40, num_updates=20720, lr=6.14528e-05, gnorm=0.612, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64310
2022-10-01 02:23:05 - progress_bar.py[line:274] - INFO: epoch 002:   4979 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=20730, lr=6.14422e-05, gnorm=0.552, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64321
2022-10-01 02:23:16 - progress_bar.py[line:274] - INFO: epoch 002:   4989 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.88, wpb=103, bsz=40, num_updates=20740, lr=6.14316e-05, gnorm=0.574, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64333
2022-10-01 02:23:27 - progress_bar.py[line:274] - INFO: epoch 002:   4999 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.7, ups=0.92, wpb=98.7, bsz=40, num_updates=20750, lr=6.14211e-05, gnorm=0.665, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64344
2022-10-01 02:23:38 - progress_bar.py[line:274] - INFO: epoch 002:   5009 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.91, wpb=100.6, bsz=40, num_updates=20760, lr=6.14105e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64355
2022-10-01 02:23:49 - progress_bar.py[line:274] - INFO: epoch 002:   5019 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.6, ups=0.87, wpb=101.6, bsz=40, num_updates=20770, lr=6.14e-05, gnorm=0.495, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64366
2022-10-01 02:24:01 - progress_bar.py[line:274] - INFO: epoch 002:   5029 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.89, wpb=102.2, bsz=40, num_updates=20780, lr=6.13894e-05, gnorm=0.538, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64377
2022-10-01 02:24:12 - progress_bar.py[line:274] - INFO: epoch 002:   5039 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.4, ups=0.89, wpb=101.1, bsz=40, num_updates=20790, lr=6.13788e-05, gnorm=0.508, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64388
2022-10-01 02:24:23 - progress_bar.py[line:274] - INFO: epoch 002:   5049 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.1, ups=0.91, wpb=102.1, bsz=40, num_updates=20800, lr=6.13683e-05, gnorm=0.592, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64399
2022-10-01 02:24:34 - progress_bar.py[line:274] - INFO: epoch 002:   5059 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.5, ups=0.88, wpb=99.5, bsz=40, num_updates=20810, lr=6.13577e-05, gnorm=0.659, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64411
2022-10-01 02:24:46 - progress_bar.py[line:274] - INFO: epoch 002:   5069 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.9, wpb=101.1, bsz=40, num_updates=20820, lr=6.13472e-05, gnorm=0.6, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64422
2022-10-01 02:24:57 - progress_bar.py[line:274] - INFO: epoch 002:   5079 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=20830, lr=6.13366e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64433
2022-10-01 02:25:08 - progress_bar.py[line:274] - INFO: epoch 002:   5089 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.88, wpb=101.6, bsz=40, num_updates=20840, lr=6.1326e-05, gnorm=0.579, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64445
2022-10-01 02:25:20 - progress_bar.py[line:274] - INFO: epoch 002:   5099 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.2, ups=0.87, wpb=100.8, bsz=40, num_updates=20850, lr=6.13155e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64456
2022-10-01 02:25:31 - progress_bar.py[line:274] - INFO: epoch 002:   5109 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.8, ups=0.9, wpb=102.5, bsz=40, num_updates=20860, lr=6.13049e-05, gnorm=0.53, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64467
2022-10-01 02:25:42 - progress_bar.py[line:274] - INFO: epoch 002:   5119 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.89, wpb=102.4, bsz=40, num_updates=20870, lr=6.12944e-05, gnorm=0.579, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64479
2022-10-01 02:25:53 - progress_bar.py[line:274] - INFO: epoch 002:   5129 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.3, ups=0.9, wpb=103.1, bsz=40, num_updates=20880, lr=6.12838e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64490
2022-10-01 02:26:06 - progress_bar.py[line:274] - INFO: epoch 002:   5139 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=79.4, ups=0.79, wpb=100.3, bsz=40, num_updates=20890, lr=6.12732e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=64502
2022-10-01 02:26:18 - progress_bar.py[line:274] - INFO: epoch 002:   5149 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86, ups=0.85, wpb=101.7, bsz=40, num_updates=20900, lr=6.12627e-05, gnorm=0.544, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=64514
2022-10-01 02:26:29 - progress_bar.py[line:274] - INFO: epoch 002:   5159 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.89, wpb=101.6, bsz=40, num_updates=20910, lr=6.12521e-05, gnorm=0.571, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64526
2022-10-01 02:26:40 - progress_bar.py[line:274] - INFO: epoch 002:   5169 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.4, ups=0.93, wpb=100.8, bsz=40, num_updates=20920, lr=6.12416e-05, gnorm=0.517, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64536
2022-10-01 02:26:51 - progress_bar.py[line:274] - INFO: epoch 002:   5179 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.91, wpb=100.6, bsz=40, num_updates=20930, lr=6.1231e-05, gnorm=0.656, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64547
2022-10-01 02:27:02 - progress_bar.py[line:274] - INFO: epoch 002:   5189 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.88, wpb=102, bsz=40, num_updates=20940, lr=6.12204e-05, gnorm=0.624, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64559
2022-10-01 02:27:13 - progress_bar.py[line:274] - INFO: epoch 002:   5199 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.6, ups=0.89, wpb=102.4, bsz=40, num_updates=20950, lr=6.12099e-05, gnorm=0.509, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64570
2022-10-01 02:27:24 - progress_bar.py[line:274] - INFO: epoch 002:   5209 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.9, wpb=102.8, bsz=40, num_updates=20960, lr=6.11993e-05, gnorm=0.613, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64581
2022-10-01 02:27:35 - progress_bar.py[line:274] - INFO: epoch 002:   5219 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.6, ups=0.91, wpb=102.4, bsz=40, num_updates=20970, lr=6.11888e-05, gnorm=0.673, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64592
2022-10-01 02:27:47 - progress_bar.py[line:274] - INFO: epoch 002:   5229 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89, ups=0.88, wpb=101.4, bsz=40, num_updates=20980, lr=6.11782e-05, gnorm=0.63, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64604
2022-10-01 02:27:58 - progress_bar.py[line:274] - INFO: epoch 002:   5239 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.2, ups=0.89, wpb=103.8, bsz=40, num_updates=20990, lr=6.11677e-05, gnorm=0.519, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64615
2022-10-01 02:28:10 - progress_bar.py[line:274] - INFO: epoch 002:   5249 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.7, ups=0.88, wpb=103.3, bsz=40, num_updates=21000, lr=6.11571e-05, gnorm=0.552, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64626
2022-10-01 02:28:21 - progress_bar.py[line:274] - INFO: epoch 002:   5259 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.9, wpb=102, bsz=40, num_updates=21010, lr=6.11465e-05, gnorm=0.596, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64637
2022-10-01 02:28:32 - progress_bar.py[line:274] - INFO: epoch 002:   5269 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.9, wpb=101.2, bsz=40, num_updates=21020, lr=6.1136e-05, gnorm=0.572, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64648
2022-10-01 02:28:43 - progress_bar.py[line:274] - INFO: epoch 002:   5279 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.4, ups=0.88, wpb=101.8, bsz=40, num_updates=21030, lr=6.11254e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64660
2022-10-01 02:28:55 - progress_bar.py[line:274] - INFO: epoch 002:   5289 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.1, ups=0.88, wpb=102.9, bsz=40, num_updates=21040, lr=6.11149e-05, gnorm=0.592, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64671
2022-10-01 02:29:06 - progress_bar.py[line:274] - INFO: epoch 002:   5299 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.88, wpb=101.9, bsz=40, num_updates=21050, lr=6.11043e-05, gnorm=0.565, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64683
2022-10-01 02:29:17 - progress_bar.py[line:274] - INFO: epoch 002:   5309 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=21060, lr=6.10937e-05, gnorm=0.568, clip=0, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=64694
2022-10-01 02:29:22 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 02:29:30 - progress_bar.py[line:274] - INFO: epoch 002:   5320 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=79.4, ups=0.78, wpb=101.4, bsz=40, num_updates=21070, lr=6.10832e-05, gnorm=0.543, clip=0, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=64707
2022-10-01 02:29:41 - progress_bar.py[line:274] - INFO: epoch 002:   5330 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.88, wpb=102.2, bsz=40, num_updates=21080, lr=6.10726e-05, gnorm=0.536, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64718
2022-10-01 02:29:52 - progress_bar.py[line:274] - INFO: epoch 002:   5340 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.9, ups=0.9, wpb=103.1, bsz=40, num_updates=21090, lr=6.10621e-05, gnorm=0.478, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64729
2022-10-01 02:30:03 - progress_bar.py[line:274] - INFO: epoch 002:   5350 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.6, ups=0.91, wpb=100.6, bsz=40, num_updates=21100, lr=6.10515e-05, gnorm=0.565, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64740
2022-10-01 02:30:15 - progress_bar.py[line:274] - INFO: epoch 002:   5360 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.7, ups=0.9, wpb=102.1, bsz=40, num_updates=21110, lr=6.10409e-05, gnorm=0.504, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64751
2022-10-01 02:30:26 - progress_bar.py[line:274] - INFO: epoch 002:   5370 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.9, wpb=101.6, bsz=40, num_updates=21120, lr=6.10304e-05, gnorm=0.519, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64762
2022-10-01 02:30:37 - progress_bar.py[line:274] - INFO: epoch 002:   5380 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.8, ups=0.86, wpb=101.6, bsz=40, num_updates=21130, lr=6.10198e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=64774
2022-10-01 02:30:49 - progress_bar.py[line:274] - INFO: epoch 002:   5390 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.1, ups=0.87, wpb=100.5, bsz=40, num_updates=21140, lr=6.10093e-05, gnorm=0.585, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64786
2022-10-01 02:31:00 - progress_bar.py[line:274] - INFO: epoch 002:   5400 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=21150, lr=6.09987e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64797
2022-10-01 02:31:11 - progress_bar.py[line:274] - INFO: epoch 002:   5410 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.9, wpb=100.4, bsz=40, num_updates=21160, lr=6.09881e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64808
2022-10-01 02:31:22 - progress_bar.py[line:274] - INFO: epoch 002:   5420 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.6, bsz=40, num_updates=21170, lr=6.09776e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64819
2022-10-01 02:31:34 - progress_bar.py[line:274] - INFO: epoch 002:   5430 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.88, wpb=101, bsz=40, num_updates=21180, lr=6.0967e-05, gnorm=0.645, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64831
2022-10-01 02:31:45 - progress_bar.py[line:274] - INFO: epoch 002:   5440 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.89, wpb=100.4, bsz=40, num_updates=21190, lr=6.09565e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64842
2022-10-01 02:31:56 - progress_bar.py[line:274] - INFO: epoch 002:   5450 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.6, ups=0.89, wpb=99.8, bsz=40, num_updates=21200, lr=6.09459e-05, gnorm=0.602, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64853
2022-10-01 02:32:08 - progress_bar.py[line:274] - INFO: epoch 002:   5460 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.1, ups=0.88, wpb=100.6, bsz=40, num_updates=21210, lr=6.09353e-05, gnorm=0.605, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64865
2022-10-01 02:32:19 - progress_bar.py[line:274] - INFO: epoch 002:   5470 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.2, ups=0.88, wpb=100.6, bsz=40, num_updates=21220, lr=6.09248e-05, gnorm=0.667, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=64876
2022-10-01 02:32:30 - progress_bar.py[line:274] - INFO: epoch 002:   5480 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.1, ups=0.91, wpb=102, bsz=40, num_updates=21230, lr=6.09142e-05, gnorm=0.625, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64887
2022-10-01 02:32:42 - progress_bar.py[line:274] - INFO: epoch 002:   5490 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.88, wpb=102.2, bsz=40, num_updates=21240, lr=6.09037e-05, gnorm=0.636, clip=10, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=64898
2022-10-01 02:32:52 - progress_bar.py[line:274] - INFO: epoch 002:   5500 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.6, ups=0.94, wpb=99.7, bsz=40, num_updates=21250, lr=6.08931e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64909
2022-10-01 02:33:03 - progress_bar.py[line:274] - INFO: epoch 002:   5510 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91, ups=0.89, wpb=101.8, bsz=40, num_updates=21260, lr=6.08825e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64920
2022-10-01 02:33:15 - progress_bar.py[line:274] - INFO: epoch 002:   5520 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.89, wpb=102.4, bsz=40, num_updates=21270, lr=6.0872e-05, gnorm=0.494, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64931
2022-10-01 02:33:26 - progress_bar.py[line:274] - INFO: epoch 002:   5530 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.3, ups=0.88, wpb=100.9, bsz=40, num_updates=21280, lr=6.08614e-05, gnorm=0.602, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64943
2022-10-01 02:33:37 - progress_bar.py[line:274] - INFO: epoch 002:   5540 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.9, wpb=100.9, bsz=40, num_updates=21290, lr=6.08509e-05, gnorm=0.546, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64954
2022-10-01 02:33:48 - progress_bar.py[line:274] - INFO: epoch 002:   5550 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.1, ups=0.93, wpb=102.1, bsz=40, num_updates=21300, lr=6.08403e-05, gnorm=0.557, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64965
2022-10-01 02:33:59 - progress_bar.py[line:274] - INFO: epoch 002:   5560 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.9, wpb=100.5, bsz=40, num_updates=21310, lr=6.08297e-05, gnorm=0.584, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64976
2022-10-01 02:34:10 - progress_bar.py[line:274] - INFO: epoch 002:   5570 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.88, wpb=102.8, bsz=40, num_updates=21320, lr=6.08192e-05, gnorm=0.517, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64987
2022-10-01 02:34:22 - progress_bar.py[line:274] - INFO: epoch 002:   5580 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.6, ups=0.9, wpb=102, bsz=40, num_updates=21330, lr=6.08086e-05, gnorm=0.517, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64998
2022-10-01 02:34:33 - progress_bar.py[line:274] - INFO: epoch 002:   5590 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.9, ups=0.89, wpb=100.3, bsz=40, num_updates=21340, lr=6.07981e-05, gnorm=0.546, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65010
2022-10-01 02:34:44 - progress_bar.py[line:274] - INFO: epoch 002:   5600 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.1, ups=0.9, wpb=101.8, bsz=40, num_updates=21350, lr=6.07875e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65021
2022-10-01 02:34:55 - progress_bar.py[line:274] - INFO: epoch 002:   5610 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.89, wpb=102.5, bsz=40, num_updates=21360, lr=6.07769e-05, gnorm=0.601, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65032
2022-10-01 02:35:07 - progress_bar.py[line:274] - INFO: epoch 002:   5620 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=87.9, ups=0.88, wpb=99.7, bsz=40, num_updates=21370, lr=6.07664e-05, gnorm=0.463, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65043
2022-10-01 02:35:18 - progress_bar.py[line:274] - INFO: epoch 002:   5630 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.1, ups=0.85, wpb=101.6, bsz=40, num_updates=21380, lr=6.07558e-05, gnorm=0.634, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=65055
2022-10-01 02:35:30 - progress_bar.py[line:274] - INFO: epoch 002:   5640 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=86.1, ups=0.83, wpb=103.1, bsz=40, num_updates=21390, lr=6.07453e-05, gnorm=0.523, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=65067
2022-10-01 02:35:42 - progress_bar.py[line:274] - INFO: epoch 002:   5650 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.2, ups=0.87, wpb=101.1, bsz=40, num_updates=21400, lr=6.07347e-05, gnorm=0.551, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65079
2022-10-01 02:35:53 - progress_bar.py[line:274] - INFO: epoch 002:   5660 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.9, ups=0.89, wpb=99.7, bsz=40, num_updates=21410, lr=6.07241e-05, gnorm=0.605, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65090
2022-10-01 02:36:04 - progress_bar.py[line:274] - INFO: epoch 002:   5670 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=101.1, bsz=40, num_updates=21420, lr=6.07136e-05, gnorm=0.566, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65101
2022-10-01 02:36:16 - progress_bar.py[line:274] - INFO: epoch 002:   5680 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.88, wpb=101.1, bsz=40, num_updates=21430, lr=6.0703e-05, gnorm=0.58, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65112
2022-10-01 02:36:27 - progress_bar.py[line:274] - INFO: epoch 002:   5690 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.5, ups=0.87, wpb=103.2, bsz=40, num_updates=21440, lr=6.06925e-05, gnorm=0.514, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65124
2022-10-01 02:36:38 - progress_bar.py[line:274] - INFO: epoch 002:   5700 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.7, ups=0.91, wpb=102.8, bsz=40, num_updates=21450, lr=6.06819e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65135
2022-10-01 02:36:49 - progress_bar.py[line:274] - INFO: epoch 002:   5710 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.1, ups=0.89, wpb=99.3, bsz=40, num_updates=21460, lr=6.06713e-05, gnorm=0.629, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65146
2022-10-01 02:37:01 - progress_bar.py[line:274] - INFO: epoch 002:   5720 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=101.3, bsz=40, num_updates=21470, lr=6.06608e-05, gnorm=0.746, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65158
2022-10-01 02:37:12 - progress_bar.py[line:274] - INFO: epoch 002:   5730 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.3, ups=0.87, wpb=101.1, bsz=40, num_updates=21480, lr=6.06502e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65169
2022-10-01 02:37:24 - progress_bar.py[line:274] - INFO: epoch 002:   5740 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.89, wpb=102.6, bsz=40, num_updates=21490, lr=6.06397e-05, gnorm=0.593, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65180
2022-10-01 02:37:35 - progress_bar.py[line:274] - INFO: epoch 002:   5750 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.9, wpb=100.3, bsz=40, num_updates=21500, lr=6.06291e-05, gnorm=0.557, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=65191
2022-10-01 02:37:46 - progress_bar.py[line:274] - INFO: epoch 002:   5760 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.91, wpb=101.4, bsz=40, num_updates=21510, lr=6.06185e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65202
2022-10-01 02:37:57 - progress_bar.py[line:274] - INFO: epoch 002:   5770 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.91, wpb=102.2, bsz=40, num_updates=21520, lr=6.0608e-05, gnorm=0.536, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65213
2022-10-01 02:38:08 - progress_bar.py[line:274] - INFO: epoch 002:   5780 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.7, ups=0.88, wpb=99.5, bsz=40, num_updates=21530, lr=6.05974e-05, gnorm=0.731, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65225
2022-10-01 02:38:19 - progress_bar.py[line:274] - INFO: epoch 002:   5790 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=21540, lr=6.05869e-05, gnorm=0.511, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65236
2022-10-01 02:38:30 - progress_bar.py[line:274] - INFO: epoch 002:   5800 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=21550, lr=6.05763e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65247
2022-10-01 02:38:41 - progress_bar.py[line:274] - INFO: epoch 002:   5810 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=21560, lr=6.05657e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65258
2022-10-01 02:38:52 - progress_bar.py[line:274] - INFO: epoch 002:   5820 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.4, ups=0.92, wpb=101.1, bsz=40, num_updates=21570, lr=6.05552e-05, gnorm=0.67, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=65269
2022-10-01 02:39:03 - progress_bar.py[line:274] - INFO: epoch 002:   5830 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.88, wpb=100.7, bsz=40, num_updates=21580, lr=6.05446e-05, gnorm=0.529, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65280
2022-10-01 02:39:06 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 02:39:16 - progress_bar.py[line:274] - INFO: epoch 002:   5841 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=81.9, ups=0.82, wpb=99.7, bsz=40, num_updates=21590, lr=6.05341e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=65292
2022-10-01 02:39:27 - progress_bar.py[line:274] - INFO: epoch 002:   5851 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.89, wpb=101.7, bsz=40, num_updates=21600, lr=6.05235e-05, gnorm=0.62, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65304
2022-10-01 02:39:38 - progress_bar.py[line:274] - INFO: epoch 002:   5861 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.6, ups=0.89, wpb=101.9, bsz=40, num_updates=21610, lr=6.05129e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65315
2022-10-01 02:39:49 - progress_bar.py[line:274] - INFO: epoch 002:   5871 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.4, ups=0.88, wpb=103.3, bsz=40, num_updates=21620, lr=6.05024e-05, gnorm=0.491, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65326
2022-10-01 02:40:01 - progress_bar.py[line:274] - INFO: epoch 002:   5881 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.87, wpb=101.4, bsz=40, num_updates=21630, lr=6.04918e-05, gnorm=0.701, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65338
2022-10-01 02:40:13 - progress_bar.py[line:274] - INFO: epoch 002:   5891 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=84.6, ups=0.83, wpb=101.4, bsz=40, num_updates=21640, lr=6.04813e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=65350
2022-10-01 02:40:25 - progress_bar.py[line:274] - INFO: epoch 002:   5901 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=82, ups=0.82, wpb=100.4, bsz=40, num_updates=21650, lr=6.04707e-05, gnorm=0.581, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=65362
2022-10-01 02:40:37 - progress_bar.py[line:274] - INFO: epoch 002:   5911 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=84.8, ups=0.84, wpb=101.3, bsz=40, num_updates=21660, lr=6.04601e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=65374
2022-10-01 02:40:49 - progress_bar.py[line:274] - INFO: epoch 002:   5921 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=86.8, ups=0.86, wpb=101, bsz=40, num_updates=21670, lr=6.04496e-05, gnorm=0.562, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=65386
2022-10-01 02:41:00 - progress_bar.py[line:274] - INFO: epoch 002:   5931 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.9, wpb=101.2, bsz=40, num_updates=21680, lr=6.0439e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65397
2022-10-01 02:41:11 - progress_bar.py[line:274] - INFO: epoch 002:   5941 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.9, wpb=101.6, bsz=40, num_updates=21690, lr=6.04285e-05, gnorm=0.565, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65408
2022-10-01 02:41:22 - progress_bar.py[line:274] - INFO: epoch 002:   5951 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.4, ups=0.89, wpb=100.6, bsz=40, num_updates=21700, lr=6.04179e-05, gnorm=0.584, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65419
2022-10-01 02:41:34 - progress_bar.py[line:274] - INFO: epoch 002:   5961 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.1, ups=0.89, wpb=103.6, bsz=40, num_updates=21710, lr=6.04073e-05, gnorm=0.489, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65430
2022-10-01 02:41:45 - progress_bar.py[line:274] - INFO: epoch 002:   5971 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=101.3, bsz=40, num_updates=21720, lr=6.03968e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=65442
2022-10-01 02:41:56 - progress_bar.py[line:274] - INFO: epoch 002:   5981 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=21730, lr=6.03862e-05, gnorm=0.523, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=65453
2022-10-01 02:42:08 - progress_bar.py[line:274] - INFO: epoch 002:   5991 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87, ups=0.87, wpb=99.5, bsz=40, num_updates=21740, lr=6.03757e-05, gnorm=0.608, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65464
2022-10-01 02:42:19 - progress_bar.py[line:274] - INFO: epoch 002:   6001 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.9, wpb=100.9, bsz=40, num_updates=21750, lr=6.03651e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65475
2022-10-01 02:42:30 - progress_bar.py[line:274] - INFO: epoch 002:   6011 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=98.5, nsentences=40, sample_size=98.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.9, ups=0.89, wpb=98.5, bsz=40, num_updates=21760, lr=6.03545e-05, gnorm=0.626, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65487
2022-10-01 02:42:41 - progress_bar.py[line:274] - INFO: epoch 002:   6021 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=21770, lr=6.0344e-05, gnorm=0.609, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65498
2022-10-01 02:42:52 - progress_bar.py[line:274] - INFO: epoch 002:   6031 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.89, wpb=100.4, bsz=40, num_updates=21780, lr=6.03334e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65509
2022-10-01 02:43:04 - progress_bar.py[line:274] - INFO: epoch 002:   6041 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.9, wpb=101.5, bsz=40, num_updates=21790, lr=6.03229e-05, gnorm=0.51, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65520
2022-10-01 02:43:15 - progress_bar.py[line:274] - INFO: epoch 002:   6051 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.9, wpb=101.5, bsz=40, num_updates=21800, lr=6.03123e-05, gnorm=0.585, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65531
2022-10-01 02:43:26 - progress_bar.py[line:274] - INFO: epoch 002:   6061 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.1, ups=0.91, wpb=101.5, bsz=40, num_updates=21810, lr=6.03017e-05, gnorm=0.545, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=65542
2022-10-01 02:43:37 - progress_bar.py[line:274] - INFO: epoch 002:   6071 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.91, wpb=100.5, bsz=40, num_updates=21820, lr=6.02912e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65553
2022-10-01 02:43:48 - progress_bar.py[line:274] - INFO: epoch 002:   6081 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.6, ups=0.9, wpb=100, bsz=40, num_updates=21830, lr=6.02806e-05, gnorm=0.584, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65565
2022-10-01 02:43:59 - progress_bar.py[line:274] - INFO: epoch 002:   6091 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.9, wpb=101.4, bsz=40, num_updates=21840, lr=6.02701e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65576
2022-10-01 02:44:11 - progress_bar.py[line:274] - INFO: epoch 002:   6101 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.4, ups=0.86, wpb=100.1, bsz=40, num_updates=21850, lr=6.02595e-05, gnorm=0.582, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=65587
2022-10-01 02:44:22 - progress_bar.py[line:274] - INFO: epoch 002:   6111 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.89, wpb=99.1, bsz=40, num_updates=21860, lr=6.02489e-05, gnorm=0.589, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65599
2022-10-01 02:44:33 - progress_bar.py[line:274] - INFO: epoch 002:   6121 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.87, wpb=102.5, bsz=40, num_updates=21870, lr=6.02384e-05, gnorm=0.489, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65610
2022-10-01 02:44:45 - progress_bar.py[line:274] - INFO: epoch 002:   6131 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.89, wpb=101.9, bsz=40, num_updates=21880, lr=6.02278e-05, gnorm=0.517, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65621
2022-10-01 02:44:56 - progress_bar.py[line:274] - INFO: epoch 002:   6141 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.89, wpb=102.8, bsz=40, num_updates=21890, lr=6.02173e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65633
2022-10-01 02:45:07 - progress_bar.py[line:274] - INFO: epoch 002:   6151 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.1, ups=0.86, wpb=102.3, bsz=40, num_updates=21900, lr=6.02067e-05, gnorm=0.578, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=65644
2022-10-01 02:45:19 - progress_bar.py[line:274] - INFO: epoch 002:   6161 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.9, wpb=103.6, bsz=40, num_updates=21910, lr=6.01961e-05, gnorm=0.594, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65655
2022-10-01 02:45:30 - progress_bar.py[line:274] - INFO: epoch 002:   6171 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=100.3, bsz=40, num_updates=21920, lr=6.01856e-05, gnorm=0.621, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=65667
2022-10-01 02:45:41 - progress_bar.py[line:274] - INFO: epoch 002:   6181 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.87, wpb=102.2, bsz=40, num_updates=21930, lr=6.0175e-05, gnorm=0.588, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=65678
2022-10-01 02:45:53 - progress_bar.py[line:274] - INFO: epoch 002:   6191 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.88, wpb=102.1, bsz=40, num_updates=21940, lr=6.01645e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65689
2022-10-01 02:46:04 - progress_bar.py[line:274] - INFO: epoch 002:   6201 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.6, ups=0.86, wpb=101.5, bsz=40, num_updates=21950, lr=6.01539e-05, gnorm=0.604, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=65701
2022-10-01 02:46:16 - progress_bar.py[line:274] - INFO: epoch 002:   6211 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87, ups=0.87, wpb=99.4, bsz=40, num_updates=21960, lr=6.01433e-05, gnorm=0.463, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65712
2022-10-01 02:46:27 - progress_bar.py[line:274] - INFO: epoch 002:   6221 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.89, wpb=102.4, bsz=40, num_updates=21970, lr=6.01328e-05, gnorm=0.598, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65724
2022-10-01 02:46:38 - progress_bar.py[line:274] - INFO: epoch 002:   6231 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.7, ups=0.92, wpb=101.4, bsz=40, num_updates=21980, lr=6.01222e-05, gnorm=0.583, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65735
2022-10-01 02:46:49 - progress_bar.py[line:274] - INFO: epoch 002:   6241 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.88, wpb=101.3, bsz=40, num_updates=21990, lr=6.01117e-05, gnorm=0.505, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65746
2022-10-01 02:47:01 - progress_bar.py[line:274] - INFO: epoch 002:   6251 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88, ups=0.88, wpb=99.7, bsz=40, num_updates=22000, lr=6.01011e-05, gnorm=0.655, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65757
2022-10-01 02:47:12 - progress_bar.py[line:274] - INFO: epoch 002:   6261 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.6, ups=0.86, wpb=100.6, bsz=40, num_updates=22010, lr=6.00906e-05, gnorm=0.592, clip=0, loss_scale=1024, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=65769
2022-10-01 02:47:24 - progress_bar.py[line:274] - INFO: epoch 002:   6271 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.87, wpb=102.7, bsz=40, num_updates=22020, lr=6.008e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=65781
2022-10-01 02:47:35 - progress_bar.py[line:274] - INFO: epoch 002:   6281 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.89, wpb=102.5, bsz=40, num_updates=22030, lr=6.00694e-05, gnorm=0.572, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65792
2022-10-01 02:47:46 - progress_bar.py[line:274] - INFO: epoch 002:   6291 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.8, ups=0.91, wpb=103.4, bsz=40, num_updates=22040, lr=6.00589e-05, gnorm=0.519, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65803
2022-10-01 02:47:58 - progress_bar.py[line:274] - INFO: epoch 002:   6301 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87, ups=0.86, wpb=101, bsz=40, num_updates=22050, lr=6.00483e-05, gnorm=0.591, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=65814
2022-10-01 02:48:09 - progress_bar.py[line:274] - INFO: epoch 002:   6311 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.2, ups=0.88, wpb=100.1, bsz=40, num_updates=22060, lr=6.00378e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65826
2022-10-01 02:48:20 - progress_bar.py[line:274] - INFO: epoch 002:   6321 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.89, wpb=100.6, bsz=40, num_updates=22070, lr=6.00272e-05, gnorm=0.594, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65837
2022-10-01 02:48:31 - progress_bar.py[line:274] - INFO: epoch 002:   6331 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.91, wpb=101.4, bsz=40, num_updates=22080, lr=6.00166e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65848
2022-10-01 02:48:43 - progress_bar.py[line:274] - INFO: epoch 002:   6341 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=22090, lr=6.00061e-05, gnorm=0.6, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65859
2022-10-01 02:48:54 - progress_bar.py[line:274] - INFO: epoch 002:   6351 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.88, wpb=102, bsz=40, num_updates=22100, lr=5.99955e-05, gnorm=0.52, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65871
2022-10-01 02:48:58 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 02:49:06 - progress_bar.py[line:274] - INFO: epoch 002:   6362 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=83, ups=0.82, wpb=101.3, bsz=40, num_updates=22110, lr=5.9985e-05, gnorm=0.492, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=65883
2022-10-01 02:49:17 - progress_bar.py[line:274] - INFO: epoch 002:   6372 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.9, ups=0.92, wpb=102.7, bsz=40, num_updates=22120, lr=5.99744e-05, gnorm=0.581, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65894
2022-10-01 02:49:28 - progress_bar.py[line:274] - INFO: epoch 002:   6382 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.9, ups=0.87, wpb=100.2, bsz=40, num_updates=22130, lr=5.99638e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65905
2022-10-01 02:49:39 - progress_bar.py[line:274] - INFO: epoch 002:   6392 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.7, ups=0.92, wpb=101.7, bsz=40, num_updates=22140, lr=5.99533e-05, gnorm=0.486, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65916
2022-10-01 02:49:51 - progress_bar.py[line:274] - INFO: epoch 002:   6402 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=22150, lr=5.99427e-05, gnorm=0.492, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65927
2022-10-01 02:50:01 - progress_bar.py[line:274] - INFO: epoch 002:   6412 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.6, ups=0.91, wpb=100.4, bsz=40, num_updates=22160, lr=5.99322e-05, gnorm=0.577, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=65938
2022-10-01 02:50:13 - progress_bar.py[line:274] - INFO: epoch 002:   6422 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.88, wpb=101.1, bsz=40, num_updates=22170, lr=5.99216e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65950
2022-10-01 02:50:24 - progress_bar.py[line:274] - INFO: epoch 002:   6432 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.6, ups=0.91, wpb=101.1, bsz=40, num_updates=22180, lr=5.9911e-05, gnorm=0.609, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=65961
2022-10-01 02:50:35 - progress_bar.py[line:274] - INFO: epoch 002:   6442 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=22190, lr=5.99005e-05, gnorm=0.645, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65972
2022-10-01 02:50:46 - progress_bar.py[line:274] - INFO: epoch 002:   6452 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.88, wpb=101.9, bsz=40, num_updates=22200, lr=5.98899e-05, gnorm=0.576, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65983
2022-10-01 02:50:58 - progress_bar.py[line:274] - INFO: epoch 002:   6462 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.7, ups=0.88, wpb=101.3, bsz=40, num_updates=22210, lr=5.98794e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=65995
2022-10-01 02:51:09 - progress_bar.py[line:274] - INFO: epoch 002:   6472 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.91, wpb=101.6, bsz=40, num_updates=22220, lr=5.98688e-05, gnorm=0.601, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66006
2022-10-01 02:51:20 - progress_bar.py[line:274] - INFO: epoch 002:   6482 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.6, ups=0.88, wpb=101.1, bsz=40, num_updates=22230, lr=5.98582e-05, gnorm=0.539, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66017
2022-10-01 02:51:31 - progress_bar.py[line:274] - INFO: epoch 002:   6492 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.1, ups=0.91, wpb=101.5, bsz=40, num_updates=22240, lr=5.98477e-05, gnorm=0.628, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66028
2022-10-01 02:51:43 - progress_bar.py[line:274] - INFO: epoch 002:   6502 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.7, ups=0.89, wpb=101.6, bsz=40, num_updates=22250, lr=5.98371e-05, gnorm=0.601, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66039
2022-10-01 02:51:54 - progress_bar.py[line:274] - INFO: epoch 002:   6512 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.9, wpb=100.5, bsz=40, num_updates=22260, lr=5.98266e-05, gnorm=0.567, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66050
2022-10-01 02:52:05 - progress_bar.py[line:274] - INFO: epoch 002:   6522 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.9, wpb=101.6, bsz=40, num_updates=22270, lr=5.9816e-05, gnorm=0.585, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66062
2022-10-01 02:52:16 - progress_bar.py[line:274] - INFO: epoch 002:   6532 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.2, ups=0.91, wpb=102.1, bsz=40, num_updates=22280, lr=5.98054e-05, gnorm=0.654, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66072
2022-10-01 02:52:27 - progress_bar.py[line:274] - INFO: epoch 002:   6542 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.9, wpb=100.9, bsz=40, num_updates=22290, lr=5.97949e-05, gnorm=0.611, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66084
2022-10-01 02:52:38 - progress_bar.py[line:274] - INFO: epoch 002:   6552 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.8, ups=0.87, wpb=100.4, bsz=40, num_updates=22300, lr=5.97843e-05, gnorm=0.577, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66095
2022-10-01 02:52:50 - progress_bar.py[line:274] - INFO: epoch 002:   6562 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=22310, lr=5.97738e-05, gnorm=0.577, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66106
2022-10-01 02:53:01 - progress_bar.py[line:274] - INFO: epoch 002:   6572 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.2, ups=0.88, wpb=101.9, bsz=40, num_updates=22320, lr=5.97632e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66118
2022-10-01 02:53:12 - progress_bar.py[line:274] - INFO: epoch 002:   6582 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.9, wpb=100.5, bsz=40, num_updates=22330, lr=5.97526e-05, gnorm=0.565, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66129
2022-10-01 02:53:23 - progress_bar.py[line:274] - INFO: epoch 002:   6592 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.88, wpb=103.3, bsz=40, num_updates=22340, lr=5.97421e-05, gnorm=0.529, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66140
2022-10-01 02:53:34 - progress_bar.py[line:274] - INFO: epoch 002:   6602 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.2, ups=0.91, wpb=101, bsz=40, num_updates=22350, lr=5.97315e-05, gnorm=0.502, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66151
2022-10-01 02:53:46 - progress_bar.py[line:274] - INFO: epoch 002:   6612 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.5, ups=0.87, wpb=102.6, bsz=40, num_updates=22360, lr=5.9721e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66163
2022-10-01 02:53:57 - progress_bar.py[line:274] - INFO: epoch 002:   6622 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93, ups=0.93, wpb=100.1, bsz=40, num_updates=22370, lr=5.97104e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66173
2022-10-01 02:54:08 - progress_bar.py[line:274] - INFO: epoch 002:   6632 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.9, ups=0.92, wpb=102.2, bsz=40, num_updates=22380, lr=5.96998e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66184
2022-10-01 02:54:19 - progress_bar.py[line:274] - INFO: epoch 002:   6642 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.5, ups=0.87, wpb=102.8, bsz=40, num_updates=22390, lr=5.96893e-05, gnorm=0.539, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66196
2022-10-01 02:54:30 - progress_bar.py[line:274] - INFO: epoch 002:   6652 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.87, wpb=103, bsz=40, num_updates=22400, lr=5.96787e-05, gnorm=0.569, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66207
2022-10-01 02:54:42 - progress_bar.py[line:274] - INFO: epoch 002:   6662 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.9, wpb=100, bsz=40, num_updates=22410, lr=5.96682e-05, gnorm=0.572, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66218
2022-10-01 02:54:53 - progress_bar.py[line:274] - INFO: epoch 002:   6672 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.89, wpb=100.7, bsz=40, num_updates=22420, lr=5.96576e-05, gnorm=0.539, clip=0, loss_scale=1024, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=66230
2022-10-01 02:55:04 - progress_bar.py[line:274] - INFO: epoch 002:   6682 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.89, wpb=101.8, bsz=40, num_updates=22430, lr=5.9647e-05, gnorm=0.527, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66241
2022-10-01 02:55:15 - progress_bar.py[line:274] - INFO: epoch 002:   6692 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=101.2, bsz=40, num_updates=22440, lr=5.96365e-05, gnorm=0.601, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66252
2022-10-01 02:55:27 - progress_bar.py[line:274] - INFO: epoch 002:   6702 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.89, wpb=101.1, bsz=40, num_updates=22450, lr=5.96259e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=66263
2022-10-01 02:55:38 - progress_bar.py[line:274] - INFO: epoch 002:   6712 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.8, ups=0.88, wpb=99.4, bsz=40, num_updates=22460, lr=5.96154e-05, gnorm=0.635, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66275
2022-10-01 02:55:49 - progress_bar.py[line:274] - INFO: epoch 002:   6722 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=22470, lr=5.96048e-05, gnorm=0.536, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66286
2022-10-01 02:56:00 - progress_bar.py[line:274] - INFO: epoch 002:   6732 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=100.9, bsz=40, num_updates=22480, lr=5.95942e-05, gnorm=0.528, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66297
2022-10-01 02:56:11 - progress_bar.py[line:274] - INFO: epoch 002:   6742 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.91, wpb=102.4, bsz=40, num_updates=22490, lr=5.95837e-05, gnorm=0.607, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66308
2022-10-01 02:56:22 - progress_bar.py[line:274] - INFO: epoch 002:   6752 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92, ups=0.9, wpb=102.3, bsz=40, num_updates=22500, lr=5.95731e-05, gnorm=0.505, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=66319
2022-10-01 02:56:34 - progress_bar.py[line:274] - INFO: epoch 002:   6762 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.89, wpb=100.3, bsz=40, num_updates=22510, lr=5.95626e-05, gnorm=0.539, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66330
2022-10-01 02:56:44 - progress_bar.py[line:274] - INFO: epoch 002:   6772 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.1, ups=0.93, wpb=101.1, bsz=40, num_updates=22520, lr=5.9552e-05, gnorm=0.566, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66341
2022-10-01 02:56:56 - progress_bar.py[line:274] - INFO: epoch 002:   6782 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.7, ups=0.89, wpb=100.1, bsz=40, num_updates=22530, lr=5.95414e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66352
2022-10-01 02:57:07 - progress_bar.py[line:274] - INFO: epoch 002:   6792 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.7, ups=0.88, wpb=99.6, bsz=40, num_updates=22540, lr=5.95309e-05, gnorm=0.564, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66364
2022-10-01 02:57:18 - progress_bar.py[line:274] - INFO: epoch 002:   6802 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94, ups=0.92, wpb=102.7, bsz=40, num_updates=22550, lr=5.95203e-05, gnorm=0.514, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66375
2022-10-01 02:57:29 - progress_bar.py[line:274] - INFO: epoch 002:   6812 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.91, wpb=101.9, bsz=40, num_updates=22560, lr=5.95098e-05, gnorm=0.585, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66386
2022-10-01 02:57:40 - progress_bar.py[line:274] - INFO: epoch 002:   6822 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.88, wpb=102.2, bsz=40, num_updates=22570, lr=5.94992e-05, gnorm=0.613, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66397
2022-10-01 02:57:52 - progress_bar.py[line:274] - INFO: epoch 002:   6832 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.1, ups=0.89, wpb=101, bsz=40, num_updates=22580, lr=5.94886e-05, gnorm=0.56, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66408
2022-10-01 02:58:04 - progress_bar.py[line:274] - INFO: epoch 002:   6842 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=84.6, ups=0.81, wpb=104, bsz=40, num_updates=22590, lr=5.94781e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=66421
2022-10-01 02:58:16 - progress_bar.py[line:274] - INFO: epoch 002:   6852 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=85.8, ups=0.84, wpb=102.6, bsz=40, num_updates=22600, lr=5.94675e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=66433
2022-10-01 02:58:27 - progress_bar.py[line:274] - INFO: epoch 002:   6862 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.1, ups=0.87, wpb=99.9, bsz=40, num_updates=22610, lr=5.9457e-05, gnorm=0.58, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66444
2022-10-01 02:58:36 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 02:58:39 - progress_bar.py[line:274] - INFO: epoch 002:   6873 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=84.1, ups=0.84, wpb=100.7, bsz=40, num_updates=22620, lr=5.94464e-05, gnorm=0.661, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=66456
2022-10-01 02:58:51 - progress_bar.py[line:274] - INFO: epoch 002:   6883 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.5, ups=0.86, wpb=100.3, bsz=40, num_updates=22630, lr=5.94358e-05, gnorm=0.537, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=66468
2022-10-01 02:59:02 - progress_bar.py[line:274] - INFO: epoch 002:   6893 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=101.2, bsz=40, num_updates=22640, lr=5.94253e-05, gnorm=0.568, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66479
2022-10-01 02:59:14 - progress_bar.py[line:274] - INFO: epoch 002:   6903 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.6, ups=0.87, wpb=100.3, bsz=40, num_updates=22650, lr=5.94147e-05, gnorm=0.502, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66491
2022-10-01 02:59:25 - progress_bar.py[line:274] - INFO: epoch 002:   6913 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88, ups=0.87, wpb=100.8, bsz=40, num_updates=22660, lr=5.94042e-05, gnorm=0.575, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66502
2022-10-01 02:59:36 - progress_bar.py[line:274] - INFO: epoch 002:   6923 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.3, ups=0.91, wpb=101.8, bsz=40, num_updates=22670, lr=5.93936e-05, gnorm=0.611, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66513
2022-10-01 02:59:47 - progress_bar.py[line:274] - INFO: epoch 002:   6933 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.9, wpb=100.7, bsz=40, num_updates=22680, lr=5.9383e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66524
2022-10-01 02:59:59 - progress_bar.py[line:274] - INFO: epoch 002:   6943 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.88, wpb=101.5, bsz=40, num_updates=22690, lr=5.93725e-05, gnorm=0.636, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66536
2022-10-01 03:00:10 - progress_bar.py[line:274] - INFO: epoch 002:   6953 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.9, ups=0.92, wpb=102.2, bsz=40, num_updates=22700, lr=5.93619e-05, gnorm=0.606, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66546
2022-10-01 03:00:21 - progress_bar.py[line:274] - INFO: epoch 002:   6963 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.4, ups=0.87, wpb=101.4, bsz=40, num_updates=22710, lr=5.93514e-05, gnorm=0.552, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66558
2022-10-01 03:00:33 - progress_bar.py[line:274] - INFO: epoch 002:   6973 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.1, ups=0.86, wpb=102, bsz=40, num_updates=22720, lr=5.93408e-05, gnorm=0.456, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=66570
2022-10-01 03:00:44 - progress_bar.py[line:274] - INFO: epoch 002:   6983 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.9, wpb=99.9, bsz=40, num_updates=22730, lr=5.93302e-05, gnorm=0.587, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66581
2022-10-01 03:00:56 - progress_bar.py[line:274] - INFO: epoch 002:   6993 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.3, ups=0.86, wpb=101.8, bsz=40, num_updates=22740, lr=5.93197e-05, gnorm=0.568, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=66592
2022-10-01 03:01:07 - progress_bar.py[line:274] - INFO: epoch 002:   7003 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.9, wpb=102.6, bsz=40, num_updates=22750, lr=5.93091e-05, gnorm=0.524, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66604
2022-10-01 03:01:18 - progress_bar.py[line:274] - INFO: epoch 002:   7013 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.7, ups=0.9, wpb=102.3, bsz=40, num_updates=22760, lr=5.92986e-05, gnorm=0.623, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66615
2022-10-01 03:01:29 - progress_bar.py[line:274] - INFO: epoch 002:   7023 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.1, ups=0.89, wpb=100.5, bsz=40, num_updates=22770, lr=5.9288e-05, gnorm=0.538, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66626
2022-10-01 03:01:41 - progress_bar.py[line:274] - INFO: epoch 002:   7033 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.1, ups=0.87, wpb=100.1, bsz=40, num_updates=22780, lr=5.92774e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66637
2022-10-01 03:01:52 - progress_bar.py[line:274] - INFO: epoch 002:   7043 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.3, ups=0.86, wpb=102.5, bsz=40, num_updates=22790, lr=5.92669e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=66649
2022-10-01 03:02:03 - progress_bar.py[line:274] - INFO: epoch 002:   7053 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.6, ups=0.92, wpb=101.3, bsz=40, num_updates=22800, lr=5.92563e-05, gnorm=0.626, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66660
2022-10-01 03:02:14 - progress_bar.py[line:274] - INFO: epoch 002:   7063 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.9, ups=0.89, wpb=99.1, bsz=40, num_updates=22810, lr=5.92458e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66671
2022-10-01 03:02:26 - progress_bar.py[line:274] - INFO: epoch 002:   7073 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.2, ups=0.87, wpb=99.7, bsz=40, num_updates=22820, lr=5.92352e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66683
2022-10-01 03:02:37 - progress_bar.py[line:274] - INFO: epoch 002:   7083 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.9, wpb=99.4, bsz=40, num_updates=22830, lr=5.92246e-05, gnorm=0.582, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66694
2022-10-01 03:02:48 - progress_bar.py[line:274] - INFO: epoch 002:   7093 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.87, wpb=101.4, bsz=40, num_updates=22840, lr=5.92141e-05, gnorm=0.585, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66705
2022-10-01 03:03:00 - progress_bar.py[line:274] - INFO: epoch 002:   7103 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89, ups=0.88, wpb=101.6, bsz=40, num_updates=22850, lr=5.92035e-05, gnorm=0.552, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66717
2022-10-01 03:03:11 - progress_bar.py[line:274] - INFO: epoch 002:   7113 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.4, ups=0.87, wpb=100.8, bsz=40, num_updates=22860, lr=5.9193e-05, gnorm=0.543, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66728
2022-10-01 03:03:23 - progress_bar.py[line:274] - INFO: epoch 002:   7123 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.7, ups=0.88, wpb=100.6, bsz=40, num_updates=22870, lr=5.91824e-05, gnorm=0.506, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66739
2022-10-01 03:03:34 - progress_bar.py[line:274] - INFO: epoch 002:   7133 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.7, ups=0.87, wpb=101.4, bsz=40, num_updates=22880, lr=5.91718e-05, gnorm=0.527, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66751
2022-10-01 03:03:45 - progress_bar.py[line:274] - INFO: epoch 002:   7143 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=22890, lr=5.91613e-05, gnorm=0.515, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66762
2022-10-01 03:03:56 - progress_bar.py[line:274] - INFO: epoch 002:   7153 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.4, ups=0.92, wpb=103.4, bsz=40, num_updates=22900, lr=5.91507e-05, gnorm=0.528, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66773
2022-10-01 03:04:08 - progress_bar.py[line:274] - INFO: epoch 002:   7163 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=86.7, ups=0.86, wpb=100.5, bsz=40, num_updates=22910, lr=5.91402e-05, gnorm=0.646, clip=10, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=66785
2022-10-01 03:04:19 - progress_bar.py[line:274] - INFO: epoch 002:   7173 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.9, wpb=100, bsz=40, num_updates=22920, lr=5.91296e-05, gnorm=0.544, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66796
2022-10-01 03:04:30 - progress_bar.py[line:274] - INFO: epoch 002:   7183 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=22930, lr=5.9119e-05, gnorm=0.592, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66807
2022-10-01 03:04:41 - progress_bar.py[line:274] - INFO: epoch 002:   7193 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.4, ups=0.92, wpb=100.9, bsz=40, num_updates=22940, lr=5.91085e-05, gnorm=0.662, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66818
2022-10-01 03:04:52 - progress_bar.py[line:274] - INFO: epoch 002:   7203 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.89, wpb=99.9, bsz=40, num_updates=22950, lr=5.90979e-05, gnorm=0.683, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66829
2022-10-01 03:05:04 - progress_bar.py[line:274] - INFO: epoch 002:   7213 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.9, wpb=100.8, bsz=40, num_updates=22960, lr=5.90874e-05, gnorm=0.674, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66840
2022-10-01 03:05:15 - progress_bar.py[line:274] - INFO: epoch 002:   7223 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.91, wpb=100.1, bsz=40, num_updates=22970, lr=5.90768e-05, gnorm=0.567, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66851
2022-10-01 03:05:26 - progress_bar.py[line:274] - INFO: epoch 002:   7233 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91, ups=0.88, wpb=103.6, bsz=40, num_updates=22980, lr=5.90662e-05, gnorm=0.485, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66863
2022-10-01 03:05:37 - progress_bar.py[line:274] - INFO: epoch 002:   7243 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.88, wpb=101.8, bsz=40, num_updates=22990, lr=5.90557e-05, gnorm=0.592, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66874
2022-10-01 03:05:48 - progress_bar.py[line:274] - INFO: epoch 002:   7253 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.9, wpb=100.5, bsz=40, num_updates=23000, lr=5.90451e-05, gnorm=0.523, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=66885
2022-10-01 03:05:59 - progress_bar.py[line:274] - INFO: epoch 002:   7263 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.7, ups=0.92, wpb=101.4, bsz=40, num_updates=23010, lr=5.90346e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66896
2022-10-01 03:06:11 - progress_bar.py[line:274] - INFO: epoch 002:   7273 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.88, wpb=101.1, bsz=40, num_updates=23020, lr=5.9024e-05, gnorm=0.594, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66907
2022-10-01 03:06:22 - progress_bar.py[line:274] - INFO: epoch 002:   7283 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.9, ups=0.88, wpb=100, bsz=40, num_updates=23030, lr=5.90135e-05, gnorm=0.535, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66919
2022-10-01 03:06:33 - progress_bar.py[line:274] - INFO: epoch 002:   7293 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=23040, lr=5.90029e-05, gnorm=0.491, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66930
2022-10-01 03:06:45 - progress_bar.py[line:274] - INFO: epoch 002:   7303 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.89, wpb=101.7, bsz=40, num_updates=23050, lr=5.89923e-05, gnorm=0.592, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66941
2022-10-01 03:06:55 - progress_bar.py[line:274] - INFO: epoch 002:   7313 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.9, ups=0.93, wpb=101.2, bsz=40, num_updates=23060, lr=5.89818e-05, gnorm=0.516, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66952
2022-10-01 03:07:07 - progress_bar.py[line:274] - INFO: epoch 002:   7323 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.1, ups=0.86, wpb=100.8, bsz=40, num_updates=23070, lr=5.89712e-05, gnorm=0.525, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=66964
2022-10-01 03:07:18 - progress_bar.py[line:274] - INFO: epoch 002:   7333 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.9, ups=0.88, wpb=100.3, bsz=40, num_updates=23080, lr=5.89607e-05, gnorm=0.537, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66975
2022-10-01 03:07:30 - progress_bar.py[line:274] - INFO: epoch 002:   7343 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.5, ups=0.88, wpb=101.7, bsz=40, num_updates=23090, lr=5.89501e-05, gnorm=0.583, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66986
2022-10-01 03:07:41 - progress_bar.py[line:274] - INFO: epoch 002:   7353 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93, ups=0.91, wpb=102.5, bsz=40, num_updates=23100, lr=5.89395e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=66997
2022-10-01 03:07:52 - progress_bar.py[line:274] - INFO: epoch 002:   7363 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.89, wpb=100.5, bsz=40, num_updates=23110, lr=5.8929e-05, gnorm=0.699, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67009
2022-10-01 03:08:03 - progress_bar.py[line:274] - INFO: epoch 002:   7373 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.88, wpb=102.3, bsz=40, num_updates=23120, lr=5.89184e-05, gnorm=0.527, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67020
2022-10-01 03:08:15 - progress_bar.py[line:274] - INFO: epoch 002:   7383 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.7, ups=0.86, wpb=101.4, bsz=40, num_updates=23130, lr=5.89079e-05, gnorm=0.486, clip=0, loss_scale=2048, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=67032
2022-10-01 03:08:26 - progress_bar.py[line:274] - INFO: epoch 002:   7393 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.5, ups=0.91, wpb=101.4, bsz=40, num_updates=23140, lr=5.88973e-05, gnorm=0.512, clip=0, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67043
2022-10-01 03:08:35 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 03:08:38 - progress_bar.py[line:274] - INFO: epoch 002:   7404 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=84.5, ups=0.83, wpb=101.4, bsz=40, num_updates=23150, lr=5.88867e-05, gnorm=0.449, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=67055
2022-10-01 03:08:49 - progress_bar.py[line:274] - INFO: epoch 002:   7414 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.9, wpb=100.8, bsz=40, num_updates=23160, lr=5.88762e-05, gnorm=0.484, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67066
2022-10-01 03:09:00 - progress_bar.py[line:274] - INFO: epoch 002:   7424 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.9, wpb=100, bsz=40, num_updates=23170, lr=5.88656e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67077
2022-10-01 03:09:11 - progress_bar.py[line:274] - INFO: epoch 002:   7434 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.91, wpb=101.5, bsz=40, num_updates=23180, lr=5.88551e-05, gnorm=0.476, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67088
2022-10-01 03:09:22 - progress_bar.py[line:274] - INFO: epoch 002:   7444 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.7, ups=0.91, wpb=101.9, bsz=40, num_updates=23190, lr=5.88445e-05, gnorm=0.562, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67099
2022-10-01 03:09:33 - progress_bar.py[line:274] - INFO: epoch 002:   7454 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.8, ups=0.89, wpb=99.9, bsz=40, num_updates=23200, lr=5.88339e-05, gnorm=0.546, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67110
2022-10-01 03:09:45 - progress_bar.py[line:274] - INFO: epoch 002:   7464 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.89, wpb=102.3, bsz=40, num_updates=23210, lr=5.88234e-05, gnorm=0.577, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67121
2022-10-01 03:09:56 - progress_bar.py[line:274] - INFO: epoch 002:   7474 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.4, ups=0.88, wpb=100.6, bsz=40, num_updates=23220, lr=5.88128e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67133
2022-10-01 03:10:07 - progress_bar.py[line:274] - INFO: epoch 002:   7484 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.9, wpb=100.8, bsz=40, num_updates=23230, lr=5.88023e-05, gnorm=0.596, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67144
2022-10-01 03:10:18 - progress_bar.py[line:274] - INFO: epoch 002:   7494 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.9, wpb=102.2, bsz=40, num_updates=23240, lr=5.87917e-05, gnorm=0.558, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67155
2022-10-01 03:10:29 - progress_bar.py[line:274] - INFO: epoch 002:   7504 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.3, ups=0.9, wpb=103.9, bsz=40, num_updates=23250, lr=5.87811e-05, gnorm=0.57, clip=0, loss_scale=1024, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=67166
2022-10-01 03:10:41 - progress_bar.py[line:274] - INFO: epoch 002:   7514 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.89, wpb=100.4, bsz=40, num_updates=23260, lr=5.87706e-05, gnorm=0.525, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67177
2022-10-01 03:10:52 - progress_bar.py[line:274] - INFO: epoch 002:   7524 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=23270, lr=5.876e-05, gnorm=0.499, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67189
2022-10-01 03:11:04 - progress_bar.py[line:274] - INFO: epoch 002:   7534 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.6, ups=0.87, wpb=100.3, bsz=40, num_updates=23280, lr=5.87495e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67200
2022-10-01 03:11:15 - progress_bar.py[line:274] - INFO: epoch 002:   7544 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.89, wpb=101.8, bsz=40, num_updates=23290, lr=5.87389e-05, gnorm=0.502, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67212
2022-10-01 03:11:26 - progress_bar.py[line:274] - INFO: epoch 002:   7554 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.9, wpb=101.3, bsz=40, num_updates=23300, lr=5.87283e-05, gnorm=0.516, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67223
2022-10-01 03:11:37 - progress_bar.py[line:274] - INFO: epoch 002:   7564 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.88, wpb=102.5, bsz=40, num_updates=23310, lr=5.87178e-05, gnorm=0.541, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67234
2022-10-01 03:11:49 - progress_bar.py[line:274] - INFO: epoch 002:   7574 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.9, wpb=102.4, bsz=40, num_updates=23320, lr=5.87072e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67245
2022-10-01 03:12:00 - progress_bar.py[line:274] - INFO: epoch 002:   7584 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.1, ups=0.86, wpb=101.4, bsz=40, num_updates=23330, lr=5.86967e-05, gnorm=0.521, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=67257
2022-10-01 03:12:11 - progress_bar.py[line:274] - INFO: epoch 002:   7594 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.5, ups=0.92, wpb=102, bsz=40, num_updates=23340, lr=5.86861e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67268
2022-10-01 03:12:22 - progress_bar.py[line:274] - INFO: epoch 002:   7604 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.2, ups=0.88, wpb=100.4, bsz=40, num_updates=23350, lr=5.86755e-05, gnorm=0.542, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67279
2022-10-01 03:12:33 - progress_bar.py[line:274] - INFO: epoch 002:   7614 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.3, ups=0.92, wpb=102.9, bsz=40, num_updates=23360, lr=5.8665e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67290
2022-10-01 03:12:45 - progress_bar.py[line:274] - INFO: epoch 002:   7624 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.6, ups=0.86, wpb=100.3, bsz=40, num_updates=23370, lr=5.86544e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=67302
2022-10-01 03:12:56 - progress_bar.py[line:274] - INFO: epoch 002:   7634 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.89, wpb=101.9, bsz=40, num_updates=23380, lr=5.86439e-05, gnorm=0.529, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67313
2022-10-01 03:13:07 - progress_bar.py[line:274] - INFO: epoch 002:   7644 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.7, ups=0.91, wpb=102.7, bsz=40, num_updates=23390, lr=5.86333e-05, gnorm=0.441, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67324
2022-10-01 03:13:18 - progress_bar.py[line:274] - INFO: epoch 002:   7654 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.6, ups=0.9, wpb=102.6, bsz=40, num_updates=23400, lr=5.86227e-05, gnorm=0.527, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67335
2022-10-01 03:13:30 - progress_bar.py[line:274] - INFO: epoch 002:   7664 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.89, wpb=102.6, bsz=40, num_updates=23410, lr=5.86122e-05, gnorm=0.523, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67346
2022-10-01 03:13:41 - progress_bar.py[line:274] - INFO: epoch 002:   7674 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.4, ups=0.91, wpb=101.4, bsz=40, num_updates=23420, lr=5.86016e-05, gnorm=0.498, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67357
2022-10-01 03:13:51 - progress_bar.py[line:274] - INFO: epoch 002:   7684 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.91, wpb=100.6, bsz=40, num_updates=23430, lr=5.85911e-05, gnorm=0.535, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67368
2022-10-01 03:14:02 - progress_bar.py[line:274] - INFO: epoch 002:   7694 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.1, ups=0.91, wpb=102.1, bsz=40, num_updates=23440, lr=5.85805e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67379
2022-10-01 03:14:14 - progress_bar.py[line:274] - INFO: epoch 002:   7704 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.2, ups=0.88, wpb=100.3, bsz=40, num_updates=23450, lr=5.85699e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67391
2022-10-01 03:14:25 - progress_bar.py[line:274] - INFO: epoch 002:   7714 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.89, wpb=102.2, bsz=40, num_updates=23460, lr=5.85594e-05, gnorm=0.57, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67402
2022-10-01 03:14:36 - progress_bar.py[line:274] - INFO: epoch 002:   7724 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.6, ups=0.91, wpb=101.8, bsz=40, num_updates=23470, lr=5.85488e-05, gnorm=0.512, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67413
2022-10-01 03:14:47 - progress_bar.py[line:274] - INFO: epoch 002:   7734 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.9, wpb=99.7, bsz=40, num_updates=23480, lr=5.85383e-05, gnorm=0.59, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67424
2022-10-01 03:14:58 - progress_bar.py[line:274] - INFO: epoch 002:   7744 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.89, wpb=104, bsz=40, num_updates=23490, lr=5.85277e-05, gnorm=0.502, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67435
2022-10-01 03:15:10 - progress_bar.py[line:274] - INFO: epoch 002:   7754 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.9, wpb=101, bsz=40, num_updates=23500, lr=5.85171e-05, gnorm=0.644, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67446
2022-10-01 03:15:21 - progress_bar.py[line:274] - INFO: epoch 002:   7764 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.2, ups=0.89, wpb=100.2, bsz=40, num_updates=23510, lr=5.85066e-05, gnorm=0.58, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67458
2022-10-01 03:15:33 - progress_bar.py[line:274] - INFO: epoch 002:   7774 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87, ups=0.85, wpb=101.8, bsz=40, num_updates=23520, lr=5.8496e-05, gnorm=0.555, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=67469
2022-10-01 03:15:44 - progress_bar.py[line:274] - INFO: epoch 002:   7784 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=85, ups=0.84, wpb=100.9, bsz=40, num_updates=23530, lr=5.84855e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=67481
2022-10-01 03:15:56 - progress_bar.py[line:274] - INFO: epoch 002:   7794 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88, ups=0.88, wpb=100, bsz=40, num_updates=23540, lr=5.84749e-05, gnorm=0.624, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67492
2022-10-01 03:16:07 - progress_bar.py[line:274] - INFO: epoch 002:   7804 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=23550, lr=5.84643e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67504
2022-10-01 03:16:18 - progress_bar.py[line:274] - INFO: epoch 002:   7814 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.3, ups=0.88, wpb=100.4, bsz=40, num_updates=23560, lr=5.84538e-05, gnorm=0.596, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67515
2022-10-01 03:16:30 - progress_bar.py[line:274] - INFO: epoch 002:   7824 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=101.6, bsz=40, num_updates=23570, lr=5.84432e-05, gnorm=0.589, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67526
2022-10-01 03:16:40 - progress_bar.py[line:274] - INFO: epoch 002:   7834 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.5, ups=0.93, wpb=101.6, bsz=40, num_updates=23580, lr=5.84327e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=67537
2022-10-01 03:16:52 - progress_bar.py[line:274] - INFO: epoch 002:   7844 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.8, ups=0.87, wpb=101.8, bsz=40, num_updates=23590, lr=5.84221e-05, gnorm=0.522, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67549
2022-10-01 03:17:03 - progress_bar.py[line:274] - INFO: epoch 002:   7854 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.9, wpb=100.1, bsz=40, num_updates=23600, lr=5.84115e-05, gnorm=0.503, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67560
2022-10-01 03:17:14 - progress_bar.py[line:274] - INFO: epoch 002:   7864 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.3, ups=0.88, wpb=99.7, bsz=40, num_updates=23610, lr=5.8401e-05, gnorm=0.513, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67571
2022-10-01 03:17:26 - progress_bar.py[line:274] - INFO: epoch 002:   7874 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.6, ups=0.9, wpb=101.7, bsz=40, num_updates=23620, lr=5.83904e-05, gnorm=0.537, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67582
2022-10-01 03:17:37 - progress_bar.py[line:274] - INFO: epoch 002:   7884 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.9, wpb=100.7, bsz=40, num_updates=23630, lr=5.83799e-05, gnorm=0.477, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67593
2022-10-01 03:17:48 - progress_bar.py[line:274] - INFO: epoch 002:   7894 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=23640, lr=5.83693e-05, gnorm=0.514, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67605
2022-10-01 03:17:59 - progress_bar.py[line:274] - INFO: epoch 002:   7904 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.89, wpb=102.2, bsz=40, num_updates=23650, lr=5.83587e-05, gnorm=0.61, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67616
2022-10-01 03:18:10 - progress_bar.py[line:274] - INFO: epoch 002:   7914 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.89, wpb=103.4, bsz=40, num_updates=23660, lr=5.83482e-05, gnorm=0.518, clip=0, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67627
2022-10-01 03:18:14 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-01 03:18:23 - progress_bar.py[line:274] - INFO: epoch 002:   7925 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=83.8, ups=0.83, wpb=101.2, bsz=40, num_updates=23670, lr=5.83376e-05, gnorm=0.527, clip=0, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=67639
2022-10-01 03:18:34 - progress_bar.py[line:274] - INFO: epoch 002:   7935 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.87, wpb=102.9, bsz=40, num_updates=23680, lr=5.83271e-05, gnorm=0.618, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67651
2022-10-01 03:18:45 - progress_bar.py[line:274] - INFO: epoch 002:   7945 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.5, ups=0.87, wpb=101.3, bsz=40, num_updates=23690, lr=5.83165e-05, gnorm=0.485, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67662
2022-10-01 03:18:57 - progress_bar.py[line:274] - INFO: epoch 002:   7955 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.8, ups=0.87, wpb=101.5, bsz=40, num_updates=23700, lr=5.83059e-05, gnorm=0.492, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67674
2022-10-01 03:19:08 - progress_bar.py[line:274] - INFO: epoch 002:   7965 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.4, ups=0.89, wpb=102.4, bsz=40, num_updates=23710, lr=5.82954e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67685
2022-10-01 03:19:19 - progress_bar.py[line:274] - INFO: epoch 002:   7975 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.5, ups=0.93, wpb=101.9, bsz=40, num_updates=23720, lr=5.82848e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67696
2022-10-01 03:19:30 - progress_bar.py[line:274] - INFO: epoch 002:   7985 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.7, ups=0.88, wpb=100, bsz=40, num_updates=23730, lr=5.82743e-05, gnorm=0.6, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67707
2022-10-01 03:19:42 - progress_bar.py[line:274] - INFO: epoch 002:   7995 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.89, wpb=101.2, bsz=40, num_updates=23740, lr=5.82637e-05, gnorm=0.567, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=67718
2022-10-01 03:19:53 - progress_bar.py[line:274] - INFO: epoch 002:   8005 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.8, ups=0.9, wpb=101.9, bsz=40, num_updates=23750, lr=5.82531e-05, gnorm=0.5, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67729
2022-10-01 03:20:04 - progress_bar.py[line:274] - INFO: epoch 002:   8015 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.4, ups=0.86, wpb=100.4, bsz=40, num_updates=23760, lr=5.82426e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=67741
2022-10-01 03:20:16 - progress_bar.py[line:274] - INFO: epoch 002:   8025 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=84.1, ups=0.83, wpb=100.9, bsz=40, num_updates=23770, lr=5.8232e-05, gnorm=0.568, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=67753
2022-10-01 03:20:28 - progress_bar.py[line:274] - INFO: epoch 002:   8035 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.4, ups=0.86, wpb=102.3, bsz=40, num_updates=23780, lr=5.82215e-05, gnorm=0.493, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=67765
2022-10-01 03:20:39 - progress_bar.py[line:274] - INFO: epoch 002:   8045 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.6, ups=0.87, wpb=99.2, bsz=40, num_updates=23790, lr=5.82109e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=67776
2022-10-01 03:20:51 - progress_bar.py[line:274] - INFO: epoch 002:   8055 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.1, ups=0.87, wpb=99.5, bsz=40, num_updates=23800, lr=5.82003e-05, gnorm=0.605, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=67788
2022-10-01 03:21:02 - progress_bar.py[line:274] - INFO: epoch 002:   8065 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=23810, lr=5.81898e-05, gnorm=0.616, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67799
2022-10-01 03:21:14 - progress_bar.py[line:274] - INFO: epoch 002:   8075 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.7, ups=0.85, wpb=102.8, bsz=40, num_updates=23820, lr=5.81792e-05, gnorm=0.538, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=67811
2022-10-01 03:21:26 - progress_bar.py[line:274] - INFO: epoch 002:   8085 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=81.1, ups=0.81, wpb=99.5, bsz=40, num_updates=23830, lr=5.81687e-05, gnorm=0.667, clip=10, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=67823
2022-10-01 03:21:38 - progress_bar.py[line:274] - INFO: epoch 002:   8095 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.9, ups=0.87, wpb=100.5, bsz=40, num_updates=23840, lr=5.81581e-05, gnorm=0.547, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67834
2022-10-01 03:21:49 - progress_bar.py[line:274] - INFO: epoch 002:   8105 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.89, wpb=101.3, bsz=40, num_updates=23850, lr=5.81475e-05, gnorm=0.539, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67846
2022-10-01 03:22:00 - progress_bar.py[line:274] - INFO: epoch 002:   8115 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=23860, lr=5.8137e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=67857
2022-10-01 03:22:11 - progress_bar.py[line:274] - INFO: epoch 002:   8125 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.89, wpb=100.9, bsz=40, num_updates=23870, lr=5.81264e-05, gnorm=0.527, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67868
2022-10-01 03:22:22 - progress_bar.py[line:274] - INFO: epoch 002:   8135 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.1, ups=0.93, wpb=99.4, bsz=40, num_updates=23880, lr=5.81159e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67879
2022-10-01 03:22:33 - progress_bar.py[line:274] - INFO: epoch 002:   8145 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=23890, lr=5.81053e-05, gnorm=0.561, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67890
2022-10-01 03:22:45 - progress_bar.py[line:274] - INFO: epoch 002:   8155 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.89, wpb=101.9, bsz=40, num_updates=23900, lr=5.80947e-05, gnorm=0.62, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67901
2022-10-01 03:22:55 - progress_bar.py[line:274] - INFO: epoch 002:   8165 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.9, ups=0.92, wpb=100.4, bsz=40, num_updates=23910, lr=5.80842e-05, gnorm=0.488, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=67912
2022-10-01 03:23:07 - progress_bar.py[line:274] - INFO: epoch 002:   8175 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.4, ups=0.88, wpb=100.9, bsz=40, num_updates=23920, lr=5.80736e-05, gnorm=0.534, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67924
2022-10-01 03:23:18 - progress_bar.py[line:274] - INFO: epoch 002:   8185 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.89, wpb=99.9, bsz=40, num_updates=23930, lr=5.80631e-05, gnorm=0.606, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67935
2022-10-01 03:23:29 - progress_bar.py[line:274] - INFO: epoch 002:   8195 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=23940, lr=5.80525e-05, gnorm=0.572, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67946
2022-10-01 03:23:40 - progress_bar.py[line:274] - INFO: epoch 002:   8205 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.7, ups=0.9, wpb=100.5, bsz=40, num_updates=23950, lr=5.80419e-05, gnorm=0.62, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67957
2022-10-01 03:23:52 - progress_bar.py[line:274] - INFO: epoch 002:   8215 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.89, wpb=101.8, bsz=40, num_updates=23960, lr=5.80314e-05, gnorm=0.575, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67968
2022-10-01 03:24:03 - progress_bar.py[line:274] - INFO: epoch 002:   8225 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.88, wpb=101.3, bsz=40, num_updates=23970, lr=5.80208e-05, gnorm=0.546, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67980
2022-10-01 03:24:14 - progress_bar.py[line:274] - INFO: epoch 002:   8235 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.9, ups=0.89, wpb=102.4, bsz=40, num_updates=23980, lr=5.80103e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67991
2022-10-01 03:24:25 - progress_bar.py[line:274] - INFO: epoch 002:   8245 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.9, wpb=101, bsz=40, num_updates=23990, lr=5.79997e-05, gnorm=0.576, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=68002
2022-10-01 03:24:36 - progress_bar.py[line:274] - INFO: epoch 002:   8255 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.6, ups=0.91, wpb=103, bsz=40, num_updates=24000, lr=5.79891e-05, gnorm=0.533, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68013
2022-10-01 03:24:36 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-10-01 03:24:37 - train.py[line:549] - INFO: 0 / 14103
2022-10-01 03:24:37 - train.py[line:551] - INFO: load:0.67 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-01 03:24:40 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.82 GiB (GPU 0; 39.59 GiB total capacity; 12.89 GiB already allocated; 1.80 GiB free; 35.31 GiB reserved in total by PyTorch)
2022-10-01 03:24:40 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 33        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13195 MB |   16997 MB |    9094 TB |    9094 TB |
|       from large pool |   13050 MB |   16852 MB |    9090 TB |    9090 TB |
|       from small pool |     144 MB |     145 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13195 MB |   16997 MB |    9094 TB |    9094 TB |
|       from large pool |   13050 MB |   16852 MB |    9090 TB |    9090 TB |
|       from small pool |     144 MB |     145 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36158 MB |   37400 MB |  397446 MB |  361288 MB |
|       from large pool |   36012 MB |   37254 MB |  396826 MB |  360814 MB |
|       from small pool |     146 MB |     146 MB |     620 MB |     474 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22962 MB |   26409 MB |   10549 TB |   10549 TB |
|       from large pool |   22961 MB |   26407 MB |   10545 TB |   10545 TB |
|       from small pool |       1 MB |       1 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3660    |    3684    |  472112 K  |  472109 K  |
|       from large pool |     564    |     585    |  143020 K  |  143020 K  |
|       from small pool |    3096    |    3114    |  329091 K  |  329088 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3660    |    3684    |  472112 K  |  472109 K  |
|       from large pool |     564    |     585    |  143020 K  |  143020 K  |
|       from small pool |    3096    |    3114    |  329091 K  |  329088 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     148    |     151    |     828    |     680    |
|       from large pool |      75    |      78    |     518    |     443    |
|       from small pool |      73    |      73    |     310    |     237    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     112    |     114    |  348491 K  |  348491 K  |
|       from large pool |      68    |      70    |   67726 K  |   67725 K  |
|       from small pool |      44    |      51    |  280765 K  |  280765 K  |
|===========================================================================|

2022-10-01 03:24:40 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-01 03:24:40 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-10-01 03:26:03 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.10 GiB (GPU 1; 39.59 GiB total capacity; 13.33 GiB already allocated; 1.06 GiB free; 36.05 GiB reserved in total by PyTorch)
2022-10-01 03:26:03 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-01 03:26:03 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 31        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13648 MB |   17825 MB |    9146 TB |    9146 TB |
|       from large pool |   13503 MB |   17680 MB |    9142 TB |    9142 TB |
|       from small pool |     144 MB |     157 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13648 MB |   17825 MB |    9146 TB |    9146 TB |
|       from large pool |   13503 MB |   17680 MB |    9142 TB |    9142 TB |
|       from small pool |     144 MB |     157 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36914 MB |   36914 MB |  325714 MB |  288800 MB |
|       from large pool |   36768 MB |   36768 MB |  325060 MB |  288292 MB |
|       from small pool |     146 MB |     158 MB |     654 MB |     508 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23265 MB |   27027 MB |    9516 TB |    9516 TB |
|       from large pool |   23264 MB |   27025 MB |    9512 TB |    9512 TB |
|       from small pool |       1 MB |       4 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3671    |    3695    |  472795 K  |  472791 K  |
|       from large pool |     564    |     585    |  143194 K  |  143193 K  |
|       from small pool |    3107    |    3116    |  329601 K  |  329598 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3671    |    3695    |  472795 K  |  472791 K  |
|       from large pool |     564    |     585    |  143194 K  |  143193 K  |
|       from small pool |    3107    |    3116    |  329601 K  |  329598 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     129    |     135    |     779    |     650    |
|       from large pool |      56    |      56    |     452    |     396    |
|       from small pool |      73    |      79    |     327    |     254    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      82    |      95    |  342048 K  |  342048 K  |
|       from large pool |      51    |      56    |   61882 K  |   61882 K  |
|       from small pool |      31    |      48    |  280166 K  |  280166 K  |
|===========================================================================|

2022-10-01 03:26:03 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-10-01 03:27:53 - train.py[line:549] - INFO: 200 / 14103
2022-10-01 03:27:53 - train.py[line:551] - INFO: load:0.69 valid_run:195.53 task_valid:184.26 collect_output:7.38
2022-10-01 03:31:01 - train.py[line:549] - INFO: 400 / 14103
2022-10-01 03:31:01 - train.py[line:551] - INFO: load:0.71 valid_run:383.14 task_valid:367.21 collect_output:10.98
2022-10-01 03:34:09 - train.py[line:549] - INFO: 600 / 14103
2022-10-01 03:34:09 - train.py[line:551] - INFO: load:0.73 valid_run:571.77 task_valid:549.81 collect_output:15.94
2022-10-01 03:37:22 - train.py[line:549] - INFO: 800 / 14103
2022-10-01 03:37:22 - train.py[line:551] - INFO: load:0.76 valid_run:764.24 task_valid:737.39 collect_output:19.63
2022-10-01 03:40:33 - train.py[line:549] - INFO: 1000 / 14103
2022-10-01 03:40:33 - train.py[line:551] - INFO: load:0.78 valid_run:955.46 task_valid:923.77 collect_output:23.30
2022-10-01 03:43:45 - train.py[line:549] - INFO: 1200 / 14103
2022-10-01 03:43:45 - train.py[line:551] - INFO: load:0.81 valid_run:1147.07 task_valid:1109.94 collect_output:27.62
2022-10-01 03:46:58 - train.py[line:549] - INFO: 1400 / 14103
2022-10-01 03:46:58 - train.py[line:551] - INFO: load:0.83 valid_run:1339.82 task_valid:1298.56 collect_output:30.64
2022-10-01 03:50:13 - train.py[line:549] - INFO: 1600 / 14103
2022-10-01 03:50:13 - train.py[line:551] - INFO: load:0.86 valid_run:1535.01 task_valid:1489.69 collect_output:33.39
2022-10-01 03:53:26 - train.py[line:549] - INFO: 1800 / 14103
2022-10-01 03:53:26 - train.py[line:551] - INFO: load:0.88 valid_run:1727.77 task_valid:1675.52 collect_output:39.11
2022-10-01 03:56:38 - train.py[line:549] - INFO: 2000 / 14103
2022-10-01 03:56:38 - train.py[line:551] - INFO: load:0.90 valid_run:1920.06 task_valid:1863.46 collect_output:42.22
2022-10-01 03:59:52 - train.py[line:549] - INFO: 2200 / 14103
2022-10-01 03:59:52 - train.py[line:551] - INFO: load:0.93 valid_run:2114.38 task_valid:2052.41 collect_output:46.27
2022-10-01 04:03:05 - train.py[line:549] - INFO: 2400 / 14103
2022-10-01 04:03:05 - train.py[line:551] - INFO: load:0.95 valid_run:2306.43 task_valid:2237.41 collect_output:52.06
2022-10-01 04:06:17 - train.py[line:549] - INFO: 2600 / 14103
2022-10-01 04:06:17 - train.py[line:551] - INFO: load:0.98 valid_run:2498.74 task_valid:2425.72 collect_output:54.83
2022-10-01 04:09:27 - train.py[line:549] - INFO: 2800 / 14103
2022-10-01 04:09:27 - train.py[line:551] - INFO: load:1.00 valid_run:2688.42 task_valid:2610.36 collect_output:58.63
2022-10-01 04:12:43 - train.py[line:549] - INFO: 3000 / 14103
2022-10-01 04:12:43 - train.py[line:551] - INFO: load:1.04 valid_run:2884.30 task_valid:2799.01 collect_output:64.53
2022-10-01 04:15:53 - train.py[line:549] - INFO: 3200 / 14103
2022-10-01 04:15:53 - train.py[line:551] - INFO: load:1.06 valid_run:3074.28 task_valid:2982.55 collect_output:69.76
2022-10-01 04:19:05 - train.py[line:549] - INFO: 3400 / 14103
2022-10-01 04:19:05 - train.py[line:551] - INFO: load:1.08 valid_run:3266.21 task_valid:3165.81 collect_output:77.38
2022-10-01 04:22:18 - train.py[line:549] - INFO: 3600 / 14103
2022-10-01 04:22:18 - train.py[line:551] - INFO: load:1.11 valid_run:3459.40 task_valid:3351.85 collect_output:83.41
2022-10-01 04:25:29 - train.py[line:549] - INFO: 3800 / 14103
2022-10-01 04:25:29 - train.py[line:551] - INFO: load:1.14 valid_run:3650.47 task_valid:3534.98 collect_output:90.21
2022-10-01 04:28:40 - train.py[line:549] - INFO: 4000 / 14103
2022-10-01 04:28:40 - train.py[line:551] - INFO: load:1.17 valid_run:3841.44 task_valid:3721.04 collect_output:93.96
2022-10-01 04:31:52 - train.py[line:549] - INFO: 4200 / 14103
2022-10-01 04:31:52 - train.py[line:551] - INFO: load:1.19 valid_run:4033.05 task_valid:3909.71 collect_output:95.81
2022-10-01 04:34:59 - train.py[line:549] - INFO: 4400 / 14103
2022-10-01 04:34:59 - train.py[line:551] - INFO: load:1.21 valid_run:4220.10 task_valid:4089.88 collect_output:101.57
2022-10-01 04:38:10 - train.py[line:549] - INFO: 4600 / 14103
2022-10-01 04:38:10 - train.py[line:551] - INFO: load:1.24 valid_run:4410.90 task_valid:4274.16 collect_output:107.02
2022-10-01 04:41:17 - train.py[line:549] - INFO: 4800 / 14103
2022-10-01 04:41:17 - train.py[line:551] - INFO: load:1.26 valid_run:4598.44 task_valid:4456.80 collect_output:110.85
2022-10-01 04:44:28 - train.py[line:549] - INFO: 5000 / 14103
2022-10-01 04:44:28 - train.py[line:551] - INFO: load:1.28 valid_run:4789.47 task_valid:4642.64 collect_output:114.89
2022-10-01 04:47:40 - train.py[line:549] - INFO: 5200 / 14103
2022-10-01 04:47:40 - train.py[line:551] - INFO: load:1.31 valid_run:4980.77 task_valid:4828.48 collect_output:119.15
2022-10-01 04:50:51 - train.py[line:549] - INFO: 5400 / 14103
2022-10-01 04:50:51 - train.py[line:551] - INFO: load:1.33 valid_run:5172.02 task_valid:5016.66 collect_output:121.13
2022-10-01 04:54:04 - train.py[line:549] - INFO: 5600 / 14103
2022-10-01 04:54:04 - train.py[line:551] - INFO: load:1.36 valid_run:5364.67 task_valid:5205.03 collect_output:124.15
2022-10-01 04:57:16 - train.py[line:549] - INFO: 5800 / 14103
2022-10-01 04:57:16 - train.py[line:551] - INFO: load:1.38 valid_run:5556.98 task_valid:5390.90 collect_output:129.53
2022-10-01 05:00:23 - train.py[line:549] - INFO: 6000 / 14103
2022-10-01 05:00:23 - train.py[line:551] - INFO: load:1.41 valid_run:5744.04 task_valid:5571.37 collect_output:135.01
2022-10-01 05:03:35 - train.py[line:549] - INFO: 6200 / 14103
2022-10-01 05:03:35 - train.py[line:551] - INFO: load:1.43 valid_run:5936.07 task_valid:5757.02 collect_output:140.07
2022-10-01 05:06:45 - train.py[line:549] - INFO: 6400 / 14103
2022-10-01 05:06:45 - train.py[line:551] - INFO: load:1.46 valid_run:6125.81 task_valid:5942.27 collect_output:143.37
2022-10-01 05:09:54 - train.py[line:549] - INFO: 6600 / 14103
2022-10-01 05:09:54 - train.py[line:551] - INFO: load:1.48 valid_run:6314.07 task_valid:6123.44 collect_output:149.25
2022-10-01 05:13:06 - train.py[line:549] - INFO: 6800 / 14103
2022-10-01 05:13:06 - train.py[line:551] - INFO: load:1.50 valid_run:6506.49 task_valid:6307.37 collect_output:156.49
2022-10-01 05:16:19 - train.py[line:549] - INFO: 7000 / 14103
2022-10-01 05:16:19 - train.py[line:551] - INFO: load:1.53 valid_run:6699.00 task_valid:6495.96 collect_output:159.14
2022-10-01 05:19:31 - train.py[line:549] - INFO: 7200 / 14103
2022-10-01 05:19:31 - train.py[line:551] - INFO: load:1.55 valid_run:6891.36 task_valid:6685.05 collect_output:161.29
2022-10-01 05:22:41 - train.py[line:549] - INFO: 7400 / 14103
2022-10-01 05:22:41 - train.py[line:551] - INFO: load:1.58 valid_run:7081.49 task_valid:6866.58 collect_output:168.81
terminate called after throwing an instance of 'std::system_error'
  what():  Transport endpoint is not connected
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/50_way_allcand', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_8e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=10', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=8e-5', '--max-epoch=5', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=6000', '--validate-interval-updates=6000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', '--valid-batch-size=26', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' died with <Signals.SIGABRT: 6>.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2408397
Killing subprocess 2408398
