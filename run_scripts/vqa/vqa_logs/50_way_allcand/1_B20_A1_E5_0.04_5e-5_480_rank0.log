2022-09-28 11:48:49 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-09-28 11:48:49 - utils.py[line:261] - INFO: Start init
2022-09-28 11:48:49 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-09-28 11:48:49 - utils.py[line:261] - INFO: Start init
2022-09-28 11:48:50 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-09-28 11:48:50 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-09-28 11:48:50 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-09-28 11:48:50 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-09-28 11:48:53 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/50_way_allcand', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 6000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 6000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', save_interval=10, save_interval_updates=6000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/50_way_allcand', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=6000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-09-28 11:48:53 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-09-28 11:48:53 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-09-28 11:48:58 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-09-28 11:48:58 - train.py[line:118] - INFO: task: VqaGenTask
2022-09-28 11:48:58 - train.py[line:119] - INFO: model: OFAModel
2022-09-28 11:48:58 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-09-28 11:48:58 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-09-28 11:48:58 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_500.tsv slice_id 1 row count 45697 total row count 91394
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_500.tsv slice_id 0 row count 45697 total row count 91394
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-28 11:48:58 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-09-28 11:48:58 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-09-28 11:48:58 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 11:48:58 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 11:48:58 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 11:48:58 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 11:48:58 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-09-28 11:48:58 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-09-28 11:48:58 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-09-28 11:49:01 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 11:49:01 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 11:49:01 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-09-28 11:49:01 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-09-28 11:49:02 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-09-28 11:49:02 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 0 row count 315642 total row count 631284
2022-09-28 11:49:02 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 1 row count 315642 total row count 631284
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 11:49:03 - trainer.py[line:707] - INFO: begin training epoch 1
2022-09-28 11:49:03 - train.py[line:312] - INFO: Start iterating over samples
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 11:49:18 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 15783 loss=1.323, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=85.7, ups=0.84, wpb=102.4, bsz=40, num_updates=10, lr=1.58428e-07, gnorm=14.894, clip=100, loss_scale=128, train_wall=15, gb_free=10.5, ema_decay=0.9999, wall=20
2022-09-28 11:49:30 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 15783 loss=1.339, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=85.6, ups=0.85, wpb=100.6, bsz=40, num_updates=20, lr=3.16857e-07, gnorm=13.453, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=32
2022-09-28 11:49:42 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 15783 loss=1.399, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=87.7, ups=0.87, wpb=100.6, bsz=40, num_updates=30, lr=4.75285e-07, gnorm=15.351, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43
2022-09-28 11:49:53 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 15783 loss=1.273, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=87.1, ups=0.85, wpb=102.1, bsz=40, num_updates=40, lr=6.33714e-07, gnorm=10.965, clip=100, loss_scale=128, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=55
2022-09-28 11:50:05 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 15783 loss=1.226, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=88.8, ups=0.87, wpb=102.4, bsz=40, num_updates=50, lr=7.92142e-07, gnorm=10.881, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67
2022-09-28 11:50:16 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 15783 loss=1.208, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=87.2, ups=0.87, wpb=100.4, bsz=40, num_updates=60, lr=9.5057e-07, gnorm=8.946, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78
2022-09-28 11:50:28 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 15783 loss=1.135, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=90.8, ups=0.88, wpb=102.7, bsz=40, num_updates=70, lr=1.109e-06, gnorm=8.241, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=89
2022-09-28 11:50:39 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 15783 loss=1.091, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=90.3, ups=0.88, wpb=103.2, bsz=40, num_updates=80, lr=1.26743e-06, gnorm=7.361, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=101
2022-09-28 11:50:51 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 15783 loss=1.105, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=88.6, ups=0.88, wpb=101.2, bsz=40, num_updates=90, lr=1.42586e-06, gnorm=6.136, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=112
2022-09-28 11:51:02 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 15783 loss=1.064, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=88.3, ups=0.87, wpb=101, bsz=40, num_updates=100, lr=1.58428e-06, gnorm=5.483, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124
2022-09-28 11:51:13 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 15783 loss=1.051, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=88.7, ups=0.87, wpb=101.4, bsz=40, num_updates=110, lr=1.74271e-06, gnorm=5.31, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=135
2022-09-28 11:51:25 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 15783 loss=1.054, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=88, ups=0.88, wpb=100.3, bsz=40, num_updates=120, lr=1.90114e-06, gnorm=5.06, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=147
2022-09-28 11:51:36 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 15783 loss=1.039, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=130, lr=2.05957e-06, gnorm=4.798, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=158
2022-09-28 11:51:47 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 15783 loss=0.956, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=89.8, ups=0.88, wpb=101.8, bsz=40, num_updates=140, lr=2.218e-06, gnorm=4.304, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=169
2022-09-28 11:51:59 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 15783 loss=0.965, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=90.5, ups=0.89, wpb=102.2, bsz=40, num_updates=150, lr=2.37643e-06, gnorm=4.044, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=180
2022-09-28 11:52:10 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 15783 loss=0.922, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=94, ups=0.92, wpb=102.5, bsz=40, num_updates=160, lr=2.53485e-06, gnorm=4.156, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=191
2022-09-28 11:52:21 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 15783 loss=0.916, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=87, ups=0.87, wpb=100.6, bsz=40, num_updates=170, lr=2.69328e-06, gnorm=3.596, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=203
2022-09-28 11:52:33 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 15783 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=90.2, ups=0.88, wpb=102.9, bsz=40, num_updates=180, lr=2.85171e-06, gnorm=3.626, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=214
2022-09-28 11:52:44 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 15783 loss=0.954, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=87.2, ups=0.88, wpb=99.5, bsz=40, num_updates=190, lr=3.01014e-06, gnorm=3.811, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=226
2022-09-28 11:52:55 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 15783 loss=0.926, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=89.9, ups=0.88, wpb=102.6, bsz=40, num_updates=200, lr=3.16857e-06, gnorm=3.719, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=237
2022-09-28 11:53:07 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 15783 loss=0.959, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=91, ups=0.9, wpb=101.3, bsz=40, num_updates=210, lr=3.327e-06, gnorm=3.211, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=248
2022-09-28 11:53:18 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 15783 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.702, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=91.2, ups=0.89, wpb=102.9, bsz=40, num_updates=220, lr=3.48542e-06, gnorm=3.089, clip=100, loss_scale=128, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=260
2022-09-28 11:53:30 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 15783 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=88.6, ups=0.86, wpb=103, bsz=40, num_updates=230, lr=3.64385e-06, gnorm=3.084, clip=100, loss_scale=128, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=271
2022-09-28 11:53:41 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 15783 loss=0.907, loss_v1=0, loss_v2=0, nll_loss=0.741, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=90.6, ups=0.89, wpb=101.3, bsz=40, num_updates=240, lr=3.80228e-06, gnorm=3.147, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=282
2022-09-28 11:53:52 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 15783 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.717, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=92.3, ups=0.91, wpb=101.2, bsz=40, num_updates=250, lr=3.96071e-06, gnorm=3.022, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=293
2022-09-28 11:54:03 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 15783 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=95.4, ups=0.93, wpb=102.3, bsz=40, num_updates=260, lr=4.11914e-06, gnorm=2.944, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=304
2022-09-28 11:54:14 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 15783 loss=0.956, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=88.6, ups=0.89, wpb=99.9, bsz=40, num_updates=270, lr=4.27757e-06, gnorm=3.1, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=316
2022-09-28 11:54:25 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 15783 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=280, lr=4.43599e-06, gnorm=3.115, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=327
2022-09-28 11:54:36 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 15783 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=90.4, ups=0.9, wpb=100.7, bsz=40, num_updates=290, lr=4.59442e-06, gnorm=3.13, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=338
2022-09-28 11:54:48 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 15783 loss=1.001, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=98.1, nsentences=40, sample_size=98.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=88.1, ups=0.9, wpb=98.1, bsz=40, num_updates=300, lr=4.75285e-06, gnorm=2.967, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=349
2022-09-28 11:54:58 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 15783 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=93.6, ups=0.92, wpb=102.1, bsz=40, num_updates=310, lr=4.91128e-06, gnorm=2.882, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=360
2022-09-28 11:55:10 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 15783 loss=0.939, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=88.7, ups=0.88, wpb=100.7, bsz=40, num_updates=320, lr=5.06971e-06, gnorm=3.035, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=372
2022-09-28 11:55:21 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 15783 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=96, ups=0.94, wpb=102.3, bsz=40, num_updates=330, lr=5.22814e-06, gnorm=2.884, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=382
2022-09-28 11:55:32 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 15783 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=91, ups=0.9, wpb=101, bsz=40, num_updates=340, lr=5.38657e-06, gnorm=2.606, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=393
2022-09-28 11:55:43 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 15783 loss=0.819, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=94.2, ups=0.92, wpb=102.9, bsz=40, num_updates=350, lr=5.54499e-06, gnorm=2.582, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=404
2022-09-28 11:55:54 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 15783 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=90, ups=0.88, wpb=102.5, bsz=40, num_updates=360, lr=5.70342e-06, gnorm=2.879, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=416
2022-09-28 11:56:05 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 15783 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=370, lr=5.86185e-06, gnorm=2.655, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=427
2022-09-28 11:56:17 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 15783 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=87.1, ups=0.86, wpb=101, bsz=40, num_updates=380, lr=6.02028e-06, gnorm=2.828, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=438
2022-09-28 11:56:28 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 15783 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.66, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.7, ups=0.88, wpb=102.5, bsz=40, num_updates=390, lr=6.17871e-06, gnorm=2.846, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=450
2022-09-28 11:56:39 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 15783 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=92.9, ups=0.92, wpb=100.6, bsz=40, num_updates=400, lr=6.33714e-06, gnorm=2.915, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=460
2022-09-28 11:56:50 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 15783 loss=0.833, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=94.2, ups=0.93, wpb=101.2, bsz=40, num_updates=410, lr=6.49556e-06, gnorm=2.72, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=471
2022-09-28 11:57:01 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 15783 loss=0.857, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=89, ups=0.89, wpb=99.7, bsz=40, num_updates=420, lr=6.65399e-06, gnorm=2.951, clip=100, loss_scale=128, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=482
2022-09-28 11:57:12 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 15783 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.72, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=91, ups=0.9, wpb=100.6, bsz=40, num_updates=430, lr=6.81242e-06, gnorm=2.749, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=493
2022-09-28 11:57:23 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 15783 loss=0.854, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=87.5, ups=0.87, wpb=100.2, bsz=40, num_updates=440, lr=6.97085e-06, gnorm=2.745, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=505
2022-09-28 11:57:34 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 15783 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=88.5, ups=0.89, wpb=99.7, bsz=40, num_updates=450, lr=7.12928e-06, gnorm=2.889, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=516
2022-09-28 11:57:46 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 15783 loss=0.826, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=460, lr=7.28771e-06, gnorm=2.55, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=528
2022-09-28 11:57:57 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 15783 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=91.8, ups=0.9, wpb=102, bsz=40, num_updates=470, lr=7.44613e-06, gnorm=2.846, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=539
2022-09-28 11:58:08 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 15783 loss=0.773, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=90.1, ups=0.88, wpb=102.5, bsz=40, num_updates=480, lr=7.60456e-06, gnorm=2.761, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=550
2022-09-28 11:58:19 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 15783 loss=0.784, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=92, ups=0.91, wpb=101.2, bsz=40, num_updates=490, lr=7.76299e-06, gnorm=3.041, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=561
2022-09-28 11:58:30 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 15783 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=93.2, ups=0.92, wpb=101.5, bsz=40, num_updates=500, lr=7.92142e-06, gnorm=2.918, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=572
2022-09-28 11:58:42 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 15783 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=87.2, ups=0.87, wpb=100.6, bsz=40, num_updates=510, lr=8.07985e-06, gnorm=3.02, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=583
2022-09-28 11:58:53 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 15783 loss=0.807, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=89.1, ups=0.88, wpb=101.5, bsz=40, num_updates=520, lr=8.23828e-06, gnorm=2.996, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=595
2022-09-28 11:59:04 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 15783 loss=0.81, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=93.5, ups=0.93, wpb=100.1, bsz=40, num_updates=530, lr=8.3967e-06, gnorm=2.785, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=606
2022-09-28 11:59:15 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 15783 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=540, lr=8.55513e-06, gnorm=2.737, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=617
2022-09-28 11:59:26 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 15783 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.9, ups=0.94, wpb=101.9, bsz=40, num_updates=550, lr=8.71356e-06, gnorm=2.589, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=628
2022-09-28 11:59:37 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 15783 loss=0.785, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=560, lr=8.87199e-06, gnorm=2.814, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=639
2022-09-28 11:59:49 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 15783 loss=0.748, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.9, ups=0.89, wpb=102.2, bsz=40, num_updates=570, lr=9.03042e-06, gnorm=2.548, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=650
2022-09-28 12:00:00 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 15783 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.2, ups=0.9, wpb=102.5, bsz=40, num_updates=580, lr=9.18885e-06, gnorm=2.596, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=661
2022-09-28 12:00:11 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.2, ups=0.89, wpb=103.4, bsz=40, num_updates=590, lr=9.34728e-06, gnorm=2.26, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=673
2022-09-28 12:00:22 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 15783 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=91.2, ups=0.89, wpb=102.8, bsz=40, num_updates=600, lr=9.5057e-06, gnorm=3.152, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=684
2022-09-28 12:00:33 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 15783 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.6, ups=0.89, wpb=103.4, bsz=40, num_updates=610, lr=9.66413e-06, gnorm=2.721, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=695
2022-09-28 12:00:45 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.4, ups=0.88, wpb=102, bsz=40, num_updates=620, lr=9.82256e-06, gnorm=2.18, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=707
2022-09-28 12:00:56 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 15783 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.5, ups=0.88, wpb=103.1, bsz=40, num_updates=630, lr=9.98099e-06, gnorm=2.613, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=718
2022-09-28 12:01:08 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 15783 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.6, ups=0.88, wpb=103.4, bsz=40, num_updates=640, lr=1.01394e-05, gnorm=2.397, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=729
2022-09-28 12:01:19 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 15783 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=650, lr=1.02978e-05, gnorm=2.44, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=741
2022-09-28 12:01:30 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 15783 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=93.1, ups=0.92, wpb=100.7, bsz=40, num_updates=660, lr=1.04563e-05, gnorm=2.401, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=751
2022-09-28 12:01:41 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 15783 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88.1, ups=0.88, wpb=100.2, bsz=40, num_updates=670, lr=1.06147e-05, gnorm=2.35, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=763
2022-09-28 12:01:53 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 15783 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.3, ups=0.88, wpb=101.5, bsz=40, num_updates=680, lr=1.07731e-05, gnorm=2.599, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=774
2022-09-28 12:02:04 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 15783 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.7, ups=0.89, wpb=101.8, bsz=40, num_updates=690, lr=1.09316e-05, gnorm=2.477, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=785
2022-09-28 12:02:15 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 15783 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.5, ups=0.93, wpb=99.9, bsz=40, num_updates=700, lr=1.109e-05, gnorm=2.576, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=796
2022-09-28 12:02:26 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 15783 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.8, ups=0.88, wpb=102.3, bsz=40, num_updates=710, lr=1.12484e-05, gnorm=2.349, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=808
2022-09-28 12:02:37 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.9, ups=0.93, wpb=102.5, bsz=40, num_updates=720, lr=1.14068e-05, gnorm=2.228, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=818
2022-09-28 12:02:48 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 15783 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=92.4, ups=0.91, wpb=101.3, bsz=40, num_updates=730, lr=1.15653e-05, gnorm=2.364, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=829
2022-09-28 12:02:59 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 15783 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.2, ups=0.89, wpb=101.5, bsz=40, num_updates=740, lr=1.17237e-05, gnorm=2.376, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=841
2022-09-28 12:03:10 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 15783 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=750, lr=1.18821e-05, gnorm=2.282, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=852
2022-09-28 12:03:21 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 15783 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.1, ups=0.88, wpb=100.3, bsz=40, num_updates=760, lr=1.20406e-05, gnorm=2.19, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=863
2022-09-28 12:03:33 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.87, wpb=102.3, bsz=40, num_updates=770, lr=1.2199e-05, gnorm=2.264, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=875
2022-09-28 12:03:45 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 15783 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.1, ups=0.89, wpb=102, bsz=40, num_updates=780, lr=1.23574e-05, gnorm=2.209, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=886
2022-09-28 12:03:55 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 15783 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=93.5, ups=0.93, wpb=100.1, bsz=40, num_updates=790, lr=1.25158e-05, gnorm=2.671, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=897
2022-09-28 12:04:06 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 15783 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.8, ups=0.93, wpb=98.8, bsz=40, num_updates=800, lr=1.26743e-05, gnorm=2.483, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=908
2022-09-28 12:04:17 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 15783 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.2, ups=0.88, wpb=101.6, bsz=40, num_updates=810, lr=1.28327e-05, gnorm=2.196, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=919
2022-09-28 12:04:29 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 15783 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=820, lr=1.29911e-05, gnorm=2.234, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=930
2022-09-28 12:04:40 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.3, ups=0.9, wpb=101.5, bsz=40, num_updates=830, lr=1.31496e-05, gnorm=2.15, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=941
2022-09-28 12:04:51 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 15783 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=90.1, ups=0.89, wpb=101, bsz=40, num_updates=840, lr=1.3308e-05, gnorm=2.257, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=953
2022-09-28 12:05:02 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 15783 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.2, ups=0.91, wpb=101.2, bsz=40, num_updates=850, lr=1.34664e-05, gnorm=1.992, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=964
2022-09-28 12:05:13 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 15783 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.2, ups=0.9, wpb=102, bsz=40, num_updates=860, lr=1.36248e-05, gnorm=2.348, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=975
2022-09-28 12:05:24 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 15783 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=870, lr=1.37833e-05, gnorm=2.293, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=986
2022-09-28 12:05:35 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 15783 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.9, ups=0.91, wpb=101.6, bsz=40, num_updates=880, lr=1.39417e-05, gnorm=2.327, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=997
2022-09-28 12:05:46 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.9, ups=0.91, wpb=101.8, bsz=40, num_updates=890, lr=1.41001e-05, gnorm=2.021, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1008
2022-09-28 12:05:57 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 15783 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=93.4, ups=0.91, wpb=103.1, bsz=40, num_updates=900, lr=1.42586e-05, gnorm=2.146, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1019
2022-09-28 12:06:08 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.7, ups=0.93, wpb=102.3, bsz=40, num_updates=910, lr=1.4417e-05, gnorm=2.243, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1030
2022-09-28 12:06:19 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=92.4, ups=0.91, wpb=101, bsz=40, num_updates=920, lr=1.45754e-05, gnorm=2.167, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1041
2022-09-28 12:06:30 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 15783 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87, ups=0.87, wpb=100.4, bsz=40, num_updates=930, lr=1.47338e-05, gnorm=1.974, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1052
2022-09-28 12:06:42 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 15783 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.5, ups=0.87, wpb=100.6, bsz=40, num_updates=940, lr=1.48923e-05, gnorm=2.231, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1064
2022-09-28 12:06:53 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 15783 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=87.3, ups=0.88, wpb=99.3, bsz=40, num_updates=950, lr=1.50507e-05, gnorm=2.049, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1075
2022-09-28 12:07:05 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 15783 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.1, ups=0.88, wpb=100.3, bsz=40, num_updates=960, lr=1.52091e-05, gnorm=2.269, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1086
2022-09-28 12:07:16 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 15783 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91, ups=0.91, wpb=99.7, bsz=40, num_updates=970, lr=1.53676e-05, gnorm=2.132, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1097
2022-09-28 12:07:27 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.6, ups=0.88, wpb=103.3, bsz=40, num_updates=980, lr=1.5526e-05, gnorm=2.014, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1109
2022-09-28 12:07:38 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.4, ups=0.91, wpb=99.8, bsz=40, num_updates=990, lr=1.56844e-05, gnorm=2.233, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1120
2022-09-28 12:07:49 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.6, ups=0.9, wpb=103.7, bsz=40, num_updates=1000, lr=1.58428e-05, gnorm=1.999, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1131
2022-09-28 12:08:01 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.3, ups=0.88, wpb=102.5, bsz=40, num_updates=1010, lr=1.60013e-05, gnorm=2.314, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1142
2022-09-28 12:08:12 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.7, ups=0.88, wpb=103.2, bsz=40, num_updates=1020, lr=1.61597e-05, gnorm=2.178, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1154
2022-09-28 12:08:23 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.8, ups=0.89, wpb=101.2, bsz=40, num_updates=1030, lr=1.63181e-05, gnorm=1.88, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1165
2022-09-28 12:08:35 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.8, ups=0.87, wpb=101.2, bsz=40, num_updates=1040, lr=1.64766e-05, gnorm=1.926, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1176
2022-09-28 12:08:46 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.89, wpb=103.4, bsz=40, num_updates=1050, lr=1.6635e-05, gnorm=1.898, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1188
2022-09-28 12:08:57 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.2, ups=0.92, wpb=100.2, bsz=40, num_updates=1060, lr=1.67934e-05, gnorm=2.058, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1199
2022-09-28 12:09:08 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 15783 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88, ups=0.89, wpb=98.9, bsz=40, num_updates=1070, lr=1.69518e-05, gnorm=2.055, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1210
2022-09-28 12:09:19 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=1080, lr=1.71103e-05, gnorm=2.433, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1221
2022-09-28 12:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 15783 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=1090, lr=1.72687e-05, gnorm=1.908, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1232
2022-09-28 12:09:42 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.7, ups=0.89, wpb=102.2, bsz=40, num_updates=1100, lr=1.74271e-05, gnorm=1.906, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1243
2022-09-28 12:09:53 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.1, ups=0.89, wpb=101, bsz=40, num_updates=1110, lr=1.75856e-05, gnorm=2.025, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1255
2022-09-28 12:10:04 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.5, ups=0.88, wpb=100.6, bsz=40, num_updates=1120, lr=1.7744e-05, gnorm=2.159, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1266
2022-09-28 12:10:16 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 15783 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.2, ups=0.89, wpb=99.3, bsz=40, num_updates=1130, lr=1.79024e-05, gnorm=2.162, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1277
2022-09-28 12:10:27 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.9, ups=0.9, wpb=101.8, bsz=40, num_updates=1140, lr=1.80608e-05, gnorm=2.05, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1288
2022-09-28 12:10:38 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.88, wpb=102.3, bsz=40, num_updates=1150, lr=1.82193e-05, gnorm=1.853, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1300
2022-09-28 12:10:49 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91, ups=0.9, wpb=100.8, bsz=40, num_updates=1160, lr=1.83777e-05, gnorm=2.186, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1311
2022-09-28 12:11:00 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.3, ups=0.89, wpb=101.9, bsz=40, num_updates=1170, lr=1.85361e-05, gnorm=2.189, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1322
2022-09-28 12:11:12 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.9, ups=0.88, wpb=102, bsz=40, num_updates=1180, lr=1.86946e-05, gnorm=2.017, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1333
2022-09-28 12:11:23 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.1, ups=0.87, wpb=101.5, bsz=40, num_updates=1190, lr=1.8853e-05, gnorm=1.99, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1345
2022-09-28 12:11:35 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.7, ups=0.87, wpb=101, bsz=40, num_updates=1200, lr=1.90114e-05, gnorm=1.929, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1357
2022-09-28 12:11:46 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.8, ups=0.9, wpb=99.6, bsz=40, num_updates=1210, lr=1.91698e-05, gnorm=1.974, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1368
2022-09-28 12:11:57 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.8, ups=0.89, wpb=102, bsz=40, num_updates=1220, lr=1.93283e-05, gnorm=2.118, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1379
2022-09-28 12:12:09 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.88, wpb=101.2, bsz=40, num_updates=1230, lr=1.94867e-05, gnorm=2.085, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1390
2022-09-28 12:12:20 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.8, ups=0.88, wpb=100, bsz=40, num_updates=1240, lr=1.96451e-05, gnorm=1.951, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1402
2022-09-28 12:12:31 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90, ups=0.88, wpb=102.3, bsz=40, num_updates=1250, lr=1.98035e-05, gnorm=2.011, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1413
2022-09-28 12:12:43 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=1260, lr=1.9962e-05, gnorm=1.717, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1424
2022-09-28 12:12:54 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.2, ups=0.92, wpb=102, bsz=40, num_updates=1270, lr=2.01204e-05, gnorm=1.974, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1435
2022-09-28 12:13:05 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.88, wpb=102.1, bsz=40, num_updates=1280, lr=2.02788e-05, gnorm=1.811, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1447
2022-09-28 12:13:16 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.91, wpb=100.7, bsz=40, num_updates=1290, lr=2.04373e-05, gnorm=1.748, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1458
2022-09-28 12:13:27 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.6, ups=0.89, wpb=101.4, bsz=40, num_updates=1300, lr=2.05957e-05, gnorm=1.817, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1469
2022-09-28 12:13:38 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.8, ups=0.92, wpb=101.2, bsz=40, num_updates=1310, lr=2.07541e-05, gnorm=1.889, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1480
2022-09-28 12:13:49 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.8, ups=0.92, wpb=101.3, bsz=40, num_updates=1320, lr=2.09125e-05, gnorm=1.869, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1491
2022-09-28 12:14:00 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 15783 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.3, ups=0.93, wpb=100.2, bsz=40, num_updates=1330, lr=2.1071e-05, gnorm=2.122, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1502
2022-09-28 12:14:11 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=1340, lr=2.12294e-05, gnorm=1.854, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1513
2022-09-28 12:14:22 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.88, wpb=101.2, bsz=40, num_updates=1350, lr=2.13878e-05, gnorm=1.843, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1524
2022-09-28 12:14:33 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.8, ups=0.9, wpb=101, bsz=40, num_updates=1360, lr=2.15463e-05, gnorm=2.104, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1535
2022-09-28 12:14:44 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.5, ups=0.93, wpb=100.5, bsz=40, num_updates=1370, lr=2.17047e-05, gnorm=1.941, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1546
2022-09-28 12:14:55 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.89, wpb=101.9, bsz=40, num_updates=1380, lr=2.18631e-05, gnorm=1.872, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1557
2022-09-28 12:15:06 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 15783 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=1390, lr=2.20215e-05, gnorm=1.91, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1568
2022-09-28 12:15:18 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.87, wpb=102.6, bsz=40, num_updates=1400, lr=2.218e-05, gnorm=1.726, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1580
2022-09-28 12:15:29 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.4, ups=0.9, wpb=103.5, bsz=40, num_updates=1410, lr=2.23384e-05, gnorm=1.789, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1591
2022-09-28 12:15:41 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.5, ups=0.87, wpb=100.8, bsz=40, num_updates=1420, lr=2.24968e-05, gnorm=1.682, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1602
2022-09-28 12:15:52 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.88, wpb=103.7, bsz=40, num_updates=1430, lr=2.26553e-05, gnorm=1.818, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1614
2022-09-28 12:16:03 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=1440, lr=2.28137e-05, gnorm=1.838, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1625
2022-09-28 12:16:15 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.4, ups=0.88, wpb=100.9, bsz=40, num_updates=1450, lr=2.29721e-05, gnorm=1.9, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1636
2022-09-28 12:16:26 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.89, wpb=101, bsz=40, num_updates=1460, lr=2.31305e-05, gnorm=2.187, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1648
2022-09-28 12:16:37 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.9, ups=0.92, wpb=102.2, bsz=40, num_updates=1470, lr=2.3289e-05, gnorm=1.859, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1658
2022-09-28 12:16:48 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.8, ups=0.91, wpb=101.6, bsz=40, num_updates=1480, lr=2.34474e-05, gnorm=1.883, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1669
2022-09-28 12:16:59 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93, ups=0.91, wpb=101.8, bsz=40, num_updates=1490, lr=2.36058e-05, gnorm=1.667, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1680
2022-09-28 12:17:10 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.88, wpb=102.5, bsz=40, num_updates=1500, lr=2.37643e-05, gnorm=1.619, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1692
2022-09-28 12:17:21 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.7, ups=0.91, wpb=100.5, bsz=40, num_updates=1510, lr=2.39227e-05, gnorm=1.865, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1703
2022-09-28 12:17:32 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.2, ups=0.88, wpb=101.5, bsz=40, num_updates=1520, lr=2.40811e-05, gnorm=1.678, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1714
2022-09-28 12:17:44 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.6, ups=0.88, wpb=100, bsz=40, num_updates=1530, lr=2.42395e-05, gnorm=1.603, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1725
2022-09-28 12:17:52 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 12:17:56 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=84.8, ups=0.84, wpb=101.3, bsz=40, num_updates=1540, lr=2.4398e-05, gnorm=1.653, clip=100, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=1737
2022-09-28 12:18:07 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.5, ups=0.93, wpb=99.5, bsz=40, num_updates=1550, lr=2.45564e-05, gnorm=1.69, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1749
2022-09-28 12:18:19 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.8, ups=0.87, wpb=102.6, bsz=40, num_updates=1560, lr=2.47148e-05, gnorm=1.435, clip=100, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=1760
2022-09-28 12:18:30 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.2, ups=0.88, wpb=101.2, bsz=40, num_updates=1570, lr=2.48733e-05, gnorm=1.574, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1772
2022-09-28 12:18:41 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.1, ups=0.9, wpb=99.7, bsz=40, num_updates=1580, lr=2.50317e-05, gnorm=1.672, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1783
2022-09-28 12:18:52 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.6, ups=0.9, wpb=102.3, bsz=40, num_updates=1590, lr=2.51901e-05, gnorm=1.777, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1794
2022-09-28 12:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90, ups=0.89, wpb=100.8, bsz=40, num_updates=1600, lr=2.53485e-05, gnorm=1.712, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1805
2022-09-28 12:19:15 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=101.3, bsz=40, num_updates=1610, lr=2.5507e-05, gnorm=1.569, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1816
2022-09-28 12:19:26 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=1620, lr=2.56654e-05, gnorm=1.732, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1827
2022-09-28 12:19:37 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.87, wpb=102.6, bsz=40, num_updates=1630, lr=2.58238e-05, gnorm=1.819, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1839
2022-09-28 12:19:49 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.88, wpb=104.7, bsz=40, num_updates=1640, lr=2.59823e-05, gnorm=1.4, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1850
2022-09-28 12:20:00 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.3, ups=0.88, wpb=100.6, bsz=40, num_updates=1650, lr=2.61407e-05, gnorm=1.595, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1862
2022-09-28 12:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.88, wpb=101.1, bsz=40, num_updates=1660, lr=2.62991e-05, gnorm=1.658, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1873
2022-09-28 12:20:23 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.2, ups=0.9, wpb=101.5, bsz=40, num_updates=1670, lr=2.64575e-05, gnorm=1.548, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1884
2022-09-28 12:20:34 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.7, ups=0.9, wpb=100.5, bsz=40, num_updates=1680, lr=2.6616e-05, gnorm=1.731, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1895
2022-09-28 12:20:42 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-28 12:20:46 - progress_bar.py[line:274] - INFO: epoch 001:   1692 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=81.9, ups=0.81, wpb=101.6, bsz=40, num_updates=1690, lr=2.67744e-05, gnorm=1.787, clip=100, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1908
2022-09-28 12:20:57 - progress_bar.py[line:274] - INFO: epoch 001:   1702 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.9, wpb=100.4, bsz=40, num_updates=1700, lr=2.69328e-05, gnorm=1.572, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=1919
2022-09-28 12:21:08 - progress_bar.py[line:274] - INFO: epoch 001:   1712 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.2, ups=0.92, wpb=101.7, bsz=40, num_updates=1710, lr=2.70913e-05, gnorm=1.703, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1930
2022-09-28 12:21:19 - progress_bar.py[line:274] - INFO: epoch 001:   1722 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=1720, lr=2.72497e-05, gnorm=1.77, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1941
2022-09-28 12:21:30 - progress_bar.py[line:274] - INFO: epoch 001:   1732 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.2, ups=0.88, wpb=100.8, bsz=40, num_updates=1730, lr=2.74081e-05, gnorm=1.761, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1952
2022-09-28 12:21:42 - progress_bar.py[line:274] - INFO: epoch 001:   1742 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=1740, lr=2.75665e-05, gnorm=1.492, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1963
2022-09-28 12:21:53 - progress_bar.py[line:274] - INFO: epoch 001:   1752 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=1750, lr=2.7725e-05, gnorm=1.506, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1975
2022-09-28 12:22:04 - progress_bar.py[line:274] - INFO: epoch 001:   1762 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.2, ups=0.87, wpb=100.5, bsz=40, num_updates=1760, lr=2.78834e-05, gnorm=1.566, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1986
2022-09-28 12:22:16 - progress_bar.py[line:274] - INFO: epoch 001:   1772 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.88, wpb=102.3, bsz=40, num_updates=1770, lr=2.80418e-05, gnorm=1.435, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1998
2022-09-28 12:22:27 - progress_bar.py[line:274] - INFO: epoch 001:   1782 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.6, ups=0.89, wpb=100.9, bsz=40, num_updates=1780, lr=2.82003e-05, gnorm=1.551, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2009
2022-09-28 12:22:39 - progress_bar.py[line:274] - INFO: epoch 001:   1792 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.4, ups=0.89, wpb=104.4, bsz=40, num_updates=1790, lr=2.83587e-05, gnorm=1.396, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2020
2022-09-28 12:22:50 - progress_bar.py[line:274] - INFO: epoch 001:   1802 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.9, ups=0.91, wpb=102.8, bsz=40, num_updates=1800, lr=2.85171e-05, gnorm=1.698, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2031
2022-09-28 12:23:01 - progress_bar.py[line:274] - INFO: epoch 001:   1812 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.2, ups=0.89, wpb=101.4, bsz=40, num_updates=1810, lr=2.86755e-05, gnorm=1.584, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2043
2022-09-28 12:23:12 - progress_bar.py[line:274] - INFO: epoch 001:   1822 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.3, ups=0.89, wpb=99.2, bsz=40, num_updates=1820, lr=2.8834e-05, gnorm=1.7, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2054
2022-09-28 12:23:23 - progress_bar.py[line:274] - INFO: epoch 001:   1832 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=1830, lr=2.89924e-05, gnorm=1.464, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2065
2022-09-28 12:23:35 - progress_bar.py[line:274] - INFO: epoch 001:   1842 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.6, ups=0.89, wpb=101.5, bsz=40, num_updates=1840, lr=2.91508e-05, gnorm=1.3, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2076
2022-09-28 12:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   1852 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.3, ups=0.89, wpb=102.8, bsz=40, num_updates=1850, lr=2.93093e-05, gnorm=1.698, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2088
2022-09-28 12:23:57 - progress_bar.py[line:274] - INFO: epoch 001:   1862 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.89, wpb=101.9, bsz=40, num_updates=1860, lr=2.94677e-05, gnorm=1.652, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=2099
2022-09-28 12:24:08 - progress_bar.py[line:274] - INFO: epoch 001:   1872 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=1870, lr=2.96261e-05, gnorm=1.47, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2110
2022-09-28 12:24:20 - progress_bar.py[line:274] - INFO: epoch 001:   1882 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.88, wpb=102.6, bsz=40, num_updates=1880, lr=2.97845e-05, gnorm=1.503, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2122
2022-09-28 12:24:31 - progress_bar.py[line:274] - INFO: epoch 001:   1892 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.3, ups=0.9, wpb=100.2, bsz=40, num_updates=1890, lr=2.9943e-05, gnorm=1.761, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2133
2022-09-28 12:24:42 - progress_bar.py[line:274] - INFO: epoch 001:   1902 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=1900, lr=3.01014e-05, gnorm=1.49, clip=90, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=2144
2022-09-28 12:24:53 - progress_bar.py[line:274] - INFO: epoch 001:   1912 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.3, ups=0.92, wpb=101, bsz=40, num_updates=1910, lr=3.02598e-05, gnorm=1.526, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2155
2022-09-28 12:25:04 - progress_bar.py[line:274] - INFO: epoch 001:   1922 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=1920, lr=3.04183e-05, gnorm=1.451, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2166
2022-09-28 12:25:15 - progress_bar.py[line:274] - INFO: epoch 001:   1932 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.3, ups=0.89, wpb=103.5, bsz=40, num_updates=1930, lr=3.05767e-05, gnorm=1.596, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2177
2022-09-28 12:25:27 - progress_bar.py[line:274] - INFO: epoch 001:   1942 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.4, ups=0.9, wpb=101.1, bsz=40, num_updates=1940, lr=3.07351e-05, gnorm=1.644, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2188
2022-09-28 12:25:38 - progress_bar.py[line:274] - INFO: epoch 001:   1952 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.1, ups=0.91, wpb=101.7, bsz=40, num_updates=1950, lr=3.08935e-05, gnorm=1.43, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2199
2022-09-28 12:25:49 - progress_bar.py[line:274] - INFO: epoch 001:   1962 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.4, ups=0.88, wpb=100.3, bsz=40, num_updates=1960, lr=3.1052e-05, gnorm=1.506, clip=90, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2211
2022-09-28 12:26:00 - progress_bar.py[line:274] - INFO: epoch 001:   1972 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.5, ups=0.92, wpb=103, bsz=40, num_updates=1970, lr=3.12104e-05, gnorm=1.513, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2222
2022-09-28 12:26:11 - progress_bar.py[line:274] - INFO: epoch 001:   1982 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.91, wpb=100.4, bsz=40, num_updates=1980, lr=3.13688e-05, gnorm=1.478, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2233
2022-09-28 12:26:22 - progress_bar.py[line:274] - INFO: epoch 001:   1992 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.3, ups=0.88, wpb=100.3, bsz=40, num_updates=1990, lr=3.15272e-05, gnorm=1.41, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2244
2022-09-28 12:26:33 - progress_bar.py[line:274] - INFO: epoch 001:   2002 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.5, ups=0.92, wpb=100.5, bsz=40, num_updates=2000, lr=3.16857e-05, gnorm=1.523, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2255
2022-09-28 12:26:45 - progress_bar.py[line:274] - INFO: epoch 001:   2012 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.88, wpb=102.6, bsz=40, num_updates=2010, lr=3.18441e-05, gnorm=1.414, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2266
2022-09-28 12:26:55 - progress_bar.py[line:274] - INFO: epoch 001:   2022 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.7, ups=0.92, wpb=102.3, bsz=40, num_updates=2020, lr=3.20025e-05, gnorm=1.495, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2277
2022-09-28 12:27:06 - progress_bar.py[line:274] - INFO: epoch 001:   2032 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.6, ups=0.91, wpb=103.8, bsz=40, num_updates=2030, lr=3.2161e-05, gnorm=1.612, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2288
2022-09-28 12:27:18 - progress_bar.py[line:274] - INFO: epoch 001:   2042 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.6, ups=0.87, wpb=101, bsz=40, num_updates=2040, lr=3.23194e-05, gnorm=1.429, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2300
2022-09-28 12:27:29 - progress_bar.py[line:274] - INFO: epoch 001:   2052 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.8, ups=0.91, wpb=102.5, bsz=40, num_updates=2050, lr=3.24778e-05, gnorm=1.293, clip=90, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2311
2022-09-28 12:27:40 - progress_bar.py[line:274] - INFO: epoch 001:   2062 / 15783 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.7, ups=0.92, wpb=99.8, bsz=40, num_updates=2060, lr=3.26362e-05, gnorm=1.649, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2322
2022-09-28 12:27:51 - progress_bar.py[line:274] - INFO: epoch 001:   2072 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.89, wpb=102.1, bsz=40, num_updates=2070, lr=3.27947e-05, gnorm=1.518, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2333
2022-09-28 12:28:02 - progress_bar.py[line:274] - INFO: epoch 001:   2082 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.6, ups=0.92, wpb=101.9, bsz=40, num_updates=2080, lr=3.29531e-05, gnorm=1.486, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2344
2022-09-28 12:28:14 - progress_bar.py[line:274] - INFO: epoch 001:   2092 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.7, ups=0.87, wpb=100.5, bsz=40, num_updates=2090, lr=3.31115e-05, gnorm=1.486, clip=90, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2355
2022-09-28 12:28:24 - progress_bar.py[line:274] - INFO: epoch 001:   2102 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.9, ups=0.92, wpb=101.7, bsz=40, num_updates=2100, lr=3.327e-05, gnorm=1.515, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2366
2022-09-28 12:28:35 - progress_bar.py[line:274] - INFO: epoch 001:   2112 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.8, ups=0.9, wpb=101.1, bsz=40, num_updates=2110, lr=3.34284e-05, gnorm=1.726, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2377
2022-09-28 12:28:46 - progress_bar.py[line:274] - INFO: epoch 001:   2122 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.8, ups=0.92, wpb=101.6, bsz=40, num_updates=2120, lr=3.35868e-05, gnorm=1.424, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2388
2022-09-28 12:28:58 - progress_bar.py[line:274] - INFO: epoch 001:   2132 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.2, ups=0.89, wpb=102.3, bsz=40, num_updates=2130, lr=3.37452e-05, gnorm=1.385, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2399
2022-09-28 12:29:09 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.4, ups=0.86, wpb=101.3, bsz=40, num_updates=2140, lr=3.39037e-05, gnorm=1.418, clip=90, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=2411
2022-09-28 12:29:21 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.8, ups=0.86, wpb=101.7, bsz=40, num_updates=2150, lr=3.40621e-05, gnorm=1.316, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=2422
2022-09-28 12:29:32 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.7, ups=0.9, wpb=100.9, bsz=40, num_updates=2160, lr=3.42205e-05, gnorm=1.78, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2434
2022-09-28 12:29:43 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.89, wpb=103.3, bsz=40, num_updates=2170, lr=3.4379e-05, gnorm=1.545, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2445
2022-09-28 12:29:54 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.89, wpb=102.8, bsz=40, num_updates=2180, lr=3.45374e-05, gnorm=1.331, clip=90, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2456
2022-09-28 12:30:05 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94, ups=0.92, wpb=101.7, bsz=40, num_updates=2190, lr=3.46958e-05, gnorm=1.61, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2467
2022-09-28 12:30:16 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93, ups=0.92, wpb=101.5, bsz=40, num_updates=2200, lr=3.48542e-05, gnorm=1.46, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2478
2022-09-28 12:30:28 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.9, ups=0.87, wpb=100.5, bsz=40, num_updates=2210, lr=3.50127e-05, gnorm=1.609, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2489
2022-09-28 12:30:39 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=2220, lr=3.51711e-05, gnorm=1.594, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2501
2022-09-28 12:30:50 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.8, ups=0.91, wpb=101.2, bsz=40, num_updates=2230, lr=3.53295e-05, gnorm=1.564, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2512
2022-09-28 12:31:01 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91, ups=0.89, wpb=102.7, bsz=40, num_updates=2240, lr=3.5488e-05, gnorm=1.582, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2523
2022-09-28 12:31:13 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.5, ups=0.88, wpb=100.1, bsz=40, num_updates=2250, lr=3.56464e-05, gnorm=1.556, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2534
2022-09-28 12:31:24 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.4, ups=0.91, wpb=102.6, bsz=40, num_updates=2260, lr=3.58048e-05, gnorm=1.421, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2545
2022-09-28 12:31:35 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.3, ups=0.91, wpb=100.5, bsz=40, num_updates=2270, lr=3.59632e-05, gnorm=1.439, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2556
2022-09-28 12:31:46 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.89, wpb=101.3, bsz=40, num_updates=2280, lr=3.61217e-05, gnorm=1.338, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2568
2022-09-28 12:31:57 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.6, ups=0.89, wpb=99.8, bsz=40, num_updates=2290, lr=3.62801e-05, gnorm=1.59, clip=90, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=2579
2022-09-28 12:32:09 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.4, ups=0.89, wpb=99.6, bsz=40, num_updates=2300, lr=3.64385e-05, gnorm=1.548, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2590
2022-09-28 12:32:20 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.89, wpb=102.5, bsz=40, num_updates=2310, lr=3.6597e-05, gnorm=1.435, clip=80, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2602
2022-09-28 12:32:31 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.6, ups=0.88, wpb=102.8, bsz=40, num_updates=2320, lr=3.67554e-05, gnorm=1.327, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2613
2022-09-28 12:32:42 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.9, ups=0.9, wpb=100.1, bsz=40, num_updates=2330, lr=3.69138e-05, gnorm=1.538, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2624
2022-09-28 12:32:53 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.9, wpb=102, bsz=40, num_updates=2340, lr=3.70722e-05, gnorm=1.482, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2635
2022-09-28 12:33:05 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.2, ups=0.88, wpb=100.5, bsz=40, num_updates=2350, lr=3.72307e-05, gnorm=1.417, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2647
2022-09-28 12:33:16 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.88, wpb=102.1, bsz=40, num_updates=2360, lr=3.73891e-05, gnorm=1.273, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2658
2022-09-28 12:33:28 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.1, ups=0.89, wpb=99.3, bsz=40, num_updates=2370, lr=3.75475e-05, gnorm=1.445, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2669
2022-09-28 12:33:39 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.89, wpb=102.7, bsz=40, num_updates=2380, lr=3.7706e-05, gnorm=1.571, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2681
2022-09-28 12:33:50 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=2390, lr=3.78644e-05, gnorm=1.319, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2692
2022-09-28 12:34:02 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.87, wpb=102.4, bsz=40, num_updates=2400, lr=3.80228e-05, gnorm=1.339, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2703
2022-09-28 12:34:13 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.9, wpb=100.5, bsz=40, num_updates=2410, lr=3.81812e-05, gnorm=1.279, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2714
2022-09-28 12:34:24 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.91, wpb=101.7, bsz=40, num_updates=2420, lr=3.83397e-05, gnorm=1.516, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2725
2022-09-28 12:34:34 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.2, ups=0.93, wpb=100.5, bsz=40, num_updates=2430, lr=3.84981e-05, gnorm=1.54, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2736
2022-09-28 12:34:46 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.8, ups=0.87, wpb=100.3, bsz=40, num_updates=2440, lr=3.86565e-05, gnorm=1.366, clip=100, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=2748
2022-09-28 12:34:57 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=102.1, bsz=40, num_updates=2450, lr=3.8815e-05, gnorm=1.298, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2759
2022-09-28 12:35:09 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.89, wpb=101.5, bsz=40, num_updates=2460, lr=3.89734e-05, gnorm=1.332, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2770
2022-09-28 12:35:20 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.5, ups=0.86, wpb=102.3, bsz=40, num_updates=2470, lr=3.91318e-05, gnorm=1.472, clip=100, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=2782
2022-09-28 12:35:31 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.6, ups=0.89, wpb=100.7, bsz=40, num_updates=2480, lr=3.92902e-05, gnorm=1.432, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2793
2022-09-28 12:35:43 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=2490, lr=3.94487e-05, gnorm=1.328, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2805
2022-09-28 12:35:54 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=2500, lr=3.96071e-05, gnorm=1.376, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2816
2022-09-28 12:36:05 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.7, ups=0.89, wpb=103.1, bsz=40, num_updates=2510, lr=3.97655e-05, gnorm=1.328, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2827
2022-09-28 12:36:16 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.4, ups=0.9, wpb=100.1, bsz=40, num_updates=2520, lr=3.9924e-05, gnorm=1.459, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2838
2022-09-28 12:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.5, ups=0.89, wpb=98.8, bsz=40, num_updates=2530, lr=4.00824e-05, gnorm=1.389, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2849
2022-09-28 12:36:39 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.9, wpb=100.8, bsz=40, num_updates=2540, lr=4.02408e-05, gnorm=1.547, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2861
2022-09-28 12:36:50 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.3, ups=0.9, wpb=100.4, bsz=40, num_updates=2550, lr=4.03992e-05, gnorm=1.55, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2872
2022-09-28 12:37:01 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.3, ups=0.9, wpb=99.3, bsz=40, num_updates=2560, lr=4.05577e-05, gnorm=1.284, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2883
2022-09-28 12:37:13 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 15783 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=86.4, ups=0.87, wpb=99.4, bsz=40, num_updates=2570, lr=4.07161e-05, gnorm=1.625, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2894
2022-09-28 12:37:24 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.9, wpb=102.1, bsz=40, num_updates=2580, lr=4.08745e-05, gnorm=1.11, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2905
2022-09-28 12:37:35 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 15783 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.6, ups=0.89, wpb=99.9, bsz=40, num_updates=2590, lr=4.1033e-05, gnorm=1.356, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2917
2022-09-28 12:37:46 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.89, wpb=99.6, bsz=40, num_updates=2600, lr=4.11914e-05, gnorm=1.489, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2928
2022-09-28 12:37:58 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.8, ups=0.88, wpb=101.4, bsz=40, num_updates=2610, lr=4.13498e-05, gnorm=1.398, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2939
2022-09-28 12:38:09 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.4, ups=0.91, wpb=101.7, bsz=40, num_updates=2620, lr=4.15082e-05, gnorm=1.386, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2950
2022-09-28 12:38:20 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.3, ups=0.91, wpb=102.4, bsz=40, num_updates=2630, lr=4.16667e-05, gnorm=1.466, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2961
2022-09-28 12:38:31 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.8, ups=0.91, wpb=102.7, bsz=40, num_updates=2640, lr=4.18251e-05, gnorm=1.138, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2972
2022-09-28 12:38:42 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.3, ups=0.9, wpb=102.4, bsz=40, num_updates=2650, lr=4.19835e-05, gnorm=1.346, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2983
2022-09-28 12:38:53 - progress_bar.py[line:274] - INFO: epoch 001:   2662 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=2660, lr=4.2142e-05, gnorm=1.296, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2995
2022-09-28 12:39:04 - progress_bar.py[line:274] - INFO: epoch 001:   2672 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.6, ups=0.9, wpb=101.8, bsz=40, num_updates=2670, lr=4.23004e-05, gnorm=1.224, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3006
2022-09-28 12:39:16 - progress_bar.py[line:274] - INFO: epoch 001:   2682 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=2680, lr=4.24588e-05, gnorm=1.26, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3017
2022-09-28 12:39:27 - progress_bar.py[line:274] - INFO: epoch 001:   2692 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=2690, lr=4.26172e-05, gnorm=1.376, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3029
2022-09-28 12:39:39 - progress_bar.py[line:274] - INFO: epoch 001:   2702 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.87, wpb=100.8, bsz=40, num_updates=2700, lr=4.27757e-05, gnorm=1.197, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3040
2022-09-28 12:39:50 - progress_bar.py[line:274] - INFO: epoch 001:   2712 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.88, wpb=100.8, bsz=40, num_updates=2710, lr=4.29341e-05, gnorm=1.201, clip=80, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3052
2022-09-28 12:40:01 - progress_bar.py[line:274] - INFO: epoch 001:   2722 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.8, ups=0.89, wpb=100.1, bsz=40, num_updates=2720, lr=4.30925e-05, gnorm=1.43, clip=100, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=3063
2022-09-28 12:40:11 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 12:40:13 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=83.5, ups=0.82, wpb=102.2, bsz=40, num_updates=2730, lr=4.3251e-05, gnorm=1.221, clip=80, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=3075
2022-09-28 12:40:25 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.1, ups=0.88, wpb=103.1, bsz=40, num_updates=2740, lr=4.34094e-05, gnorm=1.247, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3086
2022-09-28 12:40:35 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.1, ups=0.93, wpb=99.9, bsz=40, num_updates=2750, lr=4.35678e-05, gnorm=1.437, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3097
2022-09-28 12:40:47 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.6, ups=0.9, wpb=102.3, bsz=40, num_updates=2760, lr=4.37262e-05, gnorm=1.274, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3108
2022-09-28 12:40:58 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.9, ups=0.92, wpb=100.4, bsz=40, num_updates=2770, lr=4.38847e-05, gnorm=1.232, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3119
2022-09-28 12:41:09 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=2780, lr=4.40431e-05, gnorm=1.006, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3130
2022-09-28 12:41:20 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=2790, lr=4.42015e-05, gnorm=1.344, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3142
2022-09-28 12:41:31 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 15783 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.8, ups=0.89, wpb=101.6, bsz=40, num_updates=2800, lr=4.43599e-05, gnorm=1.685, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3153
2022-09-28 12:41:42 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.9, wpb=101.2, bsz=40, num_updates=2810, lr=4.45184e-05, gnorm=1.277, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3164
2022-09-28 12:41:53 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.8, ups=0.9, wpb=100.5, bsz=40, num_updates=2820, lr=4.46768e-05, gnorm=1.241, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3175
2022-09-28 12:42:04 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95, ups=0.93, wpb=102.3, bsz=40, num_updates=2830, lr=4.48352e-05, gnorm=1.284, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=3186
2022-09-28 12:42:15 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.4, ups=0.9, wpb=101.9, bsz=40, num_updates=2840, lr=4.49937e-05, gnorm=1.262, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3197
2022-09-28 12:42:27 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=2850, lr=4.51521e-05, gnorm=1.19, clip=80, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=3208
2022-09-28 12:42:38 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=2860, lr=4.53105e-05, gnorm=1.535, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3220
2022-09-28 12:42:49 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=2870, lr=4.54689e-05, gnorm=1.273, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3231
2022-09-28 12:43:01 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.8, ups=0.88, wpb=101, bsz=40, num_updates=2880, lr=4.56274e-05, gnorm=1.356, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3242
2022-09-28 12:43:12 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=2890, lr=4.57858e-05, gnorm=1.121, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3254
2022-09-28 12:43:23 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.2, ups=0.92, wpb=101.3, bsz=40, num_updates=2900, lr=4.59442e-05, gnorm=1.278, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3264
2022-09-28 12:43:34 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.91, wpb=100.2, bsz=40, num_updates=2910, lr=4.61027e-05, gnorm=1.246, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3275
2022-09-28 12:43:45 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93, ups=0.92, wpb=101.3, bsz=40, num_updates=2920, lr=4.62611e-05, gnorm=1.162, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3286
2022-09-28 12:43:56 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.8, ups=0.88, wpb=101.3, bsz=40, num_updates=2930, lr=4.64195e-05, gnorm=1.283, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3298
2022-09-28 12:44:07 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.9, ups=0.9, wpb=100.9, bsz=40, num_updates=2940, lr=4.65779e-05, gnorm=1.254, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3309
2022-09-28 12:44:18 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=2950, lr=4.67364e-05, gnorm=1.163, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3320
2022-09-28 12:44:30 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.8, ups=0.89, wpb=102.3, bsz=40, num_updates=2960, lr=4.68948e-05, gnorm=1.147, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3331
2022-09-28 12:44:41 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.9, ups=0.9, wpb=100.2, bsz=40, num_updates=2970, lr=4.70532e-05, gnorm=1.317, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3343
2022-09-28 12:44:52 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=2980, lr=4.72117e-05, gnorm=1.251, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3354
2022-09-28 12:45:04 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=2990, lr=4.73701e-05, gnorm=1.547, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3365
2022-09-28 12:45:15 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.4, ups=0.89, wpb=100.6, bsz=40, num_updates=3000, lr=4.75285e-05, gnorm=1.205, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3376
2022-09-28 12:45:26 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.3, ups=0.88, wpb=100.7, bsz=40, num_updates=3010, lr=4.76869e-05, gnorm=1.192, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3388
2022-09-28 12:45:37 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90, ups=0.9, wpb=99.6, bsz=40, num_updates=3020, lr=4.78454e-05, gnorm=1.466, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3399
2022-09-28 12:45:48 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.6, ups=0.9, wpb=102.6, bsz=40, num_updates=3030, lr=4.80038e-05, gnorm=1.213, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3410
2022-09-28 12:45:59 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.9, wpb=101.4, bsz=40, num_updates=3040, lr=4.81622e-05, gnorm=1.18, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3421
2022-09-28 12:46:11 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.89, wpb=102.3, bsz=40, num_updates=3050, lr=4.83207e-05, gnorm=1.1, clip=70, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3432
2022-09-28 12:46:22 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.3, ups=0.91, wpb=100.5, bsz=40, num_updates=3060, lr=4.84791e-05, gnorm=1.25, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3443
2022-09-28 12:46:33 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.5, ups=0.93, wpb=101, bsz=40, num_updates=3070, lr=4.86375e-05, gnorm=1.347, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3454
2022-09-28 12:46:44 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.8, ups=0.88, wpb=100, bsz=40, num_updates=3080, lr=4.87959e-05, gnorm=1.353, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3466
2022-09-28 12:46:55 - progress_bar.py[line:274] - INFO: epoch 001:   3093 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.87, wpb=102.3, bsz=40, num_updates=3090, lr=4.89544e-05, gnorm=1.296, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3477
2022-09-28 12:47:06 - progress_bar.py[line:274] - INFO: epoch 001:   3103 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.5, ups=0.91, wpb=101.2, bsz=40, num_updates=3100, lr=4.91128e-05, gnorm=1.061, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3488
2022-09-28 12:47:17 - progress_bar.py[line:274] - INFO: epoch 001:   3113 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.2, ups=0.91, wpb=100.8, bsz=40, num_updates=3110, lr=4.92712e-05, gnorm=1.101, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3499
2022-09-28 12:47:28 - progress_bar.py[line:274] - INFO: epoch 001:   3123 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.6, ups=0.9, wpb=99.9, bsz=40, num_updates=3120, lr=4.94297e-05, gnorm=1.37, clip=80, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3510
2022-09-28 12:47:40 - progress_bar.py[line:274] - INFO: epoch 001:   3133 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.9, ups=0.89, wpb=101.6, bsz=40, num_updates=3130, lr=4.95881e-05, gnorm=1.266, clip=80, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=3521
2022-09-28 12:47:51 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91, ups=0.89, wpb=102, bsz=40, num_updates=3140, lr=4.97465e-05, gnorm=1.21, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3532
2022-09-28 12:48:02 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.2, ups=0.89, wpb=102.7, bsz=40, num_updates=3150, lr=4.99049e-05, gnorm=1.287, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3544
2022-09-28 12:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.89, wpb=100.4, bsz=40, num_updates=3160, lr=4.99974e-05, gnorm=1.154, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3555
2022-09-28 12:48:25 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.88, wpb=102.6, bsz=40, num_updates=3170, lr=4.99908e-05, gnorm=1.069, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3566
2022-09-28 12:48:36 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.1, ups=0.9, wpb=102, bsz=40, num_updates=3180, lr=4.99842e-05, gnorm=1.21, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3577
2022-09-28 12:48:47 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=3190, lr=4.99776e-05, gnorm=1.166, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3589
2022-09-28 12:48:58 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.89, wpb=101.8, bsz=40, num_updates=3200, lr=4.9971e-05, gnorm=1.202, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3600
2022-09-28 12:49:10 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.8, ups=0.88, wpb=100.1, bsz=40, num_updates=3210, lr=4.99644e-05, gnorm=1.132, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3611
2022-09-28 12:49:21 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=3220, lr=4.99578e-05, gnorm=1.068, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3623
2022-09-28 12:49:32 - progress_bar.py[line:274] - INFO: epoch 001:   3233 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.8, ups=0.87, wpb=100, bsz=40, num_updates=3230, lr=4.99512e-05, gnorm=1.048, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3634
2022-09-28 12:49:44 - progress_bar.py[line:274] - INFO: epoch 001:   3243 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.5, ups=0.87, wpb=100.8, bsz=40, num_updates=3240, lr=4.99446e-05, gnorm=1.283, clip=70, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3646
2022-09-28 12:49:55 - progress_bar.py[line:274] - INFO: epoch 001:   3253 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.7, ups=0.88, wpb=100.6, bsz=40, num_updates=3250, lr=4.9938e-05, gnorm=0.979, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3657
2022-09-28 12:50:06 - progress_bar.py[line:274] - INFO: epoch 001:   3263 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.9, wpb=101.4, bsz=40, num_updates=3260, lr=4.99314e-05, gnorm=1.056, clip=50, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3668
2022-09-28 12:50:18 - progress_bar.py[line:274] - INFO: epoch 001:   3273 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.89, wpb=100.1, bsz=40, num_updates=3270, lr=4.99248e-05, gnorm=1.147, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3679
2022-09-28 12:50:27 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 12:50:29 - progress_bar.py[line:274] - INFO: epoch 001:   3284 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.2, ups=0.86, wpb=100.8, bsz=40, num_updates=3280, lr=4.99182e-05, gnorm=1.167, clip=80, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=3691
2022-09-28 12:50:40 - progress_bar.py[line:274] - INFO: epoch 001:   3294 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.91, wpb=101.4, bsz=40, num_updates=3290, lr=4.99116e-05, gnorm=1.067, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3702
2022-09-28 12:50:51 - progress_bar.py[line:274] - INFO: epoch 001:   3304 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.6, ups=0.89, wpb=100.7, bsz=40, num_updates=3300, lr=4.9905e-05, gnorm=1.247, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3713
2022-09-28 12:51:02 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.2, ups=0.92, wpb=101.2, bsz=40, num_updates=3310, lr=4.98984e-05, gnorm=1.21, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3724
2022-09-28 12:51:13 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.6, ups=0.93, wpb=101.4, bsz=40, num_updates=3320, lr=4.98918e-05, gnorm=1.052, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3735
2022-09-28 12:51:24 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.1, ups=0.89, wpb=99, bsz=40, num_updates=3330, lr=4.98852e-05, gnorm=1.241, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3746
2022-09-28 12:51:35 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.4, ups=0.9, wpb=103.6, bsz=40, num_updates=3340, lr=4.98786e-05, gnorm=1.201, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3757
2022-09-28 12:51:46 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.1, ups=0.9, wpb=101.8, bsz=40, num_updates=3350, lr=4.9872e-05, gnorm=1.134, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3768
2022-09-28 12:51:58 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90, ups=0.89, wpb=101.6, bsz=40, num_updates=3360, lr=4.98654e-05, gnorm=0.972, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3779
2022-09-28 12:52:09 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.9, ups=0.88, wpb=100.8, bsz=40, num_updates=3370, lr=4.98588e-05, gnorm=1.172, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3791
2022-09-28 12:52:21 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.1, ups=0.87, wpb=101.8, bsz=40, num_updates=3380, lr=4.98522e-05, gnorm=0.986, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3802
2022-09-28 12:52:32 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.3, ups=0.9, wpb=99.7, bsz=40, num_updates=3390, lr=4.98456e-05, gnorm=1.19, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3813
2022-09-28 12:52:42 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.3, ups=0.96, wpb=100.8, bsz=40, num_updates=3400, lr=4.9839e-05, gnorm=1.133, clip=70, loss_scale=512, train_wall=10, gb_free=10.9, ema_decay=0.9999, wall=3824
2022-09-28 12:52:53 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88, ups=0.88, wpb=100.3, bsz=40, num_updates=3410, lr=4.98324e-05, gnorm=1.226, clip=90, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=3835
2022-09-28 12:53:05 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.1, ups=0.9, wpb=102, bsz=40, num_updates=3420, lr=4.98258e-05, gnorm=1.202, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3846
2022-09-28 12:53:16 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.9, ups=0.88, wpb=101, bsz=40, num_updates=3430, lr=4.98192e-05, gnorm=1.062, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3858
2022-09-28 12:53:27 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=3440, lr=4.98126e-05, gnorm=1.047, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3869
2022-09-28 12:53:39 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.87, wpb=101.7, bsz=40, num_updates=3450, lr=4.9806e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3880
2022-09-28 12:53:50 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89, ups=0.89, wpb=99.8, bsz=40, num_updates=3460, lr=4.97994e-05, gnorm=1.21, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3892
2022-09-28 12:54:01 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.3, ups=0.92, wpb=100.5, bsz=40, num_updates=3470, lr=4.97928e-05, gnorm=1.053, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3902
2022-09-28 12:54:12 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.1, ups=0.91, wpb=102.8, bsz=40, num_updates=3480, lr=4.97862e-05, gnorm=1.081, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3914
2022-09-28 12:54:23 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90, ups=0.9, wpb=100.5, bsz=40, num_updates=3490, lr=4.97796e-05, gnorm=0.995, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3925
2022-09-28 12:54:34 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.7, ups=0.91, wpb=101.3, bsz=40, num_updates=3500, lr=4.9773e-05, gnorm=1.039, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3936
2022-09-28 12:54:45 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.9, wpb=98.6, bsz=40, num_updates=3510, lr=4.97664e-05, gnorm=1.178, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3947
2022-09-28 12:54:56 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=3520, lr=4.97598e-05, gnorm=1.102, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3958
2022-09-28 12:55:07 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 15783 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.1, ups=0.91, wpb=100.5, bsz=40, num_updates=3530, lr=4.97532e-05, gnorm=1.423, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3969
2022-09-28 12:55:18 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.3, ups=0.92, wpb=100.9, bsz=40, num_updates=3540, lr=4.97466e-05, gnorm=1.054, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3980
2022-09-28 12:55:29 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.1, ups=0.89, wpb=100.8, bsz=40, num_updates=3550, lr=4.974e-05, gnorm=1.206, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3991
2022-09-28 12:55:41 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.6, ups=0.89, wpb=101.5, bsz=40, num_updates=3560, lr=4.97334e-05, gnorm=1.013, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4002
2022-09-28 12:55:52 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.88, wpb=102, bsz=40, num_updates=3570, lr=4.97268e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4014
2022-09-28 12:56:03 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.7, ups=0.89, wpb=101.6, bsz=40, num_updates=3580, lr=4.97202e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4025
2022-09-28 12:56:14 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.4, ups=0.92, wpb=101.9, bsz=40, num_updates=3590, lr=4.97136e-05, gnorm=1.024, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4036
2022-09-28 12:56:25 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.8, ups=0.9, wpb=102.8, bsz=40, num_updates=3600, lr=4.9707e-05, gnorm=1.141, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4047
2022-09-28 12:56:37 - progress_bar.py[line:274] - INFO: epoch 001:   3614 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.88, wpb=102.7, bsz=40, num_updates=3610, lr=4.97004e-05, gnorm=1.152, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4058
2022-09-28 12:56:48 - progress_bar.py[line:274] - INFO: epoch 001:   3624 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.1, ups=0.89, wpb=102, bsz=40, num_updates=3620, lr=4.96938e-05, gnorm=1.114, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4070
2022-09-28 12:56:59 - progress_bar.py[line:274] - INFO: epoch 001:   3634 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.1, ups=0.89, wpb=100.1, bsz=40, num_updates=3630, lr=4.96872e-05, gnorm=1.02, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4081
2022-09-28 12:57:10 - progress_bar.py[line:274] - INFO: epoch 001:   3644 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.1, ups=0.89, wpb=102.7, bsz=40, num_updates=3640, lr=4.96806e-05, gnorm=1.175, clip=80, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4092
2022-09-28 12:57:22 - progress_bar.py[line:274] - INFO: epoch 001:   3654 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.89, wpb=101.8, bsz=40, num_updates=3650, lr=4.9674e-05, gnorm=1.079, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4103
2022-09-28 12:57:32 - progress_bar.py[line:274] - INFO: epoch 001:   3664 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.91, wpb=100.8, bsz=40, num_updates=3660, lr=4.96674e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4114
2022-09-28 12:57:44 - progress_bar.py[line:274] - INFO: epoch 001:   3674 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.7, ups=0.9, wpb=102.6, bsz=40, num_updates=3670, lr=4.96608e-05, gnorm=1.023, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4125
2022-09-28 12:57:55 - progress_bar.py[line:274] - INFO: epoch 001:   3684 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.9, ups=0.89, wpb=99.9, bsz=40, num_updates=3680, lr=4.96542e-05, gnorm=1.204, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4136
2022-09-28 12:58:06 - progress_bar.py[line:274] - INFO: epoch 001:   3694 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.9, ups=0.93, wpb=101.5, bsz=40, num_updates=3690, lr=4.96476e-05, gnorm=0.962, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4147
2022-09-28 12:58:16 - progress_bar.py[line:274] - INFO: epoch 001:   3704 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.2, ups=0.92, wpb=102.8, bsz=40, num_updates=3700, lr=4.9641e-05, gnorm=0.992, clip=50, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4158
2022-09-28 12:58:28 - progress_bar.py[line:274] - INFO: epoch 001:   3714 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.4, ups=0.89, wpb=103.8, bsz=40, num_updates=3710, lr=4.96344e-05, gnorm=0.966, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4169
2022-09-28 12:58:39 - progress_bar.py[line:274] - INFO: epoch 001:   3724 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.89, wpb=101.8, bsz=40, num_updates=3720, lr=4.96278e-05, gnorm=0.996, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4181
2022-09-28 12:58:50 - progress_bar.py[line:274] - INFO: epoch 001:   3734 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.2, ups=0.87, wpb=100.3, bsz=40, num_updates=3730, lr=4.96212e-05, gnorm=1.15, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4192
2022-09-28 12:59:02 - progress_bar.py[line:274] - INFO: epoch 001:   3744 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.87, wpb=102.7, bsz=40, num_updates=3740, lr=4.96146e-05, gnorm=1.072, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4204
2022-09-28 12:59:13 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.88, wpb=100.9, bsz=40, num_updates=3750, lr=4.9608e-05, gnorm=1.042, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4215
2022-09-28 12:59:24 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.5, ups=0.9, wpb=103.3, bsz=40, num_updates=3760, lr=4.96014e-05, gnorm=1.063, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4226
2022-09-28 12:59:35 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=3770, lr=4.95948e-05, gnorm=1.09, clip=70, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4237
2022-09-28 12:59:47 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.1, ups=0.9, wpb=100.6, bsz=40, num_updates=3780, lr=4.95882e-05, gnorm=1.078, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4248
2022-09-28 12:59:58 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.89, wpb=102.4, bsz=40, num_updates=3790, lr=4.95816e-05, gnorm=1.05, clip=60, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4260
2022-09-28 13:00:09 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.4, ups=0.88, wpb=102.3, bsz=40, num_updates=3800, lr=4.9575e-05, gnorm=1.162, clip=60, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=4271
2022-09-28 13:00:14 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 13:00:21 - progress_bar.py[line:274] - INFO: epoch 001:   3815 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=81.7, ups=0.82, wpb=99.9, bsz=40, num_updates=3810, lr=4.95684e-05, gnorm=1.206, clip=70, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=4283
2022-09-28 13:00:32 - progress_bar.py[line:274] - INFO: epoch 001:   3825 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.7, ups=0.92, wpb=100.7, bsz=40, num_updates=3820, lr=4.95618e-05, gnorm=0.998, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4294
2022-09-28 13:00:44 - progress_bar.py[line:274] - INFO: epoch 001:   3835 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.88, wpb=101.1, bsz=40, num_updates=3830, lr=4.95552e-05, gnorm=1.216, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4305
2022-09-28 13:00:54 - progress_bar.py[line:274] - INFO: epoch 001:   3845 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.9, ups=0.93, wpb=102.4, bsz=40, num_updates=3840, lr=4.95486e-05, gnorm=1.036, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4316
2022-09-28 13:01:06 - progress_bar.py[line:274] - INFO: epoch 001:   3855 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.6, ups=0.87, wpb=103, bsz=40, num_updates=3850, lr=4.9542e-05, gnorm=1.063, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4328
2022-09-28 13:01:17 - progress_bar.py[line:274] - INFO: epoch 001:   3865 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.89, wpb=102.5, bsz=40, num_updates=3860, lr=4.95354e-05, gnorm=1.061, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4339
2022-09-28 13:01:28 - progress_bar.py[line:274] - INFO: epoch 001:   3875 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.8, ups=0.94, wpb=100.8, bsz=40, num_updates=3870, lr=4.95288e-05, gnorm=1.016, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4350
2022-09-28 13:01:39 - progress_bar.py[line:274] - INFO: epoch 001:   3885 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=101.7, bsz=40, num_updates=3880, lr=4.95222e-05, gnorm=1.073, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4361
2022-09-28 13:01:50 - progress_bar.py[line:274] - INFO: epoch 001:   3895 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=3890, lr=4.95156e-05, gnorm=1.11, clip=70, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4372
2022-09-28 13:02:02 - progress_bar.py[line:274] - INFO: epoch 001:   3905 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=3900, lr=4.9509e-05, gnorm=1.195, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4383
2022-09-28 13:02:13 - progress_bar.py[line:274] - INFO: epoch 001:   3915 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.7, ups=0.88, wpb=104.5, bsz=40, num_updates=3910, lr=4.95024e-05, gnorm=1.14, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4395
2022-09-28 13:02:24 - progress_bar.py[line:274] - INFO: epoch 001:   3925 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.6, ups=0.92, wpb=100.9, bsz=40, num_updates=3920, lr=4.94958e-05, gnorm=1.255, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4406
2022-09-28 13:02:35 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.88, wpb=102.2, bsz=40, num_updates=3930, lr=4.94892e-05, gnorm=1.021, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4417
2022-09-28 13:02:46 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.2, ups=0.89, wpb=99.9, bsz=40, num_updates=3940, lr=4.94826e-05, gnorm=1.097, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4428
2022-09-28 13:02:57 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97, ups=0.94, wpb=102.7, bsz=40, num_updates=3950, lr=4.9476e-05, gnorm=1.052, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4439
2022-09-28 13:03:08 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.2, ups=0.89, wpb=100.2, bsz=40, num_updates=3960, lr=4.94694e-05, gnorm=0.926, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4450
2022-09-28 13:03:20 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.9, ups=0.88, wpb=99.7, bsz=40, num_updates=3970, lr=4.94628e-05, gnorm=1.154, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4461
2022-09-28 13:03:31 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.87, wpb=101.1, bsz=40, num_updates=3980, lr=4.94562e-05, gnorm=1.113, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4473
2022-09-28 13:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.4, ups=0.91, wpb=101.9, bsz=40, num_updates=3990, lr=4.94496e-05, gnorm=1.181, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4484
2022-09-28 13:03:53 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.5, ups=0.92, wpb=99.9, bsz=40, num_updates=4000, lr=4.9443e-05, gnorm=1.061, clip=80, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4495
2022-09-28 13:04:04 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.3, ups=0.9, wpb=101.1, bsz=40, num_updates=4010, lr=4.94364e-05, gnorm=1.118, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4506
2022-09-28 13:04:16 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.7, ups=0.88, wpb=99.9, bsz=40, num_updates=4020, lr=4.94298e-05, gnorm=1.066, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4517
2022-09-28 13:04:26 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.5, ups=0.92, wpb=101.6, bsz=40, num_updates=4030, lr=4.94232e-05, gnorm=1.051, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4528
2022-09-28 13:04:38 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.6, ups=0.88, wpb=99.6, bsz=40, num_updates=4040, lr=4.94166e-05, gnorm=1.187, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4539
2022-09-28 13:04:49 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.3, ups=0.9, wpb=101.1, bsz=40, num_updates=4050, lr=4.941e-05, gnorm=1.094, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4551
2022-09-28 13:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.8, ups=0.94, wpb=103, bsz=40, num_updates=4060, lr=4.94034e-05, gnorm=1.032, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4561
2022-09-28 13:05:11 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.1, ups=0.88, wpb=99, bsz=40, num_updates=4070, lr=4.93968e-05, gnorm=1.281, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4573
2022-09-28 13:05:21 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.1, ups=0.95, wpb=101.8, bsz=40, num_updates=4080, lr=4.93902e-05, gnorm=1.053, clip=50, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=4583
2022-09-28 13:05:33 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.8, ups=0.89, wpb=100, bsz=40, num_updates=4090, lr=4.93836e-05, gnorm=1.029, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4594
2022-09-28 13:05:44 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.91, wpb=100.7, bsz=40, num_updates=4100, lr=4.9377e-05, gnorm=1.024, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4605
2022-09-28 13:05:55 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89, ups=0.89, wpb=100.2, bsz=40, num_updates=4110, lr=4.93704e-05, gnorm=1.122, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4617
2022-09-28 13:06:06 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.3, ups=0.93, wpb=100.4, bsz=40, num_updates=4120, lr=4.93638e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4627
2022-09-28 13:06:17 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.88, wpb=102, bsz=40, num_updates=4130, lr=4.93572e-05, gnorm=1.153, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4639
2022-09-28 13:06:28 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.88, wpb=103.5, bsz=40, num_updates=4140, lr=4.93506e-05, gnorm=1.091, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4650
2022-09-28 13:06:40 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=86.2, ups=0.87, wpb=99.1, bsz=40, num_updates=4150, lr=4.9344e-05, gnorm=1.117, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4662
2022-09-28 13:06:51 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.89, wpb=102.5, bsz=40, num_updates=4160, lr=4.93374e-05, gnorm=0.954, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4673
2022-09-28 13:07:02 - progress_bar.py[line:274] - INFO: epoch 001:   4175 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.5, ups=0.9, wpb=99.9, bsz=40, num_updates=4170, lr=4.93308e-05, gnorm=1.087, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4684
2022-09-28 13:07:13 - progress_bar.py[line:274] - INFO: epoch 001:   4185 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.9, wpb=100.9, bsz=40, num_updates=4180, lr=4.93242e-05, gnorm=1.116, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=4695
2022-09-28 13:07:25 - progress_bar.py[line:274] - INFO: epoch 001:   4195 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=4190, lr=4.93176e-05, gnorm=1.241, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4706
2022-09-28 13:07:36 - progress_bar.py[line:274] - INFO: epoch 001:   4205 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.7, ups=0.9, wpb=101.8, bsz=40, num_updates=4200, lr=4.9311e-05, gnorm=1.041, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4717
2022-09-28 13:07:47 - progress_bar.py[line:274] - INFO: epoch 001:   4215 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.9, ups=0.88, wpb=100, bsz=40, num_updates=4210, lr=4.93044e-05, gnorm=1.02, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4729
2022-09-28 13:07:59 - progress_bar.py[line:274] - INFO: epoch 001:   4225 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.86, wpb=102.1, bsz=40, num_updates=4220, lr=4.92978e-05, gnorm=1.038, clip=70, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=4740
2022-09-28 13:08:10 - progress_bar.py[line:274] - INFO: epoch 001:   4235 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.8, ups=0.88, wpb=100.8, bsz=40, num_updates=4230, lr=4.92912e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4752
2022-09-28 13:08:21 - progress_bar.py[line:274] - INFO: epoch 001:   4245 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.89, wpb=101.5, bsz=40, num_updates=4240, lr=4.92846e-05, gnorm=1.084, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4763
2022-09-28 13:08:32 - progress_bar.py[line:274] - INFO: epoch 001:   4255 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.3, ups=0.91, wpb=99.8, bsz=40, num_updates=4250, lr=4.9278e-05, gnorm=0.92, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4774
2022-09-28 13:08:44 - progress_bar.py[line:274] - INFO: epoch 001:   4265 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=4260, lr=4.92714e-05, gnorm=0.833, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4785
2022-09-28 13:08:55 - progress_bar.py[line:274] - INFO: epoch 001:   4275 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.9, ups=0.91, wpb=102.3, bsz=40, num_updates=4270, lr=4.92648e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4796
2022-09-28 13:09:06 - progress_bar.py[line:274] - INFO: epoch 001:   4285 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.1, ups=0.88, wpb=100.2, bsz=40, num_updates=4280, lr=4.92582e-05, gnorm=1.079, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4808
2022-09-28 13:09:17 - progress_bar.py[line:274] - INFO: epoch 001:   4295 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.6, ups=0.92, wpb=100.7, bsz=40, num_updates=4290, lr=4.92516e-05, gnorm=1.163, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4819
2022-09-28 13:09:28 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.5, ups=0.89, wpb=101.5, bsz=40, num_updates=4300, lr=4.9245e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4830
2022-09-28 13:09:40 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.4, ups=0.87, wpb=100.7, bsz=40, num_updates=4310, lr=4.92384e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4841
2022-09-28 13:09:48 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 13:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   4326 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=83.6, ups=0.84, wpb=99.5, bsz=40, num_updates=4320, lr=4.92318e-05, gnorm=0.947, clip=30, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=4853
2022-09-28 13:10:03 - progress_bar.py[line:274] - INFO: epoch 001:   4336 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.2, ups=0.91, wpb=102.8, bsz=40, num_updates=4330, lr=4.92252e-05, gnorm=1.095, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4864
2022-09-28 13:10:14 - progress_bar.py[line:274] - INFO: epoch 001:   4346 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.1, ups=0.87, wpb=100.5, bsz=40, num_updates=4340, lr=4.92186e-05, gnorm=1.097, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4876
2022-09-28 13:10:25 - progress_bar.py[line:274] - INFO: epoch 001:   4356 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.8, ups=0.89, wpb=101.8, bsz=40, num_updates=4350, lr=4.9212e-05, gnorm=1.021, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4887
2022-09-28 13:10:37 - progress_bar.py[line:274] - INFO: epoch 001:   4366 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.2, ups=0.88, wpb=101.2, bsz=40, num_updates=4360, lr=4.92054e-05, gnorm=0.954, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4898
2022-09-28 13:10:48 - progress_bar.py[line:274] - INFO: epoch 001:   4376 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.4, ups=0.89, wpb=101.4, bsz=40, num_updates=4370, lr=4.91988e-05, gnorm=1.009, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4910
2022-09-28 13:10:59 - progress_bar.py[line:274] - INFO: epoch 001:   4386 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91, ups=0.89, wpb=101.8, bsz=40, num_updates=4380, lr=4.91922e-05, gnorm=1.184, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4921
2022-09-28 13:11:10 - progress_bar.py[line:274] - INFO: epoch 001:   4396 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.9, ups=0.93, wpb=101.8, bsz=40, num_updates=4390, lr=4.91856e-05, gnorm=1.183, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4932
2022-09-28 13:11:21 - progress_bar.py[line:274] - INFO: epoch 001:   4406 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.89, wpb=99.9, bsz=40, num_updates=4400, lr=4.9179e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4943
2022-09-28 13:11:32 - progress_bar.py[line:274] - INFO: epoch 001:   4416 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.2, ups=0.9, wpb=101.8, bsz=40, num_updates=4410, lr=4.91724e-05, gnorm=1.041, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4954
2022-09-28 13:11:44 - progress_bar.py[line:274] - INFO: epoch 001:   4426 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.2, ups=0.88, wpb=101.5, bsz=40, num_updates=4420, lr=4.91658e-05, gnorm=1.074, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4965
2022-09-28 13:11:55 - progress_bar.py[line:274] - INFO: epoch 001:   4436 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.9, wpb=99.7, bsz=40, num_updates=4430, lr=4.91592e-05, gnorm=1.042, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4977
2022-09-28 13:12:06 - progress_bar.py[line:274] - INFO: epoch 001:   4446 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=4440, lr=4.91526e-05, gnorm=1.039, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4988
2022-09-28 13:12:17 - progress_bar.py[line:274] - INFO: epoch 001:   4456 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.5, ups=0.92, wpb=100.3, bsz=40, num_updates=4450, lr=4.9146e-05, gnorm=0.932, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4999
2022-09-28 13:12:28 - progress_bar.py[line:274] - INFO: epoch 001:   4466 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.3, ups=0.88, wpb=101.4, bsz=40, num_updates=4460, lr=4.91394e-05, gnorm=0.99, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5010
2022-09-28 13:12:40 - progress_bar.py[line:274] - INFO: epoch 001:   4476 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=4470, lr=4.91328e-05, gnorm=1.098, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5021
2022-09-28 13:12:51 - progress_bar.py[line:274] - INFO: epoch 001:   4486 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.91, wpb=100.7, bsz=40, num_updates=4480, lr=4.91262e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5032
2022-09-28 13:13:02 - progress_bar.py[line:274] - INFO: epoch 001:   4496 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.2, ups=0.89, wpb=101.1, bsz=40, num_updates=4490, lr=4.91196e-05, gnorm=1.009, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5044
2022-09-28 13:13:13 - progress_bar.py[line:274] - INFO: epoch 001:   4506 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=101.5, bsz=40, num_updates=4500, lr=4.9113e-05, gnorm=1.015, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5055
2022-09-28 13:13:24 - progress_bar.py[line:274] - INFO: epoch 001:   4516 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97, ups=0.94, wpb=102.8, bsz=40, num_updates=4510, lr=4.91064e-05, gnorm=1.12, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5065
2022-09-28 13:13:35 - progress_bar.py[line:274] - INFO: epoch 001:   4526 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.4, ups=0.91, wpb=100, bsz=40, num_updates=4520, lr=4.90998e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5076
2022-09-28 13:13:46 - progress_bar.py[line:274] - INFO: epoch 001:   4536 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.3, ups=0.92, wpb=102.6, bsz=40, num_updates=4530, lr=4.90932e-05, gnorm=1.137, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5087
2022-09-28 13:13:57 - progress_bar.py[line:274] - INFO: epoch 001:   4546 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.4, ups=0.9, wpb=102.5, bsz=40, num_updates=4540, lr=4.90866e-05, gnorm=0.957, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5098
2022-09-28 13:14:08 - progress_bar.py[line:274] - INFO: epoch 001:   4556 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.91, wpb=100.4, bsz=40, num_updates=4550, lr=4.908e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5109
2022-09-28 13:14:19 - progress_bar.py[line:274] - INFO: epoch 001:   4566 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.9, ups=0.92, wpb=100.7, bsz=40, num_updates=4560, lr=4.90734e-05, gnorm=0.891, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5120
2022-09-28 13:14:30 - progress_bar.py[line:274] - INFO: epoch 001:   4576 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92, ups=0.9, wpb=102.5, bsz=40, num_updates=4570, lr=4.90668e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5131
2022-09-28 13:14:41 - progress_bar.py[line:274] - INFO: epoch 001:   4586 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.6, ups=0.91, wpb=101.9, bsz=40, num_updates=4580, lr=4.90602e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5142
2022-09-28 13:14:52 - progress_bar.py[line:274] - INFO: epoch 001:   4596 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.5, ups=0.89, wpb=100.2, bsz=40, num_updates=4590, lr=4.90536e-05, gnorm=0.957, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5154
2022-09-28 13:15:03 - progress_bar.py[line:274] - INFO: epoch 001:   4606 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.3, ups=0.88, wpb=102.6, bsz=40, num_updates=4600, lr=4.9047e-05, gnorm=0.973, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5165
2022-09-28 13:15:15 - progress_bar.py[line:274] - INFO: epoch 001:   4616 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.88, wpb=103.2, bsz=40, num_updates=4610, lr=4.90404e-05, gnorm=0.918, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5176
2022-09-28 13:15:26 - progress_bar.py[line:274] - INFO: epoch 001:   4626 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.88, wpb=103.1, bsz=40, num_updates=4620, lr=4.90338e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5188
2022-09-28 13:15:37 - progress_bar.py[line:274] - INFO: epoch 001:   4636 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.7, ups=0.92, wpb=101.4, bsz=40, num_updates=4630, lr=4.90272e-05, gnorm=1.027, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5199
2022-09-28 13:15:48 - progress_bar.py[line:274] - INFO: epoch 001:   4646 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.5, ups=0.9, wpb=101.3, bsz=40, num_updates=4640, lr=4.90206e-05, gnorm=0.932, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5210
2022-09-28 13:15:59 - progress_bar.py[line:274] - INFO: epoch 001:   4656 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.5, ups=0.92, wpb=101, bsz=40, num_updates=4650, lr=4.9014e-05, gnorm=0.875, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5221
2022-09-28 13:16:10 - progress_bar.py[line:274] - INFO: epoch 001:   4666 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.91, wpb=101.3, bsz=40, num_updates=4660, lr=4.90074e-05, gnorm=1.092, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5232
2022-09-28 13:16:21 - progress_bar.py[line:274] - INFO: epoch 001:   4676 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.88, wpb=101.7, bsz=40, num_updates=4670, lr=4.90008e-05, gnorm=0.998, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5243
2022-09-28 13:16:33 - progress_bar.py[line:274] - INFO: epoch 001:   4686 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.7, ups=0.9, wpb=101.8, bsz=40, num_updates=4680, lr=4.89942e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=5254
2022-09-28 13:16:43 - progress_bar.py[line:274] - INFO: epoch 001:   4696 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.1, ups=0.93, wpb=99.2, bsz=40, num_updates=4690, lr=4.89876e-05, gnorm=1.006, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5265
2022-09-28 13:16:55 - progress_bar.py[line:274] - INFO: epoch 001:   4706 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.89, wpb=101.4, bsz=40, num_updates=4700, lr=4.8981e-05, gnorm=1, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5276
2022-09-28 13:17:06 - progress_bar.py[line:274] - INFO: epoch 001:   4716 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.9, wpb=101.9, bsz=40, num_updates=4710, lr=4.89744e-05, gnorm=1.176, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5288
2022-09-28 13:17:17 - progress_bar.py[line:274] - INFO: epoch 001:   4726 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.9, wpb=101.5, bsz=40, num_updates=4720, lr=4.89678e-05, gnorm=1.012, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5299
2022-09-28 13:17:28 - progress_bar.py[line:274] - INFO: epoch 001:   4736 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.91, wpb=100.4, bsz=40, num_updates=4730, lr=4.89612e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5310
2022-09-28 13:17:40 - progress_bar.py[line:274] - INFO: epoch 001:   4746 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.87, wpb=101.3, bsz=40, num_updates=4740, lr=4.89546e-05, gnorm=0.918, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5321
2022-09-28 13:17:51 - progress_bar.py[line:274] - INFO: epoch 001:   4756 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.7, ups=0.87, wpb=101.2, bsz=40, num_updates=4750, lr=4.8948e-05, gnorm=1.062, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5333
2022-09-28 13:18:02 - progress_bar.py[line:274] - INFO: epoch 001:   4766 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.5, ups=0.9, wpb=101.5, bsz=40, num_updates=4760, lr=4.89414e-05, gnorm=0.925, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5344
2022-09-28 13:18:13 - progress_bar.py[line:274] - INFO: epoch 001:   4776 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.91, wpb=101.7, bsz=40, num_updates=4770, lr=4.89348e-05, gnorm=1.075, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5355
2022-09-28 13:18:24 - progress_bar.py[line:274] - INFO: epoch 001:   4786 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.9, ups=0.93, wpb=99.1, bsz=40, num_updates=4780, lr=4.89282e-05, gnorm=0.967, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5366
2022-09-28 13:18:35 - progress_bar.py[line:274] - INFO: epoch 001:   4796 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.4, ups=0.89, wpb=100.3, bsz=40, num_updates=4790, lr=4.89216e-05, gnorm=1.071, clip=70, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5377
2022-09-28 13:18:46 - progress_bar.py[line:274] - INFO: epoch 001:   4806 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.6, ups=0.9, wpb=103.5, bsz=40, num_updates=4800, lr=4.8915e-05, gnorm=1.119, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5388
2022-09-28 13:18:58 - progress_bar.py[line:274] - INFO: epoch 001:   4816 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89, ups=0.88, wpb=101.5, bsz=40, num_updates=4810, lr=4.89084e-05, gnorm=0.982, clip=30, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=5399
2022-09-28 13:19:09 - progress_bar.py[line:274] - INFO: epoch 001:   4826 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.8, ups=0.87, wpb=101.1, bsz=40, num_updates=4820, lr=4.89018e-05, gnorm=1.032, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5411
2022-09-28 13:19:21 - progress_bar.py[line:274] - INFO: epoch 001:   4836 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.5, ups=0.88, wpb=99.9, bsz=40, num_updates=4830, lr=4.88952e-05, gnorm=0.984, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5422
2022-09-28 13:19:32 - progress_bar.py[line:274] - INFO: epoch 001:   4846 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.9, wpb=100.6, bsz=40, num_updates=4840, lr=4.88886e-05, gnorm=1.05, clip=70, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5433
2022-09-28 13:19:43 - progress_bar.py[line:274] - INFO: epoch 001:   4856 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.88, wpb=100.5, bsz=40, num_updates=4850, lr=4.8882e-05, gnorm=1.214, clip=60, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5445
2022-09-28 13:19:54 - progress_bar.py[line:274] - INFO: epoch 001:   4866 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.2, ups=0.89, wpb=100.8, bsz=40, num_updates=4860, lr=4.88754e-05, gnorm=1.187, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5456
2022-09-28 13:20:05 - progress_bar.py[line:274] - INFO: epoch 001:   4876 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.2, ups=0.89, wpb=100.8, bsz=40, num_updates=4870, lr=4.88688e-05, gnorm=1.006, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5467
2022-09-28 13:20:17 - progress_bar.py[line:274] - INFO: epoch 001:   4886 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=4880, lr=4.88622e-05, gnorm=1.085, clip=50, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5478
2022-09-28 13:20:27 - progress_bar.py[line:274] - INFO: epoch 001:   4896 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.9, ups=0.92, wpb=100.2, bsz=40, num_updates=4890, lr=4.88556e-05, gnorm=0.903, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5489
2022-09-28 13:20:39 - progress_bar.py[line:274] - INFO: epoch 001:   4906 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.2, ups=0.88, wpb=100.1, bsz=40, num_updates=4900, lr=4.8849e-05, gnorm=1.043, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5501
2022-09-28 13:20:49 - progress_bar.py[line:274] - INFO: epoch 001:   4916 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.3, ups=0.94, wpb=101.9, bsz=40, num_updates=4910, lr=4.88424e-05, gnorm=1.047, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5511
2022-09-28 13:20:59 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 13:21:02 - progress_bar.py[line:274] - INFO: epoch 001:   4927 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=81.7, ups=0.82, wpb=100.2, bsz=40, num_updates=4920, lr=4.88358e-05, gnorm=1.061, clip=30, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=5523
2022-09-28 13:21:13 - progress_bar.py[line:274] - INFO: epoch 001:   4937 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.3, ups=0.91, wpb=99.8, bsz=40, num_updates=4930, lr=4.88292e-05, gnorm=1.19, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5534
2022-09-28 13:21:24 - progress_bar.py[line:274] - INFO: epoch 001:   4947 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.7, ups=0.89, wpb=100.4, bsz=40, num_updates=4940, lr=4.88226e-05, gnorm=1.363, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5546
2022-09-28 13:21:35 - progress_bar.py[line:274] - INFO: epoch 001:   4957 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.6, ups=0.86, wpb=102.7, bsz=40, num_updates=4950, lr=4.8816e-05, gnorm=1.055, clip=50, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=5557
2022-09-28 13:21:46 - progress_bar.py[line:274] - INFO: epoch 001:   4967 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.5, ups=0.91, wpb=101.7, bsz=40, num_updates=4960, lr=4.88094e-05, gnorm=1.074, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5568
2022-09-28 13:21:58 - progress_bar.py[line:274] - INFO: epoch 001:   4977 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.9, ups=0.87, wpb=101.1, bsz=40, num_updates=4970, lr=4.88028e-05, gnorm=1.063, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5580
2022-09-28 13:22:09 - progress_bar.py[line:274] - INFO: epoch 001:   4987 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.8, ups=0.9, wpb=103.4, bsz=40, num_updates=4980, lr=4.87962e-05, gnorm=0.989, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5591
2022-09-28 13:22:21 - progress_bar.py[line:274] - INFO: epoch 001:   4997 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=101.4, bsz=40, num_updates=4990, lr=4.87896e-05, gnorm=1.013, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5602
2022-09-28 13:22:32 - progress_bar.py[line:274] - INFO: epoch 001:   5007 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.6, ups=0.89, wpb=101.7, bsz=40, num_updates=5000, lr=4.8783e-05, gnorm=0.881, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5614
2022-09-28 13:22:43 - progress_bar.py[line:274] - INFO: epoch 001:   5017 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=5010, lr=4.87764e-05, gnorm=0.816, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5625
2022-09-28 13:22:54 - progress_bar.py[line:274] - INFO: epoch 001:   5027 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=5020, lr=4.87698e-05, gnorm=0.898, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5636
2022-09-28 13:23:06 - progress_bar.py[line:274] - INFO: epoch 001:   5037 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.88, wpb=101.2, bsz=40, num_updates=5030, lr=4.87632e-05, gnorm=1.074, clip=50, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=5647
2022-09-28 13:23:17 - progress_bar.py[line:274] - INFO: epoch 001:   5047 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.9, ups=0.91, wpb=101.5, bsz=40, num_updates=5040, lr=4.87566e-05, gnorm=0.933, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5658
2022-09-28 13:23:28 - progress_bar.py[line:274] - INFO: epoch 001:   5057 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.92, wpb=100.6, bsz=40, num_updates=5050, lr=4.875e-05, gnorm=0.952, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5669
2022-09-28 13:23:39 - progress_bar.py[line:274] - INFO: epoch 001:   5067 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.1, ups=0.88, wpb=100.2, bsz=40, num_updates=5060, lr=4.87434e-05, gnorm=1.102, clip=70, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5681
2022-09-28 13:23:50 - progress_bar.py[line:274] - INFO: epoch 001:   5077 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.9, ups=0.9, wpb=103, bsz=40, num_updates=5070, lr=4.87368e-05, gnorm=1.015, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5692
2022-09-28 13:24:01 - progress_bar.py[line:274] - INFO: epoch 001:   5087 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.8, ups=0.91, wpb=101.3, bsz=40, num_updates=5080, lr=4.87302e-05, gnorm=0.998, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5703
2022-09-28 13:24:12 - progress_bar.py[line:274] - INFO: epoch 001:   5097 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.7, ups=0.9, wpb=101.4, bsz=40, num_updates=5090, lr=4.87236e-05, gnorm=0.994, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5714
2022-09-28 13:24:23 - progress_bar.py[line:274] - INFO: epoch 001:   5107 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.3, ups=0.91, wpb=102.1, bsz=40, num_updates=5100, lr=4.8717e-05, gnorm=0.971, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5725
2022-09-28 13:24:34 - progress_bar.py[line:274] - INFO: epoch 001:   5117 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.91, wpb=101.1, bsz=40, num_updates=5110, lr=4.87104e-05, gnorm=0.91, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5736
2022-09-28 13:24:45 - progress_bar.py[line:274] - INFO: epoch 001:   5127 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.4, ups=0.93, wpb=101.7, bsz=40, num_updates=5120, lr=4.87038e-05, gnorm=0.919, clip=30, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5747
2022-09-28 13:24:56 - progress_bar.py[line:274] - INFO: epoch 001:   5137 / 15783 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=86.8, ups=0.88, wpb=98.9, bsz=40, num_updates=5130, lr=4.86972e-05, gnorm=1.068, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5758
2022-09-28 13:25:07 - progress_bar.py[line:274] - INFO: epoch 001:   5147 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.6, ups=0.91, wpb=101.3, bsz=40, num_updates=5140, lr=4.86906e-05, gnorm=0.918, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5769
2022-09-28 13:25:18 - progress_bar.py[line:274] - INFO: epoch 001:   5157 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=101.2, bsz=40, num_updates=5150, lr=4.8684e-05, gnorm=0.867, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5780
2022-09-28 13:25:30 - progress_bar.py[line:274] - INFO: epoch 001:   5167 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.91, wpb=101.4, bsz=40, num_updates=5160, lr=4.86774e-05, gnorm=0.876, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5791
2022-09-28 13:25:41 - progress_bar.py[line:274] - INFO: epoch 001:   5177 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.8, ups=0.89, wpb=102.1, bsz=40, num_updates=5170, lr=4.86708e-05, gnorm=1.004, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5802
2022-09-28 13:25:52 - progress_bar.py[line:274] - INFO: epoch 001:   5187 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.89, wpb=102.1, bsz=40, num_updates=5180, lr=4.86642e-05, gnorm=0.885, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5814
2022-09-28 13:26:03 - progress_bar.py[line:274] - INFO: epoch 001:   5197 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.1, ups=0.88, wpb=103.5, bsz=40, num_updates=5190, lr=4.86576e-05, gnorm=0.888, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5825
2022-09-28 13:26:15 - progress_bar.py[line:274] - INFO: epoch 001:   5207 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.88, wpb=101.4, bsz=40, num_updates=5200, lr=4.8651e-05, gnorm=0.816, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5836
2022-09-28 13:26:26 - progress_bar.py[line:274] - INFO: epoch 001:   5217 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.2, ups=0.9, wpb=102.1, bsz=40, num_updates=5210, lr=4.86444e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5847
2022-09-28 13:26:37 - progress_bar.py[line:274] - INFO: epoch 001:   5227 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94, ups=0.92, wpb=102.7, bsz=40, num_updates=5220, lr=4.86378e-05, gnorm=0.962, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5858
2022-09-28 13:26:48 - progress_bar.py[line:274] - INFO: epoch 001:   5237 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=101.4, bsz=40, num_updates=5230, lr=4.86312e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5870
2022-09-28 13:27:00 - progress_bar.py[line:274] - INFO: epoch 001:   5247 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.88, wpb=101.1, bsz=40, num_updates=5240, lr=4.86246e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5881
2022-09-28 13:27:11 - progress_bar.py[line:274] - INFO: epoch 001:   5257 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=5250, lr=4.8618e-05, gnorm=0.934, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5893
2022-09-28 13:27:22 - progress_bar.py[line:274] - INFO: epoch 001:   5267 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.2, ups=0.93, wpb=100.2, bsz=40, num_updates=5260, lr=4.86114e-05, gnorm=1.048, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5903
2022-09-28 13:27:33 - progress_bar.py[line:274] - INFO: epoch 001:   5277 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=5270, lr=4.86048e-05, gnorm=0.931, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5915
2022-09-28 13:27:44 - progress_bar.py[line:274] - INFO: epoch 001:   5287 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.5, ups=0.91, wpb=101.1, bsz=40, num_updates=5280, lr=4.85982e-05, gnorm=1.098, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5926
2022-09-28 13:27:55 - progress_bar.py[line:274] - INFO: epoch 001:   5297 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.89, wpb=103, bsz=40, num_updates=5290, lr=4.85916e-05, gnorm=1.004, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5937
2022-09-28 13:28:06 - progress_bar.py[line:274] - INFO: epoch 001:   5307 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=5300, lr=4.8585e-05, gnorm=0.994, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5948
2022-09-28 13:28:17 - progress_bar.py[line:274] - INFO: epoch 001:   5317 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.2, ups=0.91, wpb=100.7, bsz=40, num_updates=5310, lr=4.85784e-05, gnorm=1.1, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5959
2022-09-28 13:28:29 - progress_bar.py[line:274] - INFO: epoch 001:   5327 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.9, wpb=100.5, bsz=40, num_updates=5320, lr=4.85718e-05, gnorm=1.092, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5970
2022-09-28 13:28:40 - progress_bar.py[line:274] - INFO: epoch 001:   5337 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.6, ups=0.88, wpb=100.6, bsz=40, num_updates=5330, lr=4.85652e-05, gnorm=1.019, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5982
2022-09-28 13:28:51 - progress_bar.py[line:274] - INFO: epoch 001:   5347 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.9, ups=0.88, wpb=98.6, bsz=40, num_updates=5340, lr=4.85586e-05, gnorm=1.055, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5993
2022-09-28 13:29:03 - progress_bar.py[line:274] - INFO: epoch 001:   5357 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=5350, lr=4.8552e-05, gnorm=0.867, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6004
2022-09-28 13:29:13 - progress_bar.py[line:274] - INFO: epoch 001:   5367 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.92, wpb=100.1, bsz=40, num_updates=5360, lr=4.85454e-05, gnorm=0.914, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6015
2022-09-28 13:29:25 - progress_bar.py[line:274] - INFO: epoch 001:   5377 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.9, ups=0.87, wpb=101.2, bsz=40, num_updates=5370, lr=4.85388e-05, gnorm=0.86, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6027
2022-09-28 13:29:36 - progress_bar.py[line:274] - INFO: epoch 001:   5387 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.1, ups=0.89, wpb=100, bsz=40, num_updates=5380, lr=4.85322e-05, gnorm=1.223, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6038
2022-09-28 13:29:48 - progress_bar.py[line:274] - INFO: epoch 001:   5397 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.88, wpb=101.1, bsz=40, num_updates=5390, lr=4.85256e-05, gnorm=0.999, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6049
2022-09-28 13:29:59 - progress_bar.py[line:274] - INFO: epoch 001:   5407 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.91, wpb=100.4, bsz=40, num_updates=5400, lr=4.8519e-05, gnorm=1.02, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6060
2022-09-28 13:30:10 - progress_bar.py[line:274] - INFO: epoch 001:   5417 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.92, wpb=100.2, bsz=40, num_updates=5410, lr=4.85124e-05, gnorm=1.19, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6071
2022-09-28 13:30:21 - progress_bar.py[line:274] - INFO: epoch 001:   5427 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.8, ups=0.88, wpb=100.6, bsz=40, num_updates=5420, lr=4.85058e-05, gnorm=0.982, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6083
2022-09-28 13:30:32 - progress_bar.py[line:274] - INFO: epoch 001:   5437 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.1, ups=0.93, wpb=100.2, bsz=40, num_updates=5430, lr=4.84992e-05, gnorm=1.07, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6093
2022-09-28 13:30:43 - progress_bar.py[line:274] - INFO: epoch 001:   5447 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.3, ups=0.89, wpb=100.6, bsz=40, num_updates=5440, lr=4.84926e-05, gnorm=0.9, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6105
2022-09-28 13:30:54 - progress_bar.py[line:274] - INFO: epoch 001:   5457 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.9, wpb=102.4, bsz=40, num_updates=5450, lr=4.8486e-05, gnorm=1.04, clip=50, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6116
2022-09-28 13:31:05 - progress_bar.py[line:274] - INFO: epoch 001:   5467 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.91, wpb=101.1, bsz=40, num_updates=5460, lr=4.84794e-05, gnorm=0.836, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6127
2022-09-28 13:31:16 - progress_bar.py[line:274] - INFO: epoch 001:   5477 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=100.5, bsz=40, num_updates=5470, lr=4.84728e-05, gnorm=0.953, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6138
2022-09-28 13:31:28 - progress_bar.py[line:274] - INFO: epoch 001:   5487 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.3, ups=0.87, wpb=100.5, bsz=40, num_updates=5480, lr=4.84662e-05, gnorm=0.981, clip=50, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6150
2022-09-28 13:31:39 - progress_bar.py[line:274] - INFO: epoch 001:   5497 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.8, ups=0.89, wpb=99.8, bsz=40, num_updates=5490, lr=4.84596e-05, gnorm=0.979, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6161
2022-09-28 13:31:50 - progress_bar.py[line:274] - INFO: epoch 001:   5507 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.4, ups=0.91, wpb=102.7, bsz=40, num_updates=5500, lr=4.8453e-05, gnorm=0.993, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6172
2022-09-28 13:32:01 - progress_bar.py[line:274] - INFO: epoch 001:   5517 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=5510, lr=4.84464e-05, gnorm=1.02, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6183
2022-09-28 13:32:13 - progress_bar.py[line:274] - INFO: epoch 001:   5527 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.89, wpb=101.8, bsz=40, num_updates=5520, lr=4.84398e-05, gnorm=0.894, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6194
2022-09-28 13:32:24 - progress_bar.py[line:274] - INFO: epoch 001:   5537 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.91, wpb=101, bsz=40, num_updates=5530, lr=4.84332e-05, gnorm=0.99, clip=50, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6205
2022-09-28 13:32:35 - progress_bar.py[line:274] - INFO: epoch 001:   5547 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.91, wpb=101.8, bsz=40, num_updates=5540, lr=4.84266e-05, gnorm=0.874, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6216
2022-09-28 13:32:46 - progress_bar.py[line:274] - INFO: epoch 001:   5557 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.89, wpb=102, bsz=40, num_updates=5550, lr=4.842e-05, gnorm=1.03, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6228
2022-09-28 13:32:57 - progress_bar.py[line:274] - INFO: epoch 001:   5567 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.89, wpb=101.4, bsz=40, num_updates=5560, lr=4.84134e-05, gnorm=0.957, clip=50, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6239
2022-09-28 13:33:09 - progress_bar.py[line:274] - INFO: epoch 001:   5577 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.88, wpb=101.9, bsz=40, num_updates=5570, lr=4.84068e-05, gnorm=0.949, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6250
2022-09-28 13:33:13 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 13:33:21 - progress_bar.py[line:274] - INFO: epoch 001:   5588 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=82.8, ups=0.83, wpb=100.2, bsz=40, num_updates=5580, lr=4.84002e-05, gnorm=0.971, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6262
2022-09-28 13:33:32 - progress_bar.py[line:274] - INFO: epoch 001:   5598 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.3, ups=0.88, wpb=101.2, bsz=40, num_updates=5590, lr=4.83936e-05, gnorm=1.024, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6274
2022-09-28 13:33:43 - progress_bar.py[line:274] - INFO: epoch 001:   5608 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.89, wpb=99, bsz=40, num_updates=5600, lr=4.8387e-05, gnorm=1.177, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6285
2022-09-28 13:33:55 - progress_bar.py[line:274] - INFO: epoch 001:   5618 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.89, wpb=100.7, bsz=40, num_updates=5610, lr=4.83804e-05, gnorm=0.93, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6296
2022-09-28 13:34:06 - progress_bar.py[line:274] - INFO: epoch 001:   5628 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.91, wpb=100.9, bsz=40, num_updates=5620, lr=4.83738e-05, gnorm=0.962, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6307
2022-09-28 13:34:17 - progress_bar.py[line:274] - INFO: epoch 001:   5638 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.8, ups=0.88, wpb=101, bsz=40, num_updates=5630, lr=4.83672e-05, gnorm=0.954, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6319
2022-09-28 13:34:28 - progress_bar.py[line:274] - INFO: epoch 001:   5648 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=5640, lr=4.83606e-05, gnorm=0.807, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6330
2022-09-28 13:34:40 - progress_bar.py[line:274] - INFO: epoch 001:   5658 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.2, ups=0.88, wpb=100.4, bsz=40, num_updates=5650, lr=4.8354e-05, gnorm=1.09, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6341
2022-09-28 13:34:51 - progress_bar.py[line:274] - INFO: epoch 001:   5668 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.89, wpb=101.9, bsz=40, num_updates=5660, lr=4.83474e-05, gnorm=1.044, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6353
2022-09-28 13:35:02 - progress_bar.py[line:274] - INFO: epoch 001:   5678 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.1, ups=0.88, wpb=101.1, bsz=40, num_updates=5670, lr=4.83408e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6364
2022-09-28 13:35:13 - progress_bar.py[line:274] - INFO: epoch 001:   5688 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.3, ups=0.92, wpb=101.3, bsz=40, num_updates=5680, lr=4.83342e-05, gnorm=1.029, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6375
2022-09-28 13:35:24 - progress_bar.py[line:274] - INFO: epoch 001:   5698 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.4, ups=0.92, wpb=103, bsz=40, num_updates=5690, lr=4.83276e-05, gnorm=1.018, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6386
2022-09-28 13:35:35 - progress_bar.py[line:274] - INFO: epoch 001:   5708 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.3, ups=0.9, wpb=101.3, bsz=40, num_updates=5700, lr=4.8321e-05, gnorm=1.081, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6397
2022-09-28 13:35:47 - progress_bar.py[line:274] - INFO: epoch 001:   5718 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=5710, lr=4.83144e-05, gnorm=0.959, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6408
2022-09-28 13:35:57 - progress_bar.py[line:274] - INFO: epoch 001:   5728 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.2, ups=0.94, wpb=102.4, bsz=40, num_updates=5720, lr=4.83078e-05, gnorm=0.983, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6419
2022-09-28 13:36:09 - progress_bar.py[line:274] - INFO: epoch 001:   5738 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90, ups=0.89, wpb=101.2, bsz=40, num_updates=5730, lr=4.83012e-05, gnorm=0.99, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6430
2022-09-28 13:36:20 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=5740, lr=4.82946e-05, gnorm=1.136, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6442
2022-09-28 13:36:31 - progress_bar.py[line:274] - INFO: epoch 001:   5758 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.6, ups=0.91, wpb=101.7, bsz=40, num_updates=5750, lr=4.8288e-05, gnorm=0.929, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6453
2022-09-28 13:36:42 - progress_bar.py[line:274] - INFO: epoch 001:   5768 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91, ups=0.91, wpb=99.6, bsz=40, num_updates=5760, lr=4.82814e-05, gnorm=1.044, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6463
2022-09-28 13:36:53 - progress_bar.py[line:274] - INFO: epoch 001:   5778 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.1, ups=0.93, wpb=102.7, bsz=40, num_updates=5770, lr=4.82748e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6474
2022-09-28 13:37:04 - progress_bar.py[line:274] - INFO: epoch 001:   5788 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.4, ups=0.88, wpb=100.6, bsz=40, num_updates=5780, lr=4.82682e-05, gnorm=1.07, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6486
2022-09-28 13:37:15 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.9, ups=0.92, wpb=101.6, bsz=40, num_updates=5790, lr=4.82616e-05, gnorm=1.021, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6497
2022-09-28 13:37:26 - progress_bar.py[line:274] - INFO: epoch 001:   5808 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.9, ups=0.91, wpb=103.6, bsz=40, num_updates=5800, lr=4.8255e-05, gnorm=0.979, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6508
2022-09-28 13:37:37 - progress_bar.py[line:274] - INFO: epoch 001:   5818 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.92, wpb=99, bsz=40, num_updates=5810, lr=4.82484e-05, gnorm=0.927, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6518
2022-09-28 13:37:47 - progress_bar.py[line:274] - INFO: epoch 001:   5828 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.1, ups=0.94, wpb=98.9, bsz=40, num_updates=5820, lr=4.82418e-05, gnorm=1.116, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6529
2022-09-28 13:37:59 - progress_bar.py[line:274] - INFO: epoch 001:   5838 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.6, ups=0.89, wpb=100.5, bsz=40, num_updates=5830, lr=4.82352e-05, gnorm=1.087, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6540
2022-09-28 13:38:10 - progress_bar.py[line:274] - INFO: epoch 001:   5848 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.89, wpb=100.3, bsz=40, num_updates=5840, lr=4.82286e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6552
2022-09-28 13:38:21 - progress_bar.py[line:274] - INFO: epoch 001:   5858 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.1, ups=0.91, wpb=102.2, bsz=40, num_updates=5850, lr=4.8222e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6563
2022-09-28 13:38:32 - progress_bar.py[line:274] - INFO: epoch 001:   5868 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.3, ups=0.88, wpb=99.7, bsz=40, num_updates=5860, lr=4.82154e-05, gnorm=1.107, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6574
2022-09-28 13:38:43 - progress_bar.py[line:274] - INFO: epoch 001:   5878 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.3, ups=0.91, wpb=100.1, bsz=40, num_updates=5870, lr=4.82088e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6585
2022-09-28 13:38:54 - progress_bar.py[line:274] - INFO: epoch 001:   5888 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.1, ups=0.89, wpb=102.2, bsz=40, num_updates=5880, lr=4.82022e-05, gnorm=1, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6596
2022-09-28 13:39:06 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.3, ups=0.86, wpb=101.3, bsz=40, num_updates=5890, lr=4.81956e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=6608
2022-09-28 13:39:18 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.1, ups=0.86, wpb=100.8, bsz=40, num_updates=5900, lr=4.8189e-05, gnorm=0.945, clip=20, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=6619
2022-09-28 13:39:29 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.1, ups=0.89, wpb=100.5, bsz=40, num_updates=5910, lr=4.81824e-05, gnorm=1.031, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6631
2022-09-28 13:39:40 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.1, ups=0.88, wpb=102.3, bsz=40, num_updates=5920, lr=4.81758e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6642
2022-09-28 13:39:51 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.9, wpb=101.4, bsz=40, num_updates=5930, lr=4.81692e-05, gnorm=1.028, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6653
2022-09-28 13:40:03 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.89, wpb=102.3, bsz=40, num_updates=5940, lr=4.81626e-05, gnorm=1.064, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6664
2022-09-28 13:40:14 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.9, wpb=101.7, bsz=40, num_updates=5950, lr=4.8156e-05, gnorm=1.026, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6676
2022-09-28 13:40:25 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.88, wpb=101.2, bsz=40, num_updates=5960, lr=4.81494e-05, gnorm=0.956, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6687
2022-09-28 13:40:37 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.3, ups=0.86, wpb=102.1, bsz=40, num_updates=5970, lr=4.81428e-05, gnorm=0.937, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6698
2022-09-28 13:40:48 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.3, ups=0.89, wpb=102.6, bsz=40, num_updates=5980, lr=4.81362e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6710
2022-09-28 13:40:59 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.88, wpb=101.8, bsz=40, num_updates=5990, lr=4.81296e-05, gnorm=0.948, clip=30, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6721
2022-09-28 13:41:11 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.6, ups=0.89, wpb=103.2, bsz=40, num_updates=6000, lr=4.8123e-05, gnorm=1.015, clip=30, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6732
2022-09-28 13:41:11 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-28 13:41:11 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-28 13:41:12 - train.py[line:549] - INFO: 0 / 3047
2022-09-28 13:41:12 - train.py[line:551] - INFO: load:0.98 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-28 13:41:14 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 13.05 GiB (GPU 1; 39.59 GiB total capacity; 13.92 GiB already allocated; 8.91 GiB free; 28.20 GiB reserved in total by PyTorch)
2022-09-28 13:41:14 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-28 13:41:14 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 10        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   14254 MB |   16996 MB |    1029 TB |    1029 TB |
|       from large pool |   14109 MB |   16850 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   14254 MB |   16996 MB |    1029 TB |    1029 TB |
|       from large pool |   14109 MB |   16850 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   28878 MB |   37844 MB |  142512 MB |  113634 MB |
|       from large pool |   28732 MB |   37696 MB |  142156 MB |  113424 MB |
|       from small pool |     146 MB |     148 MB |     356 MB |     210 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   14623 MB |   15503 MB |  770332 GB |  770318 GB |
|       from large pool |   14622 MB |   15501 MB |  769563 GB |  769548 GB |
|       from small pool |       0 MB |       2 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    3641    |    3655    |   31923 K  |   31920 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15695 K  |   15692 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3641    |    3655    |   31923 K  |   31920 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15695 K  |   15692 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     207    |     291    |     595    |     388    |
|       from large pool |     134    |     217    |     417    |     283    |
|       from small pool |      73    |      74    |     178    |     105    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     141    |     149    |   17542 K  |   17542 K  |
|       from large pool |      99    |     106    |    9736 K  |    9736 K  |
|       from small pool |      42    |      51    |    7805 K  |    7805 K  |
|===========================================================================|

2022-09-28 13:41:14 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-28 13:41:15 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 14.98 GiB already allocated; 11.19 GiB free; 25.92 GiB reserved in total by PyTorch)
2022-09-28 13:41:15 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15339 MB |   18306 MB |    1029 TB |    1029 TB |
|       from large pool |   15193 MB |   18159 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   15339 MB |   18306 MB |    1029 TB |    1029 TB |
|       from large pool |   15193 MB |   18159 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26542 MB |   37668 MB |  154242 MB |  127700 MB |
|       from large pool |   26394 MB |   37520 MB |  153860 MB |  127466 MB |
|       from small pool |     148 MB |     148 MB |     382 MB |     234 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   11202 MB |   11982 MB |  738605 GB |  738594 GB |
|       from large pool |   11200 MB |   11980 MB |  737835 GB |  737824 GB |
|       from small pool |       2 MB |       2 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    3641    |    3655    |   31923 K  |   31920 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15695 K  |   15692 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3641    |    3655    |   31923 K  |   31920 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15695 K  |   15692 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     204    |     292    |     617    |     413    |
|       from large pool |     130    |     218    |     426    |     296    |
|       from small pool |      74    |      74    |     191    |     117    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     144    |     149    |   17256 K  |   17256 K  |
|       from large pool |     103    |     107    |    9451 K  |    9451 K  |
|       from small pool |      41    |      48    |    7805 K  |    7805 K  |
|===========================================================================|

2022-09-28 13:41:15 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-28 13:41:15 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-28 13:41:16 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 13.05 GiB (GPU 1; 39.59 GiB total capacity; 23.00 GiB already allocated; 13.04 GiB free; 24.07 GiB reserved in total by PyTorch)
2022-09-28 13:41:16 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-28 13:41:16 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   23550 MB |   26292 MB |    1029 TB |    1029 TB |
|       from large pool |   23431 MB |   26172 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   23550 MB |   26292 MB |    1029 TB |    1029 TB |
|       from large pool |   23431 MB |   26172 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   24652 MB |   37844 MB |  163212 MB |  138560 MB |
|       from large pool |   24530 MB |   37696 MB |  162856 MB |  138326 MB |
|       from small pool |     122 MB |     148 MB |     356 MB |     234 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1101 MB |   15503 MB |  770392 GB |  770391 GB |
|       from large pool |    1098 MB |   15501 MB |  769622 GB |  769621 GB |
|       from small pool |       2 MB |       4 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    2997    |    3655    |   31929 K  |   31926 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15699 K  |   15696 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    2997    |    3655    |   31929 K  |   31926 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15699 K  |   15696 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     130    |     291    |     616    |     486    |
|       from large pool |      69    |     217    |     438    |     369    |
|       from small pool |      61    |      74    |     178    |     117    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     124    |     196    |   17547 K  |   17547 K  |
|       from large pool |      58    |     106    |    9737 K  |    9737 K  |
|       from small pool |      66    |     107    |    7809 K  |    7809 K  |
|===========================================================================|

Traceback (most recent call last):
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 13.05 GiB (GPU 1; 39.59 GiB total capacity; 13.92 GiB already allocated; 8.91 GiB free; 28.20 GiB reserved in total by PyTorch)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 630, in <module>
    cli_main()
  File "../../train.py", line 623, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "../../train.py", line 332, in train
    cfg, trainer, task, epoch_itr, valid_subsets, end_of_epoch
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, (pred_scores, pred, sample_ids), time_info = trainer.valid_step(sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1088, in valid_step
    return self.valid_step(sample, raise_oom=True)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1089, in valid_step
    raise e
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 13.05 GiB (GPU 1; 39.59 GiB total capacity; 23.00 GiB already allocated; 13.04 GiB free; 24.07 GiB reserved in total by PyTorch)
2022-09-28 13:41:17 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 25.12 GiB already allocated; 10.81 GiB free; 26.30 GiB reserved in total by PyTorch)
2022-09-28 13:41:17 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 12        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   25719 MB |   28687 MB |    1029 TB |    1029 TB |
|       from large pool |   25600 MB |   28566 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   25719 MB |   28687 MB |    1029 TB |    1029 TB |
|       from large pool |   25600 MB |   28566 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26934 MB |   37748 MB |  175852 MB |  148918 MB |
|       from large pool |   26810 MB |   37624 MB |  175470 MB |  148660 MB |
|       from small pool |     124 MB |     148 MB |     382 MB |     258 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1214 MB |   11982 MB |  738678 GB |  738677 GB |
|       from large pool |    1209 MB |   11980 MB |  737908 GB |  737907 GB |
|       from small pool |       4 MB |       6 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    2997    |    3655    |   31929 K  |   31926 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15699 K  |   15696 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    2997    |    3655    |   31929 K  |   31926 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15699 K  |   15696 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     116    |     292    |     631    |     515    |
|       from large pool |      54    |     218    |     440    |     386    |
|       from small pool |      62    |      74    |     191    |     129    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     124    |     191    |   17261 K  |   17261 K  |
|       from large pool |      57    |     107    |    9452 K  |    9452 K  |
|       from small pool |      67    |     115    |    7809 K  |    7809 K  |
|===========================================================================|

2022-09-28 13:41:17 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

Traceback (most recent call last):
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 14.98 GiB already allocated; 11.19 GiB free; 25.92 GiB reserved in total by PyTorch)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 630, in <module>
    cli_main()
  File "../../train.py", line 623, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "../../train.py", line 332, in train
    cfg, trainer, task, epoch_itr, valid_subsets, end_of_epoch
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, (pred_scores, pred, sample_ids), time_info = trainer.valid_step(sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1088, in valid_step
    return self.valid_step(sample, raise_oom=True)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1089, in valid_step
    raise e
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 25.12 GiB already allocated; 10.81 GiB free; 26.30 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/50_way_allcand', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=15', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=5', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=6000', '--validate-interval-updates=6000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 953
Killing subprocess 954
2022-09-28 15:54:49 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-09-28 15:54:49 - utils.py[line:261] - INFO: Start init
2022-09-28 15:54:50 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-09-28 15:54:50 - utils.py[line:261] - INFO: Start init
2022-09-28 15:54:50 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-09-28 15:54:51 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-09-28 15:54:51 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-09-28 15:54:51 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-09-28 15:54:54 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/50_way_allcand', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 6000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 6000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', save_interval=10, save_interval_updates=6000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/50_way_allcand', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=6000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-09-28 15:54:54 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-09-28 15:54:54 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-09-28 15:54:59 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-09-28 15:54:59 - train.py[line:118] - INFO: task: VqaGenTask
2022-09-28 15:54:59 - train.py[line:119] - INFO: model: OFAModel
2022-09-28 15:54:59 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-09-28 15:54:59 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-09-28 15:54:59 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv slice_id 0 row count 141030 total row count 282060
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv slice_id 1 row count 141030 total row count 282060
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-28 15:54:59 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-09-28 15:54:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-09-28 15:55:00 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 15:55:00 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 15:55:00 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 15:55:00 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 15:55:00 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-09-28 15:55:00 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-09-28 15:55:00 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-09-28 15:55:03 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 15:55:03 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 15:55:04 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-09-28 15:55:04 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-09-28 15:55:05 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-09-28 15:55:05 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 0 row count 315642 total row count 631284
2022-09-28 15:55:05 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 1 row count 315642 total row count 631284
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 15:55:06 - trainer.py[line:707] - INFO: begin training epoch 1
2022-09-28 15:55:06 - train.py[line:312] - INFO: Start iterating over samples
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 15:55:22 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 15783 loss=1.323, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=86.2, ups=0.84, wpb=102.4, bsz=40, num_updates=10, lr=1.58428e-07, gnorm=14.869, clip=100, loss_scale=128, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=22
2022-09-28 15:55:33 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 15783 loss=1.339, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=85.7, ups=0.85, wpb=100.6, bsz=40, num_updates=20, lr=3.16857e-07, gnorm=13.453, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=34
2022-09-28 15:55:45 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 15783 loss=1.399, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=87.8, ups=0.87, wpb=100.6, bsz=40, num_updates=30, lr=4.75285e-07, gnorm=15.341, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45
2022-09-28 15:55:56 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 15783 loss=1.273, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=87.9, ups=0.86, wpb=102.1, bsz=40, num_updates=40, lr=6.33714e-07, gnorm=10.969, clip=100, loss_scale=128, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=57
2022-09-28 15:56:08 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 15783 loss=1.226, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=88.6, ups=0.87, wpb=102.4, bsz=40, num_updates=50, lr=7.92142e-07, gnorm=10.893, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=68
2022-09-28 15:56:19 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 15783 loss=1.208, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=87.4, ups=0.87, wpb=100.4, bsz=40, num_updates=60, lr=9.5057e-07, gnorm=8.953, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80
2022-09-28 15:56:31 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 15783 loss=1.135, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=70, lr=1.109e-06, gnorm=8.22, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=91
2022-09-28 15:56:42 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 15783 loss=1.09, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=90.4, ups=0.88, wpb=103.2, bsz=40, num_updates=80, lr=1.26743e-06, gnorm=7.344, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 848770
Killing subprocess 848771
Main process received SIGINT, exiting
2022-09-28 15:57:02 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-09-28 15:57:02 - utils.py[line:261] - INFO: Start init
2022-09-28 15:57:02 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-09-28 15:57:02 - utils.py[line:261] - INFO: Start init
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 850965
Killing subprocess 850966
Main process received SIGINT, exiting
2022-09-28 15:57:15 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-09-28 15:57:15 - utils.py[line:261] - INFO: Start init
2022-09-28 15:57:15 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-09-28 15:57:15 - utils.py[line:261] - INFO: Start init
2022-09-28 15:57:16 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-09-28 15:57:16 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-09-28 15:57:16 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-09-28 15:57:16 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-09-28 15:57:20 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/50_way_allcand', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 6000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 6000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', save_interval=10, save_interval_updates=6000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/50_way_allcand', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=6000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-09-28 15:57:20 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-09-28 15:57:20 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-09-28 15:57:24 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-09-28 15:57:24 - train.py[line:118] - INFO: task: VqaGenTask
2022-09-28 15:57:24 - train.py[line:119] - INFO: model: OFAModel
2022-09-28 15:57:24 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-09-28 15:57:24 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-09-28 15:57:24 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv slice_id 1 row count 141030 total row count 282060
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv slice_id 0 row count 141030 total row count 282060
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-28 15:57:25 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-09-28 15:57:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-09-28 15:57:25 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 15:57:25 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 15:57:25 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 15:57:25 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 15:57:25 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-09-28 15:57:25 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-09-28 15:57:25 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-09-28 15:57:27 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 15:57:27 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 15:57:28 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-09-28 15:57:28 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-09-28 15:57:28 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-09-28 15:57:28 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 0 row count 315642 total row count 631284
2022-09-28 15:57:29 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 1 row count 315642 total row count 631284
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 15:57:29 - trainer.py[line:707] - INFO: begin training epoch 1
2022-09-28 15:57:29 - train.py[line:312] - INFO: Start iterating over samples
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 15:57:46 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 15783 loss=1.323, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=86.1, ups=0.84, wpb=102.4, bsz=40, num_updates=10, lr=1.58428e-07, gnorm=14.888, clip=100, loss_scale=128, train_wall=15, gb_free=10.5, ema_decay=0.9999, wall=21
2022-09-28 15:57:57 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 15783 loss=1.339, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=85.5, ups=0.85, wpb=100.6, bsz=40, num_updates=20, lr=3.16857e-07, gnorm=13.455, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=33
2022-09-28 15:58:09 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 15783 loss=1.399, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=87.7, ups=0.87, wpb=100.6, bsz=40, num_updates=30, lr=4.75285e-07, gnorm=15.367, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44
2022-09-28 15:58:21 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 15783 loss=1.273, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=86.9, ups=0.85, wpb=102.1, bsz=40, num_updates=40, lr=6.33714e-07, gnorm=10.969, clip=100, loss_scale=128, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=56
2022-09-28 15:58:32 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 15783 loss=1.226, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=88.4, ups=0.86, wpb=102.4, bsz=40, num_updates=50, lr=7.92142e-07, gnorm=10.89, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=67
2022-09-28 15:58:44 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 15783 loss=1.208, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=87.4, ups=0.87, wpb=100.4, bsz=40, num_updates=60, lr=9.5057e-07, gnorm=8.954, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79
2022-09-28 15:58:55 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 15783 loss=1.135, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=70, lr=1.109e-06, gnorm=8.245, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=90
2022-09-28 15:59:06 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 15783 loss=1.09, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=89.9, ups=0.87, wpb=103.2, bsz=40, num_updates=80, lr=1.26743e-06, gnorm=7.336, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102
2022-09-28 15:59:18 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 15783 loss=1.105, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=88.1, ups=0.87, wpb=101.2, bsz=40, num_updates=90, lr=1.42586e-06, gnorm=6.135, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=113
2022-09-28 15:59:29 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 15783 loss=1.064, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=87.9, ups=0.87, wpb=101, bsz=40, num_updates=100, lr=1.58428e-06, gnorm=5.482, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125
2022-09-28 15:59:41 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 15783 loss=1.051, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=88.5, ups=0.87, wpb=101.4, bsz=40, num_updates=110, lr=1.74271e-06, gnorm=5.302, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=136
2022-09-28 15:59:52 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 15783 loss=1.054, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=88, ups=0.88, wpb=100.3, bsz=40, num_updates=120, lr=1.90114e-06, gnorm=5.048, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=147
2022-09-28 16:00:04 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 15783 loss=1.039, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=89.2, ups=0.89, wpb=100.4, bsz=40, num_updates=130, lr=2.05957e-06, gnorm=4.808, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=159
2022-09-28 16:00:15 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 15783 loss=0.956, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=88.9, ups=0.87, wpb=101.8, bsz=40, num_updates=140, lr=2.218e-06, gnorm=4.309, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=170
2022-09-28 16:00:26 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 15783 loss=0.965, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=90.7, ups=0.89, wpb=102.2, bsz=40, num_updates=150, lr=2.37643e-06, gnorm=4.043, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=181
2022-09-28 16:00:37 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 15783 loss=0.922, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=93.7, ups=0.91, wpb=102.5, bsz=40, num_updates=160, lr=2.53485e-06, gnorm=4.174, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=192
2022-09-28 16:00:49 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 15783 loss=0.916, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=87.1, ups=0.87, wpb=100.6, bsz=40, num_updates=170, lr=2.69328e-06, gnorm=3.614, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=204
2022-09-28 16:01:00 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 15783 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=89.9, ups=0.87, wpb=102.9, bsz=40, num_updates=180, lr=2.85171e-06, gnorm=3.623, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=215
2022-09-28 16:01:12 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 15783 loss=0.954, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=87.2, ups=0.88, wpb=99.5, bsz=40, num_updates=190, lr=3.01014e-06, gnorm=3.716, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=227
2022-09-28 16:01:23 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 15783 loss=0.926, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=89.8, ups=0.88, wpb=102.6, bsz=40, num_updates=200, lr=3.16857e-06, gnorm=3.737, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=238
2022-09-28 16:01:34 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 15783 loss=0.959, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=91.1, ups=0.9, wpb=101.3, bsz=40, num_updates=210, lr=3.327e-06, gnorm=3.19, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=249
2022-09-28 16:01:46 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 15783 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.702, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=91, ups=0.88, wpb=102.9, bsz=40, num_updates=220, lr=3.48542e-06, gnorm=3.075, clip=100, loss_scale=128, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=261
2022-09-28 16:01:57 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 15783 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=88.8, ups=0.86, wpb=103, bsz=40, num_updates=230, lr=3.64385e-06, gnorm=3.105, clip=100, loss_scale=128, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=272
2022-09-28 16:02:09 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 15783 loss=0.907, loss_v1=0, loss_v2=0, nll_loss=0.741, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=89.6, ups=0.88, wpb=101.3, bsz=40, num_updates=240, lr=3.80228e-06, gnorm=3.182, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=284
2022-09-28 16:02:20 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 15783 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.717, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=92.4, ups=0.91, wpb=101.2, bsz=40, num_updates=250, lr=3.96071e-06, gnorm=3.028, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=295
2022-09-28 16:02:30 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 15783 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=95.1, ups=0.93, wpb=102.3, bsz=40, num_updates=260, lr=4.11914e-06, gnorm=2.988, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=306
2022-09-28 16:02:42 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 15783 loss=0.956, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=88.9, ups=0.89, wpb=99.9, bsz=40, num_updates=270, lr=4.27757e-06, gnorm=3.098, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=317
2022-09-28 16:02:53 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 15783 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=280, lr=4.43599e-06, gnorm=3.103, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=328
2022-09-28 16:03:04 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 15783 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=90.6, ups=0.9, wpb=100.7, bsz=40, num_updates=290, lr=4.59442e-06, gnorm=3.11, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=339
2022-09-28 16:03:15 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 15783 loss=1.001, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=98.1, nsentences=40, sample_size=98.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=88, ups=0.9, wpb=98.1, bsz=40, num_updates=300, lr=4.75285e-06, gnorm=2.911, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=350
2022-09-28 16:03:26 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 15783 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=93.4, ups=0.91, wpb=102.1, bsz=40, num_updates=310, lr=4.91128e-06, gnorm=2.911, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=361
2022-09-28 16:03:37 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 15783 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=88.6, ups=0.88, wpb=100.7, bsz=40, num_updates=320, lr=5.06971e-06, gnorm=2.966, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=373
2022-09-28 16:03:48 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 15783 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=95.9, ups=0.94, wpb=102.3, bsz=40, num_updates=330, lr=5.22814e-06, gnorm=2.864, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=383
2022-09-28 16:03:59 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 15783 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=90.7, ups=0.9, wpb=101, bsz=40, num_updates=340, lr=5.38657e-06, gnorm=2.621, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=394
2022-09-28 16:04:10 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 15783 loss=0.819, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=93.9, ups=0.91, wpb=102.9, bsz=40, num_updates=350, lr=5.54499e-06, gnorm=2.575, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=405
2022-09-28 16:04:22 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 15783 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=90, ups=0.88, wpb=102.5, bsz=40, num_updates=360, lr=5.70342e-06, gnorm=2.888, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=417
2022-09-28 16:04:33 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 15783 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=91, ups=0.9, wpb=101.3, bsz=40, num_updates=370, lr=5.86185e-06, gnorm=2.658, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=428
2022-09-28 16:04:44 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 15783 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=86.8, ups=0.86, wpb=101, bsz=40, num_updates=380, lr=6.02028e-06, gnorm=2.824, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=440
2022-09-28 16:04:56 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 15783 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.5, ups=0.88, wpb=102.5, bsz=40, num_updates=390, lr=6.17871e-06, gnorm=2.855, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=451
2022-09-28 16:05:07 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 15783 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=93.1, ups=0.93, wpb=100.6, bsz=40, num_updates=400, lr=6.33714e-06, gnorm=2.916, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=462
2022-09-28 16:05:17 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 15783 loss=0.833, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=93.8, ups=0.93, wpb=101.2, bsz=40, num_updates=410, lr=6.49556e-06, gnorm=2.703, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=472
2022-09-28 16:05:29 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 15783 loss=0.857, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=88.6, ups=0.89, wpb=99.7, bsz=40, num_updates=420, lr=6.65399e-06, gnorm=2.913, clip=100, loss_scale=128, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=484
2022-09-28 16:05:40 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 15783 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.72, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=90.9, ups=0.9, wpb=100.6, bsz=40, num_updates=430, lr=6.81242e-06, gnorm=2.758, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=495
2022-09-28 16:05:51 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 15783 loss=0.854, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=86.9, ups=0.87, wpb=100.2, bsz=40, num_updates=440, lr=6.97085e-06, gnorm=2.796, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=506
2022-09-28 16:06:03 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 15783 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=88.5, ups=0.89, wpb=99.7, bsz=40, num_updates=450, lr=7.12928e-06, gnorm=2.862, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=518
2022-09-28 16:06:14 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 15783 loss=0.826, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=88.5, ups=0.88, wpb=100.8, bsz=40, num_updates=460, lr=7.28771e-06, gnorm=2.603, clip=100, loss_scale=128, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=529
2022-09-28 16:06:25 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 15783 loss=0.79, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=91.7, ups=0.9, wpb=102, bsz=40, num_updates=470, lr=7.44613e-06, gnorm=2.821, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=540
2022-09-28 16:06:36 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 15783 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=89.9, ups=0.88, wpb=102.5, bsz=40, num_updates=480, lr=7.60456e-06, gnorm=2.684, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=552
2022-09-28 16:06:48 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 15783 loss=0.783, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=490, lr=7.76299e-06, gnorm=3.045, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=563
2022-09-28 16:06:58 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 15783 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=93, ups=0.92, wpb=101.5, bsz=40, num_updates=500, lr=7.92142e-06, gnorm=2.975, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=574
2022-09-28 16:07:10 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 15783 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=86.8, ups=0.86, wpb=100.6, bsz=40, num_updates=510, lr=8.07985e-06, gnorm=2.999, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=585
2022-09-28 16:07:21 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 15783 loss=0.807, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=89.1, ups=0.88, wpb=101.5, bsz=40, num_updates=520, lr=8.23828e-06, gnorm=2.978, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=597
2022-09-28 16:07:32 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 15783 loss=0.81, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=93.3, ups=0.93, wpb=100.1, bsz=40, num_updates=530, lr=8.3967e-06, gnorm=2.844, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=607
2022-09-28 16:07:44 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 15783 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=540, lr=8.55513e-06, gnorm=2.83, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=619
2022-09-28 16:07:54 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 15783 loss=0.736, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96, ups=0.94, wpb=101.9, bsz=40, num_updates=550, lr=8.71356e-06, gnorm=2.565, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=629
2022-09-28 16:08:05 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 15783 loss=0.785, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.2, ups=0.88, wpb=100.8, bsz=40, num_updates=560, lr=8.87199e-06, gnorm=2.874, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=641
2022-09-28 16:08:17 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 15783 loss=0.748, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=91, ups=0.89, wpb=102.2, bsz=40, num_updates=570, lr=9.03042e-06, gnorm=2.541, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=652
2022-09-28 16:08:28 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 15783 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=92.3, ups=0.9, wpb=102.5, bsz=40, num_updates=580, lr=9.18885e-06, gnorm=2.604, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=663
2022-09-28 16:08:39 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.2, ups=0.89, wpb=103.4, bsz=40, num_updates=590, lr=9.34728e-06, gnorm=2.299, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=674
2022-09-28 16:08:50 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 15783 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.9, ups=0.88, wpb=102.8, bsz=40, num_updates=600, lr=9.5057e-06, gnorm=3.168, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=685
2022-09-28 16:09:02 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 15783 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.5, ups=0.89, wpb=103.4, bsz=40, num_updates=610, lr=9.66413e-06, gnorm=2.693, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=697
2022-09-28 16:09:13 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.4, ups=0.88, wpb=102, bsz=40, num_updates=620, lr=9.82256e-06, gnorm=2.184, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=708
2022-09-28 16:09:25 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 15783 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.4, ups=0.88, wpb=103.1, bsz=40, num_updates=630, lr=9.98099e-06, gnorm=2.592, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=720
2022-09-28 16:09:36 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.5, ups=0.88, wpb=103.4, bsz=40, num_updates=640, lr=1.01394e-05, gnorm=2.346, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=731
2022-09-28 16:09:47 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 15783 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=89.3, ups=0.89, wpb=100.8, bsz=40, num_updates=650, lr=1.02978e-05, gnorm=2.426, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=742
2022-09-28 16:09:58 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 15783 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=92.7, ups=0.92, wpb=100.7, bsz=40, num_updates=660, lr=1.04563e-05, gnorm=2.449, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=753
2022-09-28 16:10:10 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 15783 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=88, ups=0.88, wpb=100.2, bsz=40, num_updates=670, lr=1.06147e-05, gnorm=2.372, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=765
2022-09-28 16:10:21 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 15783 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=89.3, ups=0.88, wpb=101.5, bsz=40, num_updates=680, lr=1.07731e-05, gnorm=2.579, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=776
2022-09-28 16:10:32 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 15783 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.8, ups=0.89, wpb=101.8, bsz=40, num_updates=690, lr=1.09316e-05, gnorm=2.469, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=787
2022-09-28 16:10:43 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 15783 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.4, ups=0.92, wpb=99.9, bsz=40, num_updates=700, lr=1.109e-05, gnorm=2.552, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=798
2022-09-28 16:10:54 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 15783 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.7, ups=0.88, wpb=102.3, bsz=40, num_updates=710, lr=1.12484e-05, gnorm=2.337, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=809
2022-09-28 16:11:05 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.8, ups=0.93, wpb=102.5, bsz=40, num_updates=720, lr=1.14068e-05, gnorm=2.29, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=820
2022-09-28 16:11:16 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 15783 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.9, ups=0.91, wpb=101.3, bsz=40, num_updates=730, lr=1.15653e-05, gnorm=2.408, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=831
2022-09-28 16:11:27 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 15783 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.6, ups=0.88, wpb=101.5, bsz=40, num_updates=740, lr=1.17237e-05, gnorm=2.344, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=843
2022-09-28 16:11:39 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=750, lr=1.18821e-05, gnorm=2.228, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=854
2022-09-28 16:11:50 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 15783 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.6, ups=0.87, wpb=100.3, bsz=40, num_updates=760, lr=1.20406e-05, gnorm=2.229, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=865
2022-09-28 16:12:02 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.2, ups=0.86, wpb=102.3, bsz=40, num_updates=770, lr=1.2199e-05, gnorm=2.317, clip=100, loss_scale=256, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=877
2022-09-28 16:12:13 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 15783 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.9, ups=0.89, wpb=102, bsz=40, num_updates=780, lr=1.23574e-05, gnorm=2.272, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=888
2022-09-28 16:12:24 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 15783 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=93.2, ups=0.93, wpb=100.1, bsz=40, num_updates=790, lr=1.25158e-05, gnorm=2.658, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=899
2022-09-28 16:12:34 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 15783 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.6, ups=0.93, wpb=98.8, bsz=40, num_updates=800, lr=1.26743e-05, gnorm=2.502, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=909
2022-09-28 16:12:46 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 15783 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.7, ups=0.87, wpb=101.6, bsz=40, num_updates=810, lr=1.28327e-05, gnorm=2.175, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=921
2022-09-28 16:12:57 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 15783 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.2, ups=0.9, wpb=101.2, bsz=40, num_updates=820, lr=1.29911e-05, gnorm=2.271, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=932
2022-09-28 16:13:08 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 15783 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.2, ups=0.9, wpb=101.5, bsz=40, num_updates=830, lr=1.31496e-05, gnorm=2.155, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=943
2022-09-28 16:13:19 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 15783 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=840, lr=1.3308e-05, gnorm=2.228, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=954
2022-09-28 16:13:30 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.2, ups=0.9, wpb=101.2, bsz=40, num_updates=850, lr=1.34664e-05, gnorm=1.961, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=966
2022-09-28 16:13:42 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 15783 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.9, ups=0.9, wpb=102, bsz=40, num_updates=860, lr=1.36248e-05, gnorm=2.196, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=977
2022-09-28 16:13:53 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 15783 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.2, ups=0.88, wpb=101, bsz=40, num_updates=870, lr=1.37833e-05, gnorm=2.26, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=988
2022-09-28 16:14:04 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 15783 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.6, ups=0.91, wpb=101.6, bsz=40, num_updates=880, lr=1.39417e-05, gnorm=2.289, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=999
2022-09-28 16:14:15 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.6, ups=0.91, wpb=101.8, bsz=40, num_updates=890, lr=1.41001e-05, gnorm=1.961, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1010
2022-09-28 16:14:26 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 15783 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=93, ups=0.9, wpb=103.1, bsz=40, num_updates=900, lr=1.42586e-05, gnorm=2.105, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1021
2022-09-28 16:14:37 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.6, ups=0.93, wpb=102.3, bsz=40, num_updates=910, lr=1.4417e-05, gnorm=2.163, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1032
2022-09-28 16:14:48 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.7, ups=0.91, wpb=101, bsz=40, num_updates=920, lr=1.45754e-05, gnorm=2.056, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1043
2022-09-28 16:14:59 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 15783 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=86.6, ups=0.86, wpb=100.4, bsz=40, num_updates=930, lr=1.47338e-05, gnorm=1.968, clip=100, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1054
2022-09-28 16:15:11 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 15783 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.2, ups=0.87, wpb=100.6, bsz=40, num_updates=940, lr=1.48923e-05, gnorm=2.219, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1066
2022-09-28 16:15:22 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 15783 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=87, ups=0.88, wpb=99.3, bsz=40, num_updates=950, lr=1.50507e-05, gnorm=2.055, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1077
2022-09-28 16:15:34 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 15783 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=87.7, ups=0.87, wpb=100.3, bsz=40, num_updates=960, lr=1.52091e-05, gnorm=2.296, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1089
2022-09-28 16:15:45 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 15783 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.9, ups=0.91, wpb=99.7, bsz=40, num_updates=970, lr=1.53676e-05, gnorm=2.112, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1100
2022-09-28 16:15:56 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.2, ups=0.87, wpb=103.3, bsz=40, num_updates=980, lr=1.5526e-05, gnorm=1.997, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1111
2022-09-28 16:16:07 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.3, ups=0.91, wpb=99.8, bsz=40, num_updates=990, lr=1.56844e-05, gnorm=2.223, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1122
2022-09-28 16:16:18 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.4, ups=0.9, wpb=103.7, bsz=40, num_updates=1000, lr=1.58428e-05, gnorm=1.966, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1133
2022-09-28 16:16:30 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.9, ups=0.88, wpb=102.5, bsz=40, num_updates=1010, lr=1.60013e-05, gnorm=2.31, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1145
2022-09-28 16:16:41 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.5, ups=0.88, wpb=103.2, bsz=40, num_updates=1020, lr=1.61597e-05, gnorm=2.228, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1156
2022-09-28 16:16:53 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=1030, lr=1.63181e-05, gnorm=1.913, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1168
2022-09-28 16:17:04 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.8, ups=0.87, wpb=101.2, bsz=40, num_updates=1040, lr=1.64766e-05, gnorm=1.972, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1179
2022-09-28 16:17:15 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.9, ups=0.89, wpb=103.4, bsz=40, num_updates=1050, lr=1.6635e-05, gnorm=1.933, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1190
2022-09-28 16:17:26 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 15783 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.7, ups=0.92, wpb=100.2, bsz=40, num_updates=1060, lr=1.67934e-05, gnorm=2.098, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1201
2022-09-28 16:17:38 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 15783 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.8, ups=0.89, wpb=98.9, bsz=40, num_updates=1070, lr=1.69518e-05, gnorm=2.092, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1213
2022-09-28 16:17:49 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.89, wpb=102.7, bsz=40, num_updates=1080, lr=1.71103e-05, gnorm=2.435, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1224
2022-09-28 16:18:00 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 15783 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=1090, lr=1.72687e-05, gnorm=1.906, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1235
2022-09-28 16:18:11 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.89, wpb=102.2, bsz=40, num_updates=1100, lr=1.74271e-05, gnorm=1.968, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1246
2022-09-28 16:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.1, ups=0.89, wpb=101, bsz=40, num_updates=1110, lr=1.75856e-05, gnorm=2.03, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1257
2022-09-28 16:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.2, ups=0.88, wpb=100.6, bsz=40, num_updates=1120, lr=1.7744e-05, gnorm=2.104, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1269
2022-09-28 16:18:45 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 15783 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.1, ups=0.89, wpb=99.3, bsz=40, num_updates=1130, lr=1.79024e-05, gnorm=2.206, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1280
2022-09-28 16:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.1, ups=0.89, wpb=101.8, bsz=40, num_updates=1140, lr=1.80608e-05, gnorm=2.019, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1291
2022-09-28 16:19:08 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89, ups=0.87, wpb=102.3, bsz=40, num_updates=1150, lr=1.82193e-05, gnorm=1.873, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1303
2022-09-28 16:19:19 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.7, ups=0.9, wpb=100.8, bsz=40, num_updates=1160, lr=1.83777e-05, gnorm=2.229, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1314
2022-09-28 16:19:30 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.1, ups=0.88, wpb=101.9, bsz=40, num_updates=1170, lr=1.85361e-05, gnorm=2.259, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1325
2022-09-28 16:19:42 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.8, ups=0.88, wpb=102, bsz=40, num_updates=1180, lr=1.86946e-05, gnorm=2.129, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1337
2022-09-28 16:19:53 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.7, ups=0.86, wpb=101.5, bsz=40, num_updates=1190, lr=1.8853e-05, gnorm=1.991, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1348
2022-09-28 16:20:05 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.5, ups=0.87, wpb=101, bsz=40, num_updates=1200, lr=1.90114e-05, gnorm=1.977, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1360
2022-09-28 16:20:16 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.8, ups=0.9, wpb=99.6, bsz=40, num_updates=1210, lr=1.91698e-05, gnorm=2.124, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1371
2022-09-28 16:20:27 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.8, ups=0.89, wpb=102, bsz=40, num_updates=1220, lr=1.93283e-05, gnorm=2.094, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1382
2022-09-28 16:20:38 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89, ups=0.88, wpb=101.2, bsz=40, num_updates=1230, lr=1.94867e-05, gnorm=2.137, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1393
2022-09-28 16:20:50 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88, ups=0.88, wpb=100, bsz=40, num_updates=1240, lr=1.96451e-05, gnorm=1.941, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1405
2022-09-28 16:21:01 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.4, ups=0.87, wpb=102.3, bsz=40, num_updates=1250, lr=1.98035e-05, gnorm=2.038, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1416
2022-09-28 16:21:13 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.87, wpb=102.1, bsz=40, num_updates=1260, lr=1.9962e-05, gnorm=1.795, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1428
2022-09-28 16:21:24 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.1, ups=0.92, wpb=102, bsz=40, num_updates=1270, lr=2.01204e-05, gnorm=1.97, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1439
2022-09-28 16:21:35 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.87, wpb=102.1, bsz=40, num_updates=1280, lr=2.02788e-05, gnorm=1.91, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1450
2022-09-28 16:21:46 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.9, wpb=100.7, bsz=40, num_updates=1290, lr=2.04373e-05, gnorm=1.758, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1461
2022-09-28 16:21:57 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.7, ups=0.89, wpb=101.4, bsz=40, num_updates=1300, lr=2.05957e-05, gnorm=1.788, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1472
2022-09-28 16:22:08 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.9, ups=0.92, wpb=101.2, bsz=40, num_updates=1310, lr=2.07541e-05, gnorm=1.782, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1483
2022-09-28 16:22:19 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.9, ups=0.92, wpb=101.3, bsz=40, num_updates=1320, lr=2.09125e-05, gnorm=1.812, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1494
2022-09-28 16:22:30 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.2, ups=0.93, wpb=100.2, bsz=40, num_updates=1330, lr=2.1071e-05, gnorm=1.969, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1505
2022-09-28 16:22:41 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.5, ups=0.9, wpb=101.3, bsz=40, num_updates=1340, lr=2.12294e-05, gnorm=1.894, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1516
2022-09-28 16:22:52 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.88, wpb=101.2, bsz=40, num_updates=1350, lr=2.13878e-05, gnorm=1.813, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1527
2022-09-28 16:23:03 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91, ups=0.9, wpb=101, bsz=40, num_updates=1360, lr=2.15463e-05, gnorm=1.927, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1538
2022-09-28 16:23:14 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.8, ups=0.93, wpb=100.5, bsz=40, num_updates=1370, lr=2.17047e-05, gnorm=1.926, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1549
2022-09-28 16:23:25 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=1380, lr=2.18631e-05, gnorm=1.841, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1560
2022-09-28 16:23:36 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 15783 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=1390, lr=2.20215e-05, gnorm=1.948, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1571
2022-09-28 16:23:48 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.2, ups=0.87, wpb=102.6, bsz=40, num_updates=1400, lr=2.218e-05, gnorm=1.809, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1583
2022-09-28 16:23:59 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.8, ups=0.91, wpb=103.5, bsz=40, num_updates=1410, lr=2.23384e-05, gnorm=1.773, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1594
2022-09-28 16:24:10 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.3, ups=0.87, wpb=100.8, bsz=40, num_updates=1420, lr=2.24968e-05, gnorm=1.647, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1605
2022-09-28 16:24:22 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92, ups=0.89, wpb=103.7, bsz=40, num_updates=1430, lr=2.26553e-05, gnorm=1.885, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1617
2022-09-28 16:24:33 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=1440, lr=2.28137e-05, gnorm=2.04, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1628
2022-09-28 16:24:44 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89, ups=0.88, wpb=100.9, bsz=40, num_updates=1450, lr=2.29721e-05, gnorm=1.924, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1639
2022-09-28 16:24:55 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.4, ups=0.9, wpb=101, bsz=40, num_updates=1460, lr=2.31305e-05, gnorm=2.123, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1650
2022-09-28 16:25:06 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94, ups=0.92, wpb=102.2, bsz=40, num_updates=1470, lr=2.3289e-05, gnorm=1.996, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1661
2022-09-28 16:25:17 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93, ups=0.92, wpb=101.6, bsz=40, num_updates=1480, lr=2.34474e-05, gnorm=1.981, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1672
2022-09-28 16:25:28 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.2, ups=0.92, wpb=101.8, bsz=40, num_updates=1490, lr=2.36058e-05, gnorm=1.796, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1683
2022-09-28 16:25:39 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.88, wpb=102.5, bsz=40, num_updates=1500, lr=2.37643e-05, gnorm=1.635, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1695
2022-09-28 16:25:50 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.9, ups=0.91, wpb=100.5, bsz=40, num_updates=1510, lr=2.39227e-05, gnorm=1.954, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1705
2022-09-28 16:26:02 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.88, wpb=101.5, bsz=40, num_updates=1520, lr=2.40811e-05, gnorm=1.853, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1717
2022-09-28 16:26:13 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.8, ups=0.88, wpb=100, bsz=40, num_updates=1530, lr=2.42395e-05, gnorm=1.711, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1728
2022-09-28 16:26:22 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 16:26:25 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=84.7, ups=0.84, wpb=101.3, bsz=40, num_updates=1540, lr=2.4398e-05, gnorm=1.826, clip=100, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=1740
2022-09-28 16:26:36 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.3, ups=0.93, wpb=99.5, bsz=40, num_updates=1550, lr=2.45564e-05, gnorm=1.851, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1751
2022-09-28 16:26:47 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.1, ups=0.87, wpb=102.6, bsz=40, num_updates=1560, lr=2.47148e-05, gnorm=1.47, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1763
2022-09-28 16:26:59 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.9, ups=0.88, wpb=101.2, bsz=40, num_updates=1570, lr=2.48733e-05, gnorm=1.597, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1774
2022-09-28 16:27:10 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90, ups=0.9, wpb=99.7, bsz=40, num_updates=1580, lr=2.50317e-05, gnorm=1.74, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1785
2022-09-28 16:27:21 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.7, ups=0.9, wpb=102.3, bsz=40, num_updates=1590, lr=2.51901e-05, gnorm=1.936, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1796
2022-09-28 16:27:32 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=1600, lr=2.53485e-05, gnorm=1.747, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1807
2022-09-28 16:27:44 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=101.3, bsz=40, num_updates=1610, lr=2.5507e-05, gnorm=1.668, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1819
2022-09-28 16:27:55 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=1620, lr=2.56654e-05, gnorm=1.816, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1830
2022-09-28 16:28:06 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.87, wpb=102.6, bsz=40, num_updates=1630, lr=2.58238e-05, gnorm=1.858, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1841
2022-09-28 16:28:18 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.88, wpb=104.7, bsz=40, num_updates=1640, lr=2.59823e-05, gnorm=1.61, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1853
2022-09-28 16:28:29 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.5, ups=0.88, wpb=100.6, bsz=40, num_updates=1650, lr=2.61407e-05, gnorm=1.706, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1864
2022-09-28 16:28:40 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.3, ups=0.88, wpb=101.1, bsz=40, num_updates=1660, lr=2.62991e-05, gnorm=1.781, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1875
2022-09-28 16:28:52 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.9, wpb=101.5, bsz=40, num_updates=1670, lr=2.64575e-05, gnorm=1.622, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1887
2022-09-28 16:29:03 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.8, ups=0.9, wpb=100.5, bsz=40, num_updates=1680, lr=2.6616e-05, gnorm=1.874, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1898
2022-09-28 16:29:11 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-28 16:29:15 - progress_bar.py[line:274] - INFO: epoch 001:   1692 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=81.9, ups=0.81, wpb=101.6, bsz=40, num_updates=1690, lr=2.67744e-05, gnorm=1.771, clip=100, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1910
2022-09-28 16:29:26 - progress_bar.py[line:274] - INFO: epoch 001:   1702 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.1, ups=0.9, wpb=100.4, bsz=40, num_updates=1700, lr=2.69328e-05, gnorm=1.638, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=1921
2022-09-28 16:29:37 - progress_bar.py[line:274] - INFO: epoch 001:   1712 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.3, ups=0.92, wpb=101.7, bsz=40, num_updates=1710, lr=2.70913e-05, gnorm=1.746, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1932
2022-09-28 16:29:48 - progress_bar.py[line:274] - INFO: epoch 001:   1722 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.3, ups=0.9, wpb=101.4, bsz=40, num_updates=1720, lr=2.72497e-05, gnorm=1.816, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1943
2022-09-28 16:29:59 - progress_bar.py[line:274] - INFO: epoch 001:   1732 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89, ups=0.88, wpb=100.8, bsz=40, num_updates=1730, lr=2.74081e-05, gnorm=1.782, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1955
2022-09-28 16:30:11 - progress_bar.py[line:274] - INFO: epoch 001:   1742 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=1740, lr=2.75665e-05, gnorm=1.536, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1966
2022-09-28 16:30:22 - progress_bar.py[line:274] - INFO: epoch 001:   1752 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.4, ups=0.89, wpb=100.5, bsz=40, num_updates=1750, lr=2.7725e-05, gnorm=1.503, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1977
2022-09-28 16:30:33 - progress_bar.py[line:274] - INFO: epoch 001:   1762 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.4, ups=0.87, wpb=100.5, bsz=40, num_updates=1760, lr=2.78834e-05, gnorm=1.586, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1989
2022-09-28 16:30:45 - progress_bar.py[line:274] - INFO: epoch 001:   1772 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.88, wpb=102.3, bsz=40, num_updates=1770, lr=2.80418e-05, gnorm=1.429, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2000
2022-09-28 16:30:56 - progress_bar.py[line:274] - INFO: epoch 001:   1782 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=1780, lr=2.82003e-05, gnorm=1.541, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2011
2022-09-28 16:31:07 - progress_bar.py[line:274] - INFO: epoch 001:   1792 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.8, ups=0.89, wpb=104.4, bsz=40, num_updates=1790, lr=2.83587e-05, gnorm=1.464, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2022
2022-09-28 16:31:18 - progress_bar.py[line:274] - INFO: epoch 001:   1802 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.7, ups=0.91, wpb=102.8, bsz=40, num_updates=1800, lr=2.85171e-05, gnorm=1.775, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2033
2022-09-28 16:31:30 - progress_bar.py[line:274] - INFO: epoch 001:   1812 / 15783 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.1, ups=0.89, wpb=101.4, bsz=40, num_updates=1810, lr=2.86755e-05, gnorm=1.616, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2045
2022-09-28 16:31:41 - progress_bar.py[line:274] - INFO: epoch 001:   1822 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.4, ups=0.89, wpb=99.2, bsz=40, num_updates=1820, lr=2.8834e-05, gnorm=1.806, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2056
2022-09-28 16:31:52 - progress_bar.py[line:274] - INFO: epoch 001:   1832 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=1830, lr=2.89924e-05, gnorm=1.454, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2067
2022-09-28 16:32:03 - progress_bar.py[line:274] - INFO: epoch 001:   1842 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.89, wpb=101.5, bsz=40, num_updates=1840, lr=2.91508e-05, gnorm=1.317, clip=90, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2078
2022-09-28 16:32:15 - progress_bar.py[line:274] - INFO: epoch 001:   1852 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.89, wpb=102.8, bsz=40, num_updates=1850, lr=2.93093e-05, gnorm=1.749, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2090
2022-09-28 16:32:26 - progress_bar.py[line:274] - INFO: epoch 001:   1862 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.3, ups=0.89, wpb=101.9, bsz=40, num_updates=1860, lr=2.94677e-05, gnorm=1.749, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=2101
2022-09-28 16:32:37 - progress_bar.py[line:274] - INFO: epoch 001:   1872 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=1870, lr=2.96261e-05, gnorm=1.495, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2112
2022-09-28 16:32:49 - progress_bar.py[line:274] - INFO: epoch 001:   1882 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.88, wpb=102.6, bsz=40, num_updates=1880, lr=2.97845e-05, gnorm=1.483, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2124
2022-09-28 16:33:00 - progress_bar.py[line:274] - INFO: epoch 001:   1892 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.3, ups=0.9, wpb=100.2, bsz=40, num_updates=1890, lr=2.9943e-05, gnorm=1.726, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2135
2022-09-28 16:33:11 - progress_bar.py[line:274] - INFO: epoch 001:   1902 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.89, wpb=101.8, bsz=40, num_updates=1900, lr=3.01014e-05, gnorm=1.498, clip=90, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=2146
2022-09-28 16:33:22 - progress_bar.py[line:274] - INFO: epoch 001:   1912 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.1, ups=0.92, wpb=101, bsz=40, num_updates=1910, lr=3.02598e-05, gnorm=1.543, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2157
2022-09-28 16:33:33 - progress_bar.py[line:274] - INFO: epoch 001:   1922 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.7, ups=0.89, wpb=101.7, bsz=40, num_updates=1920, lr=3.04183e-05, gnorm=1.487, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2168
2022-09-28 16:33:44 - progress_bar.py[line:274] - INFO: epoch 001:   1932 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92, ups=0.89, wpb=103.5, bsz=40, num_updates=1930, lr=3.05767e-05, gnorm=1.581, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2179
2022-09-28 16:33:55 - progress_bar.py[line:274] - INFO: epoch 001:   1942 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.3, ups=0.9, wpb=101.1, bsz=40, num_updates=1940, lr=3.07351e-05, gnorm=1.677, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2190
2022-09-28 16:34:06 - progress_bar.py[line:274] - INFO: epoch 001:   1952 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.1, ups=0.91, wpb=101.7, bsz=40, num_updates=1950, lr=3.08935e-05, gnorm=1.464, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2201
2022-09-28 16:34:18 - progress_bar.py[line:274] - INFO: epoch 001:   1962 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.3, ups=0.88, wpb=100.3, bsz=40, num_updates=1960, lr=3.1052e-05, gnorm=1.544, clip=90, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2213
2022-09-28 16:34:29 - progress_bar.py[line:274] - INFO: epoch 001:   1972 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.6, ups=0.92, wpb=103, bsz=40, num_updates=1970, lr=3.12104e-05, gnorm=1.504, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2224
2022-09-28 16:34:40 - progress_bar.py[line:274] - INFO: epoch 001:   1982 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.5, ups=0.91, wpb=100.4, bsz=40, num_updates=1980, lr=3.13688e-05, gnorm=1.552, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2235
2022-09-28 16:34:51 - progress_bar.py[line:274] - INFO: epoch 001:   1992 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88, ups=0.88, wpb=100.3, bsz=40, num_updates=1990, lr=3.15272e-05, gnorm=1.409, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2246
2022-09-28 16:35:02 - progress_bar.py[line:274] - INFO: epoch 001:   2002 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.5, ups=0.92, wpb=100.5, bsz=40, num_updates=2000, lr=3.16857e-05, gnorm=1.446, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2257
2022-09-28 16:35:13 - progress_bar.py[line:274] - INFO: epoch 001:   2012 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.3, ups=0.88, wpb=102.6, bsz=40, num_updates=2010, lr=3.18441e-05, gnorm=1.388, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2268
2022-09-28 16:35:24 - progress_bar.py[line:274] - INFO: epoch 001:   2022 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.5, ups=0.91, wpb=102.3, bsz=40, num_updates=2020, lr=3.20025e-05, gnorm=1.537, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2279
2022-09-28 16:35:35 - progress_bar.py[line:274] - INFO: epoch 001:   2032 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.6, ups=0.91, wpb=103.8, bsz=40, num_updates=2030, lr=3.2161e-05, gnorm=1.573, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2290
2022-09-28 16:35:47 - progress_bar.py[line:274] - INFO: epoch 001:   2042 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.6, ups=0.87, wpb=101, bsz=40, num_updates=2040, lr=3.23194e-05, gnorm=1.588, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2302
2022-09-28 16:35:58 - progress_bar.py[line:274] - INFO: epoch 001:   2052 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.4, ups=0.9, wpb=102.5, bsz=40, num_updates=2050, lr=3.24778e-05, gnorm=1.331, clip=90, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2313
2022-09-28 16:36:09 - progress_bar.py[line:274] - INFO: epoch 001:   2062 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.4, ups=0.92, wpb=99.8, bsz=40, num_updates=2060, lr=3.26362e-05, gnorm=1.631, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2324
2022-09-28 16:36:20 - progress_bar.py[line:274] - INFO: epoch 001:   2072 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=2070, lr=3.27947e-05, gnorm=1.538, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2335
2022-09-28 16:36:31 - progress_bar.py[line:274] - INFO: epoch 001:   2082 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.8, ups=0.92, wpb=101.9, bsz=40, num_updates=2080, lr=3.29531e-05, gnorm=1.485, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2346
2022-09-28 16:36:42 - progress_bar.py[line:274] - INFO: epoch 001:   2092 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=2090, lr=3.31115e-05, gnorm=1.444, clip=90, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2357
2022-09-28 16:36:53 - progress_bar.py[line:274] - INFO: epoch 001:   2102 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94, ups=0.92, wpb=101.7, bsz=40, num_updates=2100, lr=3.327e-05, gnorm=1.514, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2368
2022-09-28 16:37:04 - progress_bar.py[line:274] - INFO: epoch 001:   2112 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.9, wpb=101.1, bsz=40, num_updates=2110, lr=3.34284e-05, gnorm=1.737, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2379
2022-09-28 16:37:15 - progress_bar.py[line:274] - INFO: epoch 001:   2122 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.1, ups=0.93, wpb=101.6, bsz=40, num_updates=2120, lr=3.35868e-05, gnorm=1.496, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2390
2022-09-28 16:37:26 - progress_bar.py[line:274] - INFO: epoch 001:   2132 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.5, ups=0.89, wpb=102.3, bsz=40, num_updates=2130, lr=3.37452e-05, gnorm=1.418, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2401
2022-09-28 16:37:38 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.6, ups=0.86, wpb=101.3, bsz=40, num_updates=2140, lr=3.39037e-05, gnorm=1.464, clip=80, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=2413
2022-09-28 16:37:49 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.8, ups=0.86, wpb=101.7, bsz=40, num_updates=2150, lr=3.40621e-05, gnorm=1.362, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=2424
2022-09-28 16:38:00 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=2160, lr=3.42205e-05, gnorm=1.778, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2436
2022-09-28 16:38:12 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.6, ups=0.89, wpb=103.3, bsz=40, num_updates=2170, lr=3.4379e-05, gnorm=1.587, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2447
2022-09-28 16:38:23 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.89, wpb=102.8, bsz=40, num_updates=2180, lr=3.45374e-05, gnorm=1.347, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2458
2022-09-28 16:38:34 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.2, ups=0.93, wpb=101.7, bsz=40, num_updates=2190, lr=3.46958e-05, gnorm=1.718, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2469
2022-09-28 16:38:45 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.1, ups=0.92, wpb=101.5, bsz=40, num_updates=2200, lr=3.48542e-05, gnorm=1.438, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2480
2022-09-28 16:38:56 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.2, ups=0.88, wpb=100.5, bsz=40, num_updates=2210, lr=3.50127e-05, gnorm=1.655, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2491
2022-09-28 16:39:07 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.5, ups=0.88, wpb=100.8, bsz=40, num_updates=2220, lr=3.51711e-05, gnorm=1.683, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2503
2022-09-28 16:39:18 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.2, ups=0.91, wpb=101.2, bsz=40, num_updates=2230, lr=3.53295e-05, gnorm=1.619, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2514
2022-09-28 16:39:30 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.2, ups=0.89, wpb=102.7, bsz=40, num_updates=2240, lr=3.5488e-05, gnorm=1.566, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2525
2022-09-28 16:39:41 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.9, ups=0.89, wpb=100.1, bsz=40, num_updates=2250, lr=3.56464e-05, gnorm=1.534, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2536
2022-09-28 16:39:52 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.9, ups=0.91, wpb=102.6, bsz=40, num_updates=2260, lr=3.58048e-05, gnorm=1.458, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2547
2022-09-28 16:40:03 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.7, ups=0.91, wpb=100.5, bsz=40, num_updates=2270, lr=3.59632e-05, gnorm=1.508, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2559
2022-09-28 16:40:15 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=2280, lr=3.61217e-05, gnorm=1.329, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2570
2022-09-28 16:40:26 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.7, ups=0.89, wpb=99.8, bsz=40, num_updates=2290, lr=3.62801e-05, gnorm=1.649, clip=100, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=2581
2022-09-28 16:40:37 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 15783 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.5, ups=0.89, wpb=99.6, bsz=40, num_updates=2300, lr=3.64385e-05, gnorm=1.51, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2592
2022-09-28 16:40:49 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.6, ups=0.88, wpb=102.5, bsz=40, num_updates=2310, lr=3.6597e-05, gnorm=1.346, clip=80, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2604
2022-09-28 16:41:00 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.88, wpb=102.8, bsz=40, num_updates=2320, lr=3.67554e-05, gnorm=1.321, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2615
2022-09-28 16:41:11 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.4, ups=0.9, wpb=100.1, bsz=40, num_updates=2330, lr=3.69138e-05, gnorm=1.56, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2626
2022-09-28 16:41:22 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.9, wpb=102, bsz=40, num_updates=2340, lr=3.70722e-05, gnorm=1.504, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2637
2022-09-28 16:41:33 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.3, ups=0.88, wpb=100.5, bsz=40, num_updates=2350, lr=3.72307e-05, gnorm=1.393, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2649
2022-09-28 16:41:45 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.88, wpb=102.1, bsz=40, num_updates=2360, lr=3.73891e-05, gnorm=1.235, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2660
2022-09-28 16:41:56 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.3, ups=0.88, wpb=99.3, bsz=40, num_updates=2370, lr=3.75475e-05, gnorm=1.417, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2671
2022-09-28 16:42:08 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.89, wpb=102.7, bsz=40, num_updates=2380, lr=3.7706e-05, gnorm=1.395, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2683
2022-09-28 16:42:19 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89, ups=0.88, wpb=100.8, bsz=40, num_updates=2390, lr=3.78644e-05, gnorm=1.284, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2694
2022-09-28 16:42:30 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.87, wpb=102.4, bsz=40, num_updates=2400, lr=3.80228e-05, gnorm=1.31, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2705
2022-09-28 16:42:41 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.9, wpb=100.5, bsz=40, num_updates=2410, lr=3.81812e-05, gnorm=1.398, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2717
2022-09-28 16:42:52 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.8, ups=0.91, wpb=101.7, bsz=40, num_updates=2420, lr=3.83397e-05, gnorm=1.482, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2727
2022-09-28 16:43:03 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.9, ups=0.93, wpb=100.5, bsz=40, num_updates=2430, lr=3.84981e-05, gnorm=1.462, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2738
2022-09-28 16:43:15 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87, ups=0.87, wpb=100.3, bsz=40, num_updates=2440, lr=3.86565e-05, gnorm=1.311, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2750
2022-09-28 16:43:26 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=2450, lr=3.8815e-05, gnorm=1.327, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2761
2022-09-28 16:43:37 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.89, wpb=101.5, bsz=40, num_updates=2460, lr=3.89734e-05, gnorm=1.237, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2772
2022-09-28 16:43:49 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.87, wpb=102.3, bsz=40, num_updates=2470, lr=3.91318e-05, gnorm=1.406, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2784
2022-09-28 16:44:00 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=2480, lr=3.92902e-05, gnorm=1.477, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2795
2022-09-28 16:44:11 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=2490, lr=3.94487e-05, gnorm=1.341, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2806
2022-09-28 16:44:23 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=2500, lr=3.96071e-05, gnorm=1.343, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2818
2022-09-28 16:44:34 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.3, ups=0.9, wpb=103.1, bsz=40, num_updates=2510, lr=3.97655e-05, gnorm=1.316, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2829
2022-09-28 16:44:45 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90, ups=0.9, wpb=100.1, bsz=40, num_updates=2520, lr=3.9924e-05, gnorm=1.427, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2840
2022-09-28 16:44:56 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 15783 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.8, ups=0.89, wpb=98.8, bsz=40, num_updates=2530, lr=4.00824e-05, gnorm=1.443, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2851
2022-09-28 16:45:07 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.6, ups=0.9, wpb=100.8, bsz=40, num_updates=2540, lr=4.02408e-05, gnorm=1.474, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2862
2022-09-28 16:45:18 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=2550, lr=4.03992e-05, gnorm=1.411, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2873
2022-09-28 16:45:29 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.9, wpb=99.3, bsz=40, num_updates=2560, lr=4.05577e-05, gnorm=1.277, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2885
2022-09-28 16:45:41 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=86.2, ups=0.87, wpb=99.4, bsz=40, num_updates=2570, lr=4.07161e-05, gnorm=1.539, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2896
2022-09-28 16:45:52 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.9, ups=0.9, wpb=102.1, bsz=40, num_updates=2580, lr=4.08745e-05, gnorm=1.111, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2907
2022-09-28 16:46:04 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.8, ups=0.88, wpb=99.9, bsz=40, num_updates=2590, lr=4.1033e-05, gnorm=1.321, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2919
2022-09-28 16:46:15 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.2, ups=0.88, wpb=99.6, bsz=40, num_updates=2600, lr=4.11914e-05, gnorm=1.423, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2930
2022-09-28 16:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.7, ups=0.88, wpb=101.4, bsz=40, num_updates=2610, lr=4.13498e-05, gnorm=1.282, clip=90, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2941
2022-09-28 16:46:37 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.91, wpb=101.7, bsz=40, num_updates=2620, lr=4.15082e-05, gnorm=1.272, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2953
2022-09-28 16:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.5, ups=0.91, wpb=102.4, bsz=40, num_updates=2630, lr=4.16667e-05, gnorm=1.361, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2963
2022-09-28 16:46:59 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.9, ups=0.91, wpb=102.7, bsz=40, num_updates=2640, lr=4.18251e-05, gnorm=1.151, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2974
2022-09-28 16:47:10 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.9, ups=0.9, wpb=102.4, bsz=40, num_updates=2650, lr=4.19835e-05, gnorm=1.324, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2986
2022-09-28 16:47:22 - progress_bar.py[line:274] - INFO: epoch 001:   2662 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.6, ups=0.88, wpb=101.8, bsz=40, num_updates=2660, lr=4.2142e-05, gnorm=1.257, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2997
2022-09-28 16:47:33 - progress_bar.py[line:274] - INFO: epoch 001:   2672 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.5, ups=0.9, wpb=101.8, bsz=40, num_updates=2670, lr=4.23004e-05, gnorm=1.173, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3008
2022-09-28 16:47:44 - progress_bar.py[line:274] - INFO: epoch 001:   2682 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89, ups=0.87, wpb=102, bsz=40, num_updates=2680, lr=4.24588e-05, gnorm=1.237, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3020
2022-09-28 16:47:56 - progress_bar.py[line:274] - INFO: epoch 001:   2692 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.9, ups=0.89, wpb=100.7, bsz=40, num_updates=2690, lr=4.26172e-05, gnorm=1.414, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3031
2022-09-28 16:48:07 - progress_bar.py[line:274] - INFO: epoch 001:   2702 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=2700, lr=4.27757e-05, gnorm=1.226, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3042
2022-09-28 16:48:18 - progress_bar.py[line:274] - INFO: epoch 001:   2712 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=2710, lr=4.29341e-05, gnorm=1.217, clip=90, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3053
2022-09-28 16:48:30 - progress_bar.py[line:274] - INFO: epoch 001:   2722 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.9, ups=0.89, wpb=100.1, bsz=40, num_updates=2720, lr=4.30925e-05, gnorm=1.357, clip=90, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=3065
2022-09-28 16:48:40 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 16:48:42 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=83.5, ups=0.82, wpb=102.2, bsz=40, num_updates=2730, lr=4.3251e-05, gnorm=1.344, clip=90, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=3077
2022-09-28 16:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.5, ups=0.89, wpb=103.1, bsz=40, num_updates=2740, lr=4.34094e-05, gnorm=1.165, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3088
2022-09-28 16:49:04 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.3, ups=0.93, wpb=99.9, bsz=40, num_updates=2750, lr=4.35678e-05, gnorm=1.407, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3099
2022-09-28 16:49:15 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.6, ups=0.9, wpb=102.3, bsz=40, num_updates=2760, lr=4.37262e-05, gnorm=1.287, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3110
2022-09-28 16:49:26 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.9, ups=0.92, wpb=100.4, bsz=40, num_updates=2770, lr=4.38847e-05, gnorm=1.209, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3121
2022-09-28 16:49:37 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=2780, lr=4.40431e-05, gnorm=1.031, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3132
2022-09-28 16:49:48 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=101.6, bsz=40, num_updates=2790, lr=4.42015e-05, gnorm=1.288, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3143
2022-09-28 16:50:00 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 15783 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.7, ups=0.89, wpb=101.6, bsz=40, num_updates=2800, lr=4.43599e-05, gnorm=1.723, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3155
2022-09-28 16:50:11 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=2810, lr=4.45184e-05, gnorm=1.345, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3166
2022-09-28 16:50:22 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.8, ups=0.9, wpb=100.5, bsz=40, num_updates=2820, lr=4.46768e-05, gnorm=1.163, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3177
2022-09-28 16:50:32 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.9, ups=0.93, wpb=102.3, bsz=40, num_updates=2830, lr=4.48352e-05, gnorm=1.216, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=3188
2022-09-28 16:50:44 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.2, ups=0.89, wpb=101.9, bsz=40, num_updates=2840, lr=4.49937e-05, gnorm=1.24, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3199
2022-09-28 16:50:55 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.88, wpb=102.7, bsz=40, num_updates=2850, lr=4.51521e-05, gnorm=1.276, clip=80, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=3210
2022-09-28 16:51:06 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=2860, lr=4.53105e-05, gnorm=1.472, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3221
2022-09-28 16:51:18 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.5, ups=0.88, wpb=100.8, bsz=40, num_updates=2870, lr=4.54689e-05, gnorm=1.343, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3233
2022-09-28 16:51:29 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.1, ups=0.88, wpb=101, bsz=40, num_updates=2880, lr=4.56274e-05, gnorm=1.468, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3244
2022-09-28 16:51:40 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=2890, lr=4.57858e-05, gnorm=1.181, clip=80, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3255
2022-09-28 16:51:51 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.9, ups=0.92, wpb=101.3, bsz=40, num_updates=2900, lr=4.59442e-05, gnorm=1.206, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3266
2022-09-28 16:52:02 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.9, wpb=100.2, bsz=40, num_updates=2910, lr=4.61027e-05, gnorm=1.358, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3277
2022-09-28 16:52:13 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.1, ups=0.92, wpb=101.3, bsz=40, num_updates=2920, lr=4.62611e-05, gnorm=1.154, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3288
2022-09-28 16:52:25 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88, ups=0.87, wpb=101.3, bsz=40, num_updates=2930, lr=4.64195e-05, gnorm=1.246, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3300
2022-09-28 16:52:36 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.3, ups=0.9, wpb=100.9, bsz=40, num_updates=2940, lr=4.65779e-05, gnorm=1.237, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3311
2022-09-28 16:52:47 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.5, ups=0.89, wpb=101.3, bsz=40, num_updates=2950, lr=4.67364e-05, gnorm=1.177, clip=90, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3322
2022-09-28 16:52:58 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.1, ups=0.89, wpb=102.3, bsz=40, num_updates=2960, lr=4.68948e-05, gnorm=1.125, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3333
2022-09-28 16:53:09 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.2, ups=0.9, wpb=100.2, bsz=40, num_updates=2970, lr=4.70532e-05, gnorm=1.466, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3344
2022-09-28 16:53:21 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=2980, lr=4.72117e-05, gnorm=1.234, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3356
2022-09-28 16:53:32 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=2990, lr=4.73701e-05, gnorm=1.502, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3367
2022-09-28 16:53:43 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.7, ups=0.89, wpb=100.6, bsz=40, num_updates=3000, lr=4.75285e-05, gnorm=1.188, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3378
2022-09-28 16:53:55 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.7, ups=0.88, wpb=100.7, bsz=40, num_updates=3010, lr=4.76869e-05, gnorm=1.193, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3390
2022-09-28 16:54:06 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.3, ups=0.91, wpb=99.6, bsz=40, num_updates=3020, lr=4.78454e-05, gnorm=1.393, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3401
2022-09-28 16:54:17 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.8, ups=0.9, wpb=102.6, bsz=40, num_updates=3030, lr=4.80038e-05, gnorm=1.11, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3412
2022-09-28 16:54:28 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.1, ups=0.91, wpb=101.4, bsz=40, num_updates=3040, lr=4.81622e-05, gnorm=1.286, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3423
2022-09-28 16:54:39 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.3, ups=0.89, wpb=102.3, bsz=40, num_updates=3050, lr=4.83207e-05, gnorm=1.129, clip=70, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3434
2022-09-28 16:54:50 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.8, ups=0.91, wpb=100.5, bsz=40, num_updates=3060, lr=4.84791e-05, gnorm=1.391, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3445
2022-09-28 16:55:01 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.6, ups=0.93, wpb=101, bsz=40, num_updates=3070, lr=4.86375e-05, gnorm=1.29, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3456
2022-09-28 16:55:12 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.2, ups=0.88, wpb=100, bsz=40, num_updates=3080, lr=4.87959e-05, gnorm=1.299, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3467
2022-09-28 16:55:24 - progress_bar.py[line:274] - INFO: epoch 001:   3093 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.7, ups=0.88, wpb=102.3, bsz=40, num_updates=3090, lr=4.89544e-05, gnorm=1.363, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3479
2022-09-28 16:55:35 - progress_bar.py[line:274] - INFO: epoch 001:   3103 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92, ups=0.91, wpb=101.2, bsz=40, num_updates=3100, lr=4.91128e-05, gnorm=1.188, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3490
2022-09-28 16:55:46 - progress_bar.py[line:274] - INFO: epoch 001:   3113 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92, ups=0.91, wpb=100.8, bsz=40, num_updates=3110, lr=4.92712e-05, gnorm=1.114, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3501
2022-09-28 16:55:57 - progress_bar.py[line:274] - INFO: epoch 001:   3123 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.7, ups=0.9, wpb=99.9, bsz=40, num_updates=3120, lr=4.94297e-05, gnorm=1.456, clip=70, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3512
2022-09-28 16:56:08 - progress_bar.py[line:274] - INFO: epoch 001:   3133 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.3, ups=0.9, wpb=101.6, bsz=40, num_updates=3130, lr=4.95881e-05, gnorm=1.137, clip=70, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=3523
2022-09-28 16:56:19 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91, ups=0.89, wpb=102, bsz=40, num_updates=3140, lr=4.97465e-05, gnorm=1.206, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3534
2022-09-28 16:56:30 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.89, wpb=102.7, bsz=40, num_updates=3150, lr=4.99049e-05, gnorm=1.257, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3545
2022-09-28 16:56:41 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.5, ups=0.89, wpb=100.4, bsz=40, num_updates=3160, lr=4.99974e-05, gnorm=1.116, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3557
2022-09-28 16:56:53 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.4, ups=0.87, wpb=102.6, bsz=40, num_updates=3170, lr=4.99908e-05, gnorm=1.123, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3568
2022-09-28 16:57:04 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.89, wpb=102, bsz=40, num_updates=3180, lr=4.99842e-05, gnorm=1.181, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3579
2022-09-28 16:57:15 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.6, ups=0.89, wpb=100.5, bsz=40, num_updates=3190, lr=4.99776e-05, gnorm=1.223, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3591
2022-09-28 16:57:27 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.89, wpb=101.8, bsz=40, num_updates=3200, lr=4.9971e-05, gnorm=1.133, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3602
2022-09-28 16:57:38 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.8, ups=0.88, wpb=100.1, bsz=40, num_updates=3210, lr=4.99644e-05, gnorm=1.223, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3613
2022-09-28 16:57:49 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.89, wpb=101.7, bsz=40, num_updates=3220, lr=4.99578e-05, gnorm=1.103, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3624
2022-09-28 16:58:01 - progress_bar.py[line:274] - INFO: epoch 001:   3233 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.9, ups=0.87, wpb=100, bsz=40, num_updates=3230, lr=4.99512e-05, gnorm=1.066, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3636
2022-09-28 16:58:12 - progress_bar.py[line:274] - INFO: epoch 001:   3243 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.8, ups=0.87, wpb=100.8, bsz=40, num_updates=3240, lr=4.99446e-05, gnorm=1.274, clip=70, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3647
2022-09-28 16:58:24 - progress_bar.py[line:274] - INFO: epoch 001:   3253 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.88, wpb=100.6, bsz=40, num_updates=3250, lr=4.9938e-05, gnorm=1.013, clip=60, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3659
2022-09-28 16:58:35 - progress_bar.py[line:274] - INFO: epoch 001:   3263 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=3260, lr=4.99314e-05, gnorm=1.05, clip=50, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3670
2022-09-28 16:58:46 - progress_bar.py[line:274] - INFO: epoch 001:   3273 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.6, ups=0.89, wpb=100.1, bsz=40, num_updates=3270, lr=4.99248e-05, gnorm=1.186, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3681
2022-09-28 16:58:57 - progress_bar.py[line:274] - INFO: epoch 001:   3283 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95, ups=0.94, wpb=101, bsz=40, num_updates=3280, lr=4.99182e-05, gnorm=1.273, clip=80, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3692
2022-09-28 16:59:08 - progress_bar.py[line:274] - INFO: epoch 001:   3293 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.4, ups=0.91, wpb=101.2, bsz=40, num_updates=3290, lr=4.99116e-05, gnorm=1.09, clip=70, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3703
2022-09-28 16:59:19 - progress_bar.py[line:274] - INFO: epoch 001:   3303 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.6, ups=0.9, wpb=100.5, bsz=40, num_updates=3300, lr=4.9905e-05, gnorm=1.191, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3714
2022-09-28 16:59:24 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 16:59:31 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=85.6, ups=0.84, wpb=101.5, bsz=40, num_updates=3310, lr=4.98984e-05, gnorm=1.309, clip=80, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=3726
2022-09-28 16:59:41 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.9, ups=0.93, wpb=101.4, bsz=40, num_updates=3320, lr=4.98918e-05, gnorm=1.102, clip=80, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3737
2022-09-28 16:59:53 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87, ups=0.88, wpb=99, bsz=40, num_updates=3330, lr=4.98852e-05, gnorm=1.249, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3748
2022-09-28 17:00:04 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.1, ups=0.89, wpb=103.6, bsz=40, num_updates=3340, lr=4.98786e-05, gnorm=1.257, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3759
2022-09-28 17:00:16 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.1, ups=0.87, wpb=101.8, bsz=40, num_updates=3350, lr=4.9872e-05, gnorm=1.158, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3771
2022-09-28 17:00:27 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87, ups=0.86, wpb=101.6, bsz=40, num_updates=3360, lr=4.98654e-05, gnorm=1.032, clip=60, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=3782
2022-09-28 17:00:39 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.4, ups=0.86, wpb=100.8, bsz=40, num_updates=3370, lr=4.98588e-05, gnorm=1.193, clip=70, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=3794
2022-09-28 17:00:51 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=84.1, ups=0.83, wpb=101.8, bsz=40, num_updates=3380, lr=4.98522e-05, gnorm=1.01, clip=40, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=3806
2022-09-28 17:01:03 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86, ups=0.86, wpb=99.7, bsz=40, num_updates=3390, lr=4.98456e-05, gnorm=1.23, clip=90, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=3818
2022-09-28 17:01:14 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.9, ups=0.91, wpb=100.8, bsz=40, num_updates=3400, lr=4.9839e-05, gnorm=1.104, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=3829
2022-09-28 17:01:25 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 15783 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=86.2, ups=0.86, wpb=100.3, bsz=40, num_updates=3410, lr=4.98324e-05, gnorm=1.314, clip=100, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=3840
2022-09-28 17:01:37 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=3420, lr=4.98258e-05, gnorm=1.161, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3852
2022-09-28 17:01:48 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.3, ups=0.85, wpb=101, bsz=40, num_updates=3430, lr=4.98192e-05, gnorm=1.011, clip=70, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=3863
2022-09-28 17:02:00 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.1, ups=0.83, wpb=102.5, bsz=40, num_updates=3440, lr=4.98126e-05, gnorm=0.999, clip=50, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=3876
2022-09-28 17:02:12 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.7, ups=0.86, wpb=101.7, bsz=40, num_updates=3450, lr=4.9806e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=3887
2022-09-28 17:02:24 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.9, ups=0.87, wpb=99.8, bsz=40, num_updates=3460, lr=4.97994e-05, gnorm=1.159, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3899
2022-09-28 17:02:35 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.6, ups=0.88, wpb=100.5, bsz=40, num_updates=3470, lr=4.97928e-05, gnorm=1.078, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3910
2022-09-28 17:02:46 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89, ups=0.87, wpb=102.8, bsz=40, num_updates=3480, lr=4.97862e-05, gnorm=1.03, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3922
2022-09-28 17:02:58 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=3490, lr=4.97796e-05, gnorm=0.983, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3933
2022-09-28 17:03:09 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.91, wpb=101.3, bsz=40, num_updates=3500, lr=4.9773e-05, gnorm=1.123, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3944
2022-09-28 17:03:20 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89, ups=0.9, wpb=98.6, bsz=40, num_updates=3510, lr=4.97664e-05, gnorm=1.105, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3955
2022-09-28 17:03:31 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=3520, lr=4.97598e-05, gnorm=1.142, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3966
2022-09-28 17:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 15783 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.3, ups=0.91, wpb=100.5, bsz=40, num_updates=3530, lr=4.97532e-05, gnorm=1.487, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3977
2022-09-28 17:03:53 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.91, wpb=100.9, bsz=40, num_updates=3540, lr=4.97466e-05, gnorm=1.055, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3988
2022-09-28 17:04:04 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 15783 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.9, ups=0.89, wpb=100.8, bsz=40, num_updates=3550, lr=4.974e-05, gnorm=1.158, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4000
2022-09-28 17:04:16 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.2, ups=0.89, wpb=101.5, bsz=40, num_updates=3560, lr=4.97334e-05, gnorm=1.028, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4011
2022-09-28 17:04:27 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.88, wpb=102, bsz=40, num_updates=3570, lr=4.97268e-05, gnorm=0.956, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4022
2022-09-28 17:04:38 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.8, ups=0.89, wpb=101.6, bsz=40, num_updates=3580, lr=4.97202e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4033
2022-09-28 17:04:49 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.1, ups=0.91, wpb=101.9, bsz=40, num_updates=3590, lr=4.97136e-05, gnorm=1.069, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4044
2022-09-28 17:05:00 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.6, ups=0.9, wpb=102.8, bsz=40, num_updates=3600, lr=4.9707e-05, gnorm=1.102, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4055
2022-09-28 17:05:12 - progress_bar.py[line:274] - INFO: epoch 001:   3614 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.87, wpb=102.7, bsz=40, num_updates=3610, lr=4.97004e-05, gnorm=1.143, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4067
2022-09-28 17:05:23 - progress_bar.py[line:274] - INFO: epoch 001:   3624 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.89, wpb=102, bsz=40, num_updates=3620, lr=4.96938e-05, gnorm=1.122, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4078
2022-09-28 17:05:34 - progress_bar.py[line:274] - INFO: epoch 001:   3634 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.8, ups=0.89, wpb=100.1, bsz=40, num_updates=3630, lr=4.96872e-05, gnorm=1.046, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4089
2022-09-28 17:05:46 - progress_bar.py[line:274] - INFO: epoch 001:   3644 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.88, wpb=102.7, bsz=40, num_updates=3640, lr=4.96806e-05, gnorm=1.13, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4101
2022-09-28 17:05:57 - progress_bar.py[line:274] - INFO: epoch 001:   3654 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.89, wpb=101.8, bsz=40, num_updates=3650, lr=4.9674e-05, gnorm=1.052, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4112
2022-09-28 17:06:08 - progress_bar.py[line:274] - INFO: epoch 001:   3664 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.1, ups=0.91, wpb=100.8, bsz=40, num_updates=3660, lr=4.96674e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4123
2022-09-28 17:06:19 - progress_bar.py[line:274] - INFO: epoch 001:   3674 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.4, ups=0.9, wpb=102.6, bsz=40, num_updates=3670, lr=4.96608e-05, gnorm=1.126, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4134
2022-09-28 17:06:30 - progress_bar.py[line:274] - INFO: epoch 001:   3684 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.9, ups=0.89, wpb=99.9, bsz=40, num_updates=3680, lr=4.96542e-05, gnorm=1.269, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4145
2022-09-28 17:06:41 - progress_bar.py[line:274] - INFO: epoch 001:   3694 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.8, ups=0.92, wpb=101.5, bsz=40, num_updates=3690, lr=4.96476e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4156
2022-09-28 17:06:52 - progress_bar.py[line:274] - INFO: epoch 001:   3704 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94, ups=0.91, wpb=102.8, bsz=40, num_updates=3700, lr=4.9641e-05, gnorm=1.021, clip=60, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4167
2022-09-28 17:07:03 - progress_bar.py[line:274] - INFO: epoch 001:   3714 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.89, wpb=103.8, bsz=40, num_updates=3710, lr=4.96344e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4178
2022-09-28 17:07:14 - progress_bar.py[line:274] - INFO: epoch 001:   3724 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.1, ups=0.89, wpb=101.8, bsz=40, num_updates=3720, lr=4.96278e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4190
2022-09-28 17:07:26 - progress_bar.py[line:274] - INFO: epoch 001:   3734 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.3, ups=0.87, wpb=100.3, bsz=40, num_updates=3730, lr=4.96212e-05, gnorm=1.077, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4201
2022-09-28 17:07:37 - progress_bar.py[line:274] - INFO: epoch 001:   3744 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.87, wpb=102.7, bsz=40, num_updates=3740, lr=4.96146e-05, gnorm=1.114, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4213
2022-09-28 17:07:49 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.88, wpb=100.9, bsz=40, num_updates=3750, lr=4.9608e-05, gnorm=0.964, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4224
2022-09-28 17:08:00 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.3, ups=0.9, wpb=103.3, bsz=40, num_updates=3760, lr=4.96014e-05, gnorm=1.075, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4235
2022-09-28 17:08:11 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.8, ups=0.89, wpb=100.4, bsz=40, num_updates=3770, lr=4.95948e-05, gnorm=1.095, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4246
2022-09-28 17:08:22 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=100.6, bsz=40, num_updates=3780, lr=4.95882e-05, gnorm=1.054, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4257
2022-09-28 17:08:34 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=102.4, bsz=40, num_updates=3790, lr=4.95816e-05, gnorm=1.038, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4269
2022-09-28 17:08:45 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.6, ups=0.88, wpb=102.3, bsz=40, num_updates=3800, lr=4.9575e-05, gnorm=1.112, clip=80, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=4280
2022-09-28 17:08:56 - progress_bar.py[line:274] - INFO: epoch 001:   3814 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.9, ups=0.88, wpb=100.2, bsz=40, num_updates=3810, lr=4.95684e-05, gnorm=1.107, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4291
2022-09-28 17:09:07 - progress_bar.py[line:274] - INFO: epoch 001:   3824 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.7, ups=0.92, wpb=100.5, bsz=40, num_updates=3820, lr=4.95618e-05, gnorm=0.926, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4302
2022-09-28 17:09:19 - progress_bar.py[line:274] - INFO: epoch 001:   3834 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88, ups=0.88, wpb=100.3, bsz=40, num_updates=3830, lr=4.95552e-05, gnorm=1.199, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4314
2022-09-28 17:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   3844 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.8, ups=0.91, wpb=103, bsz=40, num_updates=3840, lr=4.95486e-05, gnorm=0.935, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4325
2022-09-28 17:09:41 - progress_bar.py[line:274] - INFO: epoch 001:   3854 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.88, wpb=102.6, bsz=40, num_updates=3850, lr=4.9542e-05, gnorm=1.052, clip=60, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4336
2022-09-28 17:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   3864 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.88, wpb=102.8, bsz=40, num_updates=3860, lr=4.95354e-05, gnorm=1.157, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4347
2022-09-28 17:10:03 - progress_bar.py[line:274] - INFO: epoch 001:   3874 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.2, ups=0.93, wpb=100.9, bsz=40, num_updates=3870, lr=4.95288e-05, gnorm=1.046, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4358
2022-09-28 17:10:14 - progress_bar.py[line:274] - INFO: epoch 001:   3884 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.9, ups=0.9, wpb=101.9, bsz=40, num_updates=3880, lr=4.95222e-05, gnorm=0.992, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4369
2022-09-28 17:10:26 - progress_bar.py[line:274] - INFO: epoch 001:   3894 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88, ups=0.88, wpb=100.2, bsz=40, num_updates=3890, lr=4.95156e-05, gnorm=1.162, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4381
2022-09-28 17:10:37 - progress_bar.py[line:274] - INFO: epoch 001:   3904 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.9, wpb=101, bsz=40, num_updates=3900, lr=4.9509e-05, gnorm=1.115, clip=60, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4392
2022-09-28 17:10:48 - progress_bar.py[line:274] - INFO: epoch 001:   3914 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.4, ups=0.88, wpb=104.4, bsz=40, num_updates=3910, lr=4.95024e-05, gnorm=1.126, clip=70, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4403
2022-09-28 17:10:49 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 17:11:00 - progress_bar.py[line:274] - INFO: epoch 001:   3925 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=84.2, ups=0.83, wpb=100.9, bsz=40, num_updates=3920, lr=4.94958e-05, gnorm=1.397, clip=80, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4415
2022-09-28 17:11:12 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.88, wpb=102.2, bsz=40, num_updates=3930, lr=4.94892e-05, gnorm=1.087, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4427
2022-09-28 17:11:23 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.6, ups=0.89, wpb=99.9, bsz=40, num_updates=3940, lr=4.94826e-05, gnorm=1.157, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4438
2022-09-28 17:11:34 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.1, ups=0.91, wpb=102.7, bsz=40, num_updates=3950, lr=4.9476e-05, gnorm=1.079, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4449
2022-09-28 17:11:47 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=77.6, ups=0.77, wpb=100.2, bsz=40, num_updates=3960, lr=4.94694e-05, gnorm=0.972, clip=60, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=4462
2022-09-28 17:11:59 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=81, ups=0.81, wpb=99.7, bsz=40, num_updates=3970, lr=4.94628e-05, gnorm=1.136, clip=60, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4474
2022-09-28 17:12:11 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=84.2, ups=0.83, wpb=101.1, bsz=40, num_updates=3980, lr=4.94562e-05, gnorm=1.18, clip=70, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4486
2022-09-28 17:12:22 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.9, wpb=101.9, bsz=40, num_updates=3990, lr=4.94496e-05, gnorm=1.106, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4497
2022-09-28 17:12:33 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91, ups=0.91, wpb=99.9, bsz=40, num_updates=4000, lr=4.9443e-05, gnorm=1.014, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4508
2022-09-28 17:12:44 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.8, ups=0.9, wpb=101.1, bsz=40, num_updates=4010, lr=4.94364e-05, gnorm=1.104, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4520
2022-09-28 17:12:56 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.6, ups=0.88, wpb=99.9, bsz=40, num_updates=4020, lr=4.94298e-05, gnorm=1.066, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4531
2022-09-28 17:13:07 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.8, ups=0.91, wpb=101.6, bsz=40, num_updates=4030, lr=4.94232e-05, gnorm=1.03, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4542
2022-09-28 17:13:18 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 15783 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.5, ups=0.88, wpb=99.6, bsz=40, num_updates=4040, lr=4.94166e-05, gnorm=1.205, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4553
2022-09-28 17:13:29 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.9, wpb=101.1, bsz=40, num_updates=4050, lr=4.941e-05, gnorm=1.121, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4564
2022-09-28 17:13:40 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.3, ups=0.94, wpb=103, bsz=40, num_updates=4060, lr=4.94034e-05, gnorm=1.072, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4575
2022-09-28 17:13:51 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.8, ups=0.88, wpb=99, bsz=40, num_updates=4070, lr=4.93968e-05, gnorm=1.054, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4587
2022-09-28 17:14:02 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97, ups=0.95, wpb=101.8, bsz=40, num_updates=4080, lr=4.93902e-05, gnorm=1.04, clip=50, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=4597
2022-09-28 17:14:13 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.5, ups=0.88, wpb=100, bsz=40, num_updates=4090, lr=4.93836e-05, gnorm=1.039, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4608
2022-09-28 17:14:24 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.2, ups=0.91, wpb=100.7, bsz=40, num_updates=4100, lr=4.9377e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4619
2022-09-28 17:14:36 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.2, ups=0.86, wpb=100.2, bsz=40, num_updates=4110, lr=4.93704e-05, gnorm=1.09, clip=50, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4631
2022-09-28 17:14:47 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.2, ups=0.93, wpb=100.4, bsz=40, num_updates=4120, lr=4.93638e-05, gnorm=0.989, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4642
2022-09-28 17:14:59 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.88, wpb=102, bsz=40, num_updates=4130, lr=4.93572e-05, gnorm=1.061, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4654
2022-09-28 17:15:10 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.88, wpb=103.5, bsz=40, num_updates=4140, lr=4.93506e-05, gnorm=1.069, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4665
2022-09-28 17:15:21 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=85.7, ups=0.86, wpb=99.1, bsz=40, num_updates=4150, lr=4.9344e-05, gnorm=1.165, clip=50, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=4677
2022-09-28 17:15:33 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.88, wpb=102.5, bsz=40, num_updates=4160, lr=4.93374e-05, gnorm=0.956, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4688
2022-09-28 17:15:45 - progress_bar.py[line:274] - INFO: epoch 001:   4175 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.89, wpb=99.9, bsz=40, num_updates=4170, lr=4.93308e-05, gnorm=1.09, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4700
2022-09-28 17:15:56 - progress_bar.py[line:274] - INFO: epoch 001:   4185 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.7, ups=0.89, wpb=100.9, bsz=40, num_updates=4180, lr=4.93242e-05, gnorm=1.007, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=4711
2022-09-28 17:16:07 - progress_bar.py[line:274] - INFO: epoch 001:   4195 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=4190, lr=4.93176e-05, gnorm=1.201, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4722
2022-09-28 17:16:18 - progress_bar.py[line:274] - INFO: epoch 001:   4205 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.5, ups=0.9, wpb=101.8, bsz=40, num_updates=4200, lr=4.9311e-05, gnorm=1.066, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4733
2022-09-28 17:16:30 - progress_bar.py[line:274] - INFO: epoch 001:   4215 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.6, ups=0.88, wpb=100, bsz=40, num_updates=4210, lr=4.93044e-05, gnorm=1.026, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4745
2022-09-28 17:16:41 - progress_bar.py[line:274] - INFO: epoch 001:   4225 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.9, ups=0.86, wpb=102.1, bsz=40, num_updates=4220, lr=4.92978e-05, gnorm=1.069, clip=70, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=4756
2022-09-28 17:16:53 - progress_bar.py[line:274] - INFO: epoch 001:   4235 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=4230, lr=4.92912e-05, gnorm=1.023, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4768
2022-09-28 17:17:04 - progress_bar.py[line:274] - INFO: epoch 001:   4245 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.89, wpb=101.5, bsz=40, num_updates=4240, lr=4.92846e-05, gnorm=1.116, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4779
2022-09-28 17:17:15 - progress_bar.py[line:274] - INFO: epoch 001:   4255 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.8, ups=0.91, wpb=99.8, bsz=40, num_updates=4250, lr=4.9278e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4790
2022-09-28 17:17:26 - progress_bar.py[line:274] - INFO: epoch 001:   4265 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.88, wpb=102.7, bsz=40, num_updates=4260, lr=4.92714e-05, gnorm=0.954, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4801
2022-09-28 17:17:37 - progress_bar.py[line:274] - INFO: epoch 001:   4275 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.9, ups=0.91, wpb=102.3, bsz=40, num_updates=4270, lr=4.92648e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4812
2022-09-28 17:17:49 - progress_bar.py[line:274] - INFO: epoch 001:   4285 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.8, ups=0.88, wpb=100.2, bsz=40, num_updates=4280, lr=4.92582e-05, gnorm=1.069, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4824
2022-09-28 17:18:00 - progress_bar.py[line:274] - INFO: epoch 001:   4295 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.9, ups=0.91, wpb=100.7, bsz=40, num_updates=4290, lr=4.92516e-05, gnorm=1.171, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4835
2022-09-28 17:18:11 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.9, ups=0.89, wpb=101.5, bsz=40, num_updates=4300, lr=4.9245e-05, gnorm=1.11, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4846
2022-09-28 17:18:23 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.2, ups=0.87, wpb=100.7, bsz=40, num_updates=4310, lr=4.92384e-05, gnorm=0.928, clip=40, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=4858
2022-09-28 17:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   4325 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.3, ups=0.91, wpb=99.8, bsz=40, num_updates=4320, lr=4.92318e-05, gnorm=1.008, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4869
2022-09-28 17:18:45 - progress_bar.py[line:274] - INFO: epoch 001:   4335 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.7, ups=0.88, wpb=102.6, bsz=40, num_updates=4330, lr=4.92252e-05, gnorm=1.016, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4880
2022-09-28 17:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   4345 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.4, ups=0.87, wpb=100.7, bsz=40, num_updates=4340, lr=4.92186e-05, gnorm=1.004, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4891
2022-09-28 17:19:08 - progress_bar.py[line:274] - INFO: epoch 001:   4355 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=4350, lr=4.9212e-05, gnorm=0.941, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4903
2022-09-28 17:19:19 - progress_bar.py[line:274] - INFO: epoch 001:   4365 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.87, wpb=101.1, bsz=40, num_updates=4360, lr=4.92054e-05, gnorm=0.967, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4914
2022-09-28 17:19:30 - progress_bar.py[line:274] - INFO: epoch 001:   4375 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.89, wpb=101.9, bsz=40, num_updates=4370, lr=4.91988e-05, gnorm=0.981, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4925
2022-09-28 17:19:42 - progress_bar.py[line:274] - INFO: epoch 001:   4385 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.4, ups=0.89, wpb=101.5, bsz=40, num_updates=4380, lr=4.91922e-05, gnorm=1.136, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4937
2022-09-28 17:19:53 - progress_bar.py[line:274] - INFO: epoch 001:   4395 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.3, ups=0.9, wpb=102.3, bsz=40, num_updates=4390, lr=4.91856e-05, gnorm=1.18, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4948
2022-09-28 17:20:04 - progress_bar.py[line:274] - INFO: epoch 001:   4405 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.9, ups=0.9, wpb=99.7, bsz=40, num_updates=4400, lr=4.9179e-05, gnorm=1.035, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4959
2022-09-28 17:20:15 - progress_bar.py[line:274] - INFO: epoch 001:   4415 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.8, ups=0.9, wpb=101.4, bsz=40, num_updates=4410, lr=4.91724e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4970
2022-09-28 17:20:26 - progress_bar.py[line:274] - INFO: epoch 001:   4425 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.2, ups=0.88, wpb=101.5, bsz=40, num_updates=4420, lr=4.91658e-05, gnorm=1.016, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4981
2022-09-28 17:20:37 - progress_bar.py[line:274] - INFO: epoch 001:   4435 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.9, wpb=100.7, bsz=40, num_updates=4430, lr=4.91592e-05, gnorm=1.009, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4993
2022-09-28 17:20:49 - progress_bar.py[line:274] - INFO: epoch 001:   4445 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.8, ups=0.89, wpb=100.2, bsz=40, num_updates=4440, lr=4.91526e-05, gnorm=1.036, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5004
2022-09-28 17:21:00 - progress_bar.py[line:274] - INFO: epoch 001:   4455 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.91, wpb=100.4, bsz=40, num_updates=4450, lr=4.9146e-05, gnorm=0.954, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5015
2022-09-28 17:21:11 - progress_bar.py[line:274] - INFO: epoch 001:   4465 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=100.9, bsz=40, num_updates=4460, lr=4.91394e-05, gnorm=1.042, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5026
2022-09-28 17:21:22 - progress_bar.py[line:274] - INFO: epoch 001:   4475 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.1, ups=0.89, wpb=101.1, bsz=40, num_updates=4470, lr=4.91328e-05, gnorm=0.971, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5037
2022-09-28 17:21:33 - progress_bar.py[line:274] - INFO: epoch 001:   4485 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91, ups=0.9, wpb=100.6, bsz=40, num_updates=4480, lr=4.91262e-05, gnorm=1.029, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5049
2022-09-28 17:21:42 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 17:21:46 - progress_bar.py[line:274] - INFO: epoch 001:   4496 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=82.4, ups=0.81, wpb=101.2, bsz=40, num_updates=4490, lr=4.91196e-05, gnorm=0.996, clip=40, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=5061
2022-09-28 17:21:57 - progress_bar.py[line:274] - INFO: epoch 001:   4506 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=101.5, bsz=40, num_updates=4500, lr=4.9113e-05, gnorm=0.989, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5072
2022-09-28 17:22:08 - progress_bar.py[line:274] - INFO: epoch 001:   4516 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.4, ups=0.94, wpb=102.8, bsz=40, num_updates=4510, lr=4.91064e-05, gnorm=1.125, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5083
2022-09-28 17:22:19 - progress_bar.py[line:274] - INFO: epoch 001:   4526 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.5, ups=0.91, wpb=100, bsz=40, num_updates=4520, lr=4.90998e-05, gnorm=1.066, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5094
2022-09-28 17:22:30 - progress_bar.py[line:274] - INFO: epoch 001:   4536 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.7, ups=0.91, wpb=102.6, bsz=40, num_updates=4530, lr=4.90932e-05, gnorm=1.13, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5105
2022-09-28 17:22:41 - progress_bar.py[line:274] - INFO: epoch 001:   4546 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.3, ups=0.9, wpb=102.5, bsz=40, num_updates=4540, lr=4.90866e-05, gnorm=1.07, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5116
2022-09-28 17:22:52 - progress_bar.py[line:274] - INFO: epoch 001:   4556 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.91, wpb=100.4, bsz=40, num_updates=4550, lr=4.908e-05, gnorm=0.906, clip=20, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5127
2022-09-28 17:23:02 - progress_bar.py[line:274] - INFO: epoch 001:   4566 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.8, ups=0.92, wpb=100.7, bsz=40, num_updates=4560, lr=4.90734e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5138
2022-09-28 17:23:14 - progress_bar.py[line:274] - INFO: epoch 001:   4576 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.8, ups=0.9, wpb=102.5, bsz=40, num_updates=4570, lr=4.90668e-05, gnorm=1.02, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5149
2022-09-28 17:23:25 - progress_bar.py[line:274] - INFO: epoch 001:   4586 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.9, wpb=101.9, bsz=40, num_updates=4580, lr=4.90602e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5160
2022-09-28 17:23:36 - progress_bar.py[line:274] - INFO: epoch 001:   4596 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.7, ups=0.9, wpb=100.2, bsz=40, num_updates=4590, lr=4.90536e-05, gnorm=1.056, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5171
2022-09-28 17:23:47 - progress_bar.py[line:274] - INFO: epoch 001:   4606 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.1, ups=0.88, wpb=102.6, bsz=40, num_updates=4600, lr=4.9047e-05, gnorm=1.014, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5182
2022-09-28 17:23:59 - progress_bar.py[line:274] - INFO: epoch 001:   4616 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.3, ups=0.88, wpb=103.2, bsz=40, num_updates=4610, lr=4.90404e-05, gnorm=1.037, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5194
2022-09-28 17:24:10 - progress_bar.py[line:274] - INFO: epoch 001:   4626 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.88, wpb=103.1, bsz=40, num_updates=4620, lr=4.90338e-05, gnorm=1.015, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5205
2022-09-28 17:24:21 - progress_bar.py[line:274] - INFO: epoch 001:   4636 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.6, ups=0.92, wpb=101.4, bsz=40, num_updates=4630, lr=4.90272e-05, gnorm=1.023, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5216
2022-09-28 17:24:32 - progress_bar.py[line:274] - INFO: epoch 001:   4646 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=4640, lr=4.90206e-05, gnorm=0.924, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5227
2022-09-28 17:24:43 - progress_bar.py[line:274] - INFO: epoch 001:   4656 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.1, ups=0.91, wpb=101, bsz=40, num_updates=4650, lr=4.9014e-05, gnorm=0.948, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5238
2022-09-28 17:24:54 - progress_bar.py[line:274] - INFO: epoch 001:   4666 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.9, wpb=101.3, bsz=40, num_updates=4660, lr=4.90074e-05, gnorm=1.412, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5249
2022-09-28 17:25:06 - progress_bar.py[line:274] - INFO: epoch 001:   4676 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.87, wpb=101.7, bsz=40, num_updates=4670, lr=4.90008e-05, gnorm=1.097, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5261
2022-09-28 17:25:17 - progress_bar.py[line:274] - INFO: epoch 001:   4686 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.9, wpb=101.8, bsz=40, num_updates=4680, lr=4.89942e-05, gnorm=1.011, clip=40, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=5272
2022-09-28 17:25:28 - progress_bar.py[line:274] - INFO: epoch 001:   4696 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.7, ups=0.92, wpb=99.2, bsz=40, num_updates=4690, lr=4.89876e-05, gnorm=1.023, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5283
2022-09-28 17:25:39 - progress_bar.py[line:274] - INFO: epoch 001:   4706 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.88, wpb=101.4, bsz=40, num_updates=4700, lr=4.8981e-05, gnorm=1.025, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5294
2022-09-28 17:25:50 - progress_bar.py[line:274] - INFO: epoch 001:   4716 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.89, wpb=101.9, bsz=40, num_updates=4710, lr=4.89744e-05, gnorm=1.223, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5305
2022-09-28 17:26:01 - progress_bar.py[line:274] - INFO: epoch 001:   4726 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=4720, lr=4.89678e-05, gnorm=1.017, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5316
2022-09-28 17:26:12 - progress_bar.py[line:274] - INFO: epoch 001:   4736 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.5, ups=0.91, wpb=100.4, bsz=40, num_updates=4730, lr=4.89612e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5327
2022-09-28 17:26:24 - progress_bar.py[line:274] - INFO: epoch 001:   4746 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.3, ups=0.86, wpb=101.3, bsz=40, num_updates=4740, lr=4.89546e-05, gnorm=1.026, clip=50, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=5339
2022-09-28 17:26:35 - progress_bar.py[line:274] - INFO: epoch 001:   4756 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.7, ups=0.87, wpb=101.2, bsz=40, num_updates=4750, lr=4.8948e-05, gnorm=1.109, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5351
2022-09-28 17:26:47 - progress_bar.py[line:274] - INFO: epoch 001:   4766 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.9, wpb=101.5, bsz=40, num_updates=4760, lr=4.89414e-05, gnorm=1.038, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5362
2022-09-28 17:26:58 - progress_bar.py[line:274] - INFO: epoch 001:   4776 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.4, ups=0.9, wpb=101.7, bsz=40, num_updates=4770, lr=4.89348e-05, gnorm=1.04, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5373
2022-09-28 17:27:09 - progress_bar.py[line:274] - INFO: epoch 001:   4786 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.4, ups=0.92, wpb=99.1, bsz=40, num_updates=4780, lr=4.89282e-05, gnorm=0.99, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5384
2022-09-28 17:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   4796 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.9, ups=0.89, wpb=100.3, bsz=40, num_updates=4790, lr=4.89216e-05, gnorm=1.13, clip=70, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5395
2022-09-28 17:27:31 - progress_bar.py[line:274] - INFO: epoch 001:   4806 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.2, ups=0.9, wpb=103.5, bsz=40, num_updates=4800, lr=4.8915e-05, gnorm=1.094, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5406
2022-09-28 17:27:43 - progress_bar.py[line:274] - INFO: epoch 001:   4816 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.87, wpb=101.5, bsz=40, num_updates=4810, lr=4.89084e-05, gnorm=1.051, clip=50, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=5418
2022-09-28 17:27:54 - progress_bar.py[line:274] - INFO: epoch 001:   4826 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.5, ups=0.87, wpb=101.1, bsz=40, num_updates=4820, lr=4.89018e-05, gnorm=1.063, clip=60, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5429
2022-09-28 17:28:06 - progress_bar.py[line:274] - INFO: epoch 001:   4836 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.3, ups=0.87, wpb=99.9, bsz=40, num_updates=4830, lr=4.88952e-05, gnorm=0.951, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5441
2022-09-28 17:28:17 - progress_bar.py[line:274] - INFO: epoch 001:   4846 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.9, wpb=100.6, bsz=40, num_updates=4840, lr=4.88886e-05, gnorm=1.131, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5452
2022-09-28 17:28:28 - progress_bar.py[line:274] - INFO: epoch 001:   4856 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.88, wpb=100.5, bsz=40, num_updates=4850, lr=4.8882e-05, gnorm=1.093, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5463
2022-09-28 17:28:39 - progress_bar.py[line:274] - INFO: epoch 001:   4866 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=4860, lr=4.88754e-05, gnorm=1.146, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5474
2022-09-28 17:28:50 - progress_bar.py[line:274] - INFO: epoch 001:   4876 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.9, ups=0.89, wpb=100.8, bsz=40, num_updates=4870, lr=4.88688e-05, gnorm=0.99, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5485
2022-09-28 17:29:02 - progress_bar.py[line:274] - INFO: epoch 001:   4886 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.4, ups=0.9, wpb=100.9, bsz=40, num_updates=4880, lr=4.88622e-05, gnorm=1.079, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5497
2022-09-28 17:29:13 - progress_bar.py[line:274] - INFO: epoch 001:   4896 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.92, wpb=100.2, bsz=40, num_updates=4890, lr=4.88556e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5508
2022-09-28 17:29:24 - progress_bar.py[line:274] - INFO: epoch 001:   4906 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.4, ups=0.87, wpb=100.1, bsz=40, num_updates=4900, lr=4.8849e-05, gnorm=0.964, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5519
2022-09-28 17:29:35 - progress_bar.py[line:274] - INFO: epoch 001:   4916 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96, ups=0.94, wpb=101.9, bsz=40, num_updates=4910, lr=4.88424e-05, gnorm=0.936, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5530
2022-09-28 17:29:46 - progress_bar.py[line:274] - INFO: epoch 001:   4926 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.7, ups=0.89, wpb=99.9, bsz=40, num_updates=4920, lr=4.88358e-05, gnorm=1.097, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5541
2022-09-28 17:29:57 - progress_bar.py[line:274] - INFO: epoch 001:   4936 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.4, ups=0.9, wpb=100.6, bsz=40, num_updates=4930, lr=4.88292e-05, gnorm=1.103, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5552
2022-09-28 17:30:08 - progress_bar.py[line:274] - INFO: epoch 001:   4946 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.5, ups=0.9, wpb=99.7, bsz=40, num_updates=4940, lr=4.88226e-05, gnorm=1.215, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5563
2022-09-28 17:30:20 - progress_bar.py[line:274] - INFO: epoch 001:   4956 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.5, ups=0.86, wpb=102.8, bsz=40, num_updates=4950, lr=4.8816e-05, gnorm=1.062, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=5575
2022-09-28 17:30:31 - progress_bar.py[line:274] - INFO: epoch 001:   4966 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94, ups=0.92, wpb=102.4, bsz=40, num_updates=4960, lr=4.88094e-05, gnorm=1.121, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5586
2022-09-28 17:30:42 - progress_bar.py[line:274] - INFO: epoch 001:   4976 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.9, ups=0.87, wpb=100.1, bsz=40, num_updates=4970, lr=4.88028e-05, gnorm=1.062, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5597
2022-09-28 17:30:53 - progress_bar.py[line:274] - INFO: epoch 001:   4986 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.5, ups=0.89, wpb=103.7, bsz=40, num_updates=4980, lr=4.87962e-05, gnorm=0.985, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5608
2022-09-28 17:31:05 - progress_bar.py[line:274] - INFO: epoch 001:   4996 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.87, wpb=101.8, bsz=40, num_updates=4990, lr=4.87896e-05, gnorm=1.005, clip=50, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5620
2022-09-28 17:31:16 - progress_bar.py[line:274] - INFO: epoch 001:   5006 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.89, wpb=101.7, bsz=40, num_updates=5000, lr=4.8783e-05, gnorm=0.959, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5631
2022-09-28 17:31:24 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 17:31:29 - progress_bar.py[line:274] - INFO: epoch 001:   5017 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=82.7, ups=0.81, wpb=102.2, bsz=40, num_updates=5010, lr=4.87764e-05, gnorm=0.902, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=5644
2022-09-28 17:31:40 - progress_bar.py[line:274] - INFO: epoch 001:   5027 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.2, ups=0.89, wpb=100.7, bsz=40, num_updates=5020, lr=4.87698e-05, gnorm=0.989, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5655
2022-09-28 17:31:51 - progress_bar.py[line:274] - INFO: epoch 001:   5037 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=5030, lr=4.87632e-05, gnorm=1.095, clip=50, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=5666
2022-09-28 17:32:02 - progress_bar.py[line:274] - INFO: epoch 001:   5047 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.8, ups=0.91, wpb=101.5, bsz=40, num_updates=5040, lr=4.87566e-05, gnorm=0.968, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5677
2022-09-28 17:32:13 - progress_bar.py[line:274] - INFO: epoch 001:   5057 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.9, ups=0.91, wpb=100.6, bsz=40, num_updates=5050, lr=4.875e-05, gnorm=1.09, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5688
2022-09-28 17:32:25 - progress_bar.py[line:274] - INFO: epoch 001:   5067 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.9, ups=0.88, wpb=100.2, bsz=40, num_updates=5060, lr=4.87434e-05, gnorm=1.278, clip=90, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5700
2022-09-28 17:32:36 - progress_bar.py[line:274] - INFO: epoch 001:   5077 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.5, ups=0.9, wpb=103, bsz=40, num_updates=5070, lr=4.87368e-05, gnorm=1.084, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5711
2022-09-28 17:32:47 - progress_bar.py[line:274] - INFO: epoch 001:   5087 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.5, ups=0.9, wpb=101.3, bsz=40, num_updates=5080, lr=4.87302e-05, gnorm=1.184, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5722
2022-09-28 17:32:58 - progress_bar.py[line:274] - INFO: epoch 001:   5097 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=5090, lr=4.87236e-05, gnorm=1.026, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5733
2022-09-28 17:33:10 - progress_bar.py[line:274] - INFO: epoch 001:   5107 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.2, ups=0.91, wpb=102.1, bsz=40, num_updates=5100, lr=4.8717e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5744
2022-09-28 17:33:21 - progress_bar.py[line:274] - INFO: epoch 001:   5117 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.5, ups=0.92, wpb=101.1, bsz=40, num_updates=5110, lr=4.87104e-05, gnorm=0.945, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5756
2022-09-28 17:33:32 - progress_bar.py[line:274] - INFO: epoch 001:   5127 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.1, ups=0.93, wpb=101.7, bsz=40, num_updates=5120, lr=4.87038e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5767
2022-09-28 17:33:44 - progress_bar.py[line:274] - INFO: epoch 001:   5137 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=86.5, ups=0.87, wpb=98.9, bsz=40, num_updates=5130, lr=4.86972e-05, gnorm=1.081, clip=60, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5779
2022-09-28 17:33:55 - progress_bar.py[line:274] - INFO: epoch 001:   5147 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.91, wpb=101.3, bsz=40, num_updates=5140, lr=4.86906e-05, gnorm=0.948, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5790
2022-09-28 17:34:06 - progress_bar.py[line:274] - INFO: epoch 001:   5157 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=5150, lr=4.8684e-05, gnorm=0.862, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5801
2022-09-28 17:34:17 - progress_bar.py[line:274] - INFO: epoch 001:   5167 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.9, ups=0.91, wpb=101.4, bsz=40, num_updates=5160, lr=4.86774e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5812
2022-09-28 17:34:28 - progress_bar.py[line:274] - INFO: epoch 001:   5177 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.8, ups=0.89, wpb=102.1, bsz=40, num_updates=5170, lr=4.86708e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5823
2022-09-28 17:34:39 - progress_bar.py[line:274] - INFO: epoch 001:   5187 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.8, ups=0.89, wpb=102.1, bsz=40, num_updates=5180, lr=4.86642e-05, gnorm=0.892, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5834
2022-09-28 17:34:51 - progress_bar.py[line:274] - INFO: epoch 001:   5197 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.1, ups=0.88, wpb=103.5, bsz=40, num_updates=5190, lr=4.86576e-05, gnorm=0.945, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5846
2022-09-28 17:35:02 - progress_bar.py[line:274] - INFO: epoch 001:   5207 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.6, ups=0.88, wpb=101.4, bsz=40, num_updates=5200, lr=4.8651e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5857
2022-09-28 17:35:13 - progress_bar.py[line:274] - INFO: epoch 001:   5217 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92, ups=0.9, wpb=102.1, bsz=40, num_updates=5210, lr=4.86444e-05, gnorm=1.023, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5868
2022-09-28 17:35:24 - progress_bar.py[line:274] - INFO: epoch 001:   5227 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94, ups=0.91, wpb=102.7, bsz=40, num_updates=5220, lr=4.86378e-05, gnorm=0.999, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5879
2022-09-28 17:35:36 - progress_bar.py[line:274] - INFO: epoch 001:   5237 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.8, ups=0.87, wpb=101.4, bsz=40, num_updates=5230, lr=4.86312e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5891
2022-09-28 17:35:47 - progress_bar.py[line:274] - INFO: epoch 001:   5247 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.6, ups=0.88, wpb=101.1, bsz=40, num_updates=5240, lr=4.86246e-05, gnorm=0.937, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5902
2022-09-28 17:35:58 - progress_bar.py[line:274] - INFO: epoch 001:   5257 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.1, ups=0.88, wpb=102.1, bsz=40, num_updates=5250, lr=4.8618e-05, gnorm=0.98, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5913
2022-09-28 17:36:09 - progress_bar.py[line:274] - INFO: epoch 001:   5267 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.2, ups=0.93, wpb=100.2, bsz=40, num_updates=5260, lr=4.86114e-05, gnorm=1.085, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5924
2022-09-28 17:36:20 - progress_bar.py[line:274] - INFO: epoch 001:   5277 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=5270, lr=4.86048e-05, gnorm=0.989, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5935
2022-09-28 17:36:31 - progress_bar.py[line:274] - INFO: epoch 001:   5287 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.91, wpb=101.1, bsz=40, num_updates=5280, lr=4.85982e-05, gnorm=1.111, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5946
2022-09-28 17:36:43 - progress_bar.py[line:274] - INFO: epoch 001:   5297 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.89, wpb=103, bsz=40, num_updates=5290, lr=4.85916e-05, gnorm=0.949, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5958
2022-09-28 17:36:54 - progress_bar.py[line:274] - INFO: epoch 001:   5307 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=5300, lr=4.8585e-05, gnorm=1.051, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5969
2022-09-28 17:37:05 - progress_bar.py[line:274] - INFO: epoch 001:   5317 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.1, ups=0.91, wpb=100.7, bsz=40, num_updates=5310, lr=4.85784e-05, gnorm=1.053, clip=70, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5980
2022-09-28 17:37:16 - progress_bar.py[line:274] - INFO: epoch 001:   5327 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90, ups=0.9, wpb=100.5, bsz=40, num_updates=5320, lr=4.85718e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5991
2022-09-28 17:37:27 - progress_bar.py[line:274] - INFO: epoch 001:   5337 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.4, ups=0.88, wpb=100.6, bsz=40, num_updates=5330, lr=4.85652e-05, gnorm=1.073, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6003
2022-09-28 17:37:39 - progress_bar.py[line:274] - INFO: epoch 001:   5347 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.8, ups=0.88, wpb=98.6, bsz=40, num_updates=5340, lr=4.85586e-05, gnorm=0.963, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6014
2022-09-28 17:37:50 - progress_bar.py[line:274] - INFO: epoch 001:   5357 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.89, wpb=101.3, bsz=40, num_updates=5350, lr=4.8552e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6025
2022-09-28 17:38:01 - progress_bar.py[line:274] - INFO: epoch 001:   5367 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.91, wpb=100.1, bsz=40, num_updates=5360, lr=4.85454e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6036
2022-09-28 17:38:13 - progress_bar.py[line:274] - INFO: epoch 001:   5377 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.7, ups=0.87, wpb=101.2, bsz=40, num_updates=5370, lr=4.85388e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6048
2022-09-28 17:38:24 - progress_bar.py[line:274] - INFO: epoch 001:   5387 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.89, wpb=100, bsz=40, num_updates=5380, lr=4.85322e-05, gnorm=1.119, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6059
2022-09-28 17:38:35 - progress_bar.py[line:274] - INFO: epoch 001:   5397 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.88, wpb=101.1, bsz=40, num_updates=5390, lr=4.85256e-05, gnorm=1.054, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6070
2022-09-28 17:38:46 - progress_bar.py[line:274] - INFO: epoch 001:   5407 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.9, wpb=100.4, bsz=40, num_updates=5400, lr=4.8519e-05, gnorm=1.091, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6081
2022-09-28 17:38:57 - progress_bar.py[line:274] - INFO: epoch 001:   5417 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92, ups=0.92, wpb=100.2, bsz=40, num_updates=5410, lr=4.85124e-05, gnorm=1.055, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6092
2022-09-28 17:39:09 - progress_bar.py[line:274] - INFO: epoch 001:   5427 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.4, ups=0.88, wpb=100.6, bsz=40, num_updates=5420, lr=4.85058e-05, gnorm=1.057, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6104
2022-09-28 17:39:19 - progress_bar.py[line:274] - INFO: epoch 001:   5437 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.9, ups=0.93, wpb=100.2, bsz=40, num_updates=5430, lr=4.84992e-05, gnorm=1.252, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6115
2022-09-28 17:39:31 - progress_bar.py[line:274] - INFO: epoch 001:   5447 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.9, ups=0.88, wpb=100.6, bsz=40, num_updates=5440, lr=4.84926e-05, gnorm=1.009, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6126
2022-09-28 17:39:42 - progress_bar.py[line:274] - INFO: epoch 001:   5457 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.1, ups=0.9, wpb=102.4, bsz=40, num_updates=5450, lr=4.8486e-05, gnorm=0.998, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6137
2022-09-28 17:39:53 - progress_bar.py[line:274] - INFO: epoch 001:   5467 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.91, wpb=101.1, bsz=40, num_updates=5460, lr=4.84794e-05, gnorm=0.867, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6148
2022-09-28 17:40:04 - progress_bar.py[line:274] - INFO: epoch 001:   5477 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=5470, lr=4.84728e-05, gnorm=1.016, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6159
2022-09-28 17:40:16 - progress_bar.py[line:274] - INFO: epoch 001:   5487 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.2, ups=0.87, wpb=100.5, bsz=40, num_updates=5480, lr=4.84662e-05, gnorm=1.001, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6171
2022-09-28 17:40:27 - progress_bar.py[line:274] - INFO: epoch 001:   5497 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.5, ups=0.89, wpb=99.8, bsz=40, num_updates=5490, lr=4.84596e-05, gnorm=0.997, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6182
2022-09-28 17:40:38 - progress_bar.py[line:274] - INFO: epoch 001:   5507 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.7, ups=0.91, wpb=102.7, bsz=40, num_updates=5500, lr=4.8453e-05, gnorm=1.077, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6193
2022-09-28 17:40:49 - progress_bar.py[line:274] - INFO: epoch 001:   5517 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=5510, lr=4.84464e-05, gnorm=1.074, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6205
2022-09-28 17:41:01 - progress_bar.py[line:274] - INFO: epoch 001:   5527 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.88, wpb=101.8, bsz=40, num_updates=5520, lr=4.84398e-05, gnorm=1.027, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6216
2022-09-28 17:41:12 - progress_bar.py[line:274] - INFO: epoch 001:   5537 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.91, wpb=101, bsz=40, num_updates=5530, lr=4.84332e-05, gnorm=0.984, clip=50, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6227
2022-09-28 17:41:23 - progress_bar.py[line:274] - INFO: epoch 001:   5547 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.9, wpb=101.8, bsz=40, num_updates=5540, lr=4.84266e-05, gnorm=0.969, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6238
2022-09-28 17:41:34 - progress_bar.py[line:274] - INFO: epoch 001:   5557 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=5550, lr=4.842e-05, gnorm=1.046, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6249
2022-09-28 17:41:45 - progress_bar.py[line:274] - INFO: epoch 001:   5567 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.89, wpb=101.4, bsz=40, num_updates=5560, lr=4.84134e-05, gnorm=0.963, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6260
2022-09-28 17:41:57 - progress_bar.py[line:274] - INFO: epoch 001:   5577 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.2, ups=0.88, wpb=101.9, bsz=40, num_updates=5570, lr=4.84068e-05, gnorm=0.937, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6272
2022-09-28 17:42:06 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 17:42:09 - progress_bar.py[line:274] - INFO: epoch 001:   5588 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=82.4, ups=0.82, wpb=100.2, bsz=40, num_updates=5580, lr=4.84002e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6284
2022-09-28 17:42:20 - progress_bar.py[line:274] - INFO: epoch 001:   5598 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=101.2, bsz=40, num_updates=5590, lr=4.83936e-05, gnorm=0.967, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6295
2022-09-28 17:42:32 - progress_bar.py[line:274] - INFO: epoch 001:   5608 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.2, ups=0.89, wpb=99, bsz=40, num_updates=5600, lr=4.8387e-05, gnorm=1.029, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6307
2022-09-28 17:42:43 - progress_bar.py[line:274] - INFO: epoch 001:   5618 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.88, wpb=100.7, bsz=40, num_updates=5610, lr=4.83804e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6318
2022-09-28 17:42:54 - progress_bar.py[line:274] - INFO: epoch 001:   5628 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=5620, lr=4.83738e-05, gnorm=0.991, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6329
2022-09-28 17:43:05 - progress_bar.py[line:274] - INFO: epoch 001:   5638 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.3, ups=0.87, wpb=101, bsz=40, num_updates=5630, lr=4.83672e-05, gnorm=0.991, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6341
2022-09-28 17:43:17 - progress_bar.py[line:274] - INFO: epoch 001:   5648 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.4, ups=0.89, wpb=100.8, bsz=40, num_updates=5640, lr=4.83606e-05, gnorm=0.833, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6352
2022-09-28 17:43:28 - progress_bar.py[line:274] - INFO: epoch 001:   5658 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.88, wpb=100.4, bsz=40, num_updates=5650, lr=4.8354e-05, gnorm=1.008, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6363
2022-09-28 17:43:39 - progress_bar.py[line:274] - INFO: epoch 001:   5668 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.3, ups=0.89, wpb=101.9, bsz=40, num_updates=5660, lr=4.83474e-05, gnorm=1.177, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6374
2022-09-28 17:43:51 - progress_bar.py[line:274] - INFO: epoch 001:   5678 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.88, wpb=101.1, bsz=40, num_updates=5670, lr=4.83408e-05, gnorm=0.919, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6386
2022-09-28 17:44:02 - progress_bar.py[line:274] - INFO: epoch 001:   5688 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.1, ups=0.92, wpb=101.3, bsz=40, num_updates=5680, lr=4.83342e-05, gnorm=1.02, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6397
2022-09-28 17:44:13 - progress_bar.py[line:274] - INFO: epoch 001:   5698 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.9, ups=0.91, wpb=103, bsz=40, num_updates=5690, lr=4.83276e-05, gnorm=0.989, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6408
2022-09-28 17:44:24 - progress_bar.py[line:274] - INFO: epoch 001:   5708 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=5700, lr=4.8321e-05, gnorm=1.064, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6419
2022-09-28 17:44:35 - progress_bar.py[line:274] - INFO: epoch 001:   5718 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89, ups=0.88, wpb=101.2, bsz=40, num_updates=5710, lr=4.83144e-05, gnorm=1.208, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6430
2022-09-28 17:44:46 - progress_bar.py[line:274] - INFO: epoch 001:   5728 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.4, ups=0.94, wpb=102.4, bsz=40, num_updates=5720, lr=4.83078e-05, gnorm=1.001, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6441
2022-09-28 17:44:57 - progress_bar.py[line:274] - INFO: epoch 001:   5738 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=101.2, bsz=40, num_updates=5730, lr=4.83012e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6452
2022-09-28 17:45:08 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=102, bsz=40, num_updates=5740, lr=4.82946e-05, gnorm=1.016, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6463
2022-09-28 17:45:19 - progress_bar.py[line:274] - INFO: epoch 001:   5758 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.6, ups=0.91, wpb=101.7, bsz=40, num_updates=5750, lr=4.8288e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6474
2022-09-28 17:45:31 - progress_bar.py[line:274] - INFO: epoch 001:   5768 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=83.4, ups=0.84, wpb=99.6, bsz=40, num_updates=5760, lr=4.82814e-05, gnorm=1.009, clip=50, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=6486
2022-09-28 17:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   5778 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=84.1, ups=0.82, wpb=102.7, bsz=40, num_updates=5770, lr=4.82748e-05, gnorm=0.942, clip=20, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=6499
2022-09-28 17:45:55 - progress_bar.py[line:274] - INFO: epoch 001:   5788 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=85.3, ups=0.85, wpb=100.6, bsz=40, num_updates=5780, lr=4.82682e-05, gnorm=1.092, clip=70, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=6510
2022-09-28 17:46:06 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94, ups=0.92, wpb=101.6, bsz=40, num_updates=5790, lr=4.82616e-05, gnorm=1.065, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6521
2022-09-28 17:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   5808 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.8, ups=0.91, wpb=103.6, bsz=40, num_updates=5800, lr=4.8255e-05, gnorm=1.019, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6532
2022-09-28 17:46:28 - progress_bar.py[line:274] - INFO: epoch 001:   5818 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.92, wpb=99, bsz=40, num_updates=5810, lr=4.82484e-05, gnorm=0.887, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6543
2022-09-28 17:46:39 - progress_bar.py[line:274] - INFO: epoch 001:   5828 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.2, ups=0.94, wpb=98.9, bsz=40, num_updates=5820, lr=4.82418e-05, gnorm=1.139, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6554
2022-09-28 17:46:50 - progress_bar.py[line:274] - INFO: epoch 001:   5838 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.89, wpb=100.5, bsz=40, num_updates=5830, lr=4.82352e-05, gnorm=0.959, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6565
2022-09-28 17:47:01 - progress_bar.py[line:274] - INFO: epoch 001:   5848 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.89, wpb=100.3, bsz=40, num_updates=5840, lr=4.82286e-05, gnorm=1.043, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6576
2022-09-28 17:47:12 - progress_bar.py[line:274] - INFO: epoch 001:   5858 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.4, ups=0.91, wpb=102.2, bsz=40, num_updates=5850, lr=4.8222e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6587
2022-09-28 17:47:23 - progress_bar.py[line:274] - INFO: epoch 001:   5868 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.5, ups=0.88, wpb=99.7, bsz=40, num_updates=5860, lr=4.82154e-05, gnorm=1.149, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6598
2022-09-28 17:47:34 - progress_bar.py[line:274] - INFO: epoch 001:   5878 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92, ups=0.92, wpb=100.1, bsz=40, num_updates=5870, lr=4.82088e-05, gnorm=0.916, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6609
2022-09-28 17:47:45 - progress_bar.py[line:274] - INFO: epoch 001:   5888 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.2, ups=0.89, wpb=102.2, bsz=40, num_updates=5880, lr=4.82022e-05, gnorm=0.982, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6621
2022-09-28 17:47:57 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.8, ups=0.87, wpb=101.3, bsz=40, num_updates=5890, lr=4.81956e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6632
2022-09-28 17:48:09 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.5, ups=0.87, wpb=100.8, bsz=40, num_updates=5900, lr=4.8189e-05, gnorm=0.975, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6644
2022-09-28 17:48:20 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=5910, lr=4.81824e-05, gnorm=1.033, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6655
2022-09-28 17:48:31 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.88, wpb=102.3, bsz=40, num_updates=5920, lr=4.81758e-05, gnorm=0.901, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6666
2022-09-28 17:48:42 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.3, ups=0.9, wpb=101.4, bsz=40, num_updates=5930, lr=4.81692e-05, gnorm=1.32, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6677
2022-09-28 17:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.3, ups=0.89, wpb=102.3, bsz=40, num_updates=5940, lr=4.81626e-05, gnorm=1.038, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6689
2022-09-28 17:49:05 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.9, wpb=101.7, bsz=40, num_updates=5950, lr=4.8156e-05, gnorm=1.029, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6700
2022-09-28 17:49:16 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90, ups=0.89, wpb=101.2, bsz=40, num_updates=5960, lr=4.81494e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6711
2022-09-28 17:49:28 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.4, ups=0.85, wpb=102.1, bsz=40, num_updates=5970, lr=4.81428e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6723
2022-09-28 17:49:39 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.3, ups=0.85, wpb=102.6, bsz=40, num_updates=5980, lr=4.81362e-05, gnorm=1.201, clip=50, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=6735
2022-09-28 17:49:52 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=83.8, ups=0.82, wpb=101.8, bsz=40, num_updates=5990, lr=4.81296e-05, gnorm=0.938, clip=50, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=6747
2022-09-28 17:50:03 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.87, wpb=103.2, bsz=40, num_updates=6000, lr=4.8123e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6758
2022-09-28 17:50:03 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-28 17:50:03 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-28 17:50:05 - train.py[line:549] - INFO: 0 / 9402
2022-09-28 17:50:05 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-28 17:50:07 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 12.37 GiB (GPU 1; 39.59 GiB total capacity; 13.54 GiB already allocated; 10.04 GiB free; 27.07 GiB reserved in total by PyTorch)
2022-09-28 17:50:07 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-28 17:50:07 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 10        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13860 MB |   16529 MB |    1029 TB |    1029 TB |
|       from large pool |   13714 MB |   16382 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13860 MB |   16529 MB |    1029 TB |    1029 TB |
|       from large pool |   13714 MB |   16382 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     146 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   27720 MB |   37668 MB |  143112 MB |  115392 MB |
|       from large pool |   27574 MB |   37520 MB |  142756 MB |  115182 MB |
|       from small pool |     146 MB |     148 MB |     356 MB |     210 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   13859 MB |   14594 MB |  758035 GB |  758022 GB |
|       from large pool |   13859 MB |   14592 MB |  757266 GB |  757252 GB |
|       from small pool |       0 MB |       2 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    3641    |    3655    |   31923 K  |   31920 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15695 K  |   15692 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3641    |    3655    |   31923 K  |   31920 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15695 K  |   15692 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     208    |     305    |     616    |     408    |
|       from large pool |     135    |     231    |     438    |     303    |
|       from small pool |      73    |      74    |     178    |     105    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     142    |     149    |   17432 K  |   17432 K  |
|       from large pool |      97    |     103    |    9636 K  |    9636 K  |
|       from small pool |      45    |      52    |    7795 K  |    7795 K  |
|===========================================================================|

2022-09-28 17:50:07 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-28 17:50:08 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 14.98 GiB already allocated; 11.19 GiB free; 25.92 GiB reserved in total by PyTorch)
2022-09-28 17:50:08 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   15339 MB |   18306 MB |    1029 TB |    1029 TB |
|       from large pool |   15193 MB |   18159 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   15339 MB |   18306 MB |    1029 TB |    1029 TB |
|       from large pool |   15193 MB |   18159 MB |    1028 TB |    1028 TB |
|       from small pool |     145 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26542 MB |   37668 MB |  154242 MB |  127700 MB |
|       from large pool |   26394 MB |   37520 MB |  153860 MB |  127466 MB |
|       from small pool |     148 MB |     148 MB |     382 MB |     234 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   11202 MB |   11982 MB |  737580 GB |  737569 GB |
|       from large pool |   11200 MB |   11980 MB |  736810 GB |  736799 GB |
|       from small pool |       2 MB |       2 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    3641    |    3655    |   31923 K  |   31920 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15695 K  |   15692 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3641    |    3655    |   31923 K  |   31920 K  |
|       from large pool |     563    |     575    |   16228 K  |   16228 K  |
|       from small pool |    3078    |    3096    |   15695 K  |   15692 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     204    |     292    |     617    |     413    |
|       from large pool |     130    |     218    |     426    |     296    |
|       from small pool |      74    |      74    |     191    |     117    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     141    |     146    |   17246 K  |   17245 K  |
|       from large pool |     103    |     107    |    9442 K  |    9442 K  |
|       from small pool |      38    |      44    |    7803 K  |    7803 K  |
|===========================================================================|

2022-09-28 17:50:08 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-28 17:50:08 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-28 17:50:09 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 25.12 GiB already allocated; 10.81 GiB free; 26.30 GiB reserved in total by PyTorch)
2022-09-28 17:50:09 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 12        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   25719 MB |   28687 MB |    1029 TB |    1029 TB |
|       from large pool |   25600 MB |   28566 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |   25719 MB |   28687 MB |    1029 TB |    1029 TB |
|       from large pool |   25600 MB |   28566 MB |    1028 TB |    1028 TB |
|       from small pool |     119 MB |     147 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   26934 MB |   37748 MB |  175852 MB |  148918 MB |
|       from large pool |   26810 MB |   37624 MB |  175470 MB |  148660 MB |
|       from small pool |     124 MB |     148 MB |     382 MB |     258 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1214 MB |   11982 MB |  737653 GB |  737652 GB |
|       from large pool |    1209 MB |   11980 MB |  736883 GB |  736882 GB |
|       from small pool |       4 MB |       6 MB |     769 GB |     769 GB |
|---------------------------------------------------------------------------|
| Allocations           |    2997    |    3655    |   31929 K  |   31926 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15699 K  |   15696 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    2997    |    3655    |   31929 K  |   31926 K  |
|       from large pool |     447    |     575    |   16230 K  |   16229 K  |
|       from small pool |    2550    |    3096    |   15699 K  |   15696 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     116    |     292    |     631    |     515    |
|       from large pool |      54    |     218    |     440    |     386    |
|       from small pool |      62    |      74    |     191    |     129    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     118    |     178    |   17250 K  |   17250 K  |
|       from large pool |      57    |     107    |    9443 K  |    9443 K  |
|       from small pool |      61    |     102    |    7807 K  |    7807 K  |
|===========================================================================|

2022-09-28 17:50:09 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

Traceback (most recent call last):
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 14.98 GiB already allocated; 11.19 GiB free; 25.92 GiB reserved in total by PyTorch)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 630, in <module>
    cli_main()
  File "../../train.py", line 623, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "../../train.py", line 332, in train
    cfg, trainer, task, epoch_itr, valid_subsets, end_of_epoch
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, (pred_scores, pred, sample_ids), time_info = trainer.valid_step(sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1088, in valid_step
    return self.valid_step(sample, raise_oom=True)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1089, in valid_step
    raise e
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 14.91 GiB (GPU 0; 39.59 GiB total capacity; 25.12 GiB already allocated; 10.81 GiB free; 26.30 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/50_way_allcand', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=15', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=5', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=6000', '--validate-interval-updates=6000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 851206
Killing subprocess 851207
2022-09-28 20:42:44 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-09-28 20:42:44 - utils.py[line:261] - INFO: Start init
2022-09-28 20:42:44 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-09-28 20:42:44 - utils.py[line:261] - INFO: Start init
2022-09-28 20:42:44 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-09-28 20:42:44 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-09-28 20:42:44 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-09-28 20:42:44 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-09-28 20:42:48 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/50_way_allcand', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 6000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 6000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='10', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', save_interval=10, save_interval_updates=6000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/50_way_allcand', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=26, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=6000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 26, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-09-28 20:42:48 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-09-28 20:42:48 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-09-28 20:42:53 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-09-28 20:42:53 - train.py[line:118] - INFO: task: VqaGenTask
2022-09-28 20:42:53 - train.py[line:119] - INFO: model: OFAModel
2022-09-28 20:42:53 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-09-28 20:42:53 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-09-28 20:42:53 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv slice_id 0 row count 141030 total row count 282060
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv slice_id 1 row count 141030 total row count 282060
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-09-28 20:42:55 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-09-28 20:42:55 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-09-28 20:42:55 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 20:42:55 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 20:42:55 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-09-28 20:42:55 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-09-28 20:42:55 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-09-28 20:42:55 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-09-28 20:42:55 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-09-28 20:43:06 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 20:43:06 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-09-28 20:43:06 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-09-28 20:43:06 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-09-28 20:43:07 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-09-28 20:43:07 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 1 row count 315642 total row count 631284
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv slice_id 0 row count 315642 total row count 631284
2022-09-28 20:43:07 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
Total steps 78915, warmup steps 3156, warmup_factor 0.0003168567807351077
2022-09-28 20:43:08 - trainer.py[line:707] - INFO: begin training epoch 1
2022-09-28 20:43:08 - train.py[line:312] - INFO: Start iterating over samples
2022-09-28 20:43:24 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 15783 loss=1.323, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=85.6, ups=0.84, wpb=102.4, bsz=40, num_updates=10, lr=1.58428e-07, gnorm=14.932, clip=100, loss_scale=128, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=29
2022-09-28 20:43:36 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 15783 loss=1.339, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=85.1, ups=0.85, wpb=100.6, bsz=40, num_updates=20, lr=3.16857e-07, gnorm=13.441, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=41
2022-09-28 20:43:48 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 15783 loss=1.399, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=86.8, ups=0.86, wpb=100.6, bsz=40, num_updates=30, lr=4.75285e-07, gnorm=15.35, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=52
2022-09-28 20:44:00 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 15783 loss=1.273, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=85.9, ups=0.84, wpb=102.1, bsz=40, num_updates=40, lr=6.33714e-07, gnorm=10.968, clip=100, loss_scale=128, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=64
2022-09-28 20:44:11 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 15783 loss=1.226, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=86.7, ups=0.85, wpb=102.4, bsz=40, num_updates=50, lr=7.92142e-07, gnorm=10.902, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=76
2022-09-28 20:44:23 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 15783 loss=1.208, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=85.7, ups=0.85, wpb=100.4, bsz=40, num_updates=60, lr=9.5057e-07, gnorm=8.954, clip=100, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=88
2022-09-28 20:44:35 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 15783 loss=1.135, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=89.7, ups=0.87, wpb=102.7, bsz=40, num_updates=70, lr=1.109e-06, gnorm=8.219, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=99
2022-09-28 20:44:46 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 15783 loss=1.09, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=87.9, ups=0.85, wpb=103.2, bsz=40, num_updates=80, lr=1.26743e-06, gnorm=7.334, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=111
2022-09-28 20:44:58 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 15783 loss=1.105, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=86.6, ups=0.86, wpb=101.2, bsz=40, num_updates=90, lr=1.42586e-06, gnorm=6.142, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=123
2022-09-28 20:45:10 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 15783 loss=1.063, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=86.8, ups=0.86, wpb=101, bsz=40, num_updates=100, lr=1.58428e-06, gnorm=5.461, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=134
2022-09-28 20:45:21 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 15783 loss=1.051, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=87.8, ups=0.87, wpb=101.4, bsz=40, num_updates=110, lr=1.74271e-06, gnorm=5.338, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=146
2022-09-28 20:45:33 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 15783 loss=1.054, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=86.7, ups=0.86, wpb=100.3, bsz=40, num_updates=120, lr=1.90114e-06, gnorm=5.064, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=158
2022-09-28 20:45:44 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 15783 loss=1.039, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=87.2, ups=0.87, wpb=100.4, bsz=40, num_updates=130, lr=2.05957e-06, gnorm=4.815, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=169
2022-09-28 20:45:57 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 15783 loss=0.956, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=79.3, ups=0.78, wpb=101.8, bsz=40, num_updates=140, lr=2.218e-06, gnorm=4.328, clip=100, loss_scale=128, train_wall=13, gb_free=9.8, ema_decay=0.9999, wall=182
2022-09-28 20:46:10 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 15783 loss=0.965, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=81, ups=0.79, wpb=102.2, bsz=40, num_updates=150, lr=2.37643e-06, gnorm=4.048, clip=100, loss_scale=128, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=195
2022-09-28 20:46:21 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 15783 loss=0.922, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=92.8, ups=0.91, wpb=102.5, bsz=40, num_updates=160, lr=2.53485e-06, gnorm=4.165, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=206
2022-09-28 20:46:33 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 15783 loss=0.916, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=80, ups=0.8, wpb=100.6, bsz=40, num_updates=170, lr=2.69328e-06, gnorm=3.615, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=218
2022-09-28 20:46:46 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 15783 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=81.1, ups=0.79, wpb=102.9, bsz=40, num_updates=180, lr=2.85171e-06, gnorm=3.628, clip=100, loss_scale=128, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=231
2022-09-28 20:46:58 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 15783 loss=0.954, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=86.1, ups=0.87, wpb=99.5, bsz=40, num_updates=190, lr=3.01014e-06, gnorm=3.815, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=243
2022-09-28 20:47:09 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 15783 loss=0.926, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=88.3, ups=0.86, wpb=102.6, bsz=40, num_updates=200, lr=3.16857e-06, gnorm=3.71, clip=100, loss_scale=128, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=254
2022-09-28 20:47:21 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 15783 loss=0.959, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=90.7, ups=0.89, wpb=101.3, bsz=40, num_updates=210, lr=3.327e-06, gnorm=3.248, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=265
2022-09-28 20:47:32 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 15783 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.702, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=90.5, ups=0.88, wpb=102.9, bsz=40, num_updates=220, lr=3.48542e-06, gnorm=3.066, clip=100, loss_scale=128, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=277
2022-09-28 20:47:44 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 15783 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=88.3, ups=0.86, wpb=103, bsz=40, num_updates=230, lr=3.64385e-06, gnorm=3.078, clip=100, loss_scale=128, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=289
2022-09-28 20:47:55 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 15783 loss=0.908, loss_v1=0, loss_v2=0, nll_loss=0.741, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=89.9, ups=0.89, wpb=101.3, bsz=40, num_updates=240, lr=3.80228e-06, gnorm=3.201, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=300
2022-09-28 20:48:08 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 15783 loss=0.887, loss_v1=0, loss_v2=0, nll_loss=0.717, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=76.1, ups=0.75, wpb=101.2, bsz=40, num_updates=250, lr=3.96071e-06, gnorm=3.032, clip=100, loss_scale=128, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=313
2022-09-28 20:48:21 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 15783 loss=0.91, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=79.2, ups=0.77, wpb=102.3, bsz=40, num_updates=260, lr=4.11914e-06, gnorm=2.937, clip=100, loss_scale=128, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=326
2022-09-28 20:48:33 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 15783 loss=0.956, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=83.3, ups=0.83, wpb=99.9, bsz=40, num_updates=270, lr=4.27757e-06, gnorm=3.063, clip=100, loss_scale=128, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=338
2022-09-28 20:48:45 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 15783 loss=0.931, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=89.2, ups=0.88, wpb=101, bsz=40, num_updates=280, lr=4.43599e-06, gnorm=3.102, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=349
2022-09-28 20:48:56 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 15783 loss=0.95, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=90.3, ups=0.9, wpb=100.7, bsz=40, num_updates=290, lr=4.59442e-06, gnorm=3.103, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=360
2022-09-28 20:49:07 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 15783 loss=1.001, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=98.1, nsentences=40, sample_size=98.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=87.7, ups=0.89, wpb=98.1, bsz=40, num_updates=300, lr=4.75285e-06, gnorm=2.933, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=372
2022-09-28 20:49:18 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 15783 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=92.9, ups=0.91, wpb=102.1, bsz=40, num_updates=310, lr=4.91128e-06, gnorm=2.912, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=383
2022-09-28 20:49:30 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 15783 loss=0.938, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=85.7, ups=0.85, wpb=100.7, bsz=40, num_updates=320, lr=5.06971e-06, gnorm=2.897, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=394
2022-09-28 20:49:40 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 15783 loss=0.884, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=94.9, ups=0.93, wpb=102.3, bsz=40, num_updates=330, lr=5.22814e-06, gnorm=2.899, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=405
2022-09-28 20:49:52 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 15783 loss=0.863, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=90.4, ups=0.89, wpb=101, bsz=40, num_updates=340, lr=5.38657e-06, gnorm=2.632, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=416
2022-09-28 20:50:03 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 15783 loss=0.819, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=93.4, ups=0.91, wpb=102.9, bsz=40, num_updates=350, lr=5.54499e-06, gnorm=2.572, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=427
2022-09-28 20:50:14 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 15783 loss=0.88, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=89.5, ups=0.87, wpb=102.5, bsz=40, num_updates=360, lr=5.70342e-06, gnorm=2.892, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=439
2022-09-28 20:50:25 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 15783 loss=0.888, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=90.9, ups=0.9, wpb=101.3, bsz=40, num_updates=370, lr=5.86185e-06, gnorm=2.66, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=450
2022-09-28 20:50:37 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 15783 loss=0.878, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=86.8, ups=0.86, wpb=101, bsz=40, num_updates=380, lr=6.02028e-06, gnorm=2.848, clip=100, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=462
2022-09-28 20:50:48 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 15783 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.66, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=90.2, ups=0.88, wpb=102.5, bsz=40, num_updates=390, lr=6.17871e-06, gnorm=2.849, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=473
2022-09-28 20:50:59 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 15783 loss=0.876, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=92.4, ups=0.92, wpb=100.6, bsz=40, num_updates=400, lr=6.33714e-06, gnorm=2.943, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=484
2022-09-28 20:51:10 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 15783 loss=0.833, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=93.6, ups=0.92, wpb=101.2, bsz=40, num_updates=410, lr=6.49556e-06, gnorm=2.687, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=495
2022-09-28 20:51:21 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 15783 loss=0.857, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=88.6, ups=0.89, wpb=99.7, bsz=40, num_updates=420, lr=6.65399e-06, gnorm=2.949, clip=100, loss_scale=128, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=506
2022-09-28 20:51:32 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 15783 loss=0.89, loss_v1=0, loss_v2=0, nll_loss=0.72, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=89.4, ups=0.89, wpb=100.6, bsz=40, num_updates=430, lr=6.81242e-06, gnorm=2.764, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=517
2022-09-28 20:51:45 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 15783 loss=0.854, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=81.1, ups=0.81, wpb=100.2, bsz=40, num_updates=440, lr=6.97085e-06, gnorm=2.763, clip=100, loss_scale=128, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=530
2022-09-28 20:51:57 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 15783 loss=0.868, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=81.5, ups=0.82, wpb=99.7, bsz=40, num_updates=450, lr=7.12928e-06, gnorm=2.884, clip=100, loss_scale=128, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=542
2022-09-28 20:52:10 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 15783 loss=0.826, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=80.8, ups=0.8, wpb=100.8, bsz=40, num_updates=460, lr=7.28771e-06, gnorm=2.6, clip=100, loss_scale=128, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=554
2022-09-28 20:52:21 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 15783 loss=0.79, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=91, ups=0.89, wpb=102, bsz=40, num_updates=470, lr=7.44613e-06, gnorm=2.836, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=566
2022-09-28 20:52:32 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 15783 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=89.3, ups=0.87, wpb=102.5, bsz=40, num_updates=480, lr=7.60456e-06, gnorm=2.712, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=577
2022-09-28 20:52:43 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 15783 loss=0.783, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=90.8, ups=0.9, wpb=101.2, bsz=40, num_updates=490, lr=7.76299e-06, gnorm=3.065, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=588
2022-09-28 20:52:54 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 15783 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=92.7, ups=0.91, wpb=101.5, bsz=40, num_updates=500, lr=7.92142e-06, gnorm=2.974, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=599
2022-09-28 20:53:06 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 15783 loss=0.795, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=86.8, ups=0.86, wpb=100.6, bsz=40, num_updates=510, lr=8.07985e-06, gnorm=3.016, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=611
2022-09-28 20:53:18 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 15783 loss=0.807, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=88.4, ups=0.87, wpb=101.5, bsz=40, num_updates=520, lr=8.23828e-06, gnorm=2.99, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=622
2022-09-28 20:53:28 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 15783 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=93, ups=0.93, wpb=100.1, bsz=40, num_updates=530, lr=8.3967e-06, gnorm=2.858, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=633
2022-09-28 20:53:40 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 15783 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=87.6, ups=0.87, wpb=100.7, bsz=40, num_updates=540, lr=8.55513e-06, gnorm=2.808, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=645
2022-09-28 20:53:51 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 15783 loss=0.736, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.1, ups=0.93, wpb=101.9, bsz=40, num_updates=550, lr=8.71356e-06, gnorm=2.523, clip=100, loss_scale=256, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=655
2022-09-28 20:54:02 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 15783 loss=0.785, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=560, lr=8.87199e-06, gnorm=2.88, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=667
2022-09-28 20:54:13 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 15783 loss=0.748, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=90.1, ups=0.88, wpb=102.2, bsz=40, num_updates=570, lr=9.03042e-06, gnorm=2.521, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=678
2022-09-28 20:54:24 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 15783 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.2, ups=0.89, wpb=102.5, bsz=40, num_updates=580, lr=9.18885e-06, gnorm=2.602, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=689
2022-09-28 20:54:36 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.8, ups=0.89, wpb=103.4, bsz=40, num_updates=590, lr=9.34728e-06, gnorm=2.263, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=701
2022-09-28 20:54:47 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 15783 loss=0.741, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.5, ups=0.88, wpb=102.8, bsz=40, num_updates=600, lr=9.5057e-06, gnorm=3.163, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=712
2022-09-28 20:54:58 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 15783 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.2, ups=0.88, wpb=103.4, bsz=40, num_updates=610, lr=9.66413e-06, gnorm=2.723, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=723
2022-09-28 20:55:10 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88.9, ups=0.87, wpb=102, bsz=40, num_updates=620, lr=9.82256e-06, gnorm=2.181, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=735
2022-09-28 20:55:21 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 15783 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=89.9, ups=0.87, wpb=103.1, bsz=40, num_updates=630, lr=9.98099e-06, gnorm=2.574, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=746
2022-09-28 20:55:33 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.2, ups=0.87, wpb=103.4, bsz=40, num_updates=640, lr=1.01394e-05, gnorm=2.364, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=758
2022-09-28 20:55:44 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 15783 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=88.9, ups=0.88, wpb=100.8, bsz=40, num_updates=650, lr=1.02978e-05, gnorm=2.422, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=769
2022-09-28 20:55:55 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 15783 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=92.5, ups=0.92, wpb=100.7, bsz=40, num_updates=660, lr=1.04563e-05, gnorm=2.462, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=780
2022-09-28 20:56:07 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 15783 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=87.3, ups=0.87, wpb=100.2, bsz=40, num_updates=670, lr=1.06147e-05, gnorm=2.365, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=792
2022-09-28 20:56:18 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 15783 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.7, ups=0.87, wpb=101.5, bsz=40, num_updates=680, lr=1.07731e-05, gnorm=2.563, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=803
2022-09-28 20:56:30 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 15783 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.8, ups=0.88, wpb=101.8, bsz=40, num_updates=690, lr=1.09316e-05, gnorm=2.438, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=814
2022-09-28 20:56:40 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 15783 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.4, ups=0.91, wpb=99.9, bsz=40, num_updates=700, lr=1.109e-05, gnorm=2.608, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=825
2022-09-28 20:56:52 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 15783 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.3, ups=0.87, wpb=102.3, bsz=40, num_updates=710, lr=1.12484e-05, gnorm=2.296, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=837
2022-09-28 20:57:03 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.2, ups=0.92, wpb=102.5, bsz=40, num_updates=720, lr=1.14068e-05, gnorm=2.238, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=848
2022-09-28 20:57:14 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 15783 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=730, lr=1.15653e-05, gnorm=2.404, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=859
2022-09-28 20:57:26 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 15783 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=89.8, ups=0.88, wpb=101.5, bsz=40, num_updates=740, lr=1.17237e-05, gnorm=2.293, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=870
2022-09-28 20:57:37 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92, ups=0.91, wpb=101.2, bsz=40, num_updates=750, lr=1.18821e-05, gnorm=2.189, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=882
2022-09-28 20:57:48 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 15783 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=85.8, ups=0.86, wpb=100.3, bsz=40, num_updates=760, lr=1.20406e-05, gnorm=2.208, clip=100, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=893
2022-09-28 20:58:00 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.1, ups=0.86, wpb=102.3, bsz=40, num_updates=770, lr=1.2199e-05, gnorm=2.232, clip=100, loss_scale=256, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=905
2022-09-28 20:58:11 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 15783 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=90.3, ups=0.89, wpb=102, bsz=40, num_updates=780, lr=1.23574e-05, gnorm=2.256, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=916
2022-09-28 20:58:22 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 15783 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=93.2, ups=0.93, wpb=100.1, bsz=40, num_updates=790, lr=1.25158e-05, gnorm=2.657, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=927
2022-09-28 20:58:33 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 15783 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91, ups=0.92, wpb=98.8, bsz=40, num_updates=800, lr=1.26743e-05, gnorm=2.422, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=938
2022-09-28 20:58:45 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 15783 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.9, ups=0.87, wpb=101.6, bsz=40, num_updates=810, lr=1.28327e-05, gnorm=2.139, clip=100, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=949
2022-09-28 20:58:56 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 15783 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.8, ups=0.87, wpb=101.2, bsz=40, num_updates=820, lr=1.29911e-05, gnorm=2.232, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=961
2022-09-28 20:59:08 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.4, ups=0.87, wpb=101.5, bsz=40, num_updates=830, lr=1.31496e-05, gnorm=2.1, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=972
2022-09-28 20:59:19 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 15783 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=840, lr=1.3308e-05, gnorm=2.221, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=984
2022-09-28 20:59:30 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=850, lr=1.34664e-05, gnorm=1.97, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=995
2022-09-28 20:59:41 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 15783 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.6, ups=0.9, wpb=102, bsz=40, num_updates=860, lr=1.36248e-05, gnorm=2.229, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1006
2022-09-28 20:59:52 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 15783 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=88.9, ups=0.88, wpb=101, bsz=40, num_updates=870, lr=1.37833e-05, gnorm=2.293, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1017
2022-09-28 21:00:04 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 15783 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.9, ups=0.9, wpb=101.6, bsz=40, num_updates=880, lr=1.39417e-05, gnorm=2.274, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1028
2022-09-28 21:00:15 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91.4, ups=0.9, wpb=101.8, bsz=40, num_updates=890, lr=1.41001e-05, gnorm=2.015, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1040
2022-09-28 21:00:27 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=84.3, ups=0.82, wpb=103.1, bsz=40, num_updates=900, lr=1.42586e-05, gnorm=2.089, clip=100, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1052
2022-09-28 21:00:39 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=83.6, ups=0.82, wpb=102.3, bsz=40, num_updates=910, lr=1.4417e-05, gnorm=2.195, clip=100, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1064
2022-09-28 21:00:51 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=81.9, ups=0.81, wpb=101, bsz=40, num_updates=920, lr=1.45754e-05, gnorm=2.039, clip=100, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1076
2022-09-28 21:01:04 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 15783 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=82.2, ups=0.82, wpb=100.4, bsz=40, num_updates=930, lr=1.47338e-05, gnorm=1.936, clip=100, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1089
2022-09-28 21:01:15 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 15783 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=86.9, ups=0.86, wpb=100.6, bsz=40, num_updates=940, lr=1.48923e-05, gnorm=2.183, clip=100, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1100
2022-09-28 21:01:27 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 15783 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=86.9, ups=0.87, wpb=99.3, bsz=40, num_updates=950, lr=1.50507e-05, gnorm=2.026, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1112
2022-09-28 21:01:38 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 15783 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88.1, ups=0.88, wpb=100.3, bsz=40, num_updates=960, lr=1.52091e-05, gnorm=2.232, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1123
2022-09-28 21:01:49 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 15783 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.7, ups=0.91, wpb=99.7, bsz=40, num_updates=970, lr=1.53676e-05, gnorm=2.11, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1134
2022-09-28 21:02:01 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.87, wpb=103.3, bsz=40, num_updates=980, lr=1.5526e-05, gnorm=2.005, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1145
2022-09-28 21:02:12 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.5, ups=0.9, wpb=99.8, bsz=40, num_updates=990, lr=1.56844e-05, gnorm=2.215, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1157
2022-09-28 21:02:23 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.5, ups=0.89, wpb=103.7, bsz=40, num_updates=1000, lr=1.58428e-05, gnorm=1.954, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1168
2022-09-28 21:02:34 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.8, ups=0.88, wpb=102.5, bsz=40, num_updates=1010, lr=1.60013e-05, gnorm=2.32, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1179
2022-09-28 21:02:46 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.1, ups=0.87, wpb=103.2, bsz=40, num_updates=1020, lr=1.61597e-05, gnorm=2.163, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1191
2022-09-28 21:02:57 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.7, ups=0.88, wpb=101.2, bsz=40, num_updates=1030, lr=1.63181e-05, gnorm=1.868, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1202
2022-09-28 21:03:09 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.4, ups=0.86, wpb=101.2, bsz=40, num_updates=1040, lr=1.64766e-05, gnorm=1.965, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1214
2022-09-28 21:03:20 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.5, ups=0.88, wpb=103.4, bsz=40, num_updates=1050, lr=1.6635e-05, gnorm=1.973, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1225
2022-09-28 21:03:31 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 15783 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.5, ups=0.91, wpb=100.2, bsz=40, num_updates=1060, lr=1.67934e-05, gnorm=2.13, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1236
2022-09-28 21:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 15783 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.3, ups=0.88, wpb=98.9, bsz=40, num_updates=1070, lr=1.69518e-05, gnorm=2.113, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1247
2022-09-28 21:03:54 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.7, ups=0.88, wpb=102.7, bsz=40, num_updates=1080, lr=1.71103e-05, gnorm=2.482, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1259
2022-09-28 21:04:05 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=91, ups=0.9, wpb=101.3, bsz=40, num_updates=1090, lr=1.72687e-05, gnorm=1.899, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1270
2022-09-28 21:04:16 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.89, wpb=102.2, bsz=40, num_updates=1100, lr=1.74271e-05, gnorm=1.979, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1281
2022-09-28 21:04:27 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=1110, lr=1.75856e-05, gnorm=2.015, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1292
2022-09-28 21:04:39 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.9, ups=0.87, wpb=100.6, bsz=40, num_updates=1120, lr=1.7744e-05, gnorm=2.094, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1304
2022-09-28 21:04:50 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 15783 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.6, ups=0.88, wpb=99.3, bsz=40, num_updates=1130, lr=1.79024e-05, gnorm=2.152, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1315
2022-09-28 21:05:01 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.1, ups=0.89, wpb=101.8, bsz=40, num_updates=1140, lr=1.80608e-05, gnorm=1.978, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1326
2022-09-28 21:05:13 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.87, wpb=102.3, bsz=40, num_updates=1150, lr=1.82193e-05, gnorm=1.842, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1338
2022-09-28 21:05:25 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=82.7, ups=0.82, wpb=100.8, bsz=40, num_updates=1160, lr=1.83777e-05, gnorm=2.137, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1350
2022-09-28 21:05:35 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-28 21:05:39 - progress_bar.py[line:274] - INFO: epoch 001:   1171 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=74.9, ups=0.74, wpb=101.8, bsz=40, num_updates=1170, lr=1.85361e-05, gnorm=2.108, clip=100, loss_scale=256, train_wall=14, gb_free=10.3, ema_decay=0.9999, wall=1364
2022-09-28 21:05:52 - progress_bar.py[line:274] - INFO: epoch 001:   1181 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=79, ups=0.77, wpb=102.2, bsz=40, num_updates=1180, lr=1.86946e-05, gnorm=2.059, clip=100, loss_scale=256, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=1376
2022-09-28 21:06:03 - progress_bar.py[line:274] - INFO: epoch 001:   1191 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.5, ups=0.86, wpb=101.6, bsz=40, num_updates=1190, lr=1.8853e-05, gnorm=1.825, clip=100, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1388
2022-09-28 21:06:15 - progress_bar.py[line:274] - INFO: epoch 001:   1201 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.1, ups=0.86, wpb=101.2, bsz=40, num_updates=1200, lr=1.90114e-05, gnorm=2.071, clip=100, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1400
2022-09-28 21:06:26 - progress_bar.py[line:274] - INFO: epoch 001:   1211 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.6, ups=0.9, wpb=99.6, bsz=40, num_updates=1210, lr=1.91698e-05, gnorm=2.077, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1411
2022-09-28 21:06:37 - progress_bar.py[line:274] - INFO: epoch 001:   1221 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=1220, lr=1.93283e-05, gnorm=1.964, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1422
2022-09-28 21:06:49 - progress_bar.py[line:274] - INFO: epoch 001:   1231 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.2, ups=0.87, wpb=101, bsz=40, num_updates=1230, lr=1.94867e-05, gnorm=1.956, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1434
2022-09-28 21:07:00 - progress_bar.py[line:274] - INFO: epoch 001:   1241 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.5, ups=0.87, wpb=100, bsz=40, num_updates=1240, lr=1.96451e-05, gnorm=1.99, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1445
2022-09-28 21:07:12 - progress_bar.py[line:274] - INFO: epoch 001:   1251 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=1250, lr=1.98035e-05, gnorm=1.967, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1456
2022-09-28 21:07:23 - progress_bar.py[line:274] - INFO: epoch 001:   1261 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.3, ups=0.88, wpb=102.4, bsz=40, num_updates=1260, lr=1.9962e-05, gnorm=1.916, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1468
2022-09-28 21:07:34 - progress_bar.py[line:274] - INFO: epoch 001:   1271 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.3, ups=0.91, wpb=101.9, bsz=40, num_updates=1270, lr=2.01204e-05, gnorm=2.064, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1479
2022-09-28 21:07:45 - progress_bar.py[line:274] - INFO: epoch 001:   1281 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.87, wpb=102.4, bsz=40, num_updates=1280, lr=2.02788e-05, gnorm=1.746, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1490
2022-09-28 21:07:56 - progress_bar.py[line:274] - INFO: epoch 001:   1291 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92, ups=0.92, wpb=100.5, bsz=40, num_updates=1290, lr=2.04373e-05, gnorm=1.825, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1501
2022-09-28 21:08:08 - progress_bar.py[line:274] - INFO: epoch 001:   1301 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.88, wpb=101, bsz=40, num_updates=1300, lr=2.05957e-05, gnorm=1.983, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1513
2022-09-28 21:08:19 - progress_bar.py[line:274] - INFO: epoch 001:   1311 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.6, ups=0.91, wpb=101.3, bsz=40, num_updates=1310, lr=2.07541e-05, gnorm=1.798, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1524
2022-09-28 21:08:29 - progress_bar.py[line:274] - INFO: epoch 001:   1321 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.9, ups=0.93, wpb=101.4, bsz=40, num_updates=1320, lr=2.09125e-05, gnorm=2.034, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1534
2022-09-28 21:08:40 - progress_bar.py[line:274] - INFO: epoch 001:   1331 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.4, ups=0.91, wpb=100.2, bsz=40, num_updates=1330, lr=2.1071e-05, gnorm=1.999, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1545
2022-09-28 21:08:52 - progress_bar.py[line:274] - INFO: epoch 001:   1341 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=1340, lr=2.12294e-05, gnorm=1.917, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1557
2022-09-28 21:09:04 - progress_bar.py[line:274] - INFO: epoch 001:   1351 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=78.6, ups=0.78, wpb=100.5, bsz=40, num_updates=1350, lr=2.13878e-05, gnorm=1.813, clip=100, loss_scale=256, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=1569
2022-09-28 21:09:17 - progress_bar.py[line:274] - INFO: epoch 001:   1361 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=78.2, ups=0.77, wpb=101.9, bsz=40, num_updates=1360, lr=2.15463e-05, gnorm=1.701, clip=100, loss_scale=256, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=1582
2022-09-28 21:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   1371 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=80.5, ups=0.8, wpb=100.1, bsz=40, num_updates=1370, lr=2.17047e-05, gnorm=1.952, clip=100, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=1595
2022-09-28 21:09:42 - progress_bar.py[line:274] - INFO: epoch 001:   1381 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.1, ups=0.84, wpb=102, bsz=40, num_updates=1380, lr=2.18631e-05, gnorm=1.846, clip=100, loss_scale=256, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=1607
2022-09-28 21:09:53 - progress_bar.py[line:274] - INFO: epoch 001:   1391 / 15783 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.6, ups=0.87, wpb=101.4, bsz=40, num_updates=1390, lr=2.20215e-05, gnorm=1.752, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1618
2022-09-28 21:10:05 - progress_bar.py[line:274] - INFO: epoch 001:   1401 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=83.7, ups=0.82, wpb=102.1, bsz=40, num_updates=1400, lr=2.218e-05, gnorm=1.708, clip=100, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1630
2022-09-28 21:10:17 - progress_bar.py[line:274] - INFO: epoch 001:   1411 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.9, ups=0.9, wpb=103.3, bsz=40, num_updates=1410, lr=2.23384e-05, gnorm=1.729, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1641
2022-09-28 21:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   1421 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.89, wpb=100.9, bsz=40, num_updates=1420, lr=2.24968e-05, gnorm=1.872, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=1653
2022-09-28 21:10:39 - progress_bar.py[line:274] - INFO: epoch 001:   1431 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.87, wpb=103.6, bsz=40, num_updates=1430, lr=2.26553e-05, gnorm=1.735, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=1664
2022-09-28 21:10:51 - progress_bar.py[line:274] - INFO: epoch 001:   1441 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=1440, lr=2.28137e-05, gnorm=2.005, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1675
2022-09-28 21:11:02 - progress_bar.py[line:274] - INFO: epoch 001:   1451 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.7, ups=0.88, wpb=101.3, bsz=40, num_updates=1450, lr=2.29721e-05, gnorm=1.836, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1687
2022-09-28 21:11:14 - progress_bar.py[line:274] - INFO: epoch 001:   1461 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.6, ups=0.87, wpb=100.9, bsz=40, num_updates=1460, lr=2.31305e-05, gnorm=2.055, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1698
2022-09-28 21:11:26 - progress_bar.py[line:274] - INFO: epoch 001:   1471 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=84.7, ups=0.83, wpb=101.9, bsz=40, num_updates=1470, lr=2.3289e-05, gnorm=1.804, clip=100, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1710
2022-09-28 21:11:38 - progress_bar.py[line:274] - INFO: epoch 001:   1481 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=83.2, ups=0.82, wpb=101.2, bsz=40, num_updates=1480, lr=2.34474e-05, gnorm=1.866, clip=100, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1723
2022-09-28 21:11:49 - progress_bar.py[line:274] - INFO: epoch 001:   1491 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.4, ups=0.91, wpb=102.4, bsz=40, num_updates=1490, lr=2.36058e-05, gnorm=1.668, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1734
2022-09-28 21:12:00 - progress_bar.py[line:274] - INFO: epoch 001:   1501 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.89, wpb=101.9, bsz=40, num_updates=1500, lr=2.37643e-05, gnorm=1.927, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1745
2022-09-28 21:12:11 - progress_bar.py[line:274] - INFO: epoch 001:   1511 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.8, ups=0.9, wpb=101.1, bsz=40, num_updates=1510, lr=2.39227e-05, gnorm=1.739, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1756
2022-09-28 21:12:23 - progress_bar.py[line:274] - INFO: epoch 001:   1521 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.4, ups=0.87, wpb=101.1, bsz=40, num_updates=1520, lr=2.40811e-05, gnorm=1.825, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1767
2022-09-28 21:12:34 - progress_bar.py[line:274] - INFO: epoch 001:   1531 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.9, ups=0.88, wpb=100.5, bsz=40, num_updates=1530, lr=2.42395e-05, gnorm=1.649, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1779
2022-09-28 21:12:45 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.4, ups=0.91, wpb=101.6, bsz=40, num_updates=1540, lr=2.4398e-05, gnorm=1.719, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1790
2022-09-28 21:12:56 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92, ups=0.92, wpb=99.5, bsz=40, num_updates=1550, lr=2.45564e-05, gnorm=1.905, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1801
2022-09-28 21:13:07 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.86, wpb=102.6, bsz=40, num_updates=1560, lr=2.47148e-05, gnorm=1.509, clip=100, loss_scale=256, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=1812
2022-09-28 21:13:19 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=1570, lr=2.48733e-05, gnorm=1.696, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1824
2022-09-28 21:13:30 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.5, ups=0.9, wpb=99.7, bsz=40, num_updates=1580, lr=2.50317e-05, gnorm=1.844, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1835
2022-09-28 21:13:42 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=83.5, ups=0.82, wpb=102.3, bsz=40, num_updates=1590, lr=2.51901e-05, gnorm=1.887, clip=100, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1847
2022-09-28 21:13:54 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 15783 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=81.7, ups=0.81, wpb=100.8, bsz=40, num_updates=1600, lr=2.53485e-05, gnorm=1.85, clip=100, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1859
2022-09-28 21:14:06 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.4, ups=0.85, wpb=101.3, bsz=40, num_updates=1610, lr=2.5507e-05, gnorm=1.672, clip=100, loss_scale=256, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=1871
2022-09-28 21:14:17 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=1620, lr=2.56654e-05, gnorm=1.792, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1882
2022-09-28 21:14:29 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.3, ups=0.86, wpb=102.6, bsz=40, num_updates=1630, lr=2.58238e-05, gnorm=1.894, clip=100, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1894
2022-09-28 21:14:42 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=79, ups=0.75, wpb=104.7, bsz=40, num_updates=1640, lr=2.59823e-05, gnorm=1.463, clip=100, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1907
2022-09-28 21:14:57 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=67, ups=0.67, wpb=100.6, bsz=40, num_updates=1650, lr=2.61407e-05, gnorm=1.744, clip=90, loss_scale=256, train_wall=15, gb_free=10.9, ema_decay=0.9999, wall=1922
2022-09-28 21:15:09 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.88, wpb=101.1, bsz=40, num_updates=1660, lr=2.62991e-05, gnorm=1.905, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=1934
2022-09-28 21:15:20 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.2, ups=0.9, wpb=101.5, bsz=40, num_updates=1670, lr=2.64575e-05, gnorm=1.743, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1945
2022-09-28 21:15:31 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.4, ups=0.9, wpb=100.5, bsz=40, num_updates=1680, lr=2.6616e-05, gnorm=1.943, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1956
2022-09-28 21:15:39 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-09-28 21:15:43 - progress_bar.py[line:274] - INFO: epoch 001:   1692 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=81.7, ups=0.8, wpb=101.6, bsz=40, num_updates=1690, lr=2.67744e-05, gnorm=2.012, clip=100, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1968
2022-09-28 21:15:54 - progress_bar.py[line:274] - INFO: epoch 001:   1702 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.9, wpb=100.4, bsz=40, num_updates=1700, lr=2.69328e-05, gnorm=1.708, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=1979
2022-09-28 21:16:05 - progress_bar.py[line:274] - INFO: epoch 001:   1712 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93, ups=0.91, wpb=101.7, bsz=40, num_updates=1710, lr=2.70913e-05, gnorm=1.721, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1990
2022-09-28 21:16:17 - progress_bar.py[line:274] - INFO: epoch 001:   1722 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.1, ups=0.9, wpb=101.4, bsz=40, num_updates=1720, lr=2.72497e-05, gnorm=1.784, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2001
2022-09-28 21:16:28 - progress_bar.py[line:274] - INFO: epoch 001:   1732 / 15783 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=1730, lr=2.74081e-05, gnorm=1.858, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2013
2022-09-28 21:16:39 - progress_bar.py[line:274] - INFO: epoch 001:   1742 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=1740, lr=2.75665e-05, gnorm=1.572, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2024
2022-09-28 21:16:51 - progress_bar.py[line:274] - INFO: epoch 001:   1752 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.2, ups=0.89, wpb=100.5, bsz=40, num_updates=1750, lr=2.7725e-05, gnorm=1.537, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2035
2022-09-28 21:17:02 - progress_bar.py[line:274] - INFO: epoch 001:   1762 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.1, ups=0.87, wpb=100.5, bsz=40, num_updates=1760, lr=2.78834e-05, gnorm=1.613, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2047
2022-09-28 21:17:13 - progress_bar.py[line:274] - INFO: epoch 001:   1772 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.88, wpb=102.3, bsz=40, num_updates=1770, lr=2.80418e-05, gnorm=1.624, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2058
2022-09-28 21:17:25 - progress_bar.py[line:274] - INFO: epoch 001:   1782 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.7, ups=0.89, wpb=100.9, bsz=40, num_updates=1780, lr=2.82003e-05, gnorm=1.572, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2070
2022-09-28 21:17:36 - progress_bar.py[line:274] - INFO: epoch 001:   1792 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.4, ups=0.89, wpb=104.4, bsz=40, num_updates=1790, lr=2.83587e-05, gnorm=1.409, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2081
2022-09-28 21:17:47 - progress_bar.py[line:274] - INFO: epoch 001:   1802 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.6, ups=0.91, wpb=102.8, bsz=40, num_updates=1800, lr=2.85171e-05, gnorm=1.708, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2092
2022-09-28 21:17:58 - progress_bar.py[line:274] - INFO: epoch 001:   1812 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.9, ups=0.89, wpb=101.4, bsz=40, num_updates=1810, lr=2.86755e-05, gnorm=1.588, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2103
2022-09-28 21:18:10 - progress_bar.py[line:274] - INFO: epoch 001:   1822 / 15783 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.2, ups=0.89, wpb=99.2, bsz=40, num_updates=1820, lr=2.8834e-05, gnorm=1.735, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2114
2022-09-28 21:18:21 - progress_bar.py[line:274] - INFO: epoch 001:   1832 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=85.5, ups=0.85, wpb=100.7, bsz=40, num_updates=1830, lr=2.89924e-05, gnorm=1.474, clip=100, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2126
2022-09-28 21:18:33 - progress_bar.py[line:274] - INFO: epoch 001:   1842 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.5, ups=0.85, wpb=101.5, bsz=40, num_updates=1840, lr=2.91508e-05, gnorm=1.295, clip=90, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=2138
2022-09-28 21:18:45 - progress_bar.py[line:274] - INFO: epoch 001:   1852 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.4, ups=0.86, wpb=102.8, bsz=40, num_updates=1850, lr=2.93093e-05, gnorm=1.67, clip=100, loss_scale=256, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=2150
2022-09-28 21:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   1862 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.88, wpb=101.9, bsz=40, num_updates=1860, lr=2.94677e-05, gnorm=1.721, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=2161
2022-09-28 21:19:07 - progress_bar.py[line:274] - INFO: epoch 001:   1872 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.2, ups=0.88, wpb=100.8, bsz=40, num_updates=1870, lr=2.96261e-05, gnorm=1.555, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2172
2022-09-28 21:19:20 - progress_bar.py[line:274] - INFO: epoch 001:   1882 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.87, wpb=102.6, bsz=40, num_updates=1880, lr=2.97845e-05, gnorm=1.52, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2184
2022-09-28 21:19:31 - progress_bar.py[line:274] - INFO: epoch 001:   1892 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.4, ups=0.9, wpb=100.2, bsz=40, num_updates=1890, lr=2.9943e-05, gnorm=1.691, clip=100, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2196
2022-09-28 21:19:42 - progress_bar.py[line:274] - INFO: epoch 001:   1902 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=101.8, bsz=40, num_updates=1900, lr=3.01014e-05, gnorm=1.504, clip=100, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=2207
2022-09-28 21:19:53 - progress_bar.py[line:274] - INFO: epoch 001:   1912 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.92, wpb=101, bsz=40, num_updates=1910, lr=3.02598e-05, gnorm=1.611, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2218
2022-09-28 21:20:04 - progress_bar.py[line:274] - INFO: epoch 001:   1922 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.89, wpb=101.7, bsz=40, num_updates=1920, lr=3.04183e-05, gnorm=1.496, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2229
2022-09-28 21:20:15 - progress_bar.py[line:274] - INFO: epoch 001:   1932 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.2, ups=0.89, wpb=103.5, bsz=40, num_updates=1930, lr=3.05767e-05, gnorm=1.68, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2240
2022-09-28 21:20:27 - progress_bar.py[line:274] - INFO: epoch 001:   1942 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.5, ups=0.9, wpb=101.1, bsz=40, num_updates=1940, lr=3.07351e-05, gnorm=1.656, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2251
2022-09-28 21:20:38 - progress_bar.py[line:274] - INFO: epoch 001:   1952 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.5, ups=0.9, wpb=101.7, bsz=40, num_updates=1950, lr=3.08935e-05, gnorm=1.5, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2262
2022-09-28 21:20:50 - progress_bar.py[line:274] - INFO: epoch 001:   1962 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=84.1, ups=0.84, wpb=100.3, bsz=40, num_updates=1960, lr=3.1052e-05, gnorm=1.574, clip=90, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=2274
2022-09-28 21:21:03 - progress_bar.py[line:274] - INFO: epoch 001:   1972 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=77.6, ups=0.75, wpb=103, bsz=40, num_updates=1970, lr=3.12104e-05, gnorm=1.505, clip=100, loss_scale=256, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=2288
2022-09-28 21:21:16 - progress_bar.py[line:274] - INFO: epoch 001:   1982 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=76.6, ups=0.76, wpb=100.4, bsz=40, num_updates=1980, lr=3.13688e-05, gnorm=1.486, clip=100, loss_scale=256, train_wall=13, gb_free=10.1, ema_decay=0.9999, wall=2301
2022-09-28 21:21:29 - progress_bar.py[line:274] - INFO: epoch 001:   1992 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=79.6, ups=0.79, wpb=100.3, bsz=40, num_updates=1990, lr=3.15272e-05, gnorm=1.402, clip=100, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=2313
2022-09-28 21:21:40 - progress_bar.py[line:274] - INFO: epoch 001:   2002 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=84.9, ups=0.84, wpb=100.5, bsz=40, num_updates=2000, lr=3.16857e-05, gnorm=1.436, clip=100, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2325
2022-09-28 21:21:52 - progress_bar.py[line:274] - INFO: epoch 001:   2012 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.87, wpb=102.6, bsz=40, num_updates=2010, lr=3.18441e-05, gnorm=1.378, clip=90, loss_scale=256, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=2337
2022-09-28 21:22:03 - progress_bar.py[line:274] - INFO: epoch 001:   2022 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.2, ups=0.91, wpb=102.3, bsz=40, num_updates=2020, lr=3.20025e-05, gnorm=1.486, clip=90, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2348
2022-09-28 21:22:14 - progress_bar.py[line:274] - INFO: epoch 001:   2032 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.3, ups=0.91, wpb=103.8, bsz=40, num_updates=2030, lr=3.2161e-05, gnorm=1.565, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2359
2022-09-28 21:22:25 - progress_bar.py[line:274] - INFO: epoch 001:   2042 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.4, ups=0.87, wpb=101, bsz=40, num_updates=2040, lr=3.23194e-05, gnorm=1.494, clip=100, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=2370
2022-09-28 21:22:37 - progress_bar.py[line:274] - INFO: epoch 001:   2052 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.1, ups=0.9, wpb=102.5, bsz=40, num_updates=2050, lr=3.24778e-05, gnorm=1.252, clip=90, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2381
2022-09-28 21:22:48 - progress_bar.py[line:274] - INFO: epoch 001:   2062 / 15783 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=91.2, ups=0.91, wpb=99.8, bsz=40, num_updates=2060, lr=3.26362e-05, gnorm=1.643, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2392
2022-09-28 21:22:59 - progress_bar.py[line:274] - INFO: epoch 001:   2072 / 15783 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.5, ups=0.89, wpb=102.1, bsz=40, num_updates=2070, lr=3.27947e-05, gnorm=1.553, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2404
2022-09-28 21:23:10 - progress_bar.py[line:274] - INFO: epoch 001:   2082 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.88, wpb=101.9, bsz=40, num_updates=2080, lr=3.29531e-05, gnorm=1.574, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2415
2022-09-28 21:23:22 - progress_bar.py[line:274] - INFO: epoch 001:   2092 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=83.9, ups=0.83, wpb=100.5, bsz=40, num_updates=2090, lr=3.31115e-05, gnorm=1.549, clip=90, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2427
2022-09-28 21:23:33 - progress_bar.py[line:274] - INFO: epoch 001:   2102 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.6, ups=0.91, wpb=101.7, bsz=40, num_updates=2100, lr=3.327e-05, gnorm=1.495, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2438
2022-09-28 21:23:44 - progress_bar.py[line:274] - INFO: epoch 001:   2112 / 15783 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.4, ups=0.89, wpb=101.1, bsz=40, num_updates=2110, lr=3.34284e-05, gnorm=1.718, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2449
2022-09-28 21:23:56 - progress_bar.py[line:274] - INFO: epoch 001:   2122 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.87, wpb=101.6, bsz=40, num_updates=2120, lr=3.35868e-05, gnorm=1.385, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2461
2022-09-28 21:24:08 - progress_bar.py[line:274] - INFO: epoch 001:   2132 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.8, ups=0.86, wpb=102.3, bsz=40, num_updates=2130, lr=3.37452e-05, gnorm=1.406, clip=100, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=2472
2022-09-28 21:24:20 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=81.7, ups=0.81, wpb=101.3, bsz=40, num_updates=2140, lr=3.39037e-05, gnorm=1.412, clip=80, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=2485
2022-09-28 21:24:32 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=82.6, ups=0.81, wpb=101.7, bsz=40, num_updates=2150, lr=3.40621e-05, gnorm=1.436, clip=100, loss_scale=256, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=2497
2022-09-28 21:24:43 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.7, ups=0.9, wpb=100.9, bsz=40, num_updates=2160, lr=3.42205e-05, gnorm=1.768, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2508
2022-09-28 21:24:55 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.6, ups=0.89, wpb=103.3, bsz=40, num_updates=2170, lr=3.4379e-05, gnorm=1.595, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2520
2022-09-28 21:25:06 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.9, ups=0.88, wpb=102.8, bsz=40, num_updates=2180, lr=3.45374e-05, gnorm=1.378, clip=90, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2531
2022-09-28 21:25:17 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.1, ups=0.93, wpb=101.7, bsz=40, num_updates=2190, lr=3.46958e-05, gnorm=1.489, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=2542
2022-09-28 21:25:28 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.9, ups=0.92, wpb=101.5, bsz=40, num_updates=2200, lr=3.48542e-05, gnorm=1.451, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2553
2022-09-28 21:25:39 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.9, ups=0.87, wpb=100.5, bsz=40, num_updates=2210, lr=3.50127e-05, gnorm=1.604, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2564
2022-09-28 21:25:51 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.2, ups=0.88, wpb=100.8, bsz=40, num_updates=2220, lr=3.51711e-05, gnorm=1.674, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2575
2022-09-28 21:26:02 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92, ups=0.91, wpb=101.2, bsz=40, num_updates=2230, lr=3.53295e-05, gnorm=1.523, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2586
2022-09-28 21:26:13 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91, ups=0.89, wpb=102.7, bsz=40, num_updates=2240, lr=3.5488e-05, gnorm=1.478, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2598
2022-09-28 21:26:24 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.7, ups=0.89, wpb=100.1, bsz=40, num_updates=2250, lr=3.56464e-05, gnorm=1.535, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2609
2022-09-28 21:26:35 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.6, ups=0.9, wpb=102.6, bsz=40, num_updates=2260, lr=3.58048e-05, gnorm=1.377, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2620
2022-09-28 21:26:46 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.2, ups=0.91, wpb=100.5, bsz=40, num_updates=2270, lr=3.59632e-05, gnorm=1.455, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2631
2022-09-28 21:26:58 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.9, ups=0.89, wpb=101.3, bsz=40, num_updates=2280, lr=3.61217e-05, gnorm=1.394, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2642
2022-09-28 21:27:09 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.4, ups=0.89, wpb=99.8, bsz=40, num_updates=2290, lr=3.62801e-05, gnorm=1.546, clip=90, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=2654
2022-09-28 21:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 15783 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.3, ups=0.89, wpb=99.6, bsz=40, num_updates=2300, lr=3.64385e-05, gnorm=1.53, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2665
2022-09-28 21:27:31 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.89, wpb=102.5, bsz=40, num_updates=2310, lr=3.6597e-05, gnorm=1.354, clip=90, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=2676
2022-09-28 21:27:43 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.88, wpb=102.8, bsz=40, num_updates=2320, lr=3.67554e-05, gnorm=1.332, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2688
2022-09-28 21:27:54 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.9, wpb=100.1, bsz=40, num_updates=2330, lr=3.69138e-05, gnorm=1.538, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2699
2022-09-28 21:28:05 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.9, wpb=102, bsz=40, num_updates=2340, lr=3.70722e-05, gnorm=1.408, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2710
2022-09-28 21:28:16 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=2350, lr=3.72307e-05, gnorm=1.383, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2721
2022-09-28 21:28:28 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=2360, lr=3.73891e-05, gnorm=1.281, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2733
2022-09-28 21:28:39 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=86.9, ups=0.88, wpb=99.3, bsz=40, num_updates=2370, lr=3.75475e-05, gnorm=1.413, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2744
2022-09-28 21:28:51 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.87, wpb=102.7, bsz=40, num_updates=2380, lr=3.7706e-05, gnorm=1.416, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2756
2022-09-28 21:29:02 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.5, ups=0.88, wpb=100.8, bsz=40, num_updates=2390, lr=3.78644e-05, gnorm=1.288, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2767
2022-09-28 21:29:14 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89, ups=0.87, wpb=102.4, bsz=40, num_updates=2400, lr=3.80228e-05, gnorm=1.374, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2779
2022-09-28 21:29:25 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.2, ups=0.9, wpb=100.5, bsz=40, num_updates=2410, lr=3.81812e-05, gnorm=1.381, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=2790
2022-09-28 21:29:36 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.91, wpb=101.7, bsz=40, num_updates=2420, lr=3.83397e-05, gnorm=1.472, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2801
2022-09-28 21:29:47 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.5, ups=0.93, wpb=100.5, bsz=40, num_updates=2430, lr=3.84981e-05, gnorm=1.561, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2811
2022-09-28 21:29:58 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=84.4, ups=0.84, wpb=100.3, bsz=40, num_updates=2440, lr=3.86565e-05, gnorm=1.349, clip=100, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=2823
2022-09-28 21:30:10 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.2, ups=0.84, wpb=102.1, bsz=40, num_updates=2450, lr=3.8815e-05, gnorm=1.318, clip=90, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=2835
2022-09-28 21:30:23 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=82.7, ups=0.82, wpb=101.5, bsz=40, num_updates=2460, lr=3.89734e-05, gnorm=1.366, clip=90, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=2847
2022-09-28 21:30:35 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=81.8, ups=0.8, wpb=102.3, bsz=40, num_updates=2470, lr=3.91318e-05, gnorm=1.394, clip=100, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=2860
2022-09-28 21:30:46 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=2480, lr=3.92902e-05, gnorm=1.536, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=2871
2022-09-28 21:30:58 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=101.2, bsz=40, num_updates=2490, lr=3.94487e-05, gnorm=1.416, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2883
2022-09-28 21:31:09 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=2500, lr=3.96071e-05, gnorm=1.282, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2894
2022-09-28 21:31:20 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.89, wpb=103.1, bsz=40, num_updates=2510, lr=3.97655e-05, gnorm=1.243, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2905
2022-09-28 21:31:31 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.9, wpb=100.1, bsz=40, num_updates=2520, lr=3.9924e-05, gnorm=1.495, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2916
2022-09-28 21:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.5, ups=0.89, wpb=98.8, bsz=40, num_updates=2530, lr=4.00824e-05, gnorm=1.387, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=2927
2022-09-28 21:31:54 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.9, wpb=100.8, bsz=40, num_updates=2540, lr=4.02408e-05, gnorm=1.297, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=2939
2022-09-28 21:32:05 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90, ups=0.9, wpb=100.4, bsz=40, num_updates=2550, lr=4.03992e-05, gnorm=1.46, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2950
2022-09-28 21:32:16 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.2, ups=0.9, wpb=99.3, bsz=40, num_updates=2560, lr=4.05577e-05, gnorm=1.25, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=2961
2022-09-28 21:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 15783 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=86.1, ups=0.87, wpb=99.4, bsz=40, num_updates=2570, lr=4.07161e-05, gnorm=1.501, clip=90, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=2972
2022-09-28 21:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.6, ups=0.9, wpb=102.1, bsz=40, num_updates=2580, lr=4.08745e-05, gnorm=1.095, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=2984
2022-09-28 21:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=88.3, ups=0.88, wpb=99.9, bsz=40, num_updates=2590, lr=4.1033e-05, gnorm=1.332, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=2995
2022-09-28 21:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.5, ups=0.89, wpb=99.6, bsz=40, num_updates=2600, lr=4.11914e-05, gnorm=1.468, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3006
2022-09-28 21:33:13 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.9, ups=0.88, wpb=101.4, bsz=40, num_updates=2610, lr=4.13498e-05, gnorm=1.326, clip=90, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3018
2022-09-28 21:33:25 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.5, ups=0.91, wpb=101.7, bsz=40, num_updates=2620, lr=4.15082e-05, gnorm=1.273, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3029
2022-09-28 21:33:36 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.3, ups=0.91, wpb=102.4, bsz=40, num_updates=2630, lr=4.16667e-05, gnorm=1.358, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3041
2022-09-28 21:33:47 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.9, ups=0.91, wpb=102.7, bsz=40, num_updates=2640, lr=4.18251e-05, gnorm=1.182, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3052
2022-09-28 21:33:58 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.7, ups=0.9, wpb=102.4, bsz=40, num_updates=2650, lr=4.19835e-05, gnorm=1.239, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3063
2022-09-28 21:34:09 - progress_bar.py[line:274] - INFO: epoch 001:   2662 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=2660, lr=4.2142e-05, gnorm=1.312, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3074
2022-09-28 21:34:20 - progress_bar.py[line:274] - INFO: epoch 001:   2672 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.7, ups=0.9, wpb=101.8, bsz=40, num_updates=2670, lr=4.23004e-05, gnorm=1.252, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3085
2022-09-28 21:34:32 - progress_bar.py[line:274] - INFO: epoch 001:   2682 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.88, wpb=102, bsz=40, num_updates=2680, lr=4.24588e-05, gnorm=1.24, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3097
2022-09-28 21:34:43 - progress_bar.py[line:274] - INFO: epoch 001:   2692 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.9, ups=0.89, wpb=100.7, bsz=40, num_updates=2690, lr=4.26172e-05, gnorm=1.376, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3108
2022-09-28 21:34:54 - progress_bar.py[line:274] - INFO: epoch 001:   2702 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.3, ups=0.88, wpb=100.8, bsz=40, num_updates=2700, lr=4.27757e-05, gnorm=1.241, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3119
2022-09-28 21:35:06 - progress_bar.py[line:274] - INFO: epoch 001:   2712 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=2710, lr=4.29341e-05, gnorm=1.242, clip=80, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3130
2022-09-28 21:35:17 - progress_bar.py[line:274] - INFO: epoch 001:   2722 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.7, ups=0.89, wpb=100.1, bsz=40, num_updates=2720, lr=4.30925e-05, gnorm=1.419, clip=90, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=3142
2022-09-28 21:35:27 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 21:35:29 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=83.4, ups=0.82, wpb=102.2, bsz=40, num_updates=2730, lr=4.3251e-05, gnorm=1.363, clip=100, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=3154
2022-09-28 21:35:40 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.3, ups=0.89, wpb=103.1, bsz=40, num_updates=2740, lr=4.34094e-05, gnorm=1.08, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3165
2022-09-28 21:35:51 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.5, ups=0.94, wpb=99.9, bsz=40, num_updates=2750, lr=4.35678e-05, gnorm=1.364, clip=100, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3176
2022-09-28 21:36:02 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.5, ups=0.89, wpb=102.3, bsz=40, num_updates=2760, lr=4.37262e-05, gnorm=1.308, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3187
2022-09-28 21:36:13 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.92, wpb=100.4, bsz=40, num_updates=2770, lr=4.38847e-05, gnorm=1.228, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3198
2022-09-28 21:36:25 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=2780, lr=4.40431e-05, gnorm=0.991, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3209
2022-09-28 21:36:36 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=2790, lr=4.42015e-05, gnorm=1.264, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3221
2022-09-28 21:36:47 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 15783 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=90.5, ups=0.89, wpb=101.6, bsz=40, num_updates=2800, lr=4.43599e-05, gnorm=1.742, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3232
2022-09-28 21:36:58 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=2810, lr=4.45184e-05, gnorm=1.199, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3243
2022-09-28 21:37:09 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.9, wpb=100.5, bsz=40, num_updates=2820, lr=4.46768e-05, gnorm=1.144, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3254
2022-09-28 21:37:20 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.6, ups=0.93, wpb=102.3, bsz=40, num_updates=2830, lr=4.48352e-05, gnorm=1.086, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=3265
2022-09-28 21:37:32 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.1, ups=0.86, wpb=101.9, bsz=40, num_updates=2840, lr=4.49937e-05, gnorm=1.067, clip=70, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=3276
2022-09-28 21:37:43 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.89, wpb=102.7, bsz=40, num_updates=2850, lr=4.51521e-05, gnorm=1.162, clip=80, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=3288
2022-09-28 21:37:54 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.8, ups=0.88, wpb=100.4, bsz=40, num_updates=2860, lr=4.53105e-05, gnorm=1.686, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3299
2022-09-28 21:38:06 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=2870, lr=4.54689e-05, gnorm=1.327, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3310
2022-09-28 21:38:17 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.8, ups=0.88, wpb=101, bsz=40, num_updates=2880, lr=4.56274e-05, gnorm=1.438, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3322
2022-09-28 21:38:28 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=2890, lr=4.57858e-05, gnorm=1.176, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3333
2022-09-28 21:38:39 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.6, ups=0.91, wpb=101.3, bsz=40, num_updates=2900, lr=4.59442e-05, gnorm=1.21, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3344
2022-09-28 21:38:50 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.91, wpb=100.2, bsz=40, num_updates=2910, lr=4.61027e-05, gnorm=1.219, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3355
2022-09-28 21:39:01 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.7, ups=0.91, wpb=101.3, bsz=40, num_updates=2920, lr=4.62611e-05, gnorm=1.133, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3366
2022-09-28 21:39:12 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.8, ups=0.88, wpb=101.3, bsz=40, num_updates=2930, lr=4.64195e-05, gnorm=1.254, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3377
2022-09-28 21:39:24 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.9, ups=0.88, wpb=100.9, bsz=40, num_updates=2940, lr=4.65779e-05, gnorm=1.285, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3389
2022-09-28 21:39:37 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=78.8, ups=0.78, wpb=101.3, bsz=40, num_updates=2950, lr=4.67364e-05, gnorm=1.21, clip=90, loss_scale=512, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=3402
2022-09-28 21:39:49 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=84.4, ups=0.82, wpb=102.3, bsz=40, num_updates=2960, lr=4.68948e-05, gnorm=1.106, clip=70, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=3414
2022-09-28 21:40:00 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.6, ups=0.88, wpb=100.2, bsz=40, num_updates=2970, lr=4.70532e-05, gnorm=1.322, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3425
2022-09-28 21:40:12 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=2980, lr=4.72117e-05, gnorm=1.346, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3436
2022-09-28 21:40:23 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.4, ups=0.89, wpb=100.5, bsz=40, num_updates=2990, lr=4.73701e-05, gnorm=1.462, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3448
2022-09-28 21:40:34 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 15783 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.5, ups=0.89, wpb=100.6, bsz=40, num_updates=3000, lr=4.75285e-05, gnorm=1.231, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3459
2022-09-28 21:40:45 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.5, ups=0.88, wpb=100.7, bsz=40, num_updates=3010, lr=4.76869e-05, gnorm=1.205, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3470
2022-09-28 21:40:56 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.1, ups=0.9, wpb=99.6, bsz=40, num_updates=3020, lr=4.78454e-05, gnorm=1.501, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3481
2022-09-28 21:41:08 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.7, ups=0.9, wpb=102.6, bsz=40, num_updates=3030, lr=4.80038e-05, gnorm=1.125, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3492
2022-09-28 21:41:19 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.9, ups=0.91, wpb=101.4, bsz=40, num_updates=3040, lr=4.81622e-05, gnorm=1.143, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3503
2022-09-28 21:41:30 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.89, wpb=102.3, bsz=40, num_updates=3050, lr=4.83207e-05, gnorm=1.133, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3515
2022-09-28 21:41:41 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 15783 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91.6, ups=0.91, wpb=100.5, bsz=40, num_updates=3060, lr=4.84791e-05, gnorm=1.399, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3526
2022-09-28 21:41:52 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 15783 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.6, ups=0.93, wpb=101, bsz=40, num_updates=3070, lr=4.86375e-05, gnorm=1.271, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=3536
2022-09-28 21:42:03 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.8, ups=0.88, wpb=100, bsz=40, num_updates=3080, lr=4.87959e-05, gnorm=1.319, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3548
2022-09-28 21:42:14 - progress_bar.py[line:274] - INFO: epoch 001:   3093 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.4, ups=0.87, wpb=102.3, bsz=40, num_updates=3090, lr=4.89544e-05, gnorm=1.284, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3559
2022-09-28 21:42:25 - progress_bar.py[line:274] - INFO: epoch 001:   3103 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.2, ups=0.91, wpb=101.2, bsz=40, num_updates=3100, lr=4.91128e-05, gnorm=1.109, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3570
2022-09-28 21:42:36 - progress_bar.py[line:274] - INFO: epoch 001:   3113 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.91, wpb=100.8, bsz=40, num_updates=3110, lr=4.92712e-05, gnorm=1.137, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3581
2022-09-28 21:42:48 - progress_bar.py[line:274] - INFO: epoch 001:   3123 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.3, ups=0.89, wpb=99.9, bsz=40, num_updates=3120, lr=4.94297e-05, gnorm=1.398, clip=90, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=3592
2022-09-28 21:42:59 - progress_bar.py[line:274] - INFO: epoch 001:   3133 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91, ups=0.9, wpb=101.6, bsz=40, num_updates=3130, lr=4.95881e-05, gnorm=1.148, clip=70, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=3604
2022-09-28 21:43:10 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.7, ups=0.89, wpb=102, bsz=40, num_updates=3140, lr=4.97465e-05, gnorm=1.15, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3615
2022-09-28 21:43:22 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=84.7, ups=0.83, wpb=102.7, bsz=40, num_updates=3150, lr=4.99049e-05, gnorm=1.323, clip=80, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=3627
2022-09-28 21:43:34 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=81.5, ups=0.81, wpb=100.4, bsz=40, num_updates=3160, lr=4.99974e-05, gnorm=1.113, clip=60, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=3639
2022-09-28 21:43:46 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=85.5, ups=0.83, wpb=102.6, bsz=40, num_updates=3170, lr=4.99908e-05, gnorm=1.11, clip=70, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=3651
2022-09-28 21:43:58 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.9, wpb=102, bsz=40, num_updates=3180, lr=4.99842e-05, gnorm=1.253, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3662
2022-09-28 21:44:09 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.2, ups=0.89, wpb=100.5, bsz=40, num_updates=3190, lr=4.99776e-05, gnorm=1.304, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3674
2022-09-28 21:44:20 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=3200, lr=4.9971e-05, gnorm=1.188, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3685
2022-09-28 21:44:32 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.8, ups=0.88, wpb=100.1, bsz=40, num_updates=3210, lr=4.99644e-05, gnorm=1.278, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3696
2022-09-28 21:44:43 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 15783 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=3220, lr=4.99578e-05, gnorm=1.131, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3708
2022-09-28 21:44:54 - progress_bar.py[line:274] - INFO: epoch 001:   3233 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.7, ups=0.87, wpb=100, bsz=40, num_updates=3230, lr=4.99512e-05, gnorm=1.125, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3719
2022-09-28 21:45:06 - progress_bar.py[line:274] - INFO: epoch 001:   3243 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.3, ups=0.87, wpb=100.8, bsz=40, num_updates=3240, lr=4.99446e-05, gnorm=1.299, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3731
2022-09-28 21:45:17 - progress_bar.py[line:274] - INFO: epoch 001:   3253 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.3, ups=0.88, wpb=100.6, bsz=40, num_updates=3250, lr=4.9938e-05, gnorm=1.026, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3742
2022-09-28 21:45:28 - progress_bar.py[line:274] - INFO: epoch 001:   3263 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=3260, lr=4.99314e-05, gnorm=1.059, clip=60, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3753
2022-09-28 21:45:40 - progress_bar.py[line:274] - INFO: epoch 001:   3273 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.89, wpb=100.1, bsz=40, num_updates=3270, lr=4.99248e-05, gnorm=1.177, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=3764
2022-09-28 21:45:49 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 21:45:51 - progress_bar.py[line:274] - INFO: epoch 001:   3284 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.4, ups=0.87, wpb=100.8, bsz=40, num_updates=3280, lr=4.99182e-05, gnorm=1.169, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3776
2022-09-28 21:46:02 - progress_bar.py[line:274] - INFO: epoch 001:   3294 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.91, wpb=101.4, bsz=40, num_updates=3290, lr=4.99116e-05, gnorm=1.086, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3787
2022-09-28 21:46:13 - progress_bar.py[line:274] - INFO: epoch 001:   3304 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.3, ups=0.89, wpb=100.7, bsz=40, num_updates=3300, lr=4.9905e-05, gnorm=1.252, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3798
2022-09-28 21:46:24 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=93.3, ups=0.92, wpb=101.2, bsz=40, num_updates=3310, lr=4.98984e-05, gnorm=1.211, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=3809
2022-09-28 21:46:35 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.4, ups=0.93, wpb=101.4, bsz=40, num_updates=3320, lr=4.98918e-05, gnorm=1.075, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3820
2022-09-28 21:46:46 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.1, ups=0.89, wpb=99, bsz=40, num_updates=3330, lr=4.98852e-05, gnorm=1.249, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3831
2022-09-28 21:46:57 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.9, wpb=103.6, bsz=40, num_updates=3340, lr=4.98786e-05, gnorm=1.223, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3842
2022-09-28 21:47:09 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92, ups=0.9, wpb=101.8, bsz=40, num_updates=3350, lr=4.9872e-05, gnorm=1.146, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3853
2022-09-28 21:47:20 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.88, wpb=101.6, bsz=40, num_updates=3360, lr=4.98654e-05, gnorm=1.061, clip=70, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=3865
2022-09-28 21:47:31 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=3370, lr=4.98588e-05, gnorm=1.173, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=3876
2022-09-28 21:47:43 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89, ups=0.87, wpb=101.8, bsz=40, num_updates=3380, lr=4.98522e-05, gnorm=1.024, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3888
2022-09-28 21:47:54 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.89, wpb=99.7, bsz=40, num_updates=3390, lr=4.98456e-05, gnorm=1.152, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3899
2022-09-28 21:48:04 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.8, ups=0.96, wpb=100.8, bsz=40, num_updates=3400, lr=4.9839e-05, gnorm=1.12, clip=60, loss_scale=512, train_wall=10, gb_free=10.9, ema_decay=0.9999, wall=3909
2022-09-28 21:48:16 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 15783 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.9, ups=0.88, wpb=100.3, bsz=40, num_updates=3410, lr=4.98324e-05, gnorm=1.317, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=3921
2022-09-28 21:48:27 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=3420, lr=4.98258e-05, gnorm=1.16, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3932
2022-09-28 21:48:39 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=85, ups=0.84, wpb=101, bsz=40, num_updates=3430, lr=4.98192e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=3944
2022-09-28 21:48:51 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.1, ups=0.86, wpb=102.5, bsz=40, num_updates=3440, lr=4.98126e-05, gnorm=1.023, clip=40, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=3956
2022-09-28 21:49:03 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.7, ups=0.86, wpb=101.7, bsz=40, num_updates=3450, lr=4.9806e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=3967
2022-09-28 21:49:14 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.6, ups=0.89, wpb=99.8, bsz=40, num_updates=3460, lr=4.97994e-05, gnorm=1.22, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=3979
2022-09-28 21:49:25 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.9, ups=0.91, wpb=100.5, bsz=40, num_updates=3470, lr=4.97928e-05, gnorm=1.011, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=3990
2022-09-28 21:49:36 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.9, wpb=102.8, bsz=40, num_updates=3480, lr=4.97862e-05, gnorm=0.99, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4001
2022-09-28 21:49:47 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=3490, lr=4.97796e-05, gnorm=1.026, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4012
2022-09-28 21:49:58 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.91, wpb=101.3, bsz=40, num_updates=3500, lr=4.9773e-05, gnorm=1.042, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4023
2022-09-28 21:50:10 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.7, ups=0.9, wpb=98.6, bsz=40, num_updates=3510, lr=4.97664e-05, gnorm=1.176, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4034
2022-09-28 21:50:21 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.89, wpb=101.3, bsz=40, num_updates=3520, lr=4.97598e-05, gnorm=1.06, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4046
2022-09-28 21:50:32 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 15783 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=91.1, ups=0.91, wpb=100.5, bsz=40, num_updates=3530, lr=4.97532e-05, gnorm=1.466, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4057
2022-09-28 21:50:43 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.91, wpb=100.9, bsz=40, num_updates=3540, lr=4.97466e-05, gnorm=1.091, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4068
2022-09-28 21:50:54 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 15783 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=3550, lr=4.974e-05, gnorm=1.146, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4079
2022-09-28 21:51:05 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.89, wpb=101.5, bsz=40, num_updates=3560, lr=4.97334e-05, gnorm=0.99, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4090
2022-09-28 21:51:17 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.88, wpb=102, bsz=40, num_updates=3570, lr=4.97268e-05, gnorm=0.99, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4102
2022-09-28 21:51:28 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=3580, lr=4.97202e-05, gnorm=0.958, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4113
2022-09-28 21:51:39 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.6, ups=0.91, wpb=101.9, bsz=40, num_updates=3590, lr=4.97136e-05, gnorm=1.039, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4124
2022-09-28 21:51:50 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.5, ups=0.9, wpb=102.8, bsz=40, num_updates=3600, lr=4.9707e-05, gnorm=1.225, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4135
2022-09-28 21:52:02 - progress_bar.py[line:274] - INFO: epoch 001:   3614 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.87, wpb=102.7, bsz=40, num_updates=3610, lr=4.97004e-05, gnorm=1.148, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4147
2022-09-28 21:52:13 - progress_bar.py[line:274] - INFO: epoch 001:   3624 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=3620, lr=4.96938e-05, gnorm=1.105, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4158
2022-09-28 21:52:25 - progress_bar.py[line:274] - INFO: epoch 001:   3634 / 15783 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=82.3, ups=0.82, wpb=100.1, bsz=40, num_updates=3630, lr=4.96872e-05, gnorm=1.051, clip=40, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=4170
2022-09-28 21:52:38 - progress_bar.py[line:274] - INFO: epoch 001:   3644 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=82.6, ups=0.8, wpb=102.7, bsz=40, num_updates=3640, lr=4.96806e-05, gnorm=1.161, clip=80, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=4182
2022-09-28 21:52:49 - progress_bar.py[line:274] - INFO: epoch 001:   3654 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88, ups=0.86, wpb=101.8, bsz=40, num_updates=3650, lr=4.9674e-05, gnorm=1.103, clip=60, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=4194
2022-09-28 21:53:00 - progress_bar.py[line:274] - INFO: epoch 001:   3664 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.2, ups=0.91, wpb=100.8, bsz=40, num_updates=3660, lr=4.96674e-05, gnorm=0.934, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4205
2022-09-28 21:53:11 - progress_bar.py[line:274] - INFO: epoch 001:   3674 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.89, wpb=102.6, bsz=40, num_updates=3670, lr=4.96608e-05, gnorm=1.028, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4216
2022-09-28 21:53:23 - progress_bar.py[line:274] - INFO: epoch 001:   3684 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.7, ups=0.89, wpb=99.9, bsz=40, num_updates=3680, lr=4.96542e-05, gnorm=1.176, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4227
2022-09-28 21:53:33 - progress_bar.py[line:274] - INFO: epoch 001:   3694 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.6, ups=0.92, wpb=101.5, bsz=40, num_updates=3690, lr=4.96476e-05, gnorm=1.028, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4238
2022-09-28 21:53:44 - progress_bar.py[line:274] - INFO: epoch 001:   3704 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.7, ups=0.91, wpb=102.8, bsz=40, num_updates=3700, lr=4.9641e-05, gnorm=0.959, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=4249
2022-09-28 21:53:56 - progress_bar.py[line:274] - INFO: epoch 001:   3714 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.89, wpb=103.8, bsz=40, num_updates=3710, lr=4.96344e-05, gnorm=0.957, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4261
2022-09-28 21:54:07 - progress_bar.py[line:274] - INFO: epoch 001:   3724 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.9, ups=0.88, wpb=101.8, bsz=40, num_updates=3720, lr=4.96278e-05, gnorm=0.955, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4272
2022-09-28 21:54:19 - progress_bar.py[line:274] - INFO: epoch 001:   3734 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.9, ups=0.87, wpb=100.3, bsz=40, num_updates=3730, lr=4.96212e-05, gnorm=1.053, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4283
2022-09-28 21:54:30 - progress_bar.py[line:274] - INFO: epoch 001:   3744 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.86, wpb=102.7, bsz=40, num_updates=3740, lr=4.96146e-05, gnorm=1.093, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=4295
2022-09-28 21:54:42 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.2, ups=0.86, wpb=100.9, bsz=40, num_updates=3750, lr=4.9608e-05, gnorm=1.031, clip=30, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=4307
2022-09-28 21:54:54 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=83.8, ups=0.81, wpb=103.3, bsz=40, num_updates=3760, lr=4.96014e-05, gnorm=1.067, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=4319
2022-09-28 21:55:07 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=76.2, ups=0.76, wpb=100.4, bsz=40, num_updates=3770, lr=4.95948e-05, gnorm=1.099, clip=60, loss_scale=512, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=4332
2022-09-28 21:55:19 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=84.6, ups=0.84, wpb=100.6, bsz=40, num_updates=3780, lr=4.95882e-05, gnorm=1.051, clip=50, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4344
2022-09-28 21:55:30 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.89, wpb=102.4, bsz=40, num_updates=3790, lr=4.95816e-05, gnorm=1.226, clip=70, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4355
2022-09-28 21:55:42 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.3, ups=0.87, wpb=102.3, bsz=40, num_updates=3800, lr=4.9575e-05, gnorm=1.127, clip=60, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=4367
2022-09-28 21:55:46 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 21:55:54 - progress_bar.py[line:274] - INFO: epoch 001:   3815 / 15783 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=81.3, ups=0.81, wpb=99.9, bsz=40, num_updates=3810, lr=4.95684e-05, gnorm=1.117, clip=80, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=4379
2022-09-28 21:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   3825 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.3, ups=0.92, wpb=100.7, bsz=40, num_updates=3820, lr=4.95618e-05, gnorm=0.881, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4390
2022-09-28 21:56:17 - progress_bar.py[line:274] - INFO: epoch 001:   3835 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.5, ups=0.88, wpb=101.1, bsz=40, num_updates=3830, lr=4.95552e-05, gnorm=1.103, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4401
2022-09-28 21:56:27 - progress_bar.py[line:274] - INFO: epoch 001:   3845 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94, ups=0.92, wpb=102.4, bsz=40, num_updates=3840, lr=4.95486e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4412
2022-09-28 21:56:39 - progress_bar.py[line:274] - INFO: epoch 001:   3855 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.2, ups=0.87, wpb=103, bsz=40, num_updates=3850, lr=4.9542e-05, gnorm=1.074, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4424
2022-09-28 21:56:50 - progress_bar.py[line:274] - INFO: epoch 001:   3865 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.6, ups=0.88, wpb=102.5, bsz=40, num_updates=3860, lr=4.95354e-05, gnorm=1.029, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4435
2022-09-28 21:57:01 - progress_bar.py[line:274] - INFO: epoch 001:   3875 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.5, ups=0.94, wpb=100.8, bsz=40, num_updates=3870, lr=4.95288e-05, gnorm=1.166, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4446
2022-09-28 21:57:12 - progress_bar.py[line:274] - INFO: epoch 001:   3885 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.89, wpb=101.7, bsz=40, num_updates=3880, lr=4.95222e-05, gnorm=1.107, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4457
2022-09-28 21:57:24 - progress_bar.py[line:274] - INFO: epoch 001:   3895 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=3890, lr=4.95156e-05, gnorm=1.046, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4469
2022-09-28 21:57:35 - progress_bar.py[line:274] - INFO: epoch 001:   3905 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.9, wpb=100.9, bsz=40, num_updates=3900, lr=4.9509e-05, gnorm=1.163, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4480
2022-09-28 21:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   3915 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.3, ups=0.87, wpb=104.5, bsz=40, num_updates=3910, lr=4.95024e-05, gnorm=1.15, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4491
2022-09-28 21:57:57 - progress_bar.py[line:274] - INFO: epoch 001:   3925 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.9, ups=0.91, wpb=100.9, bsz=40, num_updates=3920, lr=4.94958e-05, gnorm=1.23, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4502
2022-09-28 21:58:09 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.87, wpb=102.2, bsz=40, num_updates=3930, lr=4.94892e-05, gnorm=1.009, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4514
2022-09-28 21:58:20 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.7, ups=0.89, wpb=99.9, bsz=40, num_updates=3940, lr=4.94826e-05, gnorm=1.107, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4525
2022-09-28 21:58:31 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.3, ups=0.94, wpb=102.7, bsz=40, num_updates=3950, lr=4.9476e-05, gnorm=1.042, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4535
2022-09-28 21:58:42 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.88, wpb=100.2, bsz=40, num_updates=3960, lr=4.94694e-05, gnorm=0.908, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4547
2022-09-28 21:58:53 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.3, ups=0.88, wpb=99.7, bsz=40, num_updates=3970, lr=4.94628e-05, gnorm=1.169, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4558
2022-09-28 21:59:05 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.9, ups=0.87, wpb=101.1, bsz=40, num_updates=3980, lr=4.94562e-05, gnorm=1.247, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4570
2022-09-28 21:59:16 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.9, ups=0.9, wpb=101.9, bsz=40, num_updates=3990, lr=4.94496e-05, gnorm=1.152, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4581
2022-09-28 21:59:27 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 15783 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=91, ups=0.91, wpb=99.9, bsz=40, num_updates=4000, lr=4.9443e-05, gnorm=0.949, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4592
2022-09-28 21:59:38 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.6, ups=0.9, wpb=101.1, bsz=40, num_updates=4010, lr=4.94364e-05, gnorm=1.138, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4603
2022-09-28 21:59:50 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 15783 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.5, ups=0.88, wpb=99.9, bsz=40, num_updates=4020, lr=4.94298e-05, gnorm=1.159, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=4614
2022-09-28 22:00:01 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.7, ups=0.91, wpb=101.6, bsz=40, num_updates=4030, lr=4.94232e-05, gnorm=1.082, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4625
2022-09-28 22:00:12 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 15783 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=86.6, ups=0.87, wpb=99.6, bsz=40, num_updates=4040, lr=4.94166e-05, gnorm=1.156, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4637
2022-09-28 22:00:23 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.9, ups=0.9, wpb=101.1, bsz=40, num_updates=4050, lr=4.941e-05, gnorm=1.103, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4648
2022-09-28 22:00:34 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96, ups=0.93, wpb=103, bsz=40, num_updates=4060, lr=4.94034e-05, gnorm=1.015, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4659
2022-09-28 22:00:45 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 15783 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.5, ups=0.87, wpb=99, bsz=40, num_updates=4070, lr=4.93968e-05, gnorm=1.092, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4670
2022-09-28 22:00:56 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.6, ups=0.95, wpb=101.8, bsz=40, num_updates=4080, lr=4.93902e-05, gnorm=1.071, clip=50, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=4681
2022-09-28 22:01:07 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.88, wpb=100, bsz=40, num_updates=4090, lr=4.93836e-05, gnorm=1.117, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4692
2022-09-28 22:01:19 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=84.4, ups=0.84, wpb=100.7, bsz=40, num_updates=4100, lr=4.9377e-05, gnorm=1.038, clip=60, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4704
2022-09-28 22:01:31 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.8, ups=0.88, wpb=100.2, bsz=40, num_updates=4110, lr=4.93704e-05, gnorm=1.171, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4715
2022-09-28 22:01:42 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.92, wpb=100.4, bsz=40, num_updates=4120, lr=4.93638e-05, gnorm=0.931, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4726
2022-09-28 22:01:54 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=83, ups=0.81, wpb=102, bsz=40, num_updates=4130, lr=4.93572e-05, gnorm=1.106, clip=80, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=4739
2022-09-28 22:02:08 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=76.8, ups=0.74, wpb=103.5, bsz=40, num_updates=4140, lr=4.93506e-05, gnorm=1.077, clip=50, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=4752
2022-09-28 22:02:21 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=72, ups=0.73, wpb=99.1, bsz=40, num_updates=4150, lr=4.9344e-05, gnorm=1.096, clip=60, loss_scale=512, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=4766
2022-09-28 22:02:33 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.8, ups=0.86, wpb=102.5, bsz=40, num_updates=4160, lr=4.93374e-05, gnorm=0.953, clip=60, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=4778
2022-09-28 22:02:44 - progress_bar.py[line:274] - INFO: epoch 001:   4175 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89, ups=0.89, wpb=99.9, bsz=40, num_updates=4170, lr=4.93308e-05, gnorm=1.145, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4789
2022-09-28 22:02:56 - progress_bar.py[line:274] - INFO: epoch 001:   4185 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.6, ups=0.89, wpb=100.9, bsz=40, num_updates=4180, lr=4.93242e-05, gnorm=1.124, clip=70, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=4800
2022-09-28 22:03:07 - progress_bar.py[line:274] - INFO: epoch 001:   4195 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.1, ups=0.88, wpb=102, bsz=40, num_updates=4190, lr=4.93176e-05, gnorm=1.333, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4812
2022-09-28 22:03:18 - progress_bar.py[line:274] - INFO: epoch 001:   4205 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.4, ups=0.9, wpb=101.8, bsz=40, num_updates=4200, lr=4.9311e-05, gnorm=1.03, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4823
2022-09-28 22:03:30 - progress_bar.py[line:274] - INFO: epoch 001:   4215 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.3, ups=0.87, wpb=100, bsz=40, num_updates=4210, lr=4.93044e-05, gnorm=1.048, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4834
2022-09-28 22:03:41 - progress_bar.py[line:274] - INFO: epoch 001:   4225 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.4, ups=0.86, wpb=102.1, bsz=40, num_updates=4220, lr=4.92978e-05, gnorm=1.138, clip=70, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=4846
2022-09-28 22:03:53 - progress_bar.py[line:274] - INFO: epoch 001:   4235 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=83.9, ups=0.83, wpb=100.8, bsz=40, num_updates=4230, lr=4.92912e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=4858
2022-09-28 22:04:06 - progress_bar.py[line:274] - INFO: epoch 001:   4245 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=80.9, ups=0.8, wpb=101.5, bsz=40, num_updates=4240, lr=4.92846e-05, gnorm=1.208, clip=80, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=4871
2022-09-28 22:04:17 - progress_bar.py[line:274] - INFO: epoch 001:   4255 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=86, ups=0.86, wpb=99.8, bsz=40, num_updates=4250, lr=4.9278e-05, gnorm=0.955, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=4882
2022-09-28 22:04:29 - progress_bar.py[line:274] - INFO: epoch 001:   4265 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.88, wpb=102.7, bsz=40, num_updates=4260, lr=4.92714e-05, gnorm=0.915, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4894
2022-09-28 22:04:40 - progress_bar.py[line:274] - INFO: epoch 001:   4275 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92, ups=0.9, wpb=102.3, bsz=40, num_updates=4270, lr=4.92648e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4905
2022-09-28 22:04:51 - progress_bar.py[line:274] - INFO: epoch 001:   4285 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.3, ups=0.87, wpb=100.2, bsz=40, num_updates=4280, lr=4.92582e-05, gnorm=1.108, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4916
2022-09-28 22:05:02 - progress_bar.py[line:274] - INFO: epoch 001:   4295 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.9, ups=0.91, wpb=100.7, bsz=40, num_updates=4290, lr=4.92516e-05, gnorm=1.218, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4927
2022-09-28 22:05:14 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.2, ups=0.88, wpb=101.5, bsz=40, num_updates=4300, lr=4.9245e-05, gnorm=1.108, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4939
2022-09-28 22:05:25 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87, ups=0.86, wpb=100.7, bsz=40, num_updates=4310, lr=4.92384e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=4950
2022-09-28 22:05:36 - progress_bar.py[line:274] - INFO: epoch 001:   4325 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.91, wpb=99.8, bsz=40, num_updates=4320, lr=4.92318e-05, gnorm=0.941, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4961
2022-09-28 22:05:48 - progress_bar.py[line:274] - INFO: epoch 001:   4335 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.4, ups=0.88, wpb=102.6, bsz=40, num_updates=4330, lr=4.92252e-05, gnorm=1.09, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4972
2022-09-28 22:05:59 - progress_bar.py[line:274] - INFO: epoch 001:   4345 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.8, ups=0.87, wpb=100.7, bsz=40, num_updates=4340, lr=4.92186e-05, gnorm=1.009, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4984
2022-09-28 22:06:10 - progress_bar.py[line:274] - INFO: epoch 001:   4355 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=4350, lr=4.9212e-05, gnorm=0.958, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=4995
2022-09-28 22:06:23 - progress_bar.py[line:274] - INFO: epoch 001:   4365 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=84.6, ups=0.84, wpb=101.1, bsz=40, num_updates=4360, lr=4.92054e-05, gnorm=1.03, clip=50, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=5007
2022-09-28 22:06:35 - progress_bar.py[line:274] - INFO: epoch 001:   4375 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=82.8, ups=0.81, wpb=101.9, bsz=40, num_updates=4370, lr=4.91988e-05, gnorm=1.005, clip=40, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=5020
2022-09-28 22:06:47 - progress_bar.py[line:274] - INFO: epoch 001:   4385 / 15783 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=82.2, ups=0.81, wpb=101.5, bsz=40, num_updates=4380, lr=4.91922e-05, gnorm=1.155, clip=80, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=5032
2022-09-28 22:06:58 - progress_bar.py[line:274] - INFO: epoch 001:   4395 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.9, wpb=102.3, bsz=40, num_updates=4390, lr=4.91856e-05, gnorm=1.181, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5043
2022-09-28 22:07:10 - progress_bar.py[line:274] - INFO: epoch 001:   4405 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=83, ups=0.83, wpb=99.7, bsz=40, num_updates=4400, lr=4.9179e-05, gnorm=1.048, clip=60, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5055
2022-09-28 22:07:22 - progress_bar.py[line:274] - INFO: epoch 001:   4415 / 15783 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=85.7, ups=0.85, wpb=101.4, bsz=40, num_updates=4410, lr=4.91724e-05, gnorm=0.91, clip=20, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5067
2022-09-28 22:07:34 - progress_bar.py[line:274] - INFO: epoch 001:   4425 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.9, ups=0.88, wpb=101.5, bsz=40, num_updates=4420, lr=4.91658e-05, gnorm=1.007, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5079
2022-09-28 22:07:45 - progress_bar.py[line:274] - INFO: epoch 001:   4435 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.89, wpb=100.7, bsz=40, num_updates=4430, lr=4.91592e-05, gnorm=0.984, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5090
2022-09-28 22:07:56 - progress_bar.py[line:274] - INFO: epoch 001:   4445 / 15783 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.5, ups=0.88, wpb=100.2, bsz=40, num_updates=4440, lr=4.91526e-05, gnorm=1.068, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5101
2022-09-28 22:08:07 - progress_bar.py[line:274] - INFO: epoch 001:   4455 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.91, wpb=100.4, bsz=40, num_updates=4450, lr=4.9146e-05, gnorm=0.954, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5112
2022-09-28 22:08:19 - progress_bar.py[line:274] - INFO: epoch 001:   4465 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.87, wpb=100.9, bsz=40, num_updates=4460, lr=4.91394e-05, gnorm=1.02, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5124
2022-09-28 22:08:31 - progress_bar.py[line:274] - INFO: epoch 001:   4475 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=84.9, ups=0.84, wpb=101.1, bsz=40, num_updates=4470, lr=4.91328e-05, gnorm=1.018, clip=60, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5136
2022-09-28 22:08:43 - progress_bar.py[line:274] - INFO: epoch 001:   4485 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=80.3, ups=0.8, wpb=100.6, bsz=40, num_updates=4480, lr=4.91262e-05, gnorm=1.008, clip=50, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=5148
2022-09-28 22:08:55 - progress_bar.py[line:274] - INFO: epoch 001:   4495 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.1, ups=0.84, wpb=101.9, bsz=40, num_updates=4490, lr=4.91196e-05, gnorm=0.938, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=5160
2022-09-28 22:09:06 - progress_bar.py[line:274] - INFO: epoch 001:   4505 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=4500, lr=4.9113e-05, gnorm=0.997, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5171
2022-09-28 22:09:17 - progress_bar.py[line:274] - INFO: epoch 001:   4515 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.4, ups=0.93, wpb=102.1, bsz=40, num_updates=4510, lr=4.91064e-05, gnorm=1.129, clip=70, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5182
2022-09-28 22:09:28 - progress_bar.py[line:274] - INFO: epoch 001:   4525 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.8, ups=0.91, wpb=100.9, bsz=40, num_updates=4520, lr=4.90998e-05, gnorm=1.05, clip=70, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5193
2022-09-28 22:09:31 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 22:09:40 - progress_bar.py[line:274] - INFO: epoch 001:   4536 / 15783 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=84.8, ups=0.83, wpb=101.8, bsz=40, num_updates=4530, lr=4.90932e-05, gnorm=1.093, clip=50, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5205
2022-09-28 22:09:51 - progress_bar.py[line:274] - INFO: epoch 001:   4546 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.9, wpb=102.5, bsz=40, num_updates=4540, lr=4.90866e-05, gnorm=1.049, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5216
2022-09-28 22:10:02 - progress_bar.py[line:274] - INFO: epoch 001:   4556 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.4, ups=0.91, wpb=100.4, bsz=40, num_updates=4550, lr=4.908e-05, gnorm=0.886, clip=30, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=5227
2022-09-28 22:10:13 - progress_bar.py[line:274] - INFO: epoch 001:   4566 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.6, ups=0.92, wpb=100.7, bsz=40, num_updates=4560, lr=4.90734e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5238
2022-09-28 22:10:24 - progress_bar.py[line:274] - INFO: epoch 001:   4576 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=4570, lr=4.90668e-05, gnorm=0.994, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5249
2022-09-28 22:10:35 - progress_bar.py[line:274] - INFO: epoch 001:   4586 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.9, ups=0.9, wpb=101.9, bsz=40, num_updates=4580, lr=4.90602e-05, gnorm=0.975, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5260
2022-09-28 22:10:47 - progress_bar.py[line:274] - INFO: epoch 001:   4596 / 15783 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89, ups=0.89, wpb=100.2, bsz=40, num_updates=4590, lr=4.90536e-05, gnorm=1.013, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5272
2022-09-28 22:10:58 - progress_bar.py[line:274] - INFO: epoch 001:   4606 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89, ups=0.87, wpb=102.6, bsz=40, num_updates=4600, lr=4.9047e-05, gnorm=0.985, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5283
2022-09-28 22:11:10 - progress_bar.py[line:274] - INFO: epoch 001:   4616 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.7, ups=0.87, wpb=103.2, bsz=40, num_updates=4610, lr=4.90404e-05, gnorm=0.951, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5295
2022-09-28 22:11:21 - progress_bar.py[line:274] - INFO: epoch 001:   4626 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.87, wpb=103.1, bsz=40, num_updates=4620, lr=4.90338e-05, gnorm=0.989, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5306
2022-09-28 22:11:33 - progress_bar.py[line:274] - INFO: epoch 001:   4636 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87, ups=0.86, wpb=101.4, bsz=40, num_updates=4630, lr=4.90272e-05, gnorm=1.058, clip=30, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=5318
2022-09-28 22:11:46 - progress_bar.py[line:274] - INFO: epoch 001:   4646 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=80.3, ups=0.79, wpb=101.3, bsz=40, num_updates=4640, lr=4.90206e-05, gnorm=0.952, clip=50, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=5330
2022-09-28 22:11:58 - progress_bar.py[line:274] - INFO: epoch 001:   4656 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=81.3, ups=0.8, wpb=101, bsz=40, num_updates=4650, lr=4.9014e-05, gnorm=0.919, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5343
2022-09-28 22:12:11 - progress_bar.py[line:274] - INFO: epoch 001:   4666 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=77.6, ups=0.77, wpb=101.3, bsz=40, num_updates=4660, lr=4.90074e-05, gnorm=1.132, clip=60, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=5356
2022-09-28 22:12:24 - progress_bar.py[line:274] - INFO: epoch 001:   4676 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=78.8, ups=0.77, wpb=101.7, bsz=40, num_updates=4670, lr=4.90008e-05, gnorm=1.111, clip=60, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=5369
2022-09-28 22:12:36 - progress_bar.py[line:274] - INFO: epoch 001:   4686 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.5, ups=0.86, wpb=101.8, bsz=40, num_updates=4680, lr=4.89942e-05, gnorm=0.952, clip=30, loss_scale=512, train_wall=12, gb_free=9.5, ema_decay=0.9999, wall=5381
2022-09-28 22:12:47 - progress_bar.py[line:274] - INFO: epoch 001:   4696 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.8, ups=0.93, wpb=99.2, bsz=40, num_updates=4690, lr=4.89876e-05, gnorm=1.048, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5392
2022-09-28 22:12:59 - progress_bar.py[line:274] - INFO: epoch 001:   4706 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.88, wpb=101.4, bsz=40, num_updates=4700, lr=4.8981e-05, gnorm=1.113, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5403
2022-09-28 22:13:10 - progress_bar.py[line:274] - INFO: epoch 001:   4716 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.89, wpb=101.9, bsz=40, num_updates=4710, lr=4.89744e-05, gnorm=1.185, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5415
2022-09-28 22:13:21 - progress_bar.py[line:274] - INFO: epoch 001:   4726 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.8, ups=0.89, wpb=101.5, bsz=40, num_updates=4720, lr=4.89678e-05, gnorm=1.056, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5426
2022-09-28 22:13:32 - progress_bar.py[line:274] - INFO: epoch 001:   4736 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91, ups=0.91, wpb=100.4, bsz=40, num_updates=4730, lr=4.89612e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5437
2022-09-28 22:13:44 - progress_bar.py[line:274] - INFO: epoch 001:   4746 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.5, ups=0.85, wpb=101.3, bsz=40, num_updates=4740, lr=4.89546e-05, gnorm=1.014, clip=40, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=5449
2022-09-28 22:13:55 - progress_bar.py[line:274] - INFO: epoch 001:   4756 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.2, ups=0.86, wpb=101.2, bsz=40, num_updates=4750, lr=4.8948e-05, gnorm=1.117, clip=80, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=5460
2022-09-28 22:14:06 - progress_bar.py[line:274] - INFO: epoch 001:   4766 / 15783 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=91.3, ups=0.9, wpb=101.5, bsz=40, num_updates=4760, lr=4.89414e-05, gnorm=0.976, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5471
2022-09-28 22:14:18 - progress_bar.py[line:274] - INFO: epoch 001:   4776 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.2, ups=0.9, wpb=101.7, bsz=40, num_updates=4770, lr=4.89348e-05, gnorm=1.202, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5482
2022-09-28 22:14:28 - progress_bar.py[line:274] - INFO: epoch 001:   4786 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.2, ups=0.92, wpb=99.1, bsz=40, num_updates=4780, lr=4.89282e-05, gnorm=1.027, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5493
2022-09-28 22:14:40 - progress_bar.py[line:274] - INFO: epoch 001:   4796 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=84.9, ups=0.85, wpb=100.3, bsz=40, num_updates=4790, lr=4.89216e-05, gnorm=1.137, clip=90, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=5505
2022-09-28 22:14:51 - progress_bar.py[line:274] - INFO: epoch 001:   4806 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.7, ups=0.9, wpb=103.5, bsz=40, num_updates=4800, lr=4.8915e-05, gnorm=1.34, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5516
2022-09-28 22:15:03 - progress_bar.py[line:274] - INFO: epoch 001:   4816 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.4, ups=0.87, wpb=101.5, bsz=40, num_updates=4810, lr=4.89084e-05, gnorm=1.071, clip=60, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=5528
2022-09-28 22:15:15 - progress_bar.py[line:274] - INFO: epoch 001:   4826 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.4, ups=0.86, wpb=101.1, bsz=40, num_updates=4820, lr=4.89018e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5539
2022-09-28 22:15:26 - progress_bar.py[line:274] - INFO: epoch 001:   4836 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.9, ups=0.87, wpb=99.9, bsz=40, num_updates=4830, lr=4.88952e-05, gnorm=1.008, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5551
2022-09-28 22:15:37 - progress_bar.py[line:274] - INFO: epoch 001:   4846 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.9, wpb=100.6, bsz=40, num_updates=4840, lr=4.88886e-05, gnorm=1.055, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5562
2022-09-28 22:15:49 - progress_bar.py[line:274] - INFO: epoch 001:   4856 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.88, wpb=100.5, bsz=40, num_updates=4850, lr=4.8882e-05, gnorm=1.049, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5573
2022-09-28 22:16:00 - progress_bar.py[line:274] - INFO: epoch 001:   4866 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.7, ups=0.89, wpb=100.8, bsz=40, num_updates=4860, lr=4.88754e-05, gnorm=1.095, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5585
2022-09-28 22:16:11 - progress_bar.py[line:274] - INFO: epoch 001:   4876 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=4870, lr=4.88688e-05, gnorm=0.981, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5596
2022-09-28 22:16:22 - progress_bar.py[line:274] - INFO: epoch 001:   4886 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.2, ups=0.87, wpb=100.9, bsz=40, num_updates=4880, lr=4.88622e-05, gnorm=1.212, clip=80, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5607
2022-09-28 22:16:34 - progress_bar.py[line:274] - INFO: epoch 001:   4896 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.6, ups=0.87, wpb=100.2, bsz=40, num_updates=4890, lr=4.88556e-05, gnorm=0.941, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5619
2022-09-28 22:16:46 - progress_bar.py[line:274] - INFO: epoch 001:   4906 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=82.9, ups=0.83, wpb=100.1, bsz=40, num_updates=4900, lr=4.8849e-05, gnorm=1.04, clip=50, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=5631
2022-09-28 22:16:57 - progress_bar.py[line:274] - INFO: epoch 001:   4916 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=4910, lr=4.88424e-05, gnorm=1.033, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5642
2022-09-28 22:17:09 - progress_bar.py[line:274] - INFO: epoch 001:   4926 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.6, ups=0.89, wpb=99.9, bsz=40, num_updates=4920, lr=4.88358e-05, gnorm=1.236, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=5653
2022-09-28 22:17:20 - progress_bar.py[line:274] - INFO: epoch 001:   4936 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.6, ups=0.9, wpb=100.6, bsz=40, num_updates=4930, lr=4.88292e-05, gnorm=1.103, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5664
2022-09-28 22:17:31 - progress_bar.py[line:274] - INFO: epoch 001:   4946 / 15783 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.5, ups=0.9, wpb=99.7, bsz=40, num_updates=4940, lr=4.88226e-05, gnorm=1.133, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5676
2022-09-28 22:17:42 - progress_bar.py[line:274] - INFO: epoch 001:   4956 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.86, wpb=102.8, bsz=40, num_updates=4950, lr=4.8816e-05, gnorm=1.07, clip=40, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=5687
2022-09-28 22:17:53 - progress_bar.py[line:274] - INFO: epoch 001:   4966 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.4, ups=0.91, wpb=102.4, bsz=40, num_updates=4960, lr=4.88094e-05, gnorm=1.071, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5698
2022-09-28 22:18:05 - progress_bar.py[line:274] - INFO: epoch 001:   4976 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.8, ups=0.87, wpb=100.1, bsz=40, num_updates=4970, lr=4.88028e-05, gnorm=1.119, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5710
2022-09-28 22:18:16 - progress_bar.py[line:274] - INFO: epoch 001:   4986 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.5, ups=0.89, wpb=103.7, bsz=40, num_updates=4980, lr=4.87962e-05, gnorm=1.028, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5721
2022-09-28 22:18:28 - progress_bar.py[line:274] - INFO: epoch 001:   4996 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.1, ups=0.86, wpb=101.8, bsz=40, num_updates=4990, lr=4.87896e-05, gnorm=1.051, clip=60, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5733
2022-09-28 22:18:40 - progress_bar.py[line:274] - INFO: epoch 001:   5006 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.6, ups=0.85, wpb=101.7, bsz=40, num_updates=5000, lr=4.8783e-05, gnorm=0.971, clip=20, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=5744
2022-09-28 22:18:51 - progress_bar.py[line:274] - INFO: epoch 001:   5016 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.88, wpb=101.6, bsz=40, num_updates=5010, lr=4.87764e-05, gnorm=0.981, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5756
2022-09-28 22:19:02 - progress_bar.py[line:274] - INFO: epoch 001:   5026 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.88, wpb=101.1, bsz=40, num_updates=5020, lr=4.87698e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5767
2022-09-28 22:19:14 - progress_bar.py[line:274] - INFO: epoch 001:   5036 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.88, wpb=101.4, bsz=40, num_updates=5030, lr=4.87632e-05, gnorm=1.111, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5779
2022-09-28 22:19:25 - progress_bar.py[line:274] - INFO: epoch 001:   5046 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.4, ups=0.91, wpb=101.6, bsz=40, num_updates=5040, lr=4.87566e-05, gnorm=1.032, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5790
2022-09-28 22:19:36 - progress_bar.py[line:274] - INFO: epoch 001:   5056 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.91, wpb=100.5, bsz=40, num_updates=5050, lr=4.875e-05, gnorm=1.096, clip=80, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5801
2022-09-28 22:19:44 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 22:19:48 - progress_bar.py[line:274] - INFO: epoch 001:   5067 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=80.2, ups=0.8, wpb=100.3, bsz=40, num_updates=5060, lr=4.87434e-05, gnorm=1.354, clip=90, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=5813
2022-09-28 22:19:59 - progress_bar.py[line:274] - INFO: epoch 001:   5077 / 15783 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.6, ups=0.9, wpb=103, bsz=40, num_updates=5070, lr=4.87368e-05, gnorm=1.274, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5824
2022-09-28 22:20:10 - progress_bar.py[line:274] - INFO: epoch 001:   5087 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=5080, lr=4.87302e-05, gnorm=1, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5835
2022-09-28 22:20:22 - progress_bar.py[line:274] - INFO: epoch 001:   5097 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.9, wpb=101.4, bsz=40, num_updates=5090, lr=4.87236e-05, gnorm=1.022, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5846
2022-09-28 22:20:33 - progress_bar.py[line:274] - INFO: epoch 001:   5107 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.3, ups=0.91, wpb=102.1, bsz=40, num_updates=5100, lr=4.8717e-05, gnorm=1.004, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5857
2022-09-28 22:20:44 - progress_bar.py[line:274] - INFO: epoch 001:   5117 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.7, ups=0.9, wpb=101.1, bsz=40, num_updates=5110, lr=4.87104e-05, gnorm=0.954, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5869
2022-09-28 22:20:55 - progress_bar.py[line:274] - INFO: epoch 001:   5127 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.8, ups=0.92, wpb=101.7, bsz=40, num_updates=5120, lr=4.87038e-05, gnorm=1.078, clip=50, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5879
2022-09-28 22:21:06 - progress_bar.py[line:274] - INFO: epoch 001:   5137 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=84.1, ups=0.85, wpb=98.9, bsz=40, num_updates=5130, lr=4.86972e-05, gnorm=1.02, clip=50, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=5891
2022-09-28 22:21:19 - progress_bar.py[line:274] - INFO: epoch 001:   5147 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=82.1, ups=0.81, wpb=101.3, bsz=40, num_updates=5140, lr=4.86906e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=5904
2022-09-28 22:21:32 - progress_bar.py[line:274] - INFO: epoch 001:   5157 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=80.8, ups=0.8, wpb=101.2, bsz=40, num_updates=5150, lr=4.8684e-05, gnorm=1, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5916
2022-09-28 22:21:43 - progress_bar.py[line:274] - INFO: epoch 001:   5167 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=5160, lr=4.86774e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5928
2022-09-28 22:21:54 - progress_bar.py[line:274] - INFO: epoch 001:   5177 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.5, ups=0.89, wpb=102.1, bsz=40, num_updates=5170, lr=4.86708e-05, gnorm=1.147, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5939
2022-09-28 22:22:05 - progress_bar.py[line:274] - INFO: epoch 001:   5187 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.89, wpb=102.1, bsz=40, num_updates=5180, lr=4.86642e-05, gnorm=0.974, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5950
2022-09-28 22:22:17 - progress_bar.py[line:274] - INFO: epoch 001:   5197 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.88, wpb=103.5, bsz=40, num_updates=5190, lr=4.86576e-05, gnorm=0.972, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5962
2022-09-28 22:22:28 - progress_bar.py[line:274] - INFO: epoch 001:   5207 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.88, wpb=101.4, bsz=40, num_updates=5200, lr=4.8651e-05, gnorm=0.944, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5973
2022-09-28 22:22:39 - progress_bar.py[line:274] - INFO: epoch 001:   5217 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.7, ups=0.9, wpb=102.1, bsz=40, num_updates=5210, lr=4.86444e-05, gnorm=1.016, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5984
2022-09-28 22:22:50 - progress_bar.py[line:274] - INFO: epoch 001:   5227 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.5, ups=0.91, wpb=102.7, bsz=40, num_updates=5220, lr=4.86378e-05, gnorm=0.958, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5995
2022-09-28 22:23:02 - progress_bar.py[line:274] - INFO: epoch 001:   5237 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.6, ups=0.86, wpb=101.4, bsz=40, num_updates=5230, lr=4.86312e-05, gnorm=0.867, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=6007
2022-09-28 22:23:13 - progress_bar.py[line:274] - INFO: epoch 001:   5247 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.7, ups=0.88, wpb=101.1, bsz=40, num_updates=5240, lr=4.86246e-05, gnorm=0.999, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6018
2022-09-28 22:23:24 - progress_bar.py[line:274] - INFO: epoch 001:   5257 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.89, wpb=102.1, bsz=40, num_updates=5250, lr=4.8618e-05, gnorm=1.031, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6029
2022-09-28 22:23:35 - progress_bar.py[line:274] - INFO: epoch 001:   5267 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.9, ups=0.93, wpb=100.2, bsz=40, num_updates=5260, lr=4.86114e-05, gnorm=1.077, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6040
2022-09-28 22:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   5277 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=5270, lr=4.86048e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6051
2022-09-28 22:23:58 - progress_bar.py[line:274] - INFO: epoch 001:   5287 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.9, ups=0.9, wpb=101.1, bsz=40, num_updates=5280, lr=4.85982e-05, gnorm=1.103, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6062
2022-09-28 22:24:09 - progress_bar.py[line:274] - INFO: epoch 001:   5297 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.8, ups=0.84, wpb=103, bsz=40, num_updates=5290, lr=4.85916e-05, gnorm=0.982, clip=20, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=6074
2022-09-28 22:24:22 - progress_bar.py[line:274] - INFO: epoch 001:   5307 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=83.9, ups=0.83, wpb=101.3, bsz=40, num_updates=5300, lr=4.8585e-05, gnorm=1.035, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6086
2022-09-28 22:24:33 - progress_bar.py[line:274] - INFO: epoch 001:   5317 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.1, ups=0.89, wpb=100.7, bsz=40, num_updates=5310, lr=4.85784e-05, gnorm=1.022, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6098
2022-09-28 22:24:44 - progress_bar.py[line:274] - INFO: epoch 001:   5327 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.7, ups=0.88, wpb=100.5, bsz=40, num_updates=5320, lr=4.85718e-05, gnorm=0.938, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6109
2022-09-28 22:24:56 - progress_bar.py[line:274] - INFO: epoch 001:   5337 / 15783 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.9, ups=0.87, wpb=100.6, bsz=40, num_updates=5330, lr=4.85652e-05, gnorm=1.025, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6120
2022-09-28 22:25:07 - progress_bar.py[line:274] - INFO: epoch 001:   5347 / 15783 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=86.3, ups=0.87, wpb=98.6, bsz=40, num_updates=5340, lr=4.85586e-05, gnorm=0.959, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6132
2022-09-28 22:25:18 - progress_bar.py[line:274] - INFO: epoch 001:   5357 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=5350, lr=4.8552e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6143
2022-09-28 22:25:29 - progress_bar.py[line:274] - INFO: epoch 001:   5367 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.91, wpb=100.1, bsz=40, num_updates=5360, lr=4.85454e-05, gnorm=0.952, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6154
2022-09-28 22:25:41 - progress_bar.py[line:274] - INFO: epoch 001:   5377 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.8, ups=0.87, wpb=101.2, bsz=40, num_updates=5370, lr=4.85388e-05, gnorm=0.853, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6166
2022-09-28 22:25:52 - progress_bar.py[line:274] - INFO: epoch 001:   5387 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.7, ups=0.89, wpb=100, bsz=40, num_updates=5380, lr=4.85322e-05, gnorm=1.157, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6177
2022-09-28 22:26:03 - progress_bar.py[line:274] - INFO: epoch 001:   5397 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.88, wpb=101.1, bsz=40, num_updates=5390, lr=4.85256e-05, gnorm=1.025, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6188
2022-09-28 22:26:15 - progress_bar.py[line:274] - INFO: epoch 001:   5407 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.2, ups=0.9, wpb=100.4, bsz=40, num_updates=5400, lr=4.8519e-05, gnorm=1.009, clip=50, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6199
2022-09-28 22:26:26 - progress_bar.py[line:274] - INFO: epoch 001:   5417 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.92, wpb=100.2, bsz=40, num_updates=5410, lr=4.85124e-05, gnorm=1.088, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6210
2022-09-28 22:26:37 - progress_bar.py[line:274] - INFO: epoch 001:   5427 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.1, ups=0.88, wpb=100.6, bsz=40, num_updates=5420, lr=4.85058e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6222
2022-09-28 22:26:48 - progress_bar.py[line:274] - INFO: epoch 001:   5437 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=92.5, ups=0.92, wpb=100.2, bsz=40, num_updates=5430, lr=4.84992e-05, gnorm=1.214, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6233
2022-09-28 22:26:59 - progress_bar.py[line:274] - INFO: epoch 001:   5447 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.88, wpb=100.6, bsz=40, num_updates=5440, lr=4.84926e-05, gnorm=0.952, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6244
2022-09-28 22:27:11 - progress_bar.py[line:274] - INFO: epoch 001:   5457 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.1, ups=0.9, wpb=102.4, bsz=40, num_updates=5450, lr=4.8486e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6255
2022-09-28 22:27:22 - progress_bar.py[line:274] - INFO: epoch 001:   5467 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.91, wpb=101.1, bsz=40, num_updates=5460, lr=4.84794e-05, gnorm=0.873, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6266
2022-09-28 22:27:33 - progress_bar.py[line:274] - INFO: epoch 001:   5477 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.7, ups=0.87, wpb=100.5, bsz=40, num_updates=5470, lr=4.84728e-05, gnorm=1.09, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6278
2022-09-28 22:27:45 - progress_bar.py[line:274] - INFO: epoch 001:   5487 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.7, ups=0.86, wpb=100.5, bsz=40, num_updates=5480, lr=4.84662e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=6290
2022-09-28 22:27:56 - progress_bar.py[line:274] - INFO: epoch 001:   5497 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.4, ups=0.89, wpb=99.8, bsz=40, num_updates=5490, lr=4.84596e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6301
2022-09-28 22:28:07 - progress_bar.py[line:274] - INFO: epoch 001:   5507 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.9, ups=0.9, wpb=102.7, bsz=40, num_updates=5500, lr=4.8453e-05, gnorm=0.968, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6312
2022-09-28 22:28:18 - progress_bar.py[line:274] - INFO: epoch 001:   5517 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.89, wpb=101.6, bsz=40, num_updates=5510, lr=4.84464e-05, gnorm=1.047, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6323
2022-09-28 22:28:30 - progress_bar.py[line:274] - INFO: epoch 001:   5527 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.88, wpb=101.8, bsz=40, num_updates=5520, lr=4.84398e-05, gnorm=0.972, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6335
2022-09-28 22:28:41 - progress_bar.py[line:274] - INFO: epoch 001:   5537 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.9, wpb=101, bsz=40, num_updates=5530, lr=4.84332e-05, gnorm=1.008, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=6346
2022-09-28 22:28:52 - progress_bar.py[line:274] - INFO: epoch 001:   5547 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.9, wpb=101.8, bsz=40, num_updates=5540, lr=4.84266e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6357
2022-09-28 22:29:03 - progress_bar.py[line:274] - INFO: epoch 001:   5557 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.89, wpb=102, bsz=40, num_updates=5550, lr=4.842e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6368
2022-09-28 22:29:15 - progress_bar.py[line:274] - INFO: epoch 001:   5567 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.89, wpb=101.4, bsz=40, num_updates=5560, lr=4.84134e-05, gnorm=1.006, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6379
2022-09-28 22:29:26 - progress_bar.py[line:274] - INFO: epoch 001:   5577 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.2, ups=0.88, wpb=101.9, bsz=40, num_updates=5570, lr=4.84068e-05, gnorm=0.951, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6391
2022-09-28 22:29:30 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-28 22:29:38 - progress_bar.py[line:274] - INFO: epoch 001:   5588 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=82.2, ups=0.82, wpb=100.2, bsz=40, num_updates=5580, lr=4.84002e-05, gnorm=0.872, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6403
2022-09-28 22:29:50 - progress_bar.py[line:274] - INFO: epoch 001:   5598 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=101.2, bsz=40, num_updates=5590, lr=4.83936e-05, gnorm=0.925, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6414
2022-09-28 22:30:01 - progress_bar.py[line:274] - INFO: epoch 001:   5608 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88, ups=0.89, wpb=99, bsz=40, num_updates=5600, lr=4.8387e-05, gnorm=0.972, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6426
2022-09-28 22:30:12 - progress_bar.py[line:274] - INFO: epoch 001:   5618 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89, ups=0.88, wpb=100.7, bsz=40, num_updates=5610, lr=4.83804e-05, gnorm=0.893, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6437
2022-09-28 22:30:23 - progress_bar.py[line:274] - INFO: epoch 001:   5628 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=5620, lr=4.83738e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6448
2022-09-28 22:30:35 - progress_bar.py[line:274] - INFO: epoch 001:   5638 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.3, ups=0.87, wpb=101, bsz=40, num_updates=5630, lr=4.83672e-05, gnorm=0.978, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6460
2022-09-28 22:30:46 - progress_bar.py[line:274] - INFO: epoch 001:   5648 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.88, wpb=100.8, bsz=40, num_updates=5640, lr=4.83606e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6471
2022-09-28 22:30:57 - progress_bar.py[line:274] - INFO: epoch 001:   5658 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88, ups=0.88, wpb=100.4, bsz=40, num_updates=5650, lr=4.8354e-05, gnorm=1.043, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6482
2022-09-28 22:31:09 - progress_bar.py[line:274] - INFO: epoch 001:   5668 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90, ups=0.88, wpb=101.9, bsz=40, num_updates=5660, lr=4.83474e-05, gnorm=0.984, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6494
2022-09-28 22:31:20 - progress_bar.py[line:274] - INFO: epoch 001:   5678 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.3, ups=0.86, wpb=101.1, bsz=40, num_updates=5670, lr=4.83408e-05, gnorm=0.887, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6505
2022-09-28 22:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   5688 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.7, ups=0.86, wpb=101.3, bsz=40, num_updates=5680, lr=4.83342e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=6517
2022-09-28 22:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   5698 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.9, ups=0.9, wpb=103, bsz=40, num_updates=5690, lr=4.83276e-05, gnorm=0.972, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6528
2022-09-28 22:31:54 - progress_bar.py[line:274] - INFO: epoch 001:   5708 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=5700, lr=4.8321e-05, gnorm=1.015, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6539
2022-09-28 22:32:06 - progress_bar.py[line:274] - INFO: epoch 001:   5718 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=5710, lr=4.83144e-05, gnorm=0.948, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6550
2022-09-28 22:32:16 - progress_bar.py[line:274] - INFO: epoch 001:   5728 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.9, ups=0.94, wpb=102.4, bsz=40, num_updates=5720, lr=4.83078e-05, gnorm=0.923, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6561
2022-09-28 22:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   5738 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.88, wpb=101.2, bsz=40, num_updates=5730, lr=4.83012e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6572
2022-09-28 22:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.2, ups=0.88, wpb=102, bsz=40, num_updates=5740, lr=4.82946e-05, gnorm=1.057, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6584
2022-09-28 22:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   5758 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.91, wpb=101.7, bsz=40, num_updates=5750, lr=4.8288e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6595
2022-09-28 22:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   5768 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.91, wpb=99.6, bsz=40, num_updates=5760, lr=4.82814e-05, gnorm=1.071, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6606
2022-09-28 22:33:12 - progress_bar.py[line:274] - INFO: epoch 001:   5778 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.9, ups=0.92, wpb=102.7, bsz=40, num_updates=5770, lr=4.82748e-05, gnorm=0.904, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=6617
2022-09-28 22:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   5788 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.88, wpb=100.6, bsz=40, num_updates=5780, lr=4.82682e-05, gnorm=0.979, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6628
2022-09-28 22:33:34 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.6, ups=0.92, wpb=101.6, bsz=40, num_updates=5790, lr=4.82616e-05, gnorm=1.175, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6639
2022-09-28 22:33:45 - progress_bar.py[line:274] - INFO: epoch 001:   5808 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.5, ups=0.9, wpb=103.6, bsz=40, num_updates=5800, lr=4.8255e-05, gnorm=1.052, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6650
2022-09-28 22:33:56 - progress_bar.py[line:274] - INFO: epoch 001:   5818 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.91, wpb=99, bsz=40, num_updates=5810, lr=4.82484e-05, gnorm=0.976, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6661
2022-09-28 22:34:07 - progress_bar.py[line:274] - INFO: epoch 001:   5828 / 15783 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93, ups=0.94, wpb=98.9, bsz=40, num_updates=5820, lr=4.82418e-05, gnorm=1.148, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6672
2022-09-28 22:34:18 - progress_bar.py[line:274] - INFO: epoch 001:   5838 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.89, wpb=100.5, bsz=40, num_updates=5830, lr=4.82352e-05, gnorm=0.966, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6683
2022-09-28 22:34:29 - progress_bar.py[line:274] - INFO: epoch 001:   5848 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.1, ups=0.89, wpb=100.3, bsz=40, num_updates=5840, lr=4.82286e-05, gnorm=1.107, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6694
2022-09-28 22:34:40 - progress_bar.py[line:274] - INFO: epoch 001:   5858 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.9, ups=0.91, wpb=102.2, bsz=40, num_updates=5850, lr=4.8222e-05, gnorm=1.018, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6705
2022-09-28 22:34:52 - progress_bar.py[line:274] - INFO: epoch 001:   5868 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.3, ups=0.88, wpb=99.7, bsz=40, num_updates=5860, lr=4.82154e-05, gnorm=1.192, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6717
2022-09-28 22:35:03 - progress_bar.py[line:274] - INFO: epoch 001:   5878 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.8, ups=0.91, wpb=100.1, bsz=40, num_updates=5870, lr=4.82088e-05, gnorm=1.039, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=6728
2022-09-28 22:35:16 - progress_bar.py[line:274] - INFO: epoch 001:   5888 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=79.3, ups=0.78, wpb=102.2, bsz=40, num_updates=5880, lr=4.82022e-05, gnorm=1.026, clip=70, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=6740
2022-09-28 22:35:29 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=73.9, ups=0.73, wpb=101.3, bsz=40, num_updates=5890, lr=4.81956e-05, gnorm=0.955, clip=50, loss_scale=512, train_wall=14, gb_free=10.3, ema_decay=0.9999, wall=6754
2022-09-28 22:35:41 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.1, ups=0.86, wpb=100.8, bsz=40, num_updates=5900, lr=4.8189e-05, gnorm=1.064, clip=40, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=6766
2022-09-28 22:35:52 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=5910, lr=4.81824e-05, gnorm=1.136, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6777
2022-09-28 22:36:04 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.88, wpb=102.3, bsz=40, num_updates=5920, lr=4.81758e-05, gnorm=1.023, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6788
2022-09-28 22:36:15 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.8, ups=0.9, wpb=101.4, bsz=40, num_updates=5930, lr=4.81692e-05, gnorm=1.075, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6800
2022-09-28 22:36:26 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91, ups=0.89, wpb=102.3, bsz=40, num_updates=5940, lr=4.81626e-05, gnorm=1.073, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=6811
2022-09-28 22:36:37 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.9, wpb=101.7, bsz=40, num_updates=5950, lr=4.8156e-05, gnorm=1.056, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6822
2022-09-28 22:36:49 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=5960, lr=4.81494e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6833
2022-09-28 22:37:00 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.2, ups=0.86, wpb=102.1, bsz=40, num_updates=5970, lr=4.81428e-05, gnorm=1.016, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6845
2022-09-28 22:37:11 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.89, wpb=102.6, bsz=40, num_updates=5980, lr=4.81362e-05, gnorm=1.002, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6856
2022-09-28 22:37:23 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=5990, lr=4.81296e-05, gnorm=0.988, clip=60, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6868
2022-09-28 22:37:34 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.89, wpb=103.2, bsz=40, num_updates=6000, lr=4.8123e-05, gnorm=1.031, clip=30, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=6879
2022-09-28 22:37:34 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-28 22:37:34 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-28 22:37:35 - train.py[line:549] - INFO: 0 / 14103
2022-09-28 22:37:35 - train.py[line:551] - INFO: load:0.73 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-28 22:40:53 - train.py[line:549] - INFO: 200 / 14103
2022-09-28 22:40:53 - train.py[line:551] - INFO: load:0.75 valid_run:197.77 task_valid:188.24 collect_output:8.40
2022-09-28 22:44:03 - train.py[line:549] - INFO: 400 / 14103
2022-09-28 22:44:03 - train.py[line:551] - INFO: load:0.77 valid_run:387.44 task_valid:372.50 collect_output:12.60
2022-09-28 22:47:16 - train.py[line:549] - INFO: 600 / 14103
2022-09-28 22:47:16 - train.py[line:551] - INFO: load:0.81 valid_run:580.54 task_valid:558.22 collect_output:18.67
2022-09-28 22:50:30 - train.py[line:549] - INFO: 800 / 14103
2022-09-28 22:50:30 - train.py[line:551] - INFO: load:0.83 valid_run:775.04 task_valid:746.65 collect_output:23.46
2022-09-28 22:53:47 - train.py[line:549] - INFO: 1000 / 14103
2022-09-28 22:53:47 - train.py[line:551] - INFO: load:0.86 valid_run:971.07 task_valid:935.59 collect_output:29.26
2022-09-28 22:57:00 - train.py[line:549] - INFO: 1200 / 14103
2022-09-28 22:57:00 - train.py[line:551] - INFO: load:0.88 valid_run:1164.97 task_valid:1123.22 collect_output:34.41
2022-09-28 23:00:16 - train.py[line:549] - INFO: 1400 / 14103
2022-09-28 23:00:16 - train.py[line:551] - INFO: load:0.91 valid_run:1360.54 task_valid:1312.95 collect_output:39.13
2022-09-28 23:03:31 - train.py[line:549] - INFO: 1600 / 14103
2022-09-28 23:03:31 - train.py[line:551] - INFO: load:0.93 valid_run:1555.81 task_valid:1503.45 collect_output:42.66
2022-09-28 23:06:45 - train.py[line:549] - INFO: 1800 / 14103
2022-09-28 23:06:45 - train.py[line:551] - INFO: load:0.95 valid_run:1749.63 task_valid:1689.74 collect_output:49.04
2022-09-28 23:09:56 - train.py[line:549] - INFO: 2000 / 14103
2022-09-28 23:09:56 - train.py[line:551] - INFO: load:0.97 valid_run:1939.87 task_valid:1876.27 collect_output:51.60
2022-09-28 23:13:09 - train.py[line:549] - INFO: 2200 / 14103
2022-09-28 23:13:09 - train.py[line:551] - INFO: load:1.00 valid_run:2133.28 task_valid:2063.89 collect_output:56.21
2022-09-28 23:16:22 - train.py[line:549] - INFO: 2400 / 14103
2022-09-28 23:16:22 - train.py[line:551] - INFO: load:1.02 valid_run:2326.35 task_valid:2249.81 collect_output:62.13
2022-09-28 23:19:37 - train.py[line:549] - INFO: 2600 / 14103
2022-09-28 23:19:37 - train.py[line:551] - INFO: load:1.04 valid_run:2520.63 task_valid:2439.65 collect_output:65.39
2022-09-28 23:22:51 - train.py[line:549] - INFO: 2800 / 14103
2022-09-28 23:22:51 - train.py[line:551] - INFO: load:1.07 valid_run:2715.07 task_valid:2626.48 collect_output:71.77
2022-09-28 23:26:05 - train.py[line:549] - INFO: 3000 / 14103
2022-09-28 23:26:05 - train.py[line:551] - INFO: load:1.09 valid_run:2909.26 task_valid:2813.44 collect_output:77.81
2022-09-28 23:29:16 - train.py[line:549] - INFO: 3200 / 14103
2022-09-28 23:29:16 - train.py[line:551] - INFO: load:1.12 valid_run:3100.33 task_valid:2997.20 collect_output:83.91
2022-09-28 23:32:30 - train.py[line:549] - INFO: 3400 / 14103
2022-09-28 23:32:30 - train.py[line:551] - INFO: load:1.14 valid_run:3294.32 task_valid:3182.15 collect_output:91.82
2022-09-28 23:35:44 - train.py[line:549] - INFO: 3600 / 14103
2022-09-28 23:35:44 - train.py[line:551] - INFO: load:1.16 valid_run:3487.97 task_valid:3368.17 collect_output:98.31
2022-09-28 23:38:56 - train.py[line:549] - INFO: 3800 / 14103
2022-09-28 23:38:56 - train.py[line:551] - INFO: load:1.18 valid_run:3679.87 task_valid:3550.94 collect_output:106.28
2022-09-28 23:42:07 - train.py[line:549] - INFO: 4000 / 14103
2022-09-28 23:42:07 - train.py[line:551] - INFO: load:1.21 valid_run:3870.74 task_valid:3734.95 collect_output:111.95
2022-09-28 23:45:19 - train.py[line:549] - INFO: 4200 / 14103
2022-09-28 23:45:19 - train.py[line:551] - INFO: load:1.23 valid_run:4062.33 task_valid:3923.43 collect_output:113.93
2022-09-28 23:48:28 - train.py[line:549] - INFO: 4400 / 14103
2022-09-28 23:48:28 - train.py[line:551] - INFO: load:1.25 valid_run:4251.86 task_valid:4104.85 collect_output:120.88
2022-09-28 23:51:48 - train.py[line:549] - INFO: 4600 / 14103
2022-09-28 23:51:48 - train.py[line:551] - INFO: load:1.28 valid_run:4451.24 task_valid:4295.81 collect_output:128.02
2022-09-28 23:54:58 - train.py[line:549] - INFO: 4800 / 14103
2022-09-28 23:54:58 - train.py[line:551] - INFO: load:1.31 valid_run:4641.21 task_valid:4479.70 collect_output:132.88
2022-09-28 23:58:09 - train.py[line:549] - INFO: 5000 / 14103
2022-09-28 23:58:09 - train.py[line:551] - INFO: load:1.33 valid_run:4831.96 task_valid:4664.64 collect_output:137.50
2022-09-29 00:01:20 - train.py[line:549] - INFO: 5200 / 14103
2022-09-29 00:01:20 - train.py[line:551] - INFO: load:1.36 valid_run:5023.74 task_valid:4850.13 collect_output:142.66
2022-09-29 00:04:36 - train.py[line:549] - INFO: 5400 / 14103
2022-09-29 00:04:36 - train.py[line:551] - INFO: load:1.38 valid_run:5218.82 task_valid:5040.61 collect_output:146.02
2022-09-29 00:07:48 - train.py[line:549] - INFO: 5600 / 14103
2022-09-29 00:07:48 - train.py[line:551] - INFO: load:1.40 valid_run:5411.01 task_valid:5228.08 collect_output:149.60
2022-09-29 00:11:07 - train.py[line:549] - INFO: 5800 / 14103
2022-09-29 00:11:07 - train.py[line:551] - INFO: load:1.43 valid_run:5610.42 task_valid:5418.61 collect_output:157.26
2022-09-29 00:14:16 - train.py[line:549] - INFO: 6000 / 14103
2022-09-29 00:14:16 - train.py[line:551] - INFO: load:1.45 valid_run:5798.71 task_valid:5599.69 collect_output:163.36
2022-09-29 00:17:28 - train.py[line:549] - INFO: 6200 / 14103
2022-09-29 00:17:28 - train.py[line:551] - INFO: load:1.48 valid_run:5990.83 task_valid:5785.31 collect_output:168.76
2022-09-29 00:20:46 - train.py[line:549] - INFO: 6400 / 14103
2022-09-29 00:20:46 - train.py[line:551] - INFO: load:1.51 valid_run:6189.40 task_valid:5975.98 collect_output:175.30
2022-09-29 00:23:59 - train.py[line:549] - INFO: 6600 / 14103
2022-09-29 00:23:59 - train.py[line:551] - INFO: load:1.53 valid_run:6381.57 task_valid:6158.71 collect_output:183.53
2022-09-29 00:27:17 - train.py[line:549] - INFO: 6800 / 14103
2022-09-29 00:27:17 - train.py[line:551] - INFO: load:1.56 valid_run:6579.96 task_valid:6347.46 collect_output:191.75
2022-09-29 00:30:35 - train.py[line:549] - INFO: 7000 / 14103
2022-09-29 00:30:35 - train.py[line:551] - INFO: load:1.60 valid_run:6777.95 task_valid:6539.16 collect_output:196.74
2022-09-29 00:33:49 - train.py[line:549] - INFO: 7200 / 14103
2022-09-29 00:33:49 - train.py[line:551] - INFO: load:1.62 valid_run:6972.04 task_valid:6729.44 collect_output:199.34
2022-09-29 00:37:04 - train.py[line:549] - INFO: 7400 / 14103
2022-09-29 00:37:04 - train.py[line:551] - INFO: load:1.65 valid_run:7166.69 task_valid:6913.12 collect_output:209.09
2022-09-29 00:40:14 - train.py[line:549] - INFO: 7600 / 14103
2022-09-29 00:40:14 - train.py[line:551] - INFO: load:1.68 valid_run:7357.05 task_valid:7094.95 collect_output:216.33
2022-09-29 00:43:33 - train.py[line:549] - INFO: 7800 / 14103
2022-09-29 00:43:33 - train.py[line:551] - INFO: load:1.72 valid_run:7555.51 task_valid:7284.46 collect_output:224.09
2022-09-29 00:46:43 - train.py[line:549] - INFO: 8000 / 14103
2022-09-29 00:46:43 - train.py[line:551] - INFO: load:1.74 valid_run:7745.57 task_valid:7463.97 collect_output:233.57
2022-09-29 00:49:53 - train.py[line:549] - INFO: 8200 / 14103
2022-09-29 00:49:53 - train.py[line:551] - INFO: load:1.76 valid_run:7935.28 task_valid:7647.79 collect_output:238.31
2022-09-29 00:53:02 - train.py[line:549] - INFO: 8400 / 14103
2022-09-29 00:53:02 - train.py[line:551] - INFO: load:1.78 valid_run:8124.57 task_valid:7830.52 collect_output:243.73
2022-09-29 00:56:19 - train.py[line:549] - INFO: 8600 / 14103
2022-09-29 00:56:19 - train.py[line:551] - INFO: load:1.82 valid_run:8320.90 task_valid:8019.12 collect_output:250.15
2022-09-29 00:59:28 - train.py[line:549] - INFO: 8800 / 14103
2022-09-29 00:59:28 - train.py[line:551] - INFO: load:1.84 valid_run:8510.47 task_valid:8204.54 collect_output:253.17
2022-09-29 01:02:44 - train.py[line:549] - INFO: 9000 / 14103
2022-09-29 01:02:44 - train.py[line:551] - INFO: load:1.89 valid_run:8706.31 task_valid:8391.52 collect_output:260.75
2022-09-29 01:05:59 - train.py[line:549] - INFO: 9200 / 14103
2022-09-29 01:05:59 - train.py[line:551] - INFO: load:1.91 valid_run:8901.37 task_valid:8574.59 collect_output:271.52
2022-09-29 01:09:14 - train.py[line:549] - INFO: 9400 / 14103
2022-09-29 01:09:14 - train.py[line:551] - INFO: load:1.93 valid_run:9096.16 task_valid:8762.06 collect_output:277.70
2022-09-29 01:12:26 - train.py[line:549] - INFO: 9600 / 14103
2022-09-29 01:12:26 - train.py[line:551] - INFO: load:1.95 valid_run:9288.08 task_valid:8946.48 collect_output:284.06
2022-09-29 01:15:38 - train.py[line:549] - INFO: 9800 / 14103
2022-09-29 01:15:38 - train.py[line:551] - INFO: load:1.98 valid_run:9479.79 task_valid:9135.19 collect_output:285.93
2022-09-29 01:18:50 - train.py[line:549] - INFO: 10000 / 14103
2022-09-29 01:18:50 - train.py[line:551] - INFO: load:2.00 valid_run:9671.93 task_valid:9323.67 collect_output:288.44
2022-09-29 01:22:06 - train.py[line:549] - INFO: 10200 / 14103
2022-09-29 01:22:06 - train.py[line:551] - INFO: load:2.03 valid_run:9867.87 task_valid:9510.77 collect_output:295.96
2022-09-29 01:25:22 - train.py[line:549] - INFO: 10400 / 14103
2022-09-29 01:25:22 - train.py[line:551] - INFO: load:2.06 valid_run:10063.22 task_valid:9697.09 collect_output:303.79
2022-09-29 01:28:38 - train.py[line:549] - INFO: 10600 / 14103
2022-09-29 01:28:38 - train.py[line:551] - INFO: load:2.08 valid_run:10259.15 task_valid:9881.51 collect_output:314.07
2022-09-29 01:31:51 - train.py[line:549] - INFO: 10800 / 14103
2022-09-29 01:31:51 - train.py[line:551] - INFO: load:2.11 valid_run:10452.44 task_valid:10066.05 collect_output:321.59
2022-09-29 01:35:03 - train.py[line:549] - INFO: 11000 / 14103
2022-09-29 01:35:03 - train.py[line:551] - INFO: load:2.13 valid_run:10644.80 task_valid:10251.70 collect_output:327.08
2022-09-29 01:38:16 - train.py[line:549] - INFO: 11200 / 14103
2022-09-29 01:38:16 - train.py[line:551] - INFO: load:2.15 valid_run:10837.36 task_valid:10436.66 collect_output:333.43
2022-09-29 01:41:32 - train.py[line:549] - INFO: 11400 / 14103
2022-09-29 01:41:32 - train.py[line:551] - INFO: load:2.18 valid_run:11032.94 task_valid:10628.49 collect_output:335.97
2022-09-29 01:44:42 - train.py[line:549] - INFO: 11600 / 14103
2022-09-29 01:44:42 - train.py[line:551] - INFO: load:2.20 valid_run:11223.66 task_valid:10814.00 collect_output:340.02
2022-09-29 01:47:56 - train.py[line:549] - INFO: 11800 / 14103
2022-09-29 01:47:56 - train.py[line:551] - INFO: load:2.23 valid_run:11417.03 task_valid:11001.51 collect_output:344.63
2022-09-29 01:51:06 - train.py[line:549] - INFO: 12000 / 14103
2022-09-29 01:51:06 - train.py[line:551] - INFO: load:2.25 valid_run:11607.43 task_valid:11185.30 collect_output:350.04
2022-09-29 01:54:18 - train.py[line:549] - INFO: 12200 / 14103
2022-09-29 01:54:18 - train.py[line:551] - INFO: load:2.27 valid_run:11798.83 task_valid:11370.75 collect_output:354.88
2022-09-29 01:57:30 - train.py[line:549] - INFO: 12400 / 14103
2022-09-29 01:57:30 - train.py[line:551] - INFO: load:2.30 valid_run:11990.75 task_valid:11556.09 collect_output:360.33
2022-09-29 02:00:41 - train.py[line:549] - INFO: 12600 / 14103
2022-09-29 02:00:41 - train.py[line:551] - INFO: load:2.32 valid_run:12181.98 task_valid:11740.13 collect_output:366.31
2022-09-29 02:03:49 - train.py[line:549] - INFO: 12800 / 14103
2022-09-29 02:03:49 - train.py[line:551] - INFO: load:2.34 valid_run:12369.87 task_valid:11922.75 collect_output:370.42
2022-09-29 02:07:00 - train.py[line:549] - INFO: 13000 / 14103
2022-09-29 02:07:00 - train.py[line:551] - INFO: load:2.37 valid_run:12561.15 task_valid:12106.95 collect_output:376.43
2022-09-29 02:10:11 - train.py[line:549] - INFO: 13200 / 14103
2022-09-29 02:10:11 - train.py[line:551] - INFO: load:2.39 valid_run:12751.92 task_valid:12288.96 collect_output:384.01
2022-09-29 02:13:26 - train.py[line:549] - INFO: 13400 / 14103
2022-09-29 02:13:26 - train.py[line:551] - INFO: load:2.41 valid_run:12947.15 task_valid:12472.31 collect_output:394.67
2022-09-29 02:16:43 - train.py[line:549] - INFO: 13600 / 14103
2022-09-29 02:16:43 - train.py[line:551] - INFO: load:2.44 valid_run:13143.45 task_valid:12657.28 collect_output:404.77
2022-09-29 02:19:55 - train.py[line:549] - INFO: 13800 / 14103
2022-09-29 02:19:55 - train.py[line:551] - INFO: load:2.47 valid_run:13336.07 task_valid:12844.29 collect_output:409.23
2022-09-29 02:23:08 - train.py[line:549] - INFO: 14000 / 14103
2022-09-29 02:23:08 - train.py[line:551] - INFO: load:2.49 valid_run:13528.83 task_valid:13030.19 collect_output:414.89
2022-09-29 02:24:45 - train.py[line:572] - INFO: scores:torch.Size([282060]) preds:torch.Size([282060]) sample_ids:torch.Size([282060])

====================================================================================================
SGG eval:     R @ 50: 0.5865;     R @ 100: 0.6184;     R @ 500: 0.6372;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1174;    mR @ 100: 0.1403;    mR @ 500: 0.1703;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0108) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2511) (attached to:0.0000) (behind:0.2758) (belonging to:0.0000) (between:0.0000) (carrying:0.6488) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.7095) (holding:0.2093) (in:0.3010) (in front of:0.1008) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3468) (of:0.3816) (on:0.9044) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1667) (says:0.0000) (sitting on:0.2131) (standing on:0.0000) (to:0.0000) (under:0.1852) (using:1.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.9806) (wears:0.0000) (with:0.0793) 
--------------------------------------------------------
====================================================================================================

2022-09-29 02:25:05 - train.py[line:486] - INFO: 0.6183986312881135

====================================================================================================
SGG eval:     R @ 50: 0.5865;     R @ 100: 0.6184;     R @ 500: 0.6372;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1174;    mR @ 100: 0.1403;    mR @ 500: 0.1703;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0108) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2511) (attached to:0.0000) (behind:0.2758) (belonging to:0.0000) (between:0.0000) (carrying:0.6488) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.7095) (holding:0.2093) (in:0.3010) (in front of:0.1008) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3468) (of:0.3816) (on:0.9044) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1667) (says:0.0000) (sitting on:0.2131) (standing on:0.0000) (to:0.0000) (under:0.1852) (using:1.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.9806) (wears:0.0000) (with:0.0793) 
--------------------------------------------------------
====================================================================================================

2022-09-29 02:25:06 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.309 | loss_v1 0 | loss_v2 0 | nll_loss 0.111 | ntokens 59.526 | nsentences 20 | sample_size 59.526 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.618399 | ppl 1.08 | vqa_score 0.932 | wps 61.5 | wpb 59.5 | bsz 20 | num_updates 6000
2022-09-29 02:25:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-09-29 02:25:06 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_6000.pt
2022-09-29 02:25:11 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_6000.pt
2022-09-29 02:25:20 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6183986312881135) (writing took 14.17941417102702 seconds)
2022-09-29 02:25:31 - progress_bar.py[line:274] - INFO: epoch 001:   6018 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=0.1, ups=0, wpb=100.9, bsz=40, num_updates=6010, lr=4.81164e-05, gnorm=1.035, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20556
2022-09-29 02:25:42 - progress_bar.py[line:274] - INFO: epoch 001:   6028 / 15783 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=91.7, ups=0.9, wpb=102.2, bsz=40, num_updates=6020, lr=4.81098e-05, gnorm=1.059, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20567
2022-09-29 02:25:54 - progress_bar.py[line:274] - INFO: epoch 001:   6038 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.86, wpb=101.8, bsz=40, num_updates=6030, lr=4.81032e-05, gnorm=0.973, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=20579
2022-09-29 02:26:05 - progress_bar.py[line:274] - INFO: epoch 001:   6048 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=6040, lr=4.80966e-05, gnorm=1.047, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20590
2022-09-29 02:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   6058 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=6050, lr=4.809e-05, gnorm=1.112, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20601
2022-09-29 02:26:28 - progress_bar.py[line:274] - INFO: epoch 001:   6068 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=6060, lr=4.80834e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20613
2022-09-29 02:26:39 - progress_bar.py[line:274] - INFO: epoch 001:   6078 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.88, wpb=100, bsz=40, num_updates=6070, lr=4.80768e-05, gnorm=1.113, clip=60, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20624
2022-09-29 02:26:50 - progress_bar.py[line:274] - INFO: epoch 001:   6088 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.1, ups=0.9, wpb=100.9, bsz=40, num_updates=6080, lr=4.80702e-05, gnorm=1.189, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20635
2022-09-29 02:27:02 - progress_bar.py[line:274] - INFO: epoch 001:   6098 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.87, wpb=103.1, bsz=40, num_updates=6090, lr=4.80636e-05, gnorm=0.961, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20647
2022-09-29 02:27:13 - progress_bar.py[line:274] - INFO: epoch 001:   6108 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.89, wpb=100.1, bsz=40, num_updates=6100, lr=4.8057e-05, gnorm=0.989, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20658
2022-09-29 02:27:24 - progress_bar.py[line:274] - INFO: epoch 001:   6118 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.6, ups=0.88, wpb=99.9, bsz=40, num_updates=6110, lr=4.80504e-05, gnorm=1.005, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20669
2022-09-29 02:27:36 - progress_bar.py[line:274] - INFO: epoch 001:   6128 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.1, ups=0.86, wpb=99.6, bsz=40, num_updates=6120, lr=4.80438e-05, gnorm=1.054, clip=50, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=20681
2022-09-29 02:27:46 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 02:27:49 - progress_bar.py[line:274] - INFO: epoch 001:   6139 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=82, ups=0.8, wpb=102.9, bsz=40, num_updates=6130, lr=4.80372e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=20693
2022-09-29 02:28:00 - progress_bar.py[line:274] - INFO: epoch 001:   6149 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.2, ups=0.9, wpb=101.2, bsz=40, num_updates=6140, lr=4.80306e-05, gnorm=1.104, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20705
2022-09-29 02:28:11 - progress_bar.py[line:274] - INFO: epoch 001:   6159 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.9, wpb=99.9, bsz=40, num_updates=6150, lr=4.8024e-05, gnorm=1.032, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20716
2022-09-29 02:28:22 - progress_bar.py[line:274] - INFO: epoch 001:   6169 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.88, wpb=102.5, bsz=40, num_updates=6160, lr=4.80174e-05, gnorm=0.944, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20727
2022-09-29 02:28:33 - progress_bar.py[line:274] - INFO: epoch 001:   6179 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=6170, lr=4.80108e-05, gnorm=0.96, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20738
2022-09-29 02:28:45 - progress_bar.py[line:274] - INFO: epoch 001:   6189 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.9, wpb=103.6, bsz=40, num_updates=6180, lr=4.80042e-05, gnorm=0.898, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20749
2022-09-29 02:28:56 - progress_bar.py[line:274] - INFO: epoch 001:   6199 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.7, ups=0.88, wpb=103.4, bsz=40, num_updates=6190, lr=4.79976e-05, gnorm=0.921, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20761
2022-09-29 02:29:07 - progress_bar.py[line:274] - INFO: epoch 001:   6209 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=6200, lr=4.7991e-05, gnorm=1.064, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20772
2022-09-29 02:29:18 - progress_bar.py[line:274] - INFO: epoch 001:   6219 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.3, ups=0.9, wpb=99, bsz=40, num_updates=6210, lr=4.79844e-05, gnorm=1.071, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20783
2022-09-29 02:29:29 - progress_bar.py[line:274] - INFO: epoch 001:   6229 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.5, ups=0.9, wpb=102.3, bsz=40, num_updates=6220, lr=4.79778e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20794
2022-09-29 02:29:41 - progress_bar.py[line:274] - INFO: epoch 001:   6239 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.2, ups=0.87, wpb=101.7, bsz=40, num_updates=6230, lr=4.79712e-05, gnorm=1.009, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20806
2022-09-29 02:29:53 - progress_bar.py[line:274] - INFO: epoch 001:   6249 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.4, ups=0.86, wpb=101.3, bsz=40, num_updates=6240, lr=4.79646e-05, gnorm=1.166, clip=60, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=20817
2022-09-29 02:30:03 - progress_bar.py[line:274] - INFO: epoch 001:   6259 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.8, ups=0.92, wpb=102.5, bsz=40, num_updates=6250, lr=4.7958e-05, gnorm=1.019, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=20828
2022-09-29 02:30:15 - progress_bar.py[line:274] - INFO: epoch 001:   6269 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=100.6, bsz=40, num_updates=6260, lr=4.79514e-05, gnorm=0.955, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20840
2022-09-29 02:30:26 - progress_bar.py[line:274] - INFO: epoch 001:   6279 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.88, wpb=101.7, bsz=40, num_updates=6270, lr=4.79448e-05, gnorm=0.855, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=20851
2022-09-29 02:30:37 - progress_bar.py[line:274] - INFO: epoch 001:   6289 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.89, wpb=101.4, bsz=40, num_updates=6280, lr=4.79382e-05, gnorm=1.022, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20862
2022-09-29 02:30:48 - progress_bar.py[line:274] - INFO: epoch 001:   6299 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.92, wpb=100.3, bsz=40, num_updates=6290, lr=4.79316e-05, gnorm=1.007, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20873
2022-09-29 02:30:59 - progress_bar.py[line:274] - INFO: epoch 001:   6309 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.93, wpb=99.7, bsz=40, num_updates=6300, lr=4.7925e-05, gnorm=0.967, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20884
2022-09-29 02:31:10 - progress_bar.py[line:274] - INFO: epoch 001:   6319 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93, ups=0.91, wpb=101.7, bsz=40, num_updates=6310, lr=4.79184e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20895
2022-09-29 02:31:21 - progress_bar.py[line:274] - INFO: epoch 001:   6329 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.9, ups=0.9, wpb=101.6, bsz=40, num_updates=6320, lr=4.79118e-05, gnorm=1.114, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20906
2022-09-29 02:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   6339 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.1, ups=0.89, wpb=101.5, bsz=40, num_updates=6330, lr=4.79052e-05, gnorm=0.925, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20917
2022-09-29 02:31:44 - progress_bar.py[line:274] - INFO: epoch 001:   6349 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=102, bsz=40, num_updates=6340, lr=4.78986e-05, gnorm=0.921, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20929
2022-09-29 02:31:55 - progress_bar.py[line:274] - INFO: epoch 001:   6359 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.7, ups=0.91, wpb=100.5, bsz=40, num_updates=6350, lr=4.7892e-05, gnorm=0.917, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20939
2022-09-29 02:32:06 - progress_bar.py[line:274] - INFO: epoch 001:   6369 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=6360, lr=4.78854e-05, gnorm=1.058, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=20951
2022-09-29 02:32:17 - progress_bar.py[line:274] - INFO: epoch 001:   6379 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.88, wpb=99.8, bsz=40, num_updates=6370, lr=4.78788e-05, gnorm=1.064, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20962
2022-09-29 02:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   6389 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.6, ups=0.93, wpb=101.8, bsz=40, num_updates=6380, lr=4.78722e-05, gnorm=1.063, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20973
2022-09-29 02:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   6399 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.9, wpb=100.6, bsz=40, num_updates=6390, lr=4.78656e-05, gnorm=1.013, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20984
2022-09-29 02:32:51 - progress_bar.py[line:274] - INFO: epoch 001:   6409 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=6400, lr=4.7859e-05, gnorm=0.943, clip=50, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=20996
2022-09-29 02:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   6419 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.3, ups=0.93, wpb=101.9, bsz=40, num_updates=6410, lr=4.78524e-05, gnorm=0.81, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21006
2022-09-29 02:33:13 - progress_bar.py[line:274] - INFO: epoch 001:   6429 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90, ups=0.9, wpb=99.7, bsz=40, num_updates=6420, lr=4.78458e-05, gnorm=1.039, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=21017
2022-09-29 02:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   6439 / 15783 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.9, ups=0.92, wpb=98.7, bsz=40, num_updates=6430, lr=4.78392e-05, gnorm=1.078, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21028
2022-09-29 02:33:34 - progress_bar.py[line:274] - INFO: epoch 001:   6449 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.91, wpb=100.5, bsz=40, num_updates=6440, lr=4.78326e-05, gnorm=0.915, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21039
2022-09-29 02:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   6459 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101.5, bsz=40, num_updates=6450, lr=4.7826e-05, gnorm=0.876, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21051
2022-09-29 02:33:57 - progress_bar.py[line:274] - INFO: epoch 001:   6469 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.5, ups=0.89, wpb=98.8, bsz=40, num_updates=6460, lr=4.78194e-05, gnorm=0.89, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=21062
2022-09-29 02:34:08 - progress_bar.py[line:274] - INFO: epoch 001:   6479 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.3, ups=0.9, wpb=102.8, bsz=40, num_updates=6470, lr=4.78128e-05, gnorm=1.027, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=21073
2022-09-29 02:34:19 - progress_bar.py[line:274] - INFO: epoch 001:   6489 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.4, ups=0.91, wpb=100.1, bsz=40, num_updates=6480, lr=4.78062e-05, gnorm=1.09, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21084
2022-09-29 02:34:31 - progress_bar.py[line:274] - INFO: epoch 001:   6499 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88, ups=0.87, wpb=100.8, bsz=40, num_updates=6490, lr=4.77996e-05, gnorm=0.873, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21095
2022-09-29 02:34:42 - progress_bar.py[line:274] - INFO: epoch 001:   6509 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.8, ups=0.91, wpb=101.7, bsz=40, num_updates=6500, lr=4.7793e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21106
2022-09-29 02:34:52 - progress_bar.py[line:274] - INFO: epoch 001:   6519 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.9, ups=0.93, wpb=101.5, bsz=40, num_updates=6510, lr=4.77864e-05, gnorm=1.037, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21117
2022-09-29 02:35:03 - progress_bar.py[line:274] - INFO: epoch 001:   6529 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.5, ups=0.9, wpb=100.6, bsz=40, num_updates=6520, lr=4.77798e-05, gnorm=1.012, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21128
2022-09-29 02:35:14 - progress_bar.py[line:274] - INFO: epoch 001:   6539 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.4, ups=0.92, wpb=102.3, bsz=40, num_updates=6530, lr=4.77732e-05, gnorm=0.851, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21139
2022-09-29 02:35:25 - progress_bar.py[line:274] - INFO: epoch 001:   6549 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.4, ups=0.89, wpb=100.6, bsz=40, num_updates=6540, lr=4.77666e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21150
2022-09-29 02:35:37 - progress_bar.py[line:274] - INFO: epoch 001:   6559 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.88, wpb=101.9, bsz=40, num_updates=6550, lr=4.776e-05, gnorm=0.837, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21162
2022-09-29 02:35:48 - progress_bar.py[line:274] - INFO: epoch 001:   6569 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.6, ups=0.92, wpb=101.3, bsz=40, num_updates=6560, lr=4.77534e-05, gnorm=0.99, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21173
2022-09-29 02:35:59 - progress_bar.py[line:274] - INFO: epoch 001:   6579 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=100.8, bsz=40, num_updates=6570, lr=4.77468e-05, gnorm=0.918, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21184
2022-09-29 02:36:10 - progress_bar.py[line:274] - INFO: epoch 001:   6589 / 15783 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.7, ups=0.88, wpb=101.1, bsz=40, num_updates=6580, lr=4.77402e-05, gnorm=1.032, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21195
2022-09-29 02:36:22 - progress_bar.py[line:274] - INFO: epoch 001:   6599 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=6590, lr=4.77336e-05, gnorm=0.873, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21207
2022-09-29 02:36:33 - progress_bar.py[line:274] - INFO: epoch 001:   6609 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.88, wpb=100.7, bsz=40, num_updates=6600, lr=4.7727e-05, gnorm=1.062, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21218
2022-09-29 02:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   6619 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=97.7, nsentences=40, sample_size=97.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.4, ups=0.87, wpb=97.7, bsz=40, num_updates=6610, lr=4.77204e-05, gnorm=0.995, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=21229
2022-09-29 02:36:56 - progress_bar.py[line:274] - INFO: epoch 001:   6629 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.1, ups=0.86, wpb=100.8, bsz=40, num_updates=6620, lr=4.77138e-05, gnorm=1.03, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=21241
2022-09-29 02:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   6639 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.9, ups=0.92, wpb=100.1, bsz=40, num_updates=6630, lr=4.77072e-05, gnorm=1.021, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21252
2022-09-29 02:37:19 - progress_bar.py[line:274] - INFO: epoch 001:   6649 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.87, wpb=102.8, bsz=40, num_updates=6640, lr=4.77006e-05, gnorm=1, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21263
2022-09-29 02:37:29 - progress_bar.py[line:274] - INFO: epoch 001:   6659 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95, ups=0.94, wpb=101.6, bsz=40, num_updates=6650, lr=4.7694e-05, gnorm=1.436, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21274
2022-09-29 02:37:41 - progress_bar.py[line:274] - INFO: epoch 001:   6669 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=6660, lr=4.76874e-05, gnorm=1.039, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21285
2022-09-29 02:37:52 - progress_bar.py[line:274] - INFO: epoch 001:   6679 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=102.5, bsz=40, num_updates=6670, lr=4.76808e-05, gnorm=1.012, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=21297
2022-09-29 02:37:58 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 02:38:04 - progress_bar.py[line:274] - INFO: epoch 001:   6690 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=83.1, ups=0.83, wpb=100.1, bsz=40, num_updates=6680, lr=4.76742e-05, gnorm=0.854, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=21309
2022-09-29 02:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   6700 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.8, ups=0.87, wpb=99.2, bsz=40, num_updates=6690, lr=4.76676e-05, gnorm=0.946, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21320
2022-09-29 02:38:27 - progress_bar.py[line:274] - INFO: epoch 001:   6710 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.88, wpb=102.3, bsz=40, num_updates=6700, lr=4.7661e-05, gnorm=0.851, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21332
2022-09-29 02:38:38 - progress_bar.py[line:274] - INFO: epoch 001:   6720 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.87, wpb=101.1, bsz=40, num_updates=6710, lr=4.76544e-05, gnorm=1, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21343
2022-09-29 02:38:49 - progress_bar.py[line:274] - INFO: epoch 001:   6730 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.3, ups=0.91, wpb=101.3, bsz=40, num_updates=6720, lr=4.76478e-05, gnorm=1.018, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21354
2022-09-29 02:39:01 - progress_bar.py[line:274] - INFO: epoch 001:   6740 / 15783 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.6, ups=0.89, wpb=102.4, bsz=40, num_updates=6730, lr=4.76412e-05, gnorm=1.077, clip=70, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=21365
2022-09-29 02:39:12 - progress_bar.py[line:274] - INFO: epoch 001:   6750 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.6, ups=0.88, wpb=101.3, bsz=40, num_updates=6740, lr=4.76346e-05, gnorm=1.076, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21377
2022-09-29 02:39:24 - progress_bar.py[line:274] - INFO: epoch 001:   6760 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.1, ups=0.89, wpb=101.1, bsz=40, num_updates=6750, lr=4.7628e-05, gnorm=1.056, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21388
2022-09-29 02:39:35 - progress_bar.py[line:274] - INFO: epoch 001:   6770 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.6, ups=0.91, wpb=101.5, bsz=40, num_updates=6760, lr=4.76214e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21400
2022-09-29 02:39:46 - progress_bar.py[line:274] - INFO: epoch 001:   6780 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.7, ups=0.92, wpb=101.4, bsz=40, num_updates=6770, lr=4.76148e-05, gnorm=1.064, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21411
2022-09-29 02:39:57 - progress_bar.py[line:274] - INFO: epoch 001:   6790 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.9, wpb=101, bsz=40, num_updates=6780, lr=4.76082e-05, gnorm=0.948, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=21422
2022-09-29 02:40:08 - progress_bar.py[line:274] - INFO: epoch 001:   6800 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.89, wpb=101.3, bsz=40, num_updates=6790, lr=4.76016e-05, gnorm=0.919, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=21433
2022-09-29 02:40:19 - progress_bar.py[line:274] - INFO: epoch 001:   6810 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.9, wpb=102, bsz=40, num_updates=6800, lr=4.7595e-05, gnorm=0.981, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=21444
2022-09-29 02:40:30 - progress_bar.py[line:274] - INFO: epoch 001:   6820 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.9, wpb=101, bsz=40, num_updates=6810, lr=4.75884e-05, gnorm=1.101, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21455
2022-09-29 02:40:41 - progress_bar.py[line:274] - INFO: epoch 001:   6830 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.9, wpb=101.6, bsz=40, num_updates=6820, lr=4.75818e-05, gnorm=0.918, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21466
2022-09-29 02:40:53 - progress_bar.py[line:274] - INFO: epoch 001:   6840 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.89, wpb=102.2, bsz=40, num_updates=6830, lr=4.75752e-05, gnorm=0.788, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21478
2022-09-29 02:41:04 - progress_bar.py[line:274] - INFO: epoch 001:   6850 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.9, wpb=101, bsz=40, num_updates=6840, lr=4.75686e-05, gnorm=1.029, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21489
2022-09-29 02:41:15 - progress_bar.py[line:274] - INFO: epoch 001:   6860 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.9, ups=0.88, wpb=101.2, bsz=40, num_updates=6850, lr=4.7562e-05, gnorm=1.031, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21500
2022-09-29 02:41:28 - progress_bar.py[line:274] - INFO: epoch 001:   6870 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.1, ups=0.85, wpb=101.3, bsz=40, num_updates=6860, lr=4.75554e-05, gnorm=0.919, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=21512
2022-09-29 02:41:40 - progress_bar.py[line:274] - INFO: epoch 001:   6880 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=81.4, ups=0.8, wpb=101.4, bsz=40, num_updates=6870, lr=4.75488e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21525
2022-09-29 02:41:52 - progress_bar.py[line:274] - INFO: epoch 001:   6890 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.4, ups=0.83, wpb=104.2, bsz=40, num_updates=6880, lr=4.75422e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=21537
2022-09-29 02:42:04 - progress_bar.py[line:274] - INFO: epoch 001:   6900 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88, ups=0.86, wpb=101.8, bsz=40, num_updates=6890, lr=4.75356e-05, gnorm=1.008, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=21549
2022-09-29 02:42:15 - progress_bar.py[line:274] - INFO: epoch 001:   6910 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.9, ups=0.89, wpb=100.3, bsz=40, num_updates=6900, lr=4.7529e-05, gnorm=0.88, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21560
2022-09-29 02:42:27 - progress_bar.py[line:274] - INFO: epoch 001:   6920 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=6910, lr=4.75224e-05, gnorm=0.937, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=21571
2022-09-29 02:42:37 - progress_bar.py[line:274] - INFO: epoch 001:   6930 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.7, ups=0.92, wpb=99, bsz=40, num_updates=6920, lr=4.75158e-05, gnorm=0.925, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21582
2022-09-29 02:42:49 - progress_bar.py[line:274] - INFO: epoch 001:   6940 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.9, wpb=100.1, bsz=40, num_updates=6930, lr=4.75092e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21593
2022-09-29 02:43:00 - progress_bar.py[line:274] - INFO: epoch 001:   6950 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.8, ups=0.86, wpb=102.5, bsz=40, num_updates=6940, lr=4.75026e-05, gnorm=0.914, clip=40, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=21605
2022-09-29 02:43:12 - progress_bar.py[line:274] - INFO: epoch 001:   6960 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.8, ups=0.86, wpb=100.5, bsz=40, num_updates=6950, lr=4.7496e-05, gnorm=0.978, clip=50, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=21617
2022-09-29 02:43:23 - progress_bar.py[line:274] - INFO: epoch 001:   6970 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.3, ups=0.9, wpb=100.8, bsz=40, num_updates=6960, lr=4.74894e-05, gnorm=0.94, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21628
2022-09-29 02:43:35 - progress_bar.py[line:274] - INFO: epoch 001:   6980 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.4, ups=0.86, wpb=100.4, bsz=40, num_updates=6970, lr=4.74828e-05, gnorm=0.976, clip=50, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=21640
2022-09-29 02:43:47 - progress_bar.py[line:274] - INFO: epoch 001:   6990 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=83.7, ups=0.84, wpb=99.9, bsz=40, num_updates=6980, lr=4.74762e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=21652
2022-09-29 02:43:59 - progress_bar.py[line:274] - INFO: epoch 001:   7000 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=83.7, ups=0.83, wpb=101, bsz=40, num_updates=6990, lr=4.74696e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=21664
2022-09-29 02:44:11 - progress_bar.py[line:274] - INFO: epoch 001:   7010 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.4, ups=0.86, wpb=102.4, bsz=40, num_updates=7000, lr=4.7463e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=21675
2022-09-29 02:44:22 - progress_bar.py[line:274] - INFO: epoch 001:   7020 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.7, ups=0.87, wpb=101.9, bsz=40, num_updates=7010, lr=4.74564e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=21687
2022-09-29 02:44:33 - progress_bar.py[line:274] - INFO: epoch 001:   7030 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=7020, lr=4.74498e-05, gnorm=0.862, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21698
2022-09-29 02:44:45 - progress_bar.py[line:274] - INFO: epoch 001:   7040 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.89, wpb=100.8, bsz=40, num_updates=7030, lr=4.74432e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21709
2022-09-29 02:44:56 - progress_bar.py[line:274] - INFO: epoch 001:   7050 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.5, ups=0.89, wpb=103.6, bsz=40, num_updates=7040, lr=4.74366e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21721
2022-09-29 02:45:07 - progress_bar.py[line:274] - INFO: epoch 001:   7060 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.87, wpb=102.2, bsz=40, num_updates=7050, lr=4.743e-05, gnorm=0.988, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21732
2022-09-29 02:45:18 - progress_bar.py[line:274] - INFO: epoch 001:   7070 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.6, ups=0.9, wpb=102.6, bsz=40, num_updates=7060, lr=4.74234e-05, gnorm=1.229, clip=20, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=21743
2022-09-29 02:45:29 - progress_bar.py[line:274] - INFO: epoch 001:   7080 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93, ups=0.9, wpb=103.2, bsz=40, num_updates=7070, lr=4.74168e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21754
2022-09-29 02:45:41 - progress_bar.py[line:274] - INFO: epoch 001:   7090 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.89, wpb=100.3, bsz=40, num_updates=7080, lr=4.74102e-05, gnorm=0.848, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21766
2022-09-29 02:45:52 - progress_bar.py[line:274] - INFO: epoch 001:   7100 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.3, ups=0.92, wpb=102.1, bsz=40, num_updates=7090, lr=4.74036e-05, gnorm=0.893, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=21776
2022-09-29 02:46:03 - progress_bar.py[line:274] - INFO: epoch 001:   7110 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.1, ups=0.86, wpb=101.2, bsz=40, num_updates=7100, lr=4.7397e-05, gnorm=1.019, clip=60, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=21788
2022-09-29 02:46:15 - progress_bar.py[line:274] - INFO: epoch 001:   7120 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=7110, lr=4.73904e-05, gnorm=0.986, clip=30, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=21799
2022-09-29 02:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   7130 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.7, ups=0.87, wpb=99.4, bsz=40, num_updates=7120, lr=4.73838e-05, gnorm=0.997, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21811
2022-09-29 02:46:37 - progress_bar.py[line:274] - INFO: epoch 001:   7140 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.89, wpb=100.2, bsz=40, num_updates=7130, lr=4.73772e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=21822
2022-09-29 02:46:49 - progress_bar.py[line:274] - INFO: epoch 001:   7150 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.8, ups=0.86, wpb=101.6, bsz=40, num_updates=7140, lr=4.73706e-05, gnorm=1.059, clip=50, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=21834
2022-09-29 02:47:00 - progress_bar.py[line:274] - INFO: epoch 001:   7160 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.8, ups=0.91, wpb=102.1, bsz=40, num_updates=7150, lr=4.7364e-05, gnorm=0.962, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=21845
2022-09-29 02:47:11 - progress_bar.py[line:274] - INFO: epoch 001:   7170 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.2, ups=0.87, wpb=102.3, bsz=40, num_updates=7160, lr=4.73574e-05, gnorm=0.864, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21856
2022-09-29 02:47:23 - progress_bar.py[line:274] - INFO: epoch 001:   7180 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.2, ups=0.87, wpb=101, bsz=40, num_updates=7170, lr=4.73508e-05, gnorm=0.951, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21868
2022-09-29 02:47:34 - progress_bar.py[line:274] - INFO: epoch 001:   7190 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.9, ups=0.9, wpb=99.7, bsz=40, num_updates=7180, lr=4.73442e-05, gnorm=1.08, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21879
2022-09-29 02:47:45 - progress_bar.py[line:274] - INFO: epoch 001:   7200 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.89, wpb=101.9, bsz=40, num_updates=7190, lr=4.73376e-05, gnorm=0.955, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=21890
2022-09-29 02:47:56 - progress_bar.py[line:274] - INFO: epoch 001:   7210 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=7200, lr=4.7331e-05, gnorm=0.95, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=21901
2022-09-29 02:48:08 - progress_bar.py[line:274] - INFO: epoch 001:   7220 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.88, wpb=101.9, bsz=40, num_updates=7210, lr=4.73244e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21913
2022-09-29 02:48:12 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 02:48:20 - progress_bar.py[line:274] - INFO: epoch 001:   7231 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=81.3, ups=0.8, wpb=102.1, bsz=40, num_updates=7220, lr=4.73178e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=21925
2022-09-29 02:48:31 - progress_bar.py[line:274] - INFO: epoch 001:   7241 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.9, wpb=102.5, bsz=40, num_updates=7230, lr=4.73112e-05, gnorm=0.919, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=21936
2022-09-29 02:48:43 - progress_bar.py[line:274] - INFO: epoch 001:   7251 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=7240, lr=4.73046e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21948
2022-09-29 02:48:54 - progress_bar.py[line:274] - INFO: epoch 001:   7261 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.7, ups=0.91, wpb=101.6, bsz=40, num_updates=7250, lr=4.7298e-05, gnorm=0.97, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=21959
2022-09-29 02:49:05 - progress_bar.py[line:274] - INFO: epoch 001:   7271 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.9, wpb=99.9, bsz=40, num_updates=7260, lr=4.72914e-05, gnorm=0.921, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=21970
2022-09-29 02:49:16 - progress_bar.py[line:274] - INFO: epoch 001:   7281 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.6, ups=0.87, wpb=101.3, bsz=40, num_updates=7270, lr=4.72848e-05, gnorm=1.055, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=21981
2022-09-29 02:49:28 - progress_bar.py[line:274] - INFO: epoch 001:   7291 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.1, ups=0.87, wpb=99.7, bsz=40, num_updates=7280, lr=4.72782e-05, gnorm=1.001, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=21993
2022-09-29 02:49:39 - progress_bar.py[line:274] - INFO: epoch 001:   7301 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.8, ups=0.87, wpb=100.5, bsz=40, num_updates=7290, lr=4.72716e-05, gnorm=0.966, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22004
2022-09-29 02:49:50 - progress_bar.py[line:274] - INFO: epoch 001:   7311 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.9, wpb=100.5, bsz=40, num_updates=7300, lr=4.7265e-05, gnorm=0.925, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22015
2022-09-29 02:50:02 - progress_bar.py[line:274] - INFO: epoch 001:   7321 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.4, ups=0.88, wpb=99.9, bsz=40, num_updates=7310, lr=4.72584e-05, gnorm=0.966, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22027
2022-09-29 02:50:13 - progress_bar.py[line:274] - INFO: epoch 001:   7331 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.89, wpb=99.6, bsz=40, num_updates=7320, lr=4.72518e-05, gnorm=0.924, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=22038
2022-09-29 02:50:25 - progress_bar.py[line:274] - INFO: epoch 001:   7341 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.86, wpb=101.7, bsz=40, num_updates=7330, lr=4.72452e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=22050
2022-09-29 02:50:36 - progress_bar.py[line:274] - INFO: epoch 001:   7351 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.3, ups=0.87, wpb=101.9, bsz=40, num_updates=7340, lr=4.72386e-05, gnorm=1.017, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22061
2022-09-29 02:50:48 - progress_bar.py[line:274] - INFO: epoch 001:   7361 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.7, ups=0.87, wpb=100.5, bsz=40, num_updates=7350, lr=4.7232e-05, gnorm=0.904, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22073
2022-09-29 02:50:59 - progress_bar.py[line:274] - INFO: epoch 001:   7371 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.1, ups=0.91, wpb=101, bsz=40, num_updates=7360, lr=4.72254e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22084
2022-09-29 02:51:10 - progress_bar.py[line:274] - INFO: epoch 001:   7381 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.88, wpb=101.6, bsz=40, num_updates=7370, lr=4.72188e-05, gnorm=1.028, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22095
2022-09-29 02:51:21 - progress_bar.py[line:274] - INFO: epoch 001:   7391 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.89, wpb=102.6, bsz=40, num_updates=7380, lr=4.72122e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=22106
2022-09-29 02:51:32 - progress_bar.py[line:274] - INFO: epoch 001:   7401 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.7, ups=0.9, wpb=103, bsz=40, num_updates=7390, lr=4.72056e-05, gnorm=1.036, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22117
2022-09-29 02:51:44 - progress_bar.py[line:274] - INFO: epoch 001:   7411 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.2, ups=0.88, wpb=101.8, bsz=40, num_updates=7400, lr=4.7199e-05, gnorm=1.081, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22129
2022-09-29 02:51:55 - progress_bar.py[line:274] - INFO: epoch 001:   7421 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.87, wpb=101, bsz=40, num_updates=7410, lr=4.71924e-05, gnorm=0.932, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22140
2022-09-29 02:52:07 - progress_bar.py[line:274] - INFO: epoch 001:   7431 / 15783 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.88, wpb=100.8, bsz=40, num_updates=7420, lr=4.71858e-05, gnorm=1.009, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22151
2022-09-29 02:52:18 - progress_bar.py[line:274] - INFO: epoch 001:   7441 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.6, ups=0.91, wpb=102.6, bsz=40, num_updates=7430, lr=4.71792e-05, gnorm=1.054, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=22162
2022-09-29 02:52:29 - progress_bar.py[line:274] - INFO: epoch 001:   7451 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=7440, lr=4.71726e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22174
2022-09-29 02:52:40 - progress_bar.py[line:274] - INFO: epoch 001:   7461 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=7450, lr=4.7166e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22185
2022-09-29 02:52:51 - progress_bar.py[line:274] - INFO: epoch 001:   7471 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.88, wpb=103.1, bsz=40, num_updates=7460, lr=4.71594e-05, gnorm=1.03, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=22196
2022-09-29 02:53:03 - progress_bar.py[line:274] - INFO: epoch 001:   7481 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.89, wpb=100.2, bsz=40, num_updates=7470, lr=4.71528e-05, gnorm=0.946, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22208
2022-09-29 02:53:14 - progress_bar.py[line:274] - INFO: epoch 001:   7491 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.88, wpb=100.9, bsz=40, num_updates=7480, lr=4.71462e-05, gnorm=1.008, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22219
2022-09-29 02:53:25 - progress_bar.py[line:274] - INFO: epoch 001:   7501 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101.6, bsz=40, num_updates=7490, lr=4.71396e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22230
2022-09-29 02:53:37 - progress_bar.py[line:274] - INFO: epoch 001:   7511 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.88, wpb=101.4, bsz=40, num_updates=7500, lr=4.7133e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22241
2022-09-29 02:53:48 - progress_bar.py[line:274] - INFO: epoch 001:   7521 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=87.6, ups=0.88, wpb=99.8, bsz=40, num_updates=7510, lr=4.71264e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22253
2022-09-29 02:54:00 - progress_bar.py[line:274] - INFO: epoch 001:   7531 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.7, ups=0.86, wpb=100.5, bsz=40, num_updates=7520, lr=4.71198e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=22264
2022-09-29 02:54:11 - progress_bar.py[line:274] - INFO: epoch 001:   7541 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92, ups=0.9, wpb=102.4, bsz=40, num_updates=7530, lr=4.71132e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22275
2022-09-29 02:54:21 - progress_bar.py[line:274] - INFO: epoch 001:   7551 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.5, ups=0.95, wpb=102.8, bsz=40, num_updates=7540, lr=4.71066e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=10, gb_free=10.4, ema_decay=0.9999, wall=22286
2022-09-29 02:54:32 - progress_bar.py[line:274] - INFO: epoch 001:   7561 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=7550, lr=4.71e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22297
2022-09-29 02:54:44 - progress_bar.py[line:274] - INFO: epoch 001:   7571 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.9, wpb=100.2, bsz=40, num_updates=7560, lr=4.70934e-05, gnorm=0.95, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22308
2022-09-29 02:54:55 - progress_bar.py[line:274] - INFO: epoch 001:   7581 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.89, wpb=99.5, bsz=40, num_updates=7570, lr=4.70868e-05, gnorm=0.912, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22320
2022-09-29 02:55:06 - progress_bar.py[line:274] - INFO: epoch 001:   7591 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.9, ups=0.87, wpb=101.6, bsz=40, num_updates=7580, lr=4.70802e-05, gnorm=1.052, clip=50, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=22331
2022-09-29 02:55:17 - progress_bar.py[line:274] - INFO: epoch 001:   7601 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=94.7, ups=0.92, wpb=102.8, bsz=40, num_updates=7590, lr=4.70736e-05, gnorm=0.893, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22342
2022-09-29 02:55:28 - progress_bar.py[line:274] - INFO: epoch 001:   7611 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.91, wpb=99.9, bsz=40, num_updates=7600, lr=4.7067e-05, gnorm=0.907, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22353
2022-09-29 02:55:39 - progress_bar.py[line:274] - INFO: epoch 001:   7621 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.91, wpb=100, bsz=40, num_updates=7610, lr=4.70604e-05, gnorm=0.931, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=22364
2022-09-29 02:55:51 - progress_bar.py[line:274] - INFO: epoch 001:   7631 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.8, ups=0.88, wpb=101.3, bsz=40, num_updates=7620, lr=4.70538e-05, gnorm=0.983, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22376
2022-09-29 02:56:02 - progress_bar.py[line:274] - INFO: epoch 001:   7641 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.1, ups=0.86, wpb=102.3, bsz=40, num_updates=7630, lr=4.70472e-05, gnorm=1.025, clip=60, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=22387
2022-09-29 02:56:13 - progress_bar.py[line:274] - INFO: epoch 001:   7651 / 15783 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.1, ups=0.91, wpb=101.9, bsz=40, num_updates=7640, lr=4.70406e-05, gnorm=1.03, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22398
2022-09-29 02:56:25 - progress_bar.py[line:274] - INFO: epoch 001:   7661 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.87, wpb=103.9, bsz=40, num_updates=7650, lr=4.7034e-05, gnorm=0.947, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22410
2022-09-29 02:56:36 - progress_bar.py[line:274] - INFO: epoch 001:   7671 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92, ups=0.91, wpb=101.3, bsz=40, num_updates=7660, lr=4.70274e-05, gnorm=1.108, clip=70, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=22421
2022-09-29 02:56:47 - progress_bar.py[line:274] - INFO: epoch 001:   7681 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.4, ups=0.89, wpb=101.9, bsz=40, num_updates=7670, lr=4.70208e-05, gnorm=0.983, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22432
2022-09-29 02:56:58 - progress_bar.py[line:274] - INFO: epoch 001:   7691 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=93.6, ups=0.93, wpb=101.1, bsz=40, num_updates=7680, lr=4.70142e-05, gnorm=1.003, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22443
2022-09-29 02:57:10 - progress_bar.py[line:274] - INFO: epoch 001:   7701 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.1, ups=0.87, wpb=100.8, bsz=40, num_updates=7690, lr=4.70076e-05, gnorm=0.987, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22454
2022-09-29 02:57:21 - progress_bar.py[line:274] - INFO: epoch 001:   7711 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.9, wpb=101.2, bsz=40, num_updates=7700, lr=4.7001e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22465
2022-09-29 02:57:32 - progress_bar.py[line:274] - INFO: epoch 001:   7721 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=7710, lr=4.69944e-05, gnorm=0.908, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22477
2022-09-29 02:57:44 - progress_bar.py[line:274] - INFO: epoch 001:   7731 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.87, wpb=102, bsz=40, num_updates=7720, lr=4.69878e-05, gnorm=0.973, clip=50, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=22488
2022-09-29 02:57:55 - progress_bar.py[line:274] - INFO: epoch 001:   7741 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.9, wpb=100.5, bsz=40, num_updates=7730, lr=4.69812e-05, gnorm=1.105, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22500
2022-09-29 02:58:06 - progress_bar.py[line:274] - INFO: epoch 001:   7751 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.5, ups=0.89, wpb=101.9, bsz=40, num_updates=7740, lr=4.69746e-05, gnorm=0.918, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22511
2022-09-29 02:58:17 - progress_bar.py[line:274] - INFO: epoch 001:   7761 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.89, wpb=100.9, bsz=40, num_updates=7750, lr=4.6968e-05, gnorm=0.898, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=22522
2022-09-29 02:58:28 - progress_bar.py[line:274] - INFO: epoch 001:   7771 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94, ups=0.93, wpb=101, bsz=40, num_updates=7760, lr=4.69614e-05, gnorm=0.914, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=22533
2022-09-29 02:58:39 - progress_bar.py[line:274] - INFO: epoch 001:   7781 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.9, ups=0.87, wpb=100.5, bsz=40, num_updates=7770, lr=4.69548e-05, gnorm=0.974, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22544
2022-09-29 02:58:50 - progress_bar.py[line:274] - INFO: epoch 001:   7791 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.3, ups=0.91, wpb=100.4, bsz=40, num_updates=7780, lr=4.69482e-05, gnorm=1.074, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22555
2022-09-29 02:59:02 - progress_bar.py[line:274] - INFO: epoch 001:   7801 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.88, wpb=101.5, bsz=40, num_updates=7790, lr=4.69416e-05, gnorm=0.866, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=22567
2022-09-29 02:59:13 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 02:59:14 - progress_bar.py[line:274] - INFO: epoch 001:   7812 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=82.2, ups=0.81, wpb=101.3, bsz=40, num_updates=7800, lr=4.6935e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=22579
2022-09-29 02:59:26 - progress_bar.py[line:274] - INFO: epoch 001:   7822 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=7810, lr=4.69284e-05, gnorm=0.937, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22590
2022-09-29 02:59:37 - progress_bar.py[line:274] - INFO: epoch 001:   7832 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.9, wpb=101.1, bsz=40, num_updates=7820, lr=4.69218e-05, gnorm=1.021, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22602
2022-09-29 02:59:48 - progress_bar.py[line:274] - INFO: epoch 001:   7842 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.86, wpb=103, bsz=40, num_updates=7830, lr=4.69152e-05, gnorm=0.814, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=22613
2022-09-29 03:00:00 - progress_bar.py[line:274] - INFO: epoch 001:   7852 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.1, ups=0.86, wpb=101.3, bsz=40, num_updates=7840, lr=4.69086e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=22625
2022-09-29 03:00:11 - progress_bar.py[line:274] - INFO: epoch 001:   7862 / 15783 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.9, ups=0.91, wpb=100, bsz=40, num_updates=7850, lr=4.6902e-05, gnorm=0.978, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22636
2022-09-29 03:00:22 - progress_bar.py[line:274] - INFO: epoch 001:   7872 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.7, ups=0.9, wpb=102, bsz=40, num_updates=7860, lr=4.68954e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22647
2022-09-29 03:00:33 - progress_bar.py[line:274] - INFO: epoch 001:   7882 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.88, wpb=100.3, bsz=40, num_updates=7870, lr=4.68888e-05, gnorm=0.772, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22658
2022-09-29 03:00:45 - progress_bar.py[line:274] - INFO: epoch 001:   7892 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.89, wpb=101.6, bsz=40, num_updates=7880, lr=4.68822e-05, gnorm=0.841, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22670
2022-09-29 03:00:56 - progress_bar.py[line:274] - INFO: epoch 001:   7902 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.5, ups=0.91, wpb=103.2, bsz=40, num_updates=7890, lr=4.68756e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=22681
2022-09-29 03:01:07 - progress_bar.py[line:274] - INFO: epoch 001:   7912 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.88, wpb=101.6, bsz=40, num_updates=7900, lr=4.6869e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22692
2022-09-29 03:01:18 - progress_bar.py[line:274] - INFO: epoch 001:   7922 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.5, ups=0.9, wpb=103.1, bsz=40, num_updates=7910, lr=4.68624e-05, gnorm=0.957, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22703
2022-09-29 03:01:29 - progress_bar.py[line:274] - INFO: epoch 001:   7932 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=100.7, bsz=40, num_updates=7920, lr=4.68558e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22714
2022-09-29 03:01:40 - progress_bar.py[line:274] - INFO: epoch 001:   7942 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.1, ups=0.91, wpb=101.6, bsz=40, num_updates=7930, lr=4.68492e-05, gnorm=1.094, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=22725
2022-09-29 03:01:52 - progress_bar.py[line:274] - INFO: epoch 001:   7952 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.89, wpb=101.4, bsz=40, num_updates=7940, lr=4.68426e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22736
2022-09-29 03:02:02 - progress_bar.py[line:274] - INFO: epoch 001:   7962 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.7, ups=0.93, wpb=102.3, bsz=40, num_updates=7950, lr=4.6836e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22747
2022-09-29 03:02:13 - progress_bar.py[line:274] - INFO: epoch 001:   7972 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.92, wpb=101.6, bsz=40, num_updates=7960, lr=4.68294e-05, gnorm=1.012, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=22758
2022-09-29 03:02:25 - progress_bar.py[line:274] - INFO: epoch 001:   7982 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90, ups=0.89, wpb=101.4, bsz=40, num_updates=7970, lr=4.68228e-05, gnorm=0.993, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22769
2022-09-29 03:02:35 - progress_bar.py[line:274] - INFO: epoch 001:   7992 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.4, ups=0.93, wpb=100.5, bsz=40, num_updates=7980, lr=4.68162e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22780
2022-09-29 03:02:48 - progress_bar.py[line:274] - INFO: epoch 001:   8002 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=82.6, ups=0.8, wpb=103.6, bsz=40, num_updates=7990, lr=4.68096e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=22793
2022-09-29 03:03:01 - progress_bar.py[line:274] - INFO: epoch 001:   8012 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=81.3, ups=0.79, wpb=103.2, bsz=40, num_updates=8000, lr=4.6803e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=22805
2022-09-29 03:03:11 - progress_bar.py[line:274] - INFO: epoch 001:   8022 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.7, ups=0.91, wpb=101.4, bsz=40, num_updates=8010, lr=4.67964e-05, gnorm=0.851, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22816
2022-09-29 03:03:22 - progress_bar.py[line:274] - INFO: epoch 001:   8032 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.4, ups=0.92, wpb=102.3, bsz=40, num_updates=8020, lr=4.67898e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22827
2022-09-29 03:03:34 - progress_bar.py[line:274] - INFO: epoch 001:   8042 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.89, wpb=102.8, bsz=40, num_updates=8030, lr=4.67832e-05, gnorm=1.056, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22838
2022-09-29 03:03:45 - progress_bar.py[line:274] - INFO: epoch 001:   8052 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.8, ups=0.91, wpb=99.7, bsz=40, num_updates=8040, lr=4.67766e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22849
2022-09-29 03:03:56 - progress_bar.py[line:274] - INFO: epoch 001:   8062 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.6, ups=0.87, wpb=101.1, bsz=40, num_updates=8050, lr=4.677e-05, gnorm=0.913, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22861
2022-09-29 03:04:07 - progress_bar.py[line:274] - INFO: epoch 001:   8072 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.7, ups=0.9, wpb=102.5, bsz=40, num_updates=8060, lr=4.67634e-05, gnorm=0.99, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22872
2022-09-29 03:04:19 - progress_bar.py[line:274] - INFO: epoch 001:   8082 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.6, ups=0.88, wpb=99.5, bsz=40, num_updates=8070, lr=4.67568e-05, gnorm=1.045, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22883
2022-09-29 03:04:30 - progress_bar.py[line:274] - INFO: epoch 001:   8092 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.6, ups=0.86, wpb=100.9, bsz=40, num_updates=8080, lr=4.67502e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=22895
2022-09-29 03:04:41 - progress_bar.py[line:274] - INFO: epoch 001:   8102 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.9, wpb=101.8, bsz=40, num_updates=8090, lr=4.67436e-05, gnorm=0.835, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22906
2022-09-29 03:04:52 - progress_bar.py[line:274] - INFO: epoch 001:   8112 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.7, ups=0.9, wpb=100.6, bsz=40, num_updates=8100, lr=4.6737e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22917
2022-09-29 03:05:04 - progress_bar.py[line:274] - INFO: epoch 001:   8122 / 15783 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=8110, lr=4.67304e-05, gnorm=0.971, clip=30, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=22928
2022-09-29 03:05:15 - progress_bar.py[line:274] - INFO: epoch 001:   8132 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.89, wpb=100.5, bsz=40, num_updates=8120, lr=4.67238e-05, gnorm=0.952, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22940
2022-09-29 03:05:26 - progress_bar.py[line:274] - INFO: epoch 001:   8142 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90, ups=0.89, wpb=100.8, bsz=40, num_updates=8130, lr=4.67172e-05, gnorm=0.884, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22951
2022-09-29 03:05:37 - progress_bar.py[line:274] - INFO: epoch 001:   8152 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.7, ups=0.93, wpb=102.5, bsz=40, num_updates=8140, lr=4.67106e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=22962
2022-09-29 03:05:48 - progress_bar.py[line:274] - INFO: epoch 001:   8162 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.89, wpb=102.9, bsz=40, num_updates=8150, lr=4.6704e-05, gnorm=0.783, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=22973
2022-09-29 03:05:59 - progress_bar.py[line:274] - INFO: epoch 001:   8172 / 15783 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.9, ups=0.9, wpb=100.7, bsz=40, num_updates=8160, lr=4.66974e-05, gnorm=0.944, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=22984
2022-09-29 03:06:11 - progress_bar.py[line:274] - INFO: epoch 001:   8182 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.88, wpb=101.7, bsz=40, num_updates=8170, lr=4.66908e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=22995
2022-09-29 03:06:21 - progress_bar.py[line:274] - INFO: epoch 001:   8192 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.9, ups=0.91, wpb=100.8, bsz=40, num_updates=8180, lr=4.66842e-05, gnorm=0.942, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23006
2022-09-29 03:06:33 - progress_bar.py[line:274] - INFO: epoch 001:   8202 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=8190, lr=4.66776e-05, gnorm=0.852, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23018
2022-09-29 03:06:44 - progress_bar.py[line:274] - INFO: epoch 001:   8212 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.4, ups=0.92, wpb=101.7, bsz=40, num_updates=8200, lr=4.6671e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23029
2022-09-29 03:06:55 - progress_bar.py[line:274] - INFO: epoch 001:   8222 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.5, ups=0.91, wpb=102.5, bsz=40, num_updates=8210, lr=4.66644e-05, gnorm=0.924, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23039
2022-09-29 03:07:05 - progress_bar.py[line:274] - INFO: epoch 001:   8232 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=93.3, ups=0.94, wpb=99.2, bsz=40, num_updates=8220, lr=4.66578e-05, gnorm=0.888, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23050
2022-09-29 03:07:17 - progress_bar.py[line:274] - INFO: epoch 001:   8242 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.2, ups=0.88, wpb=101.6, bsz=40, num_updates=8230, lr=4.66512e-05, gnorm=0.788, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23061
2022-09-29 03:07:28 - progress_bar.py[line:274] - INFO: epoch 001:   8252 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.7, ups=0.87, wpb=102.1, bsz=40, num_updates=8240, lr=4.66446e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23073
2022-09-29 03:07:39 - progress_bar.py[line:274] - INFO: epoch 001:   8262 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.5, ups=0.94, wpb=101.6, bsz=40, num_updates=8250, lr=4.6638e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=23084
2022-09-29 03:07:50 - progress_bar.py[line:274] - INFO: epoch 001:   8272 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.4, ups=0.87, wpb=99.7, bsz=40, num_updates=8260, lr=4.66314e-05, gnorm=0.938, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23095
2022-09-29 03:08:01 - progress_bar.py[line:274] - INFO: epoch 001:   8282 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.6, ups=0.92, wpb=99.9, bsz=40, num_updates=8270, lr=4.66248e-05, gnorm=0.848, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23106
2022-09-29 03:08:13 - progress_bar.py[line:274] - INFO: epoch 001:   8292 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.88, wpb=103.3, bsz=40, num_updates=8280, lr=4.66182e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23118
2022-09-29 03:08:24 - progress_bar.py[line:274] - INFO: epoch 001:   8302 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.88, wpb=102.3, bsz=40, num_updates=8290, lr=4.66116e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23129
2022-09-29 03:08:35 - progress_bar.py[line:274] - INFO: epoch 001:   8312 / 15783 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.7, ups=0.89, wpb=98.7, bsz=40, num_updates=8300, lr=4.6605e-05, gnorm=1.026, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23140
2022-09-29 03:08:46 - progress_bar.py[line:274] - INFO: epoch 001:   8322 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.3, ups=0.92, wpb=101.7, bsz=40, num_updates=8310, lr=4.65984e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23151
2022-09-29 03:08:57 - progress_bar.py[line:274] - INFO: epoch 001:   8332 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.6, ups=0.9, wpb=102.4, bsz=40, num_updates=8320, lr=4.65918e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23162
2022-09-29 03:09:09 - progress_bar.py[line:274] - INFO: epoch 001:   8342 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.6, ups=0.88, wpb=100.1, bsz=40, num_updates=8330, lr=4.65852e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23174
2022-09-29 03:09:20 - progress_bar.py[line:274] - INFO: epoch 001:   8352 / 15783 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91, ups=0.91, wpb=100.5, bsz=40, num_updates=8340, lr=4.65786e-05, gnorm=1.019, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23185
2022-09-29 03:09:31 - progress_bar.py[line:274] - INFO: epoch 001:   8362 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.9, ups=0.87, wpb=101.5, bsz=40, num_updates=8350, lr=4.6572e-05, gnorm=0.915, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23196
2022-09-29 03:09:34 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 03:09:44 - progress_bar.py[line:274] - INFO: epoch 001:   8373 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=80.1, ups=0.8, wpb=100.5, bsz=40, num_updates=8360, lr=4.65654e-05, gnorm=0.899, clip=40, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=23209
2022-09-29 03:09:56 - progress_bar.py[line:274] - INFO: epoch 001:   8383 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.2, ups=0.84, wpb=102.7, bsz=40, num_updates=8370, lr=4.65588e-05, gnorm=0.926, clip=50, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=23221
2022-09-29 03:10:10 - progress_bar.py[line:274] - INFO: epoch 001:   8393 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.9, wpb=100.4, bsz=40, num_updates=8380, lr=4.65522e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=23232
2022-09-29 03:10:21 - progress_bar.py[line:274] - INFO: epoch 001:   8403 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91, ups=0.9, wpb=101.6, bsz=40, num_updates=8390, lr=4.65456e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23246
2022-09-29 03:10:32 - progress_bar.py[line:274] - INFO: epoch 001:   8413 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.7, ups=0.88, wpb=99.5, bsz=40, num_updates=8400, lr=4.6539e-05, gnorm=0.975, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23257
2022-09-29 03:10:43 - progress_bar.py[line:274] - INFO: epoch 001:   8423 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=102.2, bsz=40, num_updates=8410, lr=4.65324e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23268
2022-09-29 03:10:55 - progress_bar.py[line:274] - INFO: epoch 001:   8433 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.7, ups=0.88, wpb=99.7, bsz=40, num_updates=8420, lr=4.65258e-05, gnorm=1.037, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23280
2022-09-29 03:11:06 - progress_bar.py[line:274] - INFO: epoch 001:   8443 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.88, wpb=101.8, bsz=40, num_updates=8430, lr=4.65192e-05, gnorm=0.795, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23291
2022-09-29 03:11:18 - progress_bar.py[line:274] - INFO: epoch 001:   8453 / 15783 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.2, ups=0.88, wpb=100.3, bsz=40, num_updates=8440, lr=4.65126e-05, gnorm=0.939, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23302
2022-09-29 03:11:29 - progress_bar.py[line:274] - INFO: epoch 001:   8463 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.6, ups=0.88, wpb=102.3, bsz=40, num_updates=8450, lr=4.6506e-05, gnorm=0.853, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23314
2022-09-29 03:11:40 - progress_bar.py[line:274] - INFO: epoch 001:   8473 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.4, ups=0.93, wpb=101.4, bsz=40, num_updates=8460, lr=4.64994e-05, gnorm=0.924, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23325
2022-09-29 03:11:51 - progress_bar.py[line:274] - INFO: epoch 001:   8483 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.89, wpb=100.9, bsz=40, num_updates=8470, lr=4.64928e-05, gnorm=0.887, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23336
2022-09-29 03:12:02 - progress_bar.py[line:274] - INFO: epoch 001:   8493 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.4, ups=0.92, wpb=100.6, bsz=40, num_updates=8480, lr=4.64862e-05, gnorm=0.904, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23347
2022-09-29 03:12:13 - progress_bar.py[line:274] - INFO: epoch 001:   8503 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.3, ups=0.89, wpb=99.5, bsz=40, num_updates=8490, lr=4.64796e-05, gnorm=0.903, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23358
2022-09-29 03:12:24 - progress_bar.py[line:274] - INFO: epoch 001:   8513 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.2, ups=0.92, wpb=102.6, bsz=40, num_updates=8500, lr=4.6473e-05, gnorm=0.869, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=23369
2022-09-29 03:12:35 - progress_bar.py[line:274] - INFO: epoch 001:   8523 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.9, wpb=102.2, bsz=40, num_updates=8510, lr=4.64664e-05, gnorm=0.963, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23380
2022-09-29 03:12:46 - progress_bar.py[line:274] - INFO: epoch 001:   8533 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.3, ups=0.89, wpb=100.4, bsz=40, num_updates=8520, lr=4.64598e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23391
2022-09-29 03:12:58 - progress_bar.py[line:274] - INFO: epoch 001:   8543 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=8530, lr=4.64532e-05, gnorm=0.932, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23402
2022-09-29 03:13:09 - progress_bar.py[line:274] - INFO: epoch 001:   8553 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.3, ups=0.91, wpb=102.1, bsz=40, num_updates=8540, lr=4.64466e-05, gnorm=0.804, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23413
2022-09-29 03:13:20 - progress_bar.py[line:274] - INFO: epoch 001:   8563 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.9, wpb=101.1, bsz=40, num_updates=8550, lr=4.644e-05, gnorm=0.806, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23425
2022-09-29 03:13:31 - progress_bar.py[line:274] - INFO: epoch 001:   8573 / 15783 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87.3, ups=0.88, wpb=99.5, bsz=40, num_updates=8560, lr=4.64334e-05, gnorm=1.011, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=23436
2022-09-29 03:13:42 - progress_bar.py[line:274] - INFO: epoch 001:   8583 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.91, wpb=100, bsz=40, num_updates=8570, lr=4.64268e-05, gnorm=0.929, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23447
2022-09-29 03:13:53 - progress_bar.py[line:274] - INFO: epoch 001:   8593 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.8, ups=0.92, wpb=101.2, bsz=40, num_updates=8580, lr=4.64202e-05, gnorm=0.946, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23458
2022-09-29 03:14:04 - progress_bar.py[line:274] - INFO: epoch 001:   8603 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.9, ups=0.91, wpb=102.9, bsz=40, num_updates=8590, lr=4.64136e-05, gnorm=0.89, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23469
2022-09-29 03:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   8613 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.89, wpb=102.9, bsz=40, num_updates=8600, lr=4.6407e-05, gnorm=0.851, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23480
2022-09-29 03:14:27 - progress_bar.py[line:274] - INFO: epoch 001:   8623 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=82.3, ups=0.82, wpb=100.7, bsz=40, num_updates=8610, lr=4.64004e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=23492
2022-09-29 03:14:39 - progress_bar.py[line:274] - INFO: epoch 001:   8633 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.88, wpb=102.9, bsz=40, num_updates=8620, lr=4.63938e-05, gnorm=0.84, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23504
2022-09-29 03:14:50 - progress_bar.py[line:274] - INFO: epoch 001:   8643 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=8630, lr=4.63872e-05, gnorm=0.956, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23515
2022-09-29 03:15:01 - progress_bar.py[line:274] - INFO: epoch 001:   8653 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.5, ups=0.91, wpb=101.2, bsz=40, num_updates=8640, lr=4.63806e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23526
2022-09-29 03:15:12 - progress_bar.py[line:274] - INFO: epoch 001:   8663 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.9, wpb=101.5, bsz=40, num_updates=8650, lr=4.6374e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23537
2022-09-29 03:15:23 - progress_bar.py[line:274] - INFO: epoch 001:   8673 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.91, wpb=101.4, bsz=40, num_updates=8660, lr=4.63674e-05, gnorm=0.927, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23548
2022-09-29 03:15:34 - progress_bar.py[line:274] - INFO: epoch 001:   8683 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.8, ups=0.91, wpb=100.5, bsz=40, num_updates=8670, lr=4.63608e-05, gnorm=0.898, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23559
2022-09-29 03:15:46 - progress_bar.py[line:274] - INFO: epoch 001:   8693 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.8, ups=0.86, wpb=101.7, bsz=40, num_updates=8680, lr=4.63542e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=23570
2022-09-29 03:15:57 - progress_bar.py[line:274] - INFO: epoch 001:   8703 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.87, wpb=102.9, bsz=40, num_updates=8690, lr=4.63476e-05, gnorm=0.961, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23582
2022-09-29 03:16:09 - progress_bar.py[line:274] - INFO: epoch 001:   8713 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.87, wpb=103.2, bsz=40, num_updates=8700, lr=4.6341e-05, gnorm=0.989, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23593
2022-09-29 03:16:19 - progress_bar.py[line:274] - INFO: epoch 001:   8723 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.3, ups=0.93, wpb=103.3, bsz=40, num_updates=8710, lr=4.63344e-05, gnorm=0.745, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=23604
2022-09-29 03:16:31 - progress_bar.py[line:274] - INFO: epoch 001:   8733 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.2, bsz=40, num_updates=8720, lr=4.63278e-05, gnorm=0.958, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23615
2022-09-29 03:16:42 - progress_bar.py[line:274] - INFO: epoch 001:   8743 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.9, wpb=101, bsz=40, num_updates=8730, lr=4.63212e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23627
2022-09-29 03:16:53 - progress_bar.py[line:274] - INFO: epoch 001:   8753 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.89, wpb=99.7, bsz=40, num_updates=8740, lr=4.63146e-05, gnorm=0.962, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23638
2022-09-29 03:17:04 - progress_bar.py[line:274] - INFO: epoch 001:   8763 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.7, ups=0.89, wpb=101.1, bsz=40, num_updates=8750, lr=4.6308e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23649
2022-09-29 03:17:15 - progress_bar.py[line:274] - INFO: epoch 001:   8773 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.88, wpb=100.5, bsz=40, num_updates=8760, lr=4.63014e-05, gnorm=0.898, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23660
2022-09-29 03:17:26 - progress_bar.py[line:274] - INFO: epoch 001:   8783 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.7, ups=0.93, wpb=100.5, bsz=40, num_updates=8770, lr=4.62948e-05, gnorm=0.985, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23671
2022-09-29 03:17:38 - progress_bar.py[line:274] - INFO: epoch 001:   8793 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88, ups=0.88, wpb=100.1, bsz=40, num_updates=8780, lr=4.62882e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23682
2022-09-29 03:17:49 - progress_bar.py[line:274] - INFO: epoch 001:   8803 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.89, wpb=101.4, bsz=40, num_updates=8790, lr=4.62816e-05, gnorm=0.754, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23694
2022-09-29 03:18:00 - progress_bar.py[line:274] - INFO: epoch 001:   8813 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.1, ups=0.9, wpb=101.3, bsz=40, num_updates=8800, lr=4.6275e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23705
2022-09-29 03:18:11 - progress_bar.py[line:274] - INFO: epoch 001:   8823 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.2, ups=0.87, wpb=100.9, bsz=40, num_updates=8810, lr=4.62684e-05, gnorm=0.829, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23716
2022-09-29 03:18:23 - progress_bar.py[line:274] - INFO: epoch 001:   8833 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.6, ups=0.9, wpb=102.7, bsz=40, num_updates=8820, lr=4.62618e-05, gnorm=0.891, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23727
2022-09-29 03:18:33 - progress_bar.py[line:274] - INFO: epoch 001:   8843 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.7, ups=0.95, wpb=102.5, bsz=40, num_updates=8830, lr=4.62552e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=23738
2022-09-29 03:18:44 - progress_bar.py[line:274] - INFO: epoch 001:   8853 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=8840, lr=4.62486e-05, gnorm=0.824, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=23749
2022-09-29 03:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   8863 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.88, wpb=100.7, bsz=40, num_updates=8850, lr=4.6242e-05, gnorm=0.909, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23761
2022-09-29 03:19:07 - progress_bar.py[line:274] - INFO: epoch 001:   8873 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.4, ups=0.89, wpb=102.3, bsz=40, num_updates=8860, lr=4.62354e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23772
2022-09-29 03:19:18 - progress_bar.py[line:274] - INFO: epoch 001:   8883 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.6, ups=0.88, wpb=99.7, bsz=40, num_updates=8870, lr=4.62288e-05, gnorm=1.09, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23783
2022-09-29 03:19:29 - progress_bar.py[line:274] - INFO: epoch 001:   8893 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.9, ups=0.93, wpb=101.4, bsz=40, num_updates=8880, lr=4.62222e-05, gnorm=0.907, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23794
2022-09-29 03:19:33 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 03:19:41 - progress_bar.py[line:274] - INFO: epoch 001:   8904 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=83.1, ups=0.82, wpb=101.1, bsz=40, num_updates=8890, lr=4.62156e-05, gnorm=0.786, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=23806
2022-09-29 03:19:53 - progress_bar.py[line:274] - INFO: epoch 001:   8914 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90, ups=0.87, wpb=103, bsz=40, num_updates=8900, lr=4.6209e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23818
2022-09-29 03:20:04 - progress_bar.py[line:274] - INFO: epoch 001:   8924 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.7, ups=0.88, wpb=99.7, bsz=40, num_updates=8910, lr=4.62024e-05, gnorm=0.941, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23829
2022-09-29 03:20:16 - progress_bar.py[line:274] - INFO: epoch 001:   8934 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.87, wpb=101.9, bsz=40, num_updates=8920, lr=4.61958e-05, gnorm=0.884, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23840
2022-09-29 03:20:27 - progress_bar.py[line:274] - INFO: epoch 001:   8944 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.87, wpb=104.1, bsz=40, num_updates=8930, lr=4.61892e-05, gnorm=0.888, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23852
2022-09-29 03:20:39 - progress_bar.py[line:274] - INFO: epoch 001:   8954 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.6, ups=0.87, wpb=100.2, bsz=40, num_updates=8940, lr=4.61826e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23863
2022-09-29 03:20:51 - progress_bar.py[line:274] - INFO: epoch 001:   8964 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=83.6, ups=0.82, wpb=101.5, bsz=40, num_updates=8950, lr=4.6176e-05, gnorm=0.88, clip=20, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=23876
2022-09-29 03:21:03 - progress_bar.py[line:274] - INFO: epoch 001:   8974 / 15783 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=84.7, ups=0.85, wpb=100.1, bsz=40, num_updates=8960, lr=4.61694e-05, gnorm=0.999, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=23887
2022-09-29 03:21:13 - progress_bar.py[line:274] - INFO: epoch 001:   8984 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.3, ups=0.92, wpb=101.8, bsz=40, num_updates=8970, lr=4.61628e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23898
2022-09-29 03:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   8994 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.6, ups=0.9, wpb=102.8, bsz=40, num_updates=8980, lr=4.61562e-05, gnorm=0.868, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23909
2022-09-29 03:21:36 - progress_bar.py[line:274] - INFO: epoch 001:   9004 / 15783 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91, ups=0.9, wpb=101, bsz=40, num_updates=8990, lr=4.61496e-05, gnorm=1.044, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23921
2022-09-29 03:21:47 - progress_bar.py[line:274] - INFO: epoch 001:   9014 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.9, wpb=101.9, bsz=40, num_updates=9000, lr=4.6143e-05, gnorm=0.755, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=23932
2022-09-29 03:21:58 - progress_bar.py[line:274] - INFO: epoch 001:   9024 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92, ups=0.91, wpb=101.4, bsz=40, num_updates=9010, lr=4.61364e-05, gnorm=0.971, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23943
2022-09-29 03:22:08 - progress_bar.py[line:274] - INFO: epoch 001:   9034 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.8, ups=0.94, wpb=101, bsz=40, num_updates=9020, lr=4.61298e-05, gnorm=0.863, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23953
2022-09-29 03:22:19 - progress_bar.py[line:274] - INFO: epoch 001:   9044 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.5, ups=0.92, wpb=101.1, bsz=40, num_updates=9030, lr=4.61232e-05, gnorm=0.89, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23964
2022-09-29 03:22:31 - progress_bar.py[line:274] - INFO: epoch 001:   9054 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87, ups=0.87, wpb=100.2, bsz=40, num_updates=9040, lr=4.61166e-05, gnorm=1.016, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23976
2022-09-29 03:22:42 - progress_bar.py[line:274] - INFO: epoch 001:   9064 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.1, ups=0.91, wpb=100.9, bsz=40, num_updates=9050, lr=4.611e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23987
2022-09-29 03:22:53 - progress_bar.py[line:274] - INFO: epoch 001:   9074 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.88, wpb=101.6, bsz=40, num_updates=9060, lr=4.61034e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=23998
2022-09-29 03:23:04 - progress_bar.py[line:274] - INFO: epoch 001:   9084 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=9070, lr=4.60968e-05, gnorm=0.957, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24009
2022-09-29 03:23:16 - progress_bar.py[line:274] - INFO: epoch 001:   9094 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.8, ups=0.87, wpb=100.3, bsz=40, num_updates=9080, lr=4.60902e-05, gnorm=0.858, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=24021
2022-09-29 03:23:27 - progress_bar.py[line:274] - INFO: epoch 001:   9104 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.89, wpb=100, bsz=40, num_updates=9090, lr=4.60836e-05, gnorm=0.806, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24032
2022-09-29 03:23:38 - progress_bar.py[line:274] - INFO: epoch 001:   9114 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.2, ups=0.88, wpb=101.7, bsz=40, num_updates=9100, lr=4.6077e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24043
2022-09-29 03:23:50 - progress_bar.py[line:274] - INFO: epoch 001:   9124 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.89, wpb=100.8, bsz=40, num_updates=9110, lr=4.60704e-05, gnorm=0.861, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24054
2022-09-29 03:24:01 - progress_bar.py[line:274] - INFO: epoch 001:   9134 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.4, ups=0.87, wpb=100.7, bsz=40, num_updates=9120, lr=4.60638e-05, gnorm=0.984, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=24066
2022-09-29 03:24:12 - progress_bar.py[line:274] - INFO: epoch 001:   9144 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.89, wpb=101.6, bsz=40, num_updates=9130, lr=4.60572e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24077
2022-09-29 03:24:24 - progress_bar.py[line:274] - INFO: epoch 001:   9154 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.88, wpb=101.3, bsz=40, num_updates=9140, lr=4.60506e-05, gnorm=1.024, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24089
2022-09-29 03:24:35 - progress_bar.py[line:274] - INFO: epoch 001:   9164 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.89, wpb=102.4, bsz=40, num_updates=9150, lr=4.6044e-05, gnorm=0.75, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24100
2022-09-29 03:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   9174 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.9, wpb=101.6, bsz=40, num_updates=9160, lr=4.60374e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24111
2022-09-29 03:24:57 - progress_bar.py[line:274] - INFO: epoch 001:   9184 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.88, wpb=102.9, bsz=40, num_updates=9170, lr=4.60308e-05, gnorm=0.827, clip=20, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=24122
2022-09-29 03:25:09 - progress_bar.py[line:274] - INFO: epoch 001:   9194 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92, ups=0.89, wpb=102.9, bsz=40, num_updates=9180, lr=4.60242e-05, gnorm=0.871, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24133
2022-09-29 03:25:20 - progress_bar.py[line:274] - INFO: epoch 001:   9204 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.88, wpb=103.1, bsz=40, num_updates=9190, lr=4.60176e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24145
2022-09-29 03:25:31 - progress_bar.py[line:274] - INFO: epoch 001:   9214 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.88, wpb=100.9, bsz=40, num_updates=9200, lr=4.6011e-05, gnorm=0.875, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24156
2022-09-29 03:25:43 - progress_bar.py[line:274] - INFO: epoch 001:   9224 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.88, wpb=102.1, bsz=40, num_updates=9210, lr=4.60044e-05, gnorm=0.937, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24167
2022-09-29 03:25:54 - progress_bar.py[line:274] - INFO: epoch 001:   9234 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.9, wpb=99.4, bsz=40, num_updates=9220, lr=4.59978e-05, gnorm=0.942, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24179
2022-09-29 03:26:05 - progress_bar.py[line:274] - INFO: epoch 001:   9244 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=9230, lr=4.59912e-05, gnorm=1.07, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24190
2022-09-29 03:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   9254 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.9, wpb=101.9, bsz=40, num_updates=9240, lr=4.59846e-05, gnorm=1.027, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24201
2022-09-29 03:26:27 - progress_bar.py[line:274] - INFO: epoch 001:   9264 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.9, wpb=100, bsz=40, num_updates=9250, lr=4.5978e-05, gnorm=0.964, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24212
2022-09-29 03:26:38 - progress_bar.py[line:274] - INFO: epoch 001:   9274 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.4, ups=0.89, wpb=101.4, bsz=40, num_updates=9260, lr=4.59714e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24223
2022-09-29 03:26:50 - progress_bar.py[line:274] - INFO: epoch 001:   9284 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.3, ups=0.88, wpb=99.4, bsz=40, num_updates=9270, lr=4.59648e-05, gnorm=0.888, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24234
2022-09-29 03:27:01 - progress_bar.py[line:274] - INFO: epoch 001:   9294 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.88, wpb=102.4, bsz=40, num_updates=9280, lr=4.59582e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24246
2022-09-29 03:27:13 - progress_bar.py[line:274] - INFO: epoch 001:   9304 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.87, wpb=102.8, bsz=40, num_updates=9290, lr=4.59516e-05, gnorm=0.921, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24257
2022-09-29 03:27:24 - progress_bar.py[line:274] - INFO: epoch 001:   9314 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.87, wpb=102.4, bsz=40, num_updates=9300, lr=4.5945e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24269
2022-09-29 03:27:35 - progress_bar.py[line:274] - INFO: epoch 001:   9324 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92, ups=0.9, wpb=101.8, bsz=40, num_updates=9310, lr=4.59384e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24280
2022-09-29 03:27:46 - progress_bar.py[line:274] - INFO: epoch 001:   9334 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.9, wpb=102.9, bsz=40, num_updates=9320, lr=4.59318e-05, gnorm=0.802, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24291
2022-09-29 03:27:57 - progress_bar.py[line:274] - INFO: epoch 001:   9344 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.8, ups=0.91, wpb=100.4, bsz=40, num_updates=9330, lr=4.59252e-05, gnorm=0.979, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24302
2022-09-29 03:28:09 - progress_bar.py[line:274] - INFO: epoch 001:   9354 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.9, ups=0.88, wpb=100, bsz=40, num_updates=9340, lr=4.59186e-05, gnorm=1.101, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24313
2022-09-29 03:28:20 - progress_bar.py[line:274] - INFO: epoch 001:   9364 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=9350, lr=4.5912e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24325
2022-09-29 03:28:31 - progress_bar.py[line:274] - INFO: epoch 001:   9374 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.9, wpb=101.8, bsz=40, num_updates=9360, lr=4.59054e-05, gnorm=1, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24336
2022-09-29 03:28:42 - progress_bar.py[line:274] - INFO: epoch 001:   9384 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=9370, lr=4.58988e-05, gnorm=1, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24347
2022-09-29 03:28:53 - progress_bar.py[line:274] - INFO: epoch 001:   9394 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92, ups=0.91, wpb=101.6, bsz=40, num_updates=9380, lr=4.58922e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24358
2022-09-29 03:29:04 - progress_bar.py[line:274] - INFO: epoch 001:   9404 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.89, wpb=100.6, bsz=40, num_updates=9390, lr=4.58856e-05, gnorm=0.853, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24369
2022-09-29 03:29:16 - progress_bar.py[line:274] - INFO: epoch 001:   9414 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=9400, lr=4.5879e-05, gnorm=0.985, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24381
2022-09-29 03:29:27 - progress_bar.py[line:274] - INFO: epoch 001:   9424 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.9, wpb=101.7, bsz=40, num_updates=9410, lr=4.58724e-05, gnorm=0.871, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24392
2022-09-29 03:29:38 - progress_bar.py[line:274] - INFO: epoch 001:   9434 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.86, wpb=102.7, bsz=40, num_updates=9420, lr=4.58658e-05, gnorm=0.828, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=24403
2022-09-29 03:29:50 - progress_bar.py[line:274] - INFO: epoch 001:   9444 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.2, ups=0.88, wpb=99.5, bsz=40, num_updates=9430, lr=4.58592e-05, gnorm=1.04, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24415
2022-09-29 03:30:01 - progress_bar.py[line:274] - INFO: epoch 001:   9454 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=9440, lr=4.58526e-05, gnorm=0.823, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24426
2022-09-29 03:30:12 - progress_bar.py[line:274] - INFO: epoch 001:   9464 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=9450, lr=4.5846e-05, gnorm=0.85, clip=40, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=24437
2022-09-29 03:30:24 - progress_bar.py[line:274] - INFO: epoch 001:   9474 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.88, wpb=100.5, bsz=40, num_updates=9460, lr=4.58394e-05, gnorm=0.899, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24448
2022-09-29 03:30:35 - progress_bar.py[line:274] - INFO: epoch 001:   9484 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=9470, lr=4.58328e-05, gnorm=0.855, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24460
2022-09-29 03:30:46 - progress_bar.py[line:274] - INFO: epoch 001:   9494 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.3, ups=0.88, wpb=101.9, bsz=40, num_updates=9480, lr=4.58262e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24471
2022-09-29 03:30:58 - progress_bar.py[line:274] - INFO: epoch 001:   9504 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.88, wpb=101.2, bsz=40, num_updates=9490, lr=4.58196e-05, gnorm=1.027, clip=50, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24482
2022-09-29 03:31:09 - progress_bar.py[line:274] - INFO: epoch 001:   9514 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.7, ups=0.92, wpb=102.1, bsz=40, num_updates=9500, lr=4.5813e-05, gnorm=0.955, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24493
2022-09-29 03:31:18 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 03:31:21 - progress_bar.py[line:274] - INFO: epoch 001:   9525 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=83.3, ups=0.82, wpb=102, bsz=40, num_updates=9510, lr=4.58064e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=24506
2022-09-29 03:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   9535 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.92, wpb=102, bsz=40, num_updates=9520, lr=4.57998e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24517
2022-09-29 03:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   9545 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101.5, bsz=40, num_updates=9530, lr=4.57932e-05, gnorm=0.907, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24528
2022-09-29 03:31:54 - progress_bar.py[line:274] - INFO: epoch 001:   9555 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=101.4, bsz=40, num_updates=9540, lr=4.57866e-05, gnorm=0.879, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24539
2022-09-29 03:32:06 - progress_bar.py[line:274] - INFO: epoch 001:   9565 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.86, wpb=101.8, bsz=40, num_updates=9550, lr=4.578e-05, gnorm=0.824, clip=20, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=24551
2022-09-29 03:32:17 - progress_bar.py[line:274] - INFO: epoch 001:   9575 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=9560, lr=4.57734e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24562
2022-09-29 03:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   9585 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.89, wpb=102, bsz=40, num_updates=9570, lr=4.57668e-05, gnorm=0.838, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24573
2022-09-29 03:32:40 - progress_bar.py[line:274] - INFO: epoch 001:   9595 / 15783 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.8, ups=0.88, wpb=100, bsz=40, num_updates=9580, lr=4.57602e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24585
2022-09-29 03:32:51 - progress_bar.py[line:274] - INFO: epoch 001:   9605 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.7, ups=0.9, wpb=103.1, bsz=40, num_updates=9590, lr=4.57536e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24596
2022-09-29 03:33:02 - progress_bar.py[line:274] - INFO: epoch 001:   9615 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.7, ups=0.91, wpb=101.2, bsz=40, num_updates=9600, lr=4.5747e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=24607
2022-09-29 03:33:13 - progress_bar.py[line:274] - INFO: epoch 001:   9625 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.9, wpb=101.6, bsz=40, num_updates=9610, lr=4.57404e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24618
2022-09-29 03:33:24 - progress_bar.py[line:274] - INFO: epoch 001:   9635 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=9620, lr=4.57338e-05, gnorm=0.825, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24629
2022-09-29 03:33:36 - progress_bar.py[line:274] - INFO: epoch 001:   9645 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=9630, lr=4.57272e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24640
2022-09-29 03:33:47 - progress_bar.py[line:274] - INFO: epoch 001:   9655 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.2, ups=0.88, wpb=99.5, bsz=40, num_updates=9640, lr=4.57206e-05, gnorm=0.884, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24652
2022-09-29 03:33:58 - progress_bar.py[line:274] - INFO: epoch 001:   9665 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=9650, lr=4.5714e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24663
2022-09-29 03:34:10 - progress_bar.py[line:274] - INFO: epoch 001:   9675 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.3, ups=0.88, wpb=100.7, bsz=40, num_updates=9660, lr=4.57074e-05, gnorm=0.91, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24675
2022-09-29 03:34:21 - progress_bar.py[line:274] - INFO: epoch 001:   9685 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.1, ups=0.92, wpb=101.4, bsz=40, num_updates=9670, lr=4.57008e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24685
2022-09-29 03:34:32 - progress_bar.py[line:274] - INFO: epoch 001:   9695 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=9680, lr=4.56942e-05, gnorm=0.807, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24697
2022-09-29 03:34:43 - progress_bar.py[line:274] - INFO: epoch 001:   9705 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=89.8, ups=0.9, wpb=99.7, bsz=40, num_updates=9690, lr=4.56876e-05, gnorm=1.023, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24708
2022-09-29 03:34:55 - progress_bar.py[line:274] - INFO: epoch 001:   9715 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.5, ups=0.86, wpb=101.5, bsz=40, num_updates=9700, lr=4.5681e-05, gnorm=0.77, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=24719
2022-09-29 03:35:06 - progress_bar.py[line:274] - INFO: epoch 001:   9725 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.87, wpb=102.4, bsz=40, num_updates=9710, lr=4.56744e-05, gnorm=0.797, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24731
2022-09-29 03:35:18 - progress_bar.py[line:274] - INFO: epoch 001:   9735 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.6, ups=0.89, wpb=100.7, bsz=40, num_updates=9720, lr=4.56678e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24743
2022-09-29 03:35:29 - progress_bar.py[line:274] - INFO: epoch 001:   9745 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.5, ups=0.9, wpb=102.6, bsz=40, num_updates=9730, lr=4.56612e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24754
2022-09-29 03:35:40 - progress_bar.py[line:274] - INFO: epoch 001:   9755 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.7, ups=0.92, wpb=99.5, bsz=40, num_updates=9740, lr=4.56546e-05, gnorm=0.948, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24765
2022-09-29 03:35:51 - progress_bar.py[line:274] - INFO: epoch 001:   9765 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.89, wpb=99.2, bsz=40, num_updates=9750, lr=4.5648e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24776
2022-09-29 03:36:02 - progress_bar.py[line:274] - INFO: epoch 001:   9775 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=9760, lr=4.56414e-05, gnorm=0.945, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24787
2022-09-29 03:36:13 - progress_bar.py[line:274] - INFO: epoch 001:   9785 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=9770, lr=4.56348e-05, gnorm=0.802, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24798
2022-09-29 03:36:25 - progress_bar.py[line:274] - INFO: epoch 001:   9795 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.7, ups=0.87, wpb=100.8, bsz=40, num_updates=9780, lr=4.56282e-05, gnorm=0.892, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24810
2022-09-29 03:36:36 - progress_bar.py[line:274] - INFO: epoch 001:   9805 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=87.5, ups=0.88, wpb=99.4, bsz=40, num_updates=9790, lr=4.56216e-05, gnorm=1.085, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24821
2022-09-29 03:36:47 - progress_bar.py[line:274] - INFO: epoch 001:   9815 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.2, ups=0.9, wpb=100.5, bsz=40, num_updates=9800, lr=4.5615e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24832
2022-09-29 03:36:58 - progress_bar.py[line:274] - INFO: epoch 001:   9825 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.7, ups=0.91, wpb=100.3, bsz=40, num_updates=9810, lr=4.56084e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24843
2022-09-29 03:37:10 - progress_bar.py[line:274] - INFO: epoch 001:   9835 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.5, ups=0.9, wpb=102.6, bsz=40, num_updates=9820, lr=4.56018e-05, gnorm=0.824, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24854
2022-09-29 03:37:21 - progress_bar.py[line:274] - INFO: epoch 001:   9845 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=9830, lr=4.55952e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24866
2022-09-29 03:37:32 - progress_bar.py[line:274] - INFO: epoch 001:   9855 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.8, ups=0.9, wpb=99.7, bsz=40, num_updates=9840, lr=4.55886e-05, gnorm=0.917, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24877
2022-09-29 03:37:43 - progress_bar.py[line:274] - INFO: epoch 001:   9865 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.9, wpb=102.3, bsz=40, num_updates=9850, lr=4.5582e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24888
2022-09-29 03:37:54 - progress_bar.py[line:274] - INFO: epoch 001:   9875 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.5, ups=0.91, wpb=104.3, bsz=40, num_updates=9860, lr=4.55754e-05, gnorm=0.777, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24899
2022-09-29 03:38:05 - progress_bar.py[line:274] - INFO: epoch 001:   9885 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.7, ups=0.89, wpb=99.7, bsz=40, num_updates=9870, lr=4.55688e-05, gnorm=0.98, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24910
2022-09-29 03:38:16 - progress_bar.py[line:274] - INFO: epoch 001:   9895 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.6, ups=0.93, wpb=101.1, bsz=40, num_updates=9880, lr=4.55622e-05, gnorm=0.94, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24921
2022-09-29 03:38:28 - progress_bar.py[line:274] - INFO: epoch 001:   9905 / 15783 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.1, ups=0.88, wpb=99.1, bsz=40, num_updates=9890, lr=4.55556e-05, gnorm=1.022, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24932
2022-09-29 03:38:39 - progress_bar.py[line:274] - INFO: epoch 001:   9915 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=101.2, bsz=40, num_updates=9900, lr=4.5549e-05, gnorm=0.92, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24944
2022-09-29 03:38:50 - progress_bar.py[line:274] - INFO: epoch 001:   9925 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.3, ups=0.9, wpb=103.2, bsz=40, num_updates=9910, lr=4.55424e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24955
2022-09-29 03:39:01 - progress_bar.py[line:274] - INFO: epoch 001:   9935 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=9920, lr=4.55358e-05, gnorm=0.845, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24966
2022-09-29 03:39:12 - progress_bar.py[line:274] - INFO: epoch 001:   9945 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=92.6, ups=0.91, wpb=101.6, bsz=40, num_updates=9930, lr=4.55292e-05, gnorm=0.84, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=24977
2022-09-29 03:39:24 - progress_bar.py[line:274] - INFO: epoch 001:   9955 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.7, ups=0.87, wpb=101.3, bsz=40, num_updates=9940, lr=4.55226e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=24988
2022-09-29 03:39:34 - progress_bar.py[line:274] - INFO: epoch 001:   9965 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.8, ups=0.92, wpb=100.2, bsz=40, num_updates=9950, lr=4.5516e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=24999
2022-09-29 03:39:46 - progress_bar.py[line:274] - INFO: epoch 001:   9975 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.89, wpb=100.9, bsz=40, num_updates=9960, lr=4.55094e-05, gnorm=1.051, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25011
2022-09-29 03:39:57 - progress_bar.py[line:274] - INFO: epoch 001:   9985 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=9970, lr=4.55028e-05, gnorm=0.821, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25022
2022-09-29 03:40:08 - progress_bar.py[line:274] - INFO: epoch 001:   9995 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.91, wpb=101.1, bsz=40, num_updates=9980, lr=4.54962e-05, gnorm=0.873, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25033
2022-09-29 03:40:19 - progress_bar.py[line:274] - INFO: epoch 001:  10005 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.9, wpb=101.7, bsz=40, num_updates=9990, lr=4.54896e-05, gnorm=0.858, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25044
2022-09-29 03:40:30 - progress_bar.py[line:274] - INFO: epoch 001:  10015 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.89, wpb=102.1, bsz=40, num_updates=10000, lr=4.5483e-05, gnorm=0.955, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25055
2022-09-29 03:40:41 - progress_bar.py[line:274] - INFO: epoch 001:  10025 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.3, ups=0.91, wpb=103.2, bsz=40, num_updates=10010, lr=4.54764e-05, gnorm=0.796, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25066
2022-09-29 03:40:52 - progress_bar.py[line:274] - INFO: epoch 001:  10035 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=10020, lr=4.54698e-05, gnorm=0.754, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25077
2022-09-29 03:41:04 - progress_bar.py[line:274] - INFO: epoch 001:  10045 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.92, wpb=101.1, bsz=40, num_updates=10030, lr=4.54632e-05, gnorm=0.854, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25088
2022-09-29 03:41:15 - progress_bar.py[line:274] - INFO: epoch 001:  10055 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=10040, lr=4.54566e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25100
2022-09-29 03:41:26 - progress_bar.py[line:274] - INFO: epoch 001:  10065 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.9, ups=0.91, wpb=102, bsz=40, num_updates=10050, lr=4.545e-05, gnorm=0.816, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25111
2022-09-29 03:41:37 - progress_bar.py[line:274] - INFO: epoch 001:  10075 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.9, wpb=101, bsz=40, num_updates=10060, lr=4.54434e-05, gnorm=0.867, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25122
2022-09-29 03:41:49 - progress_bar.py[line:274] - INFO: epoch 001:  10085 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.9, ups=0.88, wpb=101.2, bsz=40, num_updates=10070, lr=4.54368e-05, gnorm=0.831, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25133
2022-09-29 03:42:00 - progress_bar.py[line:274] - INFO: epoch 001:  10095 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93, ups=0.91, wpb=101.8, bsz=40, num_updates=10080, lr=4.54302e-05, gnorm=0.867, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25144
2022-09-29 03:42:11 - progress_bar.py[line:274] - INFO: epoch 001:  10105 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.7, ups=0.9, wpb=101.5, bsz=40, num_updates=10090, lr=4.54236e-05, gnorm=0.873, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25155
2022-09-29 03:42:22 - progress_bar.py[line:274] - INFO: epoch 001:  10115 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=10100, lr=4.5417e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25167
2022-09-29 03:42:33 - progress_bar.py[line:274] - INFO: epoch 001:  10125 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.3, ups=0.9, wpb=102.4, bsz=40, num_updates=10110, lr=4.54104e-05, gnorm=0.772, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25178
2022-09-29 03:42:37 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 03:42:45 - progress_bar.py[line:274] - INFO: epoch 001:  10136 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=84.1, ups=0.83, wpb=101.4, bsz=40, num_updates=10120, lr=4.54038e-05, gnorm=0.847, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=25190
2022-09-29 03:42:57 - progress_bar.py[line:274] - INFO: epoch 001:  10146 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.87, wpb=102.2, bsz=40, num_updates=10130, lr=4.53972e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=25202
2022-09-29 03:43:08 - progress_bar.py[line:274] - INFO: epoch 001:  10156 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91, ups=0.9, wpb=101.1, bsz=40, num_updates=10140, lr=4.53906e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25213
2022-09-29 03:43:20 - progress_bar.py[line:274] - INFO: epoch 001:  10166 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.89, wpb=102.5, bsz=40, num_updates=10150, lr=4.5384e-05, gnorm=0.785, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25224
2022-09-29 03:43:32 - progress_bar.py[line:274] - INFO: epoch 001:  10176 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=79.9, ups=0.8, wpb=99.5, bsz=40, num_updates=10160, lr=4.53774e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=25237
2022-09-29 03:43:45 - progress_bar.py[line:274] - INFO: epoch 001:  10186 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=78.6, ups=0.78, wpb=100.9, bsz=40, num_updates=10170, lr=4.53708e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=25250
2022-09-29 03:43:57 - progress_bar.py[line:274] - INFO: epoch 001:  10196 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=85.3, ups=0.84, wpb=101.4, bsz=40, num_updates=10180, lr=4.53642e-05, gnorm=0.876, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=25262
2022-09-29 03:44:08 - progress_bar.py[line:274] - INFO: epoch 001:  10206 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.6, ups=0.91, wpb=102.4, bsz=40, num_updates=10190, lr=4.53576e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=25273
2022-09-29 03:44:20 - progress_bar.py[line:274] - INFO: epoch 001:  10216 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.88, wpb=101.5, bsz=40, num_updates=10200, lr=4.5351e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25284
2022-09-29 03:44:31 - progress_bar.py[line:274] - INFO: epoch 001:  10226 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.88, wpb=101.1, bsz=40, num_updates=10210, lr=4.53444e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25296
2022-09-29 03:44:43 - progress_bar.py[line:274] - INFO: epoch 001:  10236 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.2, ups=0.87, wpb=100.8, bsz=40, num_updates=10220, lr=4.53378e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=25307
2022-09-29 03:44:54 - progress_bar.py[line:274] - INFO: epoch 001:  10246 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.9, ups=0.89, wpb=101.4, bsz=40, num_updates=10230, lr=4.53312e-05, gnorm=0.859, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25319
2022-09-29 03:45:05 - progress_bar.py[line:274] - INFO: epoch 001:  10256 / 15783 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.8, ups=0.89, wpb=100, bsz=40, num_updates=10240, lr=4.53246e-05, gnorm=0.871, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25330
2022-09-29 03:45:17 - progress_bar.py[line:274] - INFO: epoch 001:  10266 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.87, wpb=102, bsz=40, num_updates=10250, lr=4.5318e-05, gnorm=0.882, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25341
2022-09-29 03:45:28 - progress_bar.py[line:274] - INFO: epoch 001:  10276 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.91, wpb=101.9, bsz=40, num_updates=10260, lr=4.53114e-05, gnorm=0.754, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25352
2022-09-29 03:45:39 - progress_bar.py[line:274] - INFO: epoch 001:  10286 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=10270, lr=4.53048e-05, gnorm=0.833, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25364
2022-09-29 03:45:50 - progress_bar.py[line:274] - INFO: epoch 001:  10296 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.88, wpb=101.3, bsz=40, num_updates=10280, lr=4.52982e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25375
2022-09-29 03:46:01 - progress_bar.py[line:274] - INFO: epoch 001:  10306 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.1, ups=0.92, wpb=101.7, bsz=40, num_updates=10290, lr=4.52916e-05, gnorm=0.861, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25386
2022-09-29 03:46:13 - progress_bar.py[line:274] - INFO: epoch 001:  10316 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.3, ups=0.85, wpb=101, bsz=40, num_updates=10300, lr=4.5285e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=25398
2022-09-29 03:46:24 - progress_bar.py[line:274] - INFO: epoch 001:  10326 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.9, ups=0.86, wpb=102.9, bsz=40, num_updates=10310, lr=4.52784e-05, gnorm=0.695, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=25409
2022-09-29 03:46:36 - progress_bar.py[line:274] - INFO: epoch 001:  10336 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.89, wpb=101.8, bsz=40, num_updates=10320, lr=4.52718e-05, gnorm=0.851, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25420
2022-09-29 03:46:47 - progress_bar.py[line:274] - INFO: epoch 001:  10346 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=10330, lr=4.52652e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25432
2022-09-29 03:46:58 - progress_bar.py[line:274] - INFO: epoch 001:  10356 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.89, wpb=103, bsz=40, num_updates=10340, lr=4.52586e-05, gnorm=0.762, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25443
2022-09-29 03:47:10 - progress_bar.py[line:274] - INFO: epoch 001:  10366 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.89, wpb=101.1, bsz=40, num_updates=10350, lr=4.5252e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25455
2022-09-29 03:47:21 - progress_bar.py[line:274] - INFO: epoch 001:  10376 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.6, ups=0.88, wpb=99.6, bsz=40, num_updates=10360, lr=4.52454e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25466
2022-09-29 03:47:32 - progress_bar.py[line:274] - INFO: epoch 001:  10386 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=10370, lr=4.52388e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25477
2022-09-29 03:47:44 - progress_bar.py[line:274] - INFO: epoch 001:  10396 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.6, ups=0.88, wpb=102.2, bsz=40, num_updates=10380, lr=4.52322e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25489
2022-09-29 03:47:55 - progress_bar.py[line:274] - INFO: epoch 001:  10406 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.88, wpb=100.4, bsz=40, num_updates=10390, lr=4.52256e-05, gnorm=0.891, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25500
2022-09-29 03:48:07 - progress_bar.py[line:274] - INFO: epoch 001:  10416 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.88, wpb=101.5, bsz=40, num_updates=10400, lr=4.5219e-05, gnorm=0.865, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25511
2022-09-29 03:48:18 - progress_bar.py[line:274] - INFO: epoch 001:  10426 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93, ups=0.91, wpb=101.9, bsz=40, num_updates=10410, lr=4.52125e-05, gnorm=0.777, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25522
2022-09-29 03:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  10436 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.3, ups=0.91, wpb=102, bsz=40, num_updates=10420, lr=4.52059e-05, gnorm=0.812, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25533
2022-09-29 03:48:40 - progress_bar.py[line:274] - INFO: epoch 001:  10446 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.6, ups=0.87, wpb=101.4, bsz=40, num_updates=10430, lr=4.51993e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25545
2022-09-29 03:48:51 - progress_bar.py[line:274] - INFO: epoch 001:  10456 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.4, ups=0.89, wpb=102, bsz=40, num_updates=10440, lr=4.51927e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25556
2022-09-29 03:49:03 - progress_bar.py[line:274] - INFO: epoch 001:  10466 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.4, ups=0.86, wpb=100, bsz=40, num_updates=10450, lr=4.51861e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=25568
2022-09-29 03:49:14 - progress_bar.py[line:274] - INFO: epoch 001:  10476 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.88, wpb=100.6, bsz=40, num_updates=10460, lr=4.51795e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25579
2022-09-29 03:49:25 - progress_bar.py[line:274] - INFO: epoch 001:  10486 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.4, ups=0.91, wpb=101.8, bsz=40, num_updates=10470, lr=4.51729e-05, gnorm=0.863, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=25590
2022-09-29 03:49:37 - progress_bar.py[line:274] - INFO: epoch 001:  10496 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.9, wpb=99.4, bsz=40, num_updates=10480, lr=4.51663e-05, gnorm=1.003, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25601
2022-09-29 03:49:48 - progress_bar.py[line:274] - INFO: epoch 001:  10506 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.7, ups=0.91, wpb=98.8, bsz=40, num_updates=10490, lr=4.51597e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25612
2022-09-29 03:49:59 - progress_bar.py[line:274] - INFO: epoch 001:  10516 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=10500, lr=4.51531e-05, gnorm=0.861, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25624
2022-09-29 03:50:10 - progress_bar.py[line:274] - INFO: epoch 001:  10526 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.88, wpb=102.2, bsz=40, num_updates=10510, lr=4.51465e-05, gnorm=0.887, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25635
2022-09-29 03:50:22 - progress_bar.py[line:274] - INFO: epoch 001:  10536 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.87, wpb=101.2, bsz=40, num_updates=10520, lr=4.51399e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25646
2022-09-29 03:50:33 - progress_bar.py[line:274] - INFO: epoch 001:  10546 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.7, ups=0.9, wpb=101.5, bsz=40, num_updates=10530, lr=4.51333e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25657
2022-09-29 03:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  10556 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.9, wpb=101.7, bsz=40, num_updates=10540, lr=4.51267e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25669
2022-09-29 03:50:55 - progress_bar.py[line:274] - INFO: epoch 001:  10566 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.3, ups=0.9, wpb=102.8, bsz=40, num_updates=10550, lr=4.51201e-05, gnorm=0.83, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25680
2022-09-29 03:51:06 - progress_bar.py[line:274] - INFO: epoch 001:  10576 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92, ups=0.9, wpb=102.2, bsz=40, num_updates=10560, lr=4.51135e-05, gnorm=0.759, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25691
2022-09-29 03:51:17 - progress_bar.py[line:274] - INFO: epoch 001:  10586 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=10570, lr=4.51069e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25702
2022-09-29 03:51:29 - progress_bar.py[line:274] - INFO: epoch 001:  10596 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=102, bsz=40, num_updates=10580, lr=4.51003e-05, gnorm=0.853, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25713
2022-09-29 03:51:40 - progress_bar.py[line:274] - INFO: epoch 001:  10606 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.2, ups=0.88, wpb=99.3, bsz=40, num_updates=10590, lr=4.50937e-05, gnorm=0.908, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25725
2022-09-29 03:51:51 - progress_bar.py[line:274] - INFO: epoch 001:  10616 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.4, ups=0.9, wpb=100.9, bsz=40, num_updates=10600, lr=4.50871e-05, gnorm=0.81, clip=20, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=25736
2022-09-29 03:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  10626 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=10610, lr=4.50805e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25747
2022-09-29 03:52:13 - progress_bar.py[line:274] - INFO: epoch 001:  10636 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.91, wpb=100.5, bsz=40, num_updates=10620, lr=4.50739e-05, gnorm=0.726, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25758
2022-09-29 03:52:24 - progress_bar.py[line:274] - INFO: epoch 001:  10646 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.4, ups=0.92, wpb=102.2, bsz=40, num_updates=10630, lr=4.50673e-05, gnorm=0.959, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25769
2022-09-29 03:52:28 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 03:52:36 - progress_bar.py[line:274] - INFO: epoch 001:  10657 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=83.8, ups=0.82, wpb=101.9, bsz=40, num_updates=10640, lr=4.50607e-05, gnorm=0.739, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=25781
2022-09-29 03:52:48 - progress_bar.py[line:274] - INFO: epoch 001:  10667 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.88, wpb=101.4, bsz=40, num_updates=10650, lr=4.50541e-05, gnorm=0.858, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25793
2022-09-29 03:52:59 - progress_bar.py[line:274] - INFO: epoch 001:  10677 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.8, ups=0.85, wpb=101.5, bsz=40, num_updates=10660, lr=4.50475e-05, gnorm=0.729, clip=10, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=25804
2022-09-29 03:53:10 - progress_bar.py[line:274] - INFO: epoch 001:  10687 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.7, ups=0.91, wpb=100.5, bsz=40, num_updates=10670, lr=4.50409e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25815
2022-09-29 03:53:22 - progress_bar.py[line:274] - INFO: epoch 001:  10697 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.1, ups=0.88, wpb=101.8, bsz=40, num_updates=10680, lr=4.50343e-05, gnorm=0.754, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25827
2022-09-29 03:53:33 - progress_bar.py[line:274] - INFO: epoch 001:  10707 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.89, wpb=104.3, bsz=40, num_updates=10690, lr=4.50277e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25838
2022-09-29 03:53:44 - progress_bar.py[line:274] - INFO: epoch 001:  10717 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.89, wpb=101.2, bsz=40, num_updates=10700, lr=4.50211e-05, gnorm=0.829, clip=0, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=25849
2022-09-29 03:53:56 - progress_bar.py[line:274] - INFO: epoch 001:  10727 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.88, wpb=102, bsz=40, num_updates=10710, lr=4.50145e-05, gnorm=0.86, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25861
2022-09-29 03:54:07 - progress_bar.py[line:274] - INFO: epoch 001:  10737 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.8, ups=0.91, wpb=101.2, bsz=40, num_updates=10720, lr=4.50079e-05, gnorm=0.922, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25872
2022-09-29 03:54:18 - progress_bar.py[line:274] - INFO: epoch 001:  10747 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.88, wpb=100.2, bsz=40, num_updates=10730, lr=4.50013e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25883
2022-09-29 03:54:29 - progress_bar.py[line:274] - INFO: epoch 001:  10757 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=10740, lr=4.49947e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25894
2022-09-29 03:54:40 - progress_bar.py[line:274] - INFO: epoch 001:  10767 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.91, wpb=100.7, bsz=40, num_updates=10750, lr=4.49881e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25905
2022-09-29 03:54:52 - progress_bar.py[line:274] - INFO: epoch 001:  10777 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.5, ups=0.88, wpb=100.2, bsz=40, num_updates=10760, lr=4.49815e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25916
2022-09-29 03:55:02 - progress_bar.py[line:274] - INFO: epoch 001:  10787 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.93, wpb=100.7, bsz=40, num_updates=10770, lr=4.49749e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25927
2022-09-29 03:55:13 - progress_bar.py[line:274] - INFO: epoch 001:  10797 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.1, ups=0.9, wpb=101.4, bsz=40, num_updates=10780, lr=4.49683e-05, gnorm=0.75, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25938
2022-09-29 03:55:25 - progress_bar.py[line:274] - INFO: epoch 001:  10807 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.5, ups=0.89, wpb=102.2, bsz=40, num_updates=10790, lr=4.49617e-05, gnorm=0.891, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25950
2022-09-29 03:55:36 - progress_bar.py[line:274] - INFO: epoch 001:  10817 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.1, ups=0.89, wpb=100.6, bsz=40, num_updates=10800, lr=4.49551e-05, gnorm=0.788, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25961
2022-09-29 03:55:47 - progress_bar.py[line:274] - INFO: epoch 001:  10827 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.4, ups=0.92, wpb=101, bsz=40, num_updates=10810, lr=4.49485e-05, gnorm=0.752, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25972
2022-09-29 03:55:58 - progress_bar.py[line:274] - INFO: epoch 001:  10837 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.4, ups=0.88, wpb=99.2, bsz=40, num_updates=10820, lr=4.49419e-05, gnorm=0.789, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25983
2022-09-29 03:56:09 - progress_bar.py[line:274] - INFO: epoch 001:  10847 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.9, ups=0.9, wpb=102.5, bsz=40, num_updates=10830, lr=4.49353e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25994
2022-09-29 03:56:21 - progress_bar.py[line:274] - INFO: epoch 001:  10857 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.3, ups=0.9, wpb=101.4, bsz=40, num_updates=10840, lr=4.49287e-05, gnorm=0.771, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=26005
2022-09-29 03:56:32 - progress_bar.py[line:274] - INFO: epoch 001:  10867 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.9, wpb=100.1, bsz=40, num_updates=10850, lr=4.49221e-05, gnorm=0.669, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26017
2022-09-29 03:56:43 - progress_bar.py[line:274] - INFO: epoch 001:  10877 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.88, wpb=101.8, bsz=40, num_updates=10860, lr=4.49155e-05, gnorm=0.928, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26028
2022-09-29 03:56:54 - progress_bar.py[line:274] - INFO: epoch 001:  10887 / 15783 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.7, ups=0.92, wpb=102.7, bsz=40, num_updates=10870, lr=4.49089e-05, gnorm=0.687, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26039
2022-09-29 03:57:05 - progress_bar.py[line:274] - INFO: epoch 001:  10897 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.9, ups=0.89, wpb=100.8, bsz=40, num_updates=10880, lr=4.49023e-05, gnorm=0.922, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26050
2022-09-29 03:57:16 - progress_bar.py[line:274] - INFO: epoch 001:  10907 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.89, wpb=102.3, bsz=40, num_updates=10890, lr=4.48957e-05, gnorm=0.886, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26061
2022-09-29 03:57:28 - progress_bar.py[line:274] - INFO: epoch 001:  10917 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.8, ups=0.9, wpb=101.9, bsz=40, num_updates=10900, lr=4.48891e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26072
2022-09-29 03:57:39 - progress_bar.py[line:274] - INFO: epoch 001:  10927 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89, ups=0.87, wpb=101.7, bsz=40, num_updates=10910, lr=4.48825e-05, gnorm=0.886, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26084
2022-09-29 03:57:50 - progress_bar.py[line:274] - INFO: epoch 001:  10937 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.5, ups=0.87, wpb=101.2, bsz=40, num_updates=10920, lr=4.48759e-05, gnorm=0.707, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26095
2022-09-29 03:58:01 - progress_bar.py[line:274] - INFO: epoch 001:  10947 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.5, ups=0.91, wpb=102.8, bsz=40, num_updates=10930, lr=4.48693e-05, gnorm=0.847, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26106
2022-09-29 03:58:13 - progress_bar.py[line:274] - INFO: epoch 001:  10957 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.88, wpb=101.1, bsz=40, num_updates=10940, lr=4.48627e-05, gnorm=0.851, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26118
2022-09-29 03:58:24 - progress_bar.py[line:274] - INFO: epoch 001:  10967 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.1, ups=0.92, wpb=102.6, bsz=40, num_updates=10950, lr=4.48561e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26128
2022-09-29 03:58:35 - progress_bar.py[line:274] - INFO: epoch 001:  10977 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.89, wpb=102.8, bsz=40, num_updates=10960, lr=4.48495e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26140
2022-09-29 03:58:46 - progress_bar.py[line:274] - INFO: epoch 001:  10987 / 15783 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90, ups=0.9, wpb=100.5, bsz=40, num_updates=10970, lr=4.48429e-05, gnorm=0.992, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26151
2022-09-29 03:58:57 - progress_bar.py[line:274] - INFO: epoch 001:  10997 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.5, ups=0.91, wpb=102.9, bsz=40, num_updates=10980, lr=4.48363e-05, gnorm=0.951, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=26162
2022-09-29 03:59:08 - progress_bar.py[line:274] - INFO: epoch 001:  11007 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.5, ups=0.9, wpb=102, bsz=40, num_updates=10990, lr=4.48297e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26173
2022-09-29 03:59:19 - progress_bar.py[line:274] - INFO: epoch 001:  11017 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.89, wpb=100.6, bsz=40, num_updates=11000, lr=4.48231e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26184
2022-09-29 03:59:31 - progress_bar.py[line:274] - INFO: epoch 001:  11027 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.88, wpb=102.1, bsz=40, num_updates=11010, lr=4.48165e-05, gnorm=0.732, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26196
2022-09-29 03:59:42 - progress_bar.py[line:274] - INFO: epoch 001:  11037 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.88, wpb=101.6, bsz=40, num_updates=11020, lr=4.48099e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=26207
2022-09-29 03:59:53 - progress_bar.py[line:274] - INFO: epoch 001:  11047 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.4, ups=0.91, wpb=101.2, bsz=40, num_updates=11030, lr=4.48033e-05, gnorm=0.694, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26218
2022-09-29 04:00:04 - progress_bar.py[line:274] - INFO: epoch 001:  11057 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.2, ups=0.91, wpb=102.2, bsz=40, num_updates=11040, lr=4.47967e-05, gnorm=0.702, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26229
2022-09-29 04:00:15 - progress_bar.py[line:274] - INFO: epoch 001:  11067 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.1, ups=0.93, wpb=100.9, bsz=40, num_updates=11050, lr=4.47901e-05, gnorm=0.806, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26240
2022-09-29 04:00:27 - progress_bar.py[line:274] - INFO: epoch 001:  11077 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.6, ups=0.9, wpb=104.1, bsz=40, num_updates=11060, lr=4.47835e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26251
2022-09-29 04:00:38 - progress_bar.py[line:274] - INFO: epoch 001:  11087 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.9, ups=0.89, wpb=102.6, bsz=40, num_updates=11070, lr=4.47769e-05, gnorm=0.831, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26263
2022-09-29 04:00:50 - progress_bar.py[line:274] - INFO: epoch 001:  11097 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.88, wpb=102.4, bsz=40, num_updates=11080, lr=4.47703e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26274
2022-09-29 04:01:01 - progress_bar.py[line:274] - INFO: epoch 001:  11107 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=100.5, bsz=40, num_updates=11090, lr=4.47637e-05, gnorm=0.855, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26286
2022-09-29 04:01:12 - progress_bar.py[line:274] - INFO: epoch 001:  11117 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94, ups=0.92, wpb=102.6, bsz=40, num_updates=11100, lr=4.47571e-05, gnorm=0.841, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26297
2022-09-29 04:01:23 - progress_bar.py[line:274] - INFO: epoch 001:  11127 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.9, wpb=103.6, bsz=40, num_updates=11110, lr=4.47505e-05, gnorm=0.7, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26308
2022-09-29 04:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  11137 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.1, ups=0.9, wpb=101.4, bsz=40, num_updates=11120, lr=4.47439e-05, gnorm=0.869, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26319
2022-09-29 04:01:46 - progress_bar.py[line:274] - INFO: epoch 001:  11147 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.5, ups=0.89, wpb=98.7, bsz=40, num_updates=11130, lr=4.47373e-05, gnorm=0.938, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26330
2022-09-29 04:01:56 - progress_bar.py[line:274] - INFO: epoch 001:  11157 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.9, ups=0.91, wpb=100.8, bsz=40, num_updates=11140, lr=4.47307e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26341
2022-09-29 04:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  11167 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94, ups=0.94, wpb=99.8, bsz=40, num_updates=11150, lr=4.47241e-05, gnorm=0.781, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26352
2022-09-29 04:02:18 - progress_bar.py[line:274] - INFO: epoch 001:  11177 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.9, wpb=100.1, bsz=40, num_updates=11160, lr=4.47175e-05, gnorm=0.743, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26363
2022-09-29 04:02:30 - progress_bar.py[line:274] - INFO: epoch 001:  11187 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.7, ups=0.87, wpb=101.2, bsz=40, num_updates=11170, lr=4.47109e-05, gnorm=0.891, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26375
2022-09-29 04:02:41 - progress_bar.py[line:274] - INFO: epoch 001:  11197 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.1, ups=0.91, wpb=99.8, bsz=40, num_updates=11180, lr=4.47043e-05, gnorm=0.796, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26386
2022-09-29 04:02:52 - progress_bar.py[line:274] - INFO: epoch 001:  11207 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.1, ups=0.89, wpb=101.8, bsz=40, num_updates=11190, lr=4.46977e-05, gnorm=0.871, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26397
2022-09-29 04:03:03 - progress_bar.py[line:274] - INFO: epoch 001:  11217 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.6, ups=0.89, wpb=102.4, bsz=40, num_updates=11200, lr=4.46911e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26408
2022-09-29 04:03:15 - progress_bar.py[line:274] - INFO: epoch 001:  11227 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.4, ups=0.88, wpb=103.3, bsz=40, num_updates=11210, lr=4.46845e-05, gnorm=0.734, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26419
2022-09-29 04:03:26 - progress_bar.py[line:274] - INFO: epoch 001:  11237 / 15783 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.3, ups=0.86, wpb=99.9, bsz=40, num_updates=11220, lr=4.46779e-05, gnorm=0.871, clip=20, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=26431
2022-09-29 04:03:37 - progress_bar.py[line:274] - INFO: epoch 001:  11247 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.9, ups=0.92, wpb=101.9, bsz=40, num_updates=11230, lr=4.46713e-05, gnorm=0.824, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26442
2022-09-29 04:03:49 - progress_bar.py[line:274] - INFO: epoch 001:  11257 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.87, wpb=102.6, bsz=40, num_updates=11240, lr=4.46647e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26453
2022-09-29 04:04:00 - progress_bar.py[line:274] - INFO: epoch 001:  11267 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92, ups=0.89, wpb=102.9, bsz=40, num_updates=11250, lr=4.46581e-05, gnorm=0.818, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26465
2022-09-29 04:04:04 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 04:04:12 - progress_bar.py[line:274] - INFO: epoch 001:  11278 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=84.2, ups=0.83, wpb=101.2, bsz=40, num_updates=11260, lr=4.46515e-05, gnorm=0.824, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=26477
2022-09-29 04:04:23 - progress_bar.py[line:274] - INFO: epoch 001:  11288 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.88, wpb=101.8, bsz=40, num_updates=11270, lr=4.46449e-05, gnorm=0.86, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26488
2022-09-29 04:04:34 - progress_bar.py[line:274] - INFO: epoch 001:  11298 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.9, wpb=100.8, bsz=40, num_updates=11280, lr=4.46383e-05, gnorm=0.783, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26499
2022-09-29 04:04:46 - progress_bar.py[line:274] - INFO: epoch 001:  11308 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=11290, lr=4.46317e-05, gnorm=0.891, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26510
2022-09-29 04:04:57 - progress_bar.py[line:274] - INFO: epoch 001:  11318 / 15783 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.5, ups=0.9, wpb=103, bsz=40, num_updates=11300, lr=4.46251e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26522
2022-09-29 04:05:08 - progress_bar.py[line:274] - INFO: epoch 001:  11328 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.9, wpb=99.9, bsz=40, num_updates=11310, lr=4.46185e-05, gnorm=0.74, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26533
2022-09-29 04:05:19 - progress_bar.py[line:274] - INFO: epoch 001:  11338 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.87, wpb=102.5, bsz=40, num_updates=11320, lr=4.46119e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26544
2022-09-29 04:05:31 - progress_bar.py[line:274] - INFO: epoch 001:  11348 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.8, ups=0.87, wpb=101.5, bsz=40, num_updates=11330, lr=4.46053e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26556
2022-09-29 04:05:42 - progress_bar.py[line:274] - INFO: epoch 001:  11358 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.88, wpb=101.9, bsz=40, num_updates=11340, lr=4.45987e-05, gnorm=0.984, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26567
2022-09-29 04:05:53 - progress_bar.py[line:274] - INFO: epoch 001:  11368 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.3, ups=0.91, wpb=102.7, bsz=40, num_updates=11350, lr=4.45921e-05, gnorm=0.874, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26578
2022-09-29 04:06:04 - progress_bar.py[line:274] - INFO: epoch 001:  11378 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.9, wpb=102.1, bsz=40, num_updates=11360, lr=4.45855e-05, gnorm=0.888, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26589
2022-09-29 04:06:16 - progress_bar.py[line:274] - INFO: epoch 001:  11388 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.87, wpb=102.7, bsz=40, num_updates=11370, lr=4.45789e-05, gnorm=0.881, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26600
2022-09-29 04:06:27 - progress_bar.py[line:274] - INFO: epoch 001:  11398 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.91, wpb=101.4, bsz=40, num_updates=11380, lr=4.45723e-05, gnorm=0.861, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26611
2022-09-29 04:06:37 - progress_bar.py[line:274] - INFO: epoch 001:  11408 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.9, ups=0.94, wpb=102.2, bsz=40, num_updates=11390, lr=4.45657e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26622
2022-09-29 04:06:49 - progress_bar.py[line:274] - INFO: epoch 001:  11418 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.8, ups=0.87, wpb=101.4, bsz=40, num_updates=11400, lr=4.45591e-05, gnorm=0.692, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=26634
2022-09-29 04:07:00 - progress_bar.py[line:274] - INFO: epoch 001:  11428 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.88, wpb=101.3, bsz=40, num_updates=11410, lr=4.45525e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26645
2022-09-29 04:07:11 - progress_bar.py[line:274] - INFO: epoch 001:  11438 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.6, ups=0.9, wpb=101.2, bsz=40, num_updates=11420, lr=4.45459e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=26656
2022-09-29 04:07:23 - progress_bar.py[line:274] - INFO: epoch 001:  11448 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.9, ups=0.89, wpb=101.5, bsz=40, num_updates=11430, lr=4.45393e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26668
2022-09-29 04:07:34 - progress_bar.py[line:274] - INFO: epoch 001:  11458 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.9, ups=0.88, wpb=99.2, bsz=40, num_updates=11440, lr=4.45327e-05, gnorm=0.883, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26679
2022-09-29 04:07:45 - progress_bar.py[line:274] - INFO: epoch 001:  11468 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.8, ups=0.92, wpb=102, bsz=40, num_updates=11450, lr=4.45261e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=26690
2022-09-29 04:07:56 - progress_bar.py[line:274] - INFO: epoch 001:  11478 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.1, ups=0.88, wpb=101.7, bsz=40, num_updates=11460, lr=4.45195e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26701
2022-09-29 04:08:07 - progress_bar.py[line:274] - INFO: epoch 001:  11488 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.2, ups=0.91, wpb=100.9, bsz=40, num_updates=11470, lr=4.45129e-05, gnorm=0.83, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26712
2022-09-29 04:08:18 - progress_bar.py[line:274] - INFO: epoch 001:  11498 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.91, wpb=101.4, bsz=40, num_updates=11480, lr=4.45063e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26723
2022-09-29 04:08:30 - progress_bar.py[line:274] - INFO: epoch 001:  11508 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.1, ups=0.88, wpb=100.7, bsz=40, num_updates=11490, lr=4.44997e-05, gnorm=0.795, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26735
2022-09-29 04:08:41 - progress_bar.py[line:274] - INFO: epoch 001:  11518 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.3, ups=0.86, wpb=98.6, bsz=40, num_updates=11500, lr=4.44931e-05, gnorm=0.857, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26746
2022-09-29 04:08:53 - progress_bar.py[line:274] - INFO: epoch 001:  11528 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.9, wpb=102.1, bsz=40, num_updates=11510, lr=4.44865e-05, gnorm=0.853, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26757
2022-09-29 04:09:04 - progress_bar.py[line:274] - INFO: epoch 001:  11538 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.91, wpb=101.6, bsz=40, num_updates=11520, lr=4.44799e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26768
2022-09-29 04:09:15 - progress_bar.py[line:274] - INFO: epoch 001:  11548 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.4, ups=0.9, wpb=103.2, bsz=40, num_updates=11530, lr=4.44733e-05, gnorm=0.807, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26779
2022-09-29 04:09:26 - progress_bar.py[line:274] - INFO: epoch 001:  11558 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=11540, lr=4.44667e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26791
2022-09-29 04:09:37 - progress_bar.py[line:274] - INFO: epoch 001:  11568 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.5, ups=0.9, wpb=101.8, bsz=40, num_updates=11550, lr=4.44601e-05, gnorm=0.825, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26802
2022-09-29 04:09:49 - progress_bar.py[line:274] - INFO: epoch 001:  11578 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.8, ups=0.86, wpb=101.6, bsz=40, num_updates=11560, lr=4.44535e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=26813
2022-09-29 04:10:00 - progress_bar.py[line:274] - INFO: epoch 001:  11588 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.88, wpb=103, bsz=40, num_updates=11570, lr=4.44469e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26825
2022-09-29 04:10:11 - progress_bar.py[line:274] - INFO: epoch 001:  11598 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.88, wpb=102, bsz=40, num_updates=11580, lr=4.44403e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26836
2022-09-29 04:10:23 - progress_bar.py[line:274] - INFO: epoch 001:  11608 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.89, wpb=102.4, bsz=40, num_updates=11590, lr=4.44337e-05, gnorm=0.78, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26847
2022-09-29 04:10:34 - progress_bar.py[line:274] - INFO: epoch 001:  11618 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.5, ups=0.87, wpb=101.2, bsz=40, num_updates=11600, lr=4.44271e-05, gnorm=0.848, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26859
2022-09-29 04:10:45 - progress_bar.py[line:274] - INFO: epoch 001:  11628 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.8, ups=0.9, wpb=102.3, bsz=40, num_updates=11610, lr=4.44205e-05, gnorm=0.724, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26870
2022-09-29 04:10:56 - progress_bar.py[line:274] - INFO: epoch 001:  11638 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.1, ups=0.91, wpb=101, bsz=40, num_updates=11620, lr=4.44139e-05, gnorm=0.756, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26881
2022-09-29 04:11:08 - progress_bar.py[line:274] - INFO: epoch 001:  11648 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.87, wpb=101.9, bsz=40, num_updates=11630, lr=4.44073e-05, gnorm=0.791, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26892
2022-09-29 04:11:19 - progress_bar.py[line:274] - INFO: epoch 001:  11658 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.6, ups=0.88, wpb=101, bsz=40, num_updates=11640, lr=4.44007e-05, gnorm=0.885, clip=50, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=26904
2022-09-29 04:11:30 - progress_bar.py[line:274] - INFO: epoch 001:  11668 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.6, ups=0.92, wpb=101.6, bsz=40, num_updates=11650, lr=4.43941e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26915
2022-09-29 04:11:41 - progress_bar.py[line:274] - INFO: epoch 001:  11678 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.91, wpb=100.1, bsz=40, num_updates=11660, lr=4.43875e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=26926
2022-09-29 04:11:52 - progress_bar.py[line:274] - INFO: epoch 001:  11688 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.9, wpb=100.7, bsz=40, num_updates=11670, lr=4.43809e-05, gnorm=0.79, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26937
2022-09-29 04:12:03 - progress_bar.py[line:274] - INFO: epoch 001:  11698 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=100.9, bsz=40, num_updates=11680, lr=4.43743e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26948
2022-09-29 04:12:15 - progress_bar.py[line:274] - INFO: epoch 001:  11708 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=86.2, ups=0.87, wpb=99.5, bsz=40, num_updates=11690, lr=4.43677e-05, gnorm=0.913, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26959
2022-09-29 04:12:26 - progress_bar.py[line:274] - INFO: epoch 001:  11718 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=11700, lr=4.43611e-05, gnorm=0.691, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26971
2022-09-29 04:12:37 - progress_bar.py[line:274] - INFO: epoch 001:  11728 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.89, wpb=101.6, bsz=40, num_updates=11710, lr=4.43545e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26982
2022-09-29 04:12:48 - progress_bar.py[line:274] - INFO: epoch 001:  11738 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.2, ups=0.92, wpb=101.3, bsz=40, num_updates=11720, lr=4.43479e-05, gnorm=0.761, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26993
2022-09-29 04:12:59 - progress_bar.py[line:274] - INFO: epoch 001:  11748 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.88, wpb=100.9, bsz=40, num_updates=11730, lr=4.43413e-05, gnorm=0.891, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=27004
2022-09-29 04:13:10 - progress_bar.py[line:274] - INFO: epoch 001:  11758 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.89, wpb=102.4, bsz=40, num_updates=11740, lr=4.43347e-05, gnorm=0.694, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=27015
2022-09-29 04:13:22 - progress_bar.py[line:274] - INFO: epoch 001:  11768 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.89, wpb=102.5, bsz=40, num_updates=11750, lr=4.43281e-05, gnorm=0.783, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=27027
2022-09-29 04:13:33 - progress_bar.py[line:274] - INFO: epoch 001:  11778 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.4, ups=0.92, wpb=104.2, bsz=40, num_updates=11760, lr=4.43215e-05, gnorm=0.755, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27038
2022-09-29 04:13:44 - progress_bar.py[line:274] - INFO: epoch 001:  11788 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.2, ups=0.89, wpb=100.5, bsz=40, num_updates=11770, lr=4.43149e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27049
2022-09-29 04:13:55 - progress_bar.py[line:274] - INFO: epoch 001:  11798 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.7, ups=0.9, wpb=102.3, bsz=40, num_updates=11780, lr=4.43083e-05, gnorm=0.739, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27060
2022-09-29 04:14:06 - progress_bar.py[line:274] - INFO: epoch 001:  11808 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.4, ups=0.91, wpb=102.1, bsz=40, num_updates=11790, lr=4.43017e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=27071
2022-09-29 04:14:17 - progress_bar.py[line:274] - INFO: epoch 001:  11818 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=11800, lr=4.42951e-05, gnorm=0.782, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=27082
2022-09-29 04:14:29 - progress_bar.py[line:274] - INFO: epoch 001:  11828 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.89, wpb=102.4, bsz=40, num_updates=11810, lr=4.42885e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=27093
2022-09-29 04:14:40 - progress_bar.py[line:274] - INFO: epoch 001:  11838 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=11820, lr=4.42819e-05, gnorm=0.811, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27105
2022-09-29 04:14:51 - progress_bar.py[line:274] - INFO: epoch 001:  11848 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.9, wpb=101, bsz=40, num_updates=11830, lr=4.42753e-05, gnorm=0.794, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=27116
2022-09-29 04:15:02 - progress_bar.py[line:274] - INFO: epoch 001:  11858 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.4, ups=0.87, wpb=103, bsz=40, num_updates=11840, lr=4.42687e-05, gnorm=0.751, clip=10, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=27127
2022-09-29 04:15:14 - progress_bar.py[line:274] - INFO: epoch 001:  11868 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=11850, lr=4.42621e-05, gnorm=0.745, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=27139
2022-09-29 04:15:25 - progress_bar.py[line:274] - INFO: epoch 001:  11878 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.5, ups=0.88, wpb=100.7, bsz=40, num_updates=11860, lr=4.42555e-05, gnorm=0.763, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27150
2022-09-29 04:15:36 - progress_bar.py[line:274] - INFO: epoch 001:  11888 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.9, wpb=100.4, bsz=40, num_updates=11870, lr=4.42489e-05, gnorm=0.937, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27161
2022-09-29 04:15:47 - progress_bar.py[line:274] - INFO: epoch 001:  11898 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.9, wpb=102.5, bsz=40, num_updates=11880, lr=4.42423e-05, gnorm=0.889, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=27172
2022-09-29 04:15:59 - progress_bar.py[line:274] - INFO: epoch 001:  11908 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=11890, lr=4.42357e-05, gnorm=0.77, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=27183
2022-09-29 04:16:09 - progress_bar.py[line:274] - INFO: epoch 001:  11918 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92, ups=0.92, wpb=100.5, bsz=40, num_updates=11900, lr=4.42291e-05, gnorm=0.896, clip=50, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=27194
2022-09-29 04:16:21 - progress_bar.py[line:274] - INFO: epoch 001:  11928 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=101.5, bsz=40, num_updates=11910, lr=4.42225e-05, gnorm=0.821, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=27206
2022-09-29 04:16:32 - progress_bar.py[line:274] - INFO: epoch 001:  11938 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.6, ups=0.91, wpb=102.7, bsz=40, num_updates=11920, lr=4.42159e-05, gnorm=0.905, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27216
2022-09-29 04:16:43 - progress_bar.py[line:274] - INFO: epoch 001:  11948 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89, ups=0.88, wpb=101.2, bsz=40, num_updates=11930, lr=4.42093e-05, gnorm=0.746, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=27228
2022-09-29 04:16:54 - progress_bar.py[line:274] - INFO: epoch 001:  11958 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.89, wpb=102.6, bsz=40, num_updates=11940, lr=4.42027e-05, gnorm=0.726, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=27239
2022-09-29 04:17:05 - progress_bar.py[line:274] - INFO: epoch 001:  11968 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.7, ups=0.91, wpb=102.5, bsz=40, num_updates=11950, lr=4.41961e-05, gnorm=0.697, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=27250
2022-09-29 04:17:16 - progress_bar.py[line:274] - INFO: epoch 001:  11978 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.9, ups=0.9, wpb=101.9, bsz=40, num_updates=11960, lr=4.41895e-05, gnorm=0.883, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27261
2022-09-29 04:17:28 - progress_bar.py[line:274] - INFO: epoch 001:  11988 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.7, ups=0.92, wpb=101.7, bsz=40, num_updates=11970, lr=4.41829e-05, gnorm=0.75, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27272
2022-09-29 04:17:39 - progress_bar.py[line:274] - INFO: epoch 001:  11998 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.9, ups=0.91, wpb=103, bsz=40, num_updates=11980, lr=4.41763e-05, gnorm=0.802, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=27284
2022-09-29 04:17:50 - progress_bar.py[line:274] - INFO: epoch 001:  12008 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.91, wpb=102.2, bsz=40, num_updates=11990, lr=4.41697e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=27295
2022-09-29 04:18:01 - progress_bar.py[line:274] - INFO: epoch 001:  12018 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.89, wpb=101.9, bsz=40, num_updates=12000, lr=4.41631e-05, gnorm=0.789, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=27306
2022-09-29 04:18:01 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-29 04:18:02 - train.py[line:549] - INFO: 0 / 14103
2022-09-29 04:18:02 - train.py[line:551] - INFO: load:0.81 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-29 04:21:17 - train.py[line:549] - INFO: 200 / 14103
2022-09-29 04:21:17 - train.py[line:551] - INFO: load:0.83 valid_run:194.90 task_valid:186.72 collect_output:6.98
2022-09-29 04:24:29 - train.py[line:549] - INFO: 400 / 14103
2022-09-29 04:24:29 - train.py[line:551] - INFO: load:0.86 valid_run:386.43 task_valid:372.75 collect_output:11.23
2022-09-29 04:27:41 - train.py[line:549] - INFO: 600 / 14103
2022-09-29 04:27:41 - train.py[line:551] - INFO: load:0.89 valid_run:579.03 task_valid:558.39 collect_output:16.82
2022-09-29 04:30:52 - train.py[line:549] - INFO: 800 / 14103
2022-09-29 04:30:52 - train.py[line:551] - INFO: load:0.91 valid_run:769.54 task_valid:744.33 collect_output:20.18
2022-09-29 04:34:03 - train.py[line:549] - INFO: 1000 / 14103
2022-09-29 04:34:03 - train.py[line:551] - INFO: load:0.93 valid_run:960.26 task_valid:930.49 collect_output:23.50
2022-09-29 04:34:29 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.26 GiB (GPU 0; 39.59 GiB total capacity; 13.62 GiB already allocated; 5.22 GiB free; 31.89 GiB reserved in total by PyTorch)
2022-09-29 04:34:29 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 30        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13948 MB |   19334 MB |    3837 TB |    3837 TB |
|       from large pool |   13803 MB |   19190 MB |    3836 TB |    3836 TB |
|       from small pool |     144 MB |     159 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13948 MB |   19334 MB |    3837 TB |    3837 TB |
|       from large pool |   13803 MB |   19190 MB |    3836 TB |    3836 TB |
|       from small pool |     144 MB |     159 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32656 MB |   37988 MB |  350912 MB |  318256 MB |
|       from large pool |   32510 MB |   37842 MB |  350468 MB |  317958 MB |
|       from small pool |     146 MB |     162 MB |     444 MB |     298 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   18707 MB |   25452 MB |    3413 TB |    3413 TB |
|       from large pool |   18706 MB |   25450 MB |    3411 TB |    3411 TB |
|       from small pool |       1 MB |       6 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3671    |    3695    |  186973 K  |  186970 K  |
|       from large pool |     564    |     585    |   60379 K  |   60378 K  |
|       from small pool |    3107    |    3119    |  126594 K  |  126591 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3671    |    3695    |  186973 K  |  186970 K  |
|       from large pool |     564    |     585    |   60379 K  |   60378 K  |
|       from small pool |    3107    |    3119    |  126594 K  |  126591 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     184    |     210    |     692    |     508    |
|       from large pool |     111    |     129    |     470    |     359    |
|       from small pool |      73    |      81    |     222    |     149    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     125    |     144    |  130831 K  |  130831 K  |
|       from large pool |      87    |      96    |   27380 K  |   27379 K  |
|       from small pool |      38    |      53    |  103451 K  |  103451 K  |
|===========================================================================|

2022-09-29 04:34:29 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-29 04:34:29 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-29 04:37:21 - train.py[line:549] - INFO: 1200 / 14103
2022-09-29 04:37:21 - train.py[line:551] - INFO: load:0.96 valid_run:1158.55 task_valid:1120.94 collect_output:28.53
2022-09-29 04:40:35 - train.py[line:549] - INFO: 1400 / 14103
2022-09-29 04:40:35 - train.py[line:551] - INFO: load:0.98 valid_run:1352.61 task_valid:1310.50 collect_output:31.88
2022-09-29 04:43:48 - train.py[line:549] - INFO: 1600 / 14103
2022-09-29 04:43:48 - train.py[line:551] - INFO: load:1.01 valid_run:1545.78 task_valid:1499.57 collect_output:34.80
2022-09-29 04:47:01 - train.py[line:549] - INFO: 1800 / 14103
2022-09-29 04:47:01 - train.py[line:551] - INFO: load:1.03 valid_run:1738.55 task_valid:1685.67 collect_output:40.33
2022-09-29 04:50:10 - train.py[line:549] - INFO: 2000 / 14103
2022-09-29 04:50:10 - train.py[line:551] - INFO: load:1.06 valid_run:1927.78 task_valid:1871.81 collect_output:42.28
2022-09-29 04:53:19 - train.py[line:549] - INFO: 2200 / 14103
2022-09-29 04:53:19 - train.py[line:551] - INFO: load:1.08 valid_run:2116.78 task_valid:2056.65 collect_output:45.30
2022-09-29 04:56:31 - train.py[line:549] - INFO: 2400 / 14103
2022-09-29 04:56:31 - train.py[line:551] - INFO: load:1.10 valid_run:2308.36 task_valid:2241.42 collect_output:51.03
2022-09-29 04:59:50 - train.py[line:549] - INFO: 2600 / 14103
2022-09-29 04:59:50 - train.py[line:551] - INFO: load:1.13 valid_run:2506.92 task_valid:2435.04 collect_output:54.67
2022-09-29 05:03:01 - train.py[line:549] - INFO: 2800 / 14103
2022-09-29 05:03:01 - train.py[line:551] - INFO: load:1.15 valid_run:2697.78 task_valid:2620.21 collect_output:59.17
2022-09-29 05:06:15 - train.py[line:549] - INFO: 3000 / 14103
2022-09-29 05:06:15 - train.py[line:551] - INFO: load:1.17 valid_run:2891.63 task_valid:2807.03 collect_output:64.97
2022-09-29 05:09:24 - train.py[line:549] - INFO: 3200 / 14103
2022-09-29 05:09:24 - train.py[line:551] - INFO: load:1.20 valid_run:3081.44 task_valid:2990.01 collect_output:70.58
2022-09-29 05:12:38 - train.py[line:549] - INFO: 3400 / 14103
2022-09-29 05:12:38 - train.py[line:551] - INFO: load:1.22 valid_run:3274.75 task_valid:3174.75 collect_output:77.96
2022-09-29 05:15:52 - train.py[line:549] - INFO: 3600 / 14103
2022-09-29 05:15:52 - train.py[line:551] - INFO: load:1.24 valid_run:3468.51 task_valid:3361.20 collect_output:84.08
2022-09-29 05:19:03 - train.py[line:549] - INFO: 3800 / 14103
2022-09-29 05:19:03 - train.py[line:551] - INFO: load:1.27 valid_run:3660.03 task_valid:3544.22 collect_output:91.38
2022-09-29 05:22:12 - train.py[line:549] - INFO: 4000 / 14103
2022-09-29 05:22:12 - train.py[line:551] - INFO: load:1.29 valid_run:3848.62 task_valid:3727.54 collect_output:95.50
2022-09-29 05:25:23 - train.py[line:549] - INFO: 4200 / 14103
2022-09-29 05:25:23 - train.py[line:551] - INFO: load:1.31 valid_run:4040.26 task_valid:3916.23 collect_output:97.28
2022-09-29 05:28:32 - train.py[line:549] - INFO: 4400 / 14103
2022-09-29 05:28:32 - train.py[line:551] - INFO: load:1.34 valid_run:4228.89 task_valid:4097.08 collect_output:103.95
2022-09-29 05:31:45 - train.py[line:549] - INFO: 4600 / 14103
2022-09-29 05:31:45 - train.py[line:551] - INFO: load:1.36 valid_run:4421.22 task_valid:4282.01 collect_output:110.16
2022-09-29 05:34:53 - train.py[line:549] - INFO: 4800 / 14103
2022-09-29 05:34:53 - train.py[line:551] - INFO: load:1.38 valid_run:4609.81 task_valid:4465.35 collect_output:114.25
2022-09-29 05:38:03 - train.py[line:549] - INFO: 5000 / 14103
2022-09-29 05:38:03 - train.py[line:551] - INFO: load:1.41 valid_run:4799.89 task_valid:4649.76 collect_output:118.80
2022-09-29 05:41:13 - train.py[line:549] - INFO: 5200 / 14103
2022-09-29 05:41:13 - train.py[line:551] - INFO: load:1.43 valid_run:4989.65 task_valid:4833.45 collect_output:123.78
2022-09-29 05:44:26 - train.py[line:549] - INFO: 5400 / 14103
2022-09-29 05:44:26 - train.py[line:551] - INFO: load:1.45 valid_run:5182.00 task_valid:5022.26 collect_output:126.23
2022-09-29 05:47:37 - train.py[line:549] - INFO: 5600 / 14103
2022-09-29 05:47:37 - train.py[line:551] - INFO: load:1.47 valid_run:5373.63 task_valid:5209.40 collect_output:129.64
2022-09-29 05:50:51 - train.py[line:549] - INFO: 5800 / 14103
2022-09-29 05:50:51 - train.py[line:551] - INFO: load:1.50 valid_run:5567.01 task_valid:5395.76 collect_output:135.61
2022-09-29 05:53:59 - train.py[line:549] - INFO: 6000 / 14103
2022-09-29 05:53:59 - train.py[line:551] - INFO: load:1.52 valid_run:5755.29 task_valid:5576.55 collect_output:142.05
2022-09-29 05:57:11 - train.py[line:549] - INFO: 6200 / 14103
2022-09-29 05:57:11 - train.py[line:551] - INFO: load:1.54 valid_run:5947.37 task_valid:5762.02 collect_output:147.64
2022-09-29 06:00:21 - train.py[line:549] - INFO: 6400 / 14103
2022-09-29 06:00:21 - train.py[line:551] - INFO: load:1.57 valid_run:6137.52 task_valid:5947.33 collect_output:151.42
2022-09-29 06:03:31 - train.py[line:549] - INFO: 6600 / 14103
2022-09-29 06:03:31 - train.py[line:551] - INFO: load:1.59 valid_run:6326.60 task_valid:6128.43 collect_output:158.35
2022-09-29 06:06:43 - train.py[line:549] - INFO: 6800 / 14103
2022-09-29 06:06:43 - train.py[line:551] - INFO: load:1.61 valid_run:6519.49 task_valid:6312.19 collect_output:166.42
2022-09-29 06:09:57 - train.py[line:549] - INFO: 7000 / 14103
2022-09-29 06:09:57 - train.py[line:551] - INFO: load:1.64 valid_run:6712.73 task_valid:6501.46 collect_output:169.25
2022-09-29 06:13:10 - train.py[line:549] - INFO: 7200 / 14103
2022-09-29 06:13:10 - train.py[line:551] - INFO: load:1.66 valid_run:6906.18 task_valid:6691.28 collect_output:171.74
2022-09-29 06:16:22 - train.py[line:549] - INFO: 7400 / 14103
2022-09-29 06:16:22 - train.py[line:551] - INFO: load:1.69 valid_run:7097.95 task_valid:6873.38 collect_output:180.32
2022-09-29 06:19:32 - train.py[line:549] - INFO: 7600 / 14103
2022-09-29 06:19:32 - train.py[line:551] - INFO: load:1.71 valid_run:7287.63 task_valid:7054.66 collect_output:187.61
2022-09-29 06:22:48 - train.py[line:549] - INFO: 7800 / 14103
2022-09-29 06:22:48 - train.py[line:551] - INFO: load:1.73 valid_run:7483.45 task_valid:7242.35 collect_output:194.62
2022-09-29 06:25:58 - train.py[line:549] - INFO: 8000 / 14103
2022-09-29 06:25:58 - train.py[line:551] - INFO: load:1.76 valid_run:7674.14 task_valid:7422.24 collect_output:204.30
2022-09-29 06:29:08 - train.py[line:549] - INFO: 8200 / 14103
2022-09-29 06:29:08 - train.py[line:551] - INFO: load:1.79 valid_run:7863.85 task_valid:7605.94 collect_output:209.19
2022-09-29 06:32:18 - train.py[line:549] - INFO: 8400 / 14103
2022-09-29 06:32:18 - train.py[line:551] - INFO: load:1.81 valid_run:8053.23 task_valid:7789.19 collect_output:214.20
2022-09-29 06:35:29 - train.py[line:549] - INFO: 8600 / 14103
2022-09-29 06:35:29 - train.py[line:551] - INFO: load:1.83 valid_run:8244.61 task_valid:7973.66 collect_output:220.06
2022-09-29 06:38:38 - train.py[line:549] - INFO: 8800 / 14103
2022-09-29 06:38:38 - train.py[line:551] - INFO: load:1.86 valid_run:8433.63 task_valid:8158.70 collect_output:222.92
2022-09-29 06:41:49 - train.py[line:549] - INFO: 9000 / 14103
2022-09-29 06:41:49 - train.py[line:551] - INFO: load:1.88 valid_run:8624.81 task_valid:8342.22 collect_output:229.48
2022-09-29 06:45:04 - train.py[line:549] - INFO: 9200 / 14103
2022-09-29 06:45:04 - train.py[line:551] - INFO: load:1.90 valid_run:8818.99 task_valid:8525.01 collect_output:239.81
2022-09-29 06:48:17 - train.py[line:549] - INFO: 9400 / 14103
2022-09-29 06:48:17 - train.py[line:551] - INFO: load:1.93 valid_run:9012.53 task_valid:8712.02 collect_output:245.27
2022-09-29 06:51:28 - train.py[line:549] - INFO: 9600 / 14103
2022-09-29 06:51:28 - train.py[line:551] - INFO: load:1.95 valid_run:9203.61 task_valid:8896.04 collect_output:251.29
2022-09-29 06:54:39 - train.py[line:549] - INFO: 9800 / 14103
2022-09-29 06:54:39 - train.py[line:551] - INFO: load:1.97 valid_run:9394.52 task_valid:9084.18 collect_output:252.98
2022-09-29 06:57:51 - train.py[line:549] - INFO: 10000 / 14103
2022-09-29 06:57:51 - train.py[line:551] - INFO: load:2.00 valid_run:9586.24 task_valid:9272.21 collect_output:255.59
2022-09-29 07:01:02 - train.py[line:549] - INFO: 10200 / 14103
2022-09-29 07:01:02 - train.py[line:551] - INFO: load:2.02 valid_run:9777.51 task_valid:9455.28 collect_output:262.74
2022-09-29 07:04:15 - train.py[line:549] - INFO: 10400 / 14103
2022-09-29 07:04:15 - train.py[line:551] - INFO: load:2.04 valid_run:9970.04 task_valid:9639.36 collect_output:270.11
2022-09-29 07:07:28 - train.py[line:549] - INFO: 10600 / 14103
2022-09-29 07:07:28 - train.py[line:551] - INFO: load:2.07 valid_run:10162.84 task_valid:9821.47 collect_output:279.75
2022-09-29 07:10:40 - train.py[line:549] - INFO: 10800 / 14103
2022-09-29 07:10:40 - train.py[line:551] - INFO: load:2.09 valid_run:10354.77 task_valid:10005.20 collect_output:286.86
2022-09-29 07:13:52 - train.py[line:549] - INFO: 11000 / 14103
2022-09-29 07:13:52 - train.py[line:551] - INFO: load:2.11 valid_run:10546.84 task_valid:10190.15 collect_output:292.95
2022-09-29 07:17:04 - train.py[line:549] - INFO: 11200 / 14103
2022-09-29 07:17:04 - train.py[line:551] - INFO: load:2.13 valid_run:10738.61 task_valid:10374.32 collect_output:299.49
2022-09-29 07:20:19 - train.py[line:549] - INFO: 11400 / 14103
2022-09-29 07:20:19 - train.py[line:551] - INFO: load:2.16 valid_run:10933.73 task_valid:10565.84 collect_output:301.99
2022-09-29 07:23:29 - train.py[line:549] - INFO: 11600 / 14103
2022-09-29 07:23:29 - train.py[line:551] - INFO: load:2.18 valid_run:11123.90 task_valid:10751.06 collect_output:305.77
2022-09-29 07:26:42 - train.py[line:549] - INFO: 11800 / 14103
2022-09-29 07:26:42 - train.py[line:551] - INFO: load:2.21 valid_run:11316.18 task_valid:10938.09 collect_output:309.90
2022-09-29 07:29:52 - train.py[line:549] - INFO: 12000 / 14103
2022-09-29 07:29:52 - train.py[line:551] - INFO: load:2.23 valid_run:11506.58 task_valid:11122.13 collect_output:315.08
2022-09-29 07:33:04 - train.py[line:549] - INFO: 12200 / 14103
2022-09-29 07:33:04 - train.py[line:551] - INFO: load:2.25 valid_run:11698.25 task_valid:11307.84 collect_output:319.87
2022-09-29 07:36:16 - train.py[line:549] - INFO: 12400 / 14103
2022-09-29 07:36:16 - train.py[line:551] - INFO: load:2.28 valid_run:11890.11 task_valid:11493.48 collect_output:324.96
2022-09-29 07:39:27 - train.py[line:549] - INFO: 12600 / 14103
2022-09-29 07:39:27 - train.py[line:551] - INFO: load:2.31 valid_run:12080.94 task_valid:11677.47 collect_output:330.71
2022-09-29 07:42:35 - train.py[line:549] - INFO: 12800 / 14103
2022-09-29 07:42:35 - train.py[line:551] - INFO: load:2.33 valid_run:12269.31 task_valid:11860.50 collect_output:334.95
2022-09-29 07:45:46 - train.py[line:549] - INFO: 13000 / 14103
2022-09-29 07:45:46 - train.py[line:551] - INFO: load:2.35 valid_run:12459.92 task_valid:12044.35 collect_output:340.65
2022-09-29 07:48:56 - train.py[line:549] - INFO: 13200 / 14103
2022-09-29 07:48:56 - train.py[line:551] - INFO: load:2.38 valid_run:12649.88 task_valid:12225.82 collect_output:348.09
2022-09-29 07:52:10 - train.py[line:549] - INFO: 13400 / 14103
2022-09-29 07:52:10 - train.py[line:551] - INFO: load:2.40 valid_run:12843.72 task_valid:12408.19 collect_output:358.49
2022-09-29 07:55:21 - train.py[line:549] - INFO: 13600 / 14103
2022-09-29 07:55:21 - train.py[line:551] - INFO: load:2.42 valid_run:13034.75 task_valid:12589.80 collect_output:366.85
2022-09-29 07:58:33 - train.py[line:549] - INFO: 13800 / 14103
2022-09-29 07:58:33 - train.py[line:551] - INFO: load:2.45 valid_run:13227.23 task_valid:12776.43 collect_output:371.61
2022-09-29 08:01:46 - train.py[line:549] - INFO: 14000 / 14103
2022-09-29 08:01:46 - train.py[line:551] - INFO: load:2.47 valid_run:13419.65 task_valid:12961.75 collect_output:377.66
2022-09-29 08:03:22 - train.py[line:572] - INFO: scores:torch.Size([282060]) preds:torch.Size([282060]) sample_ids:torch.Size([282060])

====================================================================================================
SGG eval:     R @ 50: 0.6273;     R @ 100: 0.6542;     R @ 500: 0.6645;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1652;    mR @ 100: 0.1859;    mR @ 500: 0.2146;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0791) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2756) (attached to:0.0000) (behind:0.3733) (belonging to:0.0000) (between:0.0000) (carrying:0.6488) (covered in:0.1667) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.7703) (holding:0.3062) (in:0.3340) (in front of:0.0525) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5549) (of:0.4716) (on:0.8893) (on back of:0.0000) (over:0.0556) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.5833) (says:0.0000) (sitting on:0.3197) (standing on:0.0385) (to:0.0000) (under:0.3056) (using:1.0000) (walking in:0.0000) (walking on:0.3746) (watching:0.3333) (wearing:0.9902) (wears:0.0000) (with:0.1209) 
--------------------------------------------------------
====================================================================================================

2022-09-29 08:03:42 - train.py[line:486] - INFO: 0.6542046746998483

====================================================================================================
SGG eval:     R @ 50: 0.6273;     R @ 100: 0.6542;     R @ 500: 0.6645;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1652;    mR @ 100: 0.1859;    mR @ 500: 0.2146;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.0791) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2756) (attached to:0.0000) (behind:0.3733) (belonging to:0.0000) (between:0.0000) (carrying:0.6488) (covered in:0.1667) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.7703) (holding:0.3062) (in:0.3340) (in front of:0.0525) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5549) (of:0.4716) (on:0.8893) (on back of:0.0000) (over:0.0556) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.5833) (says:0.0000) (sitting on:0.3197) (standing on:0.0385) (to:0.0000) (under:0.3056) (using:1.0000) (walking in:0.0000) (walking on:0.3746) (watching:0.3333) (wearing:0.9902) (wears:0.0000) (with:0.1209) 
--------------------------------------------------------
====================================================================================================

2022-09-29 08:03:43 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.316 | loss_v1 0 | loss_v2 0 | nll_loss 0.121 | ntokens 59.526 | nsentences 20 | sample_size 59.526 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.654205 | ppl 1.09 | vqa_score 0.8564 | wps 62 | wpb 59.5 | bsz 20 | num_updates 12000 | best_R@100 0.654205
2022-09-29 08:03:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2022-09-29 08:03:43 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_12000.pt
2022-09-29 08:03:48 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_12000.pt
2022-09-29 08:03:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.6542046746998483) (writing took 10.312172523932531 seconds)
2022-09-29 08:04:04 - progress_bar.py[line:274] - INFO: epoch 001:  12028 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=0.1, ups=0, wpb=102.1, bsz=40, num_updates=12010, lr=4.41565e-05, gnorm=0.806, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40869
2022-09-29 08:04:15 - progress_bar.py[line:274] - INFO: epoch 001:  12038 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=12020, lr=4.41499e-05, gnorm=0.804, clip=10, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=40880
2022-09-29 08:04:27 - progress_bar.py[line:274] - INFO: epoch 001:  12048 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.9, wpb=102.3, bsz=40, num_updates=12030, lr=4.41433e-05, gnorm=0.707, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=40891
2022-09-29 08:04:38 - progress_bar.py[line:274] - INFO: epoch 001:  12058 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.5, ups=0.91, wpb=102.3, bsz=40, num_updates=12040, lr=4.41367e-05, gnorm=0.794, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40902
2022-09-29 08:04:48 - progress_bar.py[line:274] - INFO: epoch 001:  12068 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.8, ups=0.92, wpb=102.2, bsz=40, num_updates=12050, lr=4.41301e-05, gnorm=0.741, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40913
2022-09-29 08:05:00 - progress_bar.py[line:274] - INFO: epoch 001:  12078 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.88, wpb=102.4, bsz=40, num_updates=12060, lr=4.41235e-05, gnorm=0.868, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40925
2022-09-29 08:05:11 - progress_bar.py[line:274] - INFO: epoch 001:  12088 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.4, ups=0.9, wpb=102.4, bsz=40, num_updates=12070, lr=4.41169e-05, gnorm=0.732, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40936
2022-09-29 08:05:22 - progress_bar.py[line:274] - INFO: epoch 001:  12098 / 15783 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=89.2, ups=0.88, wpb=101.3, bsz=40, num_updates=12080, lr=4.41103e-05, gnorm=0.872, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=40947
2022-09-29 08:05:27 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 08:05:34 - progress_bar.py[line:274] - INFO: epoch 001:  12109 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.7, ups=0.86, wpb=102.5, bsz=40, num_updates=12090, lr=4.41037e-05, gnorm=0.781, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=40959
2022-09-29 08:05:45 - progress_bar.py[line:274] - INFO: epoch 001:  12119 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.88, wpb=101.2, bsz=40, num_updates=12100, lr=4.40971e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40970
2022-09-29 08:05:57 - progress_bar.py[line:274] - INFO: epoch 001:  12129 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.88, wpb=101.9, bsz=40, num_updates=12110, lr=4.40905e-05, gnorm=0.833, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40982
2022-09-29 08:06:08 - progress_bar.py[line:274] - INFO: epoch 001:  12139 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.91, wpb=100.9, bsz=40, num_updates=12120, lr=4.40839e-05, gnorm=0.865, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=40993
2022-09-29 08:06:19 - progress_bar.py[line:274] - INFO: epoch 001:  12149 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.9, ups=0.89, wpb=102.2, bsz=40, num_updates=12130, lr=4.40773e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=41004
2022-09-29 08:06:30 - progress_bar.py[line:274] - INFO: epoch 001:  12159 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.89, wpb=102.4, bsz=40, num_updates=12140, lr=4.40707e-05, gnorm=0.779, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41015
2022-09-29 08:06:42 - progress_bar.py[line:274] - INFO: epoch 001:  12169 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.8, ups=0.9, wpb=103.6, bsz=40, num_updates=12150, lr=4.40641e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41026
2022-09-29 08:06:53 - progress_bar.py[line:274] - INFO: epoch 001:  12179 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.6, ups=0.91, wpb=102.6, bsz=40, num_updates=12160, lr=4.40575e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41038
2022-09-29 08:07:04 - progress_bar.py[line:274] - INFO: epoch 001:  12189 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.88, wpb=102.2, bsz=40, num_updates=12170, lr=4.40509e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41049
2022-09-29 08:07:16 - progress_bar.py[line:274] - INFO: epoch 001:  12199 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.3, ups=0.88, wpb=101.9, bsz=40, num_updates=12180, lr=4.40443e-05, gnorm=0.691, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41061
2022-09-29 08:07:26 - progress_bar.py[line:274] - INFO: epoch 001:  12209 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.5, ups=0.93, wpb=99.5, bsz=40, num_updates=12190, lr=4.40377e-05, gnorm=0.947, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41071
2022-09-29 08:07:38 - progress_bar.py[line:274] - INFO: epoch 001:  12219 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=100.5, bsz=40, num_updates=12200, lr=4.40311e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41083
2022-09-29 08:07:49 - progress_bar.py[line:274] - INFO: epoch 001:  12229 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.88, wpb=102.1, bsz=40, num_updates=12210, lr=4.40245e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41094
2022-09-29 08:08:00 - progress_bar.py[line:274] - INFO: epoch 001:  12239 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.2, ups=0.88, wpb=100, bsz=40, num_updates=12220, lr=4.40179e-05, gnorm=0.825, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41105
2022-09-29 08:08:11 - progress_bar.py[line:274] - INFO: epoch 001:  12249 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.9, wpb=101.7, bsz=40, num_updates=12230, lr=4.40113e-05, gnorm=0.845, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41116
2022-09-29 08:08:23 - progress_bar.py[line:274] - INFO: epoch 001:  12259 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.9, wpb=100.1, bsz=40, num_updates=12240, lr=4.40047e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=41127
2022-09-29 08:08:34 - progress_bar.py[line:274] - INFO: epoch 001:  12269 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.88, wpb=100.9, bsz=40, num_updates=12250, lr=4.39981e-05, gnorm=0.844, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41139
2022-09-29 08:08:45 - progress_bar.py[line:274] - INFO: epoch 001:  12279 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.88, wpb=101.9, bsz=40, num_updates=12260, lr=4.39915e-05, gnorm=0.761, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41150
2022-09-29 08:08:56 - progress_bar.py[line:274] - INFO: epoch 001:  12289 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.7, ups=0.9, wpb=101.5, bsz=40, num_updates=12270, lr=4.39849e-05, gnorm=0.86, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=41161
2022-09-29 08:09:07 - progress_bar.py[line:274] - INFO: epoch 001:  12299 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.4, ups=0.91, wpb=100.8, bsz=40, num_updates=12280, lr=4.39783e-05, gnorm=0.748, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=41172
2022-09-29 08:09:19 - progress_bar.py[line:274] - INFO: epoch 001:  12309 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=12290, lr=4.39717e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=41184
2022-09-29 08:09:30 - progress_bar.py[line:274] - INFO: epoch 001:  12319 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.5, ups=0.91, wpb=102.2, bsz=40, num_updates=12300, lr=4.39651e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41194
2022-09-29 08:09:41 - progress_bar.py[line:274] - INFO: epoch 001:  12329 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.8, ups=0.89, wpb=102.1, bsz=40, num_updates=12310, lr=4.39585e-05, gnorm=0.745, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41206
2022-09-29 08:09:52 - progress_bar.py[line:274] - INFO: epoch 001:  12339 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.9, ups=0.88, wpb=101, bsz=40, num_updates=12320, lr=4.39519e-05, gnorm=0.932, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41217
2022-09-29 08:10:03 - progress_bar.py[line:274] - INFO: epoch 001:  12349 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.9, wpb=101.3, bsz=40, num_updates=12330, lr=4.39453e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41228
2022-09-29 08:10:15 - progress_bar.py[line:274] - INFO: epoch 001:  12359 / 15783 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.6, ups=0.89, wpb=99, bsz=40, num_updates=12340, lr=4.39387e-05, gnorm=0.893, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41240
2022-09-29 08:10:26 - progress_bar.py[line:274] - INFO: epoch 001:  12369 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.87, wpb=103, bsz=40, num_updates=12350, lr=4.39321e-05, gnorm=0.851, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41251
2022-09-29 08:10:37 - progress_bar.py[line:274] - INFO: epoch 001:  12379 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=92.2, ups=0.92, wpb=100.1, bsz=40, num_updates=12360, lr=4.39255e-05, gnorm=0.762, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41262
2022-09-29 08:10:48 - progress_bar.py[line:274] - INFO: epoch 001:  12389 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=12370, lr=4.39189e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=41273
2022-09-29 08:11:00 - progress_bar.py[line:274] - INFO: epoch 001:  12399 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.87, wpb=102.9, bsz=40, num_updates=12380, lr=4.39123e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41285
2022-09-29 08:11:11 - progress_bar.py[line:274] - INFO: epoch 001:  12409 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101, bsz=40, num_updates=12390, lr=4.39057e-05, gnorm=0.847, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41296
2022-09-29 08:11:23 - progress_bar.py[line:274] - INFO: epoch 001:  12419 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=101.1, bsz=40, num_updates=12400, lr=4.38991e-05, gnorm=0.702, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41307
2022-09-29 08:11:34 - progress_bar.py[line:274] - INFO: epoch 001:  12429 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=98.2, nsentences=40, sample_size=98.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.5, ups=0.88, wpb=98.2, bsz=40, num_updates=12410, lr=4.38925e-05, gnorm=0.833, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41319
2022-09-29 08:11:45 - progress_bar.py[line:274] - INFO: epoch 001:  12439 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.4, ups=0.91, wpb=102, bsz=40, num_updates=12420, lr=4.38859e-05, gnorm=0.805, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=41330
2022-09-29 08:11:56 - progress_bar.py[line:274] - INFO: epoch 001:  12449 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.9, wpb=102.2, bsz=40, num_updates=12430, lr=4.38793e-05, gnorm=0.769, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41341
2022-09-29 08:12:07 - progress_bar.py[line:274] - INFO: epoch 001:  12459 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101, bsz=40, num_updates=12440, lr=4.38727e-05, gnorm=0.746, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41352
2022-09-29 08:12:18 - progress_bar.py[line:274] - INFO: epoch 001:  12469 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=12450, lr=4.38661e-05, gnorm=0.857, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41363
2022-09-29 08:12:30 - progress_bar.py[line:274] - INFO: epoch 001:  12479 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.88, wpb=101.8, bsz=40, num_updates=12460, lr=4.38595e-05, gnorm=0.75, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41374
2022-09-29 08:12:41 - progress_bar.py[line:274] - INFO: epoch 001:  12489 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.89, wpb=101.2, bsz=40, num_updates=12470, lr=4.38529e-05, gnorm=1.149, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41386
2022-09-29 08:12:52 - progress_bar.py[line:274] - INFO: epoch 001:  12499 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=12480, lr=4.38463e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41397
2022-09-29 08:13:03 - progress_bar.py[line:274] - INFO: epoch 001:  12509 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.1, ups=0.9, wpb=102.4, bsz=40, num_updates=12490, lr=4.38397e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=41408
2022-09-29 08:13:15 - progress_bar.py[line:274] - INFO: epoch 001:  12519 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.8, ups=0.89, wpb=99.8, bsz=40, num_updates=12500, lr=4.38331e-05, gnorm=0.792, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=41419
2022-09-29 08:13:26 - progress_bar.py[line:274] - INFO: epoch 001:  12529 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.2, ups=0.88, wpb=101.3, bsz=40, num_updates=12510, lr=4.38265e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41431
2022-09-29 08:13:37 - progress_bar.py[line:274] - INFO: epoch 001:  12539 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.7, ups=0.89, wpb=102.9, bsz=40, num_updates=12520, lr=4.38199e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41442
2022-09-29 08:13:49 - progress_bar.py[line:274] - INFO: epoch 001:  12549 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.4, ups=0.86, wpb=101.1, bsz=40, num_updates=12530, lr=4.38133e-05, gnorm=0.772, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=41454
2022-09-29 08:14:00 - progress_bar.py[line:274] - INFO: epoch 001:  12559 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.7, ups=0.89, wpb=99.6, bsz=40, num_updates=12540, lr=4.38067e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41465
2022-09-29 08:14:11 - progress_bar.py[line:274] - INFO: epoch 001:  12569 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.9, ups=0.9, wpb=102.7, bsz=40, num_updates=12550, lr=4.38001e-05, gnorm=0.873, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41476
2022-09-29 08:14:22 - progress_bar.py[line:274] - INFO: epoch 001:  12579 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.88, wpb=102.1, bsz=40, num_updates=12560, lr=4.37935e-05, gnorm=0.927, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41487
2022-09-29 08:14:33 - progress_bar.py[line:274] - INFO: epoch 001:  12589 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.91, wpb=100.1, bsz=40, num_updates=12570, lr=4.37869e-05, gnorm=0.817, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41498
2022-09-29 08:14:45 - progress_bar.py[line:274] - INFO: epoch 001:  12599 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.89, wpb=100, bsz=40, num_updates=12580, lr=4.37803e-05, gnorm=0.857, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41509
2022-09-29 08:14:56 - progress_bar.py[line:274] - INFO: epoch 001:  12609 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.3, ups=0.91, wpb=102.3, bsz=40, num_updates=12590, lr=4.37737e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41520
2022-09-29 08:15:07 - progress_bar.py[line:274] - INFO: epoch 001:  12619 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=12600, lr=4.37671e-05, gnorm=0.981, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41532
2022-09-29 08:15:18 - progress_bar.py[line:274] - INFO: epoch 001:  12629 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.88, wpb=103, bsz=40, num_updates=12610, lr=4.37605e-05, gnorm=0.826, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41543
2022-09-29 08:15:29 - progress_bar.py[line:274] - INFO: epoch 001:  12639 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.89, wpb=100.9, bsz=40, num_updates=12620, lr=4.37539e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=41554
2022-09-29 08:15:41 - progress_bar.py[line:274] - INFO: epoch 001:  12649 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.88, wpb=100.8, bsz=40, num_updates=12630, lr=4.37473e-05, gnorm=0.822, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41566
2022-09-29 08:15:52 - progress_bar.py[line:274] - INFO: epoch 001:  12659 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.2, ups=0.91, wpb=102.9, bsz=40, num_updates=12640, lr=4.37407e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41577
2022-09-29 08:16:03 - progress_bar.py[line:274] - INFO: epoch 001:  12669 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.4, ups=0.92, wpb=101.2, bsz=40, num_updates=12650, lr=4.37341e-05, gnorm=0.841, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=41587
2022-09-29 08:16:14 - progress_bar.py[line:274] - INFO: epoch 001:  12679 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.9, wpb=100.8, bsz=40, num_updates=12660, lr=4.37275e-05, gnorm=0.789, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41599
2022-09-29 08:16:25 - progress_bar.py[line:274] - INFO: epoch 001:  12689 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.89, wpb=103.2, bsz=40, num_updates=12670, lr=4.37209e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=41610
2022-09-29 08:16:36 - progress_bar.py[line:274] - INFO: epoch 001:  12699 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.88, wpb=102, bsz=40, num_updates=12680, lr=4.37143e-05, gnorm=0.784, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41621
2022-09-29 08:16:48 - progress_bar.py[line:274] - INFO: epoch 001:  12709 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.88, wpb=103, bsz=40, num_updates=12690, lr=4.37077e-05, gnorm=0.759, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41633
2022-09-29 08:17:00 - progress_bar.py[line:274] - INFO: epoch 001:  12719 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=12700, lr=4.37011e-05, gnorm=0.835, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41644
2022-09-29 08:17:11 - progress_bar.py[line:274] - INFO: epoch 001:  12729 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.3, ups=0.9, wpb=101.1, bsz=40, num_updates=12710, lr=4.36945e-05, gnorm=0.848, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41656
2022-09-29 08:17:22 - progress_bar.py[line:274] - INFO: epoch 001:  12739 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.6, ups=0.93, wpb=101, bsz=40, num_updates=12720, lr=4.36879e-05, gnorm=0.83, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41666
2022-09-29 08:17:33 - progress_bar.py[line:274] - INFO: epoch 001:  12749 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.2, ups=0.91, wpb=102.1, bsz=40, num_updates=12730, lr=4.36813e-05, gnorm=0.9, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41677
2022-09-29 08:17:44 - progress_bar.py[line:274] - INFO: epoch 001:  12759 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.2, ups=0.89, wpb=100, bsz=40, num_updates=12740, lr=4.36747e-05, gnorm=0.892, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41689
2022-09-29 08:17:55 - progress_bar.py[line:274] - INFO: epoch 001:  12769 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.2, ups=0.87, wpb=101.8, bsz=40, num_updates=12750, lr=4.36681e-05, gnorm=0.794, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=41700
2022-09-29 08:18:08 - progress_bar.py[line:274] - INFO: epoch 001:  12779 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.7, ups=0.88, wpb=100, bsz=40, num_updates=12760, lr=4.36615e-05, gnorm=0.881, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=41712
2022-09-29 08:18:19 - progress_bar.py[line:274] - INFO: epoch 001:  12789 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.2, ups=0.91, wpb=102, bsz=40, num_updates=12770, lr=4.36549e-05, gnorm=0.759, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=41723
2022-09-29 08:18:30 - progress_bar.py[line:274] - INFO: epoch 001:  12799 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.89, wpb=101.3, bsz=40, num_updates=12780, lr=4.36483e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41735
2022-09-29 08:18:41 - progress_bar.py[line:274] - INFO: epoch 001:  12809 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.1, ups=0.87, wpb=99.7, bsz=40, num_updates=12790, lr=4.36417e-05, gnorm=0.777, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41746
2022-09-29 08:18:52 - progress_bar.py[line:274] - INFO: epoch 001:  12819 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.9, ups=0.92, wpb=101.4, bsz=40, num_updates=12800, lr=4.36351e-05, gnorm=0.743, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41757
2022-09-29 08:19:03 - progress_bar.py[line:274] - INFO: epoch 001:  12829 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.9, ups=0.93, wpb=102.4, bsz=40, num_updates=12810, lr=4.36285e-05, gnorm=0.776, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41768
2022-09-29 08:19:14 - progress_bar.py[line:274] - INFO: epoch 001:  12839 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.3, ups=0.88, wpb=101.9, bsz=40, num_updates=12820, lr=4.36219e-05, gnorm=0.781, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41779
2022-09-29 08:19:26 - progress_bar.py[line:274] - INFO: epoch 001:  12849 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.9, wpb=101.8, bsz=40, num_updates=12830, lr=4.36153e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=41790
2022-09-29 08:19:37 - progress_bar.py[line:274] - INFO: epoch 001:  12859 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.7, ups=0.87, wpb=99.9, bsz=40, num_updates=12840, lr=4.36087e-05, gnorm=0.728, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=41802
2022-09-29 08:19:48 - progress_bar.py[line:274] - INFO: epoch 001:  12869 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.9, ups=0.93, wpb=101.2, bsz=40, num_updates=12850, lr=4.36021e-05, gnorm=0.754, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41813
2022-09-29 08:19:59 - progress_bar.py[line:274] - INFO: epoch 001:  12879 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=12860, lr=4.35955e-05, gnorm=0.962, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41824
2022-09-29 08:20:04 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 08:20:12 - progress_bar.py[line:274] - INFO: epoch 001:  12890 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=82.1, ups=0.82, wpb=100.4, bsz=40, num_updates=12870, lr=4.35889e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=41836
2022-09-29 08:20:23 - progress_bar.py[line:274] - INFO: epoch 001:  12900 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=12880, lr=4.35823e-05, gnorm=0.879, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=41848
2022-09-29 08:20:34 - progress_bar.py[line:274] - INFO: epoch 001:  12910 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.89, wpb=101.1, bsz=40, num_updates=12890, lr=4.35757e-05, gnorm=0.698, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41859
2022-09-29 08:20:45 - progress_bar.py[line:274] - INFO: epoch 001:  12920 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.89, wpb=102.1, bsz=40, num_updates=12900, lr=4.35691e-05, gnorm=0.72, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=41870
2022-09-29 08:20:57 - progress_bar.py[line:274] - INFO: epoch 001:  12930 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89, ups=0.88, wpb=101.2, bsz=40, num_updates=12910, lr=4.35625e-05, gnorm=0.906, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41882
2022-09-29 08:21:08 - progress_bar.py[line:274] - INFO: epoch 001:  12940 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.88, wpb=102.1, bsz=40, num_updates=12920, lr=4.35559e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41893
2022-09-29 08:21:19 - progress_bar.py[line:274] - INFO: epoch 001:  12950 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.2, ups=0.88, wpb=100.7, bsz=40, num_updates=12930, lr=4.35493e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41904
2022-09-29 08:21:31 - progress_bar.py[line:274] - INFO: epoch 001:  12960 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=12940, lr=4.35427e-05, gnorm=0.744, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=41916
2022-09-29 08:21:42 - progress_bar.py[line:274] - INFO: epoch 001:  12970 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.2, ups=0.88, wpb=101.2, bsz=40, num_updates=12950, lr=4.35361e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=41927
2022-09-29 08:21:53 - progress_bar.py[line:274] - INFO: epoch 001:  12980 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.6, ups=0.91, wpb=102.6, bsz=40, num_updates=12960, lr=4.35295e-05, gnorm=0.806, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=41938
2022-09-29 08:22:04 - progress_bar.py[line:274] - INFO: epoch 001:  12990 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.89, wpb=103.3, bsz=40, num_updates=12970, lr=4.35229e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41949
2022-09-29 08:22:16 - progress_bar.py[line:274] - INFO: epoch 001:  13000 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.4, ups=0.87, wpb=100.9, bsz=40, num_updates=12980, lr=4.35163e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=41961
2022-09-29 08:22:27 - progress_bar.py[line:274] - INFO: epoch 001:  13010 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.88, wpb=102.8, bsz=40, num_updates=12990, lr=4.35097e-05, gnorm=0.788, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=41972
2022-09-29 08:22:38 - progress_bar.py[line:274] - INFO: epoch 001:  13020 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.9, wpb=102.5, bsz=40, num_updates=13000, lr=4.35031e-05, gnorm=0.712, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=41983
2022-09-29 08:22:49 - progress_bar.py[line:274] - INFO: epoch 001:  13030 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.7, ups=0.89, wpb=102.7, bsz=40, num_updates=13010, lr=4.34965e-05, gnorm=0.847, clip=10, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=41994
2022-09-29 08:23:01 - progress_bar.py[line:274] - INFO: epoch 001:  13040 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.1, ups=0.88, wpb=100.3, bsz=40, num_updates=13020, lr=4.34899e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42006
2022-09-29 08:23:12 - progress_bar.py[line:274] - INFO: epoch 001:  13050 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.6, ups=0.9, wpb=101.4, bsz=40, num_updates=13030, lr=4.34833e-05, gnorm=0.825, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42017
2022-09-29 08:23:25 - progress_bar.py[line:274] - INFO: epoch 001:  13060 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.88, wpb=103.2, bsz=40, num_updates=13040, lr=4.34767e-05, gnorm=0.816, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42028
2022-09-29 08:23:36 - progress_bar.py[line:274] - INFO: epoch 001:  13070 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.88, wpb=100.1, bsz=40, num_updates=13050, lr=4.34701e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42041
2022-09-29 08:23:47 - progress_bar.py[line:274] - INFO: epoch 001:  13080 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.8, ups=0.91, wpb=100.8, bsz=40, num_updates=13060, lr=4.34635e-05, gnorm=0.789, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42052
2022-09-29 08:23:58 - progress_bar.py[line:274] - INFO: epoch 001:  13090 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.88, wpb=102.5, bsz=40, num_updates=13070, lr=4.34569e-05, gnorm=0.84, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=42063
2022-09-29 08:24:10 - progress_bar.py[line:274] - INFO: epoch 001:  13100 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.89, wpb=102.1, bsz=40, num_updates=13080, lr=4.34503e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42074
2022-09-29 08:24:21 - progress_bar.py[line:274] - INFO: epoch 001:  13110 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.2, ups=0.91, wpb=102.3, bsz=40, num_updates=13090, lr=4.34437e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42085
2022-09-29 08:24:31 - progress_bar.py[line:274] - INFO: epoch 001:  13120 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.2, ups=0.93, wpb=100.8, bsz=40, num_updates=13100, lr=4.34371e-05, gnorm=0.827, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42096
2022-09-29 08:24:43 - progress_bar.py[line:274] - INFO: epoch 001:  13130 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=13110, lr=4.34305e-05, gnorm=0.764, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42108
2022-09-29 08:24:54 - progress_bar.py[line:274] - INFO: epoch 001:  13140 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=13120, lr=4.34239e-05, gnorm=0.834, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42119
2022-09-29 08:25:05 - progress_bar.py[line:274] - INFO: epoch 001:  13150 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.9, ups=0.9, wpb=101.8, bsz=40, num_updates=13130, lr=4.34173e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42130
2022-09-29 08:25:16 - progress_bar.py[line:274] - INFO: epoch 001:  13160 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.3, ups=0.9, wpb=102.4, bsz=40, num_updates=13140, lr=4.34107e-05, gnorm=0.721, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42141
2022-09-29 08:25:28 - progress_bar.py[line:274] - INFO: epoch 001:  13170 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.89, wpb=101.6, bsz=40, num_updates=13150, lr=4.34041e-05, gnorm=0.825, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42152
2022-09-29 08:25:39 - progress_bar.py[line:274] - INFO: epoch 001:  13180 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.5, ups=0.9, wpb=102.2, bsz=40, num_updates=13160, lr=4.33975e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42163
2022-09-29 08:25:50 - progress_bar.py[line:274] - INFO: epoch 001:  13190 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.5, ups=0.91, wpb=102.1, bsz=40, num_updates=13170, lr=4.33909e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=42175
2022-09-29 08:26:01 - progress_bar.py[line:274] - INFO: epoch 001:  13200 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.9, wpb=99.7, bsz=40, num_updates=13180, lr=4.33843e-05, gnorm=0.864, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42186
2022-09-29 08:26:12 - progress_bar.py[line:274] - INFO: epoch 001:  13210 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.5, ups=0.88, wpb=99.8, bsz=40, num_updates=13190, lr=4.33777e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=42197
2022-09-29 08:26:24 - progress_bar.py[line:274] - INFO: epoch 001:  13220 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.88, wpb=102.1, bsz=40, num_updates=13200, lr=4.33711e-05, gnorm=0.714, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42208
2022-09-29 08:26:35 - progress_bar.py[line:274] - INFO: epoch 001:  13230 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.9, wpb=103.2, bsz=40, num_updates=13210, lr=4.33645e-05, gnorm=0.794, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42220
2022-09-29 08:26:46 - progress_bar.py[line:274] - INFO: epoch 001:  13240 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.3, ups=0.9, wpb=99.9, bsz=40, num_updates=13220, lr=4.33579e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42231
2022-09-29 08:26:57 - progress_bar.py[line:274] - INFO: epoch 001:  13250 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.88, wpb=103, bsz=40, num_updates=13230, lr=4.33513e-05, gnorm=0.777, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42242
2022-09-29 08:27:09 - progress_bar.py[line:274] - INFO: epoch 001:  13260 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=13240, lr=4.33447e-05, gnorm=0.816, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42253
2022-09-29 08:27:20 - progress_bar.py[line:274] - INFO: epoch 001:  13270 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.9, wpb=101, bsz=40, num_updates=13250, lr=4.33381e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42265
2022-09-29 08:27:31 - progress_bar.py[line:274] - INFO: epoch 001:  13280 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.87, wpb=102.6, bsz=40, num_updates=13260, lr=4.33315e-05, gnorm=0.734, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42276
2022-09-29 08:27:42 - progress_bar.py[line:274] - INFO: epoch 001:  13290 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.9, wpb=100.7, bsz=40, num_updates=13270, lr=4.33249e-05, gnorm=0.842, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42287
2022-09-29 08:27:53 - progress_bar.py[line:274] - INFO: epoch 001:  13300 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.2, ups=0.91, wpb=101.5, bsz=40, num_updates=13280, lr=4.33183e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42298
2022-09-29 08:28:04 - progress_bar.py[line:274] - INFO: epoch 001:  13310 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.7, ups=0.89, wpb=100.2, bsz=40, num_updates=13290, lr=4.33117e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42309
2022-09-29 08:28:16 - progress_bar.py[line:274] - INFO: epoch 001:  13320 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=13300, lr=4.33051e-05, gnorm=0.807, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42321
2022-09-29 08:28:27 - progress_bar.py[line:274] - INFO: epoch 001:  13330 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.5, ups=0.87, wpb=99.5, bsz=40, num_updates=13310, lr=4.32985e-05, gnorm=0.862, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42332
2022-09-29 08:28:38 - progress_bar.py[line:274] - INFO: epoch 001:  13340 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.6, ups=0.9, wpb=101.2, bsz=40, num_updates=13320, lr=4.32919e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42343
2022-09-29 08:28:50 - progress_bar.py[line:274] - INFO: epoch 001:  13350 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.89, wpb=99.4, bsz=40, num_updates=13330, lr=4.32853e-05, gnorm=0.833, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42355
2022-09-29 08:29:01 - progress_bar.py[line:274] - INFO: epoch 001:  13360 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.88, wpb=101.9, bsz=40, num_updates=13340, lr=4.32787e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42366
2022-09-29 08:29:13 - progress_bar.py[line:274] - INFO: epoch 001:  13370 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.5, ups=0.86, wpb=101.4, bsz=40, num_updates=13350, lr=4.32721e-05, gnorm=0.786, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=42378
2022-09-29 08:29:24 - progress_bar.py[line:274] - INFO: epoch 001:  13380 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.88, wpb=101.7, bsz=40, num_updates=13360, lr=4.32655e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42389
2022-09-29 08:29:35 - progress_bar.py[line:274] - INFO: epoch 001:  13390 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.9, wpb=101, bsz=40, num_updates=13370, lr=4.32589e-05, gnorm=0.799, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42400
2022-09-29 08:29:47 - progress_bar.py[line:274] - INFO: epoch 001:  13400 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.87, wpb=102.4, bsz=40, num_updates=13380, lr=4.32523e-05, gnorm=0.789, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42411
2022-09-29 08:29:57 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 08:29:59 - progress_bar.py[line:274] - INFO: epoch 001:  13411 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=82.4, ups=0.82, wpb=100.2, bsz=40, num_updates=13390, lr=4.32457e-05, gnorm=0.732, clip=10, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=42424
2022-09-29 08:30:10 - progress_bar.py[line:274] - INFO: epoch 001:  13421 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.9, wpb=100.8, bsz=40, num_updates=13400, lr=4.32391e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42435
2022-09-29 08:30:21 - progress_bar.py[line:274] - INFO: epoch 001:  13431 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.9, wpb=101.4, bsz=40, num_updates=13410, lr=4.32325e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42446
2022-09-29 08:30:32 - progress_bar.py[line:274] - INFO: epoch 001:  13441 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.7, ups=0.91, wpb=101.5, bsz=40, num_updates=13420, lr=4.32259e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42457
2022-09-29 08:30:43 - progress_bar.py[line:274] - INFO: epoch 001:  13451 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.92, wpb=100.9, bsz=40, num_updates=13430, lr=4.32193e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42468
2022-09-29 08:30:54 - progress_bar.py[line:274] - INFO: epoch 001:  13461 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.3, ups=0.92, wpb=101.5, bsz=40, num_updates=13440, lr=4.32127e-05, gnorm=0.704, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42479
2022-09-29 08:31:05 - progress_bar.py[line:274] - INFO: epoch 001:  13471 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.1, ups=0.91, wpb=102.3, bsz=40, num_updates=13450, lr=4.32061e-05, gnorm=0.736, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42490
2022-09-29 08:31:16 - progress_bar.py[line:274] - INFO: epoch 001:  13481 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.9, wpb=102, bsz=40, num_updates=13460, lr=4.31995e-05, gnorm=0.76, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42501
2022-09-29 08:31:27 - progress_bar.py[line:274] - INFO: epoch 001:  13491 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.89, wpb=100.8, bsz=40, num_updates=13470, lr=4.31929e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42512
2022-09-29 08:31:38 - progress_bar.py[line:274] - INFO: epoch 001:  13501 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.8, ups=0.91, wpb=101.5, bsz=40, num_updates=13480, lr=4.31863e-05, gnorm=0.779, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42523
2022-09-29 08:31:49 - progress_bar.py[line:274] - INFO: epoch 001:  13511 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.91, wpb=100.8, bsz=40, num_updates=13490, lr=4.31797e-05, gnorm=0.753, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42534
2022-09-29 08:32:00 - progress_bar.py[line:274] - INFO: epoch 001:  13521 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.6, ups=0.92, wpb=101.1, bsz=40, num_updates=13500, lr=4.31731e-05, gnorm=0.773, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42545
2022-09-29 08:32:12 - progress_bar.py[line:274] - INFO: epoch 001:  13531 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.6, ups=0.88, wpb=100.6, bsz=40, num_updates=13510, lr=4.31665e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42556
2022-09-29 08:32:23 - progress_bar.py[line:274] - INFO: epoch 001:  13541 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=85.9, ups=0.86, wpb=99.3, bsz=40, num_updates=13520, lr=4.31599e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=42568
2022-09-29 08:32:35 - progress_bar.py[line:274] - INFO: epoch 001:  13551 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.7, ups=0.86, wpb=101.6, bsz=40, num_updates=13530, lr=4.31533e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=42580
2022-09-29 08:32:46 - progress_bar.py[line:274] - INFO: epoch 001:  13561 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.89, wpb=100.6, bsz=40, num_updates=13540, lr=4.31467e-05, gnorm=0.874, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42591
2022-09-29 08:32:57 - progress_bar.py[line:274] - INFO: epoch 001:  13571 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.9, wpb=99.2, bsz=40, num_updates=13550, lr=4.31401e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42602
2022-09-29 08:33:08 - progress_bar.py[line:274] - INFO: epoch 001:  13581 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.89, wpb=100.9, bsz=40, num_updates=13560, lr=4.31335e-05, gnorm=0.916, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42613
2022-09-29 08:33:20 - progress_bar.py[line:274] - INFO: epoch 001:  13591 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.89, wpb=102.4, bsz=40, num_updates=13570, lr=4.31269e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=42625
2022-09-29 08:33:31 - progress_bar.py[line:274] - INFO: epoch 001:  13601 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.91, wpb=100.8, bsz=40, num_updates=13580, lr=4.31203e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=42636
2022-09-29 08:33:42 - progress_bar.py[line:274] - INFO: epoch 001:  13611 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=102.1, bsz=40, num_updates=13590, lr=4.31137e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42647
2022-09-29 08:33:53 - progress_bar.py[line:274] - INFO: epoch 001:  13621 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.9, wpb=102.1, bsz=40, num_updates=13600, lr=4.31071e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42658
2022-09-29 08:34:04 - progress_bar.py[line:274] - INFO: epoch 001:  13631 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90, ups=0.89, wpb=101.1, bsz=40, num_updates=13610, lr=4.31005e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42669
2022-09-29 08:34:16 - progress_bar.py[line:274] - INFO: epoch 001:  13641 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.5, ups=0.86, wpb=101.2, bsz=40, num_updates=13620, lr=4.30939e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=42681
2022-09-29 08:34:27 - progress_bar.py[line:274] - INFO: epoch 001:  13651 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.9, wpb=100.2, bsz=40, num_updates=13630, lr=4.30873e-05, gnorm=0.873, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42692
2022-09-29 08:34:38 - progress_bar.py[line:274] - INFO: epoch 001:  13661 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.87, wpb=101.3, bsz=40, num_updates=13640, lr=4.30807e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42703
2022-09-29 08:34:49 - progress_bar.py[line:274] - INFO: epoch 001:  13671 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.91, wpb=100.2, bsz=40, num_updates=13650, lr=4.30741e-05, gnorm=0.821, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42714
2022-09-29 08:35:00 - progress_bar.py[line:274] - INFO: epoch 001:  13681 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.2, ups=0.9, wpb=99.9, bsz=40, num_updates=13660, lr=4.30675e-05, gnorm=0.846, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42725
2022-09-29 08:35:11 - progress_bar.py[line:274] - INFO: epoch 001:  13691 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.9, ups=0.92, wpb=103.5, bsz=40, num_updates=13670, lr=4.30609e-05, gnorm=0.733, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=42736
2022-09-29 08:35:22 - progress_bar.py[line:274] - INFO: epoch 001:  13701 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=13680, lr=4.30543e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42747
2022-09-29 08:35:34 - progress_bar.py[line:274] - INFO: epoch 001:  13711 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=13690, lr=4.30477e-05, gnorm=0.814, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42759
2022-09-29 08:35:45 - progress_bar.py[line:274] - INFO: epoch 001:  13721 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.9, wpb=99.9, bsz=40, num_updates=13700, lr=4.30411e-05, gnorm=0.849, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42770
2022-09-29 08:35:56 - progress_bar.py[line:274] - INFO: epoch 001:  13731 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.4, ups=0.91, wpb=101.6, bsz=40, num_updates=13710, lr=4.30345e-05, gnorm=0.843, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=42781
2022-09-29 08:36:07 - progress_bar.py[line:274] - INFO: epoch 001:  13741 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.88, wpb=101.9, bsz=40, num_updates=13720, lr=4.30279e-05, gnorm=0.829, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42792
2022-09-29 08:36:19 - progress_bar.py[line:274] - INFO: epoch 001:  13751 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.89, wpb=101.7, bsz=40, num_updates=13730, lr=4.30213e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42803
2022-09-29 08:36:30 - progress_bar.py[line:274] - INFO: epoch 001:  13761 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=13740, lr=4.30147e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42815
2022-09-29 08:36:41 - progress_bar.py[line:274] - INFO: epoch 001:  13771 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=13750, lr=4.30081e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42826
2022-09-29 08:36:52 - progress_bar.py[line:274] - INFO: epoch 001:  13781 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.2, ups=0.91, wpb=102.1, bsz=40, num_updates=13760, lr=4.30015e-05, gnorm=0.793, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42837
2022-09-29 08:37:03 - progress_bar.py[line:274] - INFO: epoch 001:  13791 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=13770, lr=4.29949e-05, gnorm=0.824, clip=10, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=42848
2022-09-29 08:37:15 - progress_bar.py[line:274] - INFO: epoch 001:  13801 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=13780, lr=4.29883e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42859
2022-09-29 08:37:26 - progress_bar.py[line:274] - INFO: epoch 001:  13811 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.9, wpb=101.5, bsz=40, num_updates=13790, lr=4.29817e-05, gnorm=0.71, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=42871
2022-09-29 08:37:37 - progress_bar.py[line:274] - INFO: epoch 001:  13821 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90, ups=0.88, wpb=101.9, bsz=40, num_updates=13800, lr=4.29751e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42882
2022-09-29 08:37:49 - progress_bar.py[line:274] - INFO: epoch 001:  13831 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.1, ups=0.88, wpb=101.7, bsz=40, num_updates=13810, lr=4.29685e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=42893
2022-09-29 08:37:59 - progress_bar.py[line:274] - INFO: epoch 001:  13841 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92, ups=0.91, wpb=100.9, bsz=40, num_updates=13820, lr=4.29619e-05, gnorm=0.777, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42904
2022-09-29 08:38:11 - progress_bar.py[line:274] - INFO: epoch 001:  13851 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.91, wpb=99.3, bsz=40, num_updates=13830, lr=4.29553e-05, gnorm=0.711, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42915
2022-09-29 08:38:22 - progress_bar.py[line:274] - INFO: epoch 001:  13861 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.9, wpb=100.6, bsz=40, num_updates=13840, lr=4.29487e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=42926
2022-09-29 08:38:33 - progress_bar.py[line:274] - INFO: epoch 001:  13871 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.8, ups=0.87, wpb=101.9, bsz=40, num_updates=13850, lr=4.29421e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42938
2022-09-29 08:38:45 - progress_bar.py[line:274] - INFO: epoch 001:  13881 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.88, wpb=102.2, bsz=40, num_updates=13860, lr=4.29355e-05, gnorm=0.854, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=42949
2022-09-29 08:38:56 - progress_bar.py[line:274] - INFO: epoch 001:  13891 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.8, ups=0.91, wpb=100.8, bsz=40, num_updates=13870, lr=4.29289e-05, gnorm=0.754, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42960
2022-09-29 08:39:07 - progress_bar.py[line:274] - INFO: epoch 001:  13901 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.9, wpb=102.5, bsz=40, num_updates=13880, lr=4.29223e-05, gnorm=0.838, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42972
2022-09-29 08:39:18 - progress_bar.py[line:274] - INFO: epoch 001:  13911 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.1, ups=0.9, wpb=102, bsz=40, num_updates=13890, lr=4.29157e-05, gnorm=0.913, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=42983
2022-09-29 08:39:29 - progress_bar.py[line:274] - INFO: epoch 001:  13921 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.88, wpb=102, bsz=40, num_updates=13900, lr=4.29091e-05, gnorm=0.795, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=42994
2022-09-29 08:39:40 - progress_bar.py[line:274] - INFO: epoch 001:  13931 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=102.4, bsz=40, num_updates=13910, lr=4.29025e-05, gnorm=0.818, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43005
2022-09-29 08:39:52 - progress_bar.py[line:274] - INFO: epoch 001:  13941 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.87, wpb=102.7, bsz=40, num_updates=13920, lr=4.28959e-05, gnorm=0.815, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43017
2022-09-29 08:40:03 - progress_bar.py[line:274] - INFO: epoch 001:  13951 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.5, ups=0.88, wpb=102.2, bsz=40, num_updates=13930, lr=4.28893e-05, gnorm=0.676, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43028
2022-09-29 08:40:15 - progress_bar.py[line:274] - INFO: epoch 001:  13961 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.1, ups=0.9, wpb=100.3, bsz=40, num_updates=13940, lr=4.28827e-05, gnorm=0.829, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43039
2022-09-29 08:40:26 - progress_bar.py[line:274] - INFO: epoch 001:  13971 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.89, wpb=100, bsz=40, num_updates=13950, lr=4.28761e-05, gnorm=0.776, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43051
2022-09-29 08:40:37 - progress_bar.py[line:274] - INFO: epoch 001:  13981 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.4, ups=0.89, wpb=99.7, bsz=40, num_updates=13960, lr=4.28695e-05, gnorm=0.752, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43062
2022-09-29 08:40:49 - progress_bar.py[line:274] - INFO: epoch 001:  13991 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.6, ups=0.87, wpb=102.1, bsz=40, num_updates=13970, lr=4.28629e-05, gnorm=0.838, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=43074
2022-09-29 08:41:00 - progress_bar.py[line:274] - INFO: epoch 001:  14001 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.88, wpb=100.6, bsz=40, num_updates=13980, lr=4.28563e-05, gnorm=0.857, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43085
2022-09-29 08:41:11 - progress_bar.py[line:274] - INFO: epoch 001:  14011 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.89, wpb=102.8, bsz=40, num_updates=13990, lr=4.28497e-05, gnorm=0.713, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43096
2022-09-29 08:41:22 - progress_bar.py[line:274] - INFO: epoch 001:  14021 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.9, wpb=101.1, bsz=40, num_updates=14000, lr=4.28431e-05, gnorm=0.858, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43107
2022-09-29 08:41:34 - progress_bar.py[line:274] - INFO: epoch 001:  14031 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=14010, lr=4.28365e-05, gnorm=0.769, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43119
2022-09-29 08:41:45 - progress_bar.py[line:274] - INFO: epoch 001:  14041 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.9, wpb=101, bsz=40, num_updates=14020, lr=4.28299e-05, gnorm=0.785, clip=10, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=43130
2022-09-29 08:41:56 - progress_bar.py[line:274] - INFO: epoch 001:  14051 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=14030, lr=4.28233e-05, gnorm=0.813, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43141
2022-09-29 08:42:05 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 08:42:08 - progress_bar.py[line:274] - INFO: epoch 001:  14062 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=84.4, ups=0.85, wpb=99.6, bsz=40, num_updates=14040, lr=4.28167e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=43153
2022-09-29 08:42:19 - progress_bar.py[line:274] - INFO: epoch 001:  14072 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.9, wpb=99.7, bsz=40, num_updates=14050, lr=4.28101e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43164
2022-09-29 08:42:30 - progress_bar.py[line:274] - INFO: epoch 001:  14082 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.89, wpb=99.5, bsz=40, num_updates=14060, lr=4.28035e-05, gnorm=0.865, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43175
2022-09-29 08:42:41 - progress_bar.py[line:274] - INFO: epoch 001:  14092 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89, ups=0.89, wpb=100.2, bsz=40, num_updates=14070, lr=4.27969e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43186
2022-09-29 08:42:53 - progress_bar.py[line:274] - INFO: epoch 001:  14102 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=14080, lr=4.27903e-05, gnorm=0.76, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43198
2022-09-29 08:43:04 - progress_bar.py[line:274] - INFO: epoch 001:  14112 / 15783 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.8, ups=0.91, wpb=102.1, bsz=40, num_updates=14090, lr=4.27837e-05, gnorm=0.748, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43209
2022-09-29 08:43:15 - progress_bar.py[line:274] - INFO: epoch 001:  14122 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.3, ups=0.87, wpb=101.2, bsz=40, num_updates=14100, lr=4.27771e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43220
2022-09-29 08:43:26 - progress_bar.py[line:274] - INFO: epoch 001:  14132 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.2, ups=0.91, wpb=103.2, bsz=40, num_updates=14110, lr=4.27705e-05, gnorm=0.797, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43231
2022-09-29 08:43:37 - progress_bar.py[line:274] - INFO: epoch 001:  14142 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.3, ups=0.91, wpb=102.7, bsz=40, num_updates=14120, lr=4.27639e-05, gnorm=0.741, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43242
2022-09-29 08:43:48 - progress_bar.py[line:274] - INFO: epoch 001:  14152 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.89, wpb=99.3, bsz=40, num_updates=14130, lr=4.27573e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43253
2022-09-29 08:44:00 - progress_bar.py[line:274] - INFO: epoch 001:  14162 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=14140, lr=4.27507e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43265
2022-09-29 08:44:11 - progress_bar.py[line:274] - INFO: epoch 001:  14172 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.9, wpb=100.2, bsz=40, num_updates=14150, lr=4.27441e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=43276
2022-09-29 08:44:22 - progress_bar.py[line:274] - INFO: epoch 001:  14182 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.7, ups=0.9, wpb=101.3, bsz=40, num_updates=14160, lr=4.27375e-05, gnorm=0.808, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43287
2022-09-29 08:44:33 - progress_bar.py[line:274] - INFO: epoch 001:  14192 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.6, ups=0.88, wpb=99.8, bsz=40, num_updates=14170, lr=4.27309e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43298
2022-09-29 08:44:45 - progress_bar.py[line:274] - INFO: epoch 001:  14202 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.88, wpb=103.4, bsz=40, num_updates=14180, lr=4.27243e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43310
2022-09-29 08:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  14212 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.9, wpb=101.1, bsz=40, num_updates=14190, lr=4.27177e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43321
2022-09-29 08:45:07 - progress_bar.py[line:274] - INFO: epoch 001:  14222 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=14200, lr=4.27111e-05, gnorm=0.725, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43332
2022-09-29 08:45:18 - progress_bar.py[line:274] - INFO: epoch 001:  14232 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.89, wpb=100.6, bsz=40, num_updates=14210, lr=4.27045e-05, gnorm=0.767, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43343
2022-09-29 08:45:30 - progress_bar.py[line:274] - INFO: epoch 001:  14242 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.2, ups=0.86, wpb=102.2, bsz=40, num_updates=14220, lr=4.26979e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=43355
2022-09-29 08:45:41 - progress_bar.py[line:274] - INFO: epoch 001:  14252 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.9, ups=0.9, wpb=102.2, bsz=40, num_updates=14230, lr=4.26913e-05, gnorm=0.88, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43366
2022-09-29 08:45:52 - progress_bar.py[line:274] - INFO: epoch 001:  14262 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.89, wpb=102.4, bsz=40, num_updates=14240, lr=4.26847e-05, gnorm=0.76, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43377
2022-09-29 08:46:04 - progress_bar.py[line:274] - INFO: epoch 001:  14272 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88, ups=0.87, wpb=100.7, bsz=40, num_updates=14250, lr=4.26781e-05, gnorm=0.847, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43389
2022-09-29 08:46:15 - progress_bar.py[line:274] - INFO: epoch 001:  14282 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.87, wpb=101.1, bsz=40, num_updates=14260, lr=4.26715e-05, gnorm=0.827, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43400
2022-09-29 08:46:26 - progress_bar.py[line:274] - INFO: epoch 001:  14292 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.7, ups=0.91, wpb=102.8, bsz=40, num_updates=14270, lr=4.26649e-05, gnorm=0.768, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43411
2022-09-29 08:46:38 - progress_bar.py[line:274] - INFO: epoch 001:  14302 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.89, wpb=101.9, bsz=40, num_updates=14280, lr=4.26583e-05, gnorm=0.911, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43422
2022-09-29 08:46:49 - progress_bar.py[line:274] - INFO: epoch 001:  14312 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=14290, lr=4.26517e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43434
2022-09-29 08:47:00 - progress_bar.py[line:274] - INFO: epoch 001:  14322 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.91, wpb=100.5, bsz=40, num_updates=14300, lr=4.26451e-05, gnorm=0.849, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43445
2022-09-29 08:47:11 - progress_bar.py[line:274] - INFO: epoch 001:  14332 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.89, wpb=103.4, bsz=40, num_updates=14310, lr=4.26385e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43456
2022-09-29 08:47:22 - progress_bar.py[line:274] - INFO: epoch 001:  14342 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.9, wpb=100, bsz=40, num_updates=14320, lr=4.26319e-05, gnorm=0.703, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43467
2022-09-29 08:47:34 - progress_bar.py[line:274] - INFO: epoch 001:  14352 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89, ups=0.88, wpb=100.6, bsz=40, num_updates=14330, lr=4.26253e-05, gnorm=0.657, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43478
2022-09-29 08:47:45 - progress_bar.py[line:274] - INFO: epoch 001:  14362 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=14340, lr=4.26187e-05, gnorm=0.738, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43490
2022-09-29 08:47:56 - progress_bar.py[line:274] - INFO: epoch 001:  14372 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.9, ups=0.92, wpb=103.6, bsz=40, num_updates=14350, lr=4.26121e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43500
2022-09-29 08:48:07 - progress_bar.py[line:274] - INFO: epoch 001:  14382 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.91, wpb=101.3, bsz=40, num_updates=14360, lr=4.26055e-05, gnorm=0.707, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43511
2022-09-29 08:48:18 - progress_bar.py[line:274] - INFO: epoch 001:  14392 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.89, wpb=101.3, bsz=40, num_updates=14370, lr=4.25989e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43523
2022-09-29 08:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  14402 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.1, ups=0.91, wpb=102, bsz=40, num_updates=14380, lr=4.25923e-05, gnorm=0.716, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43534
2022-09-29 08:48:40 - progress_bar.py[line:274] - INFO: epoch 001:  14412 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.88, wpb=101.1, bsz=40, num_updates=14390, lr=4.25857e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43545
2022-09-29 08:48:52 - progress_bar.py[line:274] - INFO: epoch 001:  14422 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90, ups=0.88, wpb=101.8, bsz=40, num_updates=14400, lr=4.25791e-05, gnorm=0.736, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43556
2022-09-29 08:49:03 - progress_bar.py[line:274] - INFO: epoch 001:  14432 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.9, wpb=101.8, bsz=40, num_updates=14410, lr=4.25725e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43567
2022-09-29 08:49:14 - progress_bar.py[line:274] - INFO: epoch 001:  14442 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.9, wpb=100.7, bsz=40, num_updates=14420, lr=4.25659e-05, gnorm=0.855, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43579
2022-09-29 08:49:25 - progress_bar.py[line:274] - INFO: epoch 001:  14452 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.88, wpb=102.3, bsz=40, num_updates=14430, lr=4.25593e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43590
2022-09-29 08:49:36 - progress_bar.py[line:274] - INFO: epoch 001:  14462 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.9, wpb=101.1, bsz=40, num_updates=14440, lr=4.25527e-05, gnorm=0.735, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43601
2022-09-29 08:49:48 - progress_bar.py[line:274] - INFO: epoch 001:  14472 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88, ups=0.87, wpb=100.6, bsz=40, num_updates=14450, lr=4.25461e-05, gnorm=0.71, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43613
2022-09-29 08:49:59 - progress_bar.py[line:274] - INFO: epoch 001:  14482 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.8, ups=0.92, wpb=102.3, bsz=40, num_updates=14460, lr=4.25395e-05, gnorm=0.781, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43623
2022-09-29 08:50:10 - progress_bar.py[line:274] - INFO: epoch 001:  14492 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.87, wpb=102.8, bsz=40, num_updates=14470, lr=4.25329e-05, gnorm=0.721, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43635
2022-09-29 08:50:21 - progress_bar.py[line:274] - INFO: epoch 001:  14502 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.89, wpb=102.2, bsz=40, num_updates=14480, lr=4.25263e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=43646
2022-09-29 08:50:33 - progress_bar.py[line:274] - INFO: epoch 001:  14512 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.88, wpb=102.6, bsz=40, num_updates=14490, lr=4.25197e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=43658
2022-09-29 08:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  14522 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=14500, lr=4.25131e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43669
2022-09-29 08:50:55 - progress_bar.py[line:274] - INFO: epoch 001:  14532 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.89, wpb=99.5, bsz=40, num_updates=14510, lr=4.25065e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43680
2022-09-29 08:51:06 - progress_bar.py[line:274] - INFO: epoch 001:  14542 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.2, ups=0.92, wpb=101.4, bsz=40, num_updates=14520, lr=4.24999e-05, gnorm=0.744, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43691
2022-09-29 08:51:17 - progress_bar.py[line:274] - INFO: epoch 001:  14552 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=14530, lr=4.24933e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43702
2022-09-29 08:51:28 - progress_bar.py[line:274] - INFO: epoch 001:  14562 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.9, ups=0.91, wpb=101.9, bsz=40, num_updates=14540, lr=4.24867e-05, gnorm=0.847, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43713
2022-09-29 08:51:40 - progress_bar.py[line:274] - INFO: epoch 001:  14572 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.88, wpb=100.6, bsz=40, num_updates=14550, lr=4.24801e-05, gnorm=0.729, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43724
2022-09-29 08:51:51 - progress_bar.py[line:274] - INFO: epoch 001:  14582 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.89, wpb=103.7, bsz=40, num_updates=14560, lr=4.24735e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43736
2022-09-29 08:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  14592 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88, ups=0.89, wpb=99.2, bsz=40, num_updates=14570, lr=4.24669e-05, gnorm=0.717, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=43747
2022-09-29 08:52:14 - progress_bar.py[line:274] - INFO: epoch 001:  14602 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.88, wpb=100, bsz=40, num_updates=14580, lr=4.24603e-05, gnorm=0.797, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43758
2022-09-29 08:52:25 - progress_bar.py[line:274] - INFO: epoch 001:  14612 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.9, wpb=102.1, bsz=40, num_updates=14590, lr=4.24537e-05, gnorm=0.647, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43770
2022-09-29 08:52:35 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 08:52:37 - progress_bar.py[line:274] - INFO: epoch 001:  14623 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=85, ups=0.84, wpb=100.7, bsz=40, num_updates=14600, lr=4.24471e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=43781
2022-09-29 08:52:48 - progress_bar.py[line:274] - INFO: epoch 001:  14633 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.91, wpb=101.5, bsz=40, num_updates=14610, lr=4.24405e-05, gnorm=0.774, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43792
2022-09-29 08:52:59 - progress_bar.py[line:274] - INFO: epoch 001:  14643 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.88, wpb=101.2, bsz=40, num_updates=14620, lr=4.24339e-05, gnorm=0.948, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43804
2022-09-29 08:53:10 - progress_bar.py[line:274] - INFO: epoch 001:  14653 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.9, ups=0.92, wpb=100.7, bsz=40, num_updates=14630, lr=4.24273e-05, gnorm=0.842, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43815
2022-09-29 08:53:21 - progress_bar.py[line:274] - INFO: epoch 001:  14663 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.91, wpb=99.6, bsz=40, num_updates=14640, lr=4.24207e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43826
2022-09-29 08:53:32 - progress_bar.py[line:274] - INFO: epoch 001:  14673 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.2, ups=0.87, wpb=102.3, bsz=40, num_updates=14650, lr=4.24141e-05, gnorm=0.718, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43837
2022-09-29 08:53:43 - progress_bar.py[line:274] - INFO: epoch 001:  14683 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.4, ups=0.91, wpb=100.3, bsz=40, num_updates=14660, lr=4.24075e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43848
2022-09-29 08:53:54 - progress_bar.py[line:274] - INFO: epoch 001:  14693 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.5, ups=0.91, wpb=101.7, bsz=40, num_updates=14670, lr=4.24009e-05, gnorm=0.788, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43859
2022-09-29 08:54:06 - progress_bar.py[line:274] - INFO: epoch 001:  14703 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=14680, lr=4.23943e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=43870
2022-09-29 08:54:17 - progress_bar.py[line:274] - INFO: epoch 001:  14713 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.89, wpb=102.2, bsz=40, num_updates=14690, lr=4.23877e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43882
2022-09-29 08:54:28 - progress_bar.py[line:274] - INFO: epoch 001:  14723 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.2, ups=0.88, wpb=102.9, bsz=40, num_updates=14700, lr=4.23811e-05, gnorm=0.734, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=43893
2022-09-29 08:54:40 - progress_bar.py[line:274] - INFO: epoch 001:  14733 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.2, ups=0.89, wpb=101.5, bsz=40, num_updates=14710, lr=4.23745e-05, gnorm=0.778, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=43904
2022-09-29 08:54:51 - progress_bar.py[line:274] - INFO: epoch 001:  14743 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.1, ups=0.9, wpb=101.9, bsz=40, num_updates=14720, lr=4.23679e-05, gnorm=0.752, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43915
2022-09-29 08:55:02 - progress_bar.py[line:274] - INFO: epoch 001:  14753 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.88, wpb=100.7, bsz=40, num_updates=14730, lr=4.23613e-05, gnorm=0.813, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=43927
2022-09-29 08:55:13 - progress_bar.py[line:274] - INFO: epoch 001:  14763 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.91, wpb=100.7, bsz=40, num_updates=14740, lr=4.23547e-05, gnorm=0.795, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43938
2022-09-29 08:55:24 - progress_bar.py[line:274] - INFO: epoch 001:  14773 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.88, wpb=102.5, bsz=40, num_updates=14750, lr=4.23481e-05, gnorm=0.82, clip=10, loss_scale=512, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=43949
2022-09-29 08:55:35 - progress_bar.py[line:274] - INFO: epoch 001:  14783 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.3, ups=0.93, wpb=103, bsz=40, num_updates=14760, lr=4.23415e-05, gnorm=0.712, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=43960
2022-09-29 08:55:47 - progress_bar.py[line:274] - INFO: epoch 001:  14793 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.88, wpb=102.1, bsz=40, num_updates=14770, lr=4.23349e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=43971
2022-09-29 08:55:57 - progress_bar.py[line:274] - INFO: epoch 001:  14803 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.91, wpb=100.7, bsz=40, num_updates=14780, lr=4.23283e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=43982
2022-09-29 08:56:09 - progress_bar.py[line:274] - INFO: epoch 001:  14813 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.88, wpb=103.4, bsz=40, num_updates=14790, lr=4.23217e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=43994
2022-09-29 08:56:20 - progress_bar.py[line:274] - INFO: epoch 001:  14823 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.4, ups=0.91, wpb=102.3, bsz=40, num_updates=14800, lr=4.23151e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44005
2022-09-29 08:56:31 - progress_bar.py[line:274] - INFO: epoch 001:  14833 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.6, ups=0.93, wpb=100.6, bsz=40, num_updates=14810, lr=4.23085e-05, gnorm=0.81, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44015
2022-09-29 08:56:42 - progress_bar.py[line:274] - INFO: epoch 001:  14843 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89, ups=0.88, wpb=101, bsz=40, num_updates=14820, lr=4.23019e-05, gnorm=0.827, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44027
2022-09-29 08:56:53 - progress_bar.py[line:274] - INFO: epoch 001:  14853 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.8, ups=0.87, wpb=100.2, bsz=40, num_updates=14830, lr=4.22953e-05, gnorm=0.763, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44038
2022-09-29 08:57:05 - progress_bar.py[line:274] - INFO: epoch 001:  14863 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=14840, lr=4.22887e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44050
2022-09-29 08:57:16 - progress_bar.py[line:274] - INFO: epoch 001:  14873 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.9, wpb=100.6, bsz=40, num_updates=14850, lr=4.22821e-05, gnorm=0.89, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44061
2022-09-29 08:57:27 - progress_bar.py[line:274] - INFO: epoch 001:  14883 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.6, ups=0.88, wpb=99.7, bsz=40, num_updates=14860, lr=4.22755e-05, gnorm=0.797, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44072
2022-09-29 08:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  14893 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.5, ups=0.89, wpb=100.6, bsz=40, num_updates=14870, lr=4.22689e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44083
2022-09-29 08:57:50 - progress_bar.py[line:274] - INFO: epoch 001:  14903 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.3, ups=0.89, wpb=102.4, bsz=40, num_updates=14880, lr=4.22623e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44094
2022-09-29 08:58:01 - progress_bar.py[line:274] - INFO: epoch 001:  14913 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.88, wpb=103.3, bsz=40, num_updates=14890, lr=4.22557e-05, gnorm=0.792, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44106
2022-09-29 08:58:12 - progress_bar.py[line:274] - INFO: epoch 001:  14923 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.1, ups=0.88, wpb=102, bsz=40, num_updates=14900, lr=4.22491e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44117
2022-09-29 08:58:24 - progress_bar.py[line:274] - INFO: epoch 001:  14933 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89, ups=0.88, wpb=101.5, bsz=40, num_updates=14910, lr=4.22425e-05, gnorm=0.777, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44129
2022-09-29 08:58:35 - progress_bar.py[line:274] - INFO: epoch 001:  14943 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.6, ups=0.9, wpb=100.8, bsz=40, num_updates=14920, lr=4.22359e-05, gnorm=0.768, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44140
2022-09-29 08:58:46 - progress_bar.py[line:274] - INFO: epoch 001:  14953 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.7, ups=0.89, wpb=99.8, bsz=40, num_updates=14930, lr=4.22293e-05, gnorm=0.861, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44151
2022-09-29 08:58:57 - progress_bar.py[line:274] - INFO: epoch 001:  14963 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=101.4, bsz=40, num_updates=14940, lr=4.22227e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44162
2022-09-29 08:59:08 - progress_bar.py[line:274] - INFO: epoch 001:  14973 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93, ups=0.91, wpb=101.8, bsz=40, num_updates=14950, lr=4.22161e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=44173
2022-09-29 08:59:20 - progress_bar.py[line:274] - INFO: epoch 001:  14983 / 15783 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90, ups=0.89, wpb=101.1, bsz=40, num_updates=14960, lr=4.22095e-05, gnorm=0.844, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44184
2022-09-29 08:59:31 - progress_bar.py[line:274] - INFO: epoch 001:  14993 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.91, wpb=100, bsz=40, num_updates=14970, lr=4.22029e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44195
2022-09-29 08:59:42 - progress_bar.py[line:274] - INFO: epoch 001:  15003 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=14980, lr=4.21963e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44207
2022-09-29 08:59:53 - progress_bar.py[line:274] - INFO: epoch 001:  15013 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.5, ups=0.87, wpb=101, bsz=40, num_updates=14990, lr=4.21897e-05, gnorm=0.825, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44218
2022-09-29 09:00:05 - progress_bar.py[line:274] - INFO: epoch 001:  15023 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.7, ups=0.87, wpb=102.1, bsz=40, num_updates=15000, lr=4.21831e-05, gnorm=0.684, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44230
2022-09-29 09:00:16 - progress_bar.py[line:274] - INFO: epoch 001:  15033 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=15010, lr=4.21765e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44241
2022-09-29 09:00:28 - progress_bar.py[line:274] - INFO: epoch 001:  15043 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.89, wpb=101.8, bsz=40, num_updates=15020, lr=4.21699e-05, gnorm=0.65, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44252
2022-09-29 09:00:38 - progress_bar.py[line:274] - INFO: epoch 001:  15053 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92, ups=0.91, wpb=100.7, bsz=40, num_updates=15030, lr=4.21633e-05, gnorm=0.762, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44263
2022-09-29 09:00:49 - progress_bar.py[line:274] - INFO: epoch 001:  15063 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.1, ups=0.92, wpb=102.1, bsz=40, num_updates=15040, lr=4.21567e-05, gnorm=0.678, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44274
2022-09-29 09:01:00 - progress_bar.py[line:274] - INFO: epoch 001:  15073 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.92, wpb=101.5, bsz=40, num_updates=15050, lr=4.21501e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=44285
2022-09-29 09:01:11 - progress_bar.py[line:274] - INFO: epoch 001:  15083 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.91, wpb=100.9, bsz=40, num_updates=15060, lr=4.21435e-05, gnorm=0.747, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44296
2022-09-29 09:01:22 - progress_bar.py[line:274] - INFO: epoch 001:  15093 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.91, wpb=100.7, bsz=40, num_updates=15070, lr=4.21369e-05, gnorm=0.714, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44307
2022-09-29 09:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  15103 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=15080, lr=4.21303e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44318
2022-09-29 09:01:44 - progress_bar.py[line:274] - INFO: epoch 001:  15113 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.4, ups=0.91, wpb=102.1, bsz=40, num_updates=15090, lr=4.21237e-05, gnorm=0.788, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44329
2022-09-29 09:01:56 - progress_bar.py[line:274] - INFO: epoch 001:  15123 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.6, ups=0.86, wpb=101.5, bsz=40, num_updates=15100, lr=4.21171e-05, gnorm=0.83, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=44341
2022-09-29 09:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  15133 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.89, wpb=104, bsz=40, num_updates=15110, lr=4.21105e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44352
2022-09-29 09:02:19 - progress_bar.py[line:274] - INFO: epoch 001:  15143 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.89, wpb=102, bsz=40, num_updates=15120, lr=4.21039e-05, gnorm=0.84, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44363
2022-09-29 09:02:30 - progress_bar.py[line:274] - INFO: epoch 001:  15153 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.2, ups=0.91, wpb=102.8, bsz=40, num_updates=15130, lr=4.20973e-05, gnorm=0.732, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44374
2022-09-29 09:02:41 - progress_bar.py[line:274] - INFO: epoch 001:  15163 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=15140, lr=4.20907e-05, gnorm=0.736, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44386
2022-09-29 09:02:52 - progress_bar.py[line:274] - INFO: epoch 001:  15173 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.89, wpb=99.1, bsz=40, num_updates=15150, lr=4.20841e-05, gnorm=0.754, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44397
2022-09-29 09:03:03 - progress_bar.py[line:274] - INFO: epoch 001:  15183 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.8, ups=0.91, wpb=101.8, bsz=40, num_updates=15160, lr=4.20775e-05, gnorm=0.873, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44408
2022-09-29 09:03:14 - progress_bar.py[line:274] - INFO: epoch 001:  15193 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.6, ups=0.88, wpb=101.1, bsz=40, num_updates=15170, lr=4.20709e-05, gnorm=0.858, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44419
2022-09-29 09:03:25 - progress_bar.py[line:274] - INFO: epoch 001:  15203 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=93.4, ups=0.93, wpb=100.8, bsz=40, num_updates=15180, lr=4.20643e-05, gnorm=0.76, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44430
2022-09-29 09:03:36 - progress_bar.py[line:274] - INFO: epoch 001:  15213 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=15190, lr=4.20577e-05, gnorm=0.763, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44441
2022-09-29 09:03:47 - progress_bar.py[line:274] - INFO: epoch 001:  15223 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.9, wpb=101.2, bsz=40, num_updates=15200, lr=4.20511e-05, gnorm=0.719, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44452
2022-09-29 09:03:59 - progress_bar.py[line:274] - INFO: epoch 001:  15233 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.89, wpb=100.6, bsz=40, num_updates=15210, lr=4.20445e-05, gnorm=0.892, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=44464
2022-09-29 09:04:10 - progress_bar.py[line:274] - INFO: epoch 001:  15243 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.89, wpb=100.7, bsz=40, num_updates=15220, lr=4.20379e-05, gnorm=0.731, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44475
2022-09-29 09:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  15253 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.9, wpb=102.1, bsz=40, num_updates=15230, lr=4.20313e-05, gnorm=0.791, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=44486
2022-09-29 09:04:32 - progress_bar.py[line:274] - INFO: epoch 001:  15263 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.9, wpb=101.9, bsz=40, num_updates=15240, lr=4.20247e-05, gnorm=0.873, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44497
2022-09-29 09:04:43 - progress_bar.py[line:274] - INFO: epoch 001:  15273 / 15783 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=87.9, ups=0.89, wpb=99.3, bsz=40, num_updates=15250, lr=4.20181e-05, gnorm=0.884, clip=20, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44508
2022-09-29 09:04:55 - progress_bar.py[line:274] - INFO: epoch 001:  15283 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.5, ups=0.88, wpb=101.6, bsz=40, num_updates=15260, lr=4.20115e-05, gnorm=0.728, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44520
2022-09-29 09:05:06 - progress_bar.py[line:274] - INFO: epoch 001:  15293 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.9, wpb=100.5, bsz=40, num_updates=15270, lr=4.20049e-05, gnorm=0.79, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44531
2022-09-29 09:05:17 - progress_bar.py[line:274] - INFO: epoch 001:  15303 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.5, ups=0.9, wpb=99.6, bsz=40, num_updates=15280, lr=4.19983e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44542
2022-09-29 09:05:28 - progress_bar.py[line:274] - INFO: epoch 001:  15313 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=15290, lr=4.19917e-05, gnorm=0.89, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44553
2022-09-29 09:05:39 - progress_bar.py[line:274] - INFO: epoch 001:  15323 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=101, bsz=40, num_updates=15300, lr=4.19851e-05, gnorm=0.778, clip=10, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=44564
2022-09-29 09:05:49 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 09:05:52 - progress_bar.py[line:274] - INFO: epoch 001:  15334 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=82.6, ups=0.82, wpb=100.7, bsz=40, num_updates=15310, lr=4.19785e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=44576
2022-09-29 09:06:03 - progress_bar.py[line:274] - INFO: epoch 001:  15344 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.4, ups=0.88, wpb=101.8, bsz=40, num_updates=15320, lr=4.19719e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44588
2022-09-29 09:06:14 - progress_bar.py[line:274] - INFO: epoch 001:  15354 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.3, ups=0.94, wpb=101.5, bsz=40, num_updates=15330, lr=4.19653e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44599
2022-09-29 09:06:25 - progress_bar.py[line:274] - INFO: epoch 001:  15364 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.9, wpb=101.7, bsz=40, num_updates=15340, lr=4.19587e-05, gnorm=0.716, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44610
2022-09-29 09:06:36 - progress_bar.py[line:274] - INFO: epoch 001:  15374 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.5, ups=0.93, wpb=100.8, bsz=40, num_updates=15350, lr=4.19521e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=44621
2022-09-29 09:06:47 - progress_bar.py[line:274] - INFO: epoch 001:  15384 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.8, ups=0.89, wpb=100, bsz=40, num_updates=15360, lr=4.19455e-05, gnorm=0.744, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44632
2022-09-29 09:06:58 - progress_bar.py[line:274] - INFO: epoch 001:  15394 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.9, wpb=100.3, bsz=40, num_updates=15370, lr=4.19389e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44643
2022-09-29 09:07:09 - progress_bar.py[line:274] - INFO: epoch 001:  15404 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.89, wpb=101.9, bsz=40, num_updates=15380, lr=4.19323e-05, gnorm=0.766, clip=0, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=44654
2022-09-29 09:07:21 - progress_bar.py[line:274] - INFO: epoch 001:  15414 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.89, wpb=101.9, bsz=40, num_updates=15390, lr=4.19257e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44666
2022-09-29 09:07:32 - progress_bar.py[line:274] - INFO: epoch 001:  15424 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.8, ups=0.89, wpb=98.7, bsz=40, num_updates=15400, lr=4.19191e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44677
2022-09-29 09:07:43 - progress_bar.py[line:274] - INFO: epoch 001:  15434 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.88, wpb=101.6, bsz=40, num_updates=15410, lr=4.19125e-05, gnorm=0.712, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44688
2022-09-29 09:07:55 - progress_bar.py[line:274] - INFO: epoch 001:  15444 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.2, ups=0.88, wpb=101.7, bsz=40, num_updates=15420, lr=4.19059e-05, gnorm=0.747, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44700
2022-09-29 09:08:06 - progress_bar.py[line:274] - INFO: epoch 001:  15454 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.6, ups=0.89, wpb=102.9, bsz=40, num_updates=15430, lr=4.18993e-05, gnorm=0.766, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44711
2022-09-29 09:08:17 - progress_bar.py[line:274] - INFO: epoch 001:  15464 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.4, ups=0.91, wpb=102.2, bsz=40, num_updates=15440, lr=4.18927e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44722
2022-09-29 09:08:29 - progress_bar.py[line:274] - INFO: epoch 001:  15474 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.6, ups=0.87, wpb=100.9, bsz=40, num_updates=15450, lr=4.18861e-05, gnorm=0.758, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44734
2022-09-29 09:08:40 - progress_bar.py[line:274] - INFO: epoch 001:  15484 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=15460, lr=4.18795e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44745
2022-09-29 09:08:51 - progress_bar.py[line:274] - INFO: epoch 001:  15494 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.9, ups=0.87, wpb=101.7, bsz=40, num_updates=15470, lr=4.18729e-05, gnorm=0.993, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44756
2022-09-29 09:09:03 - progress_bar.py[line:274] - INFO: epoch 001:  15504 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.9, wpb=103, bsz=40, num_updates=15480, lr=4.18663e-05, gnorm=0.745, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44767
2022-09-29 09:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  15514 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.88, wpb=102.4, bsz=40, num_updates=15490, lr=4.18597e-05, gnorm=0.743, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=44779
2022-09-29 09:09:25 - progress_bar.py[line:274] - INFO: epoch 001:  15524 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.88, wpb=101.5, bsz=40, num_updates=15500, lr=4.18531e-05, gnorm=0.754, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44790
2022-09-29 09:09:37 - progress_bar.py[line:274] - INFO: epoch 001:  15534 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.89, wpb=102.9, bsz=40, num_updates=15510, lr=4.18465e-05, gnorm=0.662, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44802
2022-09-29 09:09:48 - progress_bar.py[line:274] - INFO: epoch 001:  15544 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.1, ups=0.9, wpb=101.9, bsz=40, num_updates=15520, lr=4.18399e-05, gnorm=0.694, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=44813
2022-09-29 09:09:59 - progress_bar.py[line:274] - INFO: epoch 001:  15554 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.92, wpb=100.4, bsz=40, num_updates=15530, lr=4.18333e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44823
2022-09-29 09:10:10 - progress_bar.py[line:274] - INFO: epoch 001:  15564 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.5, ups=0.9, wpb=102.4, bsz=40, num_updates=15540, lr=4.18267e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44835
2022-09-29 09:10:21 - progress_bar.py[line:274] - INFO: epoch 001:  15574 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.6, ups=0.9, wpb=100.3, bsz=40, num_updates=15550, lr=4.18201e-05, gnorm=0.927, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44846
2022-09-29 09:10:32 - progress_bar.py[line:274] - INFO: epoch 001:  15584 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.9, ups=0.92, wpb=100.4, bsz=40, num_updates=15560, lr=4.18135e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=44857
2022-09-29 09:10:43 - progress_bar.py[line:274] - INFO: epoch 001:  15594 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=15570, lr=4.18069e-05, gnorm=0.821, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44868
2022-09-29 09:10:54 - progress_bar.py[line:274] - INFO: epoch 001:  15604 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.2, ups=0.87, wpb=101.8, bsz=40, num_updates=15580, lr=4.18003e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44879
2022-09-29 09:11:06 - progress_bar.py[line:274] - INFO: epoch 001:  15614 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.6, ups=0.87, wpb=101.1, bsz=40, num_updates=15590, lr=4.17937e-05, gnorm=0.859, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44891
2022-09-29 09:11:17 - progress_bar.py[line:274] - INFO: epoch 001:  15624 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.9, wpb=100.8, bsz=40, num_updates=15600, lr=4.17871e-05, gnorm=0.862, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44902
2022-09-29 09:11:28 - progress_bar.py[line:274] - INFO: epoch 001:  15634 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.7, ups=0.89, wpb=99.9, bsz=40, num_updates=15610, lr=4.17805e-05, gnorm=0.925, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44913
2022-09-29 09:11:40 - progress_bar.py[line:274] - INFO: epoch 001:  15644 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.88, wpb=101.7, bsz=40, num_updates=15620, lr=4.17739e-05, gnorm=0.777, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44924
2022-09-29 09:11:51 - progress_bar.py[line:274] - INFO: epoch 001:  15654 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.8, ups=0.9, wpb=102, bsz=40, num_updates=15630, lr=4.17673e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44936
2022-09-29 09:12:02 - progress_bar.py[line:274] - INFO: epoch 001:  15664 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.1, ups=0.93, wpb=100.5, bsz=40, num_updates=15640, lr=4.17607e-05, gnorm=0.787, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44946
2022-09-29 09:12:12 - progress_bar.py[line:274] - INFO: epoch 001:  15674 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.4, ups=0.92, wpb=101.1, bsz=40, num_updates=15650, lr=4.17541e-05, gnorm=0.726, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44957
2022-09-29 09:12:24 - progress_bar.py[line:274] - INFO: epoch 001:  15684 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.89, wpb=102.3, bsz=40, num_updates=15660, lr=4.17475e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=44969
2022-09-29 09:12:35 - progress_bar.py[line:274] - INFO: epoch 001:  15694 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.4, ups=0.86, wpb=100.8, bsz=40, num_updates=15670, lr=4.17409e-05, gnorm=0.676, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=44980
2022-09-29 09:12:47 - progress_bar.py[line:274] - INFO: epoch 001:  15704 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.89, wpb=101.5, bsz=40, num_updates=15680, lr=4.17343e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44991
2022-09-29 09:12:58 - progress_bar.py[line:274] - INFO: epoch 001:  15714 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.88, wpb=101.6, bsz=40, num_updates=15690, lr=4.17277e-05, gnorm=0.742, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45003
2022-09-29 09:13:10 - progress_bar.py[line:274] - INFO: epoch 001:  15724 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.6, ups=0.86, wpb=101.6, bsz=40, num_updates=15700, lr=4.17211e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=45014
2022-09-29 09:13:21 - progress_bar.py[line:274] - INFO: epoch 001:  15734 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=15710, lr=4.17145e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=45026
2022-09-29 09:13:32 - progress_bar.py[line:274] - INFO: epoch 001:  15744 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92, ups=0.91, wpb=100.6, bsz=40, num_updates=15720, lr=4.17079e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45037
2022-09-29 09:13:42 - progress_bar.py[line:274] - INFO: epoch 001:  15754 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95, ups=0.95, wpb=100.4, bsz=40, num_updates=15730, lr=4.17013e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45047
2022-09-29 09:13:54 - progress_bar.py[line:274] - INFO: epoch 001:  15764 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=15740, lr=4.16947e-05, gnorm=0.814, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45059
2022-09-29 09:14:05 - progress_bar.py[line:274] - INFO: epoch 001:  15774 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.4, ups=0.88, wpb=101.6, bsz=40, num_updates=15750, lr=4.16881e-05, gnorm=0.717, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45070
2022-09-29 09:14:15 - train.py[line:339] - INFO: end of epoch 1 (average epoch stats below)
2022-09-29 09:14:15 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.619 | loss_v1 0 | loss_v2 0 | nll_loss 0.413 | ntokens 101.338 | nsentences 39.998 | sample_size 101.338 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.33 | wps 35.4 | ups 0.35 | wpb 101.3 | bsz 40 | num_updates 15759 | lr 4.16822e-05 | gnorm 1.158 | clip 42 | loss_scale 512 | train_wall 17734 | gb_free 33 | ema_decay 0.9999 | wall 45079
2022-09-29 09:14:15 - trainer.py[line:643] - INFO: loading train data for epoch 2
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv slice_id 1 row count 315642 total row count 631284
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv slice_id 0 row count 315642 total row count 631284
2022-09-29 09:14:16 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-29 09:14:16 - trainer.py[line:707] - INFO: begin training epoch 2
2022-09-29 09:14:16 - train.py[line:312] - INFO: Start iterating over samples
2022-09-29 09:14:19 - progress_bar.py[line:274] - INFO: epoch 002:      1 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=92.7, nsentences=36.4, sample_size=92.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=68.4, ups=0.74, wpb=92.7, bsz=36.4, num_updates=15760, lr=4.16815e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45084
2022-09-29 09:14:30 - progress_bar.py[line:274] - INFO: epoch 002:     11 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.9, ups=0.92, wpb=100.2, bsz=40, num_updates=15770, lr=4.16749e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45094
2022-09-29 09:14:41 - progress_bar.py[line:274] - INFO: epoch 002:     21 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.4, ups=0.91, wpb=101.4, bsz=40, num_updates=15780, lr=4.16683e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45105
2022-09-29 09:14:52 - progress_bar.py[line:274] - INFO: epoch 002:     31 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.4, ups=0.9, wpb=100.2, bsz=40, num_updates=15790, lr=4.16617e-05, gnorm=0.692, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45117
2022-09-29 09:15:03 - progress_bar.py[line:274] - INFO: epoch 002:     41 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.5, ups=0.9, wpb=102.5, bsz=40, num_updates=15800, lr=4.16551e-05, gnorm=0.854, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45128
2022-09-29 09:15:14 - progress_bar.py[line:274] - INFO: epoch 002:     51 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.88, wpb=102.7, bsz=40, num_updates=15810, lr=4.16485e-05, gnorm=0.764, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45139
2022-09-29 09:15:26 - progress_bar.py[line:274] - INFO: epoch 002:     61 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=15820, lr=4.16419e-05, gnorm=0.773, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45150
2022-09-29 09:15:37 - progress_bar.py[line:274] - INFO: epoch 002:     71 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.89, wpb=102.4, bsz=40, num_updates=15830, lr=4.16353e-05, gnorm=0.865, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45162
2022-09-29 09:15:48 - progress_bar.py[line:274] - INFO: epoch 002:     81 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.9, ups=0.89, wpb=102.8, bsz=40, num_updates=15840, lr=4.16287e-05, gnorm=0.764, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45173
2022-09-29 09:15:59 - progress_bar.py[line:274] - INFO: epoch 002:     91 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=15850, lr=4.16221e-05, gnorm=0.824, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45184
2022-09-29 09:16:10 - progress_bar.py[line:274] - INFO: epoch 002:    101 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.91, wpb=99.8, bsz=40, num_updates=15860, lr=4.16155e-05, gnorm=0.778, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45195
2022-09-29 09:16:22 - progress_bar.py[line:274] - INFO: epoch 002:    111 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.1, ups=0.88, wpb=101.5, bsz=40, num_updates=15870, lr=4.16089e-05, gnorm=0.804, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45207
2022-09-29 09:16:33 - progress_bar.py[line:274] - INFO: epoch 002:    121 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.7, ups=0.88, wpb=99.9, bsz=40, num_updates=15880, lr=4.16023e-05, gnorm=0.879, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45218
2022-09-29 09:16:44 - progress_bar.py[line:274] - INFO: epoch 002:    131 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=15890, lr=4.15957e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45229
2022-09-29 09:16:56 - progress_bar.py[line:274] - INFO: epoch 002:    141 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.88, wpb=102.3, bsz=40, num_updates=15900, lr=4.15891e-05, gnorm=0.811, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45241
2022-09-29 09:17:07 - progress_bar.py[line:274] - INFO: epoch 002:    151 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.6, ups=0.9, wpb=101.9, bsz=40, num_updates=15910, lr=4.15825e-05, gnorm=0.85, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45252
2022-09-29 09:17:18 - progress_bar.py[line:274] - INFO: epoch 002:    161 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.89, wpb=102.1, bsz=40, num_updates=15920, lr=4.15759e-05, gnorm=0.732, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45263
2022-09-29 09:17:29 - progress_bar.py[line:274] - INFO: epoch 002:    171 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.9, wpb=99.9, bsz=40, num_updates=15930, lr=4.15693e-05, gnorm=0.837, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45274
2022-09-29 09:17:40 - progress_bar.py[line:274] - INFO: epoch 002:    181 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=101.5, bsz=40, num_updates=15940, lr=4.15627e-05, gnorm=0.802, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45285
2022-09-29 09:17:47 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 09:17:53 - progress_bar.py[line:274] - INFO: epoch 002:    192 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=83.7, ups=0.82, wpb=101.4, bsz=40, num_updates=15950, lr=4.15561e-05, gnorm=0.806, clip=0, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=45297
2022-09-29 09:18:04 - progress_bar.py[line:274] - INFO: epoch 002:    202 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.89, wpb=102.9, bsz=40, num_updates=15960, lr=4.15495e-05, gnorm=0.843, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45309
2022-09-29 09:18:15 - progress_bar.py[line:274] - INFO: epoch 002:    212 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.89, wpb=103.2, bsz=40, num_updates=15970, lr=4.15429e-05, gnorm=0.768, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45320
2022-09-29 09:18:26 - progress_bar.py[line:274] - INFO: epoch 002:    222 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.88, wpb=100.9, bsz=40, num_updates=15980, lr=4.15363e-05, gnorm=0.682, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45331
2022-09-29 09:18:38 - progress_bar.py[line:274] - INFO: epoch 002:    232 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.3, ups=0.89, wpb=100.4, bsz=40, num_updates=15990, lr=4.15297e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45342
2022-09-29 09:18:49 - progress_bar.py[line:274] - INFO: epoch 002:    242 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.87, wpb=101.8, bsz=40, num_updates=16000, lr=4.15231e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45354
2022-09-29 09:19:01 - progress_bar.py[line:274] - INFO: epoch 002:    252 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.88, wpb=101.8, bsz=40, num_updates=16010, lr=4.15165e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45365
2022-09-29 09:19:12 - progress_bar.py[line:274] - INFO: epoch 002:    262 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.9, ups=0.91, wpb=102.1, bsz=40, num_updates=16020, lr=4.15099e-05, gnorm=0.702, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45376
2022-09-29 09:19:23 - progress_bar.py[line:274] - INFO: epoch 002:    272 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=16030, lr=4.15033e-05, gnorm=0.793, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45388
2022-09-29 09:19:34 - progress_bar.py[line:274] - INFO: epoch 002:    282 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=101.9, bsz=40, num_updates=16040, lr=4.14967e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45399
2022-09-29 09:19:45 - progress_bar.py[line:274] - INFO: epoch 002:    292 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.88, wpb=100.5, bsz=40, num_updates=16050, lr=4.14901e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45410
2022-09-29 09:19:57 - progress_bar.py[line:274] - INFO: epoch 002:    302 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.9, wpb=99.8, bsz=40, num_updates=16060, lr=4.14835e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45421
2022-09-29 09:20:08 - progress_bar.py[line:274] - INFO: epoch 002:    312 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.89, wpb=102.4, bsz=40, num_updates=16070, lr=4.14769e-05, gnorm=0.844, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45433
2022-09-29 09:20:19 - progress_bar.py[line:274] - INFO: epoch 002:    322 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.8, ups=0.88, wpb=101, bsz=40, num_updates=16080, lr=4.14703e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45444
2022-09-29 09:20:30 - progress_bar.py[line:274] - INFO: epoch 002:    332 / 15783 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=97.9, nsentences=40, sample_size=97.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=86.9, ups=0.89, wpb=97.9, bsz=40, num_updates=16090, lr=4.14637e-05, gnorm=0.956, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45455
2022-09-29 09:20:41 - progress_bar.py[line:274] - INFO: epoch 002:    342 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.4, ups=0.91, wpb=101.6, bsz=40, num_updates=16100, lr=4.14571e-05, gnorm=0.687, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45466
2022-09-29 09:20:53 - progress_bar.py[line:274] - INFO: epoch 002:    352 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.89, wpb=102.4, bsz=40, num_updates=16110, lr=4.14505e-05, gnorm=0.745, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45478
2022-09-29 09:21:04 - progress_bar.py[line:274] - INFO: epoch 002:    362 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.9, wpb=101.6, bsz=40, num_updates=16120, lr=4.14439e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45489
2022-09-29 09:21:15 - progress_bar.py[line:274] - INFO: epoch 002:    372 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.8, ups=0.88, wpb=102.3, bsz=40, num_updates=16130, lr=4.14373e-05, gnorm=0.727, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=45500
2022-09-29 09:21:26 - progress_bar.py[line:274] - INFO: epoch 002:    382 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.6, ups=0.89, wpb=99.7, bsz=40, num_updates=16140, lr=4.14307e-05, gnorm=0.908, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45511
2022-09-29 09:21:37 - progress_bar.py[line:274] - INFO: epoch 002:    392 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95, ups=0.93, wpb=102.7, bsz=40, num_updates=16150, lr=4.14241e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45522
2022-09-29 09:21:48 - progress_bar.py[line:274] - INFO: epoch 002:    402 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.89, wpb=102.2, bsz=40, num_updates=16160, lr=4.14175e-05, gnorm=0.78, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=45533
2022-09-29 09:22:00 - progress_bar.py[line:274] - INFO: epoch 002:    412 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.89, wpb=99.6, bsz=40, num_updates=16170, lr=4.14109e-05, gnorm=1.396, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45545
2022-09-29 09:22:11 - progress_bar.py[line:274] - INFO: epoch 002:    422 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.9, wpb=100.3, bsz=40, num_updates=16180, lr=4.14043e-05, gnorm=0.726, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45556
2022-09-29 09:22:22 - progress_bar.py[line:274] - INFO: epoch 002:    432 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.88, wpb=102.7, bsz=40, num_updates=16190, lr=4.13977e-05, gnorm=0.746, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45567
2022-09-29 09:22:33 - progress_bar.py[line:274] - INFO: epoch 002:    442 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.9, wpb=99.7, bsz=40, num_updates=16200, lr=4.13911e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45578
2022-09-29 09:22:45 - progress_bar.py[line:274] - INFO: epoch 002:    452 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.3, ups=0.88, wpb=99.7, bsz=40, num_updates=16210, lr=4.13845e-05, gnorm=0.916, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45590
2022-09-29 09:22:56 - progress_bar.py[line:274] - INFO: epoch 002:    462 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=16220, lr=4.13779e-05, gnorm=0.86, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45601
2022-09-29 09:23:07 - progress_bar.py[line:274] - INFO: epoch 002:    472 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.1, ups=0.92, wpb=100.6, bsz=40, num_updates=16230, lr=4.13713e-05, gnorm=0.815, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45612
2022-09-29 09:23:18 - progress_bar.py[line:274] - INFO: epoch 002:    482 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.91, wpb=101.1, bsz=40, num_updates=16240, lr=4.13647e-05, gnorm=0.966, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45623
2022-09-29 09:23:29 - progress_bar.py[line:274] - INFO: epoch 002:    492 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.5, ups=0.92, wpb=102.2, bsz=40, num_updates=16250, lr=4.13581e-05, gnorm=0.804, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45634
2022-09-29 09:23:40 - progress_bar.py[line:274] - INFO: epoch 002:    502 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=16260, lr=4.13515e-05, gnorm=0.758, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45645
2022-09-29 09:23:51 - progress_bar.py[line:274] - INFO: epoch 002:    512 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.9, wpb=101.9, bsz=40, num_updates=16270, lr=4.13449e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45656
2022-09-29 09:24:02 - progress_bar.py[line:274] - INFO: epoch 002:    522 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.1, ups=0.93, wpb=102.6, bsz=40, num_updates=16280, lr=4.13383e-05, gnorm=0.869, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45667
2022-09-29 09:24:13 - progress_bar.py[line:274] - INFO: epoch 002:    532 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.6, ups=0.88, wpb=100, bsz=40, num_updates=16290, lr=4.13317e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45678
2022-09-29 09:24:25 - progress_bar.py[line:274] - INFO: epoch 002:    542 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.87, wpb=101.7, bsz=40, num_updates=16300, lr=4.13251e-05, gnorm=0.84, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45689
2022-09-29 09:24:36 - progress_bar.py[line:274] - INFO: epoch 002:    552 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.89, wpb=103.1, bsz=40, num_updates=16310, lr=4.13185e-05, gnorm=0.928, clip=20, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=45701
2022-09-29 09:24:47 - progress_bar.py[line:274] - INFO: epoch 002:    562 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=16320, lr=4.13119e-05, gnorm=0.922, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45712
2022-09-29 09:24:58 - progress_bar.py[line:274] - INFO: epoch 002:    572 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.89, wpb=102, bsz=40, num_updates=16330, lr=4.13053e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45723
2022-09-29 09:25:09 - progress_bar.py[line:274] - INFO: epoch 002:    582 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.9, wpb=101.2, bsz=40, num_updates=16340, lr=4.12987e-05, gnorm=0.888, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45734
2022-09-29 09:25:21 - progress_bar.py[line:274] - INFO: epoch 002:    592 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88, ups=0.88, wpb=100.4, bsz=40, num_updates=16350, lr=4.12921e-05, gnorm=0.864, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45746
2022-09-29 09:25:32 - progress_bar.py[line:274] - INFO: epoch 002:    602 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.7, ups=0.92, wpb=100, bsz=40, num_updates=16360, lr=4.12855e-05, gnorm=0.795, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45757
2022-09-29 09:25:43 - progress_bar.py[line:274] - INFO: epoch 002:    612 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.9, wpb=100.7, bsz=40, num_updates=16370, lr=4.12789e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45768
2022-09-29 09:25:54 - progress_bar.py[line:274] - INFO: epoch 002:    622 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.9, ups=0.86, wpb=101.2, bsz=40, num_updates=16380, lr=4.12723e-05, gnorm=0.75, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=45779
2022-09-29 09:26:06 - progress_bar.py[line:274] - INFO: epoch 002:    632 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=16390, lr=4.12657e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45790
2022-09-29 09:26:17 - progress_bar.py[line:274] - INFO: epoch 002:    642 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.9, wpb=102.3, bsz=40, num_updates=16400, lr=4.12591e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45802
2022-09-29 09:26:28 - progress_bar.py[line:274] - INFO: epoch 002:    652 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.5, ups=0.88, wpb=103, bsz=40, num_updates=16410, lr=4.12525e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45813
2022-09-29 09:26:39 - progress_bar.py[line:274] - INFO: epoch 002:    662 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101.8, bsz=40, num_updates=16420, lr=4.12459e-05, gnorm=0.849, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45824
2022-09-29 09:26:51 - progress_bar.py[line:274] - INFO: epoch 002:    672 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.2, ups=0.89, wpb=100.5, bsz=40, num_updates=16430, lr=4.12393e-05, gnorm=0.803, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45835
2022-09-29 09:27:01 - progress_bar.py[line:274] - INFO: epoch 002:    682 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.6, ups=0.94, wpb=100.8, bsz=40, num_updates=16440, lr=4.12327e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45846
2022-09-29 09:27:12 - progress_bar.py[line:274] - INFO: epoch 002:    692 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=101, bsz=40, num_updates=16450, lr=4.12261e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45857
2022-09-29 09:27:23 - progress_bar.py[line:274] - INFO: epoch 002:    702 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.1, ups=0.92, wpb=100.8, bsz=40, num_updates=16460, lr=4.12195e-05, gnorm=0.965, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45868
2022-09-29 09:27:35 - progress_bar.py[line:274] - INFO: epoch 002:    712 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.89, wpb=102.2, bsz=40, num_updates=16470, lr=4.12129e-05, gnorm=0.837, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45879
2022-09-29 09:27:46 - progress_bar.py[line:274] - INFO: epoch 002:    722 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.9, wpb=100.1, bsz=40, num_updates=16480, lr=4.12063e-05, gnorm=0.893, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45890
2022-09-29 09:27:56 - progress_bar.py[line:274] - INFO: epoch 002:    732 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.6, ups=0.94, wpb=101.1, bsz=40, num_updates=16490, lr=4.11997e-05, gnorm=0.723, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45901
2022-09-29 09:28:08 - progress_bar.py[line:274] - INFO: epoch 002:    742 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.88, wpb=101.9, bsz=40, num_updates=16500, lr=4.11931e-05, gnorm=0.937, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45913
2022-09-29 09:28:19 - progress_bar.py[line:274] - INFO: epoch 002:    752 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=16510, lr=4.11865e-05, gnorm=0.821, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45924
2022-09-29 09:28:30 - progress_bar.py[line:274] - INFO: epoch 002:    762 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.5, ups=0.91, wpb=102.5, bsz=40, num_updates=16520, lr=4.11799e-05, gnorm=0.844, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45935
2022-09-29 09:28:41 - progress_bar.py[line:274] - INFO: epoch 002:    772 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.2, ups=0.9, wpb=102.6, bsz=40, num_updates=16530, lr=4.11733e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45946
2022-09-29 09:28:53 - progress_bar.py[line:274] - INFO: epoch 002:    782 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.6, ups=0.87, wpb=101.2, bsz=40, num_updates=16540, lr=4.11667e-05, gnorm=0.837, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45957
2022-09-29 09:29:04 - progress_bar.py[line:274] - INFO: epoch 002:    792 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.91, wpb=100.6, bsz=40, num_updates=16550, lr=4.11601e-05, gnorm=0.91, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45968
2022-09-29 09:29:15 - progress_bar.py[line:274] - INFO: epoch 002:    802 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.87, wpb=101.9, bsz=40, num_updates=16560, lr=4.11535e-05, gnorm=0.821, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45980
2022-09-29 09:29:26 - progress_bar.py[line:274] - INFO: epoch 002:    812 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.91, wpb=101, bsz=40, num_updates=16570, lr=4.11469e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45991
2022-09-29 09:29:37 - progress_bar.py[line:274] - INFO: epoch 002:    822 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.7, ups=0.92, wpb=101.5, bsz=40, num_updates=16580, lr=4.11403e-05, gnorm=0.851, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46002
2022-09-29 09:29:48 - progress_bar.py[line:274] - INFO: epoch 002:    832 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.1, ups=0.88, wpb=99.3, bsz=40, num_updates=16590, lr=4.11337e-05, gnorm=0.936, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46013
2022-09-29 09:29:59 - progress_bar.py[line:274] - INFO: epoch 002:    842 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=16600, lr=4.11271e-05, gnorm=0.749, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46024
2022-09-29 09:30:11 - progress_bar.py[line:274] - INFO: epoch 002:    852 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.89, wpb=102.3, bsz=40, num_updates=16610, lr=4.11205e-05, gnorm=0.82, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46036
2022-09-29 09:30:22 - progress_bar.py[line:274] - INFO: epoch 002:    862 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=16620, lr=4.11139e-05, gnorm=0.764, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=46047
2022-09-29 09:30:33 - progress_bar.py[line:274] - INFO: epoch 002:    872 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.9, ups=0.88, wpb=101.3, bsz=40, num_updates=16630, lr=4.11073e-05, gnorm=0.735, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46058
2022-09-29 09:30:44 - progress_bar.py[line:274] - INFO: epoch 002:    882 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.92, wpb=101.2, bsz=40, num_updates=16640, lr=4.11007e-05, gnorm=0.749, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46069
2022-09-29 09:30:56 - progress_bar.py[line:274] - INFO: epoch 002:    892 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.88, wpb=101, bsz=40, num_updates=16650, lr=4.10941e-05, gnorm=0.89, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46080
2022-09-29 09:31:07 - progress_bar.py[line:274] - INFO: epoch 002:    902 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=100.4, bsz=40, num_updates=16660, lr=4.10875e-05, gnorm=0.848, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46091
2022-09-29 09:31:18 - progress_bar.py[line:274] - INFO: epoch 002:    912 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.89, wpb=102.3, bsz=40, num_updates=16670, lr=4.10809e-05, gnorm=0.763, clip=10, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=46103
2022-09-29 09:31:29 - progress_bar.py[line:274] - INFO: epoch 002:    922 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.8, ups=0.92, wpb=102.6, bsz=40, num_updates=16680, lr=4.10743e-05, gnorm=0.812, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46114
2022-09-29 09:31:40 - progress_bar.py[line:274] - INFO: epoch 002:    932 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=16690, lr=4.10677e-05, gnorm=0.799, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46125
2022-09-29 09:31:51 - progress_bar.py[line:274] - INFO: epoch 002:    942 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.3, ups=0.88, wpb=100.6, bsz=40, num_updates=16700, lr=4.10611e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46136
2022-09-29 09:32:03 - progress_bar.py[line:274] - INFO: epoch 002:    952 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.88, wpb=102.2, bsz=40, num_updates=16710, lr=4.10545e-05, gnorm=0.781, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46147
2022-09-29 09:32:14 - progress_bar.py[line:274] - INFO: epoch 002:    962 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.8, ups=0.89, wpb=100.2, bsz=40, num_updates=16720, lr=4.10479e-05, gnorm=0.99, clip=50, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=46159
2022-09-29 09:32:25 - progress_bar.py[line:274] - INFO: epoch 002:    972 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.5, ups=0.9, wpb=102.6, bsz=40, num_updates=16730, lr=4.10413e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46170
2022-09-29 09:32:37 - progress_bar.py[line:274] - INFO: epoch 002:    982 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.1, ups=0.87, wpb=100.5, bsz=40, num_updates=16740, lr=4.10347e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46181
2022-09-29 09:32:48 - progress_bar.py[line:274] - INFO: epoch 002:    992 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=16750, lr=4.10281e-05, gnorm=0.871, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=46193
2022-09-29 09:32:59 - progress_bar.py[line:274] - INFO: epoch 002:   1002 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.89, wpb=102, bsz=40, num_updates=16760, lr=4.10215e-05, gnorm=0.849, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46204
2022-09-29 09:33:10 - progress_bar.py[line:274] - INFO: epoch 002:   1012 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.2, ups=0.89, wpb=101.4, bsz=40, num_updates=16770, lr=4.10149e-05, gnorm=0.784, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46215
2022-09-29 09:33:22 - progress_bar.py[line:274] - INFO: epoch 002:   1022 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.8, ups=0.89, wpb=100, bsz=40, num_updates=16780, lr=4.10083e-05, gnorm=0.929, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=46226
2022-09-29 09:33:32 - progress_bar.py[line:274] - INFO: epoch 002:   1032 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.92, wpb=101.6, bsz=40, num_updates=16790, lr=4.10017e-05, gnorm=0.928, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46237
2022-09-29 09:33:44 - progress_bar.py[line:274] - INFO: epoch 002:   1042 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.87, wpb=102.2, bsz=40, num_updates=16800, lr=4.09951e-05, gnorm=0.812, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46249
2022-09-29 09:33:55 - progress_bar.py[line:274] - INFO: epoch 002:   1052 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.89, wpb=100.2, bsz=40, num_updates=16810, lr=4.09885e-05, gnorm=0.928, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46260
2022-09-29 09:34:07 - progress_bar.py[line:274] - INFO: epoch 002:   1062 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.6, ups=0.87, wpb=100.9, bsz=40, num_updates=16820, lr=4.09819e-05, gnorm=0.977, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46272
2022-09-29 09:34:18 - progress_bar.py[line:274] - INFO: epoch 002:   1072 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=16830, lr=4.09753e-05, gnorm=0.82, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46283
2022-09-29 09:34:30 - progress_bar.py[line:274] - INFO: epoch 002:   1082 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.87, wpb=102.6, bsz=40, num_updates=16840, lr=4.09687e-05, gnorm=0.752, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46294
2022-09-29 09:34:41 - progress_bar.py[line:274] - INFO: epoch 002:   1092 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.5, ups=0.87, wpb=101.4, bsz=40, num_updates=16850, lr=4.09621e-05, gnorm=0.819, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46306
2022-09-29 09:34:52 - progress_bar.py[line:274] - INFO: epoch 002:   1102 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.8, ups=0.9, wpb=99.1, bsz=40, num_updates=16860, lr=4.09555e-05, gnorm=0.911, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46317
2022-09-29 09:35:04 - progress_bar.py[line:274] - INFO: epoch 002:   1112 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.8, ups=0.88, wpb=100.7, bsz=40, num_updates=16870, lr=4.09489e-05, gnorm=0.874, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46329
2022-09-29 09:35:14 - progress_bar.py[line:274] - INFO: epoch 002:   1122 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.8, ups=0.95, wpb=101.2, bsz=40, num_updates=16880, lr=4.09423e-05, gnorm=0.978, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46339
2022-09-29 09:35:25 - progress_bar.py[line:274] - INFO: epoch 002:   1132 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.4, ups=0.91, wpb=102, bsz=40, num_updates=16890, lr=4.09357e-05, gnorm=0.843, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=46350
2022-09-29 09:35:37 - progress_bar.py[line:274] - INFO: epoch 002:   1142 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.9, ups=0.87, wpb=101.6, bsz=40, num_updates=16900, lr=4.09291e-05, gnorm=0.73, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46362
2022-09-29 09:35:48 - progress_bar.py[line:274] - INFO: epoch 002:   1152 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=16910, lr=4.09225e-05, gnorm=0.829, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46373
2022-09-29 09:35:59 - progress_bar.py[line:274] - INFO: epoch 002:   1162 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.9, wpb=100.4, bsz=40, num_updates=16920, lr=4.09159e-05, gnorm=0.966, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46384
2022-09-29 09:36:11 - progress_bar.py[line:274] - INFO: epoch 002:   1172 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=16930, lr=4.09093e-05, gnorm=0.763, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=46395
2022-09-29 09:36:22 - progress_bar.py[line:274] - INFO: epoch 002:   1182 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=16940, lr=4.09027e-05, gnorm=0.825, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46406
2022-09-29 09:36:33 - progress_bar.py[line:274] - INFO: epoch 002:   1192 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.3, ups=0.89, wpb=102.5, bsz=40, num_updates=16950, lr=4.08961e-05, gnorm=0.845, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46418
2022-09-29 09:36:44 - progress_bar.py[line:274] - INFO: epoch 002:   1202 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=101.1, bsz=40, num_updates=16960, lr=4.08895e-05, gnorm=0.828, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46429
2022-09-29 09:36:56 - progress_bar.py[line:274] - INFO: epoch 002:   1212 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=16970, lr=4.08829e-05, gnorm=0.777, clip=20, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46440
2022-09-29 09:37:07 - progress_bar.py[line:274] - INFO: epoch 002:   1222 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.91, wpb=101.9, bsz=40, num_updates=16980, lr=4.08763e-05, gnorm=0.869, clip=30, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46451
2022-09-29 09:37:10 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-29 09:37:19 - progress_bar.py[line:274] - INFO: epoch 002:   1233 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=83.5, ups=0.8, wpb=104.3, bsz=40, num_updates=16990, lr=4.08697e-05, gnorm=0.818, clip=10, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=46464
2022-09-29 09:37:30 - progress_bar.py[line:274] - INFO: epoch 002:   1243 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.91, wpb=102.3, bsz=40, num_updates=17000, lr=4.08631e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46475
2022-09-29 09:37:41 - progress_bar.py[line:274] - INFO: epoch 002:   1253 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.2, ups=0.93, wpb=101.8, bsz=40, num_updates=17010, lr=4.08565e-05, gnorm=0.798, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46486
2022-09-29 09:37:52 - progress_bar.py[line:274] - INFO: epoch 002:   1263 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.9, wpb=101.1, bsz=40, num_updates=17020, lr=4.08499e-05, gnorm=0.752, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46497
2022-09-29 09:38:03 - progress_bar.py[line:274] - INFO: epoch 002:   1273 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.88, wpb=101.3, bsz=40, num_updates=17030, lr=4.08433e-05, gnorm=0.765, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46508
2022-09-29 09:38:15 - progress_bar.py[line:274] - INFO: epoch 002:   1283 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.2, ups=0.87, wpb=100.9, bsz=40, num_updates=17040, lr=4.08367e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46520
2022-09-29 09:38:26 - progress_bar.py[line:274] - INFO: epoch 002:   1293 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.91, wpb=99.8, bsz=40, num_updates=17050, lr=4.08301e-05, gnorm=0.924, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46531
2022-09-29 09:38:37 - progress_bar.py[line:274] - INFO: epoch 002:   1303 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.8, ups=0.88, wpb=100.1, bsz=40, num_updates=17060, lr=4.08235e-05, gnorm=0.82, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46542
2022-09-29 09:38:49 - progress_bar.py[line:274] - INFO: epoch 002:   1313 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.88, wpb=102.4, bsz=40, num_updates=17070, lr=4.08169e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46553
2022-09-29 09:39:00 - progress_bar.py[line:274] - INFO: epoch 002:   1323 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=98.2, nsentences=40, sample_size=98.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87, ups=0.89, wpb=98.2, bsz=40, num_updates=17080, lr=4.08103e-05, gnorm=0.842, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=46565
2022-09-29 09:39:11 - progress_bar.py[line:274] - INFO: epoch 002:   1333 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.87, wpb=101.5, bsz=40, num_updates=17090, lr=4.08037e-05, gnorm=0.777, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46576
2022-09-29 09:39:22 - progress_bar.py[line:274] - INFO: epoch 002:   1343 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.9, wpb=101.7, bsz=40, num_updates=17100, lr=4.07971e-05, gnorm=0.887, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46587
2022-09-29 09:39:34 - progress_bar.py[line:274] - INFO: epoch 002:   1353 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.4, ups=0.87, wpb=102.6, bsz=40, num_updates=17110, lr=4.07905e-05, gnorm=0.84, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46599
2022-09-29 09:39:45 - progress_bar.py[line:274] - INFO: epoch 002:   1363 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92, ups=0.89, wpb=103.4, bsz=40, num_updates=17120, lr=4.07839e-05, gnorm=0.729, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46610
2022-09-29 09:39:56 - progress_bar.py[line:274] - INFO: epoch 002:   1373 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.6, ups=0.92, wpb=100.8, bsz=40, num_updates=17130, lr=4.07773e-05, gnorm=0.978, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46621
2022-09-29 09:40:07 - progress_bar.py[line:274] - INFO: epoch 002:   1383 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=17140, lr=4.07707e-05, gnorm=0.883, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46632
2022-09-29 09:40:19 - progress_bar.py[line:274] - INFO: epoch 002:   1393 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.4, ups=0.89, wpb=104, bsz=40, num_updates=17150, lr=4.07641e-05, gnorm=0.752, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46643
2022-09-29 09:40:30 - progress_bar.py[line:274] - INFO: epoch 002:   1403 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.8, ups=0.89, wpb=102.3, bsz=40, num_updates=17160, lr=4.07575e-05, gnorm=0.801, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46655
2022-09-29 09:40:41 - progress_bar.py[line:274] - INFO: epoch 002:   1413 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.89, wpb=102, bsz=40, num_updates=17170, lr=4.07509e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46666
2022-09-29 09:40:52 - progress_bar.py[line:274] - INFO: epoch 002:   1423 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.4, ups=0.9, wpb=100.7, bsz=40, num_updates=17180, lr=4.07443e-05, gnorm=0.795, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46677
2022-09-29 09:41:03 - progress_bar.py[line:274] - INFO: epoch 002:   1433 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.9, wpb=100.4, bsz=40, num_updates=17190, lr=4.07377e-05, gnorm=0.757, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46688
2022-09-29 09:41:15 - progress_bar.py[line:274] - INFO: epoch 002:   1443 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.9, ups=0.88, wpb=99.5, bsz=40, num_updates=17200, lr=4.07311e-05, gnorm=0.713, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46700
2022-09-29 09:41:26 - progress_bar.py[line:274] - INFO: epoch 002:   1453 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.89, wpb=102.3, bsz=40, num_updates=17210, lr=4.07245e-05, gnorm=0.869, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46711
2022-09-29 09:41:37 - progress_bar.py[line:274] - INFO: epoch 002:   1463 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.6, ups=0.87, wpb=100.5, bsz=40, num_updates=17220, lr=4.07179e-05, gnorm=0.893, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46722
2022-09-29 09:41:49 - progress_bar.py[line:274] - INFO: epoch 002:   1473 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.3, ups=0.87, wpb=103, bsz=40, num_updates=17230, lr=4.07113e-05, gnorm=0.747, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46734
2022-09-29 09:42:01 - progress_bar.py[line:274] - INFO: epoch 002:   1483 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.7, ups=0.86, wpb=101.8, bsz=40, num_updates=17240, lr=4.07047e-05, gnorm=0.763, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=46745
2022-09-29 09:42:12 - progress_bar.py[line:274] - INFO: epoch 002:   1493 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=101.1, bsz=40, num_updates=17250, lr=4.06981e-05, gnorm=0.905, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46757
2022-09-29 09:42:23 - progress_bar.py[line:274] - INFO: epoch 002:   1503 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.9, wpb=101.8, bsz=40, num_updates=17260, lr=4.06915e-05, gnorm=0.855, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46768
2022-09-29 09:42:34 - progress_bar.py[line:274] - INFO: epoch 002:   1513 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.3, ups=0.9, wpb=101.8, bsz=40, num_updates=17270, lr=4.06849e-05, gnorm=0.846, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46779
2022-09-29 09:42:45 - progress_bar.py[line:274] - INFO: epoch 002:   1523 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.88, wpb=101.7, bsz=40, num_updates=17280, lr=4.06783e-05, gnorm=0.941, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46790
2022-09-29 09:42:56 - progress_bar.py[line:274] - INFO: epoch 002:   1533 / 15783 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.7, ups=0.91, wpb=100.5, bsz=40, num_updates=17290, lr=4.06717e-05, gnorm=0.822, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46801
2022-09-29 09:43:08 - progress_bar.py[line:274] - INFO: epoch 002:   1543 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.5, ups=0.86, wpb=100.7, bsz=40, num_updates=17300, lr=4.06651e-05, gnorm=0.8, clip=20, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=46813
2022-09-29 09:43:19 - progress_bar.py[line:274] - INFO: epoch 002:   1553 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.5, ups=0.89, wpb=101.9, bsz=40, num_updates=17310, lr=4.06585e-05, gnorm=0.709, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=46824
2022-09-29 09:43:30 - progress_bar.py[line:274] - INFO: epoch 002:   1563 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.91, wpb=101.4, bsz=40, num_updates=17320, lr=4.06519e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46835
2022-09-29 09:43:42 - progress_bar.py[line:274] - INFO: epoch 002:   1573 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.4, ups=0.89, wpb=103.2, bsz=40, num_updates=17330, lr=4.06453e-05, gnorm=0.702, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46847
2022-09-29 09:43:53 - progress_bar.py[line:274] - INFO: epoch 002:   1583 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.8, ups=0.92, wpb=102.2, bsz=40, num_updates=17340, lr=4.06387e-05, gnorm=0.794, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46857
2022-09-29 09:44:04 - progress_bar.py[line:274] - INFO: epoch 002:   1593 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.88, wpb=100.9, bsz=40, num_updates=17350, lr=4.06321e-05, gnorm=0.902, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=46869
2022-09-29 09:44:14 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 09:44:16 - progress_bar.py[line:274] - INFO: epoch 002:   1604 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=82.9, ups=0.81, wpb=102.6, bsz=40, num_updates=17360, lr=4.06255e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=46881
2022-09-29 09:44:28 - progress_bar.py[line:274] - INFO: epoch 002:   1614 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.8, ups=0.88, wpb=100.1, bsz=40, num_updates=17370, lr=4.06189e-05, gnorm=0.863, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46893
2022-09-29 09:44:39 - progress_bar.py[line:274] - INFO: epoch 002:   1624 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.88, wpb=102.7, bsz=40, num_updates=17380, lr=4.06123e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46904
2022-09-29 09:44:50 - progress_bar.py[line:274] - INFO: epoch 002:   1634 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.1, ups=0.91, wpb=101.3, bsz=40, num_updates=17390, lr=4.06057e-05, gnorm=0.764, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=46915
2022-09-29 09:45:02 - progress_bar.py[line:274] - INFO: epoch 002:   1644 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.6, ups=0.87, wpb=101.5, bsz=40, num_updates=17400, lr=4.05991e-05, gnorm=0.71, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=46926
2022-09-29 09:45:13 - progress_bar.py[line:274] - INFO: epoch 002:   1654 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.89, wpb=101.4, bsz=40, num_updates=17410, lr=4.05925e-05, gnorm=0.912, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=46938
2022-09-29 09:45:24 - progress_bar.py[line:274] - INFO: epoch 002:   1664 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.5, ups=0.87, wpb=100.4, bsz=40, num_updates=17420, lr=4.05859e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46949
2022-09-29 09:45:35 - progress_bar.py[line:274] - INFO: epoch 002:   1674 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.9, ups=0.91, wpb=102.3, bsz=40, num_updates=17430, lr=4.05793e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=46960
2022-09-29 09:45:47 - progress_bar.py[line:274] - INFO: epoch 002:   1684 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.3, ups=0.88, wpb=102.2, bsz=40, num_updates=17440, lr=4.05727e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=46972
2022-09-29 09:45:58 - progress_bar.py[line:274] - INFO: epoch 002:   1694 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.5, ups=0.91, wpb=102.9, bsz=40, num_updates=17450, lr=4.05661e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=46983
2022-09-29 09:46:09 - progress_bar.py[line:274] - INFO: epoch 002:   1704 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=17460, lr=4.05595e-05, gnorm=0.852, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=46994
2022-09-29 09:46:21 - progress_bar.py[line:274] - INFO: epoch 002:   1714 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.3, ups=0.86, wpb=102.1, bsz=40, num_updates=17470, lr=4.05529e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=47006
2022-09-29 09:46:32 - progress_bar.py[line:274] - INFO: epoch 002:   1724 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.89, wpb=100.6, bsz=40, num_updates=17480, lr=4.05463e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=47017
2022-09-29 09:46:43 - progress_bar.py[line:274] - INFO: epoch 002:   1734 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.7, ups=0.89, wpb=104.6, bsz=40, num_updates=17490, lr=4.05397e-05, gnorm=0.783, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=47028
2022-09-29 09:46:55 - progress_bar.py[line:274] - INFO: epoch 002:   1744 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.3, ups=0.89, wpb=99.7, bsz=40, num_updates=17500, lr=4.05331e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47040
2022-09-29 09:47:06 - progress_bar.py[line:274] - INFO: epoch 002:   1754 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.89, wpb=102.7, bsz=40, num_updates=17510, lr=4.05265e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47051
2022-09-29 09:47:17 - progress_bar.py[line:274] - INFO: epoch 002:   1764 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.8, ups=0.92, wpb=100.8, bsz=40, num_updates=17520, lr=4.05199e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47062
2022-09-29 09:47:28 - progress_bar.py[line:274] - INFO: epoch 002:   1774 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.1, ups=0.91, wpb=99.4, bsz=40, num_updates=17530, lr=4.05133e-05, gnorm=0.784, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47073
2022-09-29 09:47:39 - progress_bar.py[line:274] - INFO: epoch 002:   1784 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.6, ups=0.88, wpb=101.3, bsz=40, num_updates=17540, lr=4.05067e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=47084
2022-09-29 09:47:51 - progress_bar.py[line:274] - INFO: epoch 002:   1794 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=100.8, bsz=40, num_updates=17550, lr=4.05001e-05, gnorm=0.814, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47095
2022-09-29 09:48:01 - progress_bar.py[line:274] - INFO: epoch 002:   1804 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.6, ups=0.92, wpb=100.2, bsz=40, num_updates=17560, lr=4.04935e-05, gnorm=0.848, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=47106
2022-09-29 09:48:13 - progress_bar.py[line:274] - INFO: epoch 002:   1814 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.88, wpb=101.2, bsz=40, num_updates=17570, lr=4.04869e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47118
2022-09-29 09:48:24 - progress_bar.py[line:274] - INFO: epoch 002:   1824 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.9, wpb=100.9, bsz=40, num_updates=17580, lr=4.04803e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=47129
2022-09-29 09:48:36 - progress_bar.py[line:274] - INFO: epoch 002:   1834 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.6, ups=0.89, wpb=102.3, bsz=40, num_updates=17590, lr=4.04737e-05, gnorm=0.782, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=47140
2022-09-29 09:48:47 - progress_bar.py[line:274] - INFO: epoch 002:   1844 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.6, ups=0.87, wpb=101, bsz=40, num_updates=17600, lr=4.04671e-05, gnorm=0.836, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=47152
2022-09-29 09:48:58 - progress_bar.py[line:274] - INFO: epoch 002:   1854 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=101.8, bsz=40, num_updates=17610, lr=4.04605e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47163
2022-09-29 09:49:09 - progress_bar.py[line:274] - INFO: epoch 002:   1864 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.9, ups=0.93, wpb=101.5, bsz=40, num_updates=17620, lr=4.04539e-05, gnorm=0.773, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=47174
2022-09-29 09:49:20 - progress_bar.py[line:274] - INFO: epoch 002:   1874 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.9, wpb=102, bsz=40, num_updates=17630, lr=4.04473e-05, gnorm=0.797, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47185
2022-09-29 09:49:32 - progress_bar.py[line:274] - INFO: epoch 002:   1884 / 15783 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.89, wpb=98.8, bsz=40, num_updates=17640, lr=4.04407e-05, gnorm=0.904, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47196
2022-09-29 09:49:43 - progress_bar.py[line:274] - INFO: epoch 002:   1894 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89, ups=0.88, wpb=100.7, bsz=40, num_updates=17650, lr=4.04341e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=47208
2022-09-29 09:49:54 - progress_bar.py[line:274] - INFO: epoch 002:   1904 / 15783 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=98.4, nsentences=40, sample_size=98.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86, ups=0.87, wpb=98.4, bsz=40, num_updates=17660, lr=4.04275e-05, gnorm=0.963, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47219
2022-09-29 09:50:05 - progress_bar.py[line:274] - INFO: epoch 002:   1914 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=17670, lr=4.04209e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=47230
2022-09-29 09:50:16 - progress_bar.py[line:274] - INFO: epoch 002:   1924 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.8, ups=0.91, wpb=103.7, bsz=40, num_updates=17680, lr=4.04143e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47241
2022-09-29 09:50:27 - progress_bar.py[line:274] - INFO: epoch 002:   1934 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.91, wpb=101.1, bsz=40, num_updates=17690, lr=4.04077e-05, gnorm=0.778, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47252
2022-09-29 09:50:39 - progress_bar.py[line:274] - INFO: epoch 002:   1944 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.89, wpb=101.3, bsz=40, num_updates=17700, lr=4.04011e-05, gnorm=0.922, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47264
2022-09-29 09:50:50 - progress_bar.py[line:274] - INFO: epoch 002:   1954 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.4, ups=0.89, wpb=99.6, bsz=40, num_updates=17710, lr=4.03945e-05, gnorm=0.905, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47275
2022-09-29 09:51:02 - progress_bar.py[line:274] - INFO: epoch 002:   1964 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.1, ups=0.86, wpb=102.2, bsz=40, num_updates=17720, lr=4.03879e-05, gnorm=0.881, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=47286
2022-09-29 09:51:13 - progress_bar.py[line:274] - INFO: epoch 002:   1974 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.5, ups=0.89, wpb=101.2, bsz=40, num_updates=17730, lr=4.03813e-05, gnorm=0.681, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=47298
2022-09-29 09:51:24 - progress_bar.py[line:274] - INFO: epoch 002:   1984 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.9, wpb=100.4, bsz=40, num_updates=17740, lr=4.03747e-05, gnorm=0.824, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=47309
2022-09-29 09:51:35 - progress_bar.py[line:274] - INFO: epoch 002:   1994 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.9, ups=0.87, wpb=100.7, bsz=40, num_updates=17750, lr=4.03681e-05, gnorm=0.787, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47320
2022-09-29 09:51:47 - progress_bar.py[line:274] - INFO: epoch 002:   2004 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.2, ups=0.88, wpb=100.7, bsz=40, num_updates=17760, lr=4.03615e-05, gnorm=0.734, clip=0, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=47332
2022-09-29 09:51:58 - progress_bar.py[line:274] - INFO: epoch 002:   2014 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.9, wpb=101.9, bsz=40, num_updates=17770, lr=4.03549e-05, gnorm=0.754, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=47343
2022-09-29 09:52:09 - progress_bar.py[line:274] - INFO: epoch 002:   2024 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=17780, lr=4.03483e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=47354
2022-09-29 09:52:21 - progress_bar.py[line:274] - INFO: epoch 002:   2034 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.9, ups=0.88, wpb=100.2, bsz=40, num_updates=17790, lr=4.03417e-05, gnorm=0.837, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47366
2022-09-29 09:52:32 - progress_bar.py[line:274] - INFO: epoch 002:   2044 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=101.6, bsz=40, num_updates=17800, lr=4.03351e-05, gnorm=0.838, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47377
2022-09-29 09:52:43 - progress_bar.py[line:274] - INFO: epoch 002:   2054 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=17810, lr=4.03285e-05, gnorm=0.814, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47388
2022-09-29 09:52:54 - progress_bar.py[line:274] - INFO: epoch 002:   2064 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.89, wpb=100.6, bsz=40, num_updates=17820, lr=4.03219e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=47399
2022-09-29 09:53:06 - progress_bar.py[line:274] - INFO: epoch 002:   2074 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.3, ups=0.88, wpb=100.9, bsz=40, num_updates=17830, lr=4.03153e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47411
2022-09-29 09:53:17 - progress_bar.py[line:274] - INFO: epoch 002:   2084 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.89, wpb=102.7, bsz=40, num_updates=17840, lr=4.03087e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47422
2022-09-29 09:53:28 - progress_bar.py[line:274] - INFO: epoch 002:   2094 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.89, wpb=101.1, bsz=40, num_updates=17850, lr=4.03021e-05, gnorm=0.847, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47433
2022-09-29 09:53:40 - progress_bar.py[line:274] - INFO: epoch 002:   2104 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.3, ups=0.87, wpb=102.2, bsz=40, num_updates=17860, lr=4.02955e-05, gnorm=0.758, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47445
2022-09-29 09:53:51 - progress_bar.py[line:274] - INFO: epoch 002:   2114 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.7, ups=0.88, wpb=101.6, bsz=40, num_updates=17870, lr=4.02889e-05, gnorm=0.747, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47456
2022-09-29 09:54:02 - progress_bar.py[line:274] - INFO: epoch 002:   2124 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.9, wpb=102.7, bsz=40, num_updates=17880, lr=4.02823e-05, gnorm=0.811, clip=30, loss_scale=1024, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=47467
2022-09-29 09:54:14 - progress_bar.py[line:274] - INFO: epoch 002:   2134 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.88, wpb=100.6, bsz=40, num_updates=17890, lr=4.02757e-05, gnorm=0.825, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=47479
2022-09-29 09:54:25 - progress_bar.py[line:274] - INFO: epoch 002:   2144 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.9, wpb=101.7, bsz=40, num_updates=17900, lr=4.02691e-05, gnorm=0.855, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=47490
2022-09-29 09:54:36 - progress_bar.py[line:274] - INFO: epoch 002:   2154 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.89, wpb=100.1, bsz=40, num_updates=17910, lr=4.02625e-05, gnorm=0.891, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=47501
2022-09-29 09:54:47 - progress_bar.py[line:274] - INFO: epoch 002:   2164 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.89, wpb=100.7, bsz=40, num_updates=17920, lr=4.02559e-05, gnorm=0.86, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47512
2022-09-29 09:54:59 - progress_bar.py[line:274] - INFO: epoch 002:   2174 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.89, wpb=102.2, bsz=40, num_updates=17930, lr=4.02493e-05, gnorm=0.962, clip=60, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47524
2022-09-29 09:55:10 - progress_bar.py[line:274] - INFO: epoch 002:   2184 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.89, wpb=100.8, bsz=40, num_updates=17940, lr=4.02427e-05, gnorm=0.875, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47535
2022-09-29 09:55:21 - progress_bar.py[line:274] - INFO: epoch 002:   2194 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.91, wpb=100.2, bsz=40, num_updates=17950, lr=4.02361e-05, gnorm=0.919, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47546
2022-09-29 09:55:32 - progress_bar.py[line:274] - INFO: epoch 002:   2204 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.89, wpb=102.3, bsz=40, num_updates=17960, lr=4.02295e-05, gnorm=0.854, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47557
2022-09-29 09:55:43 - progress_bar.py[line:274] - INFO: epoch 002:   2214 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.8, ups=0.92, wpb=101.2, bsz=40, num_updates=17970, lr=4.02229e-05, gnorm=0.758, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47568
2022-09-29 09:55:54 - progress_bar.py[line:274] - INFO: epoch 002:   2224 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.9, ups=0.91, wpb=101, bsz=40, num_updates=17980, lr=4.02163e-05, gnorm=0.73, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=47579
2022-09-29 09:56:05 - progress_bar.py[line:274] - INFO: epoch 002:   2234 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.6, ups=0.89, wpb=99.9, bsz=40, num_updates=17990, lr=4.02097e-05, gnorm=0.758, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=47590
2022-09-29 09:56:17 - progress_bar.py[line:274] - INFO: epoch 002:   2244 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.7, ups=0.88, wpb=100.2, bsz=40, num_updates=18000, lr=4.02031e-05, gnorm=0.948, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=47602
2022-09-29 09:56:17 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-29 09:56:18 - train.py[line:549] - INFO: 0 / 14103
2022-09-29 09:56:18 - train.py[line:551] - INFO: load:0.79 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-29 09:56:20 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.87 GiB (GPU 0; 39.59 GiB total capacity; 12.96 GiB already allocated; 1.46 GiB free; 35.65 GiB reserved in total by PyTorch)
2022-09-29 09:56:20 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 31        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13276 MB |   18117 MB |    6406 TB |    6406 TB |
|       from large pool |   13131 MB |   17972 MB |    6403 TB |    6403 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13276 MB |   18117 MB |    6406 TB |    6406 TB |
|       from large pool |   13131 MB |   17972 MB |    6403 TB |    6403 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36506 MB |   36618 MB |  370908 MB |  334402 MB |
|       from large pool |   36360 MB |   36360 MB |  370328 MB |  333968 MB |
|       from small pool |     146 MB |     258 MB |     580 MB |     434 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23229 MB |   26273 MB |    6063 TB |    6063 TB |
|       from large pool |   23228 MB |   26271 MB |    6060 TB |    6060 TB |
|       from small pool |       1 MB |       1 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3670    |    3694    |  325391 K  |  325387 K  |
|       from large pool |     564    |     585    |  100755 K  |  100754 K  |
|       from small pool |    3106    |    3114    |  224636 K  |  224633 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3670    |    3694    |  325391 K  |  325387 K  |
|       from large pool |     564    |     585    |  100755 K  |  100754 K  |
|       from small pool |    3106    |    3114    |  224636 K  |  224633 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     128    |     184    |     768    |     640    |
|       from large pool |      55    |      55    |     478    |     423    |
|       from small pool |      73    |     129    |     290    |     217    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      90    |     105    |  237474 K  |  237474 K  |
|       from large pool |      54    |      60    |   49149 K  |   49149 K  |
|       from small pool |      36    |      54    |  188324 K  |  188324 K  |
|===========================================================================|

2022-09-29 09:56:20 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-29 09:56:20 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-29 09:57:44 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.15 GiB (GPU 1; 39.59 GiB total capacity; 13.44 GiB already allocated; 1.56 GiB free; 35.54 GiB reserved in total by PyTorch)
2022-09-29 09:57:44 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-29 09:57:44 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 27        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13766 MB |   18891 MB |    6443 TB |    6443 TB |
|       from large pool |   13621 MB |   18746 MB |    6441 TB |    6441 TB |
|       from small pool |     144 MB |     157 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13766 MB |   18891 MB |    6443 TB |    6443 TB |
|       from large pool |   13621 MB |   18746 MB |    6441 TB |    6441 TB |
|       from small pool |     144 MB |     157 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36394 MB |   37112 MB |  280974 MB |  244580 MB |
|       from large pool |   36248 MB |   36864 MB |  280382 MB |  244134 MB |
|       from small pool |     146 MB |     248 MB |     592 MB |     446 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22627 MB |   27086 MB |    6252 TB |    6252 TB |
|       from large pool |   22626 MB |   27084 MB |    6249 TB |    6249 TB |
|       from small pool |       1 MB |       4 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3671    |    3695    |  326086 K  |  326082 K  |
|       from large pool |     564    |     585    |  100924 K  |  100924 K  |
|       from small pool |    3107    |    3116    |  225161 K  |  225158 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3671    |    3695    |  326086 K  |  326082 K  |
|       from large pool |     564    |     585    |  100924 K  |  100924 K  |
|       from small pool |    3107    |    3116    |  225161 K  |  225158 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     182    |     239    |     737    |     555    |
|       from large pool |     109    |     115    |     441    |     332    |
|       from small pool |      73    |     124    |     296    |     223    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     115    |     131    |  230884 K  |  230884 K  |
|       from large pool |      85    |      89    |   41383 K  |   41383 K  |
|       from small pool |      30    |      46    |  189501 K  |  189501 K  |
|===========================================================================|

2022-09-29 09:57:44 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-29 09:59:34 - train.py[line:549] - INFO: 200 / 14103
2022-09-29 09:59:34 - train.py[line:551] - INFO: load:0.81 valid_run:195.94 task_valid:185.72 collect_output:7.93
2022-09-29 10:02:44 - train.py[line:549] - INFO: 400 / 14103
2022-09-29 10:02:44 - train.py[line:551] - INFO: load:0.85 valid_run:385.51 task_valid:370.26 collect_output:11.76
2022-09-29 10:05:53 - train.py[line:549] - INFO: 600 / 14103
2022-09-29 10:05:53 - train.py[line:551] - INFO: load:0.87 valid_run:575.31 task_valid:553.50 collect_output:17.22
2022-09-29 10:09:04 - train.py[line:549] - INFO: 800 / 14103
2022-09-29 10:09:04 - train.py[line:551] - INFO: load:0.89 valid_run:765.92 task_valid:738.99 collect_output:21.19
2022-09-29 10:12:15 - train.py[line:549] - INFO: 1000 / 14103
2022-09-29 10:12:15 - train.py[line:551] - INFO: load:0.91 valid_run:956.52 task_valid:924.43 collect_output:25.18
2022-09-29 10:15:28 - train.py[line:549] - INFO: 1200 / 14103
2022-09-29 10:15:28 - train.py[line:551] - INFO: load:0.94 valid_run:1149.64 task_valid:1111.03 collect_output:30.60
2022-09-29 10:18:42 - train.py[line:549] - INFO: 1400 / 14103
2022-09-29 10:18:42 - train.py[line:551] - INFO: load:0.96 valid_run:1343.39 task_valid:1299.97 collect_output:34.31
2022-09-29 10:21:55 - train.py[line:549] - INFO: 1600 / 14103
2022-09-29 10:21:55 - train.py[line:551] - INFO: load:0.98 valid_run:1536.59 task_valid:1488.68 collect_output:37.74
2022-09-29 10:25:08 - train.py[line:549] - INFO: 1800 / 14103
2022-09-29 10:25:08 - train.py[line:551] - INFO: load:1.00 valid_run:1729.92 task_valid:1674.24 collect_output:44.42
2022-09-29 10:28:17 - train.py[line:549] - INFO: 2000 / 14103
2022-09-29 10:28:17 - train.py[line:551] - INFO: load:1.03 valid_run:1918.81 task_valid:1859.68 collect_output:46.82
2022-09-29 10:31:27 - train.py[line:549] - INFO: 2200 / 14103
2022-09-29 10:31:27 - train.py[line:551] - INFO: load:1.05 valid_run:2107.97 task_valid:2044.38 collect_output:50.18
2022-09-29 10:34:39 - train.py[line:549] - INFO: 2400 / 14103
2022-09-29 10:34:39 - train.py[line:551] - INFO: load:1.07 valid_run:2300.12 task_valid:2229.05 collect_output:56.57
2022-09-29 10:37:52 - train.py[line:549] - INFO: 2600 / 14103
2022-09-29 10:37:52 - train.py[line:551] - INFO: load:1.09 valid_run:2492.82 task_valid:2417.83 collect_output:59.40
2022-09-29 10:41:02 - train.py[line:549] - INFO: 2800 / 14103
2022-09-29 10:41:02 - train.py[line:551] - INFO: load:1.12 valid_run:2682.97 task_valid:2602.41 collect_output:63.84
2022-09-29 10:44:15 - train.py[line:549] - INFO: 3000 / 14103
2022-09-29 10:44:15 - train.py[line:551] - INFO: load:1.14 valid_run:2876.56 task_valid:2788.43 collect_output:70.35
2022-09-29 10:47:25 - train.py[line:549] - INFO: 3200 / 14103
2022-09-29 10:47:25 - train.py[line:551] - INFO: load:1.16 valid_run:3066.36 task_valid:2970.99 collect_output:76.46
2022-09-29 10:50:39 - train.py[line:549] - INFO: 3400 / 14103
2022-09-29 10:50:39 - train.py[line:551] - INFO: load:1.19 valid_run:3259.89 task_valid:3154.97 collect_output:84.87
2022-09-29 10:53:53 - train.py[line:549] - INFO: 3600 / 14103
2022-09-29 10:53:53 - train.py[line:551] - INFO: load:1.21 valid_run:3454.15 task_valid:3341.56 collect_output:91.33
2022-09-29 10:57:04 - train.py[line:549] - INFO: 3800 / 14103
2022-09-29 10:57:04 - train.py[line:551] - INFO: load:1.23 valid_run:3645.39 task_valid:3524.50 collect_output:98.44
2022-09-29 11:00:14 - train.py[line:549] - INFO: 4000 / 14103
2022-09-29 11:00:14 - train.py[line:551] - INFO: load:1.26 valid_run:3834.68 task_valid:3707.81 collect_output:103.27
2022-09-29 11:03:26 - train.py[line:549] - INFO: 4200 / 14103
2022-09-29 11:03:26 - train.py[line:551] - INFO: load:1.28 valid_run:4026.87 task_valid:3896.80 collect_output:105.33
2022-09-29 11:06:36 - train.py[line:549] - INFO: 4400 / 14103
2022-09-29 11:06:36 - train.py[line:551] - INFO: load:1.30 valid_run:4216.88 task_valid:4078.85 collect_output:112.06
2022-09-29 11:09:49 - train.py[line:549] - INFO: 4600 / 14103
2022-09-29 11:09:49 - train.py[line:551] - INFO: load:1.33 valid_run:4409.97 task_valid:4264.42 collect_output:118.33
2022-09-29 11:12:59 - train.py[line:549] - INFO: 4800 / 14103
2022-09-29 11:12:59 - train.py[line:551] - INFO: load:1.35 valid_run:4599.63 task_valid:4448.46 collect_output:122.83
2022-09-29 11:16:10 - train.py[line:549] - INFO: 5000 / 14103
2022-09-29 11:16:10 - train.py[line:551] - INFO: load:1.37 valid_run:4790.23 task_valid:4633.39 collect_output:127.27
2022-09-29 11:19:20 - train.py[line:549] - INFO: 5200 / 14103
2022-09-29 11:19:20 - train.py[line:551] - INFO: load:1.40 valid_run:4980.15 task_valid:4817.16 collect_output:132.35
2022-09-29 11:22:32 - train.py[line:549] - INFO: 5400 / 14103
2022-09-29 11:22:32 - train.py[line:551] - INFO: load:1.42 valid_run:5172.96 task_valid:5006.14 collect_output:135.11
2022-09-29 11:25:44 - train.py[line:549] - INFO: 5600 / 14103
2022-09-29 11:25:44 - train.py[line:551] - INFO: load:1.44 valid_run:5364.75 task_valid:5193.33 collect_output:138.63
2022-09-29 11:28:58 - train.py[line:549] - INFO: 5800 / 14103
2022-09-29 11:28:58 - train.py[line:551] - INFO: load:1.47 valid_run:5558.37 task_valid:5379.79 collect_output:144.65
2022-09-29 11:32:06 - train.py[line:549] - INFO: 6000 / 14103
2022-09-29 11:32:06 - train.py[line:551] - INFO: load:1.49 valid_run:5746.32 task_valid:5560.74 collect_output:150.58
2022-09-29 11:35:18 - train.py[line:549] - INFO: 6200 / 14103
2022-09-29 11:35:18 - train.py[line:551] - INFO: load:1.51 valid_run:5938.54 task_valid:5746.31 collect_output:156.13
2022-09-29 11:38:28 - train.py[line:549] - INFO: 6400 / 14103
2022-09-29 11:38:28 - train.py[line:551] - INFO: load:1.54 valid_run:6128.55 task_valid:5931.48 collect_output:159.89
2022-09-29 11:41:38 - train.py[line:549] - INFO: 6600 / 14103
2022-09-29 11:41:38 - train.py[line:551] - INFO: load:1.56 valid_run:6317.68 task_valid:6112.37 collect_output:167.08
2022-09-29 11:44:50 - train.py[line:549] - INFO: 6800 / 14103
2022-09-29 11:44:50 - train.py[line:551] - INFO: load:1.58 valid_run:6510.44 task_valid:6296.22 collect_output:174.92
2022-09-29 11:48:03 - train.py[line:549] - INFO: 7000 / 14103
2022-09-29 11:48:03 - train.py[line:551] - INFO: load:1.61 valid_run:6703.08 task_valid:6484.73 collect_output:178.02
2022-09-29 11:51:16 - train.py[line:549] - INFO: 7200 / 14103
2022-09-29 11:51:16 - train.py[line:551] - INFO: load:1.63 valid_run:6895.85 task_valid:6673.93 collect_output:180.52
2022-09-29 11:54:27 - train.py[line:549] - INFO: 7400 / 14103
2022-09-29 11:54:27 - train.py[line:551] - INFO: load:1.65 valid_run:7086.99 task_valid:6855.61 collect_output:188.91
2022-09-29 11:57:37 - train.py[line:549] - INFO: 7600 / 14103
2022-09-29 11:57:37 - train.py[line:551] - INFO: load:1.68 valid_run:7276.37 task_valid:7036.34 collect_output:196.45
2022-09-29 12:00:52 - train.py[line:549] - INFO: 7800 / 14103
2022-09-29 12:00:52 - train.py[line:551] - INFO: load:1.70 valid_run:7471.71 task_valid:7223.77 collect_output:203.24
2022-09-29 12:04:03 - train.py[line:549] - INFO: 8000 / 14103
2022-09-29 12:04:03 - train.py[line:551] - INFO: load:1.72 valid_run:7662.51 task_valid:7403.93 collect_output:212.66
2022-09-29 12:07:13 - train.py[line:549] - INFO: 8200 / 14103
2022-09-29 12:07:13 - train.py[line:551] - INFO: load:1.75 valid_run:7852.70 task_valid:7587.87 collect_output:217.74
2022-09-29 12:10:23 - train.py[line:549] - INFO: 8400 / 14103
2022-09-29 12:10:23 - train.py[line:551] - INFO: load:1.77 valid_run:8042.33 task_valid:7771.21 collect_output:222.82
2022-09-29 12:13:34 - train.py[line:549] - INFO: 8600 / 14103
2022-09-29 12:13:34 - train.py[line:551] - INFO: load:1.80 valid_run:8233.88 task_valid:7956.17 collect_output:228.26
2022-09-29 12:16:44 - train.py[line:549] - INFO: 8800 / 14103
2022-09-29 12:16:44 - train.py[line:551] - INFO: load:1.82 valid_run:8423.37 task_valid:8141.48 collect_output:231.29
2022-09-29 12:19:56 - train.py[line:549] - INFO: 9000 / 14103
2022-09-29 12:19:56 - train.py[line:551] - INFO: load:1.85 valid_run:8615.30 task_valid:8325.68 collect_output:237.87
2022-09-29 12:23:12 - train.py[line:549] - INFO: 9200 / 14103
2022-09-29 12:23:12 - train.py[line:551] - INFO: load:1.87 valid_run:8811.13 task_valid:8509.12 collect_output:249.15
2022-09-29 12:26:26 - train.py[line:549] - INFO: 9400 / 14103
2022-09-29 12:26:26 - train.py[line:551] - INFO: load:1.89 valid_run:9005.12 task_valid:8696.57 collect_output:254.60
2022-09-29 12:29:38 - train.py[line:549] - INFO: 9600 / 14103
2022-09-29 12:29:38 - train.py[line:551] - INFO: load:1.92 valid_run:9197.08 task_valid:8880.83 collect_output:261.23
2022-09-29 12:32:49 - train.py[line:549] - INFO: 9800 / 14103
2022-09-29 12:32:49 - train.py[line:551] - INFO: load:1.94 valid_run:9388.12 task_valid:9068.87 collect_output:263.18
2022-09-29 12:36:00 - train.py[line:549] - INFO: 10000 / 14103
2022-09-29 12:36:00 - train.py[line:551] - INFO: load:1.96 valid_run:9579.61 task_valid:9256.77 collect_output:265.69
2022-09-29 12:39:11 - train.py[line:549] - INFO: 10200 / 14103
2022-09-29 12:39:11 - train.py[line:551] - INFO: load:1.99 valid_run:9770.57 task_valid:9439.93 collect_output:272.40
2022-09-29 12:42:24 - train.py[line:549] - INFO: 10400 / 14103
2022-09-29 12:42:24 - train.py[line:551] - INFO: load:2.01 valid_run:9962.72 task_valid:9623.76 collect_output:279.69
2022-09-29 12:45:37 - train.py[line:549] - INFO: 10600 / 14103
2022-09-29 12:45:37 - train.py[line:551] - INFO: load:2.03 valid_run:10155.78 task_valid:9805.71 collect_output:289.76
2022-09-29 12:48:49 - train.py[line:549] - INFO: 10800 / 14103
2022-09-29 12:48:49 - train.py[line:551] - INFO: load:2.05 valid_run:10348.12 task_valid:9989.57 collect_output:297.16
2022-09-29 12:52:01 - train.py[line:549] - INFO: 11000 / 14103
2022-09-29 12:52:01 - train.py[line:551] - INFO: load:2.08 valid_run:10540.25 task_valid:10174.75 collect_output:303.06
2022-09-29 12:55:13 - train.py[line:549] - INFO: 11200 / 14103
2022-09-29 12:55:13 - train.py[line:551] - INFO: load:2.10 valid_run:10732.21 task_valid:10359.19 collect_output:309.49
2022-09-29 12:58:28 - train.py[line:549] - INFO: 11400 / 14103
2022-09-29 12:58:28 - train.py[line:551] - INFO: load:2.12 valid_run:10926.89 task_valid:10550.17 collect_output:312.08
2022-09-29 13:01:38 - train.py[line:549] - INFO: 11600 / 14103
2022-09-29 13:01:38 - train.py[line:551] - INFO: load:2.15 valid_run:11116.74 task_valid:10734.94 collect_output:316.09
2022-09-29 13:04:50 - train.py[line:549] - INFO: 11800 / 14103
2022-09-29 13:04:50 - train.py[line:551] - INFO: load:2.17 valid_run:11308.41 task_valid:10921.48 collect_output:320.19
2022-09-29 13:08:00 - train.py[line:549] - INFO: 12000 / 14103
2022-09-29 13:08:00 - train.py[line:551] - INFO: load:2.19 valid_run:11498.40 task_valid:11104.89 collect_output:325.70
2022-09-29 13:11:11 - train.py[line:549] - INFO: 12200 / 14103
2022-09-29 13:11:11 - train.py[line:551] - INFO: load:2.22 valid_run:11689.46 task_valid:11290.20 collect_output:330.38
2022-09-29 13:14:23 - train.py[line:549] - INFO: 12400 / 14103
2022-09-29 13:14:23 - train.py[line:551] - INFO: load:2.24 valid_run:11881.62 task_valid:11475.79 collect_output:335.83
2022-09-29 13:17:34 - train.py[line:549] - INFO: 12600 / 14103
2022-09-29 13:17:34 - train.py[line:551] - INFO: load:2.26 valid_run:12072.82 task_valid:11660.04 collect_output:341.64
2022-09-29 13:20:42 - train.py[line:549] - INFO: 12800 / 14103
2022-09-29 13:20:42 - train.py[line:551] - INFO: load:2.29 valid_run:12260.69 task_valid:11842.89 collect_output:345.52
2022-09-29 13:23:54 - train.py[line:549] - INFO: 13000 / 14103
2022-09-29 13:23:54 - train.py[line:551] - INFO: load:2.31 valid_run:12451.85 task_valid:12027.25 collect_output:351.15
2022-09-29 13:27:04 - train.py[line:549] - INFO: 13200 / 14103
2022-09-29 13:27:04 - train.py[line:551] - INFO: load:2.33 valid_run:12642.36 task_valid:12209.37 collect_output:358.38
2022-09-29 13:30:18 - train.py[line:549] - INFO: 13400 / 14103
2022-09-29 13:30:18 - train.py[line:551] - INFO: load:2.36 valid_run:12836.54 task_valid:12392.27 collect_output:368.47
2022-09-29 13:33:30 - train.py[line:549] - INFO: 13600 / 14103
2022-09-29 13:33:30 - train.py[line:551] - INFO: load:2.39 valid_run:13027.91 task_valid:12574.41 collect_output:376.55
2022-09-29 13:36:43 - train.py[line:549] - INFO: 13800 / 14103
2022-09-29 13:36:43 - train.py[line:551] - INFO: load:2.41 valid_run:13220.63 task_valid:12761.39 collect_output:381.15
2022-09-29 13:39:55 - train.py[line:549] - INFO: 14000 / 14103
2022-09-29 13:39:55 - train.py[line:551] - INFO: load:2.43 valid_run:13413.00 task_valid:12946.99 collect_output:386.77
2022-09-29 13:41:31 - train.py[line:572] - INFO: scores:torch.Size([282060]) preds:torch.Size([282060]) sample_ids:torch.Size([282060])

====================================================================================================
SGG eval:     R @ 50: 0.6407;     R @ 100: 0.6612;     R @ 500: 0.6675;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1841;    mR @ 100: 0.2162;    mR @ 500: 0.2226;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1079) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2051) (attached to:0.0000) (behind:0.3900) (belonging to:0.0000) (between:0.0000) (carrying:0.6845) (covered in:0.1667) (covering:0.0000) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0385) (has:0.7792) (holding:0.2791) (in:0.3427) (in front of:0.1141) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.6013) (of:0.4642) (on:0.8869) (on back of:0.0000) (over:0.1111) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6667) (says:0.0000) (sitting on:0.3552) (standing on:0.0385) (to:0.0000) (under:0.3333) (using:1.0000) (walking in:0.0000) (walking on:0.5610) (watching:0.3333) (wearing:0.9869) (wears:0.0000) (with:0.1134) 
--------------------------------------------------------
====================================================================================================

2022-09-29 13:41:52 - train.py[line:486] - INFO: 0.6612345409615153
2022-09-29 13:41:52 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.326 | loss_v1 0 | loss_v2 0 | nll_loss 0.134 | ntokens 59.526 | nsentences 20 | sample_size 59.526 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.661235 | ppl 1.1 | vqa_score 0.8863 | wps 62 | wpb 59.5 | bsz 20 | num_updates 18000 | best_R@100 0.661235
2022-09-29 13:41:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 18000 updates
2022-09-29 13:41:52 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_2_18000.pt

====================================================================================================
SGG eval:     R @ 50: 0.6407;     R @ 100: 0.6612;     R @ 500: 0.6675;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1841;    mR @ 100: 0.2162;    mR @ 500: 0.2226;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1079) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2051) (attached to:0.0000) (behind:0.3900) (belonging to:0.0000) (between:0.0000) (carrying:0.6845) (covered in:0.1667) (covering:0.0000) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0385) (has:0.7792) (holding:0.2791) (in:0.3427) (in front of:0.1141) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.6013) (of:0.4642) (on:0.8869) (on back of:0.0000) (over:0.1111) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6667) (says:0.0000) (sitting on:0.3552) (standing on:0.0385) (to:0.0000) (under:0.3333) (using:1.0000) (walking in:0.0000) (walking on:0.5610) (watching:0.3333) (wearing:0.9869) (wears:0.0000) (with:0.1134) 
--------------------------------------------------------
====================================================================================================

2022-09-29 13:41:58 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_2_18000.pt
2022-09-29 13:42:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_2_18000.pt (epoch 2 @ 18000 updates, score 0.6612345409615153) (writing took 10.966596998041496 seconds)
2022-09-29 13:42:15 - progress_bar.py[line:274] - INFO: epoch 002:   2254 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=0.1, ups=0, wpb=100.5, bsz=40, num_updates=18010, lr=4.01965e-05, gnorm=0.828, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=61159
2022-09-29 13:42:26 - progress_bar.py[line:274] - INFO: epoch 002:   2264 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.3, ups=0.88, wpb=101.7, bsz=40, num_updates=18020, lr=4.01899e-05, gnorm=0.729, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61171
2022-09-29 13:42:38 - progress_bar.py[line:274] - INFO: epoch 002:   2274 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.7, ups=0.89, wpb=100.8, bsz=40, num_updates=18030, lr=4.01833e-05, gnorm=0.754, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61183
2022-09-29 13:42:49 - progress_bar.py[line:274] - INFO: epoch 002:   2284 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.89, wpb=99.9, bsz=40, num_updates=18040, lr=4.01767e-05, gnorm=0.807, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61194
2022-09-29 13:43:00 - progress_bar.py[line:274] - INFO: epoch 002:   2294 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.89, wpb=102.4, bsz=40, num_updates=18050, lr=4.01701e-05, gnorm=0.716, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61205
2022-09-29 13:43:11 - progress_bar.py[line:274] - INFO: epoch 002:   2304 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.7, ups=0.92, wpb=98.8, bsz=40, num_updates=18060, lr=4.01635e-05, gnorm=0.833, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61216
2022-09-29 13:43:22 - progress_bar.py[line:274] - INFO: epoch 002:   2314 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.1, ups=0.89, wpb=100.1, bsz=40, num_updates=18070, lr=4.01569e-05, gnorm=0.729, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61227
2022-09-29 13:43:34 - progress_bar.py[line:274] - INFO: epoch 002:   2324 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=18080, lr=4.01503e-05, gnorm=0.791, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=61239
2022-09-29 13:43:45 - progress_bar.py[line:274] - INFO: epoch 002:   2334 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.88, wpb=101.8, bsz=40, num_updates=18090, lr=4.01437e-05, gnorm=0.836, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61250
2022-09-29 13:43:56 - progress_bar.py[line:274] - INFO: epoch 002:   2344 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=18100, lr=4.01371e-05, gnorm=0.841, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61261
2022-09-29 13:44:08 - progress_bar.py[line:274] - INFO: epoch 002:   2354 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.4, ups=0.89, wpb=100.3, bsz=40, num_updates=18110, lr=4.01305e-05, gnorm=0.82, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61272
2022-09-29 13:44:19 - progress_bar.py[line:274] - INFO: epoch 002:   2364 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.89, wpb=100.3, bsz=40, num_updates=18120, lr=4.01239e-05, gnorm=0.822, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61284
2022-09-29 13:44:30 - progress_bar.py[line:274] - INFO: epoch 002:   2374 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.91, wpb=101.8, bsz=40, num_updates=18130, lr=4.01173e-05, gnorm=0.754, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61295
2022-09-29 13:44:41 - progress_bar.py[line:274] - INFO: epoch 002:   2384 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.9, wpb=101, bsz=40, num_updates=18140, lr=4.01107e-05, gnorm=0.747, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61306
2022-09-29 13:44:52 - progress_bar.py[line:274] - INFO: epoch 002:   2394 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.7, ups=0.88, wpb=100.4, bsz=40, num_updates=18150, lr=4.01041e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61317
2022-09-29 13:45:04 - progress_bar.py[line:274] - INFO: epoch 002:   2404 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.89, wpb=101.5, bsz=40, num_updates=18160, lr=4.00975e-05, gnorm=0.721, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61328
2022-09-29 13:45:15 - progress_bar.py[line:274] - INFO: epoch 002:   2414 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.9, wpb=100, bsz=40, num_updates=18170, lr=4.00909e-05, gnorm=0.724, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61339
2022-09-29 13:45:26 - progress_bar.py[line:274] - INFO: epoch 002:   2424 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.2, ups=0.91, wpb=102.7, bsz=40, num_updates=18180, lr=4.00843e-05, gnorm=0.677, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61350
2022-09-29 13:45:37 - progress_bar.py[line:274] - INFO: epoch 002:   2434 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.5, ups=0.89, wpb=99.3, bsz=40, num_updates=18190, lr=4.00777e-05, gnorm=0.738, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61362
2022-09-29 13:45:48 - progress_bar.py[line:274] - INFO: epoch 002:   2444 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.1, ups=0.89, wpb=103.6, bsz=40, num_updates=18200, lr=4.00711e-05, gnorm=0.702, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61373
2022-09-29 13:45:59 - progress_bar.py[line:274] - INFO: epoch 002:   2454 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.9, wpb=99.6, bsz=40, num_updates=18210, lr=4.00645e-05, gnorm=0.814, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61384
2022-09-29 13:46:10 - progress_bar.py[line:274] - INFO: epoch 002:   2464 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.91, wpb=100.4, bsz=40, num_updates=18220, lr=4.00579e-05, gnorm=0.707, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61395
2022-09-29 13:46:21 - progress_bar.py[line:274] - INFO: epoch 002:   2474 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.91, wpb=100.9, bsz=40, num_updates=18230, lr=4.00513e-05, gnorm=0.822, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61406
2022-09-29 13:46:32 - progress_bar.py[line:274] - INFO: epoch 002:   2484 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.91, wpb=102, bsz=40, num_updates=18240, lr=4.00447e-05, gnorm=0.917, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61417
2022-09-29 13:46:44 - progress_bar.py[line:274] - INFO: epoch 002:   2494 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.1, ups=0.88, wpb=101.3, bsz=40, num_updates=18250, lr=4.00381e-05, gnorm=0.879, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61428
2022-09-29 13:46:54 - progress_bar.py[line:274] - INFO: epoch 002:   2504 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.9, ups=0.94, wpb=101.1, bsz=40, num_updates=18260, lr=4.00315e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61439
2022-09-29 13:47:06 - progress_bar.py[line:274] - INFO: epoch 002:   2514 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=18270, lr=4.00249e-05, gnorm=0.807, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61450
2022-09-29 13:47:17 - progress_bar.py[line:274] - INFO: epoch 002:   2524 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.9, wpb=101.5, bsz=40, num_updates=18280, lr=4.00183e-05, gnorm=0.753, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61461
2022-09-29 13:47:28 - progress_bar.py[line:274] - INFO: epoch 002:   2534 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.3, ups=0.9, wpb=102.4, bsz=40, num_updates=18290, lr=4.00117e-05, gnorm=0.834, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61473
2022-09-29 13:47:39 - progress_bar.py[line:274] - INFO: epoch 002:   2544 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.8, ups=0.9, wpb=102.4, bsz=40, num_updates=18300, lr=4.00051e-05, gnorm=0.773, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61484
2022-09-29 13:47:50 - progress_bar.py[line:274] - INFO: epoch 002:   2554 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.8, ups=0.88, wpb=101.3, bsz=40, num_updates=18310, lr=3.99985e-05, gnorm=0.671, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61495
2022-09-29 13:48:01 - progress_bar.py[line:274] - INFO: epoch 002:   2564 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.6, ups=0.93, wpb=102.1, bsz=40, num_updates=18320, lr=3.99919e-05, gnorm=0.845, clip=10, loss_scale=1024, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=61506
2022-09-29 13:48:12 - progress_bar.py[line:274] - INFO: epoch 002:   2574 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.9, wpb=101, bsz=40, num_updates=18330, lr=3.99853e-05, gnorm=0.884, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61517
2022-09-29 13:48:23 - progress_bar.py[line:274] - INFO: epoch 002:   2584 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.6, ups=0.92, wpb=102.1, bsz=40, num_updates=18340, lr=3.99787e-05, gnorm=0.79, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61528
2022-09-29 13:48:35 - progress_bar.py[line:274] - INFO: epoch 002:   2594 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.2, ups=0.88, wpb=101.7, bsz=40, num_updates=18350, lr=3.99721e-05, gnorm=0.785, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61539
2022-09-29 13:48:46 - progress_bar.py[line:274] - INFO: epoch 002:   2604 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=18360, lr=3.99655e-05, gnorm=0.795, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61551
2022-09-29 13:48:57 - progress_bar.py[line:274] - INFO: epoch 002:   2614 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.88, wpb=103.4, bsz=40, num_updates=18370, lr=3.99589e-05, gnorm=0.771, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61562
2022-09-29 13:49:08 - progress_bar.py[line:274] - INFO: epoch 002:   2624 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.6, ups=0.9, wpb=101.6, bsz=40, num_updates=18380, lr=3.99523e-05, gnorm=0.718, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61573
2022-09-29 13:49:19 - progress_bar.py[line:274] - INFO: epoch 002:   2634 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.88, wpb=102.3, bsz=40, num_updates=18390, lr=3.99457e-05, gnorm=0.71, clip=10, loss_scale=2048, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61584
2022-09-29 13:49:26 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-29 13:49:32 - progress_bar.py[line:274] - INFO: epoch 002:   2645 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=80.6, ups=0.8, wpb=100.3, bsz=40, num_updates=18400, lr=3.99391e-05, gnorm=0.743, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=61597
2022-09-29 13:49:43 - progress_bar.py[line:274] - INFO: epoch 002:   2655 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.9, wpb=100.4, bsz=40, num_updates=18410, lr=3.99325e-05, gnorm=0.81, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61608
2022-09-29 13:49:54 - progress_bar.py[line:274] - INFO: epoch 002:   2665 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.89, wpb=102, bsz=40, num_updates=18420, lr=3.99259e-05, gnorm=0.743, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61619
2022-09-29 13:50:06 - progress_bar.py[line:274] - INFO: epoch 002:   2675 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.89, wpb=102.2, bsz=40, num_updates=18430, lr=3.99193e-05, gnorm=0.765, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61630
2022-09-29 13:50:17 - progress_bar.py[line:274] - INFO: epoch 002:   2685 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.2, ups=0.91, wpb=102.3, bsz=40, num_updates=18440, lr=3.99127e-05, gnorm=0.754, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61641
2022-09-29 13:50:28 - progress_bar.py[line:274] - INFO: epoch 002:   2695 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.5, ups=0.87, wpb=101.3, bsz=40, num_updates=18450, lr=3.99061e-05, gnorm=0.788, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61653
2022-09-29 13:50:39 - progress_bar.py[line:274] - INFO: epoch 002:   2705 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.88, wpb=102.7, bsz=40, num_updates=18460, lr=3.98995e-05, gnorm=0.974, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61664
2022-09-29 13:50:51 - progress_bar.py[line:274] - INFO: epoch 002:   2715 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.6, ups=0.86, wpb=101.3, bsz=40, num_updates=18470, lr=3.9893e-05, gnorm=0.773, clip=10, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=61676
2022-09-29 13:51:03 - progress_bar.py[line:274] - INFO: epoch 002:   2725 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.89, wpb=100.6, bsz=40, num_updates=18480, lr=3.98864e-05, gnorm=0.825, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61687
2022-09-29 13:51:14 - progress_bar.py[line:274] - INFO: epoch 002:   2735 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.2, ups=0.9, wpb=102.3, bsz=40, num_updates=18490, lr=3.98798e-05, gnorm=0.786, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61699
2022-09-29 13:51:25 - progress_bar.py[line:274] - INFO: epoch 002:   2745 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.8, ups=0.92, wpb=101.5, bsz=40, num_updates=18500, lr=3.98732e-05, gnorm=0.914, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61709
2022-09-29 13:51:36 - progress_bar.py[line:274] - INFO: epoch 002:   2755 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.91, wpb=102, bsz=40, num_updates=18510, lr=3.98666e-05, gnorm=0.751, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61720
2022-09-29 13:51:47 - progress_bar.py[line:274] - INFO: epoch 002:   2765 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.8, ups=0.9, wpb=103.7, bsz=40, num_updates=18520, lr=3.986e-05, gnorm=0.901, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61732
2022-09-29 13:51:58 - progress_bar.py[line:274] - INFO: epoch 002:   2775 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.5, ups=0.88, wpb=100.9, bsz=40, num_updates=18530, lr=3.98534e-05, gnorm=0.834, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61743
2022-09-29 13:52:09 - progress_bar.py[line:274] - INFO: epoch 002:   2785 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.89, wpb=102, bsz=40, num_updates=18540, lr=3.98468e-05, gnorm=0.827, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61754
2022-09-29 13:52:21 - progress_bar.py[line:274] - INFO: epoch 002:   2795 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.88, wpb=102.6, bsz=40, num_updates=18550, lr=3.98402e-05, gnorm=0.843, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=61766
2022-09-29 13:52:32 - progress_bar.py[line:274] - INFO: epoch 002:   2805 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.2, ups=0.92, wpb=100.7, bsz=40, num_updates=18560, lr=3.98336e-05, gnorm=0.903, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61776
2022-09-29 13:52:43 - progress_bar.py[line:274] - INFO: epoch 002:   2815 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.4, ups=0.88, wpb=101.9, bsz=40, num_updates=18570, lr=3.9827e-05, gnorm=0.733, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61788
2022-09-29 13:52:54 - progress_bar.py[line:274] - INFO: epoch 002:   2825 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.9, ups=0.89, wpb=100.9, bsz=40, num_updates=18580, lr=3.98204e-05, gnorm=0.763, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=61799
2022-09-29 13:53:05 - progress_bar.py[line:274] - INFO: epoch 002:   2835 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92, ups=0.91, wpb=101.1, bsz=40, num_updates=18590, lr=3.98138e-05, gnorm=0.698, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61810
2022-09-29 13:53:17 - progress_bar.py[line:274] - INFO: epoch 002:   2845 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.9, ups=0.86, wpb=100.6, bsz=40, num_updates=18600, lr=3.98072e-05, gnorm=0.832, clip=0, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=61822
2022-09-29 13:53:28 - progress_bar.py[line:274] - INFO: epoch 002:   2855 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.6, ups=0.92, wpb=101.2, bsz=40, num_updates=18610, lr=3.98006e-05, gnorm=0.778, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=61833
2022-09-29 13:53:39 - progress_bar.py[line:274] - INFO: epoch 002:   2865 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.7, ups=0.86, wpb=101.6, bsz=40, num_updates=18620, lr=3.9794e-05, gnorm=0.862, clip=30, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=61844
2022-09-29 13:53:51 - progress_bar.py[line:274] - INFO: epoch 002:   2875 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.2, ups=0.88, wpb=103, bsz=40, num_updates=18630, lr=3.97874e-05, gnorm=0.772, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61856
2022-09-29 13:54:02 - progress_bar.py[line:274] - INFO: epoch 002:   2885 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.1, ups=0.87, wpb=99.6, bsz=40, num_updates=18640, lr=3.97808e-05, gnorm=0.858, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61867
2022-09-29 13:54:13 - progress_bar.py[line:274] - INFO: epoch 002:   2895 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=101, bsz=40, num_updates=18650, lr=3.97742e-05, gnorm=0.802, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61878
2022-09-29 13:54:25 - progress_bar.py[line:274] - INFO: epoch 002:   2905 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.1, ups=0.87, wpb=100.9, bsz=40, num_updates=18660, lr=3.97676e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61890
2022-09-29 13:54:36 - progress_bar.py[line:274] - INFO: epoch 002:   2915 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.4, ups=0.88, wpb=100.2, bsz=40, num_updates=18670, lr=3.9761e-05, gnorm=0.901, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61901
2022-09-29 13:54:48 - progress_bar.py[line:274] - INFO: epoch 002:   2925 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.88, wpb=102.9, bsz=40, num_updates=18680, lr=3.97544e-05, gnorm=0.76, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=61913
2022-09-29 13:54:59 - progress_bar.py[line:274] - INFO: epoch 002:   2935 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.3, ups=0.87, wpb=101.1, bsz=40, num_updates=18690, lr=3.97478e-05, gnorm=0.875, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=61924
2022-09-29 13:55:10 - progress_bar.py[line:274] - INFO: epoch 002:   2945 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.89, wpb=101.4, bsz=40, num_updates=18700, lr=3.97412e-05, gnorm=0.899, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=61935
2022-09-29 13:55:22 - progress_bar.py[line:274] - INFO: epoch 002:   2955 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.88, wpb=101.5, bsz=40, num_updates=18710, lr=3.97346e-05, gnorm=0.813, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61947
2022-09-29 13:55:33 - progress_bar.py[line:274] - INFO: epoch 002:   2965 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.89, wpb=100.7, bsz=40, num_updates=18720, lr=3.9728e-05, gnorm=0.964, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=61958
2022-09-29 13:55:44 - progress_bar.py[line:274] - INFO: epoch 002:   2975 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.89, wpb=101.1, bsz=40, num_updates=18730, lr=3.97214e-05, gnorm=0.817, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61969
2022-09-29 13:55:56 - progress_bar.py[line:274] - INFO: epoch 002:   2985 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.88, wpb=102.8, bsz=40, num_updates=18740, lr=3.97148e-05, gnorm=0.795, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=61981
2022-09-29 13:56:07 - progress_bar.py[line:274] - INFO: epoch 002:   2995 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.5, ups=0.89, wpb=101.6, bsz=40, num_updates=18750, lr=3.97082e-05, gnorm=0.693, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=61992
2022-09-29 13:56:18 - progress_bar.py[line:274] - INFO: epoch 002:   3005 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.6, ups=0.92, wpb=102.8, bsz=40, num_updates=18760, lr=3.97016e-05, gnorm=0.786, clip=20, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=62003
2022-09-29 13:56:29 - progress_bar.py[line:274] - INFO: epoch 002:   3015 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.89, wpb=102, bsz=40, num_updates=18770, lr=3.9695e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62014
2022-09-29 13:56:40 - progress_bar.py[line:274] - INFO: epoch 002:   3025 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.5, ups=0.94, wpb=103.5, bsz=40, num_updates=18780, lr=3.96884e-05, gnorm=0.764, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=62025
2022-09-29 13:56:51 - progress_bar.py[line:274] - INFO: epoch 002:   3035 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.4, ups=0.91, wpb=101.2, bsz=40, num_updates=18790, lr=3.96818e-05, gnorm=0.897, clip=30, loss_scale=1024, train_wall=11, gb_free=9.3, ema_decay=0.9999, wall=62036
2022-09-29 13:57:02 - progress_bar.py[line:274] - INFO: epoch 002:   3045 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.88, wpb=100, bsz=40, num_updates=18800, lr=3.96752e-05, gnorm=0.809, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62047
2022-09-29 13:57:13 - progress_bar.py[line:274] - INFO: epoch 002:   3055 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.7, ups=0.88, wpb=102.3, bsz=40, num_updates=18810, lr=3.96686e-05, gnorm=0.718, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62058
2022-09-29 13:57:25 - progress_bar.py[line:274] - INFO: epoch 002:   3065 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.1, ups=0.89, wpb=99, bsz=40, num_updates=18820, lr=3.9662e-05, gnorm=0.901, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62070
2022-09-29 13:57:36 - progress_bar.py[line:274] - INFO: epoch 002:   3075 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.91, wpb=101.1, bsz=40, num_updates=18830, lr=3.96554e-05, gnorm=0.829, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=62081
2022-09-29 13:57:46 - progress_bar.py[line:274] - INFO: epoch 002:   3085 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.8, ups=0.93, wpb=101.8, bsz=40, num_updates=18840, lr=3.96488e-05, gnorm=0.836, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62091
2022-09-29 13:57:58 - progress_bar.py[line:274] - INFO: epoch 002:   3095 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.88, wpb=102.2, bsz=40, num_updates=18850, lr=3.96422e-05, gnorm=0.863, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62103
2022-09-29 13:58:09 - progress_bar.py[line:274] - INFO: epoch 002:   3105 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=18860, lr=3.96356e-05, gnorm=0.928, clip=30, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=62114
2022-09-29 13:58:20 - progress_bar.py[line:274] - INFO: epoch 002:   3115 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.6, ups=0.91, wpb=101.7, bsz=40, num_updates=18870, lr=3.9629e-05, gnorm=0.8, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62125
2022-09-29 13:58:31 - progress_bar.py[line:274] - INFO: epoch 002:   3125 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.91, wpb=100.5, bsz=40, num_updates=18880, lr=3.96224e-05, gnorm=0.807, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62136
2022-09-29 13:58:42 - progress_bar.py[line:274] - INFO: epoch 002:   3135 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.8, ups=0.89, wpb=99.8, bsz=40, num_updates=18890, lr=3.96158e-05, gnorm=0.895, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62147
2022-09-29 13:58:53 - progress_bar.py[line:274] - INFO: epoch 002:   3145 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.1, ups=0.9, wpb=102.3, bsz=40, num_updates=18900, lr=3.96092e-05, gnorm=0.811, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62158
2022-09-29 13:59:05 - progress_bar.py[line:274] - INFO: epoch 002:   3155 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.88, wpb=101.7, bsz=40, num_updates=18910, lr=3.96026e-05, gnorm=0.898, clip=30, loss_scale=2048, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=62169
2022-09-29 13:59:16 - progress_bar.py[line:274] - INFO: epoch 002:   3165 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.9, ups=0.9, wpb=103.2, bsz=40, num_updates=18920, lr=3.9596e-05, gnorm=0.912, clip=40, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62181
2022-09-29 13:59:18 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-29 13:59:28 - progress_bar.py[line:274] - INFO: epoch 002:   3176 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=83.3, ups=0.83, wpb=100.6, bsz=40, num_updates=18930, lr=3.95894e-05, gnorm=0.872, clip=20, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=62193
2022-09-29 13:59:40 - progress_bar.py[line:274] - INFO: epoch 002:   3186 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.87, wpb=101.3, bsz=40, num_updates=18940, lr=3.95828e-05, gnorm=0.775, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62205
2022-09-29 13:59:51 - progress_bar.py[line:274] - INFO: epoch 002:   3196 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.9, ups=0.91, wpb=102, bsz=40, num_updates=18950, lr=3.95762e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62216
2022-09-29 14:00:02 - progress_bar.py[line:274] - INFO: epoch 002:   3206 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.6, ups=0.92, wpb=100.4, bsz=40, num_updates=18960, lr=3.95696e-05, gnorm=0.782, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62226
2022-09-29 14:00:13 - progress_bar.py[line:274] - INFO: epoch 002:   3216 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.91, wpb=101.9, bsz=40, num_updates=18970, lr=3.9563e-05, gnorm=0.813, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62237
2022-09-29 14:00:24 - progress_bar.py[line:274] - INFO: epoch 002:   3226 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.2, ups=0.89, wpb=100.5, bsz=40, num_updates=18980, lr=3.95564e-05, gnorm=0.899, clip=40, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=62249
2022-09-29 14:00:35 - progress_bar.py[line:274] - INFO: epoch 002:   3236 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.6, ups=0.89, wpb=101.7, bsz=40, num_updates=18990, lr=3.95498e-05, gnorm=0.883, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62260
2022-09-29 14:00:46 - progress_bar.py[line:274] - INFO: epoch 002:   3246 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.9, wpb=100.7, bsz=40, num_updates=19000, lr=3.95432e-05, gnorm=0.734, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62271
2022-09-29 14:00:57 - progress_bar.py[line:274] - INFO: epoch 002:   3256 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.9, wpb=101.2, bsz=40, num_updates=19010, lr=3.95366e-05, gnorm=0.778, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=62282
2022-09-29 14:01:08 - progress_bar.py[line:274] - INFO: epoch 002:   3266 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.3, ups=0.94, wpb=101, bsz=40, num_updates=19020, lr=3.953e-05, gnorm=0.743, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62293
2022-09-29 14:01:19 - progress_bar.py[line:274] - INFO: epoch 002:   3276 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.91, wpb=99, bsz=40, num_updates=19030, lr=3.95234e-05, gnorm=0.742, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62304
2022-09-29 14:01:31 - progress_bar.py[line:274] - INFO: epoch 002:   3286 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.5, ups=0.88, wpb=101.1, bsz=40, num_updates=19040, lr=3.95168e-05, gnorm=0.709, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62315
2022-09-29 14:01:42 - progress_bar.py[line:274] - INFO: epoch 002:   3296 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.6, ups=0.9, wpb=102, bsz=40, num_updates=19050, lr=3.95102e-05, gnorm=0.812, clip=30, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62327
2022-09-29 14:01:53 - progress_bar.py[line:274] - INFO: epoch 002:   3306 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.8, ups=0.9, wpb=102.4, bsz=40, num_updates=19060, lr=3.95036e-05, gnorm=0.712, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62338
2022-09-29 14:02:04 - progress_bar.py[line:274] - INFO: epoch 002:   3316 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.8, ups=0.94, wpb=101.4, bsz=40, num_updates=19070, lr=3.9497e-05, gnorm=0.784, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62348
2022-09-29 14:02:15 - progress_bar.py[line:274] - INFO: epoch 002:   3326 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=19080, lr=3.94904e-05, gnorm=0.815, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62360
2022-09-29 14:02:26 - progress_bar.py[line:274] - INFO: epoch 002:   3336 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.5, ups=0.89, wpb=102.8, bsz=40, num_updates=19090, lr=3.94838e-05, gnorm=0.902, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62371
2022-09-29 14:02:37 - progress_bar.py[line:274] - INFO: epoch 002:   3346 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.9, wpb=100.4, bsz=40, num_updates=19100, lr=3.94772e-05, gnorm=0.852, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62382
2022-09-29 14:02:48 - progress_bar.py[line:274] - INFO: epoch 002:   3356 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.92, wpb=101, bsz=40, num_updates=19110, lr=3.94706e-05, gnorm=0.854, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62393
2022-09-29 14:02:59 - progress_bar.py[line:274] - INFO: epoch 002:   3366 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.88, wpb=102.4, bsz=40, num_updates=19120, lr=3.9464e-05, gnorm=0.772, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62404
2022-09-29 14:03:10 - progress_bar.py[line:274] - INFO: epoch 002:   3376 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.9, wpb=99.9, bsz=40, num_updates=19130, lr=3.94574e-05, gnorm=0.938, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62415
2022-09-29 14:03:22 - progress_bar.py[line:274] - INFO: epoch 002:   3386 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.9, ups=0.9, wpb=101.8, bsz=40, num_updates=19140, lr=3.94508e-05, gnorm=0.775, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62426
2022-09-29 14:03:33 - progress_bar.py[line:274] - INFO: epoch 002:   3396 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.89, wpb=100.8, bsz=40, num_updates=19150, lr=3.94442e-05, gnorm=0.754, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62438
2022-09-29 14:03:44 - progress_bar.py[line:274] - INFO: epoch 002:   3406 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.9, wpb=100.3, bsz=40, num_updates=19160, lr=3.94376e-05, gnorm=0.77, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62449
2022-09-29 14:03:55 - progress_bar.py[line:274] - INFO: epoch 002:   3416 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.1, ups=0.88, wpb=99.6, bsz=40, num_updates=19170, lr=3.9431e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62460
2022-09-29 14:04:06 - progress_bar.py[line:274] - INFO: epoch 002:   3426 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.9, wpb=101.8, bsz=40, num_updates=19180, lr=3.94244e-05, gnorm=0.837, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=62471
2022-09-29 14:04:18 - progress_bar.py[line:274] - INFO: epoch 002:   3436 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=19190, lr=3.94178e-05, gnorm=0.809, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62482
2022-09-29 14:04:29 - progress_bar.py[line:274] - INFO: epoch 002:   3446 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.9, ups=0.9, wpb=101, bsz=40, num_updates=19200, lr=3.94112e-05, gnorm=0.919, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62494
2022-09-29 14:04:40 - progress_bar.py[line:274] - INFO: epoch 002:   3456 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.8, ups=0.87, wpb=100.3, bsz=40, num_updates=19210, lr=3.94046e-05, gnorm=0.792, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=62505
2022-09-29 14:04:51 - progress_bar.py[line:274] - INFO: epoch 002:   3466 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.1, ups=0.91, wpb=101.5, bsz=40, num_updates=19220, lr=3.9398e-05, gnorm=0.713, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62516
2022-09-29 14:05:02 - progress_bar.py[line:274] - INFO: epoch 002:   3476 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.89, wpb=102.6, bsz=40, num_updates=19230, lr=3.93914e-05, gnorm=0.752, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62527
2022-09-29 14:05:14 - progress_bar.py[line:274] - INFO: epoch 002:   3486 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.89, wpb=101.1, bsz=40, num_updates=19240, lr=3.93848e-05, gnorm=0.716, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62538
2022-09-29 14:05:25 - progress_bar.py[line:274] - INFO: epoch 002:   3496 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=19250, lr=3.93782e-05, gnorm=0.759, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62550
2022-09-29 14:05:36 - progress_bar.py[line:274] - INFO: epoch 002:   3506 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.4, ups=0.93, wpb=101.6, bsz=40, num_updates=19260, lr=3.93716e-05, gnorm=0.707, clip=10, loss_scale=1024, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=62560
2022-09-29 14:05:47 - progress_bar.py[line:274] - INFO: epoch 002:   3516 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.88, wpb=102.2, bsz=40, num_updates=19270, lr=3.9365e-05, gnorm=0.772, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62572
2022-09-29 14:05:58 - progress_bar.py[line:274] - INFO: epoch 002:   3526 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94, ups=0.93, wpb=101.4, bsz=40, num_updates=19280, lr=3.93584e-05, gnorm=0.822, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62583
2022-09-29 14:06:09 - progress_bar.py[line:274] - INFO: epoch 002:   3536 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=19290, lr=3.93518e-05, gnorm=0.826, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62594
2022-09-29 14:06:20 - progress_bar.py[line:274] - INFO: epoch 002:   3546 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.89, wpb=101.2, bsz=40, num_updates=19300, lr=3.93452e-05, gnorm=0.861, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62605
2022-09-29 14:06:31 - progress_bar.py[line:274] - INFO: epoch 002:   3556 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.5, ups=0.9, wpb=102.5, bsz=40, num_updates=19310, lr=3.93386e-05, gnorm=0.78, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=62616
2022-09-29 14:06:42 - progress_bar.py[line:274] - INFO: epoch 002:   3566 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.9, wpb=99.3, bsz=40, num_updates=19320, lr=3.9332e-05, gnorm=0.847, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62627
2022-09-29 14:06:54 - progress_bar.py[line:274] - INFO: epoch 002:   3576 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.89, wpb=100.2, bsz=40, num_updates=19330, lr=3.93254e-05, gnorm=0.836, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62638
2022-09-29 14:07:05 - progress_bar.py[line:274] - INFO: epoch 002:   3586 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.9, wpb=100.5, bsz=40, num_updates=19340, lr=3.93188e-05, gnorm=0.802, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62650
2022-09-29 14:07:16 - progress_bar.py[line:274] - INFO: epoch 002:   3596 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.88, wpb=102.4, bsz=40, num_updates=19350, lr=3.93122e-05, gnorm=1.012, clip=40, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62661
2022-09-29 14:07:25 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 14:07:28 - progress_bar.py[line:274] - INFO: epoch 002:   3607 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=84, ups=0.84, wpb=100.3, bsz=40, num_updates=19360, lr=3.93056e-05, gnorm=0.883, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=62673
2022-09-29 14:07:39 - progress_bar.py[line:274] - INFO: epoch 002:   3617 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.2, ups=0.93, wpb=101.4, bsz=40, num_updates=19370, lr=3.9299e-05, gnorm=0.781, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62684
2022-09-29 14:07:50 - progress_bar.py[line:274] - INFO: epoch 002:   3627 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.88, wpb=101.8, bsz=40, num_updates=19380, lr=3.92924e-05, gnorm=0.739, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=62695
2022-09-29 14:08:01 - progress_bar.py[line:274] - INFO: epoch 002:   3637 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.92, wpb=100.1, bsz=40, num_updates=19390, lr=3.92858e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62706
2022-09-29 14:08:12 - progress_bar.py[line:274] - INFO: epoch 002:   3647 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.4, ups=0.89, wpb=100.4, bsz=40, num_updates=19400, lr=3.92792e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62717
2022-09-29 14:08:24 - progress_bar.py[line:274] - INFO: epoch 002:   3657 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.88, wpb=100.7, bsz=40, num_updates=19410, lr=3.92726e-05, gnorm=0.844, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=62729
2022-09-29 14:08:35 - progress_bar.py[line:274] - INFO: epoch 002:   3667 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.6, ups=0.92, wpb=100.9, bsz=40, num_updates=19420, lr=3.9266e-05, gnorm=0.793, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=62740
2022-09-29 14:08:46 - progress_bar.py[line:274] - INFO: epoch 002:   3677 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.88, wpb=101.8, bsz=40, num_updates=19430, lr=3.92594e-05, gnorm=0.802, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=62751
2022-09-29 14:08:57 - progress_bar.py[line:274] - INFO: epoch 002:   3687 / 15783 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.8, ups=0.9, wpb=99.6, bsz=40, num_updates=19440, lr=3.92528e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62762
2022-09-29 14:09:09 - progress_bar.py[line:274] - INFO: epoch 002:   3697 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.88, wpb=102.6, bsz=40, num_updates=19450, lr=3.92462e-05, gnorm=0.721, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62773
2022-09-29 14:09:20 - progress_bar.py[line:274] - INFO: epoch 002:   3707 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.1, ups=0.93, wpb=102.4, bsz=40, num_updates=19460, lr=3.92396e-05, gnorm=0.762, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62784
2022-09-29 14:09:31 - progress_bar.py[line:274] - INFO: epoch 002:   3717 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.91, wpb=100.5, bsz=40, num_updates=19470, lr=3.9233e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62796
2022-09-29 14:09:42 - progress_bar.py[line:274] - INFO: epoch 002:   3727 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.92, wpb=99.3, bsz=40, num_updates=19480, lr=3.92264e-05, gnorm=0.883, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62807
2022-09-29 14:09:53 - progress_bar.py[line:274] - INFO: epoch 002:   3737 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.89, wpb=102.5, bsz=40, num_updates=19490, lr=3.92198e-05, gnorm=0.744, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62818
2022-09-29 14:10:04 - progress_bar.py[line:274] - INFO: epoch 002:   3747 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.8, ups=0.9, wpb=101, bsz=40, num_updates=19500, lr=3.92132e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62829
2022-09-29 14:10:15 - progress_bar.py[line:274] - INFO: epoch 002:   3757 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.5, ups=0.91, wpb=100.2, bsz=40, num_updates=19510, lr=3.92066e-05, gnorm=0.847, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=62840
2022-09-29 14:10:28 - progress_bar.py[line:274] - INFO: epoch 002:   3767 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.89, wpb=102.2, bsz=40, num_updates=19520, lr=3.92e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62851
2022-09-29 14:10:39 - progress_bar.py[line:274] - INFO: epoch 002:   3777 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.9, ups=0.92, wpb=102.5, bsz=40, num_updates=19530, lr=3.91934e-05, gnorm=0.709, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62864
2022-09-29 14:10:50 - progress_bar.py[line:274] - INFO: epoch 002:   3787 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=19540, lr=3.91868e-05, gnorm=0.803, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=62875
2022-09-29 14:11:01 - progress_bar.py[line:274] - INFO: epoch 002:   3797 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.4, ups=0.87, wpb=100.3, bsz=40, num_updates=19550, lr=3.91802e-05, gnorm=0.855, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62886
2022-09-29 14:11:12 - progress_bar.py[line:274] - INFO: epoch 002:   3807 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.6, ups=0.94, wpb=100.2, bsz=40, num_updates=19560, lr=3.91736e-05, gnorm=0.734, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=62897
2022-09-29 14:11:23 - progress_bar.py[line:274] - INFO: epoch 002:   3817 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.5, ups=0.88, wpb=100.8, bsz=40, num_updates=19570, lr=3.9167e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62908
2022-09-29 14:11:35 - progress_bar.py[line:274] - INFO: epoch 002:   3827 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.89, wpb=102.8, bsz=40, num_updates=19580, lr=3.91604e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62919
2022-09-29 14:11:46 - progress_bar.py[line:274] - INFO: epoch 002:   3837 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.91, wpb=102.3, bsz=40, num_updates=19590, lr=3.91538e-05, gnorm=0.724, clip=10, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=62931
2022-09-29 14:11:57 - progress_bar.py[line:274] - INFO: epoch 002:   3847 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.5, ups=0.89, wpb=103.4, bsz=40, num_updates=19600, lr=3.91472e-05, gnorm=0.695, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62942
2022-09-29 14:12:09 - progress_bar.py[line:274] - INFO: epoch 002:   3857 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.2, ups=0.89, wpb=100.7, bsz=40, num_updates=19610, lr=3.91406e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62953
2022-09-29 14:12:20 - progress_bar.py[line:274] - INFO: epoch 002:   3867 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.4, ups=0.89, wpb=99, bsz=40, num_updates=19620, lr=3.9134e-05, gnorm=0.81, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=62965
2022-09-29 14:12:31 - progress_bar.py[line:274] - INFO: epoch 002:   3877 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=19630, lr=3.91274e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=62976
2022-09-29 14:12:42 - progress_bar.py[line:274] - INFO: epoch 002:   3887 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.8, ups=0.9, wpb=101.7, bsz=40, num_updates=19640, lr=3.91208e-05, gnorm=0.833, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=62987
2022-09-29 14:12:53 - progress_bar.py[line:274] - INFO: epoch 002:   3897 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.1, bsz=40, num_updates=19650, lr=3.91142e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=62998
2022-09-29 14:13:04 - progress_bar.py[line:274] - INFO: epoch 002:   3907 / 15783 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.2, ups=0.92, wpb=103, bsz=40, num_updates=19660, lr=3.91076e-05, gnorm=0.686, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63009
2022-09-29 14:13:15 - progress_bar.py[line:274] - INFO: epoch 002:   3917 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.89, wpb=102.1, bsz=40, num_updates=19670, lr=3.9101e-05, gnorm=0.674, clip=0, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=63020
2022-09-29 14:13:27 - progress_bar.py[line:274] - INFO: epoch 002:   3927 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.2, ups=0.87, wpb=100.5, bsz=40, num_updates=19680, lr=3.90944e-05, gnorm=0.76, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63032
2022-09-29 14:13:38 - progress_bar.py[line:274] - INFO: epoch 002:   3937 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.7, ups=0.87, wpb=101.1, bsz=40, num_updates=19690, lr=3.90878e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63043
2022-09-29 14:13:50 - progress_bar.py[line:274] - INFO: epoch 002:   3947 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.88, wpb=101.3, bsz=40, num_updates=19700, lr=3.90812e-05, gnorm=0.799, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63055
2022-09-29 14:14:01 - progress_bar.py[line:274] - INFO: epoch 002:   3957 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.2, ups=0.9, wpb=100.9, bsz=40, num_updates=19710, lr=3.90746e-05, gnorm=0.719, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63066
2022-09-29 14:14:12 - progress_bar.py[line:274] - INFO: epoch 002:   3967 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=19720, lr=3.9068e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63077
2022-09-29 14:14:23 - progress_bar.py[line:274] - INFO: epoch 002:   3977 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.89, wpb=101.5, bsz=40, num_updates=19730, lr=3.90614e-05, gnorm=0.804, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63088
2022-09-29 14:14:34 - progress_bar.py[line:274] - INFO: epoch 002:   3987 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.3, ups=0.93, wpb=100.6, bsz=40, num_updates=19740, lr=3.90548e-05, gnorm=0.8, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63099
2022-09-29 14:14:45 - progress_bar.py[line:274] - INFO: epoch 002:   3997 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.9, ups=0.88, wpb=102.1, bsz=40, num_updates=19750, lr=3.90482e-05, gnorm=0.722, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63110
2022-09-29 14:14:57 - progress_bar.py[line:274] - INFO: epoch 002:   4007 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.9, ups=0.87, wpb=100, bsz=40, num_updates=19760, lr=3.90416e-05, gnorm=0.883, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63122
2022-09-29 14:15:08 - progress_bar.py[line:274] - INFO: epoch 002:   4017 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.5, ups=0.87, wpb=102.1, bsz=40, num_updates=19770, lr=3.9035e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63133
2022-09-29 14:15:20 - progress_bar.py[line:274] - INFO: epoch 002:   4027 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.89, wpb=101.2, bsz=40, num_updates=19780, lr=3.90284e-05, gnorm=0.777, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63144
2022-09-29 14:15:31 - progress_bar.py[line:274] - INFO: epoch 002:   4037 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=19790, lr=3.90218e-05, gnorm=0.748, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63156
2022-09-29 14:15:42 - progress_bar.py[line:274] - INFO: epoch 002:   4047 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.1, ups=0.87, wpb=102.5, bsz=40, num_updates=19800, lr=3.90152e-05, gnorm=0.787, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63167
2022-09-29 14:15:53 - progress_bar.py[line:274] - INFO: epoch 002:   4057 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.9, ups=0.89, wpb=99.7, bsz=40, num_updates=19810, lr=3.90086e-05, gnorm=0.859, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63178
2022-09-29 14:16:05 - progress_bar.py[line:274] - INFO: epoch 002:   4067 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.5, ups=0.9, wpb=101.6, bsz=40, num_updates=19820, lr=3.9002e-05, gnorm=0.769, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63189
2022-09-29 14:16:16 - progress_bar.py[line:274] - INFO: epoch 002:   4077 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.1, ups=0.88, wpb=101.1, bsz=40, num_updates=19830, lr=3.89954e-05, gnorm=0.763, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63201
2022-09-29 14:16:27 - progress_bar.py[line:274] - INFO: epoch 002:   4087 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.1, ups=0.88, wpb=102.6, bsz=40, num_updates=19840, lr=3.89888e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63212
2022-09-29 14:16:39 - progress_bar.py[line:274] - INFO: epoch 002:   4097 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.88, wpb=102.1, bsz=40, num_updates=19850, lr=3.89822e-05, gnorm=0.743, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63224
2022-09-29 14:16:50 - progress_bar.py[line:274] - INFO: epoch 002:   4107 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.7, ups=0.89, wpb=99.8, bsz=40, num_updates=19860, lr=3.89756e-05, gnorm=0.874, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63235
2022-09-29 14:17:01 - progress_bar.py[line:274] - INFO: epoch 002:   4117 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.3, ups=0.89, wpb=100.2, bsz=40, num_updates=19870, lr=3.8969e-05, gnorm=0.757, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63246
2022-09-29 14:17:12 - progress_bar.py[line:274] - INFO: epoch 002:   4127 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=19880, lr=3.89624e-05, gnorm=0.732, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63257
2022-09-29 14:17:24 - progress_bar.py[line:274] - INFO: epoch 002:   4137 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.89, wpb=101.1, bsz=40, num_updates=19890, lr=3.89558e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63269
2022-09-29 14:17:35 - progress_bar.py[line:274] - INFO: epoch 002:   4147 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.91, wpb=102.4, bsz=40, num_updates=19900, lr=3.89492e-05, gnorm=0.729, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63279
2022-09-29 14:17:46 - progress_bar.py[line:274] - INFO: epoch 002:   4157 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.9, wpb=100.1, bsz=40, num_updates=19910, lr=3.89426e-05, gnorm=0.826, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=63291
2022-09-29 14:17:57 - progress_bar.py[line:274] - INFO: epoch 002:   4167 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.88, wpb=101.2, bsz=40, num_updates=19920, lr=3.8936e-05, gnorm=0.732, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63302
2022-09-29 14:18:08 - progress_bar.py[line:274] - INFO: epoch 002:   4177 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=19930, lr=3.89294e-05, gnorm=0.774, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63313
2022-09-29 14:18:19 - progress_bar.py[line:274] - INFO: epoch 002:   4187 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.92, wpb=100.4, bsz=40, num_updates=19940, lr=3.89228e-05, gnorm=0.727, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63324
2022-09-29 14:18:30 - progress_bar.py[line:274] - INFO: epoch 002:   4197 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.9, wpb=100.7, bsz=40, num_updates=19950, lr=3.89162e-05, gnorm=0.818, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63335
2022-09-29 14:18:41 - progress_bar.py[line:274] - INFO: epoch 002:   4207 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.9, ups=0.91, wpb=101.6, bsz=40, num_updates=19960, lr=3.89096e-05, gnorm=0.826, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63346
2022-09-29 14:18:53 - progress_bar.py[line:274] - INFO: epoch 002:   4217 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.88, wpb=100.3, bsz=40, num_updates=19970, lr=3.8903e-05, gnorm=0.74, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63357
2022-09-29 14:19:04 - progress_bar.py[line:274] - INFO: epoch 002:   4227 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.89, wpb=102.6, bsz=40, num_updates=19980, lr=3.88964e-05, gnorm=0.709, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63369
2022-09-29 14:19:15 - progress_bar.py[line:274] - INFO: epoch 002:   4237 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.1, ups=0.9, wpb=103.6, bsz=40, num_updates=19990, lr=3.88898e-05, gnorm=0.748, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63380
2022-09-29 14:19:27 - progress_bar.py[line:274] - INFO: epoch 002:   4247 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.88, wpb=102.3, bsz=40, num_updates=20000, lr=3.88832e-05, gnorm=0.748, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63391
2022-09-29 14:19:38 - progress_bar.py[line:274] - INFO: epoch 002:   4257 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.6, ups=0.89, wpb=99.6, bsz=40, num_updates=20010, lr=3.88766e-05, gnorm=0.883, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63403
2022-09-29 14:19:49 - progress_bar.py[line:274] - INFO: epoch 002:   4267 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.89, wpb=101.4, bsz=40, num_updates=20020, lr=3.887e-05, gnorm=0.822, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63414
2022-09-29 14:20:01 - progress_bar.py[line:274] - INFO: epoch 002:   4277 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.2, ups=0.88, wpb=100.6, bsz=40, num_updates=20030, lr=3.88634e-05, gnorm=0.917, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63425
2022-09-29 14:20:12 - progress_bar.py[line:274] - INFO: epoch 002:   4287 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95, ups=0.93, wpb=101.8, bsz=40, num_updates=20040, lr=3.88568e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63437
2022-09-29 14:20:23 - progress_bar.py[line:274] - INFO: epoch 002:   4297 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.88, wpb=102, bsz=40, num_updates=20050, lr=3.88502e-05, gnorm=0.797, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63448
2022-09-29 14:20:34 - progress_bar.py[line:274] - INFO: epoch 002:   4307 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.9, ups=0.89, wpb=99.7, bsz=40, num_updates=20060, lr=3.88436e-05, gnorm=0.792, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63459
2022-09-29 14:20:46 - progress_bar.py[line:274] - INFO: epoch 002:   4317 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.3, ups=0.88, wpb=101.4, bsz=40, num_updates=20070, lr=3.8837e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63470
2022-09-29 14:20:57 - progress_bar.py[line:274] - INFO: epoch 002:   4327 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.4, ups=0.89, wpb=103.1, bsz=40, num_updates=20080, lr=3.88304e-05, gnorm=0.801, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63482
2022-09-29 14:21:08 - progress_bar.py[line:274] - INFO: epoch 002:   4337 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=20090, lr=3.88238e-05, gnorm=0.963, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63493
2022-09-29 14:21:20 - progress_bar.py[line:274] - INFO: epoch 002:   4347 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.4, ups=0.87, wpb=102.4, bsz=40, num_updates=20100, lr=3.88172e-05, gnorm=0.766, clip=10, loss_scale=1024, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=63505
2022-09-29 14:21:31 - progress_bar.py[line:274] - INFO: epoch 002:   4357 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=20110, lr=3.88106e-05, gnorm=0.863, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63516
2022-09-29 14:21:42 - progress_bar.py[line:274] - INFO: epoch 002:   4367 / 15783 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.8, ups=0.91, wpb=99.8, bsz=40, num_updates=20120, lr=3.8804e-05, gnorm=0.996, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63527
2022-09-29 14:21:53 - progress_bar.py[line:274] - INFO: epoch 002:   4377 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.89, wpb=102.6, bsz=40, num_updates=20130, lr=3.87974e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63538
2022-09-29 14:22:04 - progress_bar.py[line:274] - INFO: epoch 002:   4387 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92, ups=0.9, wpb=102.1, bsz=40, num_updates=20140, lr=3.87908e-05, gnorm=0.666, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63549
2022-09-29 14:22:16 - progress_bar.py[line:274] - INFO: epoch 002:   4397 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.89, wpb=101.5, bsz=40, num_updates=20150, lr=3.87842e-05, gnorm=0.769, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63560
2022-09-29 14:22:27 - progress_bar.py[line:274] - INFO: epoch 002:   4407 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.87, wpb=102.5, bsz=40, num_updates=20160, lr=3.87776e-05, gnorm=0.789, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63572
2022-09-29 14:22:38 - progress_bar.py[line:274] - INFO: epoch 002:   4417 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.7, ups=0.88, wpb=101.2, bsz=40, num_updates=20170, lr=3.8771e-05, gnorm=0.83, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63583
2022-09-29 14:22:50 - progress_bar.py[line:274] - INFO: epoch 002:   4427 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.89, wpb=101.7, bsz=40, num_updates=20180, lr=3.87644e-05, gnorm=0.822, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63595
2022-09-29 14:23:01 - progress_bar.py[line:274] - INFO: epoch 002:   4437 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91, ups=0.89, wpb=102.2, bsz=40, num_updates=20190, lr=3.87578e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63606
2022-09-29 14:23:12 - progress_bar.py[line:274] - INFO: epoch 002:   4447 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.9, wpb=99.7, bsz=40, num_updates=20200, lr=3.87512e-05, gnorm=0.687, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63617
2022-09-29 14:23:23 - progress_bar.py[line:274] - INFO: epoch 002:   4457 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.88, wpb=102.4, bsz=40, num_updates=20210, lr=3.87446e-05, gnorm=0.752, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63628
2022-09-29 14:23:35 - progress_bar.py[line:274] - INFO: epoch 002:   4467 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=20220, lr=3.8738e-05, gnorm=0.757, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63640
2022-09-29 14:23:46 - progress_bar.py[line:274] - INFO: epoch 002:   4477 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.4, ups=0.9, wpb=100.3, bsz=40, num_updates=20230, lr=3.87314e-05, gnorm=0.743, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63651
2022-09-29 14:23:57 - progress_bar.py[line:274] - INFO: epoch 002:   4487 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.7, ups=0.88, wpb=99.8, bsz=40, num_updates=20240, lr=3.87248e-05, gnorm=0.874, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=63662
2022-09-29 14:24:08 - progress_bar.py[line:274] - INFO: epoch 002:   4497 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.89, wpb=102.1, bsz=40, num_updates=20250, lr=3.87182e-05, gnorm=0.745, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63673
2022-09-29 14:24:19 - progress_bar.py[line:274] - INFO: epoch 002:   4507 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.91, wpb=101.5, bsz=40, num_updates=20260, lr=3.87116e-05, gnorm=0.702, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63684
2022-09-29 14:24:31 - progress_bar.py[line:274] - INFO: epoch 002:   4517 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90, ups=0.9, wpb=100.3, bsz=40, num_updates=20270, lr=3.8705e-05, gnorm=0.721, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63695
2022-09-29 14:24:42 - progress_bar.py[line:274] - INFO: epoch 002:   4527 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.89, wpb=102.8, bsz=40, num_updates=20280, lr=3.86984e-05, gnorm=0.718, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63707
2022-09-29 14:24:53 - progress_bar.py[line:274] - INFO: epoch 002:   4537 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.89, wpb=101.1, bsz=40, num_updates=20290, lr=3.86918e-05, gnorm=0.71, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63718
2022-09-29 14:25:05 - progress_bar.py[line:274] - INFO: epoch 002:   4547 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.88, wpb=103.9, bsz=40, num_updates=20300, lr=3.86852e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63729
2022-09-29 14:25:16 - progress_bar.py[line:274] - INFO: epoch 002:   4557 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.88, wpb=104, bsz=40, num_updates=20310, lr=3.86786e-05, gnorm=0.74, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=63741
2022-09-29 14:25:27 - progress_bar.py[line:274] - INFO: epoch 002:   4567 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.3, ups=0.87, wpb=100.2, bsz=40, num_updates=20320, lr=3.8672e-05, gnorm=0.914, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63752
2022-09-29 14:25:39 - progress_bar.py[line:274] - INFO: epoch 002:   4577 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.87, wpb=101.2, bsz=40, num_updates=20330, lr=3.86654e-05, gnorm=0.78, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63764
2022-09-29 14:25:41 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 14:25:51 - progress_bar.py[line:274] - INFO: epoch 002:   4588 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=84, ups=0.83, wpb=101.7, bsz=40, num_updates=20340, lr=3.86588e-05, gnorm=0.72, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=63776
2022-09-29 14:26:02 - progress_bar.py[line:274] - INFO: epoch 002:   4598 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=20350, lr=3.86522e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63787
2022-09-29 14:26:13 - progress_bar.py[line:274] - INFO: epoch 002:   4608 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.7, ups=0.94, wpb=102.7, bsz=40, num_updates=20360, lr=3.86456e-05, gnorm=0.913, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63798
2022-09-29 14:26:24 - progress_bar.py[line:274] - INFO: epoch 002:   4618 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.1, ups=0.87, wpb=101.9, bsz=40, num_updates=20370, lr=3.8639e-05, gnorm=0.819, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63809
2022-09-29 14:26:36 - progress_bar.py[line:274] - INFO: epoch 002:   4628 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.9, ups=0.89, wpb=100, bsz=40, num_updates=20380, lr=3.86324e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63820
2022-09-29 14:26:47 - progress_bar.py[line:274] - INFO: epoch 002:   4638 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.8, ups=0.9, wpb=102.3, bsz=40, num_updates=20390, lr=3.86258e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=63832
2022-09-29 14:26:58 - progress_bar.py[line:274] - INFO: epoch 002:   4648 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.4, ups=0.89, wpb=100.3, bsz=40, num_updates=20400, lr=3.86192e-05, gnorm=0.918, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=63843
2022-09-29 14:27:09 - progress_bar.py[line:274] - INFO: epoch 002:   4658 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.9, ups=0.87, wpb=101.2, bsz=40, num_updates=20410, lr=3.86126e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63854
2022-09-29 14:27:21 - progress_bar.py[line:274] - INFO: epoch 002:   4668 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.9, wpb=100.4, bsz=40, num_updates=20420, lr=3.8606e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63865
2022-09-29 14:27:32 - progress_bar.py[line:274] - INFO: epoch 002:   4678 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.2, ups=0.89, wpb=102.4, bsz=40, num_updates=20430, lr=3.85994e-05, gnorm=0.718, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63877
2022-09-29 14:27:43 - progress_bar.py[line:274] - INFO: epoch 002:   4688 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=20440, lr=3.85928e-05, gnorm=0.762, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63888
2022-09-29 14:27:54 - progress_bar.py[line:274] - INFO: epoch 002:   4698 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.89, wpb=101.6, bsz=40, num_updates=20450, lr=3.85862e-05, gnorm=0.679, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=63899
2022-09-29 14:28:06 - progress_bar.py[line:274] - INFO: epoch 002:   4708 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.9, ups=0.87, wpb=100.3, bsz=40, num_updates=20460, lr=3.85796e-05, gnorm=0.863, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63911
2022-09-29 14:28:17 - progress_bar.py[line:274] - INFO: epoch 002:   4718 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.2, ups=0.9, wpb=102.4, bsz=40, num_updates=20470, lr=3.8573e-05, gnorm=0.931, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63922
2022-09-29 14:28:28 - progress_bar.py[line:274] - INFO: epoch 002:   4728 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.89, wpb=100.2, bsz=40, num_updates=20480, lr=3.85664e-05, gnorm=0.787, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63933
2022-09-29 14:28:39 - progress_bar.py[line:274] - INFO: epoch 002:   4738 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.8, ups=0.93, wpb=102.2, bsz=40, num_updates=20490, lr=3.85598e-05, gnorm=0.873, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63944
2022-09-29 14:28:50 - progress_bar.py[line:274] - INFO: epoch 002:   4748 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.9, wpb=101.8, bsz=40, num_updates=20500, lr=3.85532e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63955
2022-09-29 14:29:01 - progress_bar.py[line:274] - INFO: epoch 002:   4758 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.7, ups=0.89, wpb=100.1, bsz=40, num_updates=20510, lr=3.85466e-05, gnorm=0.831, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=63966
2022-09-29 14:29:13 - progress_bar.py[line:274] - INFO: epoch 002:   4768 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92, ups=0.9, wpb=102.5, bsz=40, num_updates=20520, lr=3.854e-05, gnorm=0.869, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63977
2022-09-29 14:29:23 - progress_bar.py[line:274] - INFO: epoch 002:   4778 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.6, ups=0.92, wpb=100.9, bsz=40, num_updates=20530, lr=3.85334e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63988
2022-09-29 14:29:35 - progress_bar.py[line:274] - INFO: epoch 002:   4788 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.4, ups=0.87, wpb=102.2, bsz=40, num_updates=20540, lr=3.85268e-05, gnorm=0.763, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=64000
2022-09-29 14:29:46 - progress_bar.py[line:274] - INFO: epoch 002:   4798 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.88, wpb=103.6, bsz=40, num_updates=20550, lr=3.85202e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64011
2022-09-29 14:29:58 - progress_bar.py[line:274] - INFO: epoch 002:   4808 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.3, ups=0.88, wpb=102.6, bsz=40, num_updates=20560, lr=3.85136e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64023
2022-09-29 14:30:09 - progress_bar.py[line:274] - INFO: epoch 002:   4818 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.6, ups=0.91, wpb=99.7, bsz=40, num_updates=20570, lr=3.8507e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64034
2022-09-29 14:30:20 - progress_bar.py[line:274] - INFO: epoch 002:   4828 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.89, wpb=100.8, bsz=40, num_updates=20580, lr=3.85004e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64045
2022-09-29 14:30:31 - progress_bar.py[line:274] - INFO: epoch 002:   4838 / 15783 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87.9, ups=0.88, wpb=99.7, bsz=40, num_updates=20590, lr=3.84938e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64056
2022-09-29 14:30:43 - progress_bar.py[line:274] - INFO: epoch 002:   4848 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.88, wpb=101.4, bsz=40, num_updates=20600, lr=3.84872e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64068
2022-09-29 14:30:54 - progress_bar.py[line:274] - INFO: epoch 002:   4858 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.2, ups=0.88, wpb=100.7, bsz=40, num_updates=20610, lr=3.84806e-05, gnorm=0.758, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64079
2022-09-29 14:31:05 - progress_bar.py[line:274] - INFO: epoch 002:   4868 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.5, ups=0.91, wpb=101.5, bsz=40, num_updates=20620, lr=3.8474e-05, gnorm=0.709, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64090
2022-09-29 14:31:17 - progress_bar.py[line:274] - INFO: epoch 002:   4878 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.1, ups=0.88, wpb=101.8, bsz=40, num_updates=20630, lr=3.84674e-05, gnorm=0.806, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64101
2022-09-29 14:31:28 - progress_bar.py[line:274] - INFO: epoch 002:   4888 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.9, ups=0.88, wpb=103.2, bsz=40, num_updates=20640, lr=3.84608e-05, gnorm=0.753, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64113
2022-09-29 14:31:39 - progress_bar.py[line:274] - INFO: epoch 002:   4898 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.89, wpb=102.2, bsz=40, num_updates=20650, lr=3.84542e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64124
2022-09-29 14:31:50 - progress_bar.py[line:274] - INFO: epoch 002:   4908 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.9, wpb=101.7, bsz=40, num_updates=20660, lr=3.84476e-05, gnorm=0.711, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64135
2022-09-29 14:32:02 - progress_bar.py[line:274] - INFO: epoch 002:   4918 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.88, wpb=102.4, bsz=40, num_updates=20670, lr=3.8441e-05, gnorm=0.793, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64147
2022-09-29 14:32:13 - progress_bar.py[line:274] - INFO: epoch 002:   4928 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.91, wpb=101.1, bsz=40, num_updates=20680, lr=3.84344e-05, gnorm=0.742, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64158
2022-09-29 14:32:24 - progress_bar.py[line:274] - INFO: epoch 002:   4938 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.9, wpb=101.3, bsz=40, num_updates=20690, lr=3.84278e-05, gnorm=0.769, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64169
2022-09-29 14:32:35 - progress_bar.py[line:274] - INFO: epoch 002:   4948 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.9, wpb=99.6, bsz=40, num_updates=20700, lr=3.84212e-05, gnorm=0.719, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64180
2022-09-29 14:32:46 - progress_bar.py[line:274] - INFO: epoch 002:   4958 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.9, wpb=101.7, bsz=40, num_updates=20710, lr=3.84146e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64191
2022-09-29 14:32:57 - progress_bar.py[line:274] - INFO: epoch 002:   4968 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.5, ups=0.89, wpb=103, bsz=40, num_updates=20720, lr=3.8408e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64202
2022-09-29 14:33:09 - progress_bar.py[line:274] - INFO: epoch 002:   4978 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.2, ups=0.88, wpb=101, bsz=40, num_updates=20730, lr=3.84014e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64214
2022-09-29 14:33:20 - progress_bar.py[line:274] - INFO: epoch 002:   4988 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91, ups=0.89, wpb=102.7, bsz=40, num_updates=20740, lr=3.83948e-05, gnorm=1.126, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64225
2022-09-29 14:33:31 - progress_bar.py[line:274] - INFO: epoch 002:   4998 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.92, wpb=99.3, bsz=40, num_updates=20750, lr=3.83882e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64236
2022-09-29 14:33:42 - progress_bar.py[line:274] - INFO: epoch 002:   5008 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.9, wpb=101.4, bsz=40, num_updates=20760, lr=3.83816e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64247
2022-09-29 14:33:53 - progress_bar.py[line:274] - INFO: epoch 002:   5018 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=20770, lr=3.8375e-05, gnorm=0.701, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64258
2022-09-29 14:34:05 - progress_bar.py[line:274] - INFO: epoch 002:   5028 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=20780, lr=3.83684e-05, gnorm=0.734, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64270
2022-09-29 14:34:16 - progress_bar.py[line:274] - INFO: epoch 002:   5038 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92, ups=0.9, wpb=102, bsz=40, num_updates=20790, lr=3.83618e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64281
2022-09-29 14:34:27 - progress_bar.py[line:274] - INFO: epoch 002:   5048 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=20800, lr=3.83552e-05, gnorm=0.815, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64292
2022-09-29 14:34:38 - progress_bar.py[line:274] - INFO: epoch 002:   5058 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.89, wpb=100, bsz=40, num_updates=20810, lr=3.83486e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64303
2022-09-29 14:34:49 - progress_bar.py[line:274] - INFO: epoch 002:   5068 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=20820, lr=3.8342e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64314
2022-09-29 14:35:01 - progress_bar.py[line:274] - INFO: epoch 002:   5078 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.89, wpb=101.2, bsz=40, num_updates=20830, lr=3.83354e-05, gnorm=0.933, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64325
2022-09-29 14:35:12 - progress_bar.py[line:274] - INFO: epoch 002:   5088 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.2, ups=0.87, wpb=100.9, bsz=40, num_updates=20840, lr=3.83288e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64337
2022-09-29 14:35:23 - progress_bar.py[line:274] - INFO: epoch 002:   5098 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.9, ups=0.87, wpb=101.8, bsz=40, num_updates=20850, lr=3.83222e-05, gnorm=0.743, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64348
2022-09-29 14:35:35 - progress_bar.py[line:274] - INFO: epoch 002:   5108 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.9, wpb=101.9, bsz=40, num_updates=20860, lr=3.83156e-05, gnorm=0.809, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64359
2022-09-29 14:35:46 - progress_bar.py[line:274] - INFO: epoch 002:   5118 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91, ups=0.89, wpb=102.6, bsz=40, num_updates=20870, lr=3.8309e-05, gnorm=0.742, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64371
2022-09-29 14:35:57 - progress_bar.py[line:274] - INFO: epoch 002:   5128 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.4, ups=0.92, wpb=103, bsz=40, num_updates=20880, lr=3.83024e-05, gnorm=0.812, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64382
2022-09-29 14:36:08 - progress_bar.py[line:274] - INFO: epoch 002:   5138 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89, ups=0.88, wpb=100.6, bsz=40, num_updates=20890, lr=3.82958e-05, gnorm=0.785, clip=10, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=64393
2022-09-29 14:36:19 - progress_bar.py[line:274] - INFO: epoch 002:   5148 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.89, wpb=101.3, bsz=40, num_updates=20900, lr=3.82892e-05, gnorm=0.782, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64404
2022-09-29 14:36:31 - progress_bar.py[line:274] - INFO: epoch 002:   5158 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.88, wpb=101.4, bsz=40, num_updates=20910, lr=3.82826e-05, gnorm=0.687, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64416
2022-09-29 14:36:42 - progress_bar.py[line:274] - INFO: epoch 002:   5168 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.3, ups=0.92, wpb=101.3, bsz=40, num_updates=20920, lr=3.8276e-05, gnorm=0.728, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=64426
2022-09-29 14:36:53 - progress_bar.py[line:274] - INFO: epoch 002:   5178 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.91, wpb=100.6, bsz=40, num_updates=20930, lr=3.82694e-05, gnorm=0.908, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64437
2022-09-29 14:37:04 - progress_bar.py[line:274] - INFO: epoch 002:   5188 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.7, ups=0.87, wpb=101.8, bsz=40, num_updates=20940, lr=3.82628e-05, gnorm=0.881, clip=30, loss_scale=1024, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=64449
2022-09-29 14:37:15 - progress_bar.py[line:274] - INFO: epoch 002:   5198 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.9, ups=0.88, wpb=102.6, bsz=40, num_updates=20950, lr=3.82562e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64460
2022-09-29 14:37:27 - progress_bar.py[line:274] - INFO: epoch 002:   5208 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.89, wpb=102.4, bsz=40, num_updates=20960, lr=3.82496e-05, gnorm=0.897, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64472
2022-09-29 14:37:38 - progress_bar.py[line:274] - INFO: epoch 002:   5218 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.5, ups=0.91, wpb=102.6, bsz=40, num_updates=20970, lr=3.8243e-05, gnorm=0.954, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64483
2022-09-29 14:37:49 - progress_bar.py[line:274] - INFO: epoch 002:   5228 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.88, wpb=101.9, bsz=40, num_updates=20980, lr=3.82364e-05, gnorm=0.909, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64494
2022-09-29 14:38:00 - progress_bar.py[line:274] - INFO: epoch 002:   5238 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.89, wpb=103.3, bsz=40, num_updates=20990, lr=3.82298e-05, gnorm=0.813, clip=20, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=64505
2022-09-29 14:38:12 - progress_bar.py[line:274] - INFO: epoch 002:   5248 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.87, wpb=102.7, bsz=40, num_updates=21000, lr=3.82232e-05, gnorm=0.775, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64517
2022-09-29 14:38:23 - progress_bar.py[line:274] - INFO: epoch 002:   5258 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.89, wpb=102.7, bsz=40, num_updates=21010, lr=3.82166e-05, gnorm=0.923, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64528
2022-09-29 14:38:34 - progress_bar.py[line:274] - INFO: epoch 002:   5268 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.91, wpb=101.3, bsz=40, num_updates=21020, lr=3.821e-05, gnorm=0.9, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64539
2022-09-29 14:38:45 - progress_bar.py[line:274] - INFO: epoch 002:   5278 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.88, wpb=101.4, bsz=40, num_updates=21030, lr=3.82034e-05, gnorm=0.778, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64550
2022-09-29 14:38:54 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 14:38:58 - progress_bar.py[line:274] - INFO: epoch 002:   5289 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=83, ups=0.8, wpb=103.5, bsz=40, num_updates=21040, lr=3.81968e-05, gnorm=0.875, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=64563
2022-09-29 14:39:09 - progress_bar.py[line:274] - INFO: epoch 002:   5299 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.87, wpb=101.9, bsz=40, num_updates=21050, lr=3.81902e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64574
2022-09-29 14:39:21 - progress_bar.py[line:274] - INFO: epoch 002:   5309 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=21060, lr=3.81836e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=64585
2022-09-29 14:39:32 - progress_bar.py[line:274] - INFO: epoch 002:   5319 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.1, ups=0.86, wpb=100.6, bsz=40, num_updates=21070, lr=3.8177e-05, gnorm=0.916, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=64597
2022-09-29 14:39:44 - progress_bar.py[line:274] - INFO: epoch 002:   5329 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.87, wpb=103, bsz=40, num_updates=21080, lr=3.81704e-05, gnorm=0.72, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64609
2022-09-29 14:39:55 - progress_bar.py[line:274] - INFO: epoch 002:   5339 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.9, wpb=102.4, bsz=40, num_updates=21090, lr=3.81638e-05, gnorm=0.78, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64620
2022-09-29 14:40:06 - progress_bar.py[line:274] - INFO: epoch 002:   5349 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.9, wpb=101.1, bsz=40, num_updates=21100, lr=3.81572e-05, gnorm=1.024, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64631
2022-09-29 14:40:17 - progress_bar.py[line:274] - INFO: epoch 002:   5359 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.89, wpb=102, bsz=40, num_updates=21110, lr=3.81506e-05, gnorm=0.768, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64642
2022-09-29 14:40:28 - progress_bar.py[line:274] - INFO: epoch 002:   5369 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.7, ups=0.91, wpb=102, bsz=40, num_updates=21120, lr=3.8144e-05, gnorm=0.731, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64653
2022-09-29 14:40:40 - progress_bar.py[line:274] - INFO: epoch 002:   5379 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.7, ups=0.86, wpb=100.7, bsz=40, num_updates=21130, lr=3.81374e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=64665
2022-09-29 14:40:51 - progress_bar.py[line:274] - INFO: epoch 002:   5389 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.6, ups=0.88, wpb=101.2, bsz=40, num_updates=21140, lr=3.81308e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64676
2022-09-29 14:41:02 - progress_bar.py[line:274] - INFO: epoch 002:   5399 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.9, wpb=101.3, bsz=40, num_updates=21150, lr=3.81242e-05, gnorm=0.807, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64687
2022-09-29 14:41:14 - progress_bar.py[line:274] - INFO: epoch 002:   5409 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.3, ups=0.9, wpb=100.6, bsz=40, num_updates=21160, lr=3.81176e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64698
2022-09-29 14:41:25 - progress_bar.py[line:274] - INFO: epoch 002:   5419 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=102.1, bsz=40, num_updates=21170, lr=3.8111e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64710
2022-09-29 14:41:36 - progress_bar.py[line:274] - INFO: epoch 002:   5429 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.88, wpb=101, bsz=40, num_updates=21180, lr=3.81044e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=64721
2022-09-29 14:41:48 - progress_bar.py[line:274] - INFO: epoch 002:   5439 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.7, ups=0.88, wpb=100.6, bsz=40, num_updates=21190, lr=3.80978e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64732
2022-09-29 14:41:59 - progress_bar.py[line:274] - INFO: epoch 002:   5449 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.8, ups=0.89, wpb=100, bsz=40, num_updates=21200, lr=3.80912e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=64744
2022-09-29 14:42:10 - progress_bar.py[line:274] - INFO: epoch 002:   5459 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88, ups=0.88, wpb=100.4, bsz=40, num_updates=21210, lr=3.80846e-05, gnorm=0.962, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64755
2022-09-29 14:42:22 - progress_bar.py[line:274] - INFO: epoch 002:   5469 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.6, ups=0.87, wpb=100.5, bsz=40, num_updates=21220, lr=3.8078e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64767
2022-09-29 14:42:33 - progress_bar.py[line:274] - INFO: epoch 002:   5479 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.9, ups=0.91, wpb=101.7, bsz=40, num_updates=21230, lr=3.80714e-05, gnorm=0.908, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64778
2022-09-29 14:42:44 - progress_bar.py[line:274] - INFO: epoch 002:   5489 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.89, wpb=102.6, bsz=40, num_updates=21240, lr=3.80648e-05, gnorm=1.071, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64789
2022-09-29 14:42:55 - progress_bar.py[line:274] - INFO: epoch 002:   5499 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.1, ups=0.94, wpb=100.2, bsz=40, num_updates=21250, lr=3.80582e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64800
2022-09-29 14:43:06 - progress_bar.py[line:274] - INFO: epoch 002:   5509 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.89, wpb=101.2, bsz=40, num_updates=21260, lr=3.80516e-05, gnorm=0.921, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=64811
2022-09-29 14:43:17 - progress_bar.py[line:274] - INFO: epoch 002:   5519 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.8, ups=0.9, wpb=102.1, bsz=40, num_updates=21270, lr=3.8045e-05, gnorm=0.778, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64822
2022-09-29 14:43:28 - progress_bar.py[line:274] - INFO: epoch 002:   5529 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.6, ups=0.88, wpb=100.9, bsz=40, num_updates=21280, lr=3.80384e-05, gnorm=0.979, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64833
2022-09-29 14:43:40 - progress_bar.py[line:274] - INFO: epoch 002:   5539 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.9, wpb=101.6, bsz=40, num_updates=21290, lr=3.80318e-05, gnorm=0.74, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64844
2022-09-29 14:43:50 - progress_bar.py[line:274] - INFO: epoch 002:   5549 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93, ups=0.92, wpb=101.4, bsz=40, num_updates=21300, lr=3.80252e-05, gnorm=1.001, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=64855
2022-09-29 14:44:02 - progress_bar.py[line:274] - INFO: epoch 002:   5559 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=101.1, bsz=40, num_updates=21310, lr=3.80186e-05, gnorm=0.914, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64866
2022-09-29 14:44:13 - progress_bar.py[line:274] - INFO: epoch 002:   5569 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.87, wpb=102.1, bsz=40, num_updates=21320, lr=3.8012e-05, gnorm=0.862, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64878
2022-09-29 14:44:24 - progress_bar.py[line:274] - INFO: epoch 002:   5579 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.5, ups=0.9, wpb=102.9, bsz=40, num_updates=21330, lr=3.80054e-05, gnorm=0.766, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64889
2022-09-29 14:44:35 - progress_bar.py[line:274] - INFO: epoch 002:   5589 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.9, ups=0.89, wpb=100.3, bsz=40, num_updates=21340, lr=3.79988e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64900
2022-09-29 14:44:47 - progress_bar.py[line:274] - INFO: epoch 002:   5599 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.9, wpb=101, bsz=40, num_updates=21350, lr=3.79922e-05, gnorm=0.777, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64911
2022-09-29 14:44:58 - progress_bar.py[line:274] - INFO: epoch 002:   5609 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.6, ups=0.89, wpb=103.3, bsz=40, num_updates=21360, lr=3.79856e-05, gnorm=0.87, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64923
2022-09-29 14:45:09 - progress_bar.py[line:274] - INFO: epoch 002:   5619 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=87.9, ups=0.89, wpb=99.1, bsz=40, num_updates=21370, lr=3.7979e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64934
2022-09-29 14:45:20 - progress_bar.py[line:274] - INFO: epoch 002:   5629 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=21380, lr=3.79724e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64945
2022-09-29 14:45:32 - progress_bar.py[line:274] - INFO: epoch 002:   5639 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.5, ups=0.89, wpb=103.2, bsz=40, num_updates=21390, lr=3.79658e-05, gnorm=0.82, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64956
2022-09-29 14:45:43 - progress_bar.py[line:274] - INFO: epoch 002:   5649 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.3, ups=0.87, wpb=101.1, bsz=40, num_updates=21400, lr=3.79592e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64968
2022-09-29 14:45:54 - progress_bar.py[line:274] - INFO: epoch 002:   5659 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.4, ups=0.88, wpb=100.4, bsz=40, num_updates=21410, lr=3.79526e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64979
2022-09-29 14:46:06 - progress_bar.py[line:274] - INFO: epoch 002:   5669 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.2, ups=0.89, wpb=100.8, bsz=40, num_updates=21420, lr=3.7946e-05, gnorm=0.844, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64990
2022-09-29 14:46:17 - progress_bar.py[line:274] - INFO: epoch 002:   5679 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.89, wpb=100.8, bsz=40, num_updates=21430, lr=3.79394e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65002
2022-09-29 14:46:29 - progress_bar.py[line:274] - INFO: epoch 002:   5689 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88, ups=0.86, wpb=102.5, bsz=40, num_updates=21440, lr=3.79328e-05, gnorm=0.806, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=65013
2022-09-29 14:46:40 - progress_bar.py[line:274] - INFO: epoch 002:   5699 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.9, ups=0.91, wpb=103.1, bsz=40, num_updates=21450, lr=3.79262e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65024
2022-09-29 14:46:51 - progress_bar.py[line:274] - INFO: epoch 002:   5709 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.4, ups=0.89, wpb=99.6, bsz=40, num_updates=21460, lr=3.79196e-05, gnorm=1.001, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65036
2022-09-29 14:47:02 - progress_bar.py[line:274] - INFO: epoch 002:   5719 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.5, ups=0.87, wpb=101.1, bsz=40, num_updates=21470, lr=3.7913e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=65047
2022-09-29 14:47:14 - progress_bar.py[line:274] - INFO: epoch 002:   5729 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.5, ups=0.89, wpb=101.7, bsz=40, num_updates=21480, lr=3.79064e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65059
2022-09-29 14:47:25 - progress_bar.py[line:274] - INFO: epoch 002:   5739 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.89, wpb=102.4, bsz=40, num_updates=21490, lr=3.78998e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65070
2022-09-29 14:47:36 - progress_bar.py[line:274] - INFO: epoch 002:   5749 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.92, wpb=100.4, bsz=40, num_updates=21500, lr=3.78932e-05, gnorm=0.83, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65081
2022-09-29 14:47:47 - progress_bar.py[line:274] - INFO: epoch 002:   5759 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.91, wpb=101.2, bsz=40, num_updates=21510, lr=3.78866e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=65092
2022-09-29 14:47:58 - progress_bar.py[line:274] - INFO: epoch 002:   5769 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.1, ups=0.9, wpb=101.9, bsz=40, num_updates=21520, lr=3.788e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65103
2022-09-29 14:48:09 - progress_bar.py[line:274] - INFO: epoch 002:   5779 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.9, wpb=99.5, bsz=40, num_updates=21530, lr=3.78734e-05, gnorm=0.903, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65114
2022-09-29 14:48:20 - progress_bar.py[line:274] - INFO: epoch 002:   5789 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.89, wpb=101.3, bsz=40, num_updates=21540, lr=3.78668e-05, gnorm=0.691, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65125
2022-09-29 14:48:31 - progress_bar.py[line:274] - INFO: epoch 002:   5799 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.2, ups=0.92, wpb=101.5, bsz=40, num_updates=21550, lr=3.78602e-05, gnorm=0.885, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65136
2022-09-29 14:48:42 - progress_bar.py[line:274] - INFO: epoch 002:   5809 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=21560, lr=3.78536e-05, gnorm=0.723, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65147
2022-09-29 14:48:53 - progress_bar.py[line:274] - INFO: epoch 002:   5819 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.91, wpb=101.1, bsz=40, num_updates=21570, lr=3.7847e-05, gnorm=0.94, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65158
2022-09-29 14:49:04 - progress_bar.py[line:274] - INFO: epoch 002:   5829 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.8, ups=0.9, wpb=100.1, bsz=40, num_updates=21580, lr=3.78404e-05, gnorm=0.824, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=65169
2022-09-29 14:49:16 - progress_bar.py[line:274] - INFO: epoch 002:   5839 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.89, wpb=99.9, bsz=40, num_updates=21590, lr=3.78338e-05, gnorm=0.816, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65181
2022-09-29 14:49:27 - progress_bar.py[line:274] - INFO: epoch 002:   5849 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.7, ups=0.89, wpb=101.6, bsz=40, num_updates=21600, lr=3.78272e-05, gnorm=0.779, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65192
2022-09-29 14:49:38 - progress_bar.py[line:274] - INFO: epoch 002:   5859 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.9, wpb=101.1, bsz=40, num_updates=21610, lr=3.78206e-05, gnorm=0.817, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65203
2022-09-29 14:49:50 - progress_bar.py[line:274] - INFO: epoch 002:   5869 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.87, wpb=102.9, bsz=40, num_updates=21620, lr=3.7814e-05, gnorm=1.003, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65215
2022-09-29 14:50:01 - progress_bar.py[line:274] - INFO: epoch 002:   5879 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.8, ups=0.88, wpb=102.1, bsz=40, num_updates=21630, lr=3.78074e-05, gnorm=1.087, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65226
2022-09-29 14:50:12 - progress_bar.py[line:274] - INFO: epoch 002:   5889 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.9, wpb=101.9, bsz=40, num_updates=21640, lr=3.78008e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65237
2022-09-29 14:50:24 - progress_bar.py[line:274] - INFO: epoch 002:   5899 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89, ups=0.89, wpb=100.3, bsz=40, num_updates=21650, lr=3.77942e-05, gnorm=0.814, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65249
2022-09-29 14:50:35 - progress_bar.py[line:274] - INFO: epoch 002:   5909 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.9, wpb=101.7, bsz=40, num_updates=21660, lr=3.77876e-05, gnorm=0.823, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65260
2022-09-29 14:50:46 - progress_bar.py[line:274] - INFO: epoch 002:   5919 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.9, wpb=101.2, bsz=40, num_updates=21670, lr=3.7781e-05, gnorm=0.892, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65271
2022-09-29 14:50:57 - progress_bar.py[line:274] - INFO: epoch 002:   5929 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.3, ups=0.88, wpb=100.5, bsz=40, num_updates=21680, lr=3.77744e-05, gnorm=0.773, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65282
2022-09-29 14:51:08 - progress_bar.py[line:274] - INFO: epoch 002:   5939 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.5, ups=0.91, wpb=101.5, bsz=40, num_updates=21690, lr=3.77678e-05, gnorm=0.841, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=65293
2022-09-29 14:51:20 - progress_bar.py[line:274] - INFO: epoch 002:   5949 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.89, wpb=101.3, bsz=40, num_updates=21700, lr=3.77612e-05, gnorm=0.73, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65304
2022-09-29 14:51:31 - progress_bar.py[line:274] - INFO: epoch 002:   5959 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.89, wpb=102.3, bsz=40, num_updates=21710, lr=3.77546e-05, gnorm=0.728, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65316
2022-09-29 14:51:42 - progress_bar.py[line:274] - INFO: epoch 002:   5969 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92, ups=0.9, wpb=102.6, bsz=40, num_updates=21720, lr=3.7748e-05, gnorm=0.854, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=65327
2022-09-29 14:51:53 - progress_bar.py[line:274] - INFO: epoch 002:   5979 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.9, wpb=100.4, bsz=40, num_updates=21730, lr=3.77414e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65338
2022-09-29 14:52:04 - progress_bar.py[line:274] - INFO: epoch 002:   5989 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.9, ups=0.88, wpb=100.3, bsz=40, num_updates=21740, lr=3.77348e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65349
2022-09-29 14:52:15 - progress_bar.py[line:274] - INFO: epoch 002:   5999 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.9, wpb=100.7, bsz=40, num_updates=21750, lr=3.77282e-05, gnorm=0.85, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65360
2022-09-29 14:52:24 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 14:52:28 - progress_bar.py[line:274] - INFO: epoch 002:   6010 / 15783 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=81.3, ups=0.82, wpb=98.8, bsz=40, num_updates=21760, lr=3.77216e-05, gnorm=0.795, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=65372
2022-09-29 14:52:39 - progress_bar.py[line:274] - INFO: epoch 002:   6020 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.4, ups=0.87, wpb=100.7, bsz=40, num_updates=21770, lr=3.7715e-05, gnorm=0.846, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65384
2022-09-29 14:52:50 - progress_bar.py[line:274] - INFO: epoch 002:   6030 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.2, ups=0.9, wpb=100.4, bsz=40, num_updates=21780, lr=3.77084e-05, gnorm=0.701, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65395
2022-09-29 14:53:01 - progress_bar.py[line:274] - INFO: epoch 002:   6040 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.6, ups=0.9, wpb=101.5, bsz=40, num_updates=21790, lr=3.77018e-05, gnorm=0.683, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65406
2022-09-29 14:53:13 - progress_bar.py[line:274] - INFO: epoch 002:   6050 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.88, wpb=101.4, bsz=40, num_updates=21800, lr=3.76952e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65418
2022-09-29 14:53:23 - progress_bar.py[line:274] - INFO: epoch 002:   6060 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.3, ups=0.93, wpb=101.5, bsz=40, num_updates=21810, lr=3.76886e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65428
2022-09-29 14:53:35 - progress_bar.py[line:274] - INFO: epoch 002:   6070 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.9, wpb=100.9, bsz=40, num_updates=21820, lr=3.7682e-05, gnorm=0.808, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65439
2022-09-29 14:53:46 - progress_bar.py[line:274] - INFO: epoch 002:   6080 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90, ups=0.9, wpb=100.2, bsz=40, num_updates=21830, lr=3.76754e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65451
2022-09-29 14:53:57 - progress_bar.py[line:274] - INFO: epoch 002:   6090 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.91, wpb=101.1, bsz=40, num_updates=21840, lr=3.76688e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65461
2022-09-29 14:54:08 - progress_bar.py[line:274] - INFO: epoch 002:   6100 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.1, ups=0.87, wpb=100.4, bsz=40, num_updates=21850, lr=3.76622e-05, gnorm=0.861, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65473
2022-09-29 14:54:20 - progress_bar.py[line:274] - INFO: epoch 002:   6110 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.6, ups=0.88, wpb=98.8, bsz=40, num_updates=21860, lr=3.76556e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65484
2022-09-29 14:54:31 - progress_bar.py[line:274] - INFO: epoch 002:   6120 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.89, wpb=102.6, bsz=40, num_updates=21870, lr=3.7649e-05, gnorm=0.71, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65496
2022-09-29 14:54:42 - progress_bar.py[line:274] - INFO: epoch 002:   6130 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.89, wpb=102.3, bsz=40, num_updates=21880, lr=3.76424e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65507
2022-09-29 14:54:53 - progress_bar.py[line:274] - INFO: epoch 002:   6140 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.9, wpb=102.4, bsz=40, num_updates=21890, lr=3.76358e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65518
2022-09-29 14:55:05 - progress_bar.py[line:274] - INFO: epoch 002:   6150 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.87, wpb=101.7, bsz=40, num_updates=21900, lr=3.76292e-05, gnorm=0.786, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65530
2022-09-29 14:55:16 - progress_bar.py[line:274] - INFO: epoch 002:   6160 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.2, ups=0.91, wpb=103.5, bsz=40, num_updates=21910, lr=3.76226e-05, gnorm=0.774, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65541
2022-09-29 14:55:27 - progress_bar.py[line:274] - INFO: epoch 002:   6170 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=21920, lr=3.7616e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65552
2022-09-29 14:55:39 - progress_bar.py[line:274] - INFO: epoch 002:   6180 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.1, ups=0.86, wpb=102.1, bsz=40, num_updates=21930, lr=3.76094e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=65563
2022-09-29 14:55:51 - progress_bar.py[line:274] - INFO: epoch 002:   6190 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.88, wpb=102.1, bsz=40, num_updates=21940, lr=3.76028e-05, gnorm=0.747, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65576
2022-09-29 14:56:02 - progress_bar.py[line:274] - INFO: epoch 002:   6200 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.8, ups=0.88, wpb=102.2, bsz=40, num_updates=21950, lr=3.75962e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65587
2022-09-29 14:56:14 - progress_bar.py[line:274] - INFO: epoch 002:   6210 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.9, ups=0.88, wpb=98.9, bsz=40, num_updates=21960, lr=3.75896e-05, gnorm=0.664, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65598
2022-09-29 14:56:25 - progress_bar.py[line:274] - INFO: epoch 002:   6220 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.9, ups=0.89, wpb=102.8, bsz=40, num_updates=21970, lr=3.7583e-05, gnorm=0.778, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65610
2022-09-29 14:56:36 - progress_bar.py[line:274] - INFO: epoch 002:   6230 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.3, ups=0.93, wpb=101.1, bsz=40, num_updates=21980, lr=3.75764e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65620
2022-09-29 14:56:47 - progress_bar.py[line:274] - INFO: epoch 002:   6240 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=101.2, bsz=40, num_updates=21990, lr=3.75698e-05, gnorm=0.748, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65632
2022-09-29 14:56:58 - progress_bar.py[line:274] - INFO: epoch 002:   6250 / 15783 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.3, ups=0.89, wpb=99.6, bsz=40, num_updates=22000, lr=3.75632e-05, gnorm=0.92, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65643
2022-09-29 14:57:09 - progress_bar.py[line:274] - INFO: epoch 002:   6260 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.5, ups=0.88, wpb=100.8, bsz=40, num_updates=22010, lr=3.75566e-05, gnorm=0.744, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65654
2022-09-29 14:57:21 - progress_bar.py[line:274] - INFO: epoch 002:   6270 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.88, wpb=102.7, bsz=40, num_updates=22020, lr=3.755e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65666
2022-09-29 14:57:32 - progress_bar.py[line:274] - INFO: epoch 002:   6280 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.88, wpb=102.2, bsz=40, num_updates=22030, lr=3.75434e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65677
2022-09-29 14:57:43 - progress_bar.py[line:274] - INFO: epoch 002:   6290 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.8, ups=0.91, wpb=103.9, bsz=40, num_updates=22040, lr=3.75368e-05, gnorm=0.685, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65688
2022-09-29 14:57:55 - progress_bar.py[line:274] - INFO: epoch 002:   6300 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.1, ups=0.87, wpb=101.5, bsz=40, num_updates=22050, lr=3.75302e-05, gnorm=0.768, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65700
2022-09-29 14:58:06 - progress_bar.py[line:274] - INFO: epoch 002:   6310 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.89, wpb=99.7, bsz=40, num_updates=22060, lr=3.75236e-05, gnorm=0.8, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65711
2022-09-29 14:58:17 - progress_bar.py[line:274] - INFO: epoch 002:   6320 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.89, wpb=100.4, bsz=40, num_updates=22070, lr=3.7517e-05, gnorm=0.816, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65722
2022-09-29 14:58:28 - progress_bar.py[line:274] - INFO: epoch 002:   6330 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.6, ups=0.9, wpb=101.4, bsz=40, num_updates=22080, lr=3.75104e-05, gnorm=0.859, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65733
2022-09-29 14:58:39 - progress_bar.py[line:274] - INFO: epoch 002:   6340 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.92, wpb=101.4, bsz=40, num_updates=22090, lr=3.75038e-05, gnorm=0.917, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65744
2022-09-29 14:58:51 - progress_bar.py[line:274] - INFO: epoch 002:   6350 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.88, wpb=102.1, bsz=40, num_updates=22100, lr=3.74972e-05, gnorm=0.712, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65755
2022-09-29 14:59:02 - progress_bar.py[line:274] - INFO: epoch 002:   6360 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.91, wpb=100.7, bsz=40, num_updates=22110, lr=3.74906e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65766
2022-09-29 14:59:13 - progress_bar.py[line:274] - INFO: epoch 002:   6370 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.6, ups=0.92, wpb=102.2, bsz=40, num_updates=22120, lr=3.7484e-05, gnorm=0.826, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65777
2022-09-29 14:59:24 - progress_bar.py[line:274] - INFO: epoch 002:   6380 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.89, wpb=100.9, bsz=40, num_updates=22130, lr=3.74774e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65789
2022-09-29 14:59:35 - progress_bar.py[line:274] - INFO: epoch 002:   6390 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.6, ups=0.92, wpb=102.6, bsz=40, num_updates=22140, lr=3.74708e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65800
2022-09-29 14:59:46 - progress_bar.py[line:274] - INFO: epoch 002:   6400 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.89, wpb=100.3, bsz=40, num_updates=22150, lr=3.74642e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65811
2022-09-29 14:59:57 - progress_bar.py[line:274] - INFO: epoch 002:   6410 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.92, wpb=100.3, bsz=40, num_updates=22160, lr=3.74576e-05, gnorm=0.858, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65822
2022-09-29 15:00:08 - progress_bar.py[line:274] - INFO: epoch 002:   6420 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88, ups=0.87, wpb=101.3, bsz=40, num_updates=22170, lr=3.7451e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65833
2022-09-29 15:00:19 - progress_bar.py[line:274] - INFO: epoch 002:   6430 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.4, ups=0.93, wpb=101, bsz=40, num_updates=22180, lr=3.74444e-05, gnorm=0.853, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65844
2022-09-29 15:00:30 - progress_bar.py[line:274] - INFO: epoch 002:   6440 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.89, wpb=101.7, bsz=40, num_updates=22190, lr=3.74378e-05, gnorm=0.921, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65855
2022-09-29 15:00:42 - progress_bar.py[line:274] - INFO: epoch 002:   6450 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89, ups=0.88, wpb=101.4, bsz=40, num_updates=22200, lr=3.74312e-05, gnorm=0.927, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65867
2022-09-29 15:00:53 - progress_bar.py[line:274] - INFO: epoch 002:   6460 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=101.5, bsz=40, num_updates=22210, lr=3.74246e-05, gnorm=0.818, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65878
2022-09-29 15:01:04 - progress_bar.py[line:274] - INFO: epoch 002:   6470 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.2, ups=0.9, wpb=102.4, bsz=40, num_updates=22220, lr=3.7418e-05, gnorm=0.759, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65889
2022-09-29 15:01:15 - progress_bar.py[line:274] - INFO: epoch 002:   6480 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.89, wpb=100.4, bsz=40, num_updates=22230, lr=3.74114e-05, gnorm=0.882, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=65900
2022-09-29 15:01:27 - progress_bar.py[line:274] - INFO: epoch 002:   6490 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101.5, bsz=40, num_updates=22240, lr=3.74048e-05, gnorm=0.755, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65911
2022-09-29 15:01:38 - progress_bar.py[line:274] - INFO: epoch 002:   6500 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92, ups=0.9, wpb=102.1, bsz=40, num_updates=22250, lr=3.73982e-05, gnorm=0.781, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65922
2022-09-29 15:01:49 - progress_bar.py[line:274] - INFO: epoch 002:   6510 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.1, ups=0.91, wpb=99.5, bsz=40, num_updates=22260, lr=3.73916e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65933
2022-09-29 15:02:00 - progress_bar.py[line:274] - INFO: epoch 002:   6520 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.8, ups=0.91, wpb=102, bsz=40, num_updates=22270, lr=3.7385e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=65944
2022-09-29 15:02:11 - progress_bar.py[line:274] - INFO: epoch 002:   6530 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.89, wpb=101.7, bsz=40, num_updates=22280, lr=3.73784e-05, gnorm=0.789, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65956
2022-09-29 15:02:22 - progress_bar.py[line:274] - INFO: epoch 002:   6540 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.9, wpb=101.1, bsz=40, num_updates=22290, lr=3.73718e-05, gnorm=0.958, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=65967
2022-09-29 15:02:33 - progress_bar.py[line:274] - INFO: epoch 002:   6550 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.89, wpb=101.1, bsz=40, num_updates=22300, lr=3.73652e-05, gnorm=0.859, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65978
2022-09-29 15:02:42 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 15:02:45 - progress_bar.py[line:274] - INFO: epoch 002:   6561 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=83.6, ups=0.82, wpb=102.6, bsz=40, num_updates=22310, lr=3.73586e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=65990
2022-09-29 15:02:57 - progress_bar.py[line:274] - INFO: epoch 002:   6571 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.7, ups=0.88, wpb=102.1, bsz=40, num_updates=22320, lr=3.7352e-05, gnorm=0.729, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66002
2022-09-29 15:03:08 - progress_bar.py[line:274] - INFO: epoch 002:   6581 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.6, ups=0.9, wpb=100.3, bsz=40, num_updates=22330, lr=3.73454e-05, gnorm=0.851, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66013
2022-09-29 15:03:20 - progress_bar.py[line:274] - INFO: epoch 002:   6591 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.89, wpb=102.9, bsz=40, num_updates=22340, lr=3.73388e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66024
2022-09-29 15:03:30 - progress_bar.py[line:274] - INFO: epoch 002:   6601 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.2, ups=0.92, wpb=101.3, bsz=40, num_updates=22350, lr=3.73322e-05, gnorm=0.84, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66035
2022-09-29 15:03:42 - progress_bar.py[line:274] - INFO: epoch 002:   6611 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.88, wpb=103.2, bsz=40, num_updates=22360, lr=3.73256e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66047
2022-09-29 15:03:52 - progress_bar.py[line:274] - INFO: epoch 002:   6621 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.1, ups=0.93, wpb=100, bsz=40, num_updates=22370, lr=3.7319e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66057
2022-09-29 15:04:03 - progress_bar.py[line:274] - INFO: epoch 002:   6631 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.4, ups=0.92, wpb=101, bsz=40, num_updates=22380, lr=3.73124e-05, gnorm=0.83, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66068
2022-09-29 15:04:15 - progress_bar.py[line:274] - INFO: epoch 002:   6641 / 15783 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.3, ups=0.89, wpb=103.7, bsz=40, num_updates=22390, lr=3.73058e-05, gnorm=0.739, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=66079
2022-09-29 15:04:26 - progress_bar.py[line:274] - INFO: epoch 002:   6651 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.7, ups=0.87, wpb=102.3, bsz=40, num_updates=22400, lr=3.72992e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66091
2022-09-29 15:04:37 - progress_bar.py[line:274] - INFO: epoch 002:   6661 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.9, wpb=100.4, bsz=40, num_updates=22410, lr=3.72926e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66102
2022-09-29 15:04:48 - progress_bar.py[line:274] - INFO: epoch 002:   6671 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.89, wpb=101.4, bsz=40, num_updates=22420, lr=3.7286e-05, gnorm=0.805, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=66113
2022-09-29 15:05:00 - progress_bar.py[line:274] - INFO: epoch 002:   6681 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.2, ups=0.89, wpb=101.4, bsz=40, num_updates=22430, lr=3.72794e-05, gnorm=0.748, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66124
2022-09-29 15:05:11 - progress_bar.py[line:274] - INFO: epoch 002:   6691 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=22440, lr=3.72728e-05, gnorm=0.838, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66136
2022-09-29 15:05:22 - progress_bar.py[line:274] - INFO: epoch 002:   6701 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.9, wpb=101.7, bsz=40, num_updates=22450, lr=3.72662e-05, gnorm=0.747, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66147
2022-09-29 15:05:33 - progress_bar.py[line:274] - INFO: epoch 002:   6711 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87, ups=0.88, wpb=99.1, bsz=40, num_updates=22460, lr=3.72596e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66158
2022-09-29 15:05:44 - progress_bar.py[line:274] - INFO: epoch 002:   6721 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.9, wpb=100.8, bsz=40, num_updates=22470, lr=3.7253e-05, gnorm=0.734, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66169
2022-09-29 15:05:56 - progress_bar.py[line:274] - INFO: epoch 002:   6731 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.9, wpb=101.2, bsz=40, num_updates=22480, lr=3.72464e-05, gnorm=0.769, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66180
2022-09-29 15:06:06 - progress_bar.py[line:274] - INFO: epoch 002:   6741 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.1, ups=0.93, wpb=102, bsz=40, num_updates=22490, lr=3.72398e-05, gnorm=0.815, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66191
2022-09-29 15:06:17 - progress_bar.py[line:274] - INFO: epoch 002:   6751 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.8, ups=0.91, wpb=102.6, bsz=40, num_updates=22500, lr=3.72332e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66202
2022-09-29 15:06:29 - progress_bar.py[line:274] - INFO: epoch 002:   6761 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=87.9, ups=0.88, wpb=100.2, bsz=40, num_updates=22510, lr=3.72266e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66213
2022-09-29 15:06:39 - progress_bar.py[line:274] - INFO: epoch 002:   6771 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.5, ups=0.94, wpb=100.7, bsz=40, num_updates=22520, lr=3.722e-05, gnorm=0.799, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66224
2022-09-29 15:06:51 - progress_bar.py[line:274] - INFO: epoch 002:   6781 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.3, ups=0.88, wpb=100.2, bsz=40, num_updates=22530, lr=3.72134e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=66236
2022-09-29 15:07:02 - progress_bar.py[line:274] - INFO: epoch 002:   6791 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.7, ups=0.89, wpb=99.8, bsz=40, num_updates=22540, lr=3.72068e-05, gnorm=0.741, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66247
2022-09-29 15:07:13 - progress_bar.py[line:274] - INFO: epoch 002:   6801 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.3, ups=0.93, wpb=102.4, bsz=40, num_updates=22550, lr=3.72002e-05, gnorm=0.874, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66258
2022-09-29 15:07:24 - progress_bar.py[line:274] - INFO: epoch 002:   6811 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.3, ups=0.92, wpb=101.8, bsz=40, num_updates=22560, lr=3.71936e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66268
2022-09-29 15:07:35 - progress_bar.py[line:274] - INFO: epoch 002:   6821 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.4, ups=0.88, wpb=102, bsz=40, num_updates=22570, lr=3.7187e-05, gnorm=0.676, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66280
2022-09-29 15:07:46 - progress_bar.py[line:274] - INFO: epoch 002:   6831 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.2, ups=0.92, wpb=101.9, bsz=40, num_updates=22580, lr=3.71804e-05, gnorm=0.813, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66291
2022-09-29 15:07:57 - progress_bar.py[line:274] - INFO: epoch 002:   6841 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.1, ups=0.88, wpb=103.8, bsz=40, num_updates=22590, lr=3.71738e-05, gnorm=0.891, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66302
2022-09-29 15:08:08 - progress_bar.py[line:274] - INFO: epoch 002:   6851 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.8, ups=0.89, wpb=102.9, bsz=40, num_updates=22600, lr=3.71672e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66313
2022-09-29 15:08:20 - progress_bar.py[line:274] - INFO: epoch 002:   6861 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.7, ups=0.88, wpb=99.8, bsz=40, num_updates=22610, lr=3.71606e-05, gnorm=0.905, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66325
2022-09-29 15:08:31 - progress_bar.py[line:274] - INFO: epoch 002:   6871 / 15783 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.6, ups=0.92, wpb=100, bsz=40, num_updates=22620, lr=3.7154e-05, gnorm=0.913, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66336
2022-09-29 15:08:42 - progress_bar.py[line:274] - INFO: epoch 002:   6881 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.2, ups=0.88, wpb=100.6, bsz=40, num_updates=22630, lr=3.71474e-05, gnorm=0.983, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66347
2022-09-29 15:08:54 - progress_bar.py[line:274] - INFO: epoch 002:   6891 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89, ups=0.88, wpb=101.6, bsz=40, num_updates=22640, lr=3.71408e-05, gnorm=0.77, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66358
2022-09-29 15:09:05 - progress_bar.py[line:274] - INFO: epoch 002:   6901 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.5, ups=0.87, wpb=99.9, bsz=40, num_updates=22650, lr=3.71342e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=66370
2022-09-29 15:09:17 - progress_bar.py[line:274] - INFO: epoch 002:   6911 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86.9, ups=0.87, wpb=100.2, bsz=40, num_updates=22660, lr=3.71276e-05, gnorm=0.747, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66382
2022-09-29 15:09:28 - progress_bar.py[line:274] - INFO: epoch 002:   6921 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.6, ups=0.91, wpb=102.4, bsz=40, num_updates=22670, lr=3.7121e-05, gnorm=0.917, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66393
2022-09-29 15:09:39 - progress_bar.py[line:274] - INFO: epoch 002:   6931 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.91, wpb=100.1, bsz=40, num_updates=22680, lr=3.71144e-05, gnorm=0.855, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66404
2022-09-29 15:09:50 - progress_bar.py[line:274] - INFO: epoch 002:   6941 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.88, wpb=102.3, bsz=40, num_updates=22690, lr=3.71078e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66415
2022-09-29 15:10:01 - progress_bar.py[line:274] - INFO: epoch 002:   6951 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.3, ups=0.91, wpb=101.1, bsz=40, num_updates=22700, lr=3.71012e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66426
2022-09-29 15:10:12 - progress_bar.py[line:274] - INFO: epoch 002:   6961 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.89, wpb=102.3, bsz=40, num_updates=22710, lr=3.70946e-05, gnorm=0.843, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66437
2022-09-29 15:10:24 - progress_bar.py[line:274] - INFO: epoch 002:   6971 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.3, ups=0.87, wpb=100.8, bsz=40, num_updates=22720, lr=3.7088e-05, gnorm=0.708, clip=10, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=66449
2022-09-29 15:10:35 - progress_bar.py[line:274] - INFO: epoch 002:   6981 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.91, wpb=100.5, bsz=40, num_updates=22730, lr=3.70814e-05, gnorm=0.768, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66460
2022-09-29 15:10:46 - progress_bar.py[line:274] - INFO: epoch 002:   6991 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.8, ups=0.87, wpb=102.5, bsz=40, num_updates=22740, lr=3.70748e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66471
2022-09-29 15:10:57 - progress_bar.py[line:274] - INFO: epoch 002:   7001 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.91, wpb=101.7, bsz=40, num_updates=22750, lr=3.70682e-05, gnorm=0.821, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66482
2022-09-29 15:11:09 - progress_bar.py[line:274] - INFO: epoch 002:   7011 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.9, wpb=102.8, bsz=40, num_updates=22760, lr=3.70616e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66493
2022-09-29 15:11:20 - progress_bar.py[line:274] - INFO: epoch 002:   7021 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.89, wpb=101.1, bsz=40, num_updates=22770, lr=3.7055e-05, gnorm=0.869, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66505
2022-09-29 15:11:31 - progress_bar.py[line:274] - INFO: epoch 002:   7031 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=86.5, ups=0.87, wpb=99.4, bsz=40, num_updates=22780, lr=3.70484e-05, gnorm=0.816, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=66516
2022-09-29 15:11:43 - progress_bar.py[line:274] - INFO: epoch 002:   7041 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.3, ups=0.87, wpb=103, bsz=40, num_updates=22790, lr=3.70418e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66528
2022-09-29 15:11:54 - progress_bar.py[line:274] - INFO: epoch 002:   7051 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.91, wpb=101.7, bsz=40, num_updates=22800, lr=3.70352e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66539
2022-09-29 15:12:05 - progress_bar.py[line:274] - INFO: epoch 002:   7061 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=98.4, nsentences=40, sample_size=98.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.91, wpb=98.4, bsz=40, num_updates=22810, lr=3.70286e-05, gnorm=1.027, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66550
2022-09-29 15:12:17 - progress_bar.py[line:274] - INFO: epoch 002:   7071 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.3, ups=0.88, wpb=99.5, bsz=40, num_updates=22820, lr=3.7022e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=66562
2022-09-29 15:12:28 - progress_bar.py[line:274] - INFO: epoch 002:   7081 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.9, ups=0.9, wpb=100.2, bsz=40, num_updates=22830, lr=3.70154e-05, gnorm=0.751, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66573
2022-09-29 15:12:39 - progress_bar.py[line:274] - INFO: epoch 002:   7091 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.89, wpb=101.2, bsz=40, num_updates=22840, lr=3.70088e-05, gnorm=0.939, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66584
2022-09-29 15:12:47 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 15:12:51 - progress_bar.py[line:274] - INFO: epoch 002:   7102 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=82.7, ups=0.82, wpb=101.4, bsz=40, num_updates=22850, lr=3.70022e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=66596
2022-09-29 15:13:03 - progress_bar.py[line:274] - INFO: epoch 002:   7112 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.1, ups=0.87, wpb=100.6, bsz=40, num_updates=22860, lr=3.69956e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66608
2022-09-29 15:13:14 - progress_bar.py[line:274] - INFO: epoch 002:   7122 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.9, wpb=100.8, bsz=40, num_updates=22870, lr=3.6989e-05, gnorm=0.767, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=66619
2022-09-29 15:13:25 - progress_bar.py[line:274] - INFO: epoch 002:   7132 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=101.4, bsz=40, num_updates=22880, lr=3.69824e-05, gnorm=0.759, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66630
2022-09-29 15:13:37 - progress_bar.py[line:274] - INFO: epoch 002:   7142 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=22890, lr=3.69758e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66642
2022-09-29 15:13:48 - progress_bar.py[line:274] - INFO: epoch 002:   7152 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.2, ups=0.91, wpb=103.7, bsz=40, num_updates=22900, lr=3.69692e-05, gnorm=0.737, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66653
2022-09-29 15:13:59 - progress_bar.py[line:274] - INFO: epoch 002:   7162 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88, ups=0.88, wpb=100.3, bsz=40, num_updates=22910, lr=3.69626e-05, gnorm=0.871, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66664
2022-09-29 15:14:10 - progress_bar.py[line:274] - INFO: epoch 002:   7172 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91, ups=0.91, wpb=100.5, bsz=40, num_updates=22920, lr=3.6956e-05, gnorm=0.887, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66675
2022-09-29 15:14:21 - progress_bar.py[line:274] - INFO: epoch 002:   7182 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.3, ups=0.9, wpb=100.9, bsz=40, num_updates=22930, lr=3.69494e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66686
2022-09-29 15:14:32 - progress_bar.py[line:274] - INFO: epoch 002:   7192 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93, ups=0.92, wpb=101.2, bsz=40, num_updates=22940, lr=3.69428e-05, gnorm=0.804, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66697
2022-09-29 15:14:44 - progress_bar.py[line:274] - INFO: epoch 002:   7202 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.89, wpb=100, bsz=40, num_updates=22950, lr=3.69362e-05, gnorm=0.92, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66708
2022-09-29 15:14:55 - progress_bar.py[line:274] - INFO: epoch 002:   7212 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.1, ups=0.91, wpb=100, bsz=40, num_updates=22960, lr=3.69296e-05, gnorm=0.952, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66719
2022-09-29 15:15:06 - progress_bar.py[line:274] - INFO: epoch 002:   7222 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.9, wpb=100.8, bsz=40, num_updates=22970, lr=3.6923e-05, gnorm=0.797, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66730
2022-09-29 15:15:17 - progress_bar.py[line:274] - INFO: epoch 002:   7232 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.88, wpb=103.5, bsz=40, num_updates=22980, lr=3.69164e-05, gnorm=0.72, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66742
2022-09-29 15:15:28 - progress_bar.py[line:274] - INFO: epoch 002:   7242 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.89, wpb=101.8, bsz=40, num_updates=22990, lr=3.69098e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66753
2022-09-29 15:15:39 - progress_bar.py[line:274] - INFO: epoch 002:   7252 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.9, wpb=100.8, bsz=40, num_updates=23000, lr=3.69032e-05, gnorm=0.88, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66764
2022-09-29 15:15:50 - progress_bar.py[line:274] - INFO: epoch 002:   7262 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.9, ups=0.91, wpb=100.7, bsz=40, num_updates=23010, lr=3.68966e-05, gnorm=0.821, clip=20, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=66775
2022-09-29 15:16:02 - progress_bar.py[line:274] - INFO: epoch 002:   7272 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.6, ups=0.87, wpb=101, bsz=40, num_updates=23020, lr=3.689e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66787
2022-09-29 15:16:13 - progress_bar.py[line:274] - INFO: epoch 002:   7282 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.89, wpb=99.7, bsz=40, num_updates=23030, lr=3.68834e-05, gnorm=0.766, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66798
2022-09-29 15:16:24 - progress_bar.py[line:274] - INFO: epoch 002:   7292 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=23040, lr=3.68768e-05, gnorm=0.72, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=66809
2022-09-29 15:16:35 - progress_bar.py[line:274] - INFO: epoch 002:   7302 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.1, ups=0.89, wpb=101.8, bsz=40, num_updates=23050, lr=3.68702e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=66820
2022-09-29 15:16:46 - progress_bar.py[line:274] - INFO: epoch 002:   7312 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.92, wpb=101.1, bsz=40, num_updates=23060, lr=3.68636e-05, gnorm=0.825, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66831
2022-09-29 15:16:58 - progress_bar.py[line:274] - INFO: epoch 002:   7322 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.5, ups=0.88, wpb=100.8, bsz=40, num_updates=23070, lr=3.6857e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66843
2022-09-29 15:17:09 - progress_bar.py[line:274] - INFO: epoch 002:   7332 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.2, ups=0.88, wpb=100.5, bsz=40, num_updates=23080, lr=3.68504e-05, gnorm=0.751, clip=0, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=66854
2022-09-29 15:17:20 - progress_bar.py[line:274] - INFO: epoch 002:   7342 / 15783 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.6, ups=0.89, wpb=101.5, bsz=40, num_updates=23090, lr=3.68438e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66865
2022-09-29 15:17:31 - progress_bar.py[line:274] - INFO: epoch 002:   7352 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.8, ups=0.92, wpb=102.4, bsz=40, num_updates=23100, lr=3.68372e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66876
2022-09-29 15:17:43 - progress_bar.py[line:274] - INFO: epoch 002:   7362 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=23110, lr=3.68306e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66888
2022-09-29 15:17:54 - progress_bar.py[line:274] - INFO: epoch 002:   7372 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91, ups=0.89, wpb=102.2, bsz=40, num_updates=23120, lr=3.6824e-05, gnorm=0.765, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=66899
2022-09-29 15:18:05 - progress_bar.py[line:274] - INFO: epoch 002:   7382 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88, ups=0.87, wpb=101.6, bsz=40, num_updates=23130, lr=3.68174e-05, gnorm=0.764, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66910
2022-09-29 15:18:17 - progress_bar.py[line:274] - INFO: epoch 002:   7392 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.89, wpb=101.5, bsz=40, num_updates=23140, lr=3.68108e-05, gnorm=0.731, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=66922
2022-09-29 15:18:28 - progress_bar.py[line:274] - INFO: epoch 002:   7402 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.9, ups=0.91, wpb=100.5, bsz=40, num_updates=23150, lr=3.68042e-05, gnorm=0.719, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66932
2022-09-29 15:18:39 - progress_bar.py[line:274] - INFO: epoch 002:   7412 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.3, ups=0.9, wpb=101.2, bsz=40, num_updates=23160, lr=3.67976e-05, gnorm=0.7, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=66944
2022-09-29 15:18:50 - progress_bar.py[line:274] - INFO: epoch 002:   7422 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.1, ups=0.9, wpb=99.8, bsz=40, num_updates=23170, lr=3.6791e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66955
2022-09-29 15:19:01 - progress_bar.py[line:274] - INFO: epoch 002:   7432 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.1, ups=0.91, wpb=100.7, bsz=40, num_updates=23180, lr=3.67844e-05, gnorm=0.731, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=66966
2022-09-29 15:19:12 - progress_bar.py[line:274] - INFO: epoch 002:   7442 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.91, wpb=102.3, bsz=40, num_updates=23190, lr=3.67778e-05, gnorm=0.707, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66977
2022-09-29 15:19:23 - progress_bar.py[line:274] - INFO: epoch 002:   7452 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.89, wpb=100.4, bsz=40, num_updates=23200, lr=3.67712e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=66988
2022-09-29 15:19:34 - progress_bar.py[line:274] - INFO: epoch 002:   7462 / 15783 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.1, ups=0.9, wpb=101.6, bsz=40, num_updates=23210, lr=3.67646e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66999
2022-09-29 15:19:45 - progress_bar.py[line:274] - INFO: epoch 002:   7472 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=23220, lr=3.6758e-05, gnorm=0.722, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=67010
2022-09-29 15:19:57 - progress_bar.py[line:274] - INFO: epoch 002:   7482 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=88.5, ups=0.88, wpb=100.2, bsz=40, num_updates=23230, lr=3.67514e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67021
2022-09-29 15:20:08 - progress_bar.py[line:274] - INFO: epoch 002:   7492 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.2, ups=0.91, wpb=101.9, bsz=40, num_updates=23240, lr=3.67448e-05, gnorm=0.702, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67032
2022-09-29 15:20:19 - progress_bar.py[line:274] - INFO: epoch 002:   7502 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.1, ups=0.9, wpb=103.6, bsz=40, num_updates=23250, lr=3.67382e-05, gnorm=0.774, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67044
2022-09-29 15:20:30 - progress_bar.py[line:274] - INFO: epoch 002:   7512 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.88, wpb=101.6, bsz=40, num_updates=23260, lr=3.67316e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67055
2022-09-29 15:20:42 - progress_bar.py[line:274] - INFO: epoch 002:   7522 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88, ups=0.87, wpb=101.2, bsz=40, num_updates=23270, lr=3.6725e-05, gnorm=0.761, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67066
2022-09-29 15:20:53 - progress_bar.py[line:274] - INFO: epoch 002:   7532 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.89, wpb=100.6, bsz=40, num_updates=23280, lr=3.67184e-05, gnorm=0.774, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67078
2022-09-29 15:21:04 - progress_bar.py[line:274] - INFO: epoch 002:   7542 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.88, wpb=102.4, bsz=40, num_updates=23290, lr=3.67118e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67089
2022-09-29 15:21:15 - progress_bar.py[line:274] - INFO: epoch 002:   7552 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.9, wpb=100.4, bsz=40, num_updates=23300, lr=3.67052e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67100
2022-09-29 15:21:27 - progress_bar.py[line:274] - INFO: epoch 002:   7562 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.89, wpb=102.7, bsz=40, num_updates=23310, lr=3.66986e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67112
2022-09-29 15:21:38 - progress_bar.py[line:274] - INFO: epoch 002:   7572 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.9, wpb=102.4, bsz=40, num_updates=23320, lr=3.6692e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=67123
2022-09-29 15:21:49 - progress_bar.py[line:274] - INFO: epoch 002:   7582 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.6, ups=0.87, wpb=101.1, bsz=40, num_updates=23330, lr=3.66854e-05, gnorm=0.736, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67134
2022-09-29 15:22:00 - progress_bar.py[line:274] - INFO: epoch 002:   7592 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.9, ups=0.9, wpb=102.7, bsz=40, num_updates=23340, lr=3.66788e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67145
2022-09-29 15:22:12 - progress_bar.py[line:274] - INFO: epoch 002:   7602 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=23350, lr=3.66722e-05, gnorm=0.868, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67156
2022-09-29 15:22:22 - progress_bar.py[line:274] - INFO: epoch 002:   7612 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.1, ups=0.92, wpb=102.6, bsz=40, num_updates=23360, lr=3.66656e-05, gnorm=0.697, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67167
2022-09-29 15:22:34 - progress_bar.py[line:274] - INFO: epoch 002:   7622 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.2, ups=0.87, wpb=100.5, bsz=40, num_updates=23370, lr=3.6659e-05, gnorm=0.824, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67179
2022-09-29 15:22:45 - progress_bar.py[line:274] - INFO: epoch 002:   7632 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.89, wpb=101.2, bsz=40, num_updates=23380, lr=3.66524e-05, gnorm=0.733, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67190
2022-09-29 15:22:57 - progress_bar.py[line:274] - INFO: epoch 002:   7642 / 15783 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=91.3, ups=0.88, wpb=103.5, bsz=40, num_updates=23390, lr=3.66458e-05, gnorm=0.642, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=67201
2022-09-29 15:23:07 - progress_bar.py[line:274] - INFO: epoch 002:   7652 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95, ups=0.94, wpb=101.6, bsz=40, num_updates=23400, lr=3.66392e-05, gnorm=0.769, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67212
2022-09-29 15:23:19 - progress_bar.py[line:274] - INFO: epoch 002:   7662 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.88, wpb=103.1, bsz=40, num_updates=23410, lr=3.66326e-05, gnorm=0.705, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67223
2022-09-29 15:23:30 - progress_bar.py[line:274] - INFO: epoch 002:   7672 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.4, ups=0.91, wpb=102.1, bsz=40, num_updates=23420, lr=3.6626e-05, gnorm=0.698, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67234
2022-09-29 15:23:40 - progress_bar.py[line:274] - INFO: epoch 002:   7682 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.92, wpb=100.8, bsz=40, num_updates=23430, lr=3.66194e-05, gnorm=0.717, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67245
2022-09-29 15:23:51 - progress_bar.py[line:274] - INFO: epoch 002:   7692 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.91, wpb=101.4, bsz=40, num_updates=23440, lr=3.66128e-05, gnorm=0.748, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=67256
2022-09-29 15:24:03 - progress_bar.py[line:274] - INFO: epoch 002:   7702 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.8, ups=0.89, wpb=100.5, bsz=40, num_updates=23450, lr=3.66062e-05, gnorm=0.794, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=67267
2022-09-29 15:24:14 - progress_bar.py[line:274] - INFO: epoch 002:   7712 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.89, wpb=102.4, bsz=40, num_updates=23460, lr=3.65996e-05, gnorm=0.797, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67279
2022-09-29 15:24:25 - progress_bar.py[line:274] - INFO: epoch 002:   7722 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.9, wpb=101.5, bsz=40, num_updates=23470, lr=3.6593e-05, gnorm=0.781, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67290
2022-09-29 15:24:36 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 15:24:37 - progress_bar.py[line:274] - INFO: epoch 002:   7733 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=82.9, ups=0.83, wpb=99.5, bsz=40, num_updates=23480, lr=3.65864e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=67302
2022-09-29 15:24:48 - progress_bar.py[line:274] - INFO: epoch 002:   7743 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.89, wpb=103.7, bsz=40, num_updates=23490, lr=3.65798e-05, gnorm=0.698, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67313
2022-09-29 15:24:59 - progress_bar.py[line:274] - INFO: epoch 002:   7753 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91.2, ups=0.9, wpb=101, bsz=40, num_updates=23500, lr=3.65732e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67324
2022-09-29 15:25:11 - progress_bar.py[line:274] - INFO: epoch 002:   7763 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.89, wpb=101.1, bsz=40, num_updates=23510, lr=3.65666e-05, gnorm=0.826, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67335
2022-09-29 15:25:22 - progress_bar.py[line:274] - INFO: epoch 002:   7773 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.3, ups=0.9, wpb=101.7, bsz=40, num_updates=23520, lr=3.656e-05, gnorm=0.794, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=67347
2022-09-29 15:25:33 - progress_bar.py[line:274] - INFO: epoch 002:   7783 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.2, ups=0.89, wpb=100.1, bsz=40, num_updates=23530, lr=3.65534e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67358
2022-09-29 15:25:44 - progress_bar.py[line:274] - INFO: epoch 002:   7793 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91, ups=0.9, wpb=101, bsz=40, num_updates=23540, lr=3.65468e-05, gnorm=0.894, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67369
2022-09-29 15:25:55 - progress_bar.py[line:274] - INFO: epoch 002:   7803 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.5, ups=0.89, wpb=102.2, bsz=40, num_updates=23550, lr=3.65402e-05, gnorm=0.769, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67380
2022-09-29 15:26:07 - progress_bar.py[line:274] - INFO: epoch 002:   7813 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.88, wpb=100.4, bsz=40, num_updates=23560, lr=3.65336e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67391
2022-09-29 15:26:18 - progress_bar.py[line:274] - INFO: epoch 002:   7823 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.89, wpb=101.6, bsz=40, num_updates=23570, lr=3.6527e-05, gnorm=0.799, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67403
2022-09-29 15:26:28 - progress_bar.py[line:274] - INFO: epoch 002:   7833 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.1, ups=0.94, wpb=101.1, bsz=40, num_updates=23580, lr=3.65204e-05, gnorm=0.75, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67413
2022-09-29 15:26:40 - progress_bar.py[line:274] - INFO: epoch 002:   7843 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.5, ups=0.87, wpb=101.8, bsz=40, num_updates=23590, lr=3.65138e-05, gnorm=0.712, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67425
2022-09-29 15:26:51 - progress_bar.py[line:274] - INFO: epoch 002:   7853 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.91, wpb=100.4, bsz=40, num_updates=23600, lr=3.65072e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=67436
2022-09-29 15:27:02 - progress_bar.py[line:274] - INFO: epoch 002:   7863 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.88, wpb=100.2, bsz=40, num_updates=23610, lr=3.65006e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=67447
2022-09-29 15:27:13 - progress_bar.py[line:274] - INFO: epoch 002:   7873 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.9, wpb=101, bsz=40, num_updates=23620, lr=3.6494e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67458
2022-09-29 15:27:25 - progress_bar.py[line:274] - INFO: epoch 002:   7883 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.3, ups=0.89, wpb=101, bsz=40, num_updates=23630, lr=3.64874e-05, gnorm=0.732, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67469
2022-09-29 15:27:36 - progress_bar.py[line:274] - INFO: epoch 002:   7893 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.6, ups=0.88, wpb=100.7, bsz=40, num_updates=23640, lr=3.64808e-05, gnorm=0.73, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=67481
2022-09-29 15:27:47 - progress_bar.py[line:274] - INFO: epoch 002:   7903 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.9, ups=0.91, wpb=102.5, bsz=40, num_updates=23650, lr=3.64742e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67492
2022-09-29 15:27:58 - progress_bar.py[line:274] - INFO: epoch 002:   7913 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.89, wpb=102.4, bsz=40, num_updates=23660, lr=3.64676e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67503
2022-09-29 15:28:09 - progress_bar.py[line:274] - INFO: epoch 002:   7923 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.9, ups=0.91, wpb=102.7, bsz=40, num_updates=23670, lr=3.6461e-05, gnorm=0.768, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67514
2022-09-29 15:28:21 - progress_bar.py[line:274] - INFO: epoch 002:   7933 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.2, ups=0.88, wpb=101.5, bsz=40, num_updates=23680, lr=3.64544e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67525
2022-09-29 15:28:32 - progress_bar.py[line:274] - INFO: epoch 002:   7943 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.7, ups=0.87, wpb=101.7, bsz=40, num_updates=23690, lr=3.64478e-05, gnorm=0.808, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67537
2022-09-29 15:28:43 - progress_bar.py[line:274] - INFO: epoch 002:   7953 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.88, wpb=102.1, bsz=40, num_updates=23700, lr=3.64412e-05, gnorm=0.681, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67548
2022-09-29 15:28:55 - progress_bar.py[line:274] - INFO: epoch 002:   7963 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=23710, lr=3.64346e-05, gnorm=0.778, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67559
2022-09-29 15:29:05 - progress_bar.py[line:274] - INFO: epoch 002:   7973 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.8, ups=0.93, wpb=102.8, bsz=40, num_updates=23720, lr=3.6428e-05, gnorm=0.654, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67570
2022-09-29 15:29:17 - progress_bar.py[line:274] - INFO: epoch 002:   7983 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.7, ups=0.88, wpb=99.7, bsz=40, num_updates=23730, lr=3.64214e-05, gnorm=0.816, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67581
2022-09-29 15:29:28 - progress_bar.py[line:274] - INFO: epoch 002:   7993 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.1, ups=0.91, wpb=102.5, bsz=40, num_updates=23740, lr=3.64148e-05, gnorm=0.721, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67592
2022-09-29 15:29:39 - progress_bar.py[line:274] - INFO: epoch 002:   8003 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.9, wpb=100.8, bsz=40, num_updates=23750, lr=3.64082e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67604
2022-09-29 15:29:50 - progress_bar.py[line:274] - INFO: epoch 002:   8013 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.91, wpb=100.6, bsz=40, num_updates=23760, lr=3.64016e-05, gnorm=0.826, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67615
2022-09-29 15:30:01 - progress_bar.py[line:274] - INFO: epoch 002:   8023 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.91, wpb=101, bsz=40, num_updates=23770, lr=3.6395e-05, gnorm=0.646, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67626
2022-09-29 15:30:12 - progress_bar.py[line:274] - INFO: epoch 002:   8033 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=101.3, bsz=40, num_updates=23780, lr=3.63884e-05, gnorm=0.746, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=67637
2022-09-29 15:30:24 - progress_bar.py[line:274] - INFO: epoch 002:   8043 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.7, ups=0.88, wpb=100.1, bsz=40, num_updates=23790, lr=3.63818e-05, gnorm=0.725, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67648
2022-09-29 15:30:35 - progress_bar.py[line:274] - INFO: epoch 002:   8053 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=85.9, ups=0.87, wpb=99.2, bsz=40, num_updates=23800, lr=3.63752e-05, gnorm=0.932, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67660
2022-09-29 15:30:46 - progress_bar.py[line:274] - INFO: epoch 002:   8063 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.9, wpb=101.7, bsz=40, num_updates=23810, lr=3.63686e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67671
2022-09-29 15:30:58 - progress_bar.py[line:274] - INFO: epoch 002:   8073 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.9, ups=0.89, wpb=102.7, bsz=40, num_updates=23820, lr=3.6362e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67682
2022-09-29 15:31:09 - progress_bar.py[line:274] - INFO: epoch 002:   8083 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88, ups=0.88, wpb=99.7, bsz=40, num_updates=23830, lr=3.63554e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67694
2022-09-29 15:31:20 - progress_bar.py[line:274] - INFO: epoch 002:   8093 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.9, wpb=99.5, bsz=40, num_updates=23840, lr=3.63488e-05, gnorm=0.778, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=67705
2022-09-29 15:31:31 - progress_bar.py[line:274] - INFO: epoch 002:   8103 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.9, ups=0.88, wpb=101.9, bsz=40, num_updates=23850, lr=3.63422e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=67716
2022-09-29 15:31:43 - progress_bar.py[line:274] - INFO: epoch 002:   8113 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.89, wpb=100.7, bsz=40, num_updates=23860, lr=3.63356e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67727
2022-09-29 15:31:54 - progress_bar.py[line:274] - INFO: epoch 002:   8123 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.89, wpb=101.5, bsz=40, num_updates=23870, lr=3.6329e-05, gnorm=0.793, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67739
2022-09-29 15:32:05 - progress_bar.py[line:274] - INFO: epoch 002:   8133 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.92, wpb=99.4, bsz=40, num_updates=23880, lr=3.63224e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67749
2022-09-29 15:32:16 - progress_bar.py[line:274] - INFO: epoch 002:   8143 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.91, wpb=101.3, bsz=40, num_updates=23890, lr=3.63158e-05, gnorm=0.773, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=67760
2022-09-29 15:32:27 - progress_bar.py[line:274] - INFO: epoch 002:   8153 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.7, ups=0.89, wpb=101.6, bsz=40, num_updates=23900, lr=3.63092e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67772
2022-09-29 15:32:38 - progress_bar.py[line:274] - INFO: epoch 002:   8163 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.9, wpb=100.4, bsz=40, num_updates=23910, lr=3.63026e-05, gnorm=0.732, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=67783
2022-09-29 15:32:49 - progress_bar.py[line:274] - INFO: epoch 002:   8173 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=23920, lr=3.6296e-05, gnorm=0.761, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67794
2022-09-29 15:33:00 - progress_bar.py[line:274] - INFO: epoch 002:   8183 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=23930, lr=3.62894e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67805
2022-09-29 15:33:12 - progress_bar.py[line:274] - INFO: epoch 002:   8193 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.8, ups=0.88, wpb=100, bsz=40, num_updates=23940, lr=3.62828e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67817
2022-09-29 15:33:23 - progress_bar.py[line:274] - INFO: epoch 002:   8203 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.9, wpb=101.3, bsz=40, num_updates=23950, lr=3.62762e-05, gnorm=0.862, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67828
2022-09-29 15:33:34 - progress_bar.py[line:274] - INFO: epoch 002:   8213 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.9, wpb=101.6, bsz=40, num_updates=23960, lr=3.62696e-05, gnorm=0.779, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=67839
2022-09-29 15:33:46 - progress_bar.py[line:274] - INFO: epoch 002:   8223 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.3, ups=0.87, wpb=100.7, bsz=40, num_updates=23970, lr=3.6263e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67850
2022-09-29 15:33:57 - progress_bar.py[line:274] - INFO: epoch 002:   8233 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.9, wpb=102.4, bsz=40, num_updates=23980, lr=3.62564e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67862
2022-09-29 15:34:08 - progress_bar.py[line:274] - INFO: epoch 002:   8243 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.89, wpb=101.7, bsz=40, num_updates=23990, lr=3.62498e-05, gnorm=0.833, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=67873
2022-09-29 15:34:19 - progress_bar.py[line:274] - INFO: epoch 002:   8253 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92, ups=0.89, wpb=102.9, bsz=40, num_updates=24000, lr=3.62432e-05, gnorm=0.769, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=67884
2022-09-29 15:34:19 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-29 15:34:20 - train.py[line:549] - INFO: 0 / 14103
2022-09-29 15:34:20 - train.py[line:551] - INFO: load:0.68 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-29 15:34:21 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.82 GiB (GPU 0; 39.59 GiB total capacity; 12.88 GiB already allocated; 1.83 GiB free; 35.28 GiB reserved in total by PyTorch)
2022-09-29 15:34:21 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 33        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13190 MB |   16992 MB |    9094 TB |    9094 TB |
|       from large pool |   13046 MB |   16847 MB |    9090 TB |    9090 TB |
|       from small pool |     144 MB |     145 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13190 MB |   16992 MB |    9094 TB |    9094 TB |
|       from large pool |   13046 MB |   16847 MB |    9090 TB |    9090 TB |
|       from small pool |     144 MB |     145 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36128 MB |   37400 MB |  397446 MB |  361318 MB |
|       from large pool |   35982 MB |   37254 MB |  396826 MB |  360844 MB |
|       from small pool |     146 MB |     146 MB |     620 MB |     474 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22937 MB |   26479 MB |   10549 TB |   10549 TB |
|       from large pool |   22935 MB |   26477 MB |   10545 TB |   10545 TB |
|       from small pool |       1 MB |       1 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3660    |    3684    |  472112 K  |  472109 K  |
|       from large pool |     564    |     585    |  143015 K  |  143015 K  |
|       from small pool |    3096    |    3114    |  329096 K  |  329093 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3660    |    3684    |  472112 K  |  472109 K  |
|       from large pool |     564    |     585    |  143015 K  |  143015 K  |
|       from small pool |    3096    |    3114    |  329096 K  |  329093 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     147    |     151    |     828    |     681    |
|       from large pool |      74    |      78    |     518    |     444    |
|       from small pool |      73    |      73    |     310    |     237    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     106    |     108    |  347073 K  |  347072 K  |
|       from large pool |      65    |      67    |   67757 K  |   67757 K  |
|       from small pool |      41    |      48    |  279315 K  |  279315 K  |
|===========================================================================|

2022-09-29 15:34:21 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-29 15:34:21 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-29 15:34:31 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.71 GiB (GPU 1; 39.59 GiB total capacity; 12.70 GiB already allocated; 1.39 GiB free; 35.72 GiB reserved in total by PyTorch)
2022-09-29 15:34:31 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-29 15:34:31 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 28        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13007 MB |   16729 MB |    9137 TB |    9137 TB |
|       from large pool |   12862 MB |   16584 MB |    9133 TB |    9133 TB |
|       from small pool |     144 MB |     145 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13007 MB |   16729 MB |    9137 TB |    9137 TB |
|       from large pool |   12862 MB |   16584 MB |    9133 TB |    9133 TB |
|       from small pool |     144 MB |     145 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36574 MB |   36574 MB |  300394 MB |  263820 MB |
|       from large pool |   36428 MB |   36428 MB |  299778 MB |  263350 MB |
|       from small pool |     146 MB |     146 MB |     616 MB |     470 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23566 MB |   23566 MB |    9260 TB |    9260 TB |
|       from large pool |   23565 MB |   23565 MB |    9256 TB |    9256 TB |
|       from small pool |       1 MB |       1 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3671    |    3695    |  472168 K  |  472165 K  |
|       from large pool |     564    |     585    |  143046 K  |  143046 K  |
|       from small pool |    3107    |    3116    |  329121 K  |  329118 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3671    |    3695    |  472168 K  |  472165 K  |
|       from large pool |     564    |     585    |  143046 K  |  143046 K  |
|       from small pool |    3107    |    3116    |  329121 K  |  329118 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     138    |     138    |     757    |     619    |
|       from large pool |      65    |      65    |     449    |     384    |
|       from small pool |      73    |      73    |     308    |     235    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      89    |      92    |  343915 K  |  343915 K  |
|       from large pool |      53    |      55    |   63824 K  |   63824 K  |
|       from small pool |      36    |      46    |  280090 K  |  280090 K  |
|===========================================================================|

2022-09-29 15:34:31 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-29 15:37:36 - train.py[line:549] - INFO: 200 / 14103
2022-09-29 15:37:36 - train.py[line:551] - INFO: load:0.70 valid_run:196.08 task_valid:185.62 collect_output:7.85
2022-09-29 15:40:46 - train.py[line:549] - INFO: 400 / 14103
2022-09-29 15:40:46 - train.py[line:551] - INFO: load:0.73 valid_run:385.32 task_valid:369.59 collect_output:11.99
2022-09-29 15:43:56 - train.py[line:549] - INFO: 600 / 14103
2022-09-29 15:43:56 - train.py[line:551] - INFO: load:0.75 valid_run:575.69 task_valid:553.46 collect_output:17.28
2022-09-29 15:47:07 - train.py[line:549] - INFO: 800 / 14103
2022-09-29 15:47:07 - train.py[line:551] - INFO: load:0.77 valid_run:766.50 task_valid:739.39 collect_output:20.89
2022-09-29 15:50:18 - train.py[line:549] - INFO: 1000 / 14103
2022-09-29 15:50:18 - train.py[line:551] - INFO: load:0.80 valid_run:957.82 task_valid:925.57 collect_output:24.81
2022-09-29 15:53:32 - train.py[line:549] - INFO: 1200 / 14103
2022-09-29 15:53:32 - train.py[line:551] - INFO: load:0.82 valid_run:1151.09 task_valid:1112.60 collect_output:29.87
2022-09-29 15:56:46 - train.py[line:549] - INFO: 1400 / 14103
2022-09-29 15:56:46 - train.py[line:551] - INFO: load:0.84 valid_run:1345.60 task_valid:1302.24 collect_output:33.46
2022-09-29 16:00:00 - train.py[line:549] - INFO: 1600 / 14103
2022-09-29 16:00:00 - train.py[line:551] - INFO: load:0.87 valid_run:1539.06 task_valid:1491.40 collect_output:36.59
2022-09-29 16:03:13 - train.py[line:549] - INFO: 1800 / 14103
2022-09-29 16:03:13 - train.py[line:551] - INFO: load:0.89 valid_run:1732.49 task_valid:1677.51 collect_output:42.79
2022-09-29 16:06:23 - train.py[line:549] - INFO: 2000 / 14103
2022-09-29 16:06:23 - train.py[line:551] - INFO: load:0.91 valid_run:1921.99 task_valid:1863.49 collect_output:45.14
2022-09-29 16:09:32 - train.py[line:549] - INFO: 2200 / 14103
2022-09-29 16:09:32 - train.py[line:551] - INFO: load:0.94 valid_run:2111.36 task_valid:2048.42 collect_output:48.44
2022-09-29 16:12:44 - train.py[line:549] - INFO: 2400 / 14103
2022-09-29 16:12:44 - train.py[line:551] - INFO: load:0.96 valid_run:2303.55 task_valid:2233.39 collect_output:54.49
2022-09-29 16:15:57 - train.py[line:549] - INFO: 2600 / 14103
2022-09-29 16:15:57 - train.py[line:551] - INFO: load:0.98 valid_run:2496.53 task_valid:2422.44 collect_output:57.36
2022-09-29 16:19:08 - train.py[line:549] - INFO: 2800 / 14103
2022-09-29 16:19:08 - train.py[line:551] - INFO: load:1.00 valid_run:2686.94 task_valid:2607.24 collect_output:61.84
2022-09-29 16:22:22 - train.py[line:549] - INFO: 3000 / 14103
2022-09-29 16:22:22 - train.py[line:551] - INFO: load:1.03 valid_run:2881.22 task_valid:2793.75 collect_output:68.43
2022-09-29 16:25:32 - train.py[line:549] - INFO: 3200 / 14103
2022-09-29 16:25:32 - train.py[line:551] - INFO: load:1.05 valid_run:3071.21 task_valid:2976.40 collect_output:74.68
2022-09-29 16:28:46 - train.py[line:549] - INFO: 3400 / 14103
2022-09-29 16:28:46 - train.py[line:551] - INFO: load:1.07 valid_run:3264.83 task_valid:3160.91 collect_output:82.63
2022-09-29 16:32:00 - train.py[line:549] - INFO: 3600 / 14103
2022-09-29 16:32:00 - train.py[line:551] - INFO: load:1.09 valid_run:3458.96 task_valid:3347.48 collect_output:89.01
2022-09-29 16:35:12 - train.py[line:549] - INFO: 3800 / 14103
2022-09-29 16:35:12 - train.py[line:551] - INFO: load:1.12 valid_run:3650.66 task_valid:3530.14 collect_output:96.94
2022-09-29 16:38:20 - train.py[line:549] - INFO: 4000 / 14103
2022-09-29 16:38:20 - train.py[line:551] - INFO: load:1.14 valid_run:3839.21 task_valid:3713.13 collect_output:101.36
2022-09-29 16:41:32 - train.py[line:549] - INFO: 4200 / 14103
2022-09-29 16:41:32 - train.py[line:551] - INFO: load:1.16 valid_run:4030.61 task_valid:3901.73 collect_output:103.04
2022-09-29 16:44:40 - train.py[line:549] - INFO: 4400 / 14103
2022-09-29 16:44:40 - train.py[line:551] - INFO: load:1.19 valid_run:4218.89 task_valid:4082.68 collect_output:109.26
2022-09-29 16:47:53 - train.py[line:549] - INFO: 4600 / 14103
2022-09-29 16:47:53 - train.py[line:551] - INFO: load:1.21 valid_run:4411.40 task_valid:4267.88 collect_output:115.45
2022-09-29 16:51:02 - train.py[line:549] - INFO: 4800 / 14103
2022-09-29 16:51:02 - train.py[line:551] - INFO: load:1.23 valid_run:4600.25 task_valid:4451.47 collect_output:119.61
2022-09-29 16:54:12 - train.py[line:549] - INFO: 5000 / 14103
2022-09-29 16:54:12 - train.py[line:551] - INFO: load:1.26 valid_run:4790.54 task_valid:4636.55 collect_output:123.65
2022-09-29 16:57:22 - train.py[line:549] - INFO: 5200 / 14103
2022-09-29 16:57:22 - train.py[line:551] - INFO: load:1.28 valid_run:4980.46 task_valid:4820.62 collect_output:128.31
2022-09-29 17:00:35 - train.py[line:549] - INFO: 5400 / 14103
2022-09-29 17:00:35 - train.py[line:551] - INFO: load:1.31 valid_run:5173.24 task_valid:5009.80 collect_output:130.75
2022-09-29 17:03:47 - train.py[line:549] - INFO: 5600 / 14103
2022-09-29 17:03:47 - train.py[line:551] - INFO: load:1.33 valid_run:5365.16 task_valid:5197.12 collect_output:134.22
2022-09-29 17:07:00 - train.py[line:549] - INFO: 5800 / 14103
2022-09-29 17:07:00 - train.py[line:551] - INFO: load:1.36 valid_run:5558.71 task_valid:5383.75 collect_output:140.11
2022-09-29 17:10:08 - train.py[line:549] - INFO: 6000 / 14103
2022-09-29 17:10:08 - train.py[line:551] - INFO: load:1.38 valid_run:5746.38 task_valid:5564.49 collect_output:146.04
2022-09-29 17:13:20 - train.py[line:549] - INFO: 6200 / 14103
2022-09-29 17:13:20 - train.py[line:551] - INFO: load:1.40 valid_run:5938.24 task_valid:5749.80 collect_output:151.56
2022-09-29 17:16:30 - train.py[line:549] - INFO: 6400 / 14103
2022-09-29 17:16:30 - train.py[line:551] - INFO: load:1.42 valid_run:6128.10 task_valid:5934.86 collect_output:155.34
2022-09-29 17:19:39 - train.py[line:549] - INFO: 6600 / 14103
2022-09-29 17:19:39 - train.py[line:551] - INFO: load:1.45 valid_run:6316.87 task_valid:6115.92 collect_output:162.03
2022-09-29 17:22:51 - train.py[line:549] - INFO: 6800 / 14103
2022-09-29 17:22:51 - train.py[line:551] - INFO: load:1.47 valid_run:6509.18 task_valid:6299.59 collect_output:169.64
2022-09-29 17:26:04 - train.py[line:549] - INFO: 7000 / 14103
2022-09-29 17:26:04 - train.py[line:551] - INFO: load:1.49 valid_run:6701.94 task_valid:6488.25 collect_output:172.71
2022-09-29 17:29:17 - train.py[line:549] - INFO: 7200 / 14103
2022-09-29 17:29:17 - train.py[line:551] - INFO: load:1.51 valid_run:6894.41 task_valid:6677.39 collect_output:175.04
2022-09-29 17:32:27 - train.py[line:549] - INFO: 7400 / 14103
2022-09-29 17:32:27 - train.py[line:551] - INFO: load:1.54 valid_run:7084.80 task_valid:6859.08 collect_output:182.70
2022-09-29 17:35:36 - train.py[line:549] - INFO: 7600 / 14103
2022-09-29 17:35:36 - train.py[line:551] - INFO: load:1.56 valid_run:7273.35 task_valid:7039.58 collect_output:189.74
2022-09-29 17:38:50 - train.py[line:549] - INFO: 7800 / 14103
2022-09-29 17:38:50 - train.py[line:551] - INFO: load:1.58 valid_run:7467.79 task_valid:7226.14 collect_output:196.62
2022-09-29 17:42:00 - train.py[line:549] - INFO: 8000 / 14103
2022-09-29 17:42:00 - train.py[line:551] - INFO: load:1.60 valid_run:7657.14 task_valid:7405.29 collect_output:205.80
2022-09-29 17:45:08 - train.py[line:549] - INFO: 8200 / 14103
2022-09-29 17:45:08 - train.py[line:551] - INFO: load:1.63 valid_run:7845.81 task_valid:7588.52 collect_output:210.22
2022-09-29 17:48:17 - train.py[line:549] - INFO: 8400 / 14103
2022-09-29 17:48:17 - train.py[line:551] - INFO: load:1.65 valid_run:8034.23 task_valid:7770.80 collect_output:215.33
2022-09-29 17:51:27 - train.py[line:549] - INFO: 8600 / 14103
2022-09-29 17:51:27 - train.py[line:551] - INFO: load:1.68 valid_run:8224.89 task_valid:7954.98 collect_output:220.78
2022-09-29 17:54:37 - train.py[line:549] - INFO: 8800 / 14103
2022-09-29 17:54:37 - train.py[line:551] - INFO: load:1.70 valid_run:8413.88 task_valid:8140.03 collect_output:223.57
2022-09-29 17:57:48 - train.py[line:549] - INFO: 9000 / 14103
2022-09-29 17:57:48 - train.py[line:551] - INFO: load:1.72 valid_run:8605.29 task_valid:8323.98 collect_output:229.92
2022-09-29 18:01:03 - train.py[line:549] - INFO: 9200 / 14103
2022-09-29 18:01:03 - train.py[line:551] - INFO: load:1.75 valid_run:8800.02 task_valid:8507.20 collect_output:240.26
2022-09-29 18:04:17 - train.py[line:549] - INFO: 9400 / 14103
2022-09-29 18:04:17 - train.py[line:551] - INFO: load:1.77 valid_run:8993.84 task_valid:8694.68 collect_output:245.42
2022-09-29 18:07:28 - train.py[line:549] - INFO: 9600 / 14103
2022-09-29 18:07:28 - train.py[line:551] - INFO: load:1.80 valid_run:9185.60 task_valid:8879.09 collect_output:251.68
2022-09-29 18:10:40 - train.py[line:549] - INFO: 9800 / 14103
2022-09-29 18:10:40 - train.py[line:551] - INFO: load:1.82 valid_run:9377.03 task_valid:9067.88 collect_output:253.19
2022-09-29 18:13:52 - train.py[line:549] - INFO: 10000 / 14103
2022-09-29 18:13:52 - train.py[line:551] - INFO: load:1.84 valid_run:9568.87 task_valid:9256.29 collect_output:255.50
2022-09-29 18:17:02 - train.py[line:549] - INFO: 10200 / 14103
2022-09-29 18:17:02 - train.py[line:551] - INFO: load:1.87 valid_run:9759.05 task_valid:9439.05 collect_output:261.91
2022-09-29 18:20:14 - train.py[line:549] - INFO: 10400 / 14103
2022-09-29 18:20:14 - train.py[line:551] - INFO: load:1.89 valid_run:9950.95 task_valid:9622.76 collect_output:269.08
2022-09-29 18:23:26 - train.py[line:549] - INFO: 10600 / 14103
2022-09-29 18:23:26 - train.py[line:551] - INFO: load:1.91 valid_run:10143.31 task_valid:9804.60 collect_output:278.59
2022-09-29 18:26:38 - train.py[line:549] - INFO: 10800 / 14103
2022-09-29 18:26:38 - train.py[line:551] - INFO: load:1.94 valid_run:10334.61 task_valid:9988.18 collect_output:285.28
2022-09-29 18:29:49 - train.py[line:549] - INFO: 11000 / 14103
2022-09-29 18:29:49 - train.py[line:551] - INFO: load:1.96 valid_run:10525.84 task_valid:10172.88 collect_output:290.80
2022-09-29 18:33:01 - train.py[line:549] - INFO: 11200 / 14103
2022-09-29 18:33:01 - train.py[line:551] - INFO: load:1.98 valid_run:10717.35 task_valid:10356.98 collect_output:297.18
2022-09-29 18:36:15 - train.py[line:549] - INFO: 11400 / 14103
2022-09-29 18:36:15 - train.py[line:551] - INFO: load:2.00 valid_run:10911.77 task_valid:10547.93 collect_output:299.62
2022-09-29 18:39:25 - train.py[line:549] - INFO: 11600 / 14103
2022-09-29 18:39:25 - train.py[line:551] - INFO: load:2.03 valid_run:11101.13 task_valid:10732.61 collect_output:303.29
2022-09-29 18:42:36 - train.py[line:549] - INFO: 11800 / 14103
2022-09-29 18:42:36 - train.py[line:551] - INFO: load:2.05 valid_run:11292.24 task_valid:10918.78 collect_output:307.22
2022-09-29 18:45:45 - train.py[line:549] - INFO: 12000 / 14103
2022-09-29 18:45:45 - train.py[line:551] - INFO: load:2.07 valid_run:11481.48 task_valid:11101.79 collect_output:312.44
2022-09-29 18:48:55 - train.py[line:549] - INFO: 12200 / 14103
2022-09-29 18:48:55 - train.py[line:551] - INFO: load:2.09 valid_run:11671.88 task_valid:11286.68 collect_output:316.93
2022-09-29 18:52:06 - train.py[line:549] - INFO: 12400 / 14103
2022-09-29 18:52:06 - train.py[line:551] - INFO: load:2.12 valid_run:11862.74 task_valid:11471.70 collect_output:321.74
2022-09-29 18:55:17 - train.py[line:549] - INFO: 12600 / 14103
2022-09-29 18:55:17 - train.py[line:551] - INFO: load:2.14 valid_run:12052.86 task_valid:11655.16 collect_output:327.37
2022-09-29 18:58:24 - train.py[line:549] - INFO: 12800 / 14103
2022-09-29 18:58:24 - train.py[line:551] - INFO: load:2.17 valid_run:12239.79 task_valid:11837.19 collect_output:331.27
2022-09-29 19:01:34 - train.py[line:549] - INFO: 13000 / 14103
2022-09-29 19:01:34 - train.py[line:551] - INFO: load:2.19 valid_run:12430.18 task_valid:12021.01 collect_output:336.74
2022-09-29 19:04:45 - train.py[line:549] - INFO: 13200 / 14103
2022-09-29 19:04:45 - train.py[line:551] - INFO: load:2.22 valid_run:12620.74 task_valid:12202.87 collect_output:344.15
2022-09-29 19:07:58 - train.py[line:549] - INFO: 13400 / 14103
2022-09-29 19:07:58 - train.py[line:551] - INFO: load:2.25 valid_run:12814.39 task_valid:12385.66 collect_output:353.91
2022-09-29 19:11:09 - train.py[line:549] - INFO: 13600 / 14103
2022-09-29 19:11:09 - train.py[line:551] - INFO: load:2.29 valid_run:13005.33 task_valid:12567.33 collect_output:362.10
2022-09-29 19:14:22 - train.py[line:549] - INFO: 13800 / 14103
2022-09-29 19:14:22 - train.py[line:551] - INFO: load:2.31 valid_run:13197.78 task_valid:12754.07 collect_output:366.71
2022-09-29 19:17:34 - train.py[line:549] - INFO: 14000 / 14103
2022-09-29 19:17:34 - train.py[line:551] - INFO: load:2.34 valid_run:13390.29 task_valid:12939.81 collect_output:372.39
2022-09-29 19:19:11 - train.py[line:572] - INFO: scores:torch.Size([282060]) preds:torch.Size([282060]) sample_ids:torch.Size([282060])

====================================================================================================
SGG eval:     R @ 50: 0.6508;     R @ 100: 0.6684;     R @ 500: 0.6738;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2219;    mR @ 100: 0.2334;    mR @ 500: 0.2401;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1331) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2404) (attached to:0.0000) (behind:0.4000) (belonging to:0.0000) (between:0.0000) (carrying:0.7560) (covered in:0.6667) (covering:0.0000) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0385) (has:0.7779) (holding:0.3023) (in:0.3538) (in front of:0.1681) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.6255) (of:0.4548) (on:0.8881) (on back of:0.0000) (over:0.1111) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6667) (says:0.0000) (sitting on:0.3675) (standing on:0.0769) (to:0.0000) (under:0.3796) (using:1.0000) (walking in:0.0000) (walking on:0.5620) (watching:0.3333) (wearing:0.9869) (wears:0.0000) (with:0.1300) 
--------------------------------------------------------
====================================================================================================

2022-09-29 19:19:31 - train.py[line:486] - INFO: 0.6683650048732487

====================================================================================================
SGG eval:     R @ 50: 0.6508;     R @ 100: 0.6684;     R @ 500: 0.6738;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2219;    mR @ 100: 0.2334;    mR @ 500: 0.2401;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1331) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2404) (attached to:0.0000) (behind:0.4000) (belonging to:0.0000) (between:0.0000) (carrying:0.7560) (covered in:0.6667) (covering:0.0000) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0385) (has:0.7779) (holding:0.3023) (in:0.3538) (in front of:0.1681) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.6255) (of:0.4548) (on:0.8881) (on back of:0.0000) (over:0.1111) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6667) (says:0.0000) (sitting on:0.3675) (standing on:0.0769) (to:0.0000) (under:0.3796) (using:1.0000) (walking in:0.0000) (walking on:0.5620) (watching:0.3333) (wearing:0.9869) (wears:0.0000) (with:0.1300) 
--------------------------------------------------------
====================================================================================================

2022-09-29 19:19:31 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.322 | loss_v1 0 | loss_v2 0 | nll_loss 0.133 | ntokens 59.526 | nsentences 20 | sample_size 59.526 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.668365 | ppl 1.1 | vqa_score 0.9008 | wps 62.1 | wpb 59.5 | bsz 20 | num_updates 24000 | best_R@100 0.668365
2022-09-29 19:19:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 24000 updates
2022-09-29 19:19:31 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_2_24000.pt
2022-09-29 19:19:37 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_2_24000.pt
2022-09-29 19:19:42 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_2_24000.pt (epoch 2 @ 24000 updates, score 0.6683650048732487) (writing took 10.601124265929684 seconds)
2022-09-29 19:19:54 - progress_bar.py[line:274] - INFO: epoch 002:   8263 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=0.1, ups=0, wpb=101.2, bsz=40, num_updates=24010, lr=3.62366e-05, gnorm=0.839, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81418
2022-09-29 19:20:05 - progress_bar.py[line:274] - INFO: epoch 002:   8273 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.3, ups=0.9, wpb=102.8, bsz=40, num_updates=24020, lr=3.623e-05, gnorm=0.839, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81430
2022-09-29 19:20:16 - progress_bar.py[line:274] - INFO: epoch 002:   8283 / 15783 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.2, ups=0.89, wpb=102, bsz=40, num_updates=24030, lr=3.62234e-05, gnorm=0.648, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81441
2022-09-29 19:20:27 - progress_bar.py[line:274] - INFO: epoch 002:   8293 / 15783 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=91.1, ups=0.91, wpb=99.8, bsz=40, num_updates=24040, lr=3.62168e-05, gnorm=0.885, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=81452
2022-09-29 19:20:38 - progress_bar.py[line:274] - INFO: epoch 002:   8303 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.9, wpb=100.9, bsz=40, num_updates=24050, lr=3.62102e-05, gnorm=0.926, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=81463
2022-09-29 19:20:43 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 19:20:50 - progress_bar.py[line:274] - INFO: epoch 002:   8314 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=83.7, ups=0.85, wpb=99, bsz=40, num_updates=24060, lr=3.62036e-05, gnorm=0.843, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=81475
2022-09-29 19:21:01 - progress_bar.py[line:274] - INFO: epoch 002:   8324 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.9, wpb=99.9, bsz=40, num_updates=24070, lr=3.6197e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=81486
2022-09-29 19:21:13 - progress_bar.py[line:274] - INFO: epoch 002:   8334 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.7, ups=0.88, wpb=101.9, bsz=40, num_updates=24080, lr=3.61904e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=81497
2022-09-29 19:21:24 - progress_bar.py[line:274] - INFO: epoch 002:   8344 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=24090, lr=3.61838e-05, gnorm=0.796, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=81509
2022-09-29 19:21:35 - progress_bar.py[line:274] - INFO: epoch 002:   8354 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91, ups=0.89, wpb=102.6, bsz=40, num_updates=24100, lr=3.61772e-05, gnorm=0.807, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=81520
2022-09-29 19:21:46 - progress_bar.py[line:274] - INFO: epoch 002:   8364 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.92, wpb=98.8, bsz=40, num_updates=24110, lr=3.61706e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81531
2022-09-29 19:21:57 - progress_bar.py[line:274] - INFO: epoch 002:   8374 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.89, wpb=101.1, bsz=40, num_updates=24120, lr=3.6164e-05, gnorm=0.924, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=81542
2022-09-29 19:22:08 - progress_bar.py[line:274] - INFO: epoch 002:   8384 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.9, ups=0.91, wpb=102.6, bsz=40, num_updates=24130, lr=3.61574e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=81553
2022-09-29 19:22:20 - progress_bar.py[line:274] - INFO: epoch 002:   8394 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.4, ups=0.86, wpb=101.4, bsz=40, num_updates=24140, lr=3.61508e-05, gnorm=0.77, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=81565
2022-09-29 19:22:31 - progress_bar.py[line:274] - INFO: epoch 002:   8404 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.87, wpb=101.1, bsz=40, num_updates=24150, lr=3.61442e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81576
2022-09-29 19:22:43 - progress_bar.py[line:274] - INFO: epoch 002:   8414 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.9, wpb=100.5, bsz=40, num_updates=24160, lr=3.61376e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=81587
2022-09-29 19:22:54 - progress_bar.py[line:274] - INFO: epoch 002:   8424 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.89, wpb=101.1, bsz=40, num_updates=24170, lr=3.6131e-05, gnorm=0.701, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=81599
2022-09-29 19:23:05 - progress_bar.py[line:274] - INFO: epoch 002:   8434 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.4, ups=0.88, wpb=101.3, bsz=40, num_updates=24180, lr=3.61244e-05, gnorm=0.803, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=81610
2022-09-29 19:23:16 - progress_bar.py[line:274] - INFO: epoch 002:   8444 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.9, wpb=100.8, bsz=40, num_updates=24190, lr=3.61178e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81621
2022-09-29 19:23:28 - progress_bar.py[line:274] - INFO: epoch 002:   8454 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=24200, lr=3.61112e-05, gnorm=0.691, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=81632
2022-09-29 19:23:39 - progress_bar.py[line:274] - INFO: epoch 002:   8464 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.9, wpb=100.4, bsz=40, num_updates=24210, lr=3.61046e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=81644
2022-09-29 19:23:50 - progress_bar.py[line:274] - INFO: epoch 002:   8474 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.2, ups=0.9, wpb=103.4, bsz=40, num_updates=24220, lr=3.6098e-05, gnorm=0.764, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=81655
2022-09-29 19:24:01 - progress_bar.py[line:274] - INFO: epoch 002:   8484 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=86.9, ups=0.87, wpb=100.1, bsz=40, num_updates=24230, lr=3.60914e-05, gnorm=0.719, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=81666
2022-09-29 19:24:13 - progress_bar.py[line:274] - INFO: epoch 002:   8494 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.4, ups=0.87, wpb=101, bsz=40, num_updates=24240, lr=3.60848e-05, gnorm=0.752, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81678
2022-09-29 19:24:24 - progress_bar.py[line:274] - INFO: epoch 002:   8504 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90, ups=0.9, wpb=100, bsz=40, num_updates=24250, lr=3.60782e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=81689
2022-09-29 19:24:35 - progress_bar.py[line:274] - INFO: epoch 002:   8514 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.89, wpb=103, bsz=40, num_updates=24260, lr=3.60716e-05, gnorm=0.907, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81700
2022-09-29 19:24:47 - progress_bar.py[line:274] - INFO: epoch 002:   8524 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.8, ups=0.88, wpb=99.5, bsz=40, num_updates=24270, lr=3.6065e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81711
2022-09-29 19:24:58 - progress_bar.py[line:274] - INFO: epoch 002:   8534 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.89, wpb=101.4, bsz=40, num_updates=24280, lr=3.60584e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81723
2022-09-29 19:25:09 - progress_bar.py[line:274] - INFO: epoch 002:   8544 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.6, ups=0.88, wpb=101, bsz=40, num_updates=24290, lr=3.60518e-05, gnorm=0.828, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=81734
2022-09-29 19:25:20 - progress_bar.py[line:274] - INFO: epoch 002:   8554 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=93.2, ups=0.91, wpb=101.9, bsz=40, num_updates=24300, lr=3.60452e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=81745
2022-09-29 19:25:32 - progress_bar.py[line:274] - INFO: epoch 002:   8564 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.89, wpb=101.2, bsz=40, num_updates=24310, lr=3.60386e-05, gnorm=0.732, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=81756
2022-09-29 19:25:43 - progress_bar.py[line:274] - INFO: epoch 002:   8574 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.91, wpb=101.1, bsz=40, num_updates=24320, lr=3.6032e-05, gnorm=0.814, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=81767
2022-09-29 19:25:54 - progress_bar.py[line:274] - INFO: epoch 002:   8584 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.88, wpb=102.7, bsz=40, num_updates=24330, lr=3.60254e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=81779
2022-09-29 19:26:05 - progress_bar.py[line:274] - INFO: epoch 002:   8594 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.9, wpb=101.4, bsz=40, num_updates=24340, lr=3.60188e-05, gnorm=0.786, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81790
2022-09-29 19:26:16 - progress_bar.py[line:274] - INFO: epoch 002:   8604 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.9, wpb=100.5, bsz=40, num_updates=24350, lr=3.60122e-05, gnorm=0.814, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=81801
2022-09-29 19:26:28 - progress_bar.py[line:274] - INFO: epoch 002:   8614 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.5, ups=0.87, wpb=101.5, bsz=40, num_updates=24360, lr=3.60056e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=81813
2022-09-29 19:26:39 - progress_bar.py[line:274] - INFO: epoch 002:   8624 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.89, wpb=99.3, bsz=40, num_updates=24370, lr=3.5999e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=81824
2022-09-29 19:26:50 - progress_bar.py[line:274] - INFO: epoch 002:   8634 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.8, ups=0.87, wpb=100.4, bsz=40, num_updates=24380, lr=3.59924e-05, gnorm=0.814, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=81835
2022-09-29 19:27:02 - progress_bar.py[line:274] - INFO: epoch 002:   8644 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.4, ups=0.89, wpb=101.8, bsz=40, num_updates=24390, lr=3.59858e-05, gnorm=0.669, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81847
2022-09-29 19:27:13 - progress_bar.py[line:274] - INFO: epoch 002:   8654 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.88, wpb=101.4, bsz=40, num_updates=24400, lr=3.59792e-05, gnorm=0.828, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=81858
2022-09-29 19:27:24 - progress_bar.py[line:274] - INFO: epoch 002:   8664 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.9, wpb=100.1, bsz=40, num_updates=24410, lr=3.59726e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=81869
2022-09-29 19:27:36 - progress_bar.py[line:274] - INFO: epoch 002:   8674 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=24420, lr=3.5966e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81880
2022-09-29 19:27:47 - progress_bar.py[line:274] - INFO: epoch 002:   8684 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.7, ups=0.89, wpb=100.4, bsz=40, num_updates=24430, lr=3.59594e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=81892
2022-09-29 19:27:58 - progress_bar.py[line:274] - INFO: epoch 002:   8694 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.9, wpb=100.3, bsz=40, num_updates=24440, lr=3.59528e-05, gnorm=0.748, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=81903
2022-09-29 19:28:09 - progress_bar.py[line:274] - INFO: epoch 002:   8704 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.6, ups=0.91, wpb=101.8, bsz=40, num_updates=24450, lr=3.59462e-05, gnorm=0.748, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=81914
2022-09-29 19:28:20 - progress_bar.py[line:274] - INFO: epoch 002:   8714 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.89, wpb=103, bsz=40, num_updates=24460, lr=3.59396e-05, gnorm=0.661, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=81925
2022-09-29 19:28:31 - progress_bar.py[line:274] - INFO: epoch 002:   8724 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.9, wpb=100, bsz=40, num_updates=24470, lr=3.5933e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=81936
2022-09-29 19:28:42 - progress_bar.py[line:274] - INFO: epoch 002:   8734 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.9, wpb=101.2, bsz=40, num_updates=24480, lr=3.59264e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=81947
2022-09-29 19:28:54 - progress_bar.py[line:274] - INFO: epoch 002:   8744 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=24490, lr=3.59198e-05, gnorm=1.012, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=81959
2022-09-29 19:29:05 - progress_bar.py[line:274] - INFO: epoch 002:   8754 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.8, ups=0.9, wpb=101.2, bsz=40, num_updates=24500, lr=3.59132e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=81970
2022-09-29 19:29:16 - progress_bar.py[line:274] - INFO: epoch 002:   8764 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.9, wpb=99.4, bsz=40, num_updates=24510, lr=3.59066e-05, gnorm=0.856, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=81981
2022-09-29 19:29:27 - progress_bar.py[line:274] - INFO: epoch 002:   8774 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.9, ups=0.9, wpb=102.8, bsz=40, num_updates=24520, lr=3.59e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=81992
2022-09-29 19:29:39 - progress_bar.py[line:274] - INFO: epoch 002:   8784 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89, ups=0.88, wpb=101.5, bsz=40, num_updates=24530, lr=3.58934e-05, gnorm=0.723, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=82003
2022-09-29 19:29:50 - progress_bar.py[line:274] - INFO: epoch 002:   8794 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.88, wpb=102.3, bsz=40, num_updates=24540, lr=3.58868e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82015
2022-09-29 19:30:01 - progress_bar.py[line:274] - INFO: epoch 002:   8804 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.9, wpb=100.4, bsz=40, num_updates=24550, lr=3.58802e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=82026
2022-09-29 19:30:12 - progress_bar.py[line:274] - INFO: epoch 002:   8814 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.9, wpb=100.3, bsz=40, num_updates=24560, lr=3.58736e-05, gnorm=0.825, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82037
2022-09-29 19:30:23 - progress_bar.py[line:274] - INFO: epoch 002:   8824 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.2, ups=0.91, wpb=101.3, bsz=40, num_updates=24570, lr=3.5867e-05, gnorm=0.908, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82048
2022-09-29 19:30:34 - progress_bar.py[line:274] - INFO: epoch 002:   8834 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.91, wpb=101.8, bsz=40, num_updates=24580, lr=3.58604e-05, gnorm=0.811, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82059
2022-09-29 19:30:45 - progress_bar.py[line:274] - INFO: epoch 002:   8844 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.89, wpb=102.3, bsz=40, num_updates=24590, lr=3.58538e-05, gnorm=0.674, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82070
2022-09-29 19:30:57 - progress_bar.py[line:274] - INFO: epoch 002:   8854 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.7, ups=0.88, wpb=103.9, bsz=40, num_updates=24600, lr=3.58472e-05, gnorm=0.69, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82082
2022-09-29 19:31:08 - progress_bar.py[line:274] - INFO: epoch 002:   8864 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.9, ups=0.89, wpb=103.7, bsz=40, num_updates=24610, lr=3.58406e-05, gnorm=0.763, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82093
2022-09-29 19:31:19 - progress_bar.py[line:274] - INFO: epoch 002:   8874 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.89, wpb=102.6, bsz=40, num_updates=24620, lr=3.5834e-05, gnorm=0.748, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82104
2022-09-29 19:31:31 - progress_bar.py[line:274] - INFO: epoch 002:   8884 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.9, wpb=100.6, bsz=40, num_updates=24630, lr=3.58274e-05, gnorm=0.826, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=82115
2022-09-29 19:31:41 - progress_bar.py[line:274] - INFO: epoch 002:   8894 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.91, wpb=100, bsz=40, num_updates=24640, lr=3.58208e-05, gnorm=0.782, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82126
2022-09-29 19:31:53 - progress_bar.py[line:274] - INFO: epoch 002:   8904 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.9, wpb=101.5, bsz=40, num_updates=24650, lr=3.58142e-05, gnorm=0.777, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82137
2022-09-29 19:32:04 - progress_bar.py[line:274] - INFO: epoch 002:   8914 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.1, ups=0.88, wpb=101.7, bsz=40, num_updates=24660, lr=3.58076e-05, gnorm=0.707, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=82149
2022-09-29 19:32:16 - progress_bar.py[line:274] - INFO: epoch 002:   8924 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=85.8, ups=0.87, wpb=99.1, bsz=40, num_updates=24670, lr=3.5801e-05, gnorm=0.849, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82160
2022-09-29 19:32:27 - progress_bar.py[line:274] - INFO: epoch 002:   8934 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.9, wpb=101.1, bsz=40, num_updates=24680, lr=3.57944e-05, gnorm=0.872, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82171
2022-09-29 19:32:38 - progress_bar.py[line:274] - INFO: epoch 002:   8944 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=24690, lr=3.57878e-05, gnorm=0.824, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82183
2022-09-29 19:32:49 - progress_bar.py[line:274] - INFO: epoch 002:   8954 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.1, ups=0.94, wpb=101.8, bsz=40, num_updates=24700, lr=3.57812e-05, gnorm=0.811, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=82193
2022-09-29 19:33:00 - progress_bar.py[line:274] - INFO: epoch 002:   8964 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.89, wpb=100.4, bsz=40, num_updates=24710, lr=3.57746e-05, gnorm=0.986, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82205
2022-09-29 19:33:11 - progress_bar.py[line:274] - INFO: epoch 002:   8974 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90, ups=0.89, wpb=101.5, bsz=40, num_updates=24720, lr=3.5768e-05, gnorm=0.711, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82216
2022-09-29 19:33:22 - progress_bar.py[line:274] - INFO: epoch 002:   8984 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.89, wpb=102.2, bsz=40, num_updates=24730, lr=3.57614e-05, gnorm=0.881, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82227
2022-09-29 19:33:33 - progress_bar.py[line:274] - INFO: epoch 002:   8994 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.7, ups=0.92, wpb=102.3, bsz=40, num_updates=24740, lr=3.57548e-05, gnorm=0.75, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82238
2022-09-29 19:33:44 - progress_bar.py[line:274] - INFO: epoch 002:   9004 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=24750, lr=3.57482e-05, gnorm=0.903, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82249
2022-09-29 19:33:56 - progress_bar.py[line:274] - INFO: epoch 002:   9014 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.3, ups=0.88, wpb=100.4, bsz=40, num_updates=24760, lr=3.57416e-05, gnorm=0.841, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82261
2022-09-29 19:34:07 - progress_bar.py[line:274] - INFO: epoch 002:   9024 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.4, ups=0.94, wpb=100.9, bsz=40, num_updates=24770, lr=3.5735e-05, gnorm=0.834, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=82271
2022-09-29 19:34:18 - progress_bar.py[line:274] - INFO: epoch 002:   9034 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.3, ups=0.91, wpb=99.8, bsz=40, num_updates=24780, lr=3.57284e-05, gnorm=0.96, clip=50, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=82283
2022-09-29 19:34:28 - progress_bar.py[line:274] - INFO: epoch 002:   9044 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.2, ups=0.93, wpb=101.8, bsz=40, num_updates=24790, lr=3.57218e-05, gnorm=0.889, clip=10, loss_scale=1024, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=82293
2022-09-29 19:34:40 - progress_bar.py[line:274] - INFO: epoch 002:   9054 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.4, ups=0.89, wpb=100.4, bsz=40, num_updates=24800, lr=3.57152e-05, gnorm=0.892, clip=40, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=82305
2022-09-29 19:34:51 - progress_bar.py[line:274] - INFO: epoch 002:   9064 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=24810, lr=3.57086e-05, gnorm=0.813, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82316
2022-09-29 19:35:02 - progress_bar.py[line:274] - INFO: epoch 002:   9074 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.4, ups=0.89, wpb=100.9, bsz=40, num_updates=24820, lr=3.5702e-05, gnorm=0.779, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82327
2022-09-29 19:35:14 - progress_bar.py[line:274] - INFO: epoch 002:   9084 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.2, ups=0.89, wpb=103.6, bsz=40, num_updates=24830, lr=3.56954e-05, gnorm=1.004, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82338
2022-09-29 19:35:25 - progress_bar.py[line:274] - INFO: epoch 002:   9094 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.88, wpb=101.5, bsz=40, num_updates=24840, lr=3.56888e-05, gnorm=0.856, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82350
2022-09-29 19:35:37 - progress_bar.py[line:274] - INFO: epoch 002:   9104 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.8, ups=0.88, wpb=101.4, bsz=40, num_updates=24850, lr=3.56822e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82361
2022-09-29 19:35:48 - progress_bar.py[line:274] - INFO: epoch 002:   9114 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.9, wpb=101.5, bsz=40, num_updates=24860, lr=3.56756e-05, gnorm=0.801, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82373
2022-09-29 19:35:59 - progress_bar.py[line:274] - INFO: epoch 002:   9124 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.1, ups=0.9, wpb=102.9, bsz=40, num_updates=24870, lr=3.5669e-05, gnorm=0.797, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82384
2022-09-29 19:36:10 - progress_bar.py[line:274] - INFO: epoch 002:   9134 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.5, ups=0.9, wpb=101.3, bsz=40, num_updates=24880, lr=3.56624e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82395
2022-09-29 19:36:21 - progress_bar.py[line:274] - INFO: epoch 002:   9144 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.91, wpb=101, bsz=40, num_updates=24890, lr=3.56558e-05, gnorm=0.785, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82406
2022-09-29 19:36:32 - progress_bar.py[line:274] - INFO: epoch 002:   9154 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.9, ups=0.88, wpb=101.3, bsz=40, num_updates=24900, lr=3.56492e-05, gnorm=0.745, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82417
2022-09-29 19:36:43 - progress_bar.py[line:274] - INFO: epoch 002:   9164 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.89, wpb=100.5, bsz=40, num_updates=24910, lr=3.56426e-05, gnorm=0.76, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82428
2022-09-29 19:36:56 - progress_bar.py[line:274] - INFO: epoch 002:   9174 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93, ups=0.91, wpb=102, bsz=40, num_updates=24920, lr=3.5636e-05, gnorm=0.858, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82439
2022-09-29 19:37:07 - progress_bar.py[line:274] - INFO: epoch 002:   9184 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.2, ups=0.89, wpb=102.3, bsz=40, num_updates=24930, lr=3.56294e-05, gnorm=0.682, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82452
2022-09-29 19:37:19 - progress_bar.py[line:274] - INFO: epoch 002:   9194 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.3, ups=0.9, wpb=100.2, bsz=40, num_updates=24940, lr=3.56228e-05, gnorm=0.722, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82463
2022-09-29 19:37:30 - progress_bar.py[line:274] - INFO: epoch 002:   9204 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.9, wpb=101.1, bsz=40, num_updates=24950, lr=3.56162e-05, gnorm=0.785, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82474
2022-09-29 19:37:41 - progress_bar.py[line:274] - INFO: epoch 002:   9214 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.7, ups=0.88, wpb=100.7, bsz=40, num_updates=24960, lr=3.56096e-05, gnorm=0.644, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=82486
2022-09-29 19:37:52 - progress_bar.py[line:274] - INFO: epoch 002:   9224 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.1, ups=0.95, wpb=100.1, bsz=40, num_updates=24970, lr=3.5603e-05, gnorm=0.795, clip=10, loss_scale=1024, train_wall=10, gb_free=10.1, ema_decay=0.9999, wall=82496
2022-09-29 19:38:03 - progress_bar.py[line:274] - INFO: epoch 002:   9234 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.1, ups=0.88, wpb=101.5, bsz=40, num_updates=24980, lr=3.55964e-05, gnorm=0.807, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82508
2022-09-29 19:38:14 - progress_bar.py[line:274] - INFO: epoch 002:   9244 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=24990, lr=3.55898e-05, gnorm=0.785, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82519
2022-09-29 19:38:25 - progress_bar.py[line:274] - INFO: epoch 002:   9254 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92, ups=0.9, wpb=102.2, bsz=40, num_updates=25000, lr=3.55832e-05, gnorm=0.828, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82530
2022-09-29 19:38:37 - progress_bar.py[line:274] - INFO: epoch 002:   9264 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.3, ups=0.88, wpb=101.9, bsz=40, num_updates=25010, lr=3.55766e-05, gnorm=0.729, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82542
2022-09-29 19:38:48 - progress_bar.py[line:274] - INFO: epoch 002:   9274 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=25020, lr=3.557e-05, gnorm=0.829, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82553
2022-09-29 19:38:59 - progress_bar.py[line:274] - INFO: epoch 002:   9284 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.4, ups=0.9, wpb=102.4, bsz=40, num_updates=25030, lr=3.55634e-05, gnorm=0.714, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82564
2022-09-29 19:39:10 - progress_bar.py[line:274] - INFO: epoch 002:   9294 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.2, ups=0.9, wpb=104.3, bsz=40, num_updates=25040, lr=3.55568e-05, gnorm=0.712, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=82575
2022-09-29 19:39:22 - progress_bar.py[line:274] - INFO: epoch 002:   9304 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.2, ups=0.86, wpb=102, bsz=40, num_updates=25050, lr=3.55502e-05, gnorm=0.77, clip=10, loss_scale=1024, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=82587
2022-09-29 19:39:33 - progress_bar.py[line:274] - INFO: epoch 002:   9314 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.8, ups=0.9, wpb=101.5, bsz=40, num_updates=25060, lr=3.55436e-05, gnorm=0.657, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82598
2022-09-29 19:39:44 - progress_bar.py[line:274] - INFO: epoch 002:   9324 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.9, ups=0.87, wpb=101.4, bsz=40, num_updates=25070, lr=3.5537e-05, gnorm=0.846, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82609
2022-09-29 19:39:53 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-29 19:39:56 - progress_bar.py[line:274] - INFO: epoch 002:   9335 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=85.1, ups=0.83, wpb=103, bsz=40, num_updates=25080, lr=3.55304e-05, gnorm=0.777, clip=0, loss_scale=1024, train_wall=12, gb_free=9.7, ema_decay=0.9999, wall=82621
2022-09-29 19:40:08 - progress_bar.py[line:274] - INFO: epoch 002:   9345 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.88, wpb=102.1, bsz=40, num_updates=25090, lr=3.55238e-05, gnorm=0.864, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82633
2022-09-29 19:40:19 - progress_bar.py[line:274] - INFO: epoch 002:   9355 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.89, wpb=101.2, bsz=40, num_updates=25100, lr=3.55172e-05, gnorm=0.81, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82644
2022-09-29 19:40:30 - progress_bar.py[line:274] - INFO: epoch 002:   9365 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.6, ups=0.92, wpb=102, bsz=40, num_updates=25110, lr=3.55106e-05, gnorm=0.771, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82655
2022-09-29 19:40:41 - progress_bar.py[line:274] - INFO: epoch 002:   9375 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.2, ups=0.93, wpb=101.8, bsz=40, num_updates=25120, lr=3.5504e-05, gnorm=0.735, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82666
2022-09-29 19:40:52 - progress_bar.py[line:274] - INFO: epoch 002:   9385 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.89, wpb=102.3, bsz=40, num_updates=25130, lr=3.54974e-05, gnorm=0.966, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82677
2022-09-29 19:41:03 - progress_bar.py[line:274] - INFO: epoch 002:   9395 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.2, ups=0.9, wpb=99.2, bsz=40, num_updates=25140, lr=3.54908e-05, gnorm=0.724, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82688
2022-09-29 19:41:15 - progress_bar.py[line:274] - INFO: epoch 002:   9405 / 15783 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=87.3, ups=0.88, wpb=99.7, bsz=40, num_updates=25150, lr=3.54842e-05, gnorm=0.793, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82699
2022-09-29 19:41:26 - progress_bar.py[line:274] - INFO: epoch 002:   9415 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.7, ups=0.88, wpb=101.1, bsz=40, num_updates=25160, lr=3.54776e-05, gnorm=0.709, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82711
2022-09-29 19:41:37 - progress_bar.py[line:274] - INFO: epoch 002:   9425 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.1, ups=0.91, wpb=101.1, bsz=40, num_updates=25170, lr=3.5471e-05, gnorm=0.795, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82722
2022-09-29 19:41:48 - progress_bar.py[line:274] - INFO: epoch 002:   9435 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.88, wpb=101.3, bsz=40, num_updates=25180, lr=3.54644e-05, gnorm=0.74, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82733
2022-09-29 19:42:00 - progress_bar.py[line:274] - INFO: epoch 002:   9445 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.9, wpb=101.4, bsz=40, num_updates=25190, lr=3.54578e-05, gnorm=0.763, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=82744
2022-09-29 19:42:11 - progress_bar.py[line:274] - INFO: epoch 002:   9455 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.89, wpb=102.7, bsz=40, num_updates=25200, lr=3.54512e-05, gnorm=0.702, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82756
2022-09-29 19:42:22 - progress_bar.py[line:274] - INFO: epoch 002:   9465 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.2, ups=0.88, wpb=100.2, bsz=40, num_updates=25210, lr=3.54446e-05, gnorm=0.829, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82767
2022-09-29 19:42:34 - progress_bar.py[line:274] - INFO: epoch 002:   9475 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.7, ups=0.88, wpb=101.1, bsz=40, num_updates=25220, lr=3.5438e-05, gnorm=0.834, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82778
2022-09-29 19:42:45 - progress_bar.py[line:274] - INFO: epoch 002:   9485 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.9, wpb=99.9, bsz=40, num_updates=25230, lr=3.54314e-05, gnorm=0.852, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82790
2022-09-29 19:42:57 - progress_bar.py[line:274] - INFO: epoch 002:   9495 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=98.4, nsentences=40, sample_size=98.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.1, ups=0.88, wpb=98.4, bsz=40, num_updates=25240, lr=3.54248e-05, gnorm=0.833, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82802
2022-09-29 19:43:08 - progress_bar.py[line:274] - INFO: epoch 002:   9505 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.1, ups=0.92, wpb=102.7, bsz=40, num_updates=25250, lr=3.54182e-05, gnorm=0.859, clip=10, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=82813
2022-09-29 19:43:19 - progress_bar.py[line:274] - INFO: epoch 002:   9515 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.1, ups=0.89, wpb=100.2, bsz=40, num_updates=25260, lr=3.54116e-05, gnorm=0.782, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=82824
2022-09-29 19:43:30 - progress_bar.py[line:274] - INFO: epoch 002:   9525 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92, ups=0.92, wpb=100.5, bsz=40, num_updates=25270, lr=3.5405e-05, gnorm=0.848, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82835
2022-09-29 19:43:41 - progress_bar.py[line:274] - INFO: epoch 002:   9535 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.4, ups=0.91, wpb=100.7, bsz=40, num_updates=25280, lr=3.53984e-05, gnorm=0.757, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82846
2022-09-29 19:43:52 - progress_bar.py[line:274] - INFO: epoch 002:   9545 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.2, ups=0.88, wpb=101.9, bsz=40, num_updates=25290, lr=3.53918e-05, gnorm=0.738, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82857
2022-09-29 19:44:04 - progress_bar.py[line:274] - INFO: epoch 002:   9555 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.8, ups=0.89, wpb=102.3, bsz=40, num_updates=25300, lr=3.53852e-05, gnorm=0.768, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82868
2022-09-29 19:44:15 - progress_bar.py[line:274] - INFO: epoch 002:   9565 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.9, wpb=100.2, bsz=40, num_updates=25310, lr=3.53786e-05, gnorm=1.08, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82880
2022-09-29 19:44:26 - progress_bar.py[line:274] - INFO: epoch 002:   9575 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.2, ups=0.88, wpb=100.8, bsz=40, num_updates=25320, lr=3.5372e-05, gnorm=0.904, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=82891
2022-09-29 19:44:37 - progress_bar.py[line:274] - INFO: epoch 002:   9585 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.1, ups=0.89, wpb=101, bsz=40, num_updates=25330, lr=3.53654e-05, gnorm=0.811, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82902
2022-09-29 19:44:48 - progress_bar.py[line:274] - INFO: epoch 002:   9595 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.9, wpb=101.5, bsz=40, num_updates=25340, lr=3.53588e-05, gnorm=0.815, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=82913
2022-09-29 19:45:00 - progress_bar.py[line:274] - INFO: epoch 002:   9605 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.9, wpb=99.7, bsz=40, num_updates=25350, lr=3.53522e-05, gnorm=0.754, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82924
2022-09-29 19:45:11 - progress_bar.py[line:274] - INFO: epoch 002:   9615 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.9, wpb=100.1, bsz=40, num_updates=25360, lr=3.53456e-05, gnorm=0.852, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82935
2022-09-29 19:45:22 - progress_bar.py[line:274] - INFO: epoch 002:   9625 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.9, ups=0.92, wpb=101.1, bsz=40, num_updates=25370, lr=3.5339e-05, gnorm=0.773, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=82946
2022-09-29 19:45:33 - progress_bar.py[line:274] - INFO: epoch 002:   9635 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.91, wpb=100.6, bsz=40, num_updates=25380, lr=3.53324e-05, gnorm=0.771, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82957
2022-09-29 19:45:44 - progress_bar.py[line:274] - INFO: epoch 002:   9645 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.89, wpb=100.7, bsz=40, num_updates=25390, lr=3.53258e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=82969
2022-09-29 19:45:55 - progress_bar.py[line:274] - INFO: epoch 002:   9655 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.9, ups=0.87, wpb=101.7, bsz=40, num_updates=25400, lr=3.53192e-05, gnorm=0.785, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=82980
2022-09-29 19:46:07 - progress_bar.py[line:274] - INFO: epoch 002:   9665 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.5, ups=0.88, wpb=99.9, bsz=40, num_updates=25410, lr=3.53126e-05, gnorm=0.812, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=82991
2022-09-29 19:46:18 - progress_bar.py[line:274] - INFO: epoch 002:   9675 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.9, ups=0.9, wpb=100.8, bsz=40, num_updates=25420, lr=3.5306e-05, gnorm=0.837, clip=30, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=83003
2022-09-29 19:46:29 - progress_bar.py[line:274] - INFO: epoch 002:   9685 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.9, wpb=102.2, bsz=40, num_updates=25430, lr=3.52994e-05, gnorm=0.768, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83014
2022-09-29 19:46:40 - progress_bar.py[line:274] - INFO: epoch 002:   9695 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.1, ups=0.92, wpb=100.9, bsz=40, num_updates=25440, lr=3.52928e-05, gnorm=0.734, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83024
2022-09-29 19:46:51 - progress_bar.py[line:274] - INFO: epoch 002:   9705 / 15783 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.5, ups=0.92, wpb=100.3, bsz=40, num_updates=25450, lr=3.52862e-05, gnorm=0.645, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83035
2022-09-29 19:47:01 - progress_bar.py[line:274] - INFO: epoch 002:   9715 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.7, ups=0.91, wpb=100.5, bsz=40, num_updates=25460, lr=3.52796e-05, gnorm=0.792, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83046
2022-09-29 19:47:12 - progress_bar.py[line:274] - INFO: epoch 002:   9725 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.92, wpb=100.1, bsz=40, num_updates=25470, lr=3.5273e-05, gnorm=0.752, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83057
2022-09-29 19:47:23 - progress_bar.py[line:274] - INFO: epoch 002:   9735 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.91, wpb=100.5, bsz=40, num_updates=25480, lr=3.52664e-05, gnorm=0.794, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83068
2022-09-29 19:47:35 - progress_bar.py[line:274] - INFO: epoch 002:   9745 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.9, ups=0.88, wpb=101.3, bsz=40, num_updates=25490, lr=3.52598e-05, gnorm=0.764, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83080
2022-09-29 19:47:46 - progress_bar.py[line:274] - INFO: epoch 002:   9755 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.2, ups=0.92, wpb=101.7, bsz=40, num_updates=25500, lr=3.52532e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83091
2022-09-29 19:47:57 - progress_bar.py[line:274] - INFO: epoch 002:   9765 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.9, ups=0.88, wpb=100.3, bsz=40, num_updates=25510, lr=3.52466e-05, gnorm=0.735, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83102
2022-09-29 19:48:08 - progress_bar.py[line:274] - INFO: epoch 002:   9775 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.2, ups=0.91, wpb=101.2, bsz=40, num_updates=25520, lr=3.524e-05, gnorm=0.778, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83113
2022-09-29 19:48:19 - progress_bar.py[line:274] - INFO: epoch 002:   9785 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.9, wpb=100.4, bsz=40, num_updates=25530, lr=3.52334e-05, gnorm=0.766, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83124
2022-09-29 19:48:31 - progress_bar.py[line:274] - INFO: epoch 002:   9795 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.88, wpb=104.2, bsz=40, num_updates=25540, lr=3.52268e-05, gnorm=0.762, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83135
2022-09-29 19:48:42 - progress_bar.py[line:274] - INFO: epoch 002:   9805 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.9, ups=0.91, wpb=102, bsz=40, num_updates=25550, lr=3.52202e-05, gnorm=0.71, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83146
2022-09-29 19:48:53 - progress_bar.py[line:274] - INFO: epoch 002:   9815 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.3, ups=0.88, wpb=100.5, bsz=40, num_updates=25560, lr=3.52136e-05, gnorm=0.871, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83158
2022-09-29 19:49:04 - progress_bar.py[line:274] - INFO: epoch 002:   9825 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.1, ups=0.9, wpb=102.3, bsz=40, num_updates=25570, lr=3.5207e-05, gnorm=0.84, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=83169
2022-09-29 19:49:15 - progress_bar.py[line:274] - INFO: epoch 002:   9835 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.1, ups=0.9, wpb=102.1, bsz=40, num_updates=25580, lr=3.52004e-05, gnorm=0.746, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83180
2022-09-29 19:49:26 - progress_bar.py[line:274] - INFO: epoch 002:   9845 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.9, wpb=99.9, bsz=40, num_updates=25590, lr=3.51938e-05, gnorm=0.93, clip=20, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83191
2022-09-29 19:49:31 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-29 19:49:38 - progress_bar.py[line:274] - INFO: epoch 002:   9856 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=84.8, ups=0.84, wpb=101.2, bsz=40, num_updates=25600, lr=3.51872e-05, gnorm=0.792, clip=20, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=83203
2022-09-29 19:49:49 - progress_bar.py[line:274] - INFO: epoch 002:   9866 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.9, wpb=101.2, bsz=40, num_updates=25610, lr=3.51806e-05, gnorm=0.825, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83214
2022-09-29 19:50:00 - progress_bar.py[line:274] - INFO: epoch 002:   9876 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.7, ups=0.9, wpb=101.8, bsz=40, num_updates=25620, lr=3.5174e-05, gnorm=0.771, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83225
2022-09-29 19:50:12 - progress_bar.py[line:274] - INFO: epoch 002:   9886 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.88, wpb=103.8, bsz=40, num_updates=25630, lr=3.51674e-05, gnorm=0.715, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83237
2022-09-29 19:50:22 - progress_bar.py[line:274] - INFO: epoch 002:   9896 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.3, ups=0.94, wpb=100.7, bsz=40, num_updates=25640, lr=3.51608e-05, gnorm=0.794, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83247
2022-09-29 19:50:34 - progress_bar.py[line:274] - INFO: epoch 002:   9906 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.3, ups=0.89, wpb=100.4, bsz=40, num_updates=25650, lr=3.51542e-05, gnorm=0.827, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83259
2022-09-29 19:50:45 - progress_bar.py[line:274] - INFO: epoch 002:   9916 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.3, ups=0.87, wpb=100.5, bsz=40, num_updates=25660, lr=3.51476e-05, gnorm=0.813, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83270
2022-09-29 19:50:57 - progress_bar.py[line:274] - INFO: epoch 002:   9926 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.2, ups=0.89, wpb=100.6, bsz=40, num_updates=25670, lr=3.5141e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=83281
2022-09-29 19:51:08 - progress_bar.py[line:274] - INFO: epoch 002:   9936 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.87, wpb=102.2, bsz=40, num_updates=25680, lr=3.51344e-05, gnorm=0.742, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83293
2022-09-29 19:51:19 - progress_bar.py[line:274] - INFO: epoch 002:   9946 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.1, ups=0.92, wpb=100.6, bsz=40, num_updates=25690, lr=3.51278e-05, gnorm=0.72, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83304
2022-09-29 19:51:31 - progress_bar.py[line:274] - INFO: epoch 002:   9956 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.86, wpb=104, bsz=40, num_updates=25700, lr=3.51212e-05, gnorm=0.76, clip=10, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=83315
2022-09-29 19:51:42 - progress_bar.py[line:274] - INFO: epoch 002:   9966 / 15783 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=25710, lr=3.51146e-05, gnorm=0.787, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83327
2022-09-29 19:51:52 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 19:51:54 - progress_bar.py[line:274] - INFO: epoch 002:   9977 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=80.7, ups=0.8, wpb=101.2, bsz=40, num_updates=25720, lr=3.5108e-05, gnorm=0.827, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=83339
2022-09-29 19:52:06 - progress_bar.py[line:274] - INFO: epoch 002:   9987 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.8, ups=0.89, wpb=99.9, bsz=40, num_updates=25730, lr=3.51014e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=83350
2022-09-29 19:52:17 - progress_bar.py[line:274] - INFO: epoch 002:   9997 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.88, wpb=101.8, bsz=40, num_updates=25740, lr=3.50948e-05, gnorm=0.738, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=83362
2022-09-29 19:52:28 - progress_bar.py[line:274] - INFO: epoch 002:  10007 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=25750, lr=3.50882e-05, gnorm=0.841, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=83373
2022-09-29 19:52:40 - progress_bar.py[line:274] - INFO: epoch 002:  10017 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.6, ups=0.88, wpb=101.2, bsz=40, num_updates=25760, lr=3.50816e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83385
2022-09-29 19:52:51 - progress_bar.py[line:274] - INFO: epoch 002:  10027 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.9, wpb=101.1, bsz=40, num_updates=25770, lr=3.5075e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83396
2022-09-29 19:53:02 - progress_bar.py[line:274] - INFO: epoch 002:  10037 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.89, wpb=102.5, bsz=40, num_updates=25780, lr=3.50684e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83407
2022-09-29 19:53:13 - progress_bar.py[line:274] - INFO: epoch 002:  10047 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.7, ups=0.9, wpb=102.9, bsz=40, num_updates=25790, lr=3.50618e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83418
2022-09-29 19:53:24 - progress_bar.py[line:274] - INFO: epoch 002:  10057 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.4, ups=0.93, wpb=103.8, bsz=40, num_updates=25800, lr=3.50552e-05, gnorm=0.758, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83429
2022-09-29 19:53:35 - progress_bar.py[line:274] - INFO: epoch 002:  10067 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.2, ups=0.88, wpb=99.5, bsz=40, num_updates=25810, lr=3.50486e-05, gnorm=1.108, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83440
2022-09-29 19:53:46 - progress_bar.py[line:274] - INFO: epoch 002:  10077 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.92, wpb=99.4, bsz=40, num_updates=25820, lr=3.5042e-05, gnorm=0.781, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83451
2022-09-29 19:53:58 - progress_bar.py[line:274] - INFO: epoch 002:  10087 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.89, wpb=101, bsz=40, num_updates=25830, lr=3.50354e-05, gnorm=0.73, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83462
2022-09-29 19:54:09 - progress_bar.py[line:274] - INFO: epoch 002:  10097 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.5, ups=0.88, wpb=99.6, bsz=40, num_updates=25840, lr=3.50288e-05, gnorm=0.705, clip=0, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=83474
2022-09-29 19:54:20 - progress_bar.py[line:274] - INFO: epoch 002:  10107 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.89, wpb=102.4, bsz=40, num_updates=25850, lr=3.50222e-05, gnorm=0.75, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83485
2022-09-29 19:54:31 - progress_bar.py[line:274] - INFO: epoch 002:  10117 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.9, wpb=100.9, bsz=40, num_updates=25860, lr=3.50156e-05, gnorm=0.806, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=83496
2022-09-29 19:54:43 - progress_bar.py[line:274] - INFO: epoch 002:  10127 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.89, wpb=100.9, bsz=40, num_updates=25870, lr=3.5009e-05, gnorm=0.826, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83507
2022-09-29 19:54:54 - progress_bar.py[line:274] - INFO: epoch 002:  10137 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.5, ups=0.88, wpb=99.9, bsz=40, num_updates=25880, lr=3.50024e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83519
2022-09-29 19:55:05 - progress_bar.py[line:274] - INFO: epoch 002:  10147 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.8, ups=0.88, wpb=100.3, bsz=40, num_updates=25890, lr=3.49958e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83530
2022-09-29 19:55:17 - progress_bar.py[line:274] - INFO: epoch 002:  10157 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.9, wpb=101.5, bsz=40, num_updates=25900, lr=3.49892e-05, gnorm=0.663, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83541
2022-09-29 19:55:28 - progress_bar.py[line:274] - INFO: epoch 002:  10167 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.9, ups=0.87, wpb=101.5, bsz=40, num_updates=25910, lr=3.49826e-05, gnorm=0.739, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=83553
2022-09-29 19:55:39 - progress_bar.py[line:274] - INFO: epoch 002:  10177 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.91, wpb=99.8, bsz=40, num_updates=25920, lr=3.4976e-05, gnorm=0.83, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83564
2022-09-29 19:55:50 - progress_bar.py[line:274] - INFO: epoch 002:  10187 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.5, ups=0.93, wpb=101.8, bsz=40, num_updates=25930, lr=3.49694e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83575
2022-09-29 19:56:01 - progress_bar.py[line:274] - INFO: epoch 002:  10197 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.89, wpb=102.7, bsz=40, num_updates=25940, lr=3.49628e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83586
2022-09-29 19:56:12 - progress_bar.py[line:274] - INFO: epoch 002:  10207 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.89, wpb=100.3, bsz=40, num_updates=25950, lr=3.49562e-05, gnorm=0.79, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83597
2022-09-29 19:56:24 - progress_bar.py[line:274] - INFO: epoch 002:  10217 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.4, ups=0.87, wpb=101, bsz=40, num_updates=25960, lr=3.49496e-05, gnorm=0.721, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=83609
2022-09-29 19:56:35 - progress_bar.py[line:274] - INFO: epoch 002:  10227 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.89, wpb=103.1, bsz=40, num_updates=25970, lr=3.4943e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83620
2022-09-29 19:56:46 - progress_bar.py[line:274] - INFO: epoch 002:  10237 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.9, wpb=101.9, bsz=40, num_updates=25980, lr=3.49364e-05, gnorm=0.823, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83631
2022-09-29 19:56:58 - progress_bar.py[line:274] - INFO: epoch 002:  10247 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89, ups=0.89, wpb=100.1, bsz=40, num_updates=25990, lr=3.49298e-05, gnorm=0.793, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=83643
2022-09-29 19:57:09 - progress_bar.py[line:274] - INFO: epoch 002:  10257 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.1, ups=0.91, wpb=103, bsz=40, num_updates=26000, lr=3.49232e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83653
2022-09-29 19:57:20 - progress_bar.py[line:274] - INFO: epoch 002:  10267 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.89, wpb=100.1, bsz=40, num_updates=26010, lr=3.49166e-05, gnorm=0.814, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83665
2022-09-29 19:57:31 - progress_bar.py[line:274] - INFO: epoch 002:  10277 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=26020, lr=3.491e-05, gnorm=0.726, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83676
2022-09-29 19:57:43 - progress_bar.py[line:274] - INFO: epoch 002:  10287 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.88, wpb=101.6, bsz=40, num_updates=26030, lr=3.49034e-05, gnorm=0.824, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83687
2022-09-29 19:57:54 - progress_bar.py[line:274] - INFO: epoch 002:  10297 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.9, wpb=99.8, bsz=40, num_updates=26040, lr=3.48968e-05, gnorm=0.82, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83698
2022-09-29 19:58:05 - progress_bar.py[line:274] - INFO: epoch 002:  10307 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.92, wpb=100, bsz=40, num_updates=26050, lr=3.48902e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83709
2022-09-29 19:58:16 - progress_bar.py[line:274] - INFO: epoch 002:  10317 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.1, ups=0.88, wpb=102, bsz=40, num_updates=26060, lr=3.48836e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83721
2022-09-29 19:58:27 - progress_bar.py[line:274] - INFO: epoch 002:  10327 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.7, ups=0.88, wpb=101.1, bsz=40, num_updates=26070, lr=3.4877e-05, gnorm=0.674, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83732
2022-09-29 19:58:39 - progress_bar.py[line:274] - INFO: epoch 002:  10337 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.89, wpb=101.1, bsz=40, num_updates=26080, lr=3.48704e-05, gnorm=0.838, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83743
2022-09-29 19:58:49 - progress_bar.py[line:274] - INFO: epoch 002:  10347 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.8, ups=0.93, wpb=102.3, bsz=40, num_updates=26090, lr=3.48638e-05, gnorm=0.76, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83754
2022-09-29 19:59:00 - progress_bar.py[line:274] - INFO: epoch 002:  10357 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.3, ups=0.9, wpb=101.4, bsz=40, num_updates=26100, lr=3.48572e-05, gnorm=0.754, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83765
2022-09-29 19:59:12 - progress_bar.py[line:274] - INFO: epoch 002:  10367 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.6, ups=0.89, wpb=101.4, bsz=40, num_updates=26110, lr=3.48506e-05, gnorm=0.69, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83777
2022-09-29 19:59:23 - progress_bar.py[line:274] - INFO: epoch 002:  10377 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.9, wpb=99.9, bsz=40, num_updates=26120, lr=3.4844e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83788
2022-09-29 19:59:34 - progress_bar.py[line:274] - INFO: epoch 002:  10387 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.7, ups=0.89, wpb=101.3, bsz=40, num_updates=26130, lr=3.48374e-05, gnorm=0.723, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83799
2022-09-29 19:59:45 - progress_bar.py[line:274] - INFO: epoch 002:  10397 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.6, ups=0.89, wpb=103.1, bsz=40, num_updates=26140, lr=3.48308e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=83810
2022-09-29 19:59:57 - progress_bar.py[line:274] - INFO: epoch 002:  10407 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.8, ups=0.88, wpb=103.7, bsz=40, num_updates=26150, lr=3.48242e-05, gnorm=0.722, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83822
2022-09-29 20:00:08 - progress_bar.py[line:274] - INFO: epoch 002:  10417 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.8, ups=0.88, wpb=101.4, bsz=40, num_updates=26160, lr=3.48176e-05, gnorm=0.788, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83833
2022-09-29 20:00:19 - progress_bar.py[line:274] - INFO: epoch 002:  10427 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.9, wpb=101.8, bsz=40, num_updates=26170, lr=3.4811e-05, gnorm=0.76, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83844
2022-09-29 20:00:31 - progress_bar.py[line:274] - INFO: epoch 002:  10437 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=26180, lr=3.48044e-05, gnorm=0.676, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83855
2022-09-29 20:00:42 - progress_bar.py[line:274] - INFO: epoch 002:  10447 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.3, ups=0.88, wpb=100.9, bsz=40, num_updates=26190, lr=3.47978e-05, gnorm=0.856, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83867
2022-09-29 20:00:53 - progress_bar.py[line:274] - INFO: epoch 002:  10457 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.9, wpb=100.5, bsz=40, num_updates=26200, lr=3.47912e-05, gnorm=0.836, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83878
2022-09-29 20:01:04 - progress_bar.py[line:274] - INFO: epoch 002:  10467 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.4, ups=0.89, wpb=100.2, bsz=40, num_updates=26210, lr=3.47846e-05, gnorm=0.731, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83889
2022-09-29 20:01:16 - progress_bar.py[line:274] - INFO: epoch 002:  10477 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.5, ups=0.87, wpb=102.2, bsz=40, num_updates=26220, lr=3.4778e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=83901
2022-09-29 20:01:27 - progress_bar.py[line:274] - INFO: epoch 002:  10487 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.5, ups=0.92, wpb=101.3, bsz=40, num_updates=26230, lr=3.47714e-05, gnorm=0.835, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83912
2022-09-29 20:01:38 - progress_bar.py[line:274] - INFO: epoch 002:  10497 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.89, wpb=102.5, bsz=40, num_updates=26240, lr=3.47648e-05, gnorm=0.826, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83923
2022-09-29 20:01:50 - progress_bar.py[line:274] - INFO: epoch 002:  10507 / 15783 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.6, ups=0.88, wpb=98.9, bsz=40, num_updates=26250, lr=3.47582e-05, gnorm=1.06, clip=60, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83934
2022-09-29 20:02:01 - progress_bar.py[line:274] - INFO: epoch 002:  10517 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.9, wpb=99.9, bsz=40, num_updates=26260, lr=3.47516e-05, gnorm=0.72, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83946
2022-09-29 20:02:12 - progress_bar.py[line:274] - INFO: epoch 002:  10527 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.2, ups=0.9, wpb=102.5, bsz=40, num_updates=26270, lr=3.4745e-05, gnorm=0.808, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83957
2022-09-29 20:02:23 - progress_bar.py[line:274] - INFO: epoch 002:  10537 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.2, ups=0.92, wpb=100.3, bsz=40, num_updates=26280, lr=3.47384e-05, gnorm=0.808, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=83968
2022-09-29 20:02:34 - progress_bar.py[line:274] - INFO: epoch 002:  10547 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90, ups=0.88, wpb=102.5, bsz=40, num_updates=26290, lr=3.47318e-05, gnorm=0.736, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83979
2022-09-29 20:02:45 - progress_bar.py[line:274] - INFO: epoch 002:  10557 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.88, wpb=103.6, bsz=40, num_updates=26300, lr=3.47252e-05, gnorm=0.833, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83990
2022-09-29 20:02:56 - progress_bar.py[line:274] - INFO: epoch 002:  10567 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.91, wpb=101.7, bsz=40, num_updates=26310, lr=3.47186e-05, gnorm=0.834, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84001
2022-09-29 20:03:08 - progress_bar.py[line:274] - INFO: epoch 002:  10577 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.89, wpb=102.7, bsz=40, num_updates=26320, lr=3.4712e-05, gnorm=0.795, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=84013
2022-09-29 20:03:19 - progress_bar.py[line:274] - INFO: epoch 002:  10587 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.6, ups=0.88, wpb=101, bsz=40, num_updates=26330, lr=3.47054e-05, gnorm=0.988, clip=60, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=84024
2022-09-29 20:03:30 - progress_bar.py[line:274] - INFO: epoch 002:  10597 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.9, wpb=101.2, bsz=40, num_updates=26340, lr=3.46988e-05, gnorm=0.84, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84035
2022-09-29 20:03:42 - progress_bar.py[line:274] - INFO: epoch 002:  10607 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.1, ups=0.89, wpb=99.2, bsz=40, num_updates=26350, lr=3.46922e-05, gnorm=0.831, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84046
2022-09-29 20:03:53 - progress_bar.py[line:274] - INFO: epoch 002:  10617 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.89, wpb=101.8, bsz=40, num_updates=26360, lr=3.46856e-05, gnorm=0.875, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84058
2022-09-29 20:04:04 - progress_bar.py[line:274] - INFO: epoch 002:  10627 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=26370, lr=3.4679e-05, gnorm=0.809, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84069
2022-09-29 20:04:15 - progress_bar.py[line:274] - INFO: epoch 002:  10637 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.9, wpb=100.7, bsz=40, num_updates=26380, lr=3.46724e-05, gnorm=0.756, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=84080
2022-09-29 20:04:26 - progress_bar.py[line:274] - INFO: epoch 002:  10647 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.8, bsz=40, num_updates=26390, lr=3.46658e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=84091
2022-09-29 20:04:37 - progress_bar.py[line:274] - INFO: epoch 002:  10657 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.3, ups=0.97, wpb=101.7, bsz=40, num_updates=26400, lr=3.46592e-05, gnorm=0.78, clip=10, loss_scale=1024, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=84102
2022-09-29 20:04:48 - progress_bar.py[line:274] - INFO: epoch 002:  10667 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.7, ups=0.88, wpb=102.5, bsz=40, num_updates=26410, lr=3.46526e-05, gnorm=0.685, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84113
2022-09-29 20:05:00 - progress_bar.py[line:274] - INFO: epoch 002:  10677 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.89, wpb=101.1, bsz=40, num_updates=26420, lr=3.4646e-05, gnorm=0.743, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84124
2022-09-29 20:05:11 - progress_bar.py[line:274] - INFO: epoch 002:  10687 / 15783 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92, ups=0.9, wpb=101.7, bsz=40, num_updates=26430, lr=3.46394e-05, gnorm=0.768, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84135
2022-09-29 20:05:22 - progress_bar.py[line:274] - INFO: epoch 002:  10697 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.89, wpb=101.9, bsz=40, num_updates=26440, lr=3.46328e-05, gnorm=0.783, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=84147
2022-09-29 20:05:33 - progress_bar.py[line:274] - INFO: epoch 002:  10707 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.7, ups=0.89, wpb=101.5, bsz=40, num_updates=26450, lr=3.46262e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84158
2022-09-29 20:05:44 - progress_bar.py[line:274] - INFO: epoch 002:  10717 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.2, ups=0.9, wpb=102.8, bsz=40, num_updates=26460, lr=3.46196e-05, gnorm=0.695, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84169
2022-09-29 20:05:56 - progress_bar.py[line:274] - INFO: epoch 002:  10727 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.3, ups=0.88, wpb=100.9, bsz=40, num_updates=26470, lr=3.4613e-05, gnorm=0.815, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=84180
2022-09-29 20:06:07 - progress_bar.py[line:274] - INFO: epoch 002:  10737 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.2, ups=0.89, wpb=100.4, bsz=40, num_updates=26480, lr=3.46064e-05, gnorm=0.691, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84192
2022-09-29 20:06:18 - progress_bar.py[line:274] - INFO: epoch 002:  10747 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.92, wpb=100.2, bsz=40, num_updates=26490, lr=3.45998e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84203
2022-09-29 20:06:29 - progress_bar.py[line:274] - INFO: epoch 002:  10757 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.6, ups=0.89, wpb=102, bsz=40, num_updates=26500, lr=3.45932e-05, gnorm=0.748, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84214
2022-09-29 20:06:40 - progress_bar.py[line:274] - INFO: epoch 002:  10767 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=26510, lr=3.45866e-05, gnorm=0.709, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84225
2022-09-29 20:06:52 - progress_bar.py[line:274] - INFO: epoch 002:  10777 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.89, wpb=101.1, bsz=40, num_updates=26520, lr=3.458e-05, gnorm=0.812, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84236
2022-09-29 20:07:03 - progress_bar.py[line:274] - INFO: epoch 002:  10787 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.89, wpb=102.3, bsz=40, num_updates=26530, lr=3.45735e-05, gnorm=0.759, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84248
2022-09-29 20:07:14 - progress_bar.py[line:274] - INFO: epoch 002:  10797 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.9, wpb=101.7, bsz=40, num_updates=26540, lr=3.45669e-05, gnorm=0.684, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84259
2022-09-29 20:07:26 - progress_bar.py[line:274] - INFO: epoch 002:  10807 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.7, ups=0.87, wpb=102.1, bsz=40, num_updates=26550, lr=3.45603e-05, gnorm=0.743, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=84270
2022-09-29 20:07:37 - progress_bar.py[line:274] - INFO: epoch 002:  10817 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.5, ups=0.9, wpb=100.7, bsz=40, num_updates=26560, lr=3.45537e-05, gnorm=0.737, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84281
2022-09-29 20:07:48 - progress_bar.py[line:274] - INFO: epoch 002:  10827 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.4, ups=0.87, wpb=100.5, bsz=40, num_updates=26570, lr=3.45471e-05, gnorm=0.701, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84293
2022-09-29 20:08:00 - progress_bar.py[line:274] - INFO: epoch 002:  10837 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.88, wpb=102.1, bsz=40, num_updates=26580, lr=3.45405e-05, gnorm=0.688, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84304
2022-09-29 20:08:12 - progress_bar.py[line:274] - INFO: epoch 002:  10847 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88, ups=0.86, wpb=101.9, bsz=40, num_updates=26590, lr=3.45339e-05, gnorm=0.83, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=84316
2022-09-29 20:08:23 - progress_bar.py[line:274] - INFO: epoch 002:  10857 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.88, wpb=100.4, bsz=40, num_updates=26600, lr=3.45273e-05, gnorm=0.878, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84328
2022-09-29 20:08:34 - progress_bar.py[line:274] - INFO: epoch 002:  10867 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.7, ups=0.92, wpb=102.4, bsz=40, num_updates=26610, lr=3.45207e-05, gnorm=0.685, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84339
2022-09-29 20:08:45 - progress_bar.py[line:274] - INFO: epoch 002:  10877 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.9, wpb=99.3, bsz=40, num_updates=26620, lr=3.45141e-05, gnorm=0.752, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84350
2022-09-29 20:08:56 - progress_bar.py[line:274] - INFO: epoch 002:  10887 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.7, ups=0.92, wpb=101.2, bsz=40, num_updates=26630, lr=3.45075e-05, gnorm=0.797, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84361
2022-09-29 20:09:08 - progress_bar.py[line:274] - INFO: epoch 002:  10897 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.5, ups=0.89, wpb=102.2, bsz=40, num_updates=26640, lr=3.45009e-05, gnorm=0.739, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84373
2022-09-29 20:09:19 - progress_bar.py[line:274] - INFO: epoch 002:  10907 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.2, ups=0.92, wpb=101.2, bsz=40, num_updates=26650, lr=3.44943e-05, gnorm=0.809, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84383
2022-09-29 20:09:30 - progress_bar.py[line:274] - INFO: epoch 002:  10917 / 15783 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.1, ups=0.91, wpb=103.5, bsz=40, num_updates=26660, lr=3.44877e-05, gnorm=0.713, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84394
2022-09-29 20:09:41 - progress_bar.py[line:274] - INFO: epoch 002:  10927 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.3, ups=0.91, wpb=101.2, bsz=40, num_updates=26670, lr=3.44811e-05, gnorm=0.957, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84405
2022-09-29 20:09:52 - progress_bar.py[line:274] - INFO: epoch 002:  10937 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.3, ups=0.9, wpb=99.2, bsz=40, num_updates=26680, lr=3.44745e-05, gnorm=0.816, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84416
2022-09-29 20:10:03 - progress_bar.py[line:274] - INFO: epoch 002:  10947 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.88, wpb=101.7, bsz=40, num_updates=26690, lr=3.44679e-05, gnorm=0.794, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=84428
2022-09-29 20:10:14 - progress_bar.py[line:274] - INFO: epoch 002:  10957 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.3, ups=0.87, wpb=99.8, bsz=40, num_updates=26700, lr=3.44613e-05, gnorm=0.793, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84439
2022-09-29 20:10:26 - progress_bar.py[line:274] - INFO: epoch 002:  10967 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.2, ups=0.88, wpb=101.8, bsz=40, num_updates=26710, lr=3.44547e-05, gnorm=0.735, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84451
2022-09-29 20:10:37 - progress_bar.py[line:274] - INFO: epoch 002:  10977 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.8, ups=0.93, wpb=99.8, bsz=40, num_updates=26720, lr=3.44481e-05, gnorm=0.889, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84462
2022-09-29 20:10:48 - progress_bar.py[line:274] - INFO: epoch 002:  10987 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.4, ups=0.9, wpb=101, bsz=40, num_updates=26730, lr=3.44415e-05, gnorm=0.697, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84473
2022-09-29 20:10:59 - progress_bar.py[line:274] - INFO: epoch 002:  10997 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.3, ups=0.87, wpb=102.4, bsz=40, num_updates=26740, lr=3.44349e-05, gnorm=0.702, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84484
2022-09-29 20:11:10 - progress_bar.py[line:274] - INFO: epoch 002:  11007 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.1, ups=0.91, wpb=102.7, bsz=40, num_updates=26750, lr=3.44283e-05, gnorm=0.779, clip=0, loss_scale=2048, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=84495
2022-09-29 20:11:22 - progress_bar.py[line:274] - INFO: epoch 002:  11017 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.1, ups=0.89, wpb=100.3, bsz=40, num_updates=26760, lr=3.44217e-05, gnorm=0.897, clip=30, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84507
2022-09-29 20:11:33 - progress_bar.py[line:274] - INFO: epoch 002:  11027 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.8, ups=0.87, wpb=101.5, bsz=40, num_updates=26770, lr=3.44151e-05, gnorm=0.833, clip=20, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=84518
2022-09-29 20:11:40 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-29 20:11:45 - progress_bar.py[line:274] - INFO: epoch 002:  11038 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86, ups=0.85, wpb=101.1, bsz=40, num_updates=26780, lr=3.44085e-05, gnorm=0.76, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=84530
2022-09-29 20:11:56 - progress_bar.py[line:274] - INFO: epoch 002:  11048 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=26790, lr=3.44019e-05, gnorm=0.662, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=84541
2022-09-29 20:12:08 - progress_bar.py[line:274] - INFO: epoch 002:  11058 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.5, ups=0.88, wpb=103.4, bsz=40, num_updates=26800, lr=3.43953e-05, gnorm=0.796, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84552
2022-09-29 20:12:19 - progress_bar.py[line:274] - INFO: epoch 002:  11068 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.2, ups=0.9, wpb=102.6, bsz=40, num_updates=26810, lr=3.43887e-05, gnorm=0.783, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=84564
2022-09-29 20:12:30 - progress_bar.py[line:274] - INFO: epoch 002:  11078 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.2, ups=0.89, wpb=101.7, bsz=40, num_updates=26820, lr=3.43821e-05, gnorm=0.822, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84575
2022-09-29 20:12:41 - progress_bar.py[line:274] - INFO: epoch 002:  11088 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.7, ups=0.92, wpb=100.9, bsz=40, num_updates=26830, lr=3.43755e-05, gnorm=0.766, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=84586
2022-09-29 20:12:52 - progress_bar.py[line:274] - INFO: epoch 002:  11098 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.9, wpb=101.6, bsz=40, num_updates=26840, lr=3.43689e-05, gnorm=0.746, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84597
2022-09-29 20:13:03 - progress_bar.py[line:274] - INFO: epoch 002:  11108 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.91, wpb=100.8, bsz=40, num_updates=26850, lr=3.43623e-05, gnorm=0.756, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84608
2022-09-29 20:13:15 - progress_bar.py[line:274] - INFO: epoch 002:  11118 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=26860, lr=3.43557e-05, gnorm=0.659, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=84619
2022-09-29 20:13:26 - progress_bar.py[line:274] - INFO: epoch 002:  11128 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.7, ups=0.88, wpb=98.9, bsz=40, num_updates=26870, lr=3.43491e-05, gnorm=0.871, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84631
2022-09-29 20:13:37 - progress_bar.py[line:274] - INFO: epoch 002:  11138 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.2, ups=0.9, wpb=101.9, bsz=40, num_updates=26880, lr=3.43425e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84642
2022-09-29 20:13:49 - progress_bar.py[line:274] - INFO: epoch 002:  11148 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.9, ups=0.87, wpb=100.6, bsz=40, num_updates=26890, lr=3.43359e-05, gnorm=0.726, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84653
2022-09-29 20:14:00 - progress_bar.py[line:274] - INFO: epoch 002:  11158 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=26900, lr=3.43293e-05, gnorm=0.767, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=84665
2022-09-29 20:14:11 - progress_bar.py[line:274] - INFO: epoch 002:  11168 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.89, wpb=102.2, bsz=40, num_updates=26910, lr=3.43227e-05, gnorm=0.734, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84676
2022-09-29 20:14:22 - progress_bar.py[line:274] - INFO: epoch 002:  11178 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.7, ups=0.9, wpb=100.9, bsz=40, num_updates=26920, lr=3.43161e-05, gnorm=0.81, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84687
2022-09-29 20:14:34 - progress_bar.py[line:274] - INFO: epoch 002:  11188 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.8, ups=0.87, wpb=100.4, bsz=40, num_updates=26930, lr=3.43095e-05, gnorm=0.737, clip=10, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=84699
2022-09-29 20:14:45 - progress_bar.py[line:274] - INFO: epoch 002:  11198 / 15783 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.9, ups=0.91, wpb=99.9, bsz=40, num_updates=26940, lr=3.43029e-05, gnorm=0.799, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84710
2022-09-29 20:14:56 - progress_bar.py[line:274] - INFO: epoch 002:  11208 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.89, wpb=103, bsz=40, num_updates=26950, lr=3.42963e-05, gnorm=0.798, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84721
2022-09-29 20:15:07 - progress_bar.py[line:274] - INFO: epoch 002:  11218 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.3, ups=0.9, wpb=100.9, bsz=40, num_updates=26960, lr=3.42897e-05, gnorm=0.773, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=84732
2022-09-29 20:15:18 - progress_bar.py[line:274] - INFO: epoch 002:  11228 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.3, ups=0.9, wpb=101.8, bsz=40, num_updates=26970, lr=3.42831e-05, gnorm=0.791, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84743
2022-09-29 20:15:30 - progress_bar.py[line:274] - INFO: epoch 002:  11238 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.2, ups=0.87, wpb=102.1, bsz=40, num_updates=26980, lr=3.42765e-05, gnorm=0.854, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=84755
2022-09-29 20:15:41 - progress_bar.py[line:274] - INFO: epoch 002:  11248 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=26990, lr=3.42699e-05, gnorm=0.644, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84766
2022-09-29 20:15:52 - progress_bar.py[line:274] - INFO: epoch 002:  11258 / 15783 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92, ups=0.89, wpb=103.8, bsz=40, num_updates=27000, lr=3.42633e-05, gnorm=0.682, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84777
2022-09-29 20:16:03 - progress_bar.py[line:274] - INFO: epoch 002:  11268 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.91, wpb=99.2, bsz=40, num_updates=27010, lr=3.42567e-05, gnorm=0.917, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84788
2022-09-29 20:16:15 - progress_bar.py[line:274] - INFO: epoch 002:  11278 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.89, wpb=101.6, bsz=40, num_updates=27020, lr=3.42501e-05, gnorm=0.716, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84799
2022-09-29 20:16:26 - progress_bar.py[line:274] - INFO: epoch 002:  11288 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88, ups=0.86, wpb=101.8, bsz=40, num_updates=27030, lr=3.42435e-05, gnorm=0.793, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=84811
2022-09-29 20:16:38 - progress_bar.py[line:274] - INFO: epoch 002:  11298 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.3, ups=0.88, wpb=100.7, bsz=40, num_updates=27040, lr=3.42369e-05, gnorm=0.74, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84822
2022-09-29 20:16:42 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 20:16:50 - progress_bar.py[line:274] - INFO: epoch 002:  11309 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=84.6, ups=0.83, wpb=102.4, bsz=40, num_updates=27050, lr=3.42303e-05, gnorm=0.785, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=84834
2022-09-29 20:17:01 - progress_bar.py[line:274] - INFO: epoch 002:  11319 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93, ups=0.92, wpb=100.9, bsz=40, num_updates=27060, lr=3.42237e-05, gnorm=0.777, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84845
2022-09-29 20:17:12 - progress_bar.py[line:274] - INFO: epoch 002:  11329 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.91, wpb=101.3, bsz=40, num_updates=27070, lr=3.42171e-05, gnorm=0.767, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=84856
2022-09-29 20:17:23 - progress_bar.py[line:274] - INFO: epoch 002:  11339 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.6, ups=0.89, wpb=98.9, bsz=40, num_updates=27080, lr=3.42105e-05, gnorm=0.747, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84868
2022-09-29 20:17:34 - progress_bar.py[line:274] - INFO: epoch 002:  11349 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.2, ups=0.88, wpb=101.8, bsz=40, num_updates=27090, lr=3.42039e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84879
2022-09-29 20:17:46 - progress_bar.py[line:274] - INFO: epoch 002:  11359 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.3, ups=0.88, wpb=101.9, bsz=40, num_updates=27100, lr=3.41973e-05, gnorm=0.794, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84891
2022-09-29 20:17:57 - progress_bar.py[line:274] - INFO: epoch 002:  11369 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.8, ups=0.88, wpb=102.2, bsz=40, num_updates=27110, lr=3.41907e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84902
2022-09-29 20:18:09 - progress_bar.py[line:274] - INFO: epoch 002:  11379 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=27120, lr=3.41841e-05, gnorm=0.874, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84913
2022-09-29 20:18:20 - progress_bar.py[line:274] - INFO: epoch 002:  11389 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.5, ups=0.91, wpb=101.6, bsz=40, num_updates=27130, lr=3.41775e-05, gnorm=0.723, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84924
2022-09-29 20:18:31 - progress_bar.py[line:274] - INFO: epoch 002:  11399 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.9, ups=0.88, wpb=101.6, bsz=40, num_updates=27140, lr=3.41709e-05, gnorm=0.835, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84936
2022-09-29 20:18:42 - progress_bar.py[line:274] - INFO: epoch 002:  11409 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.6, ups=0.92, wpb=101, bsz=40, num_updates=27150, lr=3.41643e-05, gnorm=0.776, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84947
2022-09-29 20:18:53 - progress_bar.py[line:274] - INFO: epoch 002:  11419 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.8, ups=0.87, wpb=101.8, bsz=40, num_updates=27160, lr=3.41577e-05, gnorm=0.738, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84958
2022-09-29 20:19:04 - progress_bar.py[line:274] - INFO: epoch 002:  11429 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.8, ups=0.89, wpb=98.7, bsz=40, num_updates=27170, lr=3.41511e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84969
2022-09-29 20:19:16 - progress_bar.py[line:274] - INFO: epoch 002:  11439 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.2, ups=0.86, wpb=101.6, bsz=40, num_updates=27180, lr=3.41445e-05, gnorm=0.803, clip=10, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=84981
2022-09-29 20:19:27 - progress_bar.py[line:274] - INFO: epoch 002:  11449 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=101.4, bsz=40, num_updates=27190, lr=3.41379e-05, gnorm=0.883, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84992
2022-09-29 20:19:39 - progress_bar.py[line:274] - INFO: epoch 002:  11459 / 15783 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.3, ups=0.87, wpb=99.8, bsz=40, num_updates=27200, lr=3.41313e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=85004
2022-09-29 20:19:51 - progress_bar.py[line:274] - INFO: epoch 002:  11469 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=86.2, ups=0.86, wpb=99.8, bsz=40, num_updates=27210, lr=3.41247e-05, gnorm=0.922, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=85015
2022-09-29 20:20:02 - progress_bar.py[line:274] - INFO: epoch 002:  11479 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=27220, lr=3.41181e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85027
2022-09-29 20:20:13 - progress_bar.py[line:274] - INFO: epoch 002:  11489 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.91, wpb=102.5, bsz=40, num_updates=27230, lr=3.41115e-05, gnorm=0.876, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85038
2022-09-29 20:20:25 - progress_bar.py[line:274] - INFO: epoch 002:  11499 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.8, ups=0.87, wpb=101.6, bsz=40, num_updates=27240, lr=3.41049e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85049
2022-09-29 20:20:36 - progress_bar.py[line:274] - INFO: epoch 002:  11509 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.9, wpb=101.2, bsz=40, num_updates=27250, lr=3.40983e-05, gnorm=0.743, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=85060
2022-09-29 20:20:47 - progress_bar.py[line:274] - INFO: epoch 002:  11519 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.7, ups=0.88, wpb=102.6, bsz=40, num_updates=27260, lr=3.40917e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=85072
2022-09-29 20:20:59 - progress_bar.py[line:274] - INFO: epoch 002:  11529 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.6, ups=0.87, wpb=100, bsz=40, num_updates=27270, lr=3.40851e-05, gnorm=0.716, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=85083
2022-09-29 20:21:10 - progress_bar.py[line:274] - INFO: epoch 002:  11539 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.5, ups=0.88, wpb=102, bsz=40, num_updates=27280, lr=3.40785e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85095
2022-09-29 20:21:21 - progress_bar.py[line:274] - INFO: epoch 002:  11549 / 15783 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.89, wpb=98.8, bsz=40, num_updates=27290, lr=3.40719e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85106
2022-09-29 20:21:32 - progress_bar.py[line:274] - INFO: epoch 002:  11559 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.89, wpb=99.9, bsz=40, num_updates=27300, lr=3.40653e-05, gnorm=0.762, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85117
2022-09-29 20:21:44 - progress_bar.py[line:274] - INFO: epoch 002:  11569 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=27310, lr=3.40587e-05, gnorm=0.662, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85129
2022-09-29 20:21:55 - progress_bar.py[line:274] - INFO: epoch 002:  11579 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.1, ups=0.92, wpb=101.2, bsz=40, num_updates=27320, lr=3.40521e-05, gnorm=0.762, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85139
2022-09-29 20:22:06 - progress_bar.py[line:274] - INFO: epoch 002:  11589 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.91, wpb=102.4, bsz=40, num_updates=27330, lr=3.40455e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=85151
2022-09-29 20:22:17 - progress_bar.py[line:274] - INFO: epoch 002:  11599 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.89, wpb=101.9, bsz=40, num_updates=27340, lr=3.40389e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85162
2022-09-29 20:22:28 - progress_bar.py[line:274] - INFO: epoch 002:  11609 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.89, wpb=103.1, bsz=40, num_updates=27350, lr=3.40323e-05, gnorm=0.733, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85173
2022-09-29 20:22:41 - progress_bar.py[line:274] - INFO: epoch 002:  11619 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=27360, lr=3.40257e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85184
2022-09-29 20:22:52 - progress_bar.py[line:274] - INFO: epoch 002:  11629 / 15783 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=91, ups=0.91, wpb=99.9, bsz=40, num_updates=27370, lr=3.40191e-05, gnorm=0.863, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85197
2022-09-29 20:23:04 - progress_bar.py[line:274] - INFO: epoch 002:  11639 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.1, ups=0.86, wpb=103.3, bsz=40, num_updates=27380, lr=3.40125e-05, gnorm=0.671, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=85208
2022-09-29 20:23:15 - progress_bar.py[line:274] - INFO: epoch 002:  11649 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.2, ups=0.89, wpb=101.7, bsz=40, num_updates=27390, lr=3.40059e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85220
2022-09-29 20:23:26 - progress_bar.py[line:274] - INFO: epoch 002:  11659 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.3, ups=0.87, wpb=100.7, bsz=40, num_updates=27400, lr=3.39993e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85231
2022-09-29 20:23:38 - progress_bar.py[line:274] - INFO: epoch 002:  11669 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.89, wpb=100.3, bsz=40, num_updates=27410, lr=3.39927e-05, gnorm=0.787, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85243
2022-09-29 20:23:49 - progress_bar.py[line:274] - INFO: epoch 002:  11679 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.88, wpb=101.1, bsz=40, num_updates=27420, lr=3.39861e-05, gnorm=0.758, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=85254
2022-09-29 20:24:00 - progress_bar.py[line:274] - INFO: epoch 002:  11689 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.91, wpb=99.3, bsz=40, num_updates=27430, lr=3.39795e-05, gnorm=0.807, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85265
2022-09-29 20:24:12 - progress_bar.py[line:274] - INFO: epoch 002:  11699 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87, ups=0.86, wpb=101, bsz=40, num_updates=27440, lr=3.39729e-05, gnorm=0.771, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=85277
2022-09-29 20:24:23 - progress_bar.py[line:274] - INFO: epoch 002:  11709 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=86.8, ups=0.86, wpb=100.5, bsz=40, num_updates=27450, lr=3.39663e-05, gnorm=0.743, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=85288
2022-09-29 20:24:35 - progress_bar.py[line:274] - INFO: epoch 002:  11719 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=27460, lr=3.39597e-05, gnorm=0.816, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85299
2022-09-29 20:24:46 - progress_bar.py[line:274] - INFO: epoch 002:  11729 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.8, ups=0.91, wpb=100.7, bsz=40, num_updates=27470, lr=3.39531e-05, gnorm=0.824, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85310
2022-09-29 20:24:56 - progress_bar.py[line:274] - INFO: epoch 002:  11739 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.6, ups=0.91, wpb=103.5, bsz=40, num_updates=27480, lr=3.39465e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85321
2022-09-29 20:25:08 - progress_bar.py[line:274] - INFO: epoch 002:  11749 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.7, ups=0.86, wpb=101.4, bsz=40, num_updates=27490, lr=3.39399e-05, gnorm=0.824, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=85333
2022-09-29 20:25:19 - progress_bar.py[line:274] - INFO: epoch 002:  11759 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.3, ups=0.91, wpb=103.4, bsz=40, num_updates=27500, lr=3.39333e-05, gnorm=0.766, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85344
2022-09-29 20:25:30 - progress_bar.py[line:274] - INFO: epoch 002:  11769 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.89, wpb=100.6, bsz=40, num_updates=27510, lr=3.39267e-05, gnorm=0.824, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85355
2022-09-29 20:25:42 - progress_bar.py[line:274] - INFO: epoch 002:  11779 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88, ups=0.87, wpb=101, bsz=40, num_updates=27520, lr=3.39201e-05, gnorm=0.818, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85367
2022-09-29 20:25:53 - progress_bar.py[line:274] - INFO: epoch 002:  11789 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.6, ups=0.92, wpb=102.6, bsz=40, num_updates=27530, lr=3.39135e-05, gnorm=0.688, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85377
2022-09-29 20:26:05 - progress_bar.py[line:274] - INFO: epoch 002:  11799 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.88, wpb=102.3, bsz=40, num_updates=27540, lr=3.39069e-05, gnorm=0.733, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=85389
2022-09-29 20:26:16 - progress_bar.py[line:274] - INFO: epoch 002:  11809 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.2, ups=0.92, wpb=101.5, bsz=40, num_updates=27550, lr=3.39003e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=85400
2022-09-29 20:26:27 - progress_bar.py[line:274] - INFO: epoch 002:  11819 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=101.3, bsz=40, num_updates=27560, lr=3.38937e-05, gnorm=0.838, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85412
2022-09-29 20:26:38 - progress_bar.py[line:274] - INFO: epoch 002:  11829 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.7, ups=0.88, wpb=101.3, bsz=40, num_updates=27570, lr=3.38871e-05, gnorm=0.769, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85423
2022-09-29 20:26:49 - progress_bar.py[line:274] - INFO: epoch 002:  11839 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=27580, lr=3.38805e-05, gnorm=0.738, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=85434
2022-09-29 20:27:01 - progress_bar.py[line:274] - INFO: epoch 002:  11849 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.8, ups=0.88, wpb=101.4, bsz=40, num_updates=27590, lr=3.38739e-05, gnorm=0.813, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85446
2022-09-29 20:27:12 - progress_bar.py[line:274] - INFO: epoch 002:  11859 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.4, ups=0.91, wpb=100.2, bsz=40, num_updates=27600, lr=3.38673e-05, gnorm=0.766, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85457
2022-09-29 20:27:23 - progress_bar.py[line:274] - INFO: epoch 002:  11869 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.4, ups=0.9, wpb=100.7, bsz=40, num_updates=27610, lr=3.38607e-05, gnorm=0.675, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85468
2022-09-29 20:27:34 - progress_bar.py[line:274] - INFO: epoch 002:  11879 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.4, ups=0.88, wpb=101, bsz=40, num_updates=27620, lr=3.38541e-05, gnorm=0.707, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85479
2022-09-29 20:27:46 - progress_bar.py[line:274] - INFO: epoch 002:  11889 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.7, ups=0.87, wpb=101.3, bsz=40, num_updates=27630, lr=3.38475e-05, gnorm=0.724, clip=10, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=85491
2022-09-29 20:27:57 - progress_bar.py[line:274] - INFO: epoch 002:  11899 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.7, ups=0.87, wpb=101.7, bsz=40, num_updates=27640, lr=3.38409e-05, gnorm=0.693, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85502
2022-09-29 20:28:09 - progress_bar.py[line:274] - INFO: epoch 002:  11909 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.7, ups=0.87, wpb=100.4, bsz=40, num_updates=27650, lr=3.38343e-05, gnorm=0.852, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85514
2022-09-29 20:28:20 - progress_bar.py[line:274] - INFO: epoch 002:  11919 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.87, wpb=102, bsz=40, num_updates=27660, lr=3.38277e-05, gnorm=0.815, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85525
2022-09-29 20:28:32 - progress_bar.py[line:274] - INFO: epoch 002:  11929 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.3, ups=0.88, wpb=100.6, bsz=40, num_updates=27670, lr=3.38211e-05, gnorm=0.903, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=85537
2022-09-29 20:28:43 - progress_bar.py[line:274] - INFO: epoch 002:  11939 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.2, ups=0.87, wpb=102.2, bsz=40, num_updates=27680, lr=3.38145e-05, gnorm=0.766, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85548
2022-09-29 20:28:55 - progress_bar.py[line:274] - INFO: epoch 002:  11949 / 15783 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=89.5, ups=0.88, wpb=101.2, bsz=40, num_updates=27690, lr=3.38079e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85559
2022-09-29 20:29:06 - progress_bar.py[line:274] - INFO: epoch 002:  11959 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.9, wpb=101.2, bsz=40, num_updates=27700, lr=3.38013e-05, gnorm=0.94, clip=40, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=85571
2022-09-29 20:29:17 - progress_bar.py[line:274] - INFO: epoch 002:  11969 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.9, wpb=101.2, bsz=40, num_updates=27710, lr=3.37947e-05, gnorm=0.743, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85582
2022-09-29 20:29:28 - progress_bar.py[line:274] - INFO: epoch 002:  11979 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=91.2, ups=0.91, wpb=100.5, bsz=40, num_updates=27720, lr=3.37881e-05, gnorm=0.844, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85593
2022-09-29 20:29:39 - progress_bar.py[line:274] - INFO: epoch 002:  11989 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.5, ups=0.87, wpb=103.2, bsz=40, num_updates=27730, lr=3.37815e-05, gnorm=0.715, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=85604
2022-09-29 20:29:50 - progress_bar.py[line:274] - INFO: epoch 002:  11999 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.92, wpb=101.3, bsz=40, num_updates=27740, lr=3.37749e-05, gnorm=0.829, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85615
2022-09-29 20:30:01 - progress_bar.py[line:274] - INFO: epoch 002:  12009 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.5, ups=0.94, wpb=101.5, bsz=40, num_updates=27750, lr=3.37683e-05, gnorm=0.738, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85626
2022-09-29 20:30:12 - progress_bar.py[line:274] - INFO: epoch 002:  12019 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.5, ups=0.93, wpb=102, bsz=40, num_updates=27760, lr=3.37617e-05, gnorm=0.792, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=85637
2022-09-29 20:30:23 - progress_bar.py[line:274] - INFO: epoch 002:  12029 / 15783 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=87, ups=0.87, wpb=99.8, bsz=40, num_updates=27770, lr=3.37551e-05, gnorm=0.824, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85648
2022-09-29 20:30:34 - progress_bar.py[line:274] - INFO: epoch 002:  12039 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.89, wpb=101.1, bsz=40, num_updates=27780, lr=3.37485e-05, gnorm=0.735, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85659
2022-09-29 20:30:46 - progress_bar.py[line:274] - INFO: epoch 002:  12049 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.88, wpb=101.9, bsz=40, num_updates=27790, lr=3.37419e-05, gnorm=0.732, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85671
2022-09-29 20:30:57 - progress_bar.py[line:274] - INFO: epoch 002:  12059 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.8, ups=0.87, wpb=101.4, bsz=40, num_updates=27800, lr=3.37353e-05, gnorm=0.672, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=85682
2022-09-29 20:31:09 - progress_bar.py[line:274] - INFO: epoch 002:  12069 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=101.2, bsz=40, num_updates=27810, lr=3.37287e-05, gnorm=0.776, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85693
2022-09-29 20:31:20 - progress_bar.py[line:274] - INFO: epoch 002:  12079 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.9, wpb=101.3, bsz=40, num_updates=27820, lr=3.37221e-05, gnorm=0.742, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=85704
2022-09-29 20:31:31 - progress_bar.py[line:274] - INFO: epoch 002:  12089 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.89, wpb=101.1, bsz=40, num_updates=27830, lr=3.37155e-05, gnorm=0.746, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=85716
2022-09-29 20:31:42 - progress_bar.py[line:274] - INFO: epoch 002:  12099 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=27840, lr=3.37089e-05, gnorm=0.734, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=85727
2022-09-29 20:31:53 - progress_bar.py[line:274] - INFO: epoch 002:  12109 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.7, ups=0.88, wpb=103.4, bsz=40, num_updates=27850, lr=3.37023e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85738
2022-09-29 20:32:05 - progress_bar.py[line:274] - INFO: epoch 002:  12119 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.1, ups=0.88, wpb=101.7, bsz=40, num_updates=27860, lr=3.36957e-05, gnorm=0.737, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85750
2022-09-29 20:32:16 - progress_bar.py[line:274] - INFO: epoch 002:  12129 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=27870, lr=3.36891e-05, gnorm=0.697, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85761
2022-09-29 20:32:27 - progress_bar.py[line:274] - INFO: epoch 002:  12139 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.89, wpb=102, bsz=40, num_updates=27880, lr=3.36825e-05, gnorm=0.754, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=85772
2022-09-29 20:32:39 - progress_bar.py[line:274] - INFO: epoch 002:  12149 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.9, wpb=101.2, bsz=40, num_updates=27890, lr=3.36759e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85783
2022-09-29 20:32:50 - progress_bar.py[line:274] - INFO: epoch 002:  12159 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.9, wpb=101, bsz=40, num_updates=27900, lr=3.36693e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85794
2022-09-29 20:33:01 - progress_bar.py[line:274] - INFO: epoch 002:  12169 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=27910, lr=3.36627e-05, gnorm=0.816, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85806
2022-09-29 20:33:12 - progress_bar.py[line:274] - INFO: epoch 002:  12179 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.9, wpb=100.3, bsz=40, num_updates=27920, lr=3.36561e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=85817
2022-09-29 20:33:23 - progress_bar.py[line:274] - INFO: epoch 002:  12189 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.4, ups=0.88, wpb=100.9, bsz=40, num_updates=27930, lr=3.36495e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=85828
2022-09-29 20:33:35 - progress_bar.py[line:274] - INFO: epoch 002:  12199 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.88, wpb=102.3, bsz=40, num_updates=27940, lr=3.36429e-05, gnorm=0.802, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=85840
2022-09-29 20:33:46 - progress_bar.py[line:274] - INFO: epoch 002:  12209 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.5, ups=0.91, wpb=101.8, bsz=40, num_updates=27950, lr=3.36363e-05, gnorm=0.857, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85851
2022-09-29 20:33:57 - progress_bar.py[line:274] - INFO: epoch 002:  12219 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.9, wpb=102.8, bsz=40, num_updates=27960, lr=3.36297e-05, gnorm=0.713, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=85862
2022-09-29 20:34:08 - progress_bar.py[line:274] - INFO: epoch 002:  12229 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.91, wpb=100, bsz=40, num_updates=27970, lr=3.36231e-05, gnorm=0.71, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85873
2022-09-29 20:34:19 - progress_bar.py[line:274] - INFO: epoch 002:  12239 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94, ups=0.93, wpb=100.8, bsz=40, num_updates=27980, lr=3.36165e-05, gnorm=0.701, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85884
2022-09-29 20:34:30 - progress_bar.py[line:274] - INFO: epoch 002:  12249 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=27990, lr=3.36099e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=85895
2022-09-29 20:34:41 - progress_bar.py[line:274] - INFO: epoch 002:  12259 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.91, wpb=100.3, bsz=40, num_updates=28000, lr=3.36033e-05, gnorm=0.77, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=85906
2022-09-29 20:34:52 - progress_bar.py[line:274] - INFO: epoch 002:  12269 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.88, wpb=102.2, bsz=40, num_updates=28010, lr=3.35967e-05, gnorm=0.643, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85917
2022-09-29 20:35:04 - progress_bar.py[line:274] - INFO: epoch 002:  12279 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.88, wpb=101.7, bsz=40, num_updates=28020, lr=3.35901e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85928
2022-09-29 20:35:15 - progress_bar.py[line:274] - INFO: epoch 002:  12289 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.8, ups=0.88, wpb=100.7, bsz=40, num_updates=28030, lr=3.35835e-05, gnorm=0.721, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85940
2022-09-29 20:35:26 - progress_bar.py[line:274] - INFO: epoch 002:  12299 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.92, wpb=101.6, bsz=40, num_updates=28040, lr=3.35769e-05, gnorm=0.678, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85951
2022-09-29 20:35:37 - progress_bar.py[line:274] - INFO: epoch 002:  12309 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=28050, lr=3.35703e-05, gnorm=0.779, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=85962
2022-09-29 20:35:48 - progress_bar.py[line:274] - INFO: epoch 002:  12319 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.7, ups=0.9, wpb=100.6, bsz=40, num_updates=28060, lr=3.35637e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85973
2022-09-29 20:36:00 - progress_bar.py[line:274] - INFO: epoch 002:  12329 / 15783 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.3, ups=0.89, wpb=100.7, bsz=40, num_updates=28070, lr=3.35571e-05, gnorm=0.776, clip=10, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=85984
2022-09-29 20:36:06 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-29 20:36:12 - progress_bar.py[line:274] - INFO: epoch 002:  12340 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=83.3, ups=0.82, wpb=101.3, bsz=40, num_updates=28080, lr=3.35505e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=85997
2022-09-29 20:36:23 - progress_bar.py[line:274] - INFO: epoch 002:  12350 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.9, wpb=102, bsz=40, num_updates=28090, lr=3.35439e-05, gnorm=0.687, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=86008
2022-09-29 20:36:34 - progress_bar.py[line:274] - INFO: epoch 002:  12360 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.89, wpb=101.5, bsz=40, num_updates=28100, lr=3.35373e-05, gnorm=0.754, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86019
2022-09-29 20:36:46 - progress_bar.py[line:274] - INFO: epoch 002:  12370 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.3, ups=0.88, wpb=100.6, bsz=40, num_updates=28110, lr=3.35307e-05, gnorm=0.839, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86030
2022-09-29 20:36:57 - progress_bar.py[line:274] - INFO: epoch 002:  12380 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.9, wpb=101.7, bsz=40, num_updates=28120, lr=3.35241e-05, gnorm=0.76, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86041
2022-09-29 20:37:08 - progress_bar.py[line:274] - INFO: epoch 002:  12390 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.9, ups=0.87, wpb=101.7, bsz=40, num_updates=28130, lr=3.35175e-05, gnorm=0.795, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86053
2022-09-29 20:37:20 - progress_bar.py[line:274] - INFO: epoch 002:  12400 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.7, ups=0.87, wpb=101.4, bsz=40, num_updates=28140, lr=3.35109e-05, gnorm=0.714, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86064
2022-09-29 20:37:31 - progress_bar.py[line:274] - INFO: epoch 002:  12410 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.9, ups=0.9, wpb=104.4, bsz=40, num_updates=28150, lr=3.35043e-05, gnorm=0.872, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86076
2022-09-29 20:37:42 - progress_bar.py[line:274] - INFO: epoch 002:  12420 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.4, ups=0.9, wpb=102.7, bsz=40, num_updates=28160, lr=3.34977e-05, gnorm=0.782, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86087
2022-09-29 20:37:53 - progress_bar.py[line:274] - INFO: epoch 002:  12430 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.9, wpb=99.8, bsz=40, num_updates=28170, lr=3.34911e-05, gnorm=0.802, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86098
2022-09-29 20:38:04 - progress_bar.py[line:274] - INFO: epoch 002:  12440 / 15783 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.2, ups=0.88, wpb=100.3, bsz=40, num_updates=28180, lr=3.34845e-05, gnorm=0.784, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86109
2022-09-29 20:38:15 - progress_bar.py[line:274] - INFO: epoch 002:  12450 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91, ups=0.9, wpb=101.4, bsz=40, num_updates=28190, lr=3.34779e-05, gnorm=0.821, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86120
2022-09-29 20:38:27 - progress_bar.py[line:274] - INFO: epoch 002:  12460 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.9, ups=0.9, wpb=102, bsz=40, num_updates=28200, lr=3.34713e-05, gnorm=0.726, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86131
2022-09-29 20:38:38 - progress_bar.py[line:274] - INFO: epoch 002:  12470 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.89, wpb=101.9, bsz=40, num_updates=28210, lr=3.34647e-05, gnorm=0.695, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=86143
2022-09-29 20:38:49 - progress_bar.py[line:274] - INFO: epoch 002:  12480 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.9, wpb=101.9, bsz=40, num_updates=28220, lr=3.34581e-05, gnorm=0.73, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86154
2022-09-29 20:39:00 - progress_bar.py[line:274] - INFO: epoch 002:  12490 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=28230, lr=3.34515e-05, gnorm=0.791, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86165
2022-09-29 20:39:12 - progress_bar.py[line:274] - INFO: epoch 002:  12500 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.6, ups=0.88, wpb=100.9, bsz=40, num_updates=28240, lr=3.34449e-05, gnorm=0.768, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86176
2022-09-29 20:39:23 - progress_bar.py[line:274] - INFO: epoch 002:  12510 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.4, ups=0.89, wpb=102.4, bsz=40, num_updates=28250, lr=3.34383e-05, gnorm=0.694, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86188
2022-09-29 20:39:34 - progress_bar.py[line:274] - INFO: epoch 002:  12520 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.92, wpb=100.9, bsz=40, num_updates=28260, lr=3.34317e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86199
2022-09-29 20:39:46 - progress_bar.py[line:274] - INFO: epoch 002:  12530 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.88, wpb=103, bsz=40, num_updates=28270, lr=3.34251e-05, gnorm=0.811, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86210
2022-09-29 20:39:57 - progress_bar.py[line:274] - INFO: epoch 002:  12540 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.5, ups=0.88, wpb=101.2, bsz=40, num_updates=28280, lr=3.34185e-05, gnorm=0.898, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=86222
2022-09-29 20:40:08 - progress_bar.py[line:274] - INFO: epoch 002:  12550 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=28290, lr=3.34119e-05, gnorm=0.852, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86233
2022-09-29 20:40:19 - progress_bar.py[line:274] - INFO: epoch 002:  12560 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.89, wpb=102.7, bsz=40, num_updates=28300, lr=3.34053e-05, gnorm=0.858, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86244
2022-09-29 20:40:31 - progress_bar.py[line:274] - INFO: epoch 002:  12570 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.3, ups=0.9, wpb=102.4, bsz=40, num_updates=28310, lr=3.33987e-05, gnorm=0.758, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86255
2022-09-29 20:40:42 - progress_bar.py[line:274] - INFO: epoch 002:  12580 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.9, wpb=102.8, bsz=40, num_updates=28320, lr=3.33921e-05, gnorm=0.747, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86266
2022-09-29 20:40:53 - progress_bar.py[line:274] - INFO: epoch 002:  12590 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.8, ups=0.91, wpb=101.6, bsz=40, num_updates=28330, lr=3.33855e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=86277
2022-09-29 20:41:04 - progress_bar.py[line:274] - INFO: epoch 002:  12600 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.5, ups=0.92, wpb=101.4, bsz=40, num_updates=28340, lr=3.33789e-05, gnorm=0.753, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86289
2022-09-29 20:41:15 - progress_bar.py[line:274] - INFO: epoch 002:  12610 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.88, wpb=103.6, bsz=40, num_updates=28350, lr=3.33723e-05, gnorm=0.733, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86300
2022-09-29 20:41:26 - progress_bar.py[line:274] - INFO: epoch 002:  12620 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.91, wpb=101.1, bsz=40, num_updates=28360, lr=3.33657e-05, gnorm=0.688, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86311
2022-09-29 20:41:37 - progress_bar.py[line:274] - INFO: epoch 002:  12630 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.2, ups=0.92, wpb=99.9, bsz=40, num_updates=28370, lr=3.33591e-05, gnorm=0.771, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86322
2022-09-29 20:41:48 - progress_bar.py[line:274] - INFO: epoch 002:  12640 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.89, wpb=102.7, bsz=40, num_updates=28380, lr=3.33525e-05, gnorm=0.786, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86333
2022-09-29 20:41:59 - progress_bar.py[line:274] - INFO: epoch 002:  12650 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=28390, lr=3.33459e-05, gnorm=0.752, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86344
2022-09-29 20:42:10 - progress_bar.py[line:274] - INFO: epoch 002:  12660 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94, ups=0.93, wpb=101.2, bsz=40, num_updates=28400, lr=3.33393e-05, gnorm=0.821, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=86355
2022-09-29 20:42:21 - progress_bar.py[line:274] - INFO: epoch 002:  12670 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.9, wpb=101, bsz=40, num_updates=28410, lr=3.33327e-05, gnorm=0.769, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86366
2022-09-29 20:42:32 - progress_bar.py[line:274] - INFO: epoch 002:  12680 / 15783 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=90.4, ups=0.9, wpb=100.6, bsz=40, num_updates=28420, lr=3.33261e-05, gnorm=0.816, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86377
2022-09-29 20:42:44 - progress_bar.py[line:274] - INFO: epoch 002:  12690 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.89, wpb=101.1, bsz=40, num_updates=28430, lr=3.33195e-05, gnorm=0.711, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86389
2022-09-29 20:42:55 - progress_bar.py[line:274] - INFO: epoch 002:  12700 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=101.6, bsz=40, num_updates=28440, lr=3.33129e-05, gnorm=0.815, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86400
2022-09-29 20:43:06 - progress_bar.py[line:274] - INFO: epoch 002:  12710 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92.7, ups=0.91, wpb=101.8, bsz=40, num_updates=28450, lr=3.33063e-05, gnorm=0.738, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86411
2022-09-29 20:43:17 - progress_bar.py[line:274] - INFO: epoch 002:  12720 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=102.3, bsz=40, num_updates=28460, lr=3.32997e-05, gnorm=0.756, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86422
2022-09-29 20:43:29 - progress_bar.py[line:274] - INFO: epoch 002:  12730 / 15783 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.5, ups=0.89, wpb=104, bsz=40, num_updates=28470, lr=3.32931e-05, gnorm=0.736, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86433
2022-09-29 20:43:40 - progress_bar.py[line:274] - INFO: epoch 002:  12740 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.8, ups=0.9, wpb=101.9, bsz=40, num_updates=28480, lr=3.32865e-05, gnorm=0.793, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86445
2022-09-29 20:43:51 - progress_bar.py[line:274] - INFO: epoch 002:  12750 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.5, ups=0.9, wpb=103.7, bsz=40, num_updates=28490, lr=3.32799e-05, gnorm=0.751, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86456
2022-09-29 20:44:02 - progress_bar.py[line:274] - INFO: epoch 002:  12760 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.3, ups=0.87, wpb=101.5, bsz=40, num_updates=28500, lr=3.32733e-05, gnorm=0.828, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86467
2022-09-29 20:44:13 - progress_bar.py[line:274] - INFO: epoch 002:  12770 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.91, wpb=101.6, bsz=40, num_updates=28510, lr=3.32667e-05, gnorm=0.67, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86478
2022-09-29 20:44:25 - progress_bar.py[line:274] - INFO: epoch 002:  12780 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=28520, lr=3.32601e-05, gnorm=0.711, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86489
2022-09-29 20:44:36 - progress_bar.py[line:274] - INFO: epoch 002:  12790 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.87, wpb=102.3, bsz=40, num_updates=28530, lr=3.32535e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86501
2022-09-29 20:44:47 - progress_bar.py[line:274] - INFO: epoch 002:  12800 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.91, wpb=102.2, bsz=40, num_updates=28540, lr=3.32469e-05, gnorm=0.73, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86512
2022-09-29 20:44:58 - progress_bar.py[line:274] - INFO: epoch 002:  12810 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.9, wpb=102.3, bsz=40, num_updates=28550, lr=3.32403e-05, gnorm=0.876, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86523
2022-09-29 20:45:10 - progress_bar.py[line:274] - INFO: epoch 002:  12820 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.8, ups=0.89, wpb=100.2, bsz=40, num_updates=28560, lr=3.32337e-05, gnorm=0.877, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86534
2022-09-29 20:45:21 - progress_bar.py[line:274] - INFO: epoch 002:  12830 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88, ups=0.86, wpb=101.7, bsz=40, num_updates=28570, lr=3.32271e-05, gnorm=0.797, clip=0, loss_scale=1024, train_wall=12, gb_free=9.8, ema_decay=0.9999, wall=86546
2022-09-29 20:45:32 - progress_bar.py[line:274] - INFO: epoch 002:  12840 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.2, ups=0.9, wpb=99.5, bsz=40, num_updates=28580, lr=3.32205e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86557
2022-09-29 20:45:44 - progress_bar.py[line:274] - INFO: epoch 002:  12850 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.3, ups=0.88, wpb=101, bsz=40, num_updates=28590, lr=3.32139e-05, gnorm=0.796, clip=10, loss_scale=2048, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86568
2022-09-29 20:45:55 - progress_bar.py[line:274] - INFO: epoch 002:  12860 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.9, wpb=103.1, bsz=40, num_updates=28600, lr=3.32073e-05, gnorm=0.909, clip=10, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86580
2022-09-29 20:46:03 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-29 20:46:07 - progress_bar.py[line:274] - INFO: epoch 002:  12871 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=81.9, ups=0.8, wpb=102.4, bsz=40, num_updates=28610, lr=3.32007e-05, gnorm=0.845, clip=10, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=86592
2022-09-29 20:46:18 - progress_bar.py[line:274] - INFO: epoch 002:  12881 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=28620, lr=3.31941e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=86603
2022-09-29 20:46:29 - progress_bar.py[line:274] - INFO: epoch 002:  12891 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.93, wpb=101, bsz=40, num_updates=28630, lr=3.31875e-05, gnorm=0.672, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86614
2022-09-29 20:46:40 - progress_bar.py[line:274] - INFO: epoch 002:  12901 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.6, ups=0.9, wpb=99.5, bsz=40, num_updates=28640, lr=3.31809e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86625
2022-09-29 20:46:51 - progress_bar.py[line:274] - INFO: epoch 002:  12911 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.9, wpb=100.2, bsz=40, num_updates=28650, lr=3.31743e-05, gnorm=0.799, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86636
2022-09-29 20:47:03 - progress_bar.py[line:274] - INFO: epoch 002:  12921 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.2, ups=0.87, wpb=99.6, bsz=40, num_updates=28660, lr=3.31677e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=86648
2022-09-29 20:47:14 - progress_bar.py[line:274] - INFO: epoch 002:  12931 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.1, ups=0.88, wpb=100.6, bsz=40, num_updates=28670, lr=3.31611e-05, gnorm=0.843, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86659
2022-09-29 20:47:26 - progress_bar.py[line:274] - INFO: epoch 002:  12941 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.8, ups=0.89, wpb=101.4, bsz=40, num_updates=28680, lr=3.31545e-05, gnorm=0.747, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86671
2022-09-29 20:47:37 - progress_bar.py[line:274] - INFO: epoch 002:  12951 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.9, wpb=100.3, bsz=40, num_updates=28690, lr=3.31479e-05, gnorm=0.84, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=86682
2022-09-29 20:47:48 - progress_bar.py[line:274] - INFO: epoch 002:  12961 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=101.1, bsz=40, num_updates=28700, lr=3.31413e-05, gnorm=0.83, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86693
2022-09-29 20:47:59 - progress_bar.py[line:274] - INFO: epoch 002:  12971 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87, ups=0.88, wpb=99.2, bsz=40, num_updates=28710, lr=3.31347e-05, gnorm=0.812, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=86704
2022-09-29 20:48:11 - progress_bar.py[line:274] - INFO: epoch 002:  12981 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=28720, lr=3.31281e-05, gnorm=0.696, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86715
2022-09-29 20:48:22 - progress_bar.py[line:274] - INFO: epoch 002:  12991 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.89, wpb=100.5, bsz=40, num_updates=28730, lr=3.31215e-05, gnorm=0.735, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86727
2022-09-29 20:48:33 - progress_bar.py[line:274] - INFO: epoch 002:  13001 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.88, wpb=101.8, bsz=40, num_updates=28740, lr=3.31149e-05, gnorm=0.748, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86738
2022-09-29 20:48:44 - progress_bar.py[line:274] - INFO: epoch 002:  13011 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.7, ups=0.91, wpb=101.4, bsz=40, num_updates=28750, lr=3.31083e-05, gnorm=0.725, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86749
2022-09-29 20:48:56 - progress_bar.py[line:274] - INFO: epoch 002:  13021 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=28760, lr=3.31017e-05, gnorm=0.836, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86760
2022-09-29 20:49:07 - progress_bar.py[line:274] - INFO: epoch 002:  13031 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=92, ups=0.9, wpb=102.1, bsz=40, num_updates=28770, lr=3.30951e-05, gnorm=0.755, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86771
2022-09-29 20:49:18 - progress_bar.py[line:274] - INFO: epoch 002:  13041 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92, ups=0.9, wpb=102.2, bsz=40, num_updates=28780, lr=3.30885e-05, gnorm=0.704, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86783
2022-09-29 20:49:29 - progress_bar.py[line:274] - INFO: epoch 002:  13051 / 15783 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.1, ups=0.9, wpb=102.5, bsz=40, num_updates=28790, lr=3.30819e-05, gnorm=0.611, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86794
2022-09-29 20:49:40 - progress_bar.py[line:274] - INFO: epoch 002:  13061 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.4, ups=0.93, wpb=102.9, bsz=40, num_updates=28800, lr=3.30753e-05, gnorm=0.722, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=86805
2022-09-29 20:49:51 - progress_bar.py[line:274] - INFO: epoch 002:  13071 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=28810, lr=3.30687e-05, gnorm=0.753, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86816
2022-09-29 20:50:02 - progress_bar.py[line:274] - INFO: epoch 002:  13081 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.3, ups=0.9, wpb=102.5, bsz=40, num_updates=28820, lr=3.30621e-05, gnorm=0.82, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=86827
2022-09-29 20:50:13 - progress_bar.py[line:274] - INFO: epoch 002:  13091 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.8, ups=0.9, wpb=101.9, bsz=40, num_updates=28830, lr=3.30555e-05, gnorm=0.755, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86838
2022-09-29 20:50:24 - progress_bar.py[line:274] - INFO: epoch 002:  13101 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.89, wpb=100.9, bsz=40, num_updates=28840, lr=3.30489e-05, gnorm=0.829, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86849
2022-09-29 20:50:36 - progress_bar.py[line:274] - INFO: epoch 002:  13111 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92, ups=0.9, wpb=102.5, bsz=40, num_updates=28850, lr=3.30423e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86860
2022-09-29 20:50:47 - progress_bar.py[line:274] - INFO: epoch 002:  13121 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.4, ups=0.88, wpb=102.6, bsz=40, num_updates=28860, lr=3.30357e-05, gnorm=0.729, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86872
2022-09-29 20:50:58 - progress_bar.py[line:274] - INFO: epoch 002:  13131 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.4, ups=0.92, wpb=101.3, bsz=40, num_updates=28870, lr=3.30291e-05, gnorm=0.669, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86883
2022-09-29 20:51:09 - progress_bar.py[line:274] - INFO: epoch 002:  13141 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.4, ups=0.87, wpb=98.9, bsz=40, num_updates=28880, lr=3.30225e-05, gnorm=0.875, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86894
2022-09-29 20:51:20 - progress_bar.py[line:274] - INFO: epoch 002:  13151 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.9, wpb=102.6, bsz=40, num_updates=28890, lr=3.30159e-05, gnorm=0.777, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86905
2022-09-29 20:51:31 - progress_bar.py[line:274] - INFO: epoch 002:  13161 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.3, ups=0.93, wpb=101.8, bsz=40, num_updates=28900, lr=3.30093e-05, gnorm=0.802, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86916
2022-09-29 20:51:43 - progress_bar.py[line:274] - INFO: epoch 002:  13171 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.6, ups=0.88, wpb=101.1, bsz=40, num_updates=28910, lr=3.30027e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=86927
2022-09-29 20:51:54 - progress_bar.py[line:274] - INFO: epoch 002:  13181 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.9, wpb=101.5, bsz=40, num_updates=28920, lr=3.29961e-05, gnorm=0.741, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=86939
2022-09-29 20:52:04 - progress_bar.py[line:274] - INFO: epoch 002:  13191 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.8, ups=0.93, wpb=101, bsz=40, num_updates=28930, lr=3.29895e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=86949
2022-09-29 20:52:16 - progress_bar.py[line:274] - INFO: epoch 002:  13201 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.1, ups=0.88, wpb=102.8, bsz=40, num_updates=28940, lr=3.29829e-05, gnorm=0.755, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=86961
2022-09-29 20:52:27 - progress_bar.py[line:274] - INFO: epoch 002:  13211 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.1, ups=0.9, wpb=103.4, bsz=40, num_updates=28950, lr=3.29763e-05, gnorm=0.747, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86972
2022-09-29 20:52:38 - progress_bar.py[line:274] - INFO: epoch 002:  13221 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.4, ups=0.88, wpb=101.9, bsz=40, num_updates=28960, lr=3.29697e-05, gnorm=0.779, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=86983
2022-09-29 20:52:49 - progress_bar.py[line:274] - INFO: epoch 002:  13231 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.5, ups=0.91, wpb=101.4, bsz=40, num_updates=28970, lr=3.29631e-05, gnorm=0.862, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=86994
2022-09-29 20:53:01 - progress_bar.py[line:274] - INFO: epoch 002:  13241 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=101.3, bsz=40, num_updates=28980, lr=3.29565e-05, gnorm=0.76, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=87005
2022-09-29 20:53:12 - progress_bar.py[line:274] - INFO: epoch 002:  13251 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.1, ups=0.88, wpb=99.3, bsz=40, num_updates=28990, lr=3.29499e-05, gnorm=0.757, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=87017
2022-09-29 20:53:23 - progress_bar.py[line:274] - INFO: epoch 002:  13261 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.6, ups=0.9, wpb=102.8, bsz=40, num_updates=29000, lr=3.29433e-05, gnorm=0.757, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=87028
2022-09-29 20:53:35 - progress_bar.py[line:274] - INFO: epoch 002:  13271 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.9, ups=0.87, wpb=102.2, bsz=40, num_updates=29010, lr=3.29367e-05, gnorm=0.795, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87039
2022-09-29 20:53:46 - progress_bar.py[line:274] - INFO: epoch 002:  13281 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.91, wpb=100.5, bsz=40, num_updates=29020, lr=3.29301e-05, gnorm=0.77, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=87050
2022-09-29 20:53:57 - progress_bar.py[line:274] - INFO: epoch 002:  13291 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.92, wpb=100.7, bsz=40, num_updates=29030, lr=3.29235e-05, gnorm=0.795, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87061
2022-09-29 20:54:08 - progress_bar.py[line:274] - INFO: epoch 002:  13301 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93, ups=0.9, wpb=103.2, bsz=40, num_updates=29040, lr=3.29169e-05, gnorm=0.693, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87072
2022-09-29 20:54:19 - progress_bar.py[line:274] - INFO: epoch 002:  13311 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90, ups=0.89, wpb=101.5, bsz=40, num_updates=29050, lr=3.29103e-05, gnorm=0.707, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=87084
2022-09-29 20:54:30 - progress_bar.py[line:274] - INFO: epoch 002:  13321 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.5, ups=0.88, wpb=102.2, bsz=40, num_updates=29060, lr=3.29037e-05, gnorm=0.686, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=87095
2022-09-29 20:54:41 - progress_bar.py[line:274] - INFO: epoch 002:  13331 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.5, ups=0.91, wpb=102.1, bsz=40, num_updates=29070, lr=3.28971e-05, gnorm=0.743, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87106
2022-09-29 20:54:53 - progress_bar.py[line:274] - INFO: epoch 002:  13341 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.88, wpb=101.5, bsz=40, num_updates=29080, lr=3.28905e-05, gnorm=0.751, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87118
2022-09-29 20:55:04 - progress_bar.py[line:274] - INFO: epoch 002:  13351 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=29090, lr=3.28839e-05, gnorm=0.818, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=87129
2022-09-29 20:55:15 - progress_bar.py[line:274] - INFO: epoch 002:  13361 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.8, ups=0.91, wpb=101.8, bsz=40, num_updates=29100, lr=3.28773e-05, gnorm=0.771, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=87140
2022-09-29 20:55:26 - progress_bar.py[line:274] - INFO: epoch 002:  13371 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94, ups=0.9, wpb=104, bsz=40, num_updates=29110, lr=3.28707e-05, gnorm=0.695, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87151
2022-09-29 20:55:36 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-29 20:55:38 - progress_bar.py[line:274] - INFO: epoch 002:  13382 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=83.9, ups=0.83, wpb=100.7, bsz=40, num_updates=29120, lr=3.28641e-05, gnorm=0.779, clip=20, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=87163
2022-09-29 20:55:50 - progress_bar.py[line:274] - INFO: epoch 002:  13392 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.4, ups=0.87, wpb=100.5, bsz=40, num_updates=29130, lr=3.28575e-05, gnorm=0.936, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=87174
2022-09-29 20:56:01 - progress_bar.py[line:274] - INFO: epoch 002:  13402 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.89, wpb=101.4, bsz=40, num_updates=29140, lr=3.28509e-05, gnorm=0.835, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87186
2022-09-29 20:56:12 - progress_bar.py[line:274] - INFO: epoch 002:  13412 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.89, wpb=102.8, bsz=40, num_updates=29150, lr=3.28443e-05, gnorm=0.758, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87197
2022-09-29 20:56:24 - progress_bar.py[line:274] - INFO: epoch 002:  13422 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.7, ups=0.87, wpb=100.3, bsz=40, num_updates=29160, lr=3.28377e-05, gnorm=0.871, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87208
2022-09-29 20:56:34 - progress_bar.py[line:274] - INFO: epoch 002:  13432 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.1, ups=0.93, wpb=101.5, bsz=40, num_updates=29170, lr=3.28311e-05, gnorm=0.741, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87219
2022-09-29 20:56:46 - progress_bar.py[line:274] - INFO: epoch 002:  13442 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=29180, lr=3.28245e-05, gnorm=0.816, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=87231
2022-09-29 20:56:57 - progress_bar.py[line:274] - INFO: epoch 002:  13452 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.9, ups=0.88, wpb=101.3, bsz=40, num_updates=29190, lr=3.28179e-05, gnorm=0.764, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=87242
2022-09-29 20:57:08 - progress_bar.py[line:274] - INFO: epoch 002:  13462 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=29200, lr=3.28113e-05, gnorm=0.739, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87253
2022-09-29 20:57:19 - progress_bar.py[line:274] - INFO: epoch 002:  13472 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.9, ups=0.91, wpb=100.9, bsz=40, num_updates=29210, lr=3.28047e-05, gnorm=0.689, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=87264
2022-09-29 20:57:31 - progress_bar.py[line:274] - INFO: epoch 002:  13482 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.5, ups=0.9, wpb=103.1, bsz=40, num_updates=29220, lr=3.27981e-05, gnorm=0.737, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87275
2022-09-29 20:57:42 - progress_bar.py[line:274] - INFO: epoch 002:  13492 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.9, wpb=103.2, bsz=40, num_updates=29230, lr=3.27915e-05, gnorm=0.727, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87287
2022-09-29 20:57:53 - progress_bar.py[line:274] - INFO: epoch 002:  13502 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.8, ups=0.89, wpb=103.1, bsz=40, num_updates=29240, lr=3.27849e-05, gnorm=0.804, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87298
2022-09-29 20:58:04 - progress_bar.py[line:274] - INFO: epoch 002:  13512 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.89, wpb=101.1, bsz=40, num_updates=29250, lr=3.27783e-05, gnorm=0.774, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=87309
2022-09-29 20:58:16 - progress_bar.py[line:274] - INFO: epoch 002:  13522 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.7, ups=0.87, wpb=101.2, bsz=40, num_updates=29260, lr=3.27717e-05, gnorm=0.755, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=87321
2022-09-29 20:58:27 - progress_bar.py[line:274] - INFO: epoch 002:  13532 / 15783 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.3, ups=0.9, wpb=100.4, bsz=40, num_updates=29270, lr=3.27651e-05, gnorm=0.847, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=87332
2022-09-29 20:58:39 - progress_bar.py[line:274] - INFO: epoch 002:  13542 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.6, ups=0.87, wpb=101, bsz=40, num_updates=29280, lr=3.27585e-05, gnorm=0.656, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87343
2022-09-29 20:58:50 - progress_bar.py[line:274] - INFO: epoch 002:  13552 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.6, ups=0.9, wpb=100.6, bsz=40, num_updates=29290, lr=3.27519e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=87354
2022-09-29 20:59:01 - progress_bar.py[line:274] - INFO: epoch 002:  13562 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=29300, lr=3.27453e-05, gnorm=0.795, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87366
2022-09-29 20:59:12 - progress_bar.py[line:274] - INFO: epoch 002:  13572 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.5, ups=0.9, wpb=102.7, bsz=40, num_updates=29310, lr=3.27387e-05, gnorm=0.765, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87377
2022-09-29 20:59:23 - progress_bar.py[line:274] - INFO: epoch 002:  13582 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.1, ups=0.9, wpb=100.9, bsz=40, num_updates=29320, lr=3.27321e-05, gnorm=0.714, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87388
2022-09-29 20:59:35 - progress_bar.py[line:274] - INFO: epoch 002:  13592 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.4, ups=0.87, wpb=101.2, bsz=40, num_updates=29330, lr=3.27255e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=87399
2022-09-29 20:59:46 - progress_bar.py[line:274] - INFO: epoch 002:  13602 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=29340, lr=3.27189e-05, gnorm=0.859, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=87411
2022-09-29 20:59:57 - progress_bar.py[line:274] - INFO: epoch 002:  13612 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.92, wpb=99.5, bsz=40, num_updates=29350, lr=3.27123e-05, gnorm=0.78, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=87422
2022-09-29 21:00:08 - progress_bar.py[line:274] - INFO: epoch 002:  13622 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.9, wpb=100.7, bsz=40, num_updates=29360, lr=3.27057e-05, gnorm=0.765, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=87433
2022-09-29 21:00:19 - progress_bar.py[line:274] - INFO: epoch 002:  13632 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.4, ups=0.88, wpb=100, bsz=40, num_updates=29370, lr=3.26991e-05, gnorm=0.864, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87444
2022-09-29 21:00:30 - progress_bar.py[line:274] - INFO: epoch 002:  13642 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.89, wpb=102.1, bsz=40, num_updates=29380, lr=3.26925e-05, gnorm=0.792, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=87455
2022-09-29 21:00:42 - progress_bar.py[line:274] - INFO: epoch 002:  13652 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.9, wpb=100.5, bsz=40, num_updates=29390, lr=3.26859e-05, gnorm=0.789, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87466
2022-09-29 21:00:53 - progress_bar.py[line:274] - INFO: epoch 002:  13662 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.9, wpb=102.3, bsz=40, num_updates=29400, lr=3.26793e-05, gnorm=0.837, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87478
2022-09-29 21:01:04 - progress_bar.py[line:274] - INFO: epoch 002:  13672 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.7, ups=0.88, wpb=101.3, bsz=40, num_updates=29410, lr=3.26727e-05, gnorm=0.749, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87489
2022-09-29 21:01:15 - progress_bar.py[line:274] - INFO: epoch 002:  13682 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=100.8, bsz=40, num_updates=29420, lr=3.26661e-05, gnorm=0.768, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=87500
2022-09-29 21:01:27 - progress_bar.py[line:274] - INFO: epoch 002:  13692 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.9, wpb=101.4, bsz=40, num_updates=29430, lr=3.26595e-05, gnorm=0.685, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87511
2022-09-29 21:01:37 - progress_bar.py[line:274] - INFO: epoch 002:  13702 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94, ups=0.93, wpb=101.2, bsz=40, num_updates=29440, lr=3.26529e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87522
2022-09-29 21:01:49 - progress_bar.py[line:274] - INFO: epoch 002:  13712 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.7, ups=0.89, wpb=103.3, bsz=40, num_updates=29450, lr=3.26463e-05, gnorm=0.709, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87533
2022-09-29 21:02:00 - progress_bar.py[line:274] - INFO: epoch 002:  13722 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.5, ups=0.9, wpb=101.9, bsz=40, num_updates=29460, lr=3.26397e-05, gnorm=0.703, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87545
2022-09-29 21:02:11 - progress_bar.py[line:274] - INFO: epoch 002:  13732 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.88, wpb=102.2, bsz=40, num_updates=29470, lr=3.26331e-05, gnorm=0.821, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87556
2022-09-29 21:02:23 - progress_bar.py[line:274] - INFO: epoch 002:  13742 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.88, wpb=102.7, bsz=40, num_updates=29480, lr=3.26265e-05, gnorm=0.743, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87567
2022-09-29 21:02:34 - progress_bar.py[line:274] - INFO: epoch 002:  13752 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.8, ups=0.9, wpb=103, bsz=40, num_updates=29490, lr=3.26199e-05, gnorm=0.696, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87579
2022-09-29 21:02:45 - progress_bar.py[line:274] - INFO: epoch 002:  13762 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=29500, lr=3.26133e-05, gnorm=0.73, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=87590
2022-09-29 21:02:56 - progress_bar.py[line:274] - INFO: epoch 002:  13772 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.2, ups=0.92, wpb=101.2, bsz=40, num_updates=29510, lr=3.26067e-05, gnorm=0.682, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=87601
2022-09-29 21:03:07 - progress_bar.py[line:274] - INFO: epoch 002:  13782 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.89, wpb=100.3, bsz=40, num_updates=29520, lr=3.26001e-05, gnorm=0.75, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87612
2022-09-29 21:03:18 - progress_bar.py[line:274] - INFO: epoch 002:  13792 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.3, ups=0.91, wpb=103.2, bsz=40, num_updates=29530, lr=3.25935e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87623
2022-09-29 21:03:30 - progress_bar.py[line:274] - INFO: epoch 002:  13802 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.7, ups=0.87, wpb=101.3, bsz=40, num_updates=29540, lr=3.25869e-05, gnorm=0.886, clip=40, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=87635
2022-09-29 21:03:41 - progress_bar.py[line:274] - INFO: epoch 002:  13812 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.89, wpb=101.9, bsz=40, num_updates=29550, lr=3.25803e-05, gnorm=0.679, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87646
2022-09-29 21:03:52 - progress_bar.py[line:274] - INFO: epoch 002:  13822 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.89, wpb=102.6, bsz=40, num_updates=29560, lr=3.25737e-05, gnorm=0.871, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=87657
2022-09-29 21:04:03 - progress_bar.py[line:274] - INFO: epoch 002:  13832 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.9, wpb=100.8, bsz=40, num_updates=29570, lr=3.25671e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=87668
2022-09-29 21:04:15 - progress_bar.py[line:274] - INFO: epoch 002:  13842 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.9, wpb=100.7, bsz=40, num_updates=29580, lr=3.25605e-05, gnorm=0.782, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87679
2022-09-29 21:04:26 - progress_bar.py[line:274] - INFO: epoch 002:  13852 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92, ups=0.91, wpb=101.5, bsz=40, num_updates=29590, lr=3.25539e-05, gnorm=0.682, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=87690
2022-09-29 21:04:37 - progress_bar.py[line:274] - INFO: epoch 002:  13862 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.91, wpb=100.7, bsz=40, num_updates=29600, lr=3.25473e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87701
2022-09-29 21:04:48 - progress_bar.py[line:274] - INFO: epoch 002:  13872 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.1, ups=0.9, wpb=99.9, bsz=40, num_updates=29610, lr=3.25407e-05, gnorm=0.72, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=87713
2022-09-29 21:04:59 - progress_bar.py[line:274] - INFO: epoch 002:  13882 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88, ups=0.89, wpb=98.9, bsz=40, num_updates=29620, lr=3.25341e-05, gnorm=0.861, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=87724
2022-09-29 21:05:10 - progress_bar.py[line:274] - INFO: epoch 002:  13892 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.89, wpb=101.6, bsz=40, num_updates=29630, lr=3.25275e-05, gnorm=0.821, clip=10, loss_scale=2048, train_wall=11, gb_free=10, ema_decay=0.9999, wall=87735
2022-09-29 21:05:21 - progress_bar.py[line:274] - INFO: epoch 002:  13902 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.9, wpb=100.7, bsz=40, num_updates=29640, lr=3.25209e-05, gnorm=0.805, clip=20, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87746
2022-09-29 21:05:33 - progress_bar.py[line:274] - INFO: epoch 002:  13912 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.89, wpb=102.1, bsz=40, num_updates=29650, lr=3.25143e-05, gnorm=0.745, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87757
2022-09-29 21:05:34 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-29 21:05:45 - progress_bar.py[line:274] - INFO: epoch 002:  13923 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=82.9, ups=0.82, wpb=101.6, bsz=40, num_updates=29660, lr=3.25077e-05, gnorm=0.775, clip=10, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=87770
2022-09-29 21:05:56 - progress_bar.py[line:274] - INFO: epoch 002:  13933 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.89, wpb=102.4, bsz=40, num_updates=29670, lr=3.25011e-05, gnorm=0.756, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=87781
2022-09-29 21:06:08 - progress_bar.py[line:274] - INFO: epoch 002:  13943 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.6, ups=0.88, wpb=101.2, bsz=40, num_updates=29680, lr=3.24945e-05, gnorm=0.792, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87792
2022-09-29 21:06:19 - progress_bar.py[line:274] - INFO: epoch 002:  13953 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.89, wpb=101.4, bsz=40, num_updates=29690, lr=3.24879e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=87804
2022-09-29 21:06:30 - progress_bar.py[line:274] - INFO: epoch 002:  13963 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.91, wpb=100.1, bsz=40, num_updates=29700, lr=3.24813e-05, gnorm=0.641, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87815
2022-09-29 21:06:41 - progress_bar.py[line:274] - INFO: epoch 002:  13973 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.9, ups=0.91, wpb=101.1, bsz=40, num_updates=29710, lr=3.24747e-05, gnorm=0.75, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=87826
2022-09-29 21:06:52 - progress_bar.py[line:274] - INFO: epoch 002:  13983 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=85.9, ups=0.87, wpb=99, bsz=40, num_updates=29720, lr=3.24681e-05, gnorm=0.812, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87837
2022-09-29 21:07:04 - progress_bar.py[line:274] - INFO: epoch 002:  13993 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.89, wpb=103.2, bsz=40, num_updates=29730, lr=3.24615e-05, gnorm=0.732, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87848
2022-09-29 21:07:15 - progress_bar.py[line:274] - INFO: epoch 002:  14003 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.88, wpb=101, bsz=40, num_updates=29740, lr=3.24549e-05, gnorm=0.798, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87860
2022-09-29 21:07:26 - progress_bar.py[line:274] - INFO: epoch 002:  14013 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.6, ups=0.89, wpb=100.9, bsz=40, num_updates=29750, lr=3.24483e-05, gnorm=0.853, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87871
2022-09-29 21:07:37 - progress_bar.py[line:274] - INFO: epoch 002:  14023 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=94.8, ups=0.94, wpb=101.3, bsz=40, num_updates=29760, lr=3.24417e-05, gnorm=0.81, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=87882
2022-09-29 21:07:48 - progress_bar.py[line:274] - INFO: epoch 002:  14033 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.6, ups=0.92, wpb=102.1, bsz=40, num_updates=29770, lr=3.24351e-05, gnorm=0.741, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=87893
2022-09-29 21:07:59 - progress_bar.py[line:274] - INFO: epoch 002:  14043 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=29780, lr=3.24285e-05, gnorm=0.833, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=87904
2022-09-29 21:08:11 - progress_bar.py[line:274] - INFO: epoch 002:  14053 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.9, ups=0.88, wpb=102.1, bsz=40, num_updates=29790, lr=3.24219e-05, gnorm=0.735, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87915
2022-09-29 21:08:22 - progress_bar.py[line:274] - INFO: epoch 002:  14063 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.9, wpb=100.8, bsz=40, num_updates=29800, lr=3.24153e-05, gnorm=0.739, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=87927
2022-09-29 21:08:33 - progress_bar.py[line:274] - INFO: epoch 002:  14073 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.3, ups=0.87, wpb=101, bsz=40, num_updates=29810, lr=3.24087e-05, gnorm=0.683, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87938
2022-09-29 21:08:44 - progress_bar.py[line:274] - INFO: epoch 002:  14083 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.89, wpb=102.8, bsz=40, num_updates=29820, lr=3.24021e-05, gnorm=0.724, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=87949
2022-09-29 21:08:56 - progress_bar.py[line:274] - INFO: epoch 002:  14093 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.6, ups=0.87, wpb=101.3, bsz=40, num_updates=29830, lr=3.23955e-05, gnorm=0.774, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87961
2022-09-29 21:09:07 - progress_bar.py[line:274] - INFO: epoch 002:  14103 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.88, wpb=99.9, bsz=40, num_updates=29840, lr=3.23889e-05, gnorm=0.727, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=87972
2022-09-29 21:09:18 - progress_bar.py[line:274] - INFO: epoch 002:  14113 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=29850, lr=3.23823e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=87983
2022-09-29 21:09:29 - progress_bar.py[line:274] - INFO: epoch 002:  14123 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.9, wpb=100.7, bsz=40, num_updates=29860, lr=3.23757e-05, gnorm=0.841, clip=20, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=87994
2022-09-29 21:09:41 - progress_bar.py[line:274] - INFO: epoch 002:  14133 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.89, wpb=101.7, bsz=40, num_updates=29870, lr=3.23691e-05, gnorm=0.886, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88006
2022-09-29 21:09:52 - progress_bar.py[line:274] - INFO: epoch 002:  14143 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.92, wpb=101.3, bsz=40, num_updates=29880, lr=3.23625e-05, gnorm=0.736, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=88017
2022-09-29 21:10:03 - progress_bar.py[line:274] - INFO: epoch 002:  14153 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.1, ups=0.92, wpb=102.6, bsz=40, num_updates=29890, lr=3.23559e-05, gnorm=0.748, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88027
2022-09-29 21:10:14 - progress_bar.py[line:274] - INFO: epoch 002:  14163 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.9, wpb=101.5, bsz=40, num_updates=29900, lr=3.23493e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=88039
2022-09-29 21:10:25 - progress_bar.py[line:274] - INFO: epoch 002:  14173 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.89, wpb=103, bsz=40, num_updates=29910, lr=3.23427e-05, gnorm=0.691, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=88050
2022-09-29 21:10:36 - progress_bar.py[line:274] - INFO: epoch 002:  14183 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=29920, lr=3.23361e-05, gnorm=0.872, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88061
2022-09-29 21:10:48 - progress_bar.py[line:274] - INFO: epoch 002:  14193 / 15783 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.6, ups=0.89, wpb=102.2, bsz=40, num_updates=29930, lr=3.23295e-05, gnorm=0.629, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=88073
2022-09-29 21:10:59 - progress_bar.py[line:274] - INFO: epoch 002:  14203 / 15783 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=90.1, ups=0.88, wpb=102.9, bsz=40, num_updates=29940, lr=3.23229e-05, gnorm=0.673, clip=0, loss_scale=1024, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=88084
2022-09-29 21:11:10 - progress_bar.py[line:274] - INFO: epoch 002:  14213 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88, ups=0.88, wpb=99.6, bsz=40, num_updates=29950, lr=3.23163e-05, gnorm=0.781, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=88095
2022-09-29 21:11:22 - progress_bar.py[line:274] - INFO: epoch 002:  14223 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.9, wpb=99.9, bsz=40, num_updates=29960, lr=3.23097e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=88106
2022-09-29 21:11:33 - progress_bar.py[line:274] - INFO: epoch 002:  14233 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.3, ups=0.9, wpb=101.6, bsz=40, num_updates=29970, lr=3.23031e-05, gnorm=0.715, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88118
2022-09-29 21:11:44 - progress_bar.py[line:274] - INFO: epoch 002:  14243 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.6, ups=0.89, wpb=101.4, bsz=40, num_updates=29980, lr=3.22965e-05, gnorm=0.741, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=88129
2022-09-29 21:11:47 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-29 21:11:56 - progress_bar.py[line:274] - INFO: epoch 002:  14254 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=82, ups=0.82, wpb=100.6, bsz=40, num_updates=29990, lr=3.22899e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=88141
2022-09-29 21:12:08 - progress_bar.py[line:274] - INFO: epoch 002:  14264 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.8, ups=0.88, wpb=102.5, bsz=40, num_updates=30000, lr=3.22833e-05, gnorm=0.692, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=88152
2022-09-29 21:12:08 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-29 21:12:09 - train.py[line:549] - INFO: 0 / 14103
2022-09-29 21:12:09 - train.py[line:551] - INFO: load:0.81 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-29 21:12:10 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.82 GiB (GPU 0; 39.59 GiB total capacity; 12.88 GiB already allocated; 4.31 GiB free; 32.80 GiB reserved in total by PyTorch)
2022-09-29 21:12:10 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 35        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13184 MB |   16985 MB |   11782 TB |   11782 TB |
|       from large pool |   13039 MB |   16840 MB |   11777 TB |   11777 TB |
|       from small pool |     144 MB |     145 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13184 MB |   16985 MB |   11782 TB |   11782 TB |
|       from large pool |   13039 MB |   16840 MB |   11777 TB |   11777 TB |
|       from small pool |     144 MB |     145 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   33588 MB |   33588 MB |  426354 MB |  392766 MB |
|       from large pool |   33442 MB |   33442 MB |  425694 MB |  392252 MB |
|       from small pool |     146 MB |     146 MB |     660 MB |     514 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   20403 MB |   29077 MB |   13733 TB |   13733 TB |
|       from large pool |   20402 MB |   29075 MB |   13728 TB |   13728 TB |
|       from small pool |       1 MB |       1 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3660    |    3684    |  618851 K  |  618847 K  |
|       from large pool |     564    |     585    |  185283 K  |  185282 K  |
|       from small pool |    3096    |    3114    |  433567 K  |  433564 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3660    |    3684    |  618851 K  |  618847 K  |
|       from large pool |     564    |     585    |  185283 K  |  185282 K  |
|       from small pool |    3096    |    3114    |  433567 K  |  433564 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     118    |     118    |     854    |     736    |
|       from large pool |      45    |      45    |     524    |     479    |
|       from small pool |      73    |      73    |     330    |     257    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      81    |      88    |  457274 K  |  457274 K  |
|       from large pool |      42    |      49    |   87540 K  |   87540 K  |
|       from small pool |      39    |      46    |  369734 K  |  369734 K  |
|===========================================================================|

2022-09-29 21:12:10 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-29 21:12:10 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-29 21:12:20 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.71 GiB (GPU 1; 39.59 GiB total capacity; 12.70 GiB already allocated; 3.82 GiB free; 33.29 GiB reserved in total by PyTorch)
2022-09-29 21:12:20 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-29 21:12:20 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 30        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13009 MB |   16732 MB |   11840 TB |   11840 TB |
|       from large pool |   12865 MB |   16587 MB |   11836 TB |   11836 TB |
|       from small pool |     144 MB |     145 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13009 MB |   16732 MB |   11840 TB |   11840 TB |
|       from large pool |   12865 MB |   16587 MB |   11836 TB |   11836 TB |
|       from small pool |     144 MB |     145 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34086 MB |   34086 MB |  329236 MB |  295150 MB |
|       from large pool |   33940 MB |   33940 MB |  328582 MB |  294642 MB |
|       from small pool |     146 MB |     146 MB |     654 MB |     508 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   21076 MB |   29567 MB |   12542 TB |   12542 TB |
|       from large pool |   21074 MB |   29565 MB |   12537 TB |   12537 TB |
|       from small pool |       1 MB |       1 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3671    |    3695    |  618902 K  |  618899 K  |
|       from large pool |     564    |     585    |  185319 K  |  185319 K  |
|       from small pool |    3107    |    3116    |  433583 K  |  433580 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3671    |    3695    |  618902 K  |  618899 K  |
|       from large pool |     564    |     585    |  185319 K  |  185319 K  |
|       from small pool |    3107    |    3116    |  433583 K  |  433580 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     128    |     128    |     782    |     654    |
|       from large pool |      55    |      55    |     455    |     400    |
|       from small pool |      73    |      73    |     327    |     254    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      77    |      89    |  457514 K  |  457514 K  |
|       from large pool |      46    |      52    |   85577 K  |   85577 K  |
|       from small pool |      31    |      47    |  371937 K  |  371937 K  |
|===========================================================================|

2022-09-29 21:12:20 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-29 21:15:23 - train.py[line:549] - INFO: 200 / 14103
2022-09-29 21:15:23 - train.py[line:551] - INFO: load:0.83 valid_run:194.29 task_valid:184.68 collect_output:7.33
2022-09-29 21:18:31 - train.py[line:549] - INFO: 400 / 14103
2022-09-29 21:18:31 - train.py[line:551] - INFO: load:0.86 valid_run:382.65 task_valid:368.15 collect_output:11.17
2022-09-29 21:21:42 - train.py[line:549] - INFO: 600 / 14103
2022-09-29 21:21:42 - train.py[line:551] - INFO: load:0.88 valid_run:572.68 task_valid:551.67 collect_output:16.62
2022-09-29 21:24:52 - train.py[line:549] - INFO: 800 / 14103
2022-09-29 21:24:52 - train.py[line:551] - INFO: load:0.91 valid_run:763.03 task_valid:737.29 collect_output:20.27
2022-09-29 21:28:02 - train.py[line:549] - INFO: 1000 / 14103
2022-09-29 21:28:02 - train.py[line:551] - INFO: load:0.93 valid_run:953.35 task_valid:922.68 collect_output:24.13
2022-09-29 21:31:15 - train.py[line:549] - INFO: 1200 / 14103
2022-09-29 21:31:15 - train.py[line:551] - INFO: load:0.95 valid_run:1146.28 task_valid:1109.52 collect_output:29.13
2022-09-29 21:34:29 - train.py[line:549] - INFO: 1400 / 14103
2022-09-29 21:34:29 - train.py[line:551] - INFO: load:0.98 valid_run:1340.08 task_valid:1298.68 collect_output:32.71
2022-09-29 21:37:43 - train.py[line:549] - INFO: 1600 / 14103
2022-09-29 21:37:43 - train.py[line:551] - INFO: load:1.00 valid_run:1533.58 task_valid:1487.79 collect_output:35.94
2022-09-29 21:40:56 - train.py[line:549] - INFO: 1800 / 14103
2022-09-29 21:40:56 - train.py[line:551] - INFO: load:1.03 valid_run:1726.52 task_valid:1673.35 collect_output:42.24
2022-09-29 21:44:05 - train.py[line:549] - INFO: 2000 / 14103
2022-09-29 21:44:05 - train.py[line:551] - INFO: load:1.05 valid_run:1915.65 task_valid:1859.19 collect_output:44.46
2022-09-29 21:47:14 - train.py[line:549] - INFO: 2200 / 14103
2022-09-29 21:47:14 - train.py[line:551] - INFO: load:1.08 valid_run:2104.36 task_valid:2043.66 collect_output:47.66
2022-09-29 21:50:25 - train.py[line:549] - INFO: 2400 / 14103
2022-09-29 21:50:25 - train.py[line:551] - INFO: load:1.10 valid_run:2296.04 task_valid:2228.37 collect_output:53.55
2022-09-29 21:53:38 - train.py[line:549] - INFO: 2600 / 14103
2022-09-29 21:53:38 - train.py[line:551] - INFO: load:1.13 valid_run:2488.24 task_valid:2416.85 collect_output:56.23
2022-09-29 21:56:48 - train.py[line:549] - INFO: 2800 / 14103
2022-09-29 21:56:48 - train.py[line:551] - INFO: load:1.15 valid_run:2678.58 task_valid:2601.45 collect_output:60.90
2022-09-29 22:00:01 - train.py[line:549] - INFO: 3000 / 14103
2022-09-29 22:00:01 - train.py[line:551] - INFO: load:1.17 valid_run:2871.71 task_valid:2787.27 collect_output:67.16
2022-09-29 22:03:10 - train.py[line:549] - INFO: 3200 / 14103
2022-09-29 22:03:10 - train.py[line:551] - INFO: load:1.20 valid_run:3060.59 task_valid:2969.44 collect_output:72.85
2022-09-29 22:06:23 - train.py[line:549] - INFO: 3400 / 14103
2022-09-29 22:06:23 - train.py[line:551] - INFO: load:1.22 valid_run:3253.10 task_valid:3153.21 collect_output:80.55
2022-09-29 22:09:36 - train.py[line:549] - INFO: 3600 / 14103
2022-09-29 22:09:36 - train.py[line:551] - INFO: load:1.25 valid_run:3445.99 task_valid:3338.74 collect_output:86.90
2022-09-29 22:12:46 - train.py[line:549] - INFO: 3800 / 14103
2022-09-29 22:12:46 - train.py[line:551] - INFO: load:1.27 valid_run:3636.28 task_valid:3520.86 collect_output:94.05
2022-09-29 22:15:54 - train.py[line:549] - INFO: 4000 / 14103
2022-09-29 22:15:54 - train.py[line:551] - INFO: load:1.29 valid_run:3824.13 task_valid:3703.56 collect_output:98.19
2022-09-29 22:19:05 - train.py[line:549] - INFO: 4200 / 14103
2022-09-29 22:19:05 - train.py[line:551] - INFO: load:1.32 valid_run:4014.86 task_valid:3891.59 collect_output:99.87
2022-09-29 22:22:13 - train.py[line:549] - INFO: 4400 / 14103
2022-09-29 22:22:13 - train.py[line:551] - INFO: load:1.34 valid_run:4202.69 task_valid:4072.18 collect_output:106.11
2022-09-29 22:25:24 - train.py[line:549] - INFO: 4600 / 14103
2022-09-29 22:25:24 - train.py[line:551] - INFO: load:1.37 valid_run:4394.19 task_valid:4256.73 collect_output:112.03
2022-09-29 22:28:33 - train.py[line:549] - INFO: 4800 / 14103
2022-09-29 22:28:33 - train.py[line:551] - INFO: load:1.39 valid_run:4582.59 task_valid:4439.93 collect_output:116.19
2022-09-29 22:31:43 - train.py[line:549] - INFO: 5000 / 14103
2022-09-29 22:31:43 - train.py[line:551] - INFO: load:1.41 valid_run:4772.52 task_valid:4624.55 collect_output:120.43
2022-09-29 22:34:53 - train.py[line:549] - INFO: 5200 / 14103
2022-09-29 22:34:53 - train.py[line:551] - INFO: load:1.44 valid_run:4962.46 task_valid:4808.58 collect_output:125.22
2022-09-29 22:38:05 - train.py[line:549] - INFO: 5400 / 14103
2022-09-29 22:38:05 - train.py[line:551] - INFO: load:1.46 valid_run:5155.09 task_valid:4997.72 collect_output:127.56
2022-09-29 22:41:17 - train.py[line:549] - INFO: 5600 / 14103
2022-09-29 22:41:17 - train.py[line:551] - INFO: load:1.49 valid_run:5346.56 task_valid:5184.79 collect_output:130.85
2022-09-29 22:44:30 - train.py[line:549] - INFO: 5800 / 14103
2022-09-29 22:44:30 - train.py[line:551] - INFO: load:1.51 valid_run:5540.00 task_valid:5371.47 collect_output:136.53
2022-09-29 22:47:38 - train.py[line:549] - INFO: 6000 / 14103
2022-09-29 22:47:38 - train.py[line:551] - INFO: load:1.54 valid_run:5727.95 task_valid:5552.40 collect_output:142.53
2022-09-29 22:50:51 - train.py[line:549] - INFO: 6200 / 14103
2022-09-29 22:50:51 - train.py[line:551] - INFO: load:1.56 valid_run:5920.15 task_valid:5737.99 collect_output:148.06
2022-09-29 22:54:01 - train.py[line:549] - INFO: 6400 / 14103
2022-09-29 22:54:01 - train.py[line:551] - INFO: load:1.59 valid_run:6109.97 task_valid:5922.92 collect_output:151.94
2022-09-29 22:57:09 - train.py[line:549] - INFO: 6600 / 14103
2022-09-29 22:57:09 - train.py[line:551] - INFO: load:1.61 valid_run:6298.47 task_valid:6103.61 collect_output:158.72
2022-09-29 23:00:21 - train.py[line:549] - INFO: 6800 / 14103
2022-09-29 23:00:21 - train.py[line:551] - INFO: load:1.64 valid_run:6490.61 task_valid:6287.42 collect_output:166.03
2022-09-29 23:03:34 - train.py[line:549] - INFO: 7000 / 14103
2022-09-29 23:03:34 - train.py[line:551] - INFO: load:1.66 valid_run:6683.33 task_valid:6475.98 collect_output:169.16
2022-09-29 23:06:47 - train.py[line:549] - INFO: 7200 / 14103
2022-09-29 23:06:47 - train.py[line:551] - INFO: load:1.69 valid_run:6875.78 task_valid:6665.08 collect_output:171.50
2022-09-29 23:09:57 - train.py[line:549] - INFO: 7400 / 14103
2022-09-29 23:09:57 - train.py[line:551] - INFO: load:1.71 valid_run:7066.15 task_valid:6846.49 collect_output:179.43
2022-09-29 23:13:06 - train.py[line:549] - INFO: 7600 / 14103
2022-09-29 23:13:06 - train.py[line:551] - INFO: load:1.73 valid_run:7254.63 task_valid:7026.93 collect_output:186.45
2022-09-29 23:16:20 - train.py[line:549] - INFO: 7800 / 14103
2022-09-29 23:16:20 - train.py[line:551] - INFO: load:1.76 valid_run:7449.06 task_valid:7213.48 collect_output:193.33
2022-09-29 23:19:29 - train.py[line:549] - INFO: 8000 / 14103
2022-09-29 23:19:29 - train.py[line:551] - INFO: load:1.78 valid_run:7638.26 task_valid:7392.52 collect_output:202.48
2022-09-29 23:22:38 - train.py[line:549] - INFO: 8200 / 14103
2022-09-29 23:22:38 - train.py[line:551] - INFO: load:1.81 valid_run:7826.77 task_valid:7575.53 collect_output:206.96
2022-09-29 23:25:49 - train.py[line:549] - INFO: 8400 / 14103
2022-09-29 23:25:49 - train.py[line:551] - INFO: load:1.84 valid_run:8018.30 task_valid:7760.10 collect_output:212.77
2022-09-29 23:29:02 - train.py[line:549] - INFO: 8600 / 14103
2022-09-29 23:29:02 - train.py[line:551] - INFO: load:1.86 valid_run:8211.21 task_valid:7945.47 collect_output:219.26
2022-09-29 23:32:11 - train.py[line:549] - INFO: 8800 / 14103
2022-09-29 23:32:11 - train.py[line:551] - INFO: load:1.89 valid_run:8399.98 task_valid:8130.27 collect_output:222.20
2022-09-29 23:35:23 - train.py[line:549] - INFO: 9000 / 14103
2022-09-29 23:35:23 - train.py[line:551] - INFO: load:1.91 valid_run:8591.47 task_valid:8313.99 collect_output:228.95
2022-09-29 23:38:37 - train.py[line:549] - INFO: 9200 / 14103
2022-09-29 23:38:37 - train.py[line:551] - INFO: load:1.94 valid_run:8785.92 task_valid:8496.94 collect_output:239.38
2022-09-29 23:41:51 - train.py[line:549] - INFO: 9400 / 14103
2022-09-29 23:41:51 - train.py[line:551] - INFO: load:1.96 valid_run:8979.44 task_valid:8684.15 collect_output:244.52
2022-09-29 23:45:02 - train.py[line:549] - INFO: 9600 / 14103
2022-09-29 23:45:02 - train.py[line:551] - INFO: load:1.98 valid_run:9170.76 task_valid:8868.55 collect_output:250.34
2022-09-29 23:48:14 - train.py[line:549] - INFO: 9800 / 14103
2022-09-29 23:48:14 - train.py[line:551] - INFO: load:2.01 valid_run:9362.30 task_valid:9057.06 collect_output:252.27
2022-09-29 23:51:28 - train.py[line:549] - INFO: 10000 / 14103
2022-09-29 23:51:28 - train.py[line:551] - INFO: load:2.03 valid_run:9556.42 task_valid:9246.34 collect_output:255.96
2022-09-29 23:54:41 - train.py[line:549] - INFO: 10200 / 14103
2022-09-29 23:54:41 - train.py[line:551] - INFO: load:2.06 valid_run:9749.24 task_valid:9430.30 collect_output:263.69
2022-09-29 23:57:56 - train.py[line:549] - INFO: 10400 / 14103
2022-09-29 23:57:56 - train.py[line:551] - INFO: load:2.09 valid_run:9943.72 task_valid:9615.81 collect_output:271.50
2022-09-30 00:01:14 - train.py[line:549] - INFO: 10600 / 14103
2022-09-30 00:01:14 - train.py[line:551] - INFO: load:2.12 valid_run:10142.14 task_valid:9801.24 collect_output:283.16
2022-09-30 00:04:26 - train.py[line:549] - INFO: 10800 / 14103
2022-09-30 00:04:26 - train.py[line:551] - INFO: load:2.14 valid_run:10333.67 task_valid:9984.71 collect_output:290.18
2022-09-30 00:07:37 - train.py[line:549] - INFO: 11000 / 14103
2022-09-30 00:07:37 - train.py[line:551] - INFO: load:2.17 valid_run:10525.39 task_valid:10169.94 collect_output:295.64
2022-09-30 00:10:52 - train.py[line:549] - INFO: 11200 / 14103
2022-09-30 00:10:52 - train.py[line:551] - INFO: load:2.20 valid_run:10719.65 task_valid:10355.97 collect_output:302.80
2022-09-30 00:14:06 - train.py[line:549] - INFO: 11400 / 14103
2022-09-30 00:14:06 - train.py[line:551] - INFO: load:2.23 valid_run:10913.98 task_valid:10546.88 collect_output:305.20
2022-09-30 00:17:15 - train.py[line:549] - INFO: 11600 / 14103
2022-09-30 00:17:15 - train.py[line:551] - INFO: load:2.25 valid_run:11103.24 task_valid:10731.49 collect_output:308.85
2022-09-30 00:20:30 - train.py[line:549] - INFO: 11800 / 14103
2022-09-30 00:20:30 - train.py[line:551] - INFO: load:2.27 valid_run:11298.01 task_valid:10920.76 collect_output:313.09
2022-09-30 00:23:40 - train.py[line:549] - INFO: 12000 / 14103
2022-09-30 00:23:40 - train.py[line:551] - INFO: load:2.30 valid_run:11488.07 task_valid:11104.22 collect_output:318.46
2022-09-30 00:26:51 - train.py[line:549] - INFO: 12200 / 14103
2022-09-30 00:26:51 - train.py[line:551] - INFO: load:2.32 valid_run:11678.84 task_valid:11289.41 collect_output:322.92
2022-09-30 00:30:06 - train.py[line:549] - INFO: 12400 / 14103
2022-09-30 00:30:06 - train.py[line:551] - INFO: load:2.35 valid_run:11873.19 task_valid:11475.86 collect_output:329.66
2022-09-30 00:33:20 - train.py[line:549] - INFO: 12600 / 14103
2022-09-30 00:33:20 - train.py[line:551] - INFO: load:2.37 valid_run:12067.06 task_valid:11661.68 collect_output:336.51
2022-09-30 00:36:31 - train.py[line:549] - INFO: 12800 / 14103
2022-09-30 00:36:31 - train.py[line:551] - INFO: load:2.39 valid_run:12258.09 task_valid:11846.65 collect_output:341.35
2022-09-30 00:39:45 - train.py[line:549] - INFO: 13000 / 14103
2022-09-30 00:39:45 - train.py[line:551] - INFO: load:2.43 valid_run:12452.19 task_valid:12032.86 collect_output:347.97
2022-09-30 00:42:59 - train.py[line:549] - INFO: 13200 / 14103
2022-09-30 00:42:59 - train.py[line:551] - INFO: load:2.45 valid_run:12646.73 task_valid:12216.46 collect_output:357.68
2022-09-30 00:46:13 - train.py[line:549] - INFO: 13400 / 14103
2022-09-30 00:46:13 - train.py[line:551] - INFO: load:2.47 valid_run:12840.14 task_valid:12398.94 collect_output:367.45
2022-09-30 00:49:25 - train.py[line:549] - INFO: 13600 / 14103
2022-09-30 00:49:25 - train.py[line:551] - INFO: load:2.50 valid_run:13032.44 task_valid:12581.49 collect_output:375.98
2022-09-30 00:52:39 - train.py[line:549] - INFO: 13800 / 14103
2022-09-30 00:52:39 - train.py[line:551] - INFO: load:2.52 valid_run:13226.09 task_valid:12769.28 collect_output:380.71
2022-09-30 00:55:52 - train.py[line:549] - INFO: 14000 / 14103
2022-09-30 00:55:52 - train.py[line:551] - INFO: load:2.54 valid_run:13419.57 task_valid:12955.55 collect_output:386.73
2022-09-30 00:57:32 - train.py[line:572] - INFO: scores:torch.Size([282060]) preds:torch.Size([282060]) sample_ids:torch.Size([282060])

====================================================================================================
SGG eval:     R @ 50: 0.6580;     R @ 100: 0.6738;     R @ 500: 0.6795;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2298;    mR @ 100: 0.2389;    mR @ 500: 0.2469;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1475) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.3483) (attached to:0.0000) (behind:0.4167) (belonging to:0.0000) (between:0.0000) (carrying:0.7560) (covered in:0.6667) (covering:0.0000) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0577) (has:0.7777) (holding:0.3140) (in:0.3655) (in front of:0.2360) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.6016) (of:0.4565) (on:0.8936) (on back of:0.0000) (over:0.1667) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6667) (says:0.0000) (sitting on:0.3511) (standing on:0.0897) (to:0.0000) (under:0.4167) (using:1.0000) (walking in:0.0000) (walking on:0.5207) (watching:0.3333) (wearing:0.9859) (wears:0.0000) (with:0.1286) 
--------------------------------------------------------
====================================================================================================

2022-09-30 00:57:53 - train.py[line:486] - INFO: 0.6737809314704447

====================================================================================================
SGG eval:     R @ 50: 0.6580;     R @ 100: 0.6738;     R @ 500: 0.6795;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2298;    mR @ 100: 0.2389;    mR @ 500: 0.2469;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1475) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.3483) (attached to:0.0000) (behind:0.4167) (belonging to:0.0000) (between:0.0000) (carrying:0.7560) (covered in:0.6667) (covering:0.0000) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0577) (has:0.7777) (holding:0.3140) (in:0.3655) (in front of:0.2360) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.6016) (of:0.4565) (on:0.8936) (on back of:0.0000) (over:0.1667) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6667) (says:0.0000) (sitting on:0.3511) (standing on:0.0897) (to:0.0000) (under:0.4167) (using:1.0000) (walking in:0.0000) (walking on:0.5207) (watching:0.3333) (wearing:0.9859) (wears:0.0000) (with:0.1286) 
--------------------------------------------------------
====================================================================================================

2022-09-30 00:57:53 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.316 | loss_v1 0 | loss_v2 0 | nll_loss 0.124 | ntokens 59.526 | nsentences 20 | sample_size 59.526 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.673781 | ppl 1.09 | vqa_score 0.9069 | wps 62 | wpb 59.5 | bsz 20 | num_updates 30000 | best_R@100 0.673781
2022-09-30 00:57:53 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 30000 updates
2022-09-30 00:57:53 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_2_30000.pt
2022-09-30 00:58:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_2_30000.pt
2022-09-30 00:58:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_2_30000.pt (epoch 2 @ 30000 updates, score 0.6737809314704447) (writing took 11.682305227033794 seconds)
2022-09-30 00:58:17 - progress_bar.py[line:274] - INFO: epoch 002:  14274 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=0.1, ups=0, wpb=101.4, bsz=40, num_updates=30010, lr=3.22767e-05, gnorm=0.643, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=101721
2022-09-30 00:58:28 - progress_bar.py[line:274] - INFO: epoch 002:  14284 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.89, wpb=102.5, bsz=40, num_updates=30020, lr=3.22701e-05, gnorm=0.758, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=101733
2022-09-30 00:58:39 - progress_bar.py[line:274] - INFO: epoch 002:  14294 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88, ups=0.87, wpb=101, bsz=40, num_updates=30030, lr=3.22635e-05, gnorm=0.847, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=101744
2022-09-30 00:58:51 - progress_bar.py[line:274] - INFO: epoch 002:  14304 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=30040, lr=3.22569e-05, gnorm=0.664, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=101755
2022-09-30 00:59:02 - progress_bar.py[line:274] - INFO: epoch 002:  14314 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.4, ups=0.9, wpb=99.4, bsz=40, num_updates=30050, lr=3.22503e-05, gnorm=0.755, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=101767
2022-09-30 00:59:13 - progress_bar.py[line:274] - INFO: epoch 002:  14324 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.89, wpb=100.9, bsz=40, num_updates=30060, lr=3.22437e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=101778
2022-09-30 00:59:24 - progress_bar.py[line:274] - INFO: epoch 002:  14334 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88, ups=0.87, wpb=100.9, bsz=40, num_updates=30070, lr=3.22371e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=101789
2022-09-30 00:59:36 - progress_bar.py[line:274] - INFO: epoch 002:  14344 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.89, wpb=100.7, bsz=40, num_updates=30080, lr=3.22305e-05, gnorm=0.781, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=101801
2022-09-30 00:59:47 - progress_bar.py[line:274] - INFO: epoch 002:  14354 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.3, ups=0.92, wpb=100.8, bsz=40, num_updates=30090, lr=3.22239e-05, gnorm=0.763, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=101811
2022-09-30 00:59:58 - progress_bar.py[line:274] - INFO: epoch 002:  14364 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.1, ups=0.88, wpb=100.9, bsz=40, num_updates=30100, lr=3.22173e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=101823
2022-09-30 01:00:09 - progress_bar.py[line:274] - INFO: epoch 002:  14374 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.4, ups=0.92, wpb=102, bsz=40, num_updates=30110, lr=3.22107e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=101834
2022-09-30 01:00:20 - progress_bar.py[line:274] - INFO: epoch 002:  14384 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.87, wpb=101.7, bsz=40, num_updates=30120, lr=3.22041e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=101845
2022-09-30 01:00:31 - progress_bar.py[line:274] - INFO: epoch 002:  14394 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.91, wpb=102.1, bsz=40, num_updates=30130, lr=3.21975e-05, gnorm=0.816, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=101856
2022-09-30 01:00:43 - progress_bar.py[line:274] - INFO: epoch 002:  14404 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.89, wpb=102.5, bsz=40, num_updates=30140, lr=3.21909e-05, gnorm=0.746, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=101867
2022-09-30 01:00:54 - progress_bar.py[line:274] - INFO: epoch 002:  14414 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.2, ups=0.89, wpb=100.6, bsz=40, num_updates=30150, lr=3.21843e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=101879
2022-09-30 01:01:05 - progress_bar.py[line:274] - INFO: epoch 002:  14424 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.4, ups=0.88, wpb=101.2, bsz=40, num_updates=30160, lr=3.21777e-05, gnorm=0.738, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=101890
2022-09-30 01:01:16 - progress_bar.py[line:274] - INFO: epoch 002:  14434 / 15783 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.8, ups=0.91, wpb=102.6, bsz=40, num_updates=30170, lr=3.21711e-05, gnorm=0.736, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=101901
2022-09-30 01:01:28 - progress_bar.py[line:274] - INFO: epoch 002:  14444 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.5, ups=0.87, wpb=101.5, bsz=40, num_updates=30180, lr=3.21645e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=101912
2022-09-30 01:01:38 - progress_bar.py[line:274] - INFO: epoch 002:  14454 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.4, ups=0.93, wpb=102.3, bsz=40, num_updates=30190, lr=3.21579e-05, gnorm=0.7, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=101923
2022-09-30 01:01:50 - progress_bar.py[line:274] - INFO: epoch 002:  14464 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.9, ups=0.88, wpb=102.3, bsz=40, num_updates=30200, lr=3.21513e-05, gnorm=0.741, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=101935
2022-09-30 01:02:01 - progress_bar.py[line:274] - INFO: epoch 002:  14474 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.2, ups=0.88, wpb=101.4, bsz=40, num_updates=30210, lr=3.21447e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=101946
2022-09-30 01:02:12 - progress_bar.py[line:274] - INFO: epoch 002:  14484 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.7, ups=0.91, wpb=101, bsz=40, num_updates=30220, lr=3.21381e-05, gnorm=0.744, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=101957
2022-09-30 01:02:24 - progress_bar.py[line:274] - INFO: epoch 002:  14494 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.4, ups=0.87, wpb=101.7, bsz=40, num_updates=30230, lr=3.21315e-05, gnorm=0.769, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=101968
2022-09-30 01:02:36 - progress_bar.py[line:274] - INFO: epoch 002:  14504 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=79.7, ups=0.79, wpb=101.1, bsz=40, num_updates=30240, lr=3.21249e-05, gnorm=0.824, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=101981
2022-09-30 01:02:49 - progress_bar.py[line:274] - INFO: epoch 002:  14514 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=83.2, ups=0.82, wpb=101.9, bsz=40, num_updates=30250, lr=3.21183e-05, gnorm=0.703, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=101993
2022-09-30 01:03:00 - progress_bar.py[line:274] - INFO: epoch 002:  14524 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.4, ups=0.87, wpb=101.6, bsz=40, num_updates=30260, lr=3.21117e-05, gnorm=0.817, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102005
2022-09-30 01:03:11 - progress_bar.py[line:274] - INFO: epoch 002:  14534 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.3, ups=0.89, wpb=99.6, bsz=40, num_updates=30270, lr=3.21051e-05, gnorm=0.808, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102016
2022-09-30 01:03:24 - progress_bar.py[line:274] - INFO: epoch 002:  14544 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=77.9, ups=0.77, wpb=100.8, bsz=40, num_updates=30280, lr=3.20985e-05, gnorm=0.792, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=102029
2022-09-30 01:03:37 - progress_bar.py[line:274] - INFO: epoch 002:  14554 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=79.1, ups=0.78, wpb=101, bsz=40, num_updates=30290, lr=3.20919e-05, gnorm=0.677, clip=0, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=102042
2022-09-30 01:03:49 - progress_bar.py[line:274] - INFO: epoch 002:  14564 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=85.4, ups=0.84, wpb=101.1, bsz=40, num_updates=30300, lr=3.20853e-05, gnorm=0.719, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=102054
2022-09-30 01:04:00 - progress_bar.py[line:274] - INFO: epoch 002:  14574 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.7, ups=0.89, wpb=101.8, bsz=40, num_updates=30310, lr=3.20787e-05, gnorm=0.744, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102065
2022-09-30 01:04:12 - progress_bar.py[line:274] - INFO: epoch 002:  14584 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.1, ups=0.86, wpb=102, bsz=40, num_updates=30320, lr=3.20721e-05, gnorm=0.64, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=102077
2022-09-30 01:04:23 - progress_bar.py[line:274] - INFO: epoch 002:  14594 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.2, ups=0.9, wpb=102.4, bsz=40, num_updates=30330, lr=3.20655e-05, gnorm=0.705, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102088
2022-09-30 01:04:34 - progress_bar.py[line:274] - INFO: epoch 002:  14604 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.1, ups=0.88, wpb=100.6, bsz=40, num_updates=30340, lr=3.20589e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102099
2022-09-30 01:04:46 - progress_bar.py[line:274] - INFO: epoch 002:  14614 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.2, ups=0.89, wpb=101.4, bsz=40, num_updates=30350, lr=3.20523e-05, gnorm=0.694, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=102110
2022-09-30 01:04:57 - progress_bar.py[line:274] - INFO: epoch 002:  14624 / 15783 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.7, ups=0.87, wpb=101.5, bsz=40, num_updates=30360, lr=3.20457e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102122
2022-09-30 01:05:08 - progress_bar.py[line:274] - INFO: epoch 002:  14634 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=104.3, nsentences=40, sample_size=104.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.4, ups=0.91, wpb=104.3, bsz=40, num_updates=30370, lr=3.20391e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102133
2022-09-30 01:05:19 - progress_bar.py[line:274] - INFO: epoch 002:  14644 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.2, ups=0.89, wpb=100.4, bsz=40, num_updates=30380, lr=3.20325e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=102144
2022-09-30 01:05:31 - progress_bar.py[line:274] - INFO: epoch 002:  14654 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=100.9, bsz=40, num_updates=30390, lr=3.20259e-05, gnorm=0.802, clip=0, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=102155
2022-09-30 01:05:42 - progress_bar.py[line:274] - INFO: epoch 002:  14664 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.9, wpb=102.2, bsz=40, num_updates=30400, lr=3.20193e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102167
2022-09-30 01:05:53 - progress_bar.py[line:274] - INFO: epoch 002:  14674 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.9, ups=0.88, wpb=101.1, bsz=40, num_updates=30410, lr=3.20127e-05, gnorm=0.833, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102178
2022-09-30 01:06:04 - progress_bar.py[line:274] - INFO: epoch 002:  14684 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.2, ups=0.93, wpb=100.3, bsz=40, num_updates=30420, lr=3.20061e-05, gnorm=0.755, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102189
2022-09-30 01:06:15 - progress_bar.py[line:274] - INFO: epoch 002:  14694 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.89, wpb=101.4, bsz=40, num_updates=30430, lr=3.19995e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102200
2022-09-30 01:06:26 - progress_bar.py[line:274] - INFO: epoch 002:  14704 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.2, ups=0.93, wpb=101.7, bsz=40, num_updates=30440, lr=3.19929e-05, gnorm=0.74, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102211
2022-09-30 01:06:38 - progress_bar.py[line:274] - INFO: epoch 002:  14714 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=86, ups=0.86, wpb=99.9, bsz=40, num_updates=30450, lr=3.19863e-05, gnorm=0.742, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=102222
2022-09-30 01:06:49 - progress_bar.py[line:274] - INFO: epoch 002:  14724 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.2, ups=0.9, wpb=100.8, bsz=40, num_updates=30460, lr=3.19797e-05, gnorm=0.762, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102234
2022-09-30 01:07:00 - progress_bar.py[line:274] - INFO: epoch 002:  14734 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.9, wpb=101, bsz=40, num_updates=30470, lr=3.19731e-05, gnorm=0.76, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102245
2022-09-30 01:07:11 - progress_bar.py[line:274] - INFO: epoch 002:  14744 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.89, wpb=100.9, bsz=40, num_updates=30480, lr=3.19665e-05, gnorm=0.688, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102256
2022-09-30 01:07:22 - progress_bar.py[line:274] - INFO: epoch 002:  14754 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.4, ups=0.91, wpb=101.9, bsz=40, num_updates=30490, lr=3.19599e-05, gnorm=0.716, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102267
2022-09-30 01:07:33 - progress_bar.py[line:274] - INFO: epoch 002:  14764 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.89, wpb=103, bsz=40, num_updates=30500, lr=3.19533e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102278
2022-09-30 01:07:45 - progress_bar.py[line:274] - INFO: epoch 002:  14774 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.9, ups=0.9, wpb=101.6, bsz=40, num_updates=30510, lr=3.19467e-05, gnorm=0.711, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102289
2022-09-30 01:07:56 - progress_bar.py[line:274] - INFO: epoch 002:  14784 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.9, wpb=100.6, bsz=40, num_updates=30520, lr=3.19401e-05, gnorm=0.711, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102300
2022-09-30 01:08:07 - progress_bar.py[line:274] - INFO: epoch 002:  14794 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.88, wpb=101.9, bsz=40, num_updates=30530, lr=3.19335e-05, gnorm=0.738, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=102312
2022-09-30 01:08:18 - progress_bar.py[line:274] - INFO: epoch 002:  14804 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.3, ups=0.9, wpb=101.7, bsz=40, num_updates=30540, lr=3.19269e-05, gnorm=0.777, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102323
2022-09-30 01:08:29 - progress_bar.py[line:274] - INFO: epoch 002:  14814 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.1, ups=0.89, wpb=101.5, bsz=40, num_updates=30550, lr=3.19203e-05, gnorm=0.777, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102334
2022-09-30 01:08:40 - progress_bar.py[line:274] - INFO: epoch 002:  14824 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.3, ups=0.91, wpb=101.6, bsz=40, num_updates=30560, lr=3.19137e-05, gnorm=0.692, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102345
2022-09-30 01:08:52 - progress_bar.py[line:274] - INFO: epoch 002:  14834 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.4, ups=0.86, wpb=102.2, bsz=40, num_updates=30570, lr=3.19071e-05, gnorm=0.773, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=102357
2022-09-30 01:09:03 - progress_bar.py[line:274] - INFO: epoch 002:  14844 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.5, ups=0.94, wpb=103.2, bsz=40, num_updates=30580, lr=3.19005e-05, gnorm=0.835, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=102368
2022-09-30 01:09:13 - progress_bar.py[line:274] - INFO: epoch 002:  14854 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.2, ups=0.92, wpb=101.9, bsz=40, num_updates=30590, lr=3.18939e-05, gnorm=0.715, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102378
2022-09-30 01:09:25 - progress_bar.py[line:274] - INFO: epoch 002:  14864 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.1, ups=0.88, wpb=101.4, bsz=40, num_updates=30600, lr=3.18873e-05, gnorm=0.676, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102390
2022-09-30 01:09:36 - progress_bar.py[line:274] - INFO: epoch 002:  14874 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.9, ups=0.91, wpb=102.5, bsz=40, num_updates=30610, lr=3.18807e-05, gnorm=0.664, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=102401
2022-09-30 01:09:47 - progress_bar.py[line:274] - INFO: epoch 002:  14884 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.9, wpb=99.7, bsz=40, num_updates=30620, lr=3.18741e-05, gnorm=0.83, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102412
2022-09-30 01:09:58 - progress_bar.py[line:274] - INFO: epoch 002:  14894 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.6, ups=0.89, wpb=101.4, bsz=40, num_updates=30630, lr=3.18675e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=102423
2022-09-30 01:10:09 - progress_bar.py[line:274] - INFO: epoch 002:  14904 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.9, wpb=100.8, bsz=40, num_updates=30640, lr=3.18609e-05, gnorm=0.853, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=102434
2022-09-30 01:10:20 - progress_bar.py[line:274] - INFO: epoch 002:  14914 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.7, ups=0.93, wpb=102.3, bsz=40, num_updates=30650, lr=3.18543e-05, gnorm=0.774, clip=20, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=102445
2022-09-30 01:10:31 - progress_bar.py[line:274] - INFO: epoch 002:  14924 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.9, ups=0.9, wpb=101.9, bsz=40, num_updates=30660, lr=3.18477e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102456
2022-09-30 01:10:42 - progress_bar.py[line:274] - INFO: epoch 002:  14934 / 15783 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=99.1, nsentences=40, sample_size=99.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89, ups=0.9, wpb=99.1, bsz=40, num_updates=30670, lr=3.18411e-05, gnorm=0.909, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102467
2022-09-30 01:10:54 - progress_bar.py[line:274] - INFO: epoch 002:  14944 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=84.4, ups=0.83, wpb=102.1, bsz=40, num_updates=30680, lr=3.18345e-05, gnorm=0.777, clip=10, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=102479
2022-09-30 01:11:07 - progress_bar.py[line:274] - INFO: epoch 002:  14954 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=81.1, ups=0.81, wpb=100.4, bsz=40, num_updates=30690, lr=3.18279e-05, gnorm=0.863, clip=30, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=102492
2022-09-30 01:11:19 - progress_bar.py[line:274] - INFO: epoch 002:  14964 / 15783 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=84.6, ups=0.85, wpb=99.2, bsz=40, num_updates=30700, lr=3.18213e-05, gnorm=0.842, clip=30, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=102503
2022-09-30 01:11:30 - progress_bar.py[line:274] - INFO: epoch 002:  14974 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=100.8, bsz=40, num_updates=30710, lr=3.18147e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102515
2022-09-30 01:11:42 - progress_bar.py[line:274] - INFO: epoch 002:  14984 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86, ups=0.85, wpb=100.7, bsz=40, num_updates=30720, lr=3.18081e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=102527
2022-09-30 01:11:54 - progress_bar.py[line:274] - INFO: epoch 002:  14994 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=84.2, ups=0.83, wpb=100.9, bsz=40, num_updates=30730, lr=3.18015e-05, gnorm=0.787, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=102539
2022-09-30 01:12:05 - progress_bar.py[line:274] - INFO: epoch 002:  15004 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.2, ups=0.92, wpb=100.4, bsz=40, num_updates=30740, lr=3.17949e-05, gnorm=0.735, clip=10, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=102550
2022-09-30 01:12:16 - progress_bar.py[line:274] - INFO: epoch 002:  15014 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.1, ups=0.88, wpb=101.2, bsz=40, num_updates=30750, lr=3.17883e-05, gnorm=0.818, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102561
2022-09-30 01:12:28 - progress_bar.py[line:274] - INFO: epoch 002:  15024 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.89, wpb=100.8, bsz=40, num_updates=30760, lr=3.17817e-05, gnorm=0.713, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=102572
2022-09-30 01:12:39 - progress_bar.py[line:274] - INFO: epoch 002:  15034 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.5, ups=0.88, wpb=100.5, bsz=40, num_updates=30770, lr=3.17751e-05, gnorm=0.731, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=102584
2022-09-30 01:12:50 - progress_bar.py[line:274] - INFO: epoch 002:  15044 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.3, ups=0.94, wpb=100.9, bsz=40, num_updates=30780, lr=3.17685e-05, gnorm=0.747, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102594
2022-09-30 01:13:00 - progress_bar.py[line:274] - INFO: epoch 002:  15054 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.7, ups=0.92, wpb=101.8, bsz=40, num_updates=30790, lr=3.17619e-05, gnorm=0.708, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102605
2022-09-30 01:13:12 - progress_bar.py[line:274] - INFO: epoch 002:  15064 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89, ups=0.89, wpb=100, bsz=40, num_updates=30800, lr=3.17553e-05, gnorm=0.806, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102616
2022-09-30 01:13:23 - progress_bar.py[line:274] - INFO: epoch 002:  15074 / 15783 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=90.8, ups=0.88, wpb=103.5, bsz=40, num_updates=30810, lr=3.17487e-05, gnorm=0.732, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102628
2022-09-30 01:13:34 - progress_bar.py[line:274] - INFO: epoch 002:  15084 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.92, wpb=101.1, bsz=40, num_updates=30820, lr=3.17421e-05, gnorm=0.949, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=102639
2022-09-30 01:13:46 - progress_bar.py[line:274] - INFO: epoch 002:  15094 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.1, ups=0.88, wpb=100.2, bsz=40, num_updates=30830, lr=3.17355e-05, gnorm=0.931, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=102650
2022-09-30 01:13:57 - progress_bar.py[line:274] - INFO: epoch 002:  15104 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.89, wpb=101.2, bsz=40, num_updates=30840, lr=3.17289e-05, gnorm=0.857, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102662
2022-09-30 01:14:08 - progress_bar.py[line:274] - INFO: epoch 002:  15114 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.92, wpb=101.2, bsz=40, num_updates=30850, lr=3.17223e-05, gnorm=0.788, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=102673
2022-09-30 01:14:19 - progress_bar.py[line:274] - INFO: epoch 002:  15124 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.4, ups=0.88, wpb=101.3, bsz=40, num_updates=30860, lr=3.17157e-05, gnorm=0.794, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=102684
2022-09-30 01:14:30 - progress_bar.py[line:274] - INFO: epoch 002:  15134 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.1, ups=0.9, wpb=102.1, bsz=40, num_updates=30870, lr=3.17091e-05, gnorm=0.865, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=102695
2022-09-30 01:14:41 - progress_bar.py[line:274] - INFO: epoch 002:  15144 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=30880, lr=3.17025e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=102706
2022-09-30 01:14:52 - progress_bar.py[line:274] - INFO: epoch 002:  15154 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.5, ups=0.9, wpb=103.3, bsz=40, num_updates=30890, lr=3.16959e-05, gnorm=0.717, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102717
2022-09-30 01:15:04 - progress_bar.py[line:274] - INFO: epoch 002:  15164 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.88, wpb=101.8, bsz=40, num_updates=30900, lr=3.16893e-05, gnorm=0.833, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102729
2022-09-30 01:15:15 - progress_bar.py[line:274] - INFO: epoch 002:  15174 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.8, ups=0.89, wpb=100.1, bsz=40, num_updates=30910, lr=3.16827e-05, gnorm=0.888, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102740
2022-09-30 01:15:27 - progress_bar.py[line:274] - INFO: epoch 002:  15184 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.2, ups=0.85, wpb=101.1, bsz=40, num_updates=30920, lr=3.16761e-05, gnorm=0.937, clip=40, loss_scale=1024, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=102752
2022-09-30 01:15:39 - progress_bar.py[line:274] - INFO: epoch 002:  15194 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=84.2, ups=0.84, wpb=100.2, bsz=40, num_updates=30930, lr=3.16695e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=102764
2022-09-30 01:15:50 - progress_bar.py[line:274] - INFO: epoch 002:  15204 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.2, ups=0.95, wpb=100.1, bsz=40, num_updates=30940, lr=3.16629e-05, gnorm=0.777, clip=10, loss_scale=1024, train_wall=10, gb_free=10.4, ema_decay=0.9999, wall=102775
2022-09-30 01:16:01 - progress_bar.py[line:274] - INFO: epoch 002:  15214 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.88, wpb=102.9, bsz=40, num_updates=30950, lr=3.16563e-05, gnorm=0.843, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102786
2022-09-30 01:16:12 - progress_bar.py[line:274] - INFO: epoch 002:  15224 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=104.7, nsentences=40, sample_size=104.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.7, ups=0.9, wpb=104.7, bsz=40, num_updates=30960, lr=3.16497e-05, gnorm=0.77, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102797
2022-09-30 01:16:23 - progress_bar.py[line:274] - INFO: epoch 002:  15234 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.9, ups=0.9, wpb=100.7, bsz=40, num_updates=30970, lr=3.16431e-05, gnorm=0.868, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102808
2022-09-30 01:16:35 - progress_bar.py[line:274] - INFO: epoch 002:  15244 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.89, wpb=100.2, bsz=40, num_updates=30980, lr=3.16365e-05, gnorm=0.892, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102819
2022-09-30 01:16:45 - progress_bar.py[line:274] - INFO: epoch 002:  15254 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=92.7, ups=0.93, wpb=100.1, bsz=40, num_updates=30990, lr=3.16299e-05, gnorm=0.972, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102830
2022-09-30 01:16:56 - progress_bar.py[line:274] - INFO: epoch 002:  15264 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.91, wpb=100.3, bsz=40, num_updates=31000, lr=3.16233e-05, gnorm=0.777, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102841
2022-09-30 01:17:07 - progress_bar.py[line:274] - INFO: epoch 002:  15274 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.6, ups=0.91, wpb=102.2, bsz=40, num_updates=31010, lr=3.16167e-05, gnorm=0.792, clip=10, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102852
2022-09-30 01:17:09 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 01:17:20 - progress_bar.py[line:274] - INFO: epoch 002:  15285 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=82.8, ups=0.82, wpb=101.4, bsz=40, num_updates=31020, lr=3.16101e-05, gnorm=0.774, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=102865
2022-09-30 01:17:32 - progress_bar.py[line:274] - INFO: epoch 002:  15295 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.1, ups=0.88, wpb=100.2, bsz=40, num_updates=31030, lr=3.16035e-05, gnorm=0.83, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102876
2022-09-30 01:17:43 - progress_bar.py[line:274] - INFO: epoch 002:  15305 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.1, ups=0.9, wpb=103, bsz=40, num_updates=31040, lr=3.15969e-05, gnorm=0.705, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=102888
2022-09-30 01:17:54 - progress_bar.py[line:274] - INFO: epoch 002:  15315 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.3, ups=0.91, wpb=101.6, bsz=40, num_updates=31050, lr=3.15903e-05, gnorm=0.838, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102899
2022-09-30 01:18:05 - progress_bar.py[line:274] - INFO: epoch 002:  15325 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.91, wpb=101.7, bsz=40, num_updates=31060, lr=3.15837e-05, gnorm=0.75, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102910
2022-09-30 01:18:16 - progress_bar.py[line:274] - INFO: epoch 002:  15335 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.5, ups=0.91, wpb=101.1, bsz=40, num_updates=31070, lr=3.15771e-05, gnorm=0.817, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102921
2022-09-30 01:18:27 - progress_bar.py[line:274] - INFO: epoch 002:  15345 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.1, ups=0.92, wpb=101.1, bsz=40, num_updates=31080, lr=3.15705e-05, gnorm=0.692, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=102931
2022-09-30 01:18:38 - progress_bar.py[line:274] - INFO: epoch 002:  15355 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.89, wpb=100.9, bsz=40, num_updates=31090, lr=3.15639e-05, gnorm=0.796, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=102943
2022-09-30 01:18:49 - progress_bar.py[line:274] - INFO: epoch 002:  15365 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.8, ups=0.92, wpb=100.8, bsz=40, num_updates=31100, lr=3.15573e-05, gnorm=0.725, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102953
2022-09-30 01:19:00 - progress_bar.py[line:274] - INFO: epoch 002:  15375 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.92, wpb=99.7, bsz=40, num_updates=31110, lr=3.15507e-05, gnorm=0.765, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102964
2022-09-30 01:19:10 - progress_bar.py[line:274] - INFO: epoch 002:  15385 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.5, ups=0.92, wpb=101.2, bsz=40, num_updates=31120, lr=3.15441e-05, gnorm=0.727, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102975
2022-09-30 01:19:22 - progress_bar.py[line:274] - INFO: epoch 002:  15395 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.5, ups=0.9, wpb=101.2, bsz=40, num_updates=31130, lr=3.15375e-05, gnorm=0.768, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=102986
2022-09-30 01:19:33 - progress_bar.py[line:274] - INFO: epoch 002:  15405 / 15783 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=98.5, nsentences=40, sample_size=98.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=86.4, ups=0.88, wpb=98.5, bsz=40, num_updates=31140, lr=3.15309e-05, gnorm=0.878, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=102998
2022-09-30 01:19:45 - progress_bar.py[line:274] - INFO: epoch 002:  15415 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.5, ups=0.87, wpb=101.6, bsz=40, num_updates=31150, lr=3.15243e-05, gnorm=0.749, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=103009
2022-09-30 01:19:56 - progress_bar.py[line:274] - INFO: epoch 002:  15425 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.88, wpb=102.3, bsz=40, num_updates=31160, lr=3.15177e-05, gnorm=0.937, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=103021
2022-09-30 01:20:07 - progress_bar.py[line:274] - INFO: epoch 002:  15435 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.3, ups=0.94, wpb=101.6, bsz=40, num_updates=31170, lr=3.15111e-05, gnorm=0.716, clip=0, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=103032
2022-09-30 01:20:18 - progress_bar.py[line:274] - INFO: epoch 002:  15445 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.89, wpb=101.8, bsz=40, num_updates=31180, lr=3.15045e-05, gnorm=0.756, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103043
2022-09-30 01:20:29 - progress_bar.py[line:274] - INFO: epoch 002:  15455 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.89, wpb=102.3, bsz=40, num_updates=31190, lr=3.14979e-05, gnorm=0.817, clip=10, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=103054
2022-09-30 01:20:40 - progress_bar.py[line:274] - INFO: epoch 002:  15465 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.9, wpb=99.7, bsz=40, num_updates=31200, lr=3.14913e-05, gnorm=0.842, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103065
2022-09-30 01:20:51 - progress_bar.py[line:274] - INFO: epoch 002:  15475 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.92, wpb=100.5, bsz=40, num_updates=31210, lr=3.14847e-05, gnorm=0.733, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103076
2022-09-30 01:21:02 - progress_bar.py[line:274] - INFO: epoch 002:  15485 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.89, wpb=100.7, bsz=40, num_updates=31220, lr=3.14781e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=103087
2022-09-30 01:21:13 - progress_bar.py[line:274] - INFO: epoch 002:  15495 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=31230, lr=3.14715e-05, gnorm=0.692, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103098
2022-09-30 01:21:25 - progress_bar.py[line:274] - INFO: epoch 002:  15505 / 15783 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.5, ups=0.9, wpb=98.7, bsz=40, num_updates=31240, lr=3.14649e-05, gnorm=0.847, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103110
2022-09-30 01:21:36 - progress_bar.py[line:274] - INFO: epoch 002:  15515 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.9, ups=0.89, wpb=100, bsz=40, num_updates=31250, lr=3.14583e-05, gnorm=0.836, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=103121
2022-09-30 01:21:39 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 01:21:48 - progress_bar.py[line:274] - INFO: epoch 002:  15526 / 15783 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.5, ups=0.85, wpb=101.8, bsz=40, num_updates=31260, lr=3.14517e-05, gnorm=0.925, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=103133
2022-09-30 01:21:59 - progress_bar.py[line:274] - INFO: epoch 002:  15536 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.9, ups=0.89, wpb=103.1, bsz=40, num_updates=31270, lr=3.14451e-05, gnorm=0.722, clip=0, loss_scale=512, train_wall=11, gb_free=9.5, ema_decay=0.9999, wall=103144
2022-09-30 01:22:10 - progress_bar.py[line:274] - INFO: epoch 002:  15546 / 15783 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.5, ups=0.9, wpb=102.4, bsz=40, num_updates=31280, lr=3.14385e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=103155
2022-09-30 01:22:21 - progress_bar.py[line:274] - INFO: epoch 002:  15556 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.92, wpb=101, bsz=40, num_updates=31290, lr=3.14319e-05, gnorm=0.777, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=103166
2022-09-30 01:22:32 - progress_bar.py[line:274] - INFO: epoch 002:  15566 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.5, ups=0.92, wpb=102.2, bsz=40, num_updates=31300, lr=3.14253e-05, gnorm=0.777, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103177
2022-09-30 01:22:43 - progress_bar.py[line:274] - INFO: epoch 002:  15576 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90, ups=0.91, wpb=99.3, bsz=40, num_updates=31310, lr=3.14187e-05, gnorm=0.814, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103188
2022-09-30 01:22:54 - progress_bar.py[line:274] - INFO: epoch 002:  15586 / 15783 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=87.8, ups=0.88, wpb=99.9, bsz=40, num_updates=31320, lr=3.14121e-05, gnorm=0.841, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103199
2022-09-30 01:23:05 - progress_bar.py[line:274] - INFO: epoch 002:  15596 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.9, ups=0.91, wpb=101.8, bsz=40, num_updates=31330, lr=3.14055e-05, gnorm=0.748, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103210
2022-09-30 01:23:17 - progress_bar.py[line:274] - INFO: epoch 002:  15606 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89, ups=0.87, wpb=102.8, bsz=40, num_updates=31340, lr=3.13989e-05, gnorm=0.72, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=103222
2022-09-30 01:23:28 - progress_bar.py[line:274] - INFO: epoch 002:  15616 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93, ups=0.9, wpb=102.9, bsz=40, num_updates=31350, lr=3.13923e-05, gnorm=0.77, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103233
2022-09-30 01:23:39 - progress_bar.py[line:274] - INFO: epoch 002:  15626 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.9, ups=0.86, wpb=101.2, bsz=40, num_updates=31360, lr=3.13857e-05, gnorm=0.778, clip=10, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=103244
2022-09-30 01:23:51 - progress_bar.py[line:274] - INFO: epoch 002:  15636 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=31370, lr=3.13791e-05, gnorm=0.696, clip=0, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=103255
2022-09-30 01:24:02 - progress_bar.py[line:274] - INFO: epoch 002:  15646 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.89, wpb=101.3, bsz=40, num_updates=31380, lr=3.13725e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103267
2022-09-30 01:24:13 - progress_bar.py[line:274] - INFO: epoch 002:  15656 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.3, ups=0.89, wpb=102.5, bsz=40, num_updates=31390, lr=3.13659e-05, gnorm=0.742, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103278
2022-09-30 01:24:24 - progress_bar.py[line:274] - INFO: epoch 002:  15666 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.88, wpb=102, bsz=40, num_updates=31400, lr=3.13593e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103289
2022-09-30 01:24:36 - progress_bar.py[line:274] - INFO: epoch 002:  15676 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.89, wpb=101.1, bsz=40, num_updates=31410, lr=3.13527e-05, gnorm=0.782, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103300
2022-09-30 01:24:47 - progress_bar.py[line:274] - INFO: epoch 002:  15686 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.88, wpb=102.8, bsz=40, num_updates=31420, lr=3.13461e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=103312
2022-09-30 01:24:58 - progress_bar.py[line:274] - INFO: epoch 002:  15696 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.89, wpb=102.7, bsz=40, num_updates=31430, lr=3.13395e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=103323
2022-09-30 01:25:10 - progress_bar.py[line:274] - INFO: epoch 002:  15706 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.88, wpb=101.7, bsz=40, num_updates=31440, lr=3.13329e-05, gnorm=0.743, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103334
2022-09-30 01:25:21 - progress_bar.py[line:274] - INFO: epoch 002:  15716 / 15783 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.8, ups=0.9, wpb=100.6, bsz=40, num_updates=31450, lr=3.13263e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103345
2022-09-30 01:25:32 - progress_bar.py[line:274] - INFO: epoch 002:  15726 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.9, ups=0.9, wpb=101.6, bsz=40, num_updates=31460, lr=3.13197e-05, gnorm=0.759, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103356
2022-09-30 01:25:43 - progress_bar.py[line:274] - INFO: epoch 002:  15736 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.9, wpb=101.8, bsz=40, num_updates=31470, lr=3.13131e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103368
2022-09-30 01:25:54 - progress_bar.py[line:274] - INFO: epoch 002:  15746 / 15783 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.2, ups=0.89, wpb=101.9, bsz=40, num_updates=31480, lr=3.13065e-05, gnorm=0.664, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103379
2022-09-30 01:26:05 - progress_bar.py[line:274] - INFO: epoch 002:  15756 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.88, wpb=104.5, bsz=40, num_updates=31490, lr=3.12999e-05, gnorm=0.741, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103390
2022-09-30 01:26:16 - progress_bar.py[line:274] - INFO: epoch 002:  15766 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.2, ups=0.91, wpb=102.6, bsz=40, num_updates=31500, lr=3.12933e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=103401
2022-09-30 01:26:27 - progress_bar.py[line:274] - INFO: epoch 002:  15776 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.5, ups=0.9, wpb=102.6, bsz=40, num_updates=31510, lr=3.12867e-05, gnorm=0.734, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103412
2022-09-30 01:26:34 - train.py[line:339] - INFO: end of epoch 2 (average epoch stats below)
2022-09-30 01:26:34 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.564 | loss_v1 0 | loss_v2 0 | nll_loss 0.351 | ntokens 101.338 | nsentences 39.998 | sample_size 101.338 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.28 | wps 27.4 | ups 0.27 | wpb 101.3 | bsz 40 | num_updates 31517 | lr 3.12821e-05 | gnorm 0.796 | clip 13.8 | loss_scale 512 | train_wall 17601 | gb_free 33 | ema_decay 0.9999 | wall 103419
2022-09-30 01:26:34 - trainer.py[line:643] - INFO: loading train data for epoch 3
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv slice_id 1 row count 315642 total row count 631284
file /data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv slice_id 0 row count 315642 total row count 631284
2022-09-30 01:26:35 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-09-30 01:26:36 - trainer.py[line:707] - INFO: begin training epoch 3
2022-09-30 01:26:36 - train.py[line:312] - INFO: Start iterating over samples
2022-09-30 01:26:41 - progress_bar.py[line:274] - INFO: epoch 003:      3 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=91.5, nsentences=36.4, sample_size=91.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=70.1, ups=0.77, wpb=91.5, bsz=36.4, num_updates=31520, lr=3.12801e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=10, gb_free=10.4, ema_decay=0.9999, wall=103425
2022-09-30 01:26:52 - progress_bar.py[line:274] - INFO: epoch 003:     13 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.4, ups=0.9, wpb=101.8, bsz=40, num_updates=31530, lr=3.12735e-05, gnorm=0.793, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103437
2022-09-30 01:27:03 - progress_bar.py[line:274] - INFO: epoch 003:     23 / 15783 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=91.5, ups=0.89, wpb=103, bsz=40, num_updates=31540, lr=3.12669e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=103448
2022-09-30 01:27:14 - progress_bar.py[line:274] - INFO: epoch 003:     33 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.4, ups=0.88, wpb=102.1, bsz=40, num_updates=31550, lr=3.12603e-05, gnorm=0.772, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=103459
2022-09-30 01:27:26 - progress_bar.py[line:274] - INFO: epoch 003:     43 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.4, ups=0.89, wpb=100.5, bsz=40, num_updates=31560, lr=3.12537e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103470
2022-09-30 01:27:38 - progress_bar.py[line:274] - INFO: epoch 003:     53 / 15783 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=80, ups=0.78, wpb=102.2, bsz=40, num_updates=31570, lr=3.12471e-05, gnorm=0.71, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=103483
2022-09-30 01:27:50 - progress_bar.py[line:274] - INFO: epoch 003:     63 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.5, ups=0.85, wpb=103.9, bsz=40, num_updates=31580, lr=3.12405e-05, gnorm=0.781, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=103495
2022-09-30 01:28:01 - progress_bar.py[line:274] - INFO: epoch 003:     73 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.8, ups=0.93, wpb=102.1, bsz=40, num_updates=31590, lr=3.12339e-05, gnorm=0.726, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=103506
2022-09-30 01:28:12 - progress_bar.py[line:274] - INFO: epoch 003:     83 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.1, ups=0.92, wpb=101.6, bsz=40, num_updates=31600, lr=3.12273e-05, gnorm=0.839, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103517
2022-09-30 01:28:23 - progress_bar.py[line:274] - INFO: epoch 003:     93 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.5, ups=0.9, wpb=100.5, bsz=40, num_updates=31610, lr=3.12207e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103528
2022-09-30 01:28:34 - progress_bar.py[line:274] - INFO: epoch 003:    103 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.4, ups=0.88, wpb=102, bsz=40, num_updates=31620, lr=3.12141e-05, gnorm=0.811, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=103539
2022-09-30 01:28:46 - progress_bar.py[line:274] - INFO: epoch 003:    113 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.9, ups=0.87, wpb=100.7, bsz=40, num_updates=31630, lr=3.12075e-05, gnorm=0.817, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103551
2022-09-30 01:28:57 - progress_bar.py[line:274] - INFO: epoch 003:    123 / 15783 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=89.2, ups=0.86, wpb=103.9, bsz=40, num_updates=31640, lr=3.12009e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=103562
2022-09-30 01:29:08 - progress_bar.py[line:274] - INFO: epoch 003:    133 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93, ups=0.92, wpb=101.1, bsz=40, num_updates=31650, lr=3.11943e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103573
2022-09-30 01:29:20 - progress_bar.py[line:274] - INFO: epoch 003:    143 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.7, ups=0.88, wpb=102.1, bsz=40, num_updates=31660, lr=3.11877e-05, gnorm=0.683, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103585
2022-09-30 01:29:31 - progress_bar.py[line:274] - INFO: epoch 003:    153 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.5, ups=0.87, wpb=100.1, bsz=40, num_updates=31670, lr=3.11811e-05, gnorm=0.9, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103596
2022-09-30 01:29:42 - progress_bar.py[line:274] - INFO: epoch 003:    163 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.9, wpb=101.6, bsz=40, num_updates=31680, lr=3.11745e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103607
2022-09-30 01:29:53 - progress_bar.py[line:274] - INFO: epoch 003:    173 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.9, ups=0.91, wpb=100.6, bsz=40, num_updates=31690, lr=3.11679e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103618
2022-09-30 01:30:05 - progress_bar.py[line:274] - INFO: epoch 003:    183 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=87.7, ups=0.87, wpb=100.7, bsz=40, num_updates=31700, lr=3.11613e-05, gnorm=0.847, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103630
2022-09-30 01:30:16 - progress_bar.py[line:274] - INFO: epoch 003:    193 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.8, ups=0.91, wpb=101.5, bsz=40, num_updates=31710, lr=3.11547e-05, gnorm=0.715, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103640
2022-09-30 01:30:27 - progress_bar.py[line:274] - INFO: epoch 003:    203 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.7, ups=0.9, wpb=100.6, bsz=40, num_updates=31720, lr=3.11481e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103652
2022-09-30 01:30:38 - progress_bar.py[line:274] - INFO: epoch 003:    213 / 15783 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.89, wpb=101, bsz=40, num_updates=31730, lr=3.11415e-05, gnorm=0.995, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=103663
2022-09-30 01:30:49 - progress_bar.py[line:274] - INFO: epoch 003:    223 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.88, wpb=101.9, bsz=40, num_updates=31740, lr=3.11349e-05, gnorm=0.919, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103674
2022-09-30 01:31:01 - progress_bar.py[line:274] - INFO: epoch 003:    233 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.7, ups=0.86, wpb=101.4, bsz=40, num_updates=31750, lr=3.11283e-05, gnorm=0.91, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=103686
2022-09-30 01:31:12 - progress_bar.py[line:274] - INFO: epoch 003:    243 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=31760, lr=3.11217e-05, gnorm=0.989, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103697
2022-09-30 01:31:23 - progress_bar.py[line:274] - INFO: epoch 003:    253 / 15783 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=93.1, ups=0.91, wpb=101.8, bsz=40, num_updates=31770, lr=3.11151e-05, gnorm=0.759, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103708
2022-09-30 01:31:35 - progress_bar.py[line:274] - INFO: epoch 003:    263 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=87.4, ups=0.87, wpb=100.7, bsz=40, num_updates=31780, lr=3.11085e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=103719
2022-09-30 01:31:47 - progress_bar.py[line:274] - INFO: epoch 003:    273 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.1, ups=0.89, wpb=103.2, bsz=40, num_updates=31790, lr=3.11019e-05, gnorm=0.793, clip=20, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=103731
2022-09-30 01:31:58 - progress_bar.py[line:274] - INFO: epoch 003:    283 / 15783 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.6, ups=0.92, wpb=101.2, bsz=40, num_updates=31800, lr=3.10953e-05, gnorm=0.744, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=103743
2022-09-30 01:32:10 - progress_bar.py[line:274] - INFO: epoch 003:    293 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=84.5, ups=0.82, wpb=102.7, bsz=40, num_updates=31810, lr=3.10887e-05, gnorm=0.818, clip=20, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=103755
2022-09-30 01:32:23 - progress_bar.py[line:274] - INFO: epoch 003:    303 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=80.2, ups=0.81, wpb=99, bsz=40, num_updates=31820, lr=3.10821e-05, gnorm=0.822, clip=20, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=103767
2022-09-30 01:32:34 - progress_bar.py[line:274] - INFO: epoch 003:    313 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.8, ups=0.89, wpb=101.2, bsz=40, num_updates=31830, lr=3.10755e-05, gnorm=0.763, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103779
2022-09-30 01:32:45 - progress_bar.py[line:274] - INFO: epoch 003:    323 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.6, ups=0.88, wpb=100.4, bsz=40, num_updates=31840, lr=3.10689e-05, gnorm=0.72, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103790
2022-09-30 01:32:57 - progress_bar.py[line:274] - INFO: epoch 003:    333 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.9, wpb=100.9, bsz=40, num_updates=31850, lr=3.10623e-05, gnorm=0.972, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103801
2022-09-30 01:33:08 - progress_bar.py[line:274] - INFO: epoch 003:    343 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.89, wpb=101.2, bsz=40, num_updates=31860, lr=3.10557e-05, gnorm=0.767, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=103813
2022-09-30 01:33:19 - progress_bar.py[line:274] - INFO: epoch 003:    353 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.4, ups=0.9, wpb=101.1, bsz=40, num_updates=31870, lr=3.10491e-05, gnorm=0.916, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103824
2022-09-30 01:33:23 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 01:33:31 - progress_bar.py[line:274] - INFO: epoch 003:    364 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.6, ups=0.85, wpb=102.4, bsz=40, num_updates=31880, lr=3.10425e-05, gnorm=0.905, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=103836
2022-09-30 01:33:42 - progress_bar.py[line:274] - INFO: epoch 003:    374 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.89, wpb=101.5, bsz=40, num_updates=31890, lr=3.10359e-05, gnorm=0.924, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103847
2022-09-30 01:33:53 - progress_bar.py[line:274] - INFO: epoch 003:    384 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89, ups=0.88, wpb=101.4, bsz=40, num_updates=31900, lr=3.10293e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103858
2022-09-30 01:34:05 - progress_bar.py[line:274] - INFO: epoch 003:    394 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.7, ups=0.89, wpb=102.9, bsz=40, num_updates=31910, lr=3.10227e-05, gnorm=0.834, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103869
2022-09-30 01:34:15 - progress_bar.py[line:274] - INFO: epoch 003:    404 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.7, ups=0.92, wpb=101.7, bsz=40, num_updates=31920, lr=3.10161e-05, gnorm=0.996, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103880
2022-09-30 01:34:27 - progress_bar.py[line:274] - INFO: epoch 003:    414 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.9, ups=0.88, wpb=102.2, bsz=40, num_updates=31930, lr=3.10095e-05, gnorm=0.748, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103892
2022-09-30 01:34:38 - progress_bar.py[line:274] - INFO: epoch 003:    424 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89, ups=0.88, wpb=101.1, bsz=40, num_updates=31940, lr=3.10029e-05, gnorm=0.747, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103903
2022-09-30 01:34:51 - progress_bar.py[line:274] - INFO: epoch 003:    434 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=82, ups=0.79, wpb=104, bsz=40, num_updates=31950, lr=3.09963e-05, gnorm=0.695, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=103916
2022-09-30 01:35:03 - progress_bar.py[line:274] - INFO: epoch 003:    444 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=80, ups=0.81, wpb=99.4, bsz=40, num_updates=31960, lr=3.09897e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=103928
2022-09-30 01:35:15 - progress_bar.py[line:274] - INFO: epoch 003:    454 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.88, wpb=101.9, bsz=40, num_updates=31970, lr=3.09831e-05, gnorm=0.902, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103940
2022-09-30 01:35:26 - progress_bar.py[line:274] - INFO: epoch 003:    464 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.6, ups=0.9, wpb=100.6, bsz=40, num_updates=31980, lr=3.09765e-05, gnorm=0.87, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103951
2022-09-30 01:35:37 - progress_bar.py[line:274] - INFO: epoch 003:    474 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.7, ups=0.9, wpb=100.5, bsz=40, num_updates=31990, lr=3.09699e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103962
2022-09-30 01:35:48 - progress_bar.py[line:274] - INFO: epoch 003:    484 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.8, ups=0.89, wpb=100.3, bsz=40, num_updates=32000, lr=3.09633e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103973
2022-09-30 01:35:59 - progress_bar.py[line:274] - INFO: epoch 003:    494 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.9, ups=0.91, wpb=101.6, bsz=40, num_updates=32010, lr=3.09567e-05, gnorm=0.955, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103984
2022-09-30 01:36:10 - progress_bar.py[line:274] - INFO: epoch 003:    504 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.9, wpb=99.9, bsz=40, num_updates=32020, lr=3.09501e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103995
2022-09-30 01:36:21 - progress_bar.py[line:274] - INFO: epoch 003:    514 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.2, ups=0.9, wpb=101.1, bsz=40, num_updates=32030, lr=3.09435e-05, gnorm=0.767, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=104006
2022-09-30 01:36:33 - progress_bar.py[line:274] - INFO: epoch 003:    524 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87, ups=0.86, wpb=101.4, bsz=40, num_updates=32040, lr=3.09369e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=104018
2022-09-30 01:36:46 - progress_bar.py[line:274] - INFO: epoch 003:    534 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=78.9, ups=0.77, wpb=102.2, bsz=40, num_updates=32050, lr=3.09303e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=104031
2022-09-30 01:36:58 - progress_bar.py[line:274] - INFO: epoch 003:    544 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=86.2, ups=0.85, wpb=101.8, bsz=40, num_updates=32060, lr=3.09237e-05, gnorm=0.923, clip=40, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=104042
2022-09-30 01:37:10 - progress_bar.py[line:274] - INFO: epoch 003:    554 / 15783 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=93.2, ups=0.9, wpb=103.1, bsz=40, num_updates=32070, lr=3.09171e-05, gnorm=0.8, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=104054
2022-09-30 01:37:21 - progress_bar.py[line:274] - INFO: epoch 003:    564 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.2, ups=0.93, wpb=101.2, bsz=40, num_updates=32080, lr=3.09105e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=104065
2022-09-30 01:37:31 - progress_bar.py[line:274] - INFO: epoch 003:    574 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95, ups=0.93, wpb=102.5, bsz=40, num_updates=32090, lr=3.09039e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=104076
2022-09-30 01:37:43 - progress_bar.py[line:274] - INFO: epoch 003:    584 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.2, ups=0.89, wpb=99.2, bsz=40, num_updates=32100, lr=3.08973e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104088
2022-09-30 01:37:54 - progress_bar.py[line:274] - INFO: epoch 003:    594 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=32110, lr=3.08907e-05, gnorm=0.714, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104099
2022-09-30 01:38:05 - progress_bar.py[line:274] - INFO: epoch 003:    604 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.89, wpb=99.8, bsz=40, num_updates=32120, lr=3.08841e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=104110
2022-09-30 01:38:18 - progress_bar.py[line:274] - INFO: epoch 003:    614 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=80.1, ups=0.79, wpb=101.2, bsz=40, num_updates=32130, lr=3.08775e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=104123
2022-09-30 01:38:31 - progress_bar.py[line:274] - INFO: epoch 003:    624 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=79.4, ups=0.77, wpb=102.7, bsz=40, num_updates=32140, lr=3.08709e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=104136
2022-09-30 01:38:42 - progress_bar.py[line:274] - INFO: epoch 003:    634 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=32150, lr=3.08643e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104147
2022-09-30 01:38:53 - progress_bar.py[line:274] - INFO: epoch 003:    644 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.6, ups=0.91, wpb=101.2, bsz=40, num_updates=32160, lr=3.08577e-05, gnorm=0.952, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104158
2022-09-30 01:39:04 - progress_bar.py[line:274] - INFO: epoch 003:    654 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.4, ups=0.88, wpb=102.2, bsz=40, num_updates=32170, lr=3.08511e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=104169
2022-09-30 01:39:15 - progress_bar.py[line:274] - INFO: epoch 003:    664 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.91, wpb=102.3, bsz=40, num_updates=32180, lr=3.08445e-05, gnorm=0.902, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104180
2022-09-30 01:39:27 - progress_bar.py[line:274] - INFO: epoch 003:    674 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88, ups=0.87, wpb=101.5, bsz=40, num_updates=32190, lr=3.08379e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104192
2022-09-30 01:39:38 - progress_bar.py[line:274] - INFO: epoch 003:    684 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=32200, lr=3.08313e-05, gnorm=0.824, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104203
2022-09-30 01:39:49 - progress_bar.py[line:274] - INFO: epoch 003:    694 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.8, ups=0.96, wpb=101.9, bsz=40, num_updates=32210, lr=3.08247e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=104214
2022-09-30 01:40:00 - progress_bar.py[line:274] - INFO: epoch 003:    704 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.5, ups=0.87, wpb=101.7, bsz=40, num_updates=32220, lr=3.08181e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104225
2022-09-30 01:40:12 - progress_bar.py[line:274] - INFO: epoch 003:    714 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.6, ups=0.87, wpb=102.4, bsz=40, num_updates=32230, lr=3.08115e-05, gnorm=0.931, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=104237
2022-09-30 01:40:23 - progress_bar.py[line:274] - INFO: epoch 003:    724 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=32240, lr=3.08049e-05, gnorm=0.886, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=104248
2022-09-30 01:40:34 - progress_bar.py[line:274] - INFO: epoch 003:    734 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.1, ups=0.89, wpb=101, bsz=40, num_updates=32250, lr=3.07983e-05, gnorm=0.708, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104259
2022-09-30 01:40:46 - progress_bar.py[line:274] - INFO: epoch 003:    744 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.6, ups=0.88, wpb=99.8, bsz=40, num_updates=32260, lr=3.07917e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104271
2022-09-30 01:40:57 - progress_bar.py[line:274] - INFO: epoch 003:    754 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=32270, lr=3.07851e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104282
2022-09-30 01:41:08 - progress_bar.py[line:274] - INFO: epoch 003:    764 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.9, wpb=100, bsz=40, num_updates=32280, lr=3.07785e-05, gnorm=0.869, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104293
2022-09-30 01:41:20 - progress_bar.py[line:274] - INFO: epoch 003:    774 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=32290, lr=3.07719e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104305
2022-09-30 01:41:31 - progress_bar.py[line:274] - INFO: epoch 003:    784 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.8, ups=0.89, wpb=102.3, bsz=40, num_updates=32300, lr=3.07653e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=104316
2022-09-30 01:41:42 - progress_bar.py[line:274] - INFO: epoch 003:    794 / 15783 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=89.3, ups=0.88, wpb=101.8, bsz=40, num_updates=32310, lr=3.07587e-05, gnorm=0.73, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104327
2022-09-30 01:41:53 - progress_bar.py[line:274] - INFO: epoch 003:    804 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.92, wpb=99.5, bsz=40, num_updates=32320, lr=3.07521e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=104338
2022-09-30 01:42:04 - progress_bar.py[line:274] - INFO: epoch 003:    814 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.6, ups=0.92, wpb=101.1, bsz=40, num_updates=32330, lr=3.07455e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104349
2022-09-30 01:42:15 - progress_bar.py[line:274] - INFO: epoch 003:    824 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.1, ups=0.9, wpb=101.1, bsz=40, num_updates=32340, lr=3.07389e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=104360
2022-09-30 01:42:26 - progress_bar.py[line:274] - INFO: epoch 003:    834 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=32350, lr=3.07323e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104371
2022-09-30 01:42:38 - progress_bar.py[line:274] - INFO: epoch 003:    844 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.5, ups=0.87, wpb=103, bsz=40, num_updates=32360, lr=3.07257e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=104383
2022-09-30 01:42:49 - progress_bar.py[line:274] - INFO: epoch 003:    854 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.5, ups=0.9, wpb=100.6, bsz=40, num_updates=32370, lr=3.07191e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104394
2022-09-30 01:43:00 - progress_bar.py[line:274] - INFO: epoch 003:    864 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.2, ups=0.89, wpb=99.9, bsz=40, num_updates=32380, lr=3.07125e-05, gnorm=0.86, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=104405
2022-09-30 01:43:11 - progress_bar.py[line:274] - INFO: epoch 003:    874 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.9, wpb=101.5, bsz=40, num_updates=32390, lr=3.07059e-05, gnorm=0.967, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104416
2022-09-30 01:43:23 - progress_bar.py[line:274] - INFO: epoch 003:    884 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.89, wpb=100.5, bsz=40, num_updates=32400, lr=3.06993e-05, gnorm=0.841, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104428
2022-09-30 01:43:35 - progress_bar.py[line:274] - INFO: epoch 003:    894 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=80.8, ups=0.8, wpb=101.5, bsz=40, num_updates=32410, lr=3.06927e-05, gnorm=0.795, clip=10, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=104440
2022-09-30 01:43:47 - progress_bar.py[line:274] - INFO: epoch 003:    904 / 15783 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=85.4, ups=0.84, wpb=102.3, bsz=40, num_updates=32420, lr=3.06861e-05, gnorm=0.836, clip=10, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=104452
2022-09-30 01:43:58 - progress_bar.py[line:274] - INFO: epoch 003:    914 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.9, ups=0.92, wpb=102.5, bsz=40, num_updates=32430, lr=3.06795e-05, gnorm=0.824, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104463
2022-09-30 01:44:09 - progress_bar.py[line:274] - INFO: epoch 003:    924 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.89, wpb=100.3, bsz=40, num_updates=32440, lr=3.06729e-05, gnorm=0.898, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104474
2022-09-30 01:44:20 - progress_bar.py[line:274] - INFO: epoch 003:    934 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.2, ups=0.9, wpb=102.1, bsz=40, num_updates=32450, lr=3.06663e-05, gnorm=0.826, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104485
2022-09-30 01:44:31 - progress_bar.py[line:274] - INFO: epoch 003:    944 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.93, wpb=100.7, bsz=40, num_updates=32460, lr=3.06597e-05, gnorm=0.855, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=104496
2022-09-30 01:44:42 - progress_bar.py[line:274] - INFO: epoch 003:    954 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.8, ups=0.9, wpb=100.2, bsz=40, num_updates=32470, lr=3.06531e-05, gnorm=0.884, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104507
2022-09-30 01:44:53 - progress_bar.py[line:274] - INFO: epoch 003:    964 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.8, ups=0.93, wpb=101.1, bsz=40, num_updates=32480, lr=3.06465e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104518
2022-09-30 01:45:04 - progress_bar.py[line:274] - INFO: epoch 003:    974 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=32490, lr=3.06399e-05, gnorm=0.835, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104529
2022-09-30 01:45:15 - progress_bar.py[line:274] - INFO: epoch 003:    984 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.9, wpb=101.6, bsz=40, num_updates=32500, lr=3.06333e-05, gnorm=0.83, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=104540
2022-09-30 01:45:20 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 01:45:28 - progress_bar.py[line:274] - INFO: epoch 003:    995 / 15783 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=83, ups=0.82, wpb=101.8, bsz=40, num_updates=32510, lr=3.06267e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=104553
2022-09-30 01:45:39 - progress_bar.py[line:274] - INFO: epoch 003:   1005 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.2, ups=0.86, wpb=101.3, bsz=40, num_updates=32520, lr=3.06201e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=104564
2022-09-30 01:45:51 - progress_bar.py[line:274] - INFO: epoch 003:   1015 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.89, wpb=102.9, bsz=40, num_updates=32530, lr=3.06135e-05, gnorm=0.894, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104575
2022-09-30 01:46:02 - progress_bar.py[line:274] - INFO: epoch 003:   1025 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.7, ups=0.89, wpb=100.9, bsz=40, num_updates=32540, lr=3.06069e-05, gnorm=0.969, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=104587
2022-09-30 01:46:13 - progress_bar.py[line:274] - INFO: epoch 003:   1035 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.1, ups=0.89, wpb=102.5, bsz=40, num_updates=32550, lr=3.06003e-05, gnorm=0.684, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104598
2022-09-30 01:46:25 - progress_bar.py[line:274] - INFO: epoch 003:   1045 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=32560, lr=3.05937e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104609
2022-09-30 01:46:36 - progress_bar.py[line:274] - INFO: epoch 003:   1055 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=32570, lr=3.05871e-05, gnorm=0.772, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=104621
2022-09-30 01:46:47 - progress_bar.py[line:274] - INFO: epoch 003:   1065 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.3, ups=0.87, wpb=101.9, bsz=40, num_updates=32580, lr=3.05805e-05, gnorm=0.857, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=104632
2022-09-30 01:46:58 - progress_bar.py[line:274] - INFO: epoch 003:   1075 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.9, wpb=100, bsz=40, num_updates=32590, lr=3.05739e-05, gnorm=0.987, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=104643
2022-09-30 01:47:11 - progress_bar.py[line:274] - INFO: epoch 003:   1085 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.3, ups=0.9, wpb=102.7, bsz=40, num_updates=32600, lr=3.05673e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=104654
2022-09-30 01:47:22 - progress_bar.py[line:274] - INFO: epoch 003:   1095 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=86.5, ups=0.87, wpb=99.6, bsz=40, num_updates=32610, lr=3.05607e-05, gnorm=0.856, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104667
2022-09-30 01:47:33 - progress_bar.py[line:274] - INFO: epoch 003:   1105 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.94, wpb=99.8, bsz=40, num_updates=32620, lr=3.05541e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=104678
2022-09-30 01:47:44 - progress_bar.py[line:274] - INFO: epoch 003:   1115 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=32630, lr=3.05475e-05, gnorm=0.748, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104689
2022-09-30 01:47:55 - progress_bar.py[line:274] - INFO: epoch 003:   1125 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.9, wpb=100.4, bsz=40, num_updates=32640, lr=3.05409e-05, gnorm=0.879, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104700
2022-09-30 01:48:06 - progress_bar.py[line:274] - INFO: epoch 003:   1135 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.89, wpb=101.3, bsz=40, num_updates=32650, lr=3.05343e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=104711
2022-09-30 01:48:17 - progress_bar.py[line:274] - INFO: epoch 003:   1145 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=32660, lr=3.05277e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104722
2022-09-30 01:48:29 - progress_bar.py[line:274] - INFO: epoch 003:   1155 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.89, wpb=102.5, bsz=40, num_updates=32670, lr=3.05211e-05, gnorm=0.897, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104734
2022-09-30 01:48:40 - progress_bar.py[line:274] - INFO: epoch 003:   1165 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.9, wpb=101.5, bsz=40, num_updates=32680, lr=3.05145e-05, gnorm=0.882, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104745
2022-09-30 01:48:51 - progress_bar.py[line:274] - INFO: epoch 003:   1175 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=32690, lr=3.05079e-05, gnorm=0.891, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=104756
2022-09-30 01:49:02 - progress_bar.py[line:274] - INFO: epoch 003:   1185 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89, ups=0.88, wpb=101.1, bsz=40, num_updates=32700, lr=3.05013e-05, gnorm=0.814, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104767
2022-09-30 01:49:14 - progress_bar.py[line:274] - INFO: epoch 003:   1195 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=32710, lr=3.04947e-05, gnorm=0.833, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=104779
2022-09-30 01:49:25 - progress_bar.py[line:274] - INFO: epoch 003:   1205 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.91, wpb=101.1, bsz=40, num_updates=32720, lr=3.04881e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104790
2022-09-30 01:49:36 - progress_bar.py[line:274] - INFO: epoch 003:   1215 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.8, ups=0.9, wpb=101.6, bsz=40, num_updates=32730, lr=3.04815e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=104801
2022-09-30 01:49:47 - progress_bar.py[line:274] - INFO: epoch 003:   1225 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92, ups=0.91, wpb=100.8, bsz=40, num_updates=32740, lr=3.04749e-05, gnorm=0.964, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=104812
2022-09-30 01:49:58 - progress_bar.py[line:274] - INFO: epoch 003:   1235 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.9, wpb=100.6, bsz=40, num_updates=32750, lr=3.04683e-05, gnorm=0.921, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104823
2022-09-30 01:50:08 - progress_bar.py[line:274] - INFO: epoch 003:   1245 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.9, ups=0.95, wpb=101.9, bsz=40, num_updates=32760, lr=3.04617e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=10, gb_free=10.2, ema_decay=0.9999, wall=104833
2022-09-30 01:50:20 - progress_bar.py[line:274] - INFO: epoch 003:   1255 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.3, ups=0.88, wpb=101.6, bsz=40, num_updates=32770, lr=3.04551e-05, gnorm=0.864, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104845
2022-09-30 01:50:31 - progress_bar.py[line:274] - INFO: epoch 003:   1265 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.88, wpb=103.2, bsz=40, num_updates=32780, lr=3.04485e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104856
2022-09-30 01:50:42 - progress_bar.py[line:274] - INFO: epoch 003:   1275 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.89, wpb=100.1, bsz=40, num_updates=32790, lr=3.04419e-05, gnorm=0.853, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=104867
2022-09-30 01:50:54 - progress_bar.py[line:274] - INFO: epoch 003:   1285 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.4, ups=0.87, wpb=100.3, bsz=40, num_updates=32800, lr=3.04353e-05, gnorm=0.731, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=104879
2022-09-30 01:51:05 - progress_bar.py[line:274] - INFO: epoch 003:   1295 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.7, ups=0.91, wpb=100.3, bsz=40, num_updates=32810, lr=3.04287e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=104890
2022-09-30 01:51:16 - progress_bar.py[line:274] - INFO: epoch 003:   1305 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.5, ups=0.87, wpb=99.4, bsz=40, num_updates=32820, lr=3.04221e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104901
2022-09-30 01:51:28 - progress_bar.py[line:274] - INFO: epoch 003:   1315 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.6, ups=0.89, wpb=101.9, bsz=40, num_updates=32830, lr=3.04155e-05, gnorm=0.863, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104912
2022-09-30 01:51:39 - progress_bar.py[line:274] - INFO: epoch 003:   1325 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=87.7, ups=0.87, wpb=101.1, bsz=40, num_updates=32840, lr=3.04089e-05, gnorm=0.768, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104924
2022-09-30 01:51:50 - progress_bar.py[line:274] - INFO: epoch 003:   1335 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.2, ups=0.94, wpb=99.8, bsz=40, num_updates=32850, lr=3.04023e-05, gnorm=0.979, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104935
2022-09-30 01:52:01 - progress_bar.py[line:274] - INFO: epoch 003:   1345 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.7, ups=0.89, wpb=100.9, bsz=40, num_updates=32860, lr=3.03957e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=104946
2022-09-30 01:52:12 - progress_bar.py[line:274] - INFO: epoch 003:   1355 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.4, ups=0.88, wpb=99.4, bsz=40, num_updates=32870, lr=3.03891e-05, gnorm=0.82, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104957
2022-09-30 01:52:24 - progress_bar.py[line:274] - INFO: epoch 003:   1365 / 15783 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=88.6, ups=0.86, wpb=102.4, bsz=40, num_updates=32880, lr=3.03825e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=104969
2022-09-30 01:52:35 - progress_bar.py[line:274] - INFO: epoch 003:   1375 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.5, ups=0.88, wpb=100.6, bsz=40, num_updates=32890, lr=3.03759e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=104980
2022-09-30 01:52:47 - progress_bar.py[line:274] - INFO: epoch 003:   1385 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=32900, lr=3.03693e-05, gnorm=0.714, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=104991
2022-09-30 01:52:58 - progress_bar.py[line:274] - INFO: epoch 003:   1395 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.9, wpb=100.7, bsz=40, num_updates=32910, lr=3.03627e-05, gnorm=0.945, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105003
2022-09-30 01:53:09 - progress_bar.py[line:274] - INFO: epoch 003:   1405 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.5, ups=0.87, wpb=101.3, bsz=40, num_updates=32920, lr=3.03561e-05, gnorm=0.748, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=105014
2022-09-30 01:53:20 - progress_bar.py[line:274] - INFO: epoch 003:   1415 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=32930, lr=3.03495e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=105025
2022-09-30 01:53:31 - progress_bar.py[line:274] - INFO: epoch 003:   1425 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.2, ups=0.9, wpb=101, bsz=40, num_updates=32940, lr=3.03429e-05, gnorm=0.754, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105036
2022-09-30 01:53:42 - progress_bar.py[line:274] - INFO: epoch 003:   1435 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.3, ups=0.91, wpb=101.8, bsz=40, num_updates=32950, lr=3.03363e-05, gnorm=0.808, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=105047
2022-09-30 01:53:53 - progress_bar.py[line:274] - INFO: epoch 003:   1445 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.2, ups=0.94, wpb=102.3, bsz=40, num_updates=32960, lr=3.03297e-05, gnorm=0.8, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=105058
2022-09-30 01:54:04 - progress_bar.py[line:274] - INFO: epoch 003:   1455 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89, ups=0.88, wpb=101.1, bsz=40, num_updates=32970, lr=3.03231e-05, gnorm=0.795, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=105069
2022-09-30 01:54:15 - progress_bar.py[line:274] - INFO: epoch 003:   1465 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.7, ups=0.91, wpb=100.8, bsz=40, num_updates=32980, lr=3.03165e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=105080
2022-09-30 01:54:27 - progress_bar.py[line:274] - INFO: epoch 003:   1475 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.7, ups=0.88, wpb=101.5, bsz=40, num_updates=32990, lr=3.03099e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=105092
2022-09-30 01:54:38 - progress_bar.py[line:274] - INFO: epoch 003:   1485 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89, ups=0.88, wpb=101.1, bsz=40, num_updates=33000, lr=3.03033e-05, gnorm=0.789, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=105103
2022-09-30 01:54:50 - progress_bar.py[line:274] - INFO: epoch 003:   1495 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.1, ups=0.87, wpb=101, bsz=40, num_updates=33010, lr=3.02967e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=105115
2022-09-30 01:55:01 - progress_bar.py[line:274] - INFO: epoch 003:   1505 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.7, ups=0.92, wpb=100.8, bsz=40, num_updates=33020, lr=3.02901e-05, gnorm=0.858, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105125
2022-09-30 01:55:12 - progress_bar.py[line:274] - INFO: epoch 003:   1515 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.2, ups=0.89, wpb=100.8, bsz=40, num_updates=33030, lr=3.02835e-05, gnorm=0.987, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=105137
2022-09-30 01:55:23 - progress_bar.py[line:274] - INFO: epoch 003:   1525 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.8, ups=0.88, wpb=100.2, bsz=40, num_updates=33040, lr=3.02769e-05, gnorm=0.827, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=105148
2022-09-30 01:55:34 - progress_bar.py[line:274] - INFO: epoch 003:   1535 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.9, wpb=100.1, bsz=40, num_updates=33050, lr=3.02703e-05, gnorm=0.791, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=105159
2022-09-30 01:55:45 - progress_bar.py[line:274] - INFO: epoch 003:   1545 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.9, wpb=101.3, bsz=40, num_updates=33060, lr=3.02637e-05, gnorm=0.85, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=105170
2022-09-30 01:55:57 - progress_bar.py[line:274] - INFO: epoch 003:   1555 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.9, wpb=100, bsz=40, num_updates=33070, lr=3.02571e-05, gnorm=0.824, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105181
2022-09-30 01:56:07 - progress_bar.py[line:274] - INFO: epoch 003:   1565 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.2, ups=0.92, wpb=101.7, bsz=40, num_updates=33080, lr=3.02505e-05, gnorm=0.831, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=105192
2022-09-30 01:56:18 - progress_bar.py[line:274] - INFO: epoch 003:   1575 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.3, ups=0.92, wpb=101.2, bsz=40, num_updates=33090, lr=3.02439e-05, gnorm=0.823, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105203
2022-09-30 01:56:30 - progress_bar.py[line:274] - INFO: epoch 003:   1585 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.89, wpb=100.1, bsz=40, num_updates=33100, lr=3.02373e-05, gnorm=0.84, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=105214
2022-09-30 01:56:41 - progress_bar.py[line:274] - INFO: epoch 003:   1595 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.4, ups=0.88, wpb=99.2, bsz=40, num_updates=33110, lr=3.02307e-05, gnorm=0.847, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=105226
2022-09-30 01:56:52 - progress_bar.py[line:274] - INFO: epoch 003:   1605 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.1, ups=0.92, wpb=101.5, bsz=40, num_updates=33120, lr=3.02241e-05, gnorm=0.9, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105237
2022-09-30 01:57:03 - progress_bar.py[line:274] - INFO: epoch 003:   1615 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.9, ups=0.89, wpb=100.7, bsz=40, num_updates=33130, lr=3.02175e-05, gnorm=0.849, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105248
2022-09-30 01:57:15 - progress_bar.py[line:274] - INFO: epoch 003:   1625 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.6, ups=0.87, wpb=101.1, bsz=40, num_updates=33140, lr=3.02109e-05, gnorm=0.886, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105259
2022-09-30 01:57:25 - progress_bar.py[line:274] - INFO: epoch 003:   1635 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.3, ups=0.93, wpb=100.6, bsz=40, num_updates=33150, lr=3.02043e-05, gnorm=0.912, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=105270
2022-09-30 01:57:36 - progress_bar.py[line:274] - INFO: epoch 003:   1645 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96, ups=0.93, wpb=103.2, bsz=40, num_updates=33160, lr=3.01977e-05, gnorm=0.862, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105281
2022-09-30 01:57:47 - progress_bar.py[line:274] - INFO: epoch 003:   1655 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.7, ups=0.93, wpb=101.4, bsz=40, num_updates=33170, lr=3.01911e-05, gnorm=0.821, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=105292
2022-09-30 01:57:59 - progress_bar.py[line:274] - INFO: epoch 003:   1665 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=83.7, ups=0.82, wpb=101.6, bsz=40, num_updates=33180, lr=3.01845e-05, gnorm=0.884, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=105304
2022-09-30 01:58:11 - progress_bar.py[line:274] - INFO: epoch 003:   1675 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=81.6, ups=0.8, wpb=101.7, bsz=40, num_updates=33190, lr=3.01779e-05, gnorm=0.824, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=105316
2022-09-30 01:58:23 - progress_bar.py[line:274] - INFO: epoch 003:   1685 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.89, wpb=101.6, bsz=40, num_updates=33200, lr=3.01713e-05, gnorm=0.948, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105328
2022-09-30 01:58:34 - progress_bar.py[line:274] - INFO: epoch 003:   1695 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.3, ups=0.88, wpb=102.1, bsz=40, num_updates=33210, lr=3.01647e-05, gnorm=0.849, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105339
2022-09-30 01:58:45 - progress_bar.py[line:274] - INFO: epoch 003:   1705 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.9, wpb=100.5, bsz=40, num_updates=33220, lr=3.01581e-05, gnorm=0.926, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=105350
2022-09-30 01:58:56 - progress_bar.py[line:274] - INFO: epoch 003:   1715 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.89, wpb=102, bsz=40, num_updates=33230, lr=3.01515e-05, gnorm=0.874, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105361
2022-09-30 01:59:08 - progress_bar.py[line:274] - INFO: epoch 003:   1725 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=33240, lr=3.01449e-05, gnorm=0.961, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=105373
2022-09-30 01:59:19 - progress_bar.py[line:274] - INFO: epoch 003:   1735 / 15783 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.5, ups=0.86, wpb=102.5, bsz=40, num_updates=33250, lr=3.01383e-05, gnorm=0.808, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105384
2022-09-30 01:59:31 - progress_bar.py[line:274] - INFO: epoch 003:   1745 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.5, ups=0.86, wpb=101.2, bsz=40, num_updates=33260, lr=3.01317e-05, gnorm=0.835, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=105396
2022-09-30 01:59:42 - progress_bar.py[line:274] - INFO: epoch 003:   1755 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=33270, lr=3.01251e-05, gnorm=0.908, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105407
2022-09-30 01:59:53 - progress_bar.py[line:274] - INFO: epoch 003:   1765 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=33280, lr=3.01185e-05, gnorm=0.835, clip=10, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=105418
2022-09-30 02:00:05 - progress_bar.py[line:274] - INFO: epoch 003:   1775 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.88, wpb=101.9, bsz=40, num_updates=33290, lr=3.01119e-05, gnorm=0.843, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105430
2022-09-30 02:00:16 - progress_bar.py[line:274] - INFO: epoch 003:   1785 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.2, ups=0.88, wpb=102, bsz=40, num_updates=33300, lr=3.01053e-05, gnorm=0.877, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105441
2022-09-30 02:00:27 - progress_bar.py[line:274] - INFO: epoch 003:   1795 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.5, ups=0.9, wpb=101.1, bsz=40, num_updates=33310, lr=3.00987e-05, gnorm=0.822, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105452
2022-09-30 02:00:39 - progress_bar.py[line:274] - INFO: epoch 003:   1805 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.88, wpb=101.9, bsz=40, num_updates=33320, lr=3.00921e-05, gnorm=0.872, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105463
2022-09-30 02:00:50 - progress_bar.py[line:274] - INFO: epoch 003:   1815 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.9, wpb=101.4, bsz=40, num_updates=33330, lr=3.00855e-05, gnorm=0.83, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=105475
2022-09-30 02:01:02 - progress_bar.py[line:274] - INFO: epoch 003:   1825 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=86.3, ups=0.84, wpb=102.6, bsz=40, num_updates=33340, lr=3.00789e-05, gnorm=0.778, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=105486
2022-09-30 02:01:14 - progress_bar.py[line:274] - INFO: epoch 003:   1835 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=81.7, ups=0.82, wpb=100.2, bsz=40, num_updates=33350, lr=3.00723e-05, gnorm=0.833, clip=10, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=105499
2022-09-30 02:01:26 - progress_bar.py[line:274] - INFO: epoch 003:   1845 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=81.2, ups=0.8, wpb=101.8, bsz=40, num_updates=33360, lr=3.00657e-05, gnorm=0.793, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=105511
2022-09-30 02:01:38 - progress_bar.py[line:274] - INFO: epoch 003:   1855 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.1, ups=0.86, wpb=99.6, bsz=40, num_updates=33370, lr=3.00591e-05, gnorm=0.848, clip=30, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=105523
2022-09-30 02:01:49 - progress_bar.py[line:274] - INFO: epoch 003:   1865 / 15783 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=33380, lr=3.00525e-05, gnorm=0.79, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105534
2022-09-30 02:02:01 - progress_bar.py[line:274] - INFO: epoch 003:   1875 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.4, ups=0.89, wpb=100.9, bsz=40, num_updates=33390, lr=3.00459e-05, gnorm=0.979, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105545
2022-09-30 02:02:11 - progress_bar.py[line:274] - INFO: epoch 003:   1885 / 15783 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=93.6, ups=0.93, wpb=100.9, bsz=40, num_updates=33400, lr=3.00393e-05, gnorm=0.867, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105556
2022-09-30 02:02:23 - progress_bar.py[line:274] - INFO: epoch 003:   1895 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=33410, lr=3.00327e-05, gnorm=0.859, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=105567
2022-09-30 02:02:34 - progress_bar.py[line:274] - INFO: epoch 003:   1905 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.9, wpb=100.5, bsz=40, num_updates=33420, lr=3.00261e-05, gnorm=0.843, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=105579
2022-09-30 02:02:45 - progress_bar.py[line:274] - INFO: epoch 003:   1915 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.9, ups=0.9, wpb=102.8, bsz=40, num_updates=33430, lr=3.00195e-05, gnorm=0.919, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105590
2022-09-30 02:02:56 - progress_bar.py[line:274] - INFO: epoch 003:   1925 / 15783 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=91, ups=0.89, wpb=101.7, bsz=40, num_updates=33440, lr=3.00129e-05, gnorm=0.798, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=105601
2022-09-30 02:03:07 - progress_bar.py[line:274] - INFO: epoch 003:   1935 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.2, ups=0.9, wpb=100.7, bsz=40, num_updates=33450, lr=3.00063e-05, gnorm=0.93, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105612
2022-09-30 02:03:18 - progress_bar.py[line:274] - INFO: epoch 003:   1945 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.9, wpb=101.3, bsz=40, num_updates=33460, lr=2.99997e-05, gnorm=0.866, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105623
2022-09-30 02:03:30 - progress_bar.py[line:274] - INFO: epoch 003:   1955 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91, ups=0.88, wpb=102.8, bsz=40, num_updates=33470, lr=2.99931e-05, gnorm=0.909, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=105635
2022-09-30 02:03:41 - progress_bar.py[line:274] - INFO: epoch 003:   1965 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.91, wpb=102.1, bsz=40, num_updates=33480, lr=2.99865e-05, gnorm=0.912, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105646
2022-09-30 02:03:52 - progress_bar.py[line:274] - INFO: epoch 003:   1975 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.2, ups=0.9, wpb=101, bsz=40, num_updates=33490, lr=2.99799e-05, gnorm=0.876, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=105657
2022-09-30 02:04:03 - progress_bar.py[line:274] - INFO: epoch 003:   1985 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=86.9, ups=0.86, wpb=100.5, bsz=40, num_updates=33500, lr=2.99733e-05, gnorm=0.916, clip=20, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=105668
2022-09-30 02:04:15 - progress_bar.py[line:274] - INFO: epoch 003:   1995 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.88, wpb=101.9, bsz=40, num_updates=33510, lr=2.99667e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105680
2022-09-30 02:04:26 - progress_bar.py[line:274] - INFO: epoch 003:   2005 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.8, ups=0.91, wpb=101.5, bsz=40, num_updates=33520, lr=2.99601e-05, gnorm=0.68, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105691
2022-09-30 02:04:37 - progress_bar.py[line:274] - INFO: epoch 003:   2015 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.3, ups=0.9, wpb=102.5, bsz=40, num_updates=33530, lr=2.99535e-05, gnorm=0.818, clip=10, loss_scale=2048, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=105702
2022-09-30 02:04:43 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 02:04:49 - progress_bar.py[line:274] - INFO: epoch 003:   2026 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=85.3, ups=0.83, wpb=103.2, bsz=40, num_updates=33540, lr=2.99469e-05, gnorm=0.887, clip=20, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=105714
2022-09-30 02:05:00 - progress_bar.py[line:274] - INFO: epoch 003:   2036 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.88, wpb=102, bsz=40, num_updates=33550, lr=2.99403e-05, gnorm=0.956, clip=60, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=105725
2022-09-30 02:05:11 - progress_bar.py[line:274] - INFO: epoch 003:   2046 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.9, wpb=100.1, bsz=40, num_updates=33560, lr=2.99337e-05, gnorm=0.816, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105736
2022-09-30 02:05:23 - progress_bar.py[line:274] - INFO: epoch 003:   2056 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=87.3, ups=0.87, wpb=100.6, bsz=40, num_updates=33570, lr=2.99271e-05, gnorm=0.866, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105748
2022-09-30 02:05:34 - progress_bar.py[line:274] - INFO: epoch 003:   2066 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.89, wpb=100.3, bsz=40, num_updates=33580, lr=2.99205e-05, gnorm=0.823, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105759
2022-09-30 02:05:45 - progress_bar.py[line:274] - INFO: epoch 003:   2076 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.8, ups=0.89, wpb=102.5, bsz=40, num_updates=33590, lr=2.99139e-05, gnorm=0.725, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105770
2022-09-30 02:05:57 - progress_bar.py[line:274] - INFO: epoch 003:   2086 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.2, ups=0.88, wpb=100.8, bsz=40, num_updates=33600, lr=2.99073e-05, gnorm=0.781, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105782
2022-09-30 02:06:08 - progress_bar.py[line:274] - INFO: epoch 003:   2096 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.1, ups=0.91, wpb=101, bsz=40, num_updates=33610, lr=2.99007e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=105793
2022-09-30 02:06:19 - progress_bar.py[line:274] - INFO: epoch 003:   2106 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.91, wpb=101.6, bsz=40, num_updates=33620, lr=2.98941e-05, gnorm=0.851, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105804
2022-09-30 02:06:30 - progress_bar.py[line:274] - INFO: epoch 003:   2116 / 15783 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.9, ups=0.89, wpb=103.2, bsz=40, num_updates=33630, lr=2.98875e-05, gnorm=0.825, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105815
2022-09-30 02:06:41 - progress_bar.py[line:274] - INFO: epoch 003:   2126 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.3, ups=0.89, wpb=99.8, bsz=40, num_updates=33640, lr=2.98809e-05, gnorm=0.88, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105826
2022-09-30 02:06:53 - progress_bar.py[line:274] - INFO: epoch 003:   2136 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.88, wpb=101.8, bsz=40, num_updates=33650, lr=2.98743e-05, gnorm=0.883, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105838
2022-09-30 02:07:04 - progress_bar.py[line:274] - INFO: epoch 003:   2146 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.9, wpb=102.2, bsz=40, num_updates=33660, lr=2.98677e-05, gnorm=0.836, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=105849
2022-09-30 02:07:15 - progress_bar.py[line:274] - INFO: epoch 003:   2156 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.4, ups=0.92, wpb=101.6, bsz=40, num_updates=33670, lr=2.98611e-05, gnorm=0.879, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=105860
2022-09-30 02:07:26 - progress_bar.py[line:274] - INFO: epoch 003:   2166 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=33680, lr=2.98545e-05, gnorm=0.83, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105871
2022-09-30 02:07:37 - progress_bar.py[line:274] - INFO: epoch 003:   2176 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90, ups=0.9, wpb=100.4, bsz=40, num_updates=33690, lr=2.98479e-05, gnorm=0.86, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105882
2022-09-30 02:07:48 - progress_bar.py[line:274] - INFO: epoch 003:   2186 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.9, wpb=99.5, bsz=40, num_updates=33700, lr=2.98413e-05, gnorm=0.871, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105893
2022-09-30 02:07:59 - progress_bar.py[line:274] - INFO: epoch 003:   2196 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.9, wpb=100.9, bsz=40, num_updates=33710, lr=2.98347e-05, gnorm=0.843, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105904
2022-09-30 02:08:11 - progress_bar.py[line:274] - INFO: epoch 003:   2206 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.7, ups=0.89, wpb=102.2, bsz=40, num_updates=33720, lr=2.98281e-05, gnorm=0.956, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=105916
2022-09-30 02:08:22 - progress_bar.py[line:274] - INFO: epoch 003:   2216 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.8, ups=0.87, wpb=102.6, bsz=40, num_updates=33730, lr=2.98215e-05, gnorm=0.991, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=105927
2022-09-30 02:08:34 - progress_bar.py[line:274] - INFO: epoch 003:   2226 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=87.4, ups=0.87, wpb=100, bsz=40, num_updates=33740, lr=2.98149e-05, gnorm=0.825, clip=30, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=105939
2022-09-30 02:08:45 - progress_bar.py[line:274] - INFO: epoch 003:   2236 / 15783 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=89.6, ups=0.88, wpb=102.4, bsz=40, num_updates=33750, lr=2.98083e-05, gnorm=0.771, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105950
2022-09-30 02:08:56 - progress_bar.py[line:274] - INFO: epoch 003:   2246 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.8, ups=0.88, wpb=102.6, bsz=40, num_updates=33760, lr=2.98017e-05, gnorm=0.887, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=105961
2022-09-30 02:09:07 - progress_bar.py[line:274] - INFO: epoch 003:   2256 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.4, ups=0.93, wpb=101.2, bsz=40, num_updates=33770, lr=2.97951e-05, gnorm=0.933, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=105972
2022-09-30 02:09:19 - progress_bar.py[line:274] - INFO: epoch 003:   2266 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=85.4, ups=0.86, wpb=98.7, bsz=40, num_updates=33780, lr=2.97885e-05, gnorm=0.93, clip=20, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=105984
2022-09-30 02:09:30 - progress_bar.py[line:274] - INFO: epoch 003:   2276 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.6, ups=0.89, wpb=100.9, bsz=40, num_updates=33790, lr=2.97819e-05, gnorm=0.821, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=105995
2022-09-30 02:09:41 - progress_bar.py[line:274] - INFO: epoch 003:   2286 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.5, ups=0.87, wpb=101.4, bsz=40, num_updates=33800, lr=2.97753e-05, gnorm=0.767, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=106006
2022-09-30 02:09:53 - progress_bar.py[line:274] - INFO: epoch 003:   2296 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.9, wpb=101.5, bsz=40, num_updates=33810, lr=2.97687e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106017
2022-09-30 02:10:04 - progress_bar.py[line:274] - INFO: epoch 003:   2306 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.89, wpb=101.2, bsz=40, num_updates=33820, lr=2.97621e-05, gnorm=0.76, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=106029
2022-09-30 02:10:15 - progress_bar.py[line:274] - INFO: epoch 003:   2316 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.1, ups=0.91, wpb=102.9, bsz=40, num_updates=33830, lr=2.97555e-05, gnorm=0.801, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106040
2022-09-30 02:10:28 - progress_bar.py[line:274] - INFO: epoch 003:   2326 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=77.4, ups=0.77, wpb=100.5, bsz=40, num_updates=33840, lr=2.97489e-05, gnorm=0.804, clip=0, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=106053
2022-09-30 02:10:40 - progress_bar.py[line:274] - INFO: epoch 003:   2336 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=78.6, ups=0.79, wpb=99.9, bsz=40, num_updates=33850, lr=2.97423e-05, gnorm=0.857, clip=30, loss_scale=1024, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=106065
2022-09-30 02:10:52 - progress_bar.py[line:274] - INFO: epoch 003:   2346 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.8, ups=0.87, wpb=100.4, bsz=40, num_updates=33860, lr=2.97357e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106077
2022-09-30 02:11:03 - progress_bar.py[line:274] - INFO: epoch 003:   2356 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.89, wpb=102.1, bsz=40, num_updates=33870, lr=2.97291e-05, gnorm=0.816, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106088
2022-09-30 02:11:08 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-09-30 02:11:15 - progress_bar.py[line:274] - INFO: epoch 003:   2367 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=82.7, ups=0.82, wpb=100.2, bsz=40, num_updates=33880, lr=2.97225e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=106100
2022-09-30 02:11:27 - progress_bar.py[line:274] - INFO: epoch 003:   2377 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.8, ups=0.87, wpb=99.8, bsz=40, num_updates=33890, lr=2.97159e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106112
2022-09-30 02:11:38 - progress_bar.py[line:274] - INFO: epoch 003:   2387 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.9, ups=0.87, wpb=101.8, bsz=40, num_updates=33900, lr=2.97093e-05, gnorm=0.782, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106123
2022-09-30 02:11:49 - progress_bar.py[line:274] - INFO: epoch 003:   2397 / 15783 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.2, ups=0.88, wpb=99.8, bsz=40, num_updates=33910, lr=2.97027e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=106134
2022-09-30 02:12:01 - progress_bar.py[line:274] - INFO: epoch 003:   2407 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=33920, lr=2.96961e-05, gnorm=0.746, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106146
2022-09-30 02:12:12 - progress_bar.py[line:274] - INFO: epoch 003:   2417 / 15783 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=33930, lr=2.96895e-05, gnorm=0.79, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106157
2022-09-30 02:12:23 - progress_bar.py[line:274] - INFO: epoch 003:   2427 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.2, ups=0.89, wpb=101.9, bsz=40, num_updates=33940, lr=2.96829e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=106168
2022-09-30 02:12:35 - progress_bar.py[line:274] - INFO: epoch 003:   2437 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89, ups=0.89, wpb=100.4, bsz=40, num_updates=33950, lr=2.96763e-05, gnorm=1.028, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106180
2022-09-30 02:12:46 - progress_bar.py[line:274] - INFO: epoch 003:   2447 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.9, wpb=101.1, bsz=40, num_updates=33960, lr=2.96697e-05, gnorm=0.764, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=106191
2022-09-30 02:12:57 - progress_bar.py[line:274] - INFO: epoch 003:   2457 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.6, ups=0.91, wpb=101.9, bsz=40, num_updates=33970, lr=2.96631e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106202
2022-09-30 02:13:08 - progress_bar.py[line:274] - INFO: epoch 003:   2467 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.89, wpb=101.6, bsz=40, num_updates=33980, lr=2.96565e-05, gnorm=0.907, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106213
2022-09-30 02:13:20 - progress_bar.py[line:274] - INFO: epoch 003:   2477 / 15783 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=89.3, ups=0.88, wpb=102, bsz=40, num_updates=33990, lr=2.96499e-05, gnorm=0.72, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106224
2022-09-30 02:13:31 - progress_bar.py[line:274] - INFO: epoch 003:   2487 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.2, ups=0.86, wpb=100.1, bsz=40, num_updates=34000, lr=2.96433e-05, gnorm=0.874, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=106236
2022-09-30 02:13:43 - progress_bar.py[line:274] - INFO: epoch 003:   2497 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.1, ups=0.89, wpb=99.4, bsz=40, num_updates=34010, lr=2.96367e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=106247
2022-09-30 02:13:54 - progress_bar.py[line:274] - INFO: epoch 003:   2507 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.3, ups=0.89, wpb=101.8, bsz=40, num_updates=34020, lr=2.96301e-05, gnorm=0.844, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=106259
2022-09-30 02:14:05 - progress_bar.py[line:274] - INFO: epoch 003:   2517 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.87, wpb=102.9, bsz=40, num_updates=34030, lr=2.96235e-05, gnorm=0.766, clip=0, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=106270
2022-09-30 02:14:16 - progress_bar.py[line:274] - INFO: epoch 003:   2527 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.1, ups=0.9, wpb=100.4, bsz=40, num_updates=34040, lr=2.96169e-05, gnorm=0.691, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=106281
2022-09-30 02:14:28 - progress_bar.py[line:274] - INFO: epoch 003:   2537 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.1, ups=0.88, wpb=100.3, bsz=40, num_updates=34050, lr=2.96103e-05, gnorm=0.815, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106293
2022-09-30 02:14:39 - progress_bar.py[line:274] - INFO: epoch 003:   2547 / 15783 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.4, ups=0.92, wpb=102.5, bsz=40, num_updates=34060, lr=2.96037e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106304
2022-09-30 02:14:50 - progress_bar.py[line:274] - INFO: epoch 003:   2557 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.8, ups=0.88, wpb=102.4, bsz=40, num_updates=34070, lr=2.95971e-05, gnorm=0.835, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=106315
2022-09-30 02:15:02 - progress_bar.py[line:274] - INFO: epoch 003:   2567 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.88, wpb=102.7, bsz=40, num_updates=34080, lr=2.95905e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106326
2022-09-30 02:15:13 - progress_bar.py[line:274] - INFO: epoch 003:   2577 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.8, ups=0.89, wpb=101.1, bsz=40, num_updates=34090, lr=2.95839e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106338
2022-09-30 02:15:24 - progress_bar.py[line:274] - INFO: epoch 003:   2587 / 15783 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.4, ups=0.89, wpb=102.6, bsz=40, num_updates=34100, lr=2.95773e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=106349
2022-09-30 02:15:35 - progress_bar.py[line:274] - INFO: epoch 003:   2597 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.3, ups=0.88, wpb=101.8, bsz=40, num_updates=34110, lr=2.95707e-05, gnorm=0.723, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=106360
2022-09-30 02:15:47 - progress_bar.py[line:274] - INFO: epoch 003:   2607 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.7, ups=0.88, wpb=100.1, bsz=40, num_updates=34120, lr=2.95641e-05, gnorm=0.858, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=106372
2022-09-30 02:15:58 - progress_bar.py[line:274] - INFO: epoch 003:   2617 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.2, ups=0.86, wpb=101.5, bsz=40, num_updates=34130, lr=2.95575e-05, gnorm=0.908, clip=20, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=106383
2022-09-30 02:16:11 - progress_bar.py[line:274] - INFO: epoch 003:   2627 / 15783 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=83.5, ups=0.81, wpb=102.9, bsz=40, num_updates=34140, lr=2.95509e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=106396
2022-09-30 02:16:23 - progress_bar.py[line:274] - INFO: epoch 003:   2637 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=82.3, ups=0.8, wpb=102.7, bsz=40, num_updates=34150, lr=2.95443e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=106408
2022-09-30 02:16:34 - progress_bar.py[line:274] - INFO: epoch 003:   2647 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.1, ups=0.91, wpb=102.2, bsz=40, num_updates=34160, lr=2.95377e-05, gnorm=0.873, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106419
2022-09-30 02:16:45 - progress_bar.py[line:274] - INFO: epoch 003:   2657 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93, ups=0.91, wpb=102.4, bsz=40, num_updates=34170, lr=2.95311e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106430
2022-09-30 02:16:56 - progress_bar.py[line:274] - INFO: epoch 003:   2667 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.9, ups=0.93, wpb=101.1, bsz=40, num_updates=34180, lr=2.95245e-05, gnorm=0.894, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106441
2022-09-30 02:17:07 - progress_bar.py[line:274] - INFO: epoch 003:   2677 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.89, wpb=101.7, bsz=40, num_updates=34190, lr=2.95179e-05, gnorm=0.748, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=106452
2022-09-30 02:17:19 - progress_bar.py[line:274] - INFO: epoch 003:   2687 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.8, ups=0.89, wpb=102.2, bsz=40, num_updates=34200, lr=2.95113e-05, gnorm=0.81, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106463
2022-09-30 02:17:30 - progress_bar.py[line:274] - INFO: epoch 003:   2697 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.2, ups=0.88, wpb=99.8, bsz=40, num_updates=34210, lr=2.95047e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106475
2022-09-30 02:17:41 - progress_bar.py[line:274] - INFO: epoch 003:   2707 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.1, ups=0.88, wpb=101.6, bsz=40, num_updates=34220, lr=2.94981e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106486
2022-09-30 02:17:53 - progress_bar.py[line:274] - INFO: epoch 003:   2717 / 15783 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=91.1, ups=0.89, wpb=102.8, bsz=40, num_updates=34230, lr=2.94915e-05, gnorm=0.673, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106497
2022-09-30 02:18:04 - progress_bar.py[line:274] - INFO: epoch 003:   2727 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.4, ups=0.89, wpb=99.9, bsz=40, num_updates=34240, lr=2.94849e-05, gnorm=0.847, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=106509
2022-09-30 02:18:15 - progress_bar.py[line:274] - INFO: epoch 003:   2737 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=34250, lr=2.94783e-05, gnorm=0.901, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=106520
2022-09-30 02:18:27 - progress_bar.py[line:274] - INFO: epoch 003:   2747 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=85.9, ups=0.86, wpb=100.4, bsz=40, num_updates=34260, lr=2.94717e-05, gnorm=0.831, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=106532
2022-09-30 02:18:38 - progress_bar.py[line:274] - INFO: epoch 003:   2757 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.89, wpb=102.5, bsz=40, num_updates=34270, lr=2.94651e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=106543
2022-09-30 02:18:49 - progress_bar.py[line:274] - INFO: epoch 003:   2767 / 15783 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.7, ups=0.89, wpb=102.9, bsz=40, num_updates=34280, lr=2.94585e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106554
2022-09-30 02:19:00 - progress_bar.py[line:274] - INFO: epoch 003:   2777 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.8, ups=0.9, wpb=102.1, bsz=40, num_updates=34290, lr=2.94519e-05, gnorm=0.759, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106565
2022-09-30 02:19:11 - progress_bar.py[line:274] - INFO: epoch 003:   2787 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.1, ups=0.91, wpb=102, bsz=40, num_updates=34300, lr=2.94453e-05, gnorm=0.888, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=106576
2022-09-30 02:19:23 - progress_bar.py[line:274] - INFO: epoch 003:   2797 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=87.6, ups=0.87, wpb=100.8, bsz=40, num_updates=34310, lr=2.94387e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106588
2022-09-30 02:19:35 - progress_bar.py[line:274] - INFO: epoch 003:   2807 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=85.7, ups=0.85, wpb=100.6, bsz=40, num_updates=34320, lr=2.94321e-05, gnorm=0.878, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=106599
2022-09-30 02:19:47 - progress_bar.py[line:274] - INFO: epoch 003:   2817 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=79.3, ups=0.79, wpb=100.4, bsz=40, num_updates=34330, lr=2.94255e-05, gnorm=0.767, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=106612
2022-09-30 02:20:00 - progress_bar.py[line:274] - INFO: epoch 003:   2827 / 15783 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=82.7, ups=0.82, wpb=101.3, bsz=40, num_updates=34340, lr=2.94189e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=106624
2022-09-30 02:20:11 - progress_bar.py[line:274] - INFO: epoch 003:   2837 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.9, wpb=100.3, bsz=40, num_updates=34350, lr=2.94123e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106636
2022-09-30 02:20:22 - progress_bar.py[line:274] - INFO: epoch 003:   2847 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.3, ups=0.87, wpb=99.8, bsz=40, num_updates=34360, lr=2.94057e-05, gnorm=1.008, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=106647
2022-09-30 02:20:34 - progress_bar.py[line:274] - INFO: epoch 003:   2857 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.2, ups=0.87, wpb=101.1, bsz=40, num_updates=34370, lr=2.93991e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106658
2022-09-30 02:20:45 - progress_bar.py[line:274] - INFO: epoch 003:   2867 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.9, ups=0.87, wpb=99.8, bsz=40, num_updates=34380, lr=2.93925e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106670
2022-09-30 02:20:56 - progress_bar.py[line:274] - INFO: epoch 003:   2877 / 15783 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.4, ups=0.89, wpb=101.9, bsz=40, num_updates=34390, lr=2.93859e-05, gnorm=0.741, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106681
2022-09-30 02:21:08 - progress_bar.py[line:274] - INFO: epoch 003:   2887 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=85.7, ups=0.86, wpb=100.1, bsz=40, num_updates=34400, lr=2.93793e-05, gnorm=1.05, clip=40, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=106693
2022-09-30 02:21:19 - progress_bar.py[line:274] - INFO: epoch 003:   2897 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.91, wpb=100.3, bsz=40, num_updates=34410, lr=2.93727e-05, gnorm=0.866, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=106704
2022-09-30 02:21:30 - progress_bar.py[line:274] - INFO: epoch 003:   2907 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.8, ups=0.89, wpb=101.2, bsz=40, num_updates=34420, lr=2.93661e-05, gnorm=0.914, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106715
2022-09-30 02:21:42 - progress_bar.py[line:274] - INFO: epoch 003:   2917 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.7, ups=0.89, wpb=99.9, bsz=40, num_updates=34430, lr=2.93595e-05, gnorm=0.854, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106726
2022-09-30 02:21:53 - progress_bar.py[line:274] - INFO: epoch 003:   2927 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.7, ups=0.88, wpb=100.9, bsz=40, num_updates=34440, lr=2.93529e-05, gnorm=0.854, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106738
2022-09-30 02:22:04 - progress_bar.py[line:274] - INFO: epoch 003:   2937 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.9, ups=0.88, wpb=101.5, bsz=40, num_updates=34450, lr=2.93463e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106749
2022-09-30 02:22:15 - progress_bar.py[line:274] - INFO: epoch 003:   2947 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.8, ups=0.91, wpb=101.7, bsz=40, num_updates=34460, lr=2.93397e-05, gnorm=0.939, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106760
2022-09-30 02:22:27 - progress_bar.py[line:274] - INFO: epoch 003:   2957 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.2, ups=0.88, wpb=100.8, bsz=40, num_updates=34470, lr=2.93331e-05, gnorm=0.925, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=106772
2022-09-30 02:22:38 - progress_bar.py[line:274] - INFO: epoch 003:   2967 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.9, ups=0.87, wpb=102.6, bsz=40, num_updates=34480, lr=2.93265e-05, gnorm=0.794, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=106783
2022-09-30 02:22:50 - progress_bar.py[line:274] - INFO: epoch 003:   2977 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.9, ups=0.88, wpb=102.4, bsz=40, num_updates=34490, lr=2.93199e-05, gnorm=0.817, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106794
2022-09-30 02:23:01 - progress_bar.py[line:274] - INFO: epoch 003:   2987 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.4, ups=0.88, wpb=100.5, bsz=40, num_updates=34500, lr=2.93133e-05, gnorm=0.814, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106806
2022-09-30 02:23:12 - progress_bar.py[line:274] - INFO: epoch 003:   2997 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.3, ups=0.88, wpb=101.5, bsz=40, num_updates=34510, lr=2.93067e-05, gnorm=0.79, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106817
2022-09-30 02:23:24 - progress_bar.py[line:274] - INFO: epoch 003:   3007 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=104.2, nsentences=40, sample_size=104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.6, ups=0.89, wpb=104.2, bsz=40, num_updates=34520, lr=2.93001e-05, gnorm=0.845, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=106828
2022-09-30 02:23:35 - progress_bar.py[line:274] - INFO: epoch 003:   3017 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90, ups=0.88, wpb=102.4, bsz=40, num_updates=34530, lr=2.92935e-05, gnorm=1.003, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=106840
2022-09-30 02:23:47 - progress_bar.py[line:274] - INFO: epoch 003:   3027 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=85.7, ups=0.86, wpb=100, bsz=40, num_updates=34540, lr=2.92869e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=106852
2022-09-30 02:23:58 - progress_bar.py[line:274] - INFO: epoch 003:   3037 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.2, ups=0.88, wpb=101.4, bsz=40, num_updates=34550, lr=2.92803e-05, gnorm=0.819, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106863
2022-09-30 02:24:09 - progress_bar.py[line:274] - INFO: epoch 003:   3047 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.91, wpb=101.8, bsz=40, num_updates=34560, lr=2.92737e-05, gnorm=0.827, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=106874
2022-09-30 02:24:20 - progress_bar.py[line:274] - INFO: epoch 003:   3057 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.1, ups=0.92, wpb=100.6, bsz=40, num_updates=34570, lr=2.92671e-05, gnorm=0.912, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106885
2022-09-30 02:24:31 - progress_bar.py[line:274] - INFO: epoch 003:   3067 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.2, ups=0.89, wpb=100.4, bsz=40, num_updates=34580, lr=2.92605e-05, gnorm=1.011, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=106896
2022-09-30 02:24:42 - progress_bar.py[line:274] - INFO: epoch 003:   3077 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.9, wpb=100.9, bsz=40, num_updates=34590, lr=2.9254e-05, gnorm=0.887, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=106907
2022-09-30 02:24:53 - progress_bar.py[line:274] - INFO: epoch 003:   3087 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.2, ups=0.92, wpb=99.6, bsz=40, num_updates=34600, lr=2.92474e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106918
2022-09-30 02:25:05 - progress_bar.py[line:274] - INFO: epoch 003:   3097 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.6, ups=0.88, wpb=100.5, bsz=40, num_updates=34610, lr=2.92408e-05, gnorm=0.814, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=106929
2022-09-30 02:25:16 - progress_bar.py[line:274] - INFO: epoch 003:   3107 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.4, ups=0.89, wpb=100, bsz=40, num_updates=34620, lr=2.92342e-05, gnorm=0.862, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=106941
2022-09-30 02:25:27 - progress_bar.py[line:274] - INFO: epoch 003:   3117 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.1, ups=0.89, wpb=100.1, bsz=40, num_updates=34630, lr=2.92276e-05, gnorm=0.861, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=106952
2022-09-30 02:25:40 - progress_bar.py[line:274] - INFO: epoch 003:   3127 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=81.7, ups=0.8, wpb=101.5, bsz=40, num_updates=34640, lr=2.9221e-05, gnorm=0.814, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=106964
2022-09-30 02:25:52 - progress_bar.py[line:274] - INFO: epoch 003:   3137 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=85.5, ups=0.83, wpb=102.5, bsz=40, num_updates=34650, lr=2.92144e-05, gnorm=0.915, clip=30, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=106977
2022-09-30 02:26:03 - progress_bar.py[line:274] - INFO: epoch 003:   3147 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.4, ups=0.91, wpb=101.5, bsz=40, num_updates=34660, lr=2.92078e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=106988
2022-09-30 02:26:14 - progress_bar.py[line:274] - INFO: epoch 003:   3157 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.6, ups=0.88, wpb=100.8, bsz=40, num_updates=34670, lr=2.92012e-05, gnorm=0.828, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=106999
2022-09-30 02:26:25 - progress_bar.py[line:274] - INFO: epoch 003:   3167 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.2, ups=0.91, wpb=102.2, bsz=40, num_updates=34680, lr=2.91946e-05, gnorm=0.949, clip=30, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=107010
2022-09-30 02:26:37 - progress_bar.py[line:274] - INFO: epoch 003:   3177 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.2, ups=0.88, wpb=100.4, bsz=40, num_updates=34690, lr=2.9188e-05, gnorm=0.954, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107021
2022-09-30 02:26:47 - progress_bar.py[line:274] - INFO: epoch 003:   3187 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.6, ups=0.94, wpb=99.8, bsz=40, num_updates=34700, lr=2.91814e-05, gnorm=0.831, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107032
2022-09-30 02:26:58 - progress_bar.py[line:274] - INFO: epoch 003:   3197 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.9, wpb=100.2, bsz=40, num_updates=34710, lr=2.91748e-05, gnorm=1.065, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=107043
2022-09-30 02:27:09 - progress_bar.py[line:274] - INFO: epoch 003:   3207 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94, ups=0.92, wpb=102.6, bsz=40, num_updates=34720, lr=2.91682e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=107054
2022-09-30 02:27:20 - progress_bar.py[line:274] - INFO: epoch 003:   3217 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.9, ups=0.9, wpb=101.4, bsz=40, num_updates=34730, lr=2.91616e-05, gnorm=0.862, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107065
2022-09-30 02:27:32 - progress_bar.py[line:274] - INFO: epoch 003:   3227 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.9, ups=0.88, wpb=101.1, bsz=40, num_updates=34740, lr=2.9155e-05, gnorm=0.797, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=107077
2022-09-30 02:27:43 - progress_bar.py[line:274] - INFO: epoch 003:   3237 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.7, ups=0.89, wpb=101.2, bsz=40, num_updates=34750, lr=2.91484e-05, gnorm=0.873, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107088
2022-09-30 02:27:54 - progress_bar.py[line:274] - INFO: epoch 003:   3247 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.5, ups=0.9, wpb=100.7, bsz=40, num_updates=34760, lr=2.91418e-05, gnorm=0.884, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=107099
2022-09-30 02:28:05 - progress_bar.py[line:274] - INFO: epoch 003:   3257 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.6, ups=0.89, wpb=99.2, bsz=40, num_updates=34770, lr=2.91352e-05, gnorm=0.924, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107110
2022-09-30 02:28:17 - progress_bar.py[line:274] - INFO: epoch 003:   3267 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.5, ups=0.87, wpb=102.2, bsz=40, num_updates=34780, lr=2.91286e-05, gnorm=0.921, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107122
2022-09-30 02:28:28 - progress_bar.py[line:274] - INFO: epoch 003:   3277 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.6, ups=0.9, wpb=101.4, bsz=40, num_updates=34790, lr=2.9122e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107133
2022-09-30 02:28:39 - progress_bar.py[line:274] - INFO: epoch 003:   3287 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.9, wpb=101.6, bsz=40, num_updates=34800, lr=2.91154e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107144
2022-09-30 02:28:50 - progress_bar.py[line:274] - INFO: epoch 003:   3297 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.5, ups=0.92, wpb=102.1, bsz=40, num_updates=34810, lr=2.91088e-05, gnorm=0.715, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107155
2022-09-30 02:29:01 - progress_bar.py[line:274] - INFO: epoch 003:   3307 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.5, ups=0.92, wpb=102.1, bsz=40, num_updates=34820, lr=2.91022e-05, gnorm=0.934, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107166
2022-09-30 02:29:12 - progress_bar.py[line:274] - INFO: epoch 003:   3317 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=90.5, ups=0.89, wpb=101.9, bsz=40, num_updates=34830, lr=2.90956e-05, gnorm=1.022, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107177
2022-09-30 02:29:24 - progress_bar.py[line:274] - INFO: epoch 003:   3327 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.7, ups=0.88, wpb=102.4, bsz=40, num_updates=34840, lr=2.9089e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107188
2022-09-30 02:29:35 - progress_bar.py[line:274] - INFO: epoch 003:   3337 / 15783 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.6, ups=0.9, wpb=102, bsz=40, num_updates=34850, lr=2.90824e-05, gnorm=0.809, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107200
2022-09-30 02:29:46 - progress_bar.py[line:274] - INFO: epoch 003:   3347 / 15783 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.9, ups=0.88, wpb=102.6, bsz=40, num_updates=34860, lr=2.90758e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=107211
2022-09-30 02:29:57 - progress_bar.py[line:274] - INFO: epoch 003:   3357 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92, ups=0.91, wpb=101, bsz=40, num_updates=34870, lr=2.90692e-05, gnorm=0.777, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107222
2022-09-30 02:30:09 - progress_bar.py[line:274] - INFO: epoch 003:   3367 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.1, ups=0.88, wpb=102.7, bsz=40, num_updates=34880, lr=2.90626e-05, gnorm=0.773, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=107233
2022-09-30 02:30:20 - progress_bar.py[line:274] - INFO: epoch 003:   3377 / 15783 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=91.5, ups=0.9, wpb=101.5, bsz=40, num_updates=34890, lr=2.9056e-05, gnorm=0.822, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=107245
2022-09-30 02:30:31 - progress_bar.py[line:274] - INFO: epoch 003:   3387 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.8, ups=0.91, wpb=100.8, bsz=40, num_updates=34900, lr=2.90494e-05, gnorm=0.823, clip=10, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=107256
2022-09-30 02:30:41 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 02:30:43 - progress_bar.py[line:274] - INFO: epoch 003:   3398 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=81.9, ups=0.8, wpb=101.8, bsz=40, num_updates=34910, lr=2.90428e-05, gnorm=0.832, clip=30, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=107268
2022-09-30 02:30:54 - progress_bar.py[line:274] - INFO: epoch 003:   3408 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.9, ups=0.91, wpb=103, bsz=40, num_updates=34920, lr=2.90362e-05, gnorm=0.814, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107279
2022-09-30 02:31:06 - progress_bar.py[line:274] - INFO: epoch 003:   3418 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=83.6, ups=0.82, wpb=101.6, bsz=40, num_updates=34930, lr=2.90296e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=107291
2022-09-30 02:31:19 - progress_bar.py[line:274] - INFO: epoch 003:   3428 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=79.9, ups=0.8, wpb=99.5, bsz=40, num_updates=34940, lr=2.9023e-05, gnorm=0.781, clip=20, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=107304
2022-09-30 02:31:30 - progress_bar.py[line:274] - INFO: epoch 003:   3438 / 15783 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=87.8, ups=0.86, wpb=101.8, bsz=40, num_updates=34950, lr=2.90164e-05, gnorm=0.798, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=107315
2022-09-30 02:31:42 - progress_bar.py[line:274] - INFO: epoch 003:   3448 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=34960, lr=2.90098e-05, gnorm=0.879, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107326
2022-09-30 02:31:53 - progress_bar.py[line:274] - INFO: epoch 003:   3458 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.7, ups=0.9, wpb=100.6, bsz=40, num_updates=34970, lr=2.90032e-05, gnorm=0.802, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107337
2022-09-30 02:32:04 - progress_bar.py[line:274] - INFO: epoch 003:   3468 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.2, ups=0.9, wpb=102, bsz=40, num_updates=34980, lr=2.89966e-05, gnorm=0.918, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=107349
2022-09-30 02:32:15 - progress_bar.py[line:274] - INFO: epoch 003:   3478 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.2, ups=0.88, wpb=102.7, bsz=40, num_updates=34990, lr=2.899e-05, gnorm=0.964, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107360
2022-09-30 02:32:26 - progress_bar.py[line:274] - INFO: epoch 003:   3488 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.89, wpb=100.5, bsz=40, num_updates=35000, lr=2.89834e-05, gnorm=0.922, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107371
2022-09-30 02:32:38 - progress_bar.py[line:274] - INFO: epoch 003:   3498 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.6, ups=0.87, wpb=101.3, bsz=40, num_updates=35010, lr=2.89768e-05, gnorm=0.883, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107383
2022-09-30 02:32:49 - progress_bar.py[line:274] - INFO: epoch 003:   3508 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.9, ups=0.9, wpb=102.2, bsz=40, num_updates=35020, lr=2.89702e-05, gnorm=0.825, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107394
2022-09-30 02:33:00 - progress_bar.py[line:274] - INFO: epoch 003:   3518 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.8, ups=0.88, wpb=101.2, bsz=40, num_updates=35030, lr=2.89636e-05, gnorm=0.863, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107405
2022-09-30 02:33:11 - progress_bar.py[line:274] - INFO: epoch 003:   3528 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.9, wpb=100.6, bsz=40, num_updates=35040, lr=2.8957e-05, gnorm=0.926, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107416
2022-09-30 02:33:23 - progress_bar.py[line:274] - INFO: epoch 003:   3538 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.6, ups=0.87, wpb=101.7, bsz=40, num_updates=35050, lr=2.89504e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107428
2022-09-30 02:33:34 - progress_bar.py[line:274] - INFO: epoch 003:   3548 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.9, ups=0.91, wpb=100.5, bsz=40, num_updates=35060, lr=2.89438e-05, gnorm=0.79, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107439
2022-09-30 02:33:45 - progress_bar.py[line:274] - INFO: epoch 003:   3558 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.1, ups=0.92, wpb=100.9, bsz=40, num_updates=35070, lr=2.89372e-05, gnorm=0.911, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=107449
2022-09-30 02:33:56 - progress_bar.py[line:274] - INFO: epoch 003:   3568 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.6, ups=0.88, wpb=101.8, bsz=40, num_updates=35080, lr=2.89306e-05, gnorm=0.903, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107461
2022-09-30 02:34:08 - progress_bar.py[line:274] - INFO: epoch 003:   3578 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.3, ups=0.86, wpb=102.1, bsz=40, num_updates=35090, lr=2.8924e-05, gnorm=0.885, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107472
2022-09-30 02:34:19 - progress_bar.py[line:274] - INFO: epoch 003:   3588 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.91, wpb=100.3, bsz=40, num_updates=35100, lr=2.89174e-05, gnorm=0.951, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107483
2022-09-30 02:34:30 - progress_bar.py[line:274] - INFO: epoch 003:   3598 / 15783 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.4, ups=0.91, wpb=103.6, bsz=40, num_updates=35110, lr=2.89108e-05, gnorm=0.948, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=107494
2022-09-30 02:34:41 - progress_bar.py[line:274] - INFO: epoch 003:   3608 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.3, ups=0.9, wpb=102.3, bsz=40, num_updates=35120, lr=2.89042e-05, gnorm=0.889, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107505
2022-09-30 02:34:52 - progress_bar.py[line:274] - INFO: epoch 003:   3618 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.7, ups=0.91, wpb=102.3, bsz=40, num_updates=35130, lr=2.88976e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107516
2022-09-30 02:35:03 - progress_bar.py[line:274] - INFO: epoch 003:   3628 / 15783 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=93.8, ups=0.91, wpb=102.7, bsz=40, num_updates=35140, lr=2.8891e-05, gnorm=0.826, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=107527
2022-09-30 02:35:13 - progress_bar.py[line:274] - INFO: epoch 003:   3638 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.3, ups=0.94, wpb=101.4, bsz=40, num_updates=35150, lr=2.88844e-05, gnorm=0.912, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107538
2022-09-30 02:35:24 - progress_bar.py[line:274] - INFO: epoch 003:   3648 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.92, wpb=99.5, bsz=40, num_updates=35160, lr=2.88778e-05, gnorm=0.928, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107549
2022-09-30 02:35:35 - progress_bar.py[line:274] - INFO: epoch 003:   3658 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.6, ups=0.89, wpb=101.8, bsz=40, num_updates=35170, lr=2.88712e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=107560
2022-09-30 02:35:46 - progress_bar.py[line:274] - INFO: epoch 003:   3668 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.1, ups=0.91, wpb=101.6, bsz=40, num_updates=35180, lr=2.88646e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107571
2022-09-30 02:35:58 - progress_bar.py[line:274] - INFO: epoch 003:   3678 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.8, ups=0.89, wpb=102.9, bsz=40, num_updates=35190, lr=2.8858e-05, gnorm=0.816, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=107582
2022-09-30 02:36:09 - progress_bar.py[line:274] - INFO: epoch 003:   3688 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.3, ups=0.91, wpb=101.7, bsz=40, num_updates=35200, lr=2.88514e-05, gnorm=0.82, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107594
2022-09-30 02:36:20 - progress_bar.py[line:274] - INFO: epoch 003:   3698 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.88, wpb=101.6, bsz=40, num_updates=35210, lr=2.88448e-05, gnorm=0.812, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107605
2022-09-30 02:36:31 - progress_bar.py[line:274] - INFO: epoch 003:   3708 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=35220, lr=2.88382e-05, gnorm=0.748, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107616
2022-09-30 02:36:43 - progress_bar.py[line:274] - INFO: epoch 003:   3718 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.88, wpb=100.9, bsz=40, num_updates=35230, lr=2.88316e-05, gnorm=0.958, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107628
2022-09-30 02:36:54 - progress_bar.py[line:274] - INFO: epoch 003:   3728 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.7, ups=0.88, wpb=101, bsz=40, num_updates=35240, lr=2.8825e-05, gnorm=0.777, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107639
2022-09-30 02:37:05 - progress_bar.py[line:274] - INFO: epoch 003:   3738 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.7, ups=0.91, wpb=101.7, bsz=40, num_updates=35250, lr=2.88184e-05, gnorm=0.904, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107650
2022-09-30 02:37:16 - progress_bar.py[line:274] - INFO: epoch 003:   3748 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.7, ups=0.91, wpb=101.2, bsz=40, num_updates=35260, lr=2.88118e-05, gnorm=0.961, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107661
2022-09-30 02:37:28 - progress_bar.py[line:274] - INFO: epoch 003:   3758 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.6, ups=0.87, wpb=102, bsz=40, num_updates=35270, lr=2.88052e-05, gnorm=0.813, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107672
2022-09-30 02:37:39 - progress_bar.py[line:274] - INFO: epoch 003:   3768 / 15783 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=35280, lr=2.87986e-05, gnorm=0.818, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=107684
2022-09-30 02:37:50 - progress_bar.py[line:274] - INFO: epoch 003:   3778 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.6, ups=0.88, wpb=100.9, bsz=40, num_updates=35290, lr=2.8792e-05, gnorm=0.827, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107695
2022-09-30 02:38:02 - progress_bar.py[line:274] - INFO: epoch 003:   3788 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.4, ups=0.88, wpb=101.6, bsz=40, num_updates=35300, lr=2.87854e-05, gnorm=1.03, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107706
2022-09-30 02:38:12 - progress_bar.py[line:274] - INFO: epoch 003:   3798 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.92, wpb=100.8, bsz=40, num_updates=35310, lr=2.87788e-05, gnorm=0.802, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107717
2022-09-30 02:38:24 - progress_bar.py[line:274] - INFO: epoch 003:   3808 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.9, ups=0.88, wpb=101.7, bsz=40, num_updates=35320, lr=2.87722e-05, gnorm=0.802, clip=10, loss_scale=1024, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=107729
2022-09-30 02:38:35 - progress_bar.py[line:274] - INFO: epoch 003:   3818 / 15783 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=88.9, ups=0.88, wpb=101.4, bsz=40, num_updates=35330, lr=2.87656e-05, gnorm=0.837, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=107740
2022-09-30 02:38:47 - progress_bar.py[line:274] - INFO: epoch 003:   3828 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.8, ups=0.88, wpb=100.2, bsz=40, num_updates=35340, lr=2.8759e-05, gnorm=0.937, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107751
2022-09-30 02:38:58 - progress_bar.py[line:274] - INFO: epoch 003:   3838 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.4, ups=0.89, wpb=100.7, bsz=40, num_updates=35350, lr=2.87524e-05, gnorm=0.932, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107763
2022-09-30 02:39:09 - progress_bar.py[line:274] - INFO: epoch 003:   3848 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.6, ups=0.88, wpb=101.6, bsz=40, num_updates=35360, lr=2.87458e-05, gnorm=0.829, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107774
2022-09-30 02:39:20 - progress_bar.py[line:274] - INFO: epoch 003:   3858 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.6, ups=0.89, wpb=99.6, bsz=40, num_updates=35370, lr=2.87392e-05, gnorm=0.829, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107785
2022-09-30 02:39:32 - progress_bar.py[line:274] - INFO: epoch 003:   3868 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.2, ups=0.89, wpb=101.5, bsz=40, num_updates=35380, lr=2.87326e-05, gnorm=0.811, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107797
2022-09-30 02:39:43 - progress_bar.py[line:274] - INFO: epoch 003:   3878 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.5, ups=0.9, wpb=100.6, bsz=40, num_updates=35390, lr=2.8726e-05, gnorm=0.967, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107808
2022-09-30 02:39:54 - progress_bar.py[line:274] - INFO: epoch 003:   3888 / 15783 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=89.1, ups=0.87, wpb=102.8, bsz=40, num_updates=35400, lr=2.87194e-05, gnorm=0.875, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107819
2022-09-30 02:40:05 - progress_bar.py[line:274] - INFO: epoch 003:   3898 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.5, ups=0.92, wpb=100.2, bsz=40, num_updates=35410, lr=2.87128e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=107830
2022-09-30 02:40:17 - progress_bar.py[line:274] - INFO: epoch 003:   3908 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.1, ups=0.87, wpb=102.4, bsz=40, num_updates=35420, lr=2.87062e-05, gnorm=0.889, clip=30, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107842
2022-09-30 02:40:18 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 02:40:29 - progress_bar.py[line:274] - INFO: epoch 003:   3919 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=84.6, ups=0.84, wpb=101.1, bsz=40, num_updates=35430, lr=2.86996e-05, gnorm=0.908, clip=40, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=107854
2022-09-30 02:40:40 - progress_bar.py[line:274] - INFO: epoch 003:   3929 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.6, ups=0.87, wpb=100.2, bsz=40, num_updates=35440, lr=2.8693e-05, gnorm=0.834, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=107865
2022-09-30 02:40:51 - progress_bar.py[line:274] - INFO: epoch 003:   3939 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.1, ups=0.9, wpb=101.3, bsz=40, num_updates=35450, lr=2.86864e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=107876
2022-09-30 02:41:03 - progress_bar.py[line:274] - INFO: epoch 003:   3949 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.8, ups=0.88, wpb=101.1, bsz=40, num_updates=35460, lr=2.86798e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107887
2022-09-30 02:41:14 - progress_bar.py[line:274] - INFO: epoch 003:   3959 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.89, wpb=102, bsz=40, num_updates=35470, lr=2.86732e-05, gnorm=0.907, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107899
2022-09-30 02:41:25 - progress_bar.py[line:274] - INFO: epoch 003:   3969 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.89, wpb=102.8, bsz=40, num_updates=35480, lr=2.86666e-05, gnorm=0.881, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107910
2022-09-30 02:41:36 - progress_bar.py[line:274] - INFO: epoch 003:   3979 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89, ups=0.88, wpb=100.8, bsz=40, num_updates=35490, lr=2.866e-05, gnorm=0.779, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=107921
2022-09-30 02:41:47 - progress_bar.py[line:274] - INFO: epoch 003:   3989 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.8, ups=0.92, wpb=100.6, bsz=40, num_updates=35500, lr=2.86534e-05, gnorm=0.874, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107932
2022-09-30 02:41:58 - progress_bar.py[line:274] - INFO: epoch 003:   3999 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=35510, lr=2.86468e-05, gnorm=0.946, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107943
2022-09-30 02:42:10 - progress_bar.py[line:274] - INFO: epoch 003:   4009 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.9, ups=0.87, wpb=102.3, bsz=40, num_updates=35520, lr=2.86402e-05, gnorm=0.754, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107955
2022-09-30 02:42:22 - progress_bar.py[line:274] - INFO: epoch 003:   4019 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=82, ups=0.81, wpb=101.4, bsz=40, num_updates=35530, lr=2.86336e-05, gnorm=0.873, clip=30, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=107967
2022-09-30 02:42:33 - progress_bar.py[line:274] - INFO: epoch 003:   4029 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.9, ups=0.9, wpb=101.9, bsz=40, num_updates=35540, lr=2.8627e-05, gnorm=0.882, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107978
2022-09-30 02:42:45 - progress_bar.py[line:274] - INFO: epoch 003:   4039 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.89, wpb=100.7, bsz=40, num_updates=35550, lr=2.86204e-05, gnorm=0.652, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107990
2022-09-30 02:42:56 - progress_bar.py[line:274] - INFO: epoch 003:   4049 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.88, wpb=101.7, bsz=40, num_updates=35560, lr=2.86138e-05, gnorm=0.725, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108001
2022-09-30 02:43:07 - progress_bar.py[line:274] - INFO: epoch 003:   4059 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.87, wpb=102.5, bsz=40, num_updates=35570, lr=2.86072e-05, gnorm=0.817, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108012
2022-09-30 02:43:19 - progress_bar.py[line:274] - INFO: epoch 003:   4069 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.9, ups=0.89, wpb=101.1, bsz=40, num_updates=35580, lr=2.86006e-05, gnorm=0.757, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108024
2022-09-30 02:43:30 - progress_bar.py[line:274] - INFO: epoch 003:   4079 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.9, ups=0.88, wpb=102, bsz=40, num_updates=35590, lr=2.8594e-05, gnorm=0.819, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=108035
2022-09-30 02:43:41 - progress_bar.py[line:274] - INFO: epoch 003:   4089 / 15783 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.4, ups=0.9, wpb=102.5, bsz=40, num_updates=35600, lr=2.85874e-05, gnorm=0.846, clip=30, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=108046
2022-09-30 02:43:52 - progress_bar.py[line:274] - INFO: epoch 003:   4099 / 15783 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=92.6, ups=0.89, wpb=104.4, bsz=40, num_updates=35610, lr=2.85808e-05, gnorm=0.752, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108057
2022-09-30 02:44:04 - progress_bar.py[line:274] - INFO: epoch 003:   4109 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=35620, lr=2.85742e-05, gnorm=0.932, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108068
2022-09-30 02:44:15 - progress_bar.py[line:274] - INFO: epoch 003:   4119 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.89, wpb=101.1, bsz=40, num_updates=35630, lr=2.85676e-05, gnorm=0.838, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108080
2022-09-30 02:44:26 - progress_bar.py[line:274] - INFO: epoch 003:   4129 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.4, ups=0.9, wpb=101.3, bsz=40, num_updates=35640, lr=2.8561e-05, gnorm=0.799, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108091
2022-09-30 02:44:37 - progress_bar.py[line:274] - INFO: epoch 003:   4139 / 15783 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=98.3, nsentences=40, sample_size=98.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=86.3, ups=0.88, wpb=98.3, bsz=40, num_updates=35650, lr=2.85544e-05, gnorm=0.895, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108102
2022-09-30 02:44:49 - progress_bar.py[line:274] - INFO: epoch 003:   4149 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.5, ups=0.89, wpb=100.9, bsz=40, num_updates=35660, lr=2.85478e-05, gnorm=0.924, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108114
2022-09-30 02:45:00 - progress_bar.py[line:274] - INFO: epoch 003:   4159 / 15783 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.6, ups=0.9, wpb=100.5, bsz=40, num_updates=35670, lr=2.85412e-05, gnorm=0.765, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=108125
2022-09-30 02:45:11 - progress_bar.py[line:274] - INFO: epoch 003:   4169 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89, ups=0.89, wpb=100.1, bsz=40, num_updates=35680, lr=2.85346e-05, gnorm=1.005, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108136
2022-09-30 02:45:22 - progress_bar.py[line:274] - INFO: epoch 003:   4179 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.2, ups=0.89, wpb=99.2, bsz=40, num_updates=35690, lr=2.8528e-05, gnorm=0.87, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108147
2022-09-30 02:45:33 - progress_bar.py[line:274] - INFO: epoch 003:   4189 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95, ups=0.92, wpb=102.9, bsz=40, num_updates=35700, lr=2.85214e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108158
2022-09-30 02:45:44 - progress_bar.py[line:274] - INFO: epoch 003:   4199 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.9, wpb=101.7, bsz=40, num_updates=35710, lr=2.85148e-05, gnorm=0.878, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108169
2022-09-30 02:45:56 - progress_bar.py[line:274] - INFO: epoch 003:   4209 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.2, ups=0.88, wpb=100.5, bsz=40, num_updates=35720, lr=2.85082e-05, gnorm=1.027, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108180
2022-09-30 02:46:06 - progress_bar.py[line:274] - INFO: epoch 003:   4219 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.9, ups=0.92, wpb=101.8, bsz=40, num_updates=35730, lr=2.85016e-05, gnorm=0.9, clip=20, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=108191
2022-09-30 02:46:18 - progress_bar.py[line:274] - INFO: epoch 003:   4229 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.7, ups=0.89, wpb=101.9, bsz=40, num_updates=35740, lr=2.8495e-05, gnorm=0.833, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=108203
2022-09-30 02:46:28 - progress_bar.py[line:274] - INFO: epoch 003:   4239 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.6, ups=0.94, wpb=101.6, bsz=40, num_updates=35750, lr=2.84884e-05, gnorm=0.858, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108213
2022-09-30 02:46:39 - progress_bar.py[line:274] - INFO: epoch 003:   4249 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91, ups=0.9, wpb=101.2, bsz=40, num_updates=35760, lr=2.84818e-05, gnorm=0.914, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108224
2022-09-30 02:46:50 - progress_bar.py[line:274] - INFO: epoch 003:   4259 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.6, ups=0.91, wpb=101.4, bsz=40, num_updates=35770, lr=2.84752e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108235
2022-09-30 02:47:01 - progress_bar.py[line:274] - INFO: epoch 003:   4269 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.5, ups=0.92, wpb=99.2, bsz=40, num_updates=35780, lr=2.84686e-05, gnorm=0.879, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108246
2022-09-30 02:47:13 - progress_bar.py[line:274] - INFO: epoch 003:   4279 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.6, ups=0.88, wpb=100.5, bsz=40, num_updates=35790, lr=2.8462e-05, gnorm=0.883, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108257
2022-09-30 02:47:24 - progress_bar.py[line:274] - INFO: epoch 003:   4289 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89, ups=0.87, wpb=102.7, bsz=40, num_updates=35800, lr=2.84554e-05, gnorm=0.874, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=108269
2022-09-30 02:47:35 - progress_bar.py[line:274] - INFO: epoch 003:   4299 / 15783 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.4, ups=0.89, wpb=101.7, bsz=40, num_updates=35810, lr=2.84488e-05, gnorm=0.755, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=108280
2022-09-30 02:47:46 - progress_bar.py[line:274] - INFO: epoch 003:   4309 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.3, ups=0.92, wpb=102.9, bsz=40, num_updates=35820, lr=2.84422e-05, gnorm=0.866, clip=30, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=108291
2022-09-30 02:47:58 - progress_bar.py[line:274] - INFO: epoch 003:   4319 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.4, ups=0.87, wpb=101, bsz=40, num_updates=35830, lr=2.84356e-05, gnorm=0.881, clip=30, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=108303
2022-09-30 02:48:09 - progress_bar.py[line:274] - INFO: epoch 003:   4329 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.89, wpb=101.9, bsz=40, num_updates=35840, lr=2.8429e-05, gnorm=0.898, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108314
2022-09-30 02:48:20 - progress_bar.py[line:274] - INFO: epoch 003:   4339 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.4, ups=0.91, wpb=100.7, bsz=40, num_updates=35850, lr=2.84224e-05, gnorm=0.967, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108325
2022-09-30 02:48:31 - progress_bar.py[line:274] - INFO: epoch 003:   4349 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.6, ups=0.9, wpb=102.5, bsz=40, num_updates=35860, lr=2.84158e-05, gnorm=0.813, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108336
2022-09-30 02:48:43 - progress_bar.py[line:274] - INFO: epoch 003:   4359 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=83.9, ups=0.83, wpb=101.4, bsz=40, num_updates=35870, lr=2.84092e-05, gnorm=0.92, clip=20, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=108348
2022-09-30 02:48:55 - progress_bar.py[line:274] - INFO: epoch 003:   4369 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.7, ups=0.87, wpb=100.9, bsz=40, num_updates=35880, lr=2.84026e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108360
2022-09-30 02:49:06 - progress_bar.py[line:274] - INFO: epoch 003:   4379 / 15783 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=91.6, ups=0.9, wpb=101.7, bsz=40, num_updates=35890, lr=2.8396e-05, gnorm=0.752, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=108371
2022-09-30 02:49:17 - progress_bar.py[line:274] - INFO: epoch 003:   4389 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.2, ups=0.9, wpb=102.2, bsz=40, num_updates=35900, lr=2.83894e-05, gnorm=0.985, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108382
2022-09-30 02:49:28 - progress_bar.py[line:274] - INFO: epoch 003:   4399 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.9, ups=0.91, wpb=100.7, bsz=40, num_updates=35910, lr=2.83828e-05, gnorm=0.848, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=108393
2022-09-30 02:49:39 - progress_bar.py[line:274] - INFO: epoch 003:   4409 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.89, wpb=101.4, bsz=40, num_updates=35920, lr=2.83762e-05, gnorm=1.13, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108404
2022-09-30 02:49:51 - progress_bar.py[line:274] - INFO: epoch 003:   4419 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.5, ups=0.88, wpb=101.6, bsz=40, num_updates=35930, lr=2.83696e-05, gnorm=0.982, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108415
2022-09-30 02:50:01 - progress_bar.py[line:274] - INFO: epoch 003:   4429 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.93, wpb=98.9, bsz=40, num_updates=35940, lr=2.8363e-05, gnorm=0.974, clip=30, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108426
2022-09-30 02:50:13 - progress_bar.py[line:274] - INFO: epoch 003:   4439 / 15783 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90, ups=0.88, wpb=102.6, bsz=40, num_updates=35950, lr=2.83564e-05, gnorm=0.817, clip=20, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108438
2022-09-30 02:50:20 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 02:50:25 - progress_bar.py[line:274] - INFO: epoch 003:   4450 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=84.9, ups=0.83, wpb=102.7, bsz=40, num_updates=35960, lr=2.83498e-05, gnorm=0.824, clip=20, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=108450
2022-09-30 02:50:36 - progress_bar.py[line:274] - INFO: epoch 003:   4460 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.5, ups=0.91, wpb=102.5, bsz=40, num_updates=35970, lr=2.83432e-05, gnorm=0.803, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=108461
2022-09-30 02:50:47 - progress_bar.py[line:274] - INFO: epoch 003:   4470 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.9, wpb=101.2, bsz=40, num_updates=35980, lr=2.83366e-05, gnorm=0.931, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=108472
2022-09-30 02:50:58 - progress_bar.py[line:274] - INFO: epoch 003:   4480 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.89, wpb=100.6, bsz=40, num_updates=35990, lr=2.833e-05, gnorm=0.904, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=108483
2022-09-30 02:51:09 - progress_bar.py[line:274] - INFO: epoch 003:   4490 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.3, ups=0.93, wpb=101.2, bsz=40, num_updates=36000, lr=2.83234e-05, gnorm=1.025, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108494
2022-09-30 02:51:09 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-30 02:51:10 - train.py[line:549] - INFO: 0 / 14103
2022-09-30 02:51:10 - train.py[line:551] - INFO: load:0.77 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-30 02:51:11 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.04 GiB (GPU 1; 39.59 GiB total capacity; 11.63 GiB already allocated; 1.48 GiB free; 35.62 GiB reserved in total by PyTorch)
2022-09-30 02:51:11 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-30 02:51:11 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 31        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   11906 MB |   15160 MB |   14542 TB |   14542 TB |
|       from large pool |   11762 MB |   15015 MB |   14536 TB |   14536 TB |
|       from small pool |     144 MB |     145 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| Active memory         |   11906 MB |   15160 MB |   14542 TB |   14542 TB |
|       from large pool |   11762 MB |   15015 MB |   14536 TB |   14536 TB |
|       from small pool |     144 MB |     145 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36478 MB |   36578 MB |  338486 MB |  302008 MB |
|       from large pool |   36332 MB |   36332 MB |  337708 MB |  301376 MB |
|       from small pool |     146 MB |     246 MB |     778 MB |     632 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24571 MB |   27654 MB |   16603 TB |   16603 TB |
|       from large pool |   24569 MB |   27652 MB |   16596 TB |   16596 TB |
|       from small pool |       1 MB |       1 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3660    |    3684    |     765 M  |     765 M  |
|       from large pool |     564    |     585    |     227 M  |     227 M  |
|       from small pool |    3096    |    3114    |     537 M  |     537 M  |
|---------------------------------------------------------------------------|
| Active allocs         |    3660    |    3684    |     765 M  |     765 M  |
|       from large pool |     564    |     585    |     227 M  |     227 M  |
|       from small pool |    3096    |    3114    |     537 M  |     537 M  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     125    |     175    |     846    |     721    |
|       from large pool |      52    |      52    |     457    |     405    |
|       from small pool |      73    |     123    |     389    |     316    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      93    |      96    |  568435 K  |  568435 K  |
|       from large pool |      43    |      47    |  105110 K  |  105110 K  |
|       from small pool |      50    |      57    |  463325 K  |  463325 K  |
|===========================================================================|

2022-09-30 02:51:11 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-30 02:51:11 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.82 GiB (GPU 0; 39.59 GiB total capacity; 12.87 GiB already allocated; 1.94 GiB free; 35.17 GiB reserved in total by PyTorch)
2022-09-30 02:51:11 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 5            |        cudaMalloc retries: 37        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13180 MB |   16982 MB |   14470 TB |   14470 TB |
|       from large pool |   13036 MB |   16837 MB |   14464 TB |   14464 TB |
|       from small pool |     144 MB |     145 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13180 MB |   16982 MB |   14470 TB |   14470 TB |
|       from large pool |   13036 MB |   16837 MB |   14464 TB |   14464 TB |
|       from small pool |     144 MB |     145 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36012 MB |   37356 MB |  452700 MB |  416688 MB |
|       from large pool |   35866 MB |   37108 MB |  451900 MB |  416034 MB |
|       from small pool |     146 MB |     248 MB |     800 MB |     654 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22831 MB |   26373 MB |   17563 TB |   17563 TB |
|       from large pool |   22829 MB |   26371 MB |   17557 TB |   17557 TB |
|       from small pool |       1 MB |       1 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3660    |    3684    |     765 M  |     765 M  |
|       from large pool |     564    |     585    |     227 M  |     227 M  |
|       from small pool |    3096    |    3114    |     538 M  |     538 M  |
|---------------------------------------------------------------------------|
| Active allocs         |    3660    |    3684    |     765 M  |     765 M  |
|       from large pool |     564    |     585    |     227 M  |     227 M  |
|       from small pool |    3096    |    3114    |     538 M  |     538 M  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     118    |     172    |     934    |     816    |
|       from large pool |      45    |      48    |     534    |     489    |
|       from small pool |      73    |     124    |     400    |     327    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      76    |      78    |  566574 K  |  566574 K  |
|       from large pool |      36    |      38    |  106021 K  |  106021 K  |
|       from small pool |      40    |      47    |  460552 K  |  460552 K  |
|===========================================================================|

2022-09-30 02:51:11 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-30 02:51:11 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-30 02:54:28 - train.py[line:549] - INFO: 200 / 14103
2022-09-30 02:54:28 - train.py[line:551] - INFO: load:0.79 valid_run:197.93 task_valid:187.02 collect_output:8.25
2022-09-30 02:57:40 - train.py[line:549] - INFO: 400 / 14103
2022-09-30 02:57:40 - train.py[line:551] - INFO: load:0.82 valid_run:389.66 task_valid:372.20 collect_output:13.59
2022-09-30 03:00:50 - train.py[line:549] - INFO: 600 / 14103
2022-09-30 03:00:50 - train.py[line:551] - INFO: load:0.84 valid_run:579.48 task_valid:555.37 collect_output:19.16
2022-09-30 03:04:00 - train.py[line:549] - INFO: 800 / 14103
2022-09-30 03:04:00 - train.py[line:551] - INFO: load:0.86 valid_run:769.92 task_valid:740.96 collect_output:22.89
2022-09-30 03:07:11 - train.py[line:549] - INFO: 1000 / 14103
2022-09-30 03:07:11 - train.py[line:551] - INFO: load:0.89 valid_run:960.32 task_valid:926.19 collect_output:26.93
2022-09-30 03:10:25 - train.py[line:549] - INFO: 1200 / 14103
2022-09-30 03:10:25 - train.py[line:551] - INFO: load:0.91 valid_run:1154.38 task_valid:1113.76 collect_output:32.22
2022-09-30 03:13:42 - train.py[line:549] - INFO: 1400 / 14103
2022-09-30 03:13:42 - train.py[line:551] - INFO: load:0.93 valid_run:1351.64 task_valid:1305.74 collect_output:36.27
2022-09-30 03:16:56 - train.py[line:549] - INFO: 1600 / 14103
2022-09-30 03:16:56 - train.py[line:551] - INFO: load:0.96 valid_run:1545.66 task_valid:1495.29 collect_output:39.55
2022-09-30 03:20:11 - train.py[line:549] - INFO: 1800 / 14103
2022-09-30 03:20:11 - train.py[line:551] - INFO: load:0.98 valid_run:1740.93 task_valid:1682.49 collect_output:46.43
2022-09-30 03:23:22 - train.py[line:549] - INFO: 2000 / 14103
2022-09-30 03:23:22 - train.py[line:551] - INFO: load:1.01 valid_run:1931.03 task_valid:1868.66 collect_output:49.17
2022-09-30 03:26:31 - train.py[line:549] - INFO: 2200 / 14103
2022-09-30 03:26:31 - train.py[line:551] - INFO: load:1.03 valid_run:2120.82 task_valid:2053.76 collect_output:52.71
2022-09-30 03:29:44 - train.py[line:549] - INFO: 2400 / 14103
2022-09-30 03:29:44 - train.py[line:551] - INFO: load:1.05 valid_run:2313.20 task_valid:2238.83 collect_output:58.88
2022-09-30 03:32:57 - train.py[line:549] - INFO: 2600 / 14103
2022-09-30 03:32:57 - train.py[line:551] - INFO: load:1.08 valid_run:2506.60 task_valid:2428.16 collect_output:61.75
2022-09-30 03:36:08 - train.py[line:549] - INFO: 2800 / 14103
2022-09-30 03:36:08 - train.py[line:551] - INFO: load:1.10 valid_run:2696.78 task_valid:2612.42 collect_output:66.59
2022-09-30 03:39:21 - train.py[line:549] - INFO: 3000 / 14103
2022-09-30 03:39:21 - train.py[line:551] - INFO: load:1.12 valid_run:2890.08 task_valid:2798.38 collect_output:72.82
2022-09-30 03:42:31 - train.py[line:549] - INFO: 3200 / 14103
2022-09-30 03:42:31 - train.py[line:551] - INFO: load:1.14 valid_run:3080.04 task_valid:2981.14 collect_output:78.88
2022-09-30 03:45:47 - train.py[line:549] - INFO: 3400 / 14103
2022-09-30 03:45:47 - train.py[line:551] - INFO: load:1.17 valid_run:3275.58 task_valid:3166.72 collect_output:87.68
2022-09-30 03:49:00 - train.py[line:549] - INFO: 3600 / 14103
2022-09-30 03:49:00 - train.py[line:551] - INFO: load:1.20 valid_run:3468.90 task_valid:3352.58 collect_output:94.01
2022-09-30 03:52:14 - train.py[line:549] - INFO: 3800 / 14103
2022-09-30 03:52:14 - train.py[line:551] - INFO: load:1.22 valid_run:3662.67 task_valid:3537.57 collect_output:101.57
2022-09-30 03:55:23 - train.py[line:549] - INFO: 4000 / 14103
2022-09-30 03:55:23 - train.py[line:551] - INFO: load:1.24 valid_run:3851.70 task_valid:3720.91 collect_output:106.13
2022-09-30 03:58:38 - train.py[line:549] - INFO: 4200 / 14103
2022-09-30 03:58:38 - train.py[line:551] - INFO: load:1.27 valid_run:4046.64 task_valid:3911.73 collect_output:109.06
2022-09-30 04:01:47 - train.py[line:549] - INFO: 4400 / 14103
2022-09-30 04:01:47 - train.py[line:551] - INFO: load:1.29 valid_run:4235.28 task_valid:4092.35 collect_output:115.95
2022-09-30 04:04:59 - train.py[line:549] - INFO: 4600 / 14103
2022-09-30 04:04:59 - train.py[line:551] - INFO: load:1.31 valid_run:4427.65 task_valid:4277.22 collect_output:122.28
2022-09-30 04:08:12 - train.py[line:549] - INFO: 4800 / 14103
2022-09-30 04:08:12 - train.py[line:551] - INFO: load:1.34 valid_run:4620.19 task_valid:4463.71 collect_output:126.96
2022-09-30 04:11:25 - train.py[line:549] - INFO: 5000 / 14103
2022-09-30 04:11:25 - train.py[line:551] - INFO: load:1.37 valid_run:4813.47 task_valid:4650.51 collect_output:132.27
2022-09-30 04:14:35 - train.py[line:549] - INFO: 5200 / 14103
2022-09-30 04:14:35 - train.py[line:551] - INFO: load:1.39 valid_run:5003.14 task_valid:4833.99 collect_output:137.35
2022-09-30 04:17:47 - train.py[line:549] - INFO: 5400 / 14103
2022-09-30 04:17:47 - train.py[line:551] - INFO: load:1.42 valid_run:5195.69 task_valid:5022.97 collect_output:139.77
2022-09-30 04:20:59 - train.py[line:549] - INFO: 5600 / 14103
2022-09-30 04:20:59 - train.py[line:551] - INFO: load:1.44 valid_run:5387.72 task_valid:5210.27 collect_output:143.31
2022-09-30 04:24:13 - train.py[line:549] - INFO: 5800 / 14103
2022-09-30 04:24:13 - train.py[line:551] - INFO: load:1.46 valid_run:5581.77 task_valid:5397.37 collect_output:149.00
2022-09-30 04:27:24 - train.py[line:549] - INFO: 6000 / 14103
2022-09-30 04:27:24 - train.py[line:551] - INFO: load:1.49 valid_run:5771.79 task_valid:5579.69 collect_output:155.41
2022-09-30 04:30:36 - train.py[line:549] - INFO: 6200 / 14103
2022-09-30 04:30:36 - train.py[line:551] - INFO: load:1.51 valid_run:5964.24 task_valid:5765.65 collect_output:160.74
2022-09-30 04:33:47 - train.py[line:549] - INFO: 6400 / 14103
2022-09-30 04:33:47 - train.py[line:551] - INFO: load:1.54 valid_run:6155.33 task_valid:5951.70 collect_output:164.54
2022-09-30 04:37:00 - train.py[line:549] - INFO: 6600 / 14103
2022-09-30 04:37:00 - train.py[line:551] - INFO: load:1.56 valid_run:6347.66 task_valid:6134.24 collect_output:173.00
2022-09-30 04:40:13 - train.py[line:549] - INFO: 6800 / 14103
2022-09-30 04:40:13 - train.py[line:551] - INFO: load:1.58 valid_run:6540.68 task_valid:6318.30 collect_output:180.76
2022-09-30 04:43:26 - train.py[line:549] - INFO: 7000 / 14103
2022-09-30 04:43:26 - train.py[line:551] - INFO: load:1.61 valid_run:6734.35 task_valid:6507.50 collect_output:184.07
2022-09-30 04:46:44 - train.py[line:549] - INFO: 7200 / 14103
2022-09-30 04:46:44 - train.py[line:551] - INFO: load:1.64 valid_run:6932.27 task_valid:6699.93 collect_output:188.16
2022-09-30 04:49:55 - train.py[line:549] - INFO: 7400 / 14103
2022-09-30 04:49:55 - train.py[line:551] - INFO: load:1.66 valid_run:7123.23 task_valid:6881.71 collect_output:196.24
2022-09-30 04:53:05 - train.py[line:549] - INFO: 7600 / 14103
2022-09-30 04:53:05 - train.py[line:551] - INFO: load:1.68 valid_run:7312.74 task_valid:7062.14 collect_output:204.21
2022-09-30 04:56:20 - train.py[line:549] - INFO: 7800 / 14103
2022-09-30 04:56:20 - train.py[line:551] - INFO: load:1.71 valid_run:7507.39 task_valid:7248.89 collect_output:211.00
2022-09-30 04:59:30 - train.py[line:549] - INFO: 8000 / 14103
2022-09-30 04:59:30 - train.py[line:551] - INFO: load:1.73 valid_run:7697.19 task_valid:7427.94 collect_output:220.68
2022-09-30 05:02:39 - train.py[line:549] - INFO: 8200 / 14103
2022-09-30 05:02:39 - train.py[line:551] - INFO: load:1.75 valid_run:7886.33 task_valid:7611.35 collect_output:225.26
2022-09-30 05:05:50 - train.py[line:549] - INFO: 8400 / 14103
2022-09-30 05:05:50 - train.py[line:551] - INFO: load:1.77 valid_run:8077.05 task_valid:7794.76 collect_output:231.41
2022-09-30 05:09:00 - train.py[line:549] - INFO: 8600 / 14103
2022-09-30 05:09:00 - train.py[line:551] - INFO: load:1.80 valid_run:8267.82 task_valid:7978.92 collect_output:236.94
2022-09-30 05:12:15 - train.py[line:549] - INFO: 8800 / 14103
2022-09-30 05:12:15 - train.py[line:551] - INFO: load:1.83 valid_run:8462.83 task_valid:8169.19 collect_output:240.34
2022-09-30 05:15:28 - train.py[line:549] - INFO: 9000 / 14103
2022-09-30 05:15:28 - train.py[line:551] - INFO: load:1.86 valid_run:8655.62 task_valid:8354.03 collect_output:247.12
2022-09-30 05:18:43 - train.py[line:549] - INFO: 9200 / 14103
2022-09-30 05:18:43 - train.py[line:551] - INFO: load:1.88 valid_run:8849.98 task_valid:8536.64 collect_output:257.78
2022-09-30 05:21:56 - train.py[line:549] - INFO: 9400 / 14103
2022-09-30 05:21:56 - train.py[line:551] - INFO: load:1.90 valid_run:9043.41 task_valid:8723.40 collect_output:263.33
2022-09-30 05:25:07 - train.py[line:549] - INFO: 9600 / 14103
2022-09-30 05:25:07 - train.py[line:551] - INFO: load:1.93 valid_run:9234.28 task_valid:8907.53 collect_output:268.97
2022-09-30 05:28:18 - train.py[line:549] - INFO: 9800 / 14103
2022-09-30 05:28:18 - train.py[line:551] - INFO: load:1.95 valid_run:9425.05 task_valid:9095.58 collect_output:270.60
2022-09-30 05:31:30 - train.py[line:549] - INFO: 10000 / 14103
2022-09-30 05:31:30 - train.py[line:551] - INFO: load:1.97 valid_run:9617.39 task_valid:9283.95 collect_output:273.38
2022-09-30 05:34:45 - train.py[line:549] - INFO: 10200 / 14103
2022-09-30 05:34:45 - train.py[line:551] - INFO: load:2.01 valid_run:9812.19 task_valid:9470.34 collect_output:280.61
2022-09-30 05:37:58 - train.py[line:549] - INFO: 10400 / 14103
2022-09-30 05:37:58 - train.py[line:551] - INFO: load:2.03 valid_run:10005.01 task_valid:9654.91 collect_output:287.63
2022-09-30 05:41:12 - train.py[line:549] - INFO: 10600 / 14103
2022-09-30 05:41:12 - train.py[line:551] - INFO: load:2.05 valid_run:10198.95 task_valid:9837.94 collect_output:297.30
2022-09-30 05:44:25 - train.py[line:549] - INFO: 10800 / 14103
2022-09-30 05:44:25 - train.py[line:551] - INFO: load:2.08 valid_run:10391.90 task_valid:10022.87 collect_output:304.07
2022-09-30 05:47:38 - train.py[line:549] - INFO: 11000 / 14103
2022-09-30 05:47:38 - train.py[line:551] - INFO: load:2.10 valid_run:10584.57 task_valid:10208.48 collect_output:309.91
2022-09-30 05:50:50 - train.py[line:549] - INFO: 11200 / 14103
2022-09-30 05:50:50 - train.py[line:551] - INFO: load:2.12 valid_run:10776.86 task_valid:10393.03 collect_output:316.48
2022-09-30 05:54:07 - train.py[line:549] - INFO: 11400 / 14103
2022-09-30 05:54:07 - train.py[line:551] - INFO: load:2.15 valid_run:10973.72 task_valid:10585.91 collect_output:319.16
2022-09-30 05:57:17 - train.py[line:549] - INFO: 11600 / 14103
2022-09-30 05:57:17 - train.py[line:551] - INFO: load:2.17 valid_run:11163.32 task_valid:10770.53 collect_output:323.04
2022-09-30 06:00:29 - train.py[line:549] - INFO: 11800 / 14103
2022-09-30 06:00:29 - train.py[line:551] - INFO: load:2.19 valid_run:11355.10 task_valid:10956.92 collect_output:327.26
2022-09-30 06:03:39 - train.py[line:549] - INFO: 12000 / 14103
2022-09-30 06:03:39 - train.py[line:551] - INFO: load:2.22 valid_run:11544.98 task_valid:11140.22 collect_output:332.61
2022-09-30 06:06:50 - train.py[line:549] - INFO: 12200 / 14103
2022-09-30 06:06:50 - train.py[line:551] - INFO: load:2.24 valid_run:11735.90 task_valid:11325.60 collect_output:336.96
2022-09-30 06:10:01 - train.py[line:549] - INFO: 12400 / 14103
2022-09-30 06:10:01 - train.py[line:551] - INFO: load:2.27 valid_run:11927.02 task_valid:11510.54 collect_output:342.12
2022-09-30 06:13:11 - train.py[line:549] - INFO: 12600 / 14103
2022-09-30 06:13:11 - train.py[line:551] - INFO: load:2.29 valid_run:12117.29 task_valid:11693.81 collect_output:348.05
2022-09-30 06:16:23 - train.py[line:549] - INFO: 12800 / 14103
2022-09-30 06:16:23 - train.py[line:551] - INFO: load:2.31 valid_run:12309.02 task_valid:11878.86 collect_output:353.50
2022-09-30 06:19:33 - train.py[line:549] - INFO: 13000 / 14103
2022-09-30 06:19:33 - train.py[line:551] - INFO: load:2.34 valid_run:12499.44 task_valid:12062.53 collect_output:359.16
2022-09-30 06:22:43 - train.py[line:549] - INFO: 13200 / 14103
2022-09-30 06:22:43 - train.py[line:551] - INFO: load:2.36 valid_run:12689.44 task_valid:12243.84 collect_output:366.79
2022-09-30 06:25:57 - train.py[line:549] - INFO: 13400 / 14103
2022-09-30 06:25:57 - train.py[line:551] - INFO: load:2.38 valid_run:12883.41 task_valid:12426.08 collect_output:377.39
2022-09-30 06:29:09 - train.py[line:549] - INFO: 13600 / 14103
2022-09-30 06:29:09 - train.py[line:551] - INFO: load:2.41 valid_run:13074.68 task_valid:12607.62 collect_output:386.07
2022-09-30 06:32:21 - train.py[line:549] - INFO: 13800 / 14103
2022-09-30 06:32:21 - train.py[line:551] - INFO: load:2.43 valid_run:13267.07 task_valid:12794.29 collect_output:390.68
2022-09-30 06:35:34 - train.py[line:549] - INFO: 14000 / 14103
2022-09-30 06:35:34 - train.py[line:551] - INFO: load:2.45 valid_run:13459.50 task_valid:12979.70 collect_output:396.59
2022-09-30 06:37:10 - train.py[line:572] - INFO: scores:torch.Size([282060]) preds:torch.Size([282060]) sample_ids:torch.Size([282060])

====================================================================================================
SGG eval:     R @ 50: 0.6594;     R @ 100: 0.6734;     R @ 500: 0.6796;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2083;    mR @ 100: 0.2381;    mR @ 500: 0.2461;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1619) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2874) (attached to:0.0000) (behind:0.3967) (belonging to:0.0000) (between:0.0000) (carrying:0.7560) (covered in:0.6667) (covering:0.0000) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.1154) (has:0.7640) (holding:0.3488) (in:0.3631) (in front of:0.2787) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.6002) (of:0.4481) (on:0.8925) (on back of:0.0000) (over:0.1667) (painted on:0.0000) (parked on:0.0143) (part of:0.0000) (playing:0.0000) (riding:0.5000) (says:0.0000) (sitting on:0.3593) (standing on:0.0962) (to:0.0000) (under:0.4722) (using:1.0000) (walking in:0.0000) (walking on:0.4737) (watching:0.3333) (wearing:0.9859) (wears:0.0000) (with:0.1758) 
--------------------------------------------------------
====================================================================================================

2022-09-30 06:37:31 - train.py[line:486] - INFO: 0.6733988576849599

====================================================================================================
SGG eval:     R @ 50: 0.6594;     R @ 100: 0.6734;     R @ 500: 0.6796;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2083;    mR @ 100: 0.2381;    mR @ 500: 0.2461;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(above:0.1619) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2874) (attached to:0.0000) (behind:0.3967) (belonging to:0.0000) (between:0.0000) (carrying:0.7560) (covered in:0.6667) (covering:0.0000) (eating:1.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.1154) (has:0.7640) (holding:0.3488) (in:0.3631) (in front of:0.2787) (laying on:0.0000) (looking at:0.2500) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.6002) (of:0.4481) (on:0.8925) (on back of:0.0000) (over:0.1667) (painted on:0.0000) (parked on:0.0143) (part of:0.0000) (playing:0.0000) (riding:0.5000) (says:0.0000) (sitting on:0.3593) (standing on:0.0962) (to:0.0000) (under:0.4722) (using:1.0000) (walking in:0.0000) (walking on:0.4737) (watching:0.3333) (wearing:0.9859) (wears:0.0000) (with:0.1758) 
--------------------------------------------------------
====================================================================================================

2022-09-30 06:37:31 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.31 | loss_v1 0 | loss_v2 0 | nll_loss 0.115 | ntokens 59.526 | nsentences 20 | sample_size 59.526 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.673399 | ppl 1.08 | vqa_score 0.9103 | wps 61.8 | wpb 59.5 | bsz 20 | num_updates 36000 | best_R@100 0.673781
2022-09-30 06:37:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 36000 updates
2022-09-30 06:37:31 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_3_36000.pt
2022-09-30 06:37:37 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_3_36000.pt
2022-09-30 06:37:39 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480/checkpoint_3_36000.pt (epoch 3 @ 36000 updates, score 0.6733988576849599) (writing took 8.172012899070978 seconds)
2022-09-30 06:37:52 - progress_bar.py[line:274] - INFO: epoch 003:   4500 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=0.1, ups=0, wpb=101, bsz=40, num_updates=36010, lr=2.83168e-05, gnorm=0.907, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122096
2022-09-30 06:38:03 - progress_bar.py[line:274] - INFO: epoch 003:   4510 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.5, ups=0.9, wpb=100.4, bsz=40, num_updates=36020, lr=2.83102e-05, gnorm=0.954, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122108
2022-09-30 06:38:14 - progress_bar.py[line:274] - INFO: epoch 003:   4520 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.6, ups=0.9, wpb=101, bsz=40, num_updates=36030, lr=2.83036e-05, gnorm=0.925, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122119
2022-09-30 06:38:25 - progress_bar.py[line:274] - INFO: epoch 003:   4530 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.91, wpb=102.7, bsz=40, num_updates=36040, lr=2.8297e-05, gnorm=0.858, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122130
2022-09-30 06:38:36 - progress_bar.py[line:274] - INFO: epoch 003:   4540 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.9, wpb=100.5, bsz=40, num_updates=36050, lr=2.82904e-05, gnorm=0.795, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122141
2022-09-30 06:38:47 - progress_bar.py[line:274] - INFO: epoch 003:   4550 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=36060, lr=2.82838e-05, gnorm=0.929, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122152
2022-09-30 06:38:58 - progress_bar.py[line:274] - INFO: epoch 003:   4560 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=36070, lr=2.82772e-05, gnorm=0.821, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=122163
2022-09-30 06:39:10 - progress_bar.py[line:274] - INFO: epoch 003:   4570 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.9, ups=0.88, wpb=102.5, bsz=40, num_updates=36080, lr=2.82706e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122175
2022-09-30 06:39:21 - progress_bar.py[line:274] - INFO: epoch 003:   4580 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.4, ups=0.91, wpb=100.7, bsz=40, num_updates=36090, lr=2.8264e-05, gnorm=0.735, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122186
2022-09-30 06:39:32 - progress_bar.py[line:274] - INFO: epoch 003:   4590 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.91, wpb=100.3, bsz=40, num_updates=36100, lr=2.82574e-05, gnorm=0.909, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=122197
2022-09-30 06:39:43 - progress_bar.py[line:274] - INFO: epoch 003:   4600 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.7, ups=0.9, wpb=100.3, bsz=40, num_updates=36110, lr=2.82508e-05, gnorm=0.752, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122208
2022-09-30 06:39:54 - progress_bar.py[line:274] - INFO: epoch 003:   4610 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.8, ups=0.88, wpb=102.2, bsz=40, num_updates=36120, lr=2.82442e-05, gnorm=0.847, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122219
2022-09-30 06:40:05 - progress_bar.py[line:274] - INFO: epoch 003:   4620 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91, ups=0.89, wpb=102.5, bsz=40, num_updates=36130, lr=2.82376e-05, gnorm=0.801, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122230
2022-09-30 06:40:17 - progress_bar.py[line:274] - INFO: epoch 003:   4630 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89, ups=0.87, wpb=101.8, bsz=40, num_updates=36140, lr=2.8231e-05, gnorm=0.697, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122242
2022-09-30 06:40:28 - progress_bar.py[line:274] - INFO: epoch 003:   4640 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=104.1, nsentences=40, sample_size=104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.4, ups=0.93, wpb=104.1, bsz=40, num_updates=36150, lr=2.82244e-05, gnorm=0.862, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122253
2022-09-30 06:40:39 - progress_bar.py[line:274] - INFO: epoch 003:   4650 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.1, ups=0.86, wpb=103.1, bsz=40, num_updates=36160, lr=2.82178e-05, gnorm=0.723, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=122264
2022-09-30 06:40:51 - progress_bar.py[line:274] - INFO: epoch 003:   4660 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.5, ups=0.88, wpb=101.1, bsz=40, num_updates=36170, lr=2.82112e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122276
2022-09-30 06:41:02 - progress_bar.py[line:274] - INFO: epoch 003:   4670 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.9, wpb=101.7, bsz=40, num_updates=36180, lr=2.82046e-05, gnorm=0.922, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122287
2022-09-30 06:41:13 - progress_bar.py[line:274] - INFO: epoch 003:   4680 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.5, ups=0.93, wpb=100.5, bsz=40, num_updates=36190, lr=2.8198e-05, gnorm=0.851, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122297
2022-09-30 06:41:24 - progress_bar.py[line:274] - INFO: epoch 003:   4690 / 15783 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=88.6, ups=0.87, wpb=102.4, bsz=40, num_updates=36200, lr=2.81914e-05, gnorm=0.916, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122309
2022-09-30 06:41:35 - progress_bar.py[line:274] - INFO: epoch 003:   4700 / 15783 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=104, nsentences=40, sample_size=104, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.3, ups=0.89, wpb=104, bsz=40, num_updates=36210, lr=2.81848e-05, gnorm=0.866, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122320
2022-09-30 06:41:47 - progress_bar.py[line:274] - INFO: epoch 003:   4710 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.4, ups=0.86, wpb=101.3, bsz=40, num_updates=36220, lr=2.81782e-05, gnorm=0.783, clip=20, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=122332
2022-09-30 06:41:59 - progress_bar.py[line:274] - INFO: epoch 003:   4720 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=87.6, ups=0.86, wpb=101.7, bsz=40, num_updates=36230, lr=2.81716e-05, gnorm=0.857, clip=30, loss_scale=1024, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=122343
2022-09-30 06:42:10 - progress_bar.py[line:274] - INFO: epoch 003:   4730 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.7, ups=0.91, wpb=100.2, bsz=40, num_updates=36240, lr=2.8165e-05, gnorm=0.958, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=122354
2022-09-30 06:42:21 - progress_bar.py[line:274] - INFO: epoch 003:   4740 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.1, ups=0.88, wpb=99.5, bsz=40, num_updates=36250, lr=2.81584e-05, gnorm=0.842, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122366
2022-09-30 06:42:32 - progress_bar.py[line:274] - INFO: epoch 003:   4750 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.89, wpb=102, bsz=40, num_updates=36260, lr=2.81518e-05, gnorm=1.005, clip=50, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=122377
2022-09-30 06:42:43 - progress_bar.py[line:274] - INFO: epoch 003:   4760 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.91, wpb=101.2, bsz=40, num_updates=36270, lr=2.81452e-05, gnorm=0.907, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122388
2022-09-30 06:42:55 - progress_bar.py[line:274] - INFO: epoch 003:   4770 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.88, wpb=101.7, bsz=40, num_updates=36280, lr=2.81386e-05, gnorm=0.841, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122399
2022-09-30 06:43:06 - progress_bar.py[line:274] - INFO: epoch 003:   4780 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.88, wpb=101.4, bsz=40, num_updates=36290, lr=2.8132e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122411
2022-09-30 06:43:17 - progress_bar.py[line:274] - INFO: epoch 003:   4790 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.1, ups=0.9, wpb=100.4, bsz=40, num_updates=36300, lr=2.81254e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122422
2022-09-30 06:43:29 - progress_bar.py[line:274] - INFO: epoch 003:   4800 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.3, ups=0.87, wpb=101, bsz=40, num_updates=36310, lr=2.81188e-05, gnorm=0.915, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122433
2022-09-30 06:43:40 - progress_bar.py[line:274] - INFO: epoch 003:   4810 / 15783 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.8, ups=0.91, wpb=101, bsz=40, num_updates=36320, lr=2.81122e-05, gnorm=0.991, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122444
2022-09-30 06:43:51 - progress_bar.py[line:274] - INFO: epoch 003:   4820 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=100.7, bsz=40, num_updates=36330, lr=2.81056e-05, gnorm=0.914, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=122456
2022-09-30 06:44:02 - progress_bar.py[line:274] - INFO: epoch 003:   4830 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.1, ups=0.93, wpb=101.6, bsz=40, num_updates=36340, lr=2.8099e-05, gnorm=0.896, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122467
2022-09-30 06:44:13 - progress_bar.py[line:274] - INFO: epoch 003:   4840 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.9, ups=0.88, wpb=100.6, bsz=40, num_updates=36350, lr=2.80924e-05, gnorm=0.868, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122478
2022-09-30 06:44:24 - progress_bar.py[line:274] - INFO: epoch 003:   4850 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.89, wpb=102, bsz=40, num_updates=36360, lr=2.80858e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=122489
2022-09-30 06:44:36 - progress_bar.py[line:274] - INFO: epoch 003:   4860 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.8, ups=0.86, wpb=100.8, bsz=40, num_updates=36370, lr=2.80792e-05, gnorm=0.801, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=122501
2022-09-30 06:44:47 - progress_bar.py[line:274] - INFO: epoch 003:   4870 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.3, ups=0.87, wpb=102.3, bsz=40, num_updates=36380, lr=2.80726e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=122512
2022-09-30 06:44:59 - progress_bar.py[line:274] - INFO: epoch 003:   4880 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.9, wpb=100.9, bsz=40, num_updates=36390, lr=2.8066e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122523
2022-09-30 06:45:10 - progress_bar.py[line:274] - INFO: epoch 003:   4890 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.2, ups=0.89, wpb=102.7, bsz=40, num_updates=36400, lr=2.80594e-05, gnorm=0.876, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122535
2022-09-30 06:45:21 - progress_bar.py[line:274] - INFO: epoch 003:   4900 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.89, wpb=101.9, bsz=40, num_updates=36410, lr=2.80528e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=122546
2022-09-30 06:45:32 - progress_bar.py[line:274] - INFO: epoch 003:   4910 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.2, ups=0.89, wpb=99.9, bsz=40, num_updates=36420, lr=2.80462e-05, gnorm=0.876, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122557
2022-09-30 06:45:44 - progress_bar.py[line:274] - INFO: epoch 003:   4920 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.3, ups=0.89, wpb=103, bsz=40, num_updates=36430, lr=2.80396e-05, gnorm=0.795, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122568
2022-09-30 06:45:54 - progress_bar.py[line:274] - INFO: epoch 003:   4930 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.9, ups=0.92, wpb=100.5, bsz=40, num_updates=36440, lr=2.8033e-05, gnorm=0.822, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122579
2022-09-30 06:46:05 - progress_bar.py[line:274] - INFO: epoch 003:   4940 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.7, ups=0.92, wpb=100.2, bsz=40, num_updates=36450, lr=2.80264e-05, gnorm=0.816, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122590
2022-09-30 06:46:17 - progress_bar.py[line:274] - INFO: epoch 003:   4950 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.9, wpb=101.4, bsz=40, num_updates=36460, lr=2.80198e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122601
2022-09-30 06:46:28 - progress_bar.py[line:274] - INFO: epoch 003:   4960 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.5, ups=0.89, wpb=101.6, bsz=40, num_updates=36470, lr=2.80132e-05, gnorm=0.854, clip=20, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122613
2022-09-30 06:46:39 - progress_bar.py[line:274] - INFO: epoch 003:   4970 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=36480, lr=2.80066e-05, gnorm=0.834, clip=10, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122624
2022-09-30 06:46:50 - progress_bar.py[line:274] - INFO: epoch 003:   4980 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.6, ups=0.9, wpb=101.6, bsz=40, num_updates=36490, lr=2.8e-05, gnorm=0.808, clip=20, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122635
2022-09-30 06:47:01 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 06:47:02 - progress_bar.py[line:274] - INFO: epoch 003:   4991 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=83.4, ups=0.82, wpb=101.7, bsz=40, num_updates=36500, lr=2.79934e-05, gnorm=0.874, clip=20, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=122647
2022-09-30 06:47:14 - progress_bar.py[line:274] - INFO: epoch 003:   5001 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.2, ups=0.87, wpb=101.6, bsz=40, num_updates=36510, lr=2.79868e-05, gnorm=0.876, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122659
2022-09-30 06:47:25 - progress_bar.py[line:274] - INFO: epoch 003:   5011 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90, ups=0.9, wpb=100.5, bsz=40, num_updates=36520, lr=2.79802e-05, gnorm=0.786, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=122670
2022-09-30 06:47:36 - progress_bar.py[line:274] - INFO: epoch 003:   5021 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.9, wpb=101.4, bsz=40, num_updates=36530, lr=2.79736e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122681
2022-09-30 06:47:47 - progress_bar.py[line:274] - INFO: epoch 003:   5031 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.8, ups=0.88, wpb=102.7, bsz=40, num_updates=36540, lr=2.7967e-05, gnorm=0.797, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122692
2022-09-30 06:47:58 - progress_bar.py[line:274] - INFO: epoch 003:   5041 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.9, ups=0.92, wpb=101.7, bsz=40, num_updates=36550, lr=2.79604e-05, gnorm=0.876, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122703
2022-09-30 06:48:10 - progress_bar.py[line:274] - INFO: epoch 003:   5051 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=101.4, bsz=40, num_updates=36560, lr=2.79538e-05, gnorm=0.79, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=122715
2022-09-30 06:48:21 - progress_bar.py[line:274] - INFO: epoch 003:   5061 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.9, wpb=101.1, bsz=40, num_updates=36570, lr=2.79472e-05, gnorm=0.858, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122726
2022-09-30 06:48:32 - progress_bar.py[line:274] - INFO: epoch 003:   5071 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.6, ups=0.93, wpb=101.9, bsz=40, num_updates=36580, lr=2.79406e-05, gnorm=0.955, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122736
2022-09-30 06:48:43 - progress_bar.py[line:274] - INFO: epoch 003:   5081 / 15783 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.9, ups=0.9, wpb=102.1, bsz=40, num_updates=36590, lr=2.7934e-05, gnorm=0.793, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122748
2022-09-30 06:48:54 - progress_bar.py[line:274] - INFO: epoch 003:   5091 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.4, ups=0.88, wpb=101, bsz=40, num_updates=36600, lr=2.79274e-05, gnorm=0.851, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122759
2022-09-30 06:49:05 - progress_bar.py[line:274] - INFO: epoch 003:   5101 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.5, ups=0.9, wpb=100.8, bsz=40, num_updates=36610, lr=2.79208e-05, gnorm=0.879, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122770
2022-09-30 06:49:16 - progress_bar.py[line:274] - INFO: epoch 003:   5111 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.9, wpb=101.1, bsz=40, num_updates=36620, lr=2.79142e-05, gnorm=0.877, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122781
2022-09-30 06:49:28 - progress_bar.py[line:274] - INFO: epoch 003:   5121 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.2, ups=0.9, wpb=100.3, bsz=40, num_updates=36630, lr=2.79076e-05, gnorm=0.809, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122792
2022-09-30 06:49:39 - progress_bar.py[line:274] - INFO: epoch 003:   5131 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90, ups=0.88, wpb=102.8, bsz=40, num_updates=36640, lr=2.7901e-05, gnorm=0.864, clip=40, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=122804
2022-09-30 06:49:50 - progress_bar.py[line:274] - INFO: epoch 003:   5141 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.2, ups=0.92, wpb=102.1, bsz=40, num_updates=36650, lr=2.78944e-05, gnorm=0.825, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122815
2022-09-30 06:50:01 - progress_bar.py[line:274] - INFO: epoch 003:   5151 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.88, wpb=102.4, bsz=40, num_updates=36660, lr=2.78878e-05, gnorm=0.81, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122826
2022-09-30 06:50:12 - progress_bar.py[line:274] - INFO: epoch 003:   5161 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.91, wpb=99.3, bsz=40, num_updates=36670, lr=2.78812e-05, gnorm=0.891, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122837
2022-09-30 06:50:23 - progress_bar.py[line:274] - INFO: epoch 003:   5171 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.8, ups=0.9, wpb=101.3, bsz=40, num_updates=36680, lr=2.78746e-05, gnorm=0.822, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122848
2022-09-30 06:50:35 - progress_bar.py[line:274] - INFO: epoch 003:   5181 / 15783 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=88.8, ups=0.87, wpb=101.8, bsz=40, num_updates=36690, lr=2.7868e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122860
2022-09-30 06:50:46 - progress_bar.py[line:274] - INFO: epoch 003:   5191 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.5, ups=0.86, wpb=102.5, bsz=40, num_updates=36700, lr=2.78614e-05, gnorm=0.75, clip=0, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=122871
2022-09-30 06:50:58 - progress_bar.py[line:274] - INFO: epoch 003:   5201 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.9, wpb=101.1, bsz=40, num_updates=36710, lr=2.78548e-05, gnorm=1.051, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122882
2022-09-30 06:51:09 - progress_bar.py[line:274] - INFO: epoch 003:   5211 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=87.1, ups=0.86, wpb=101.8, bsz=40, num_updates=36720, lr=2.78482e-05, gnorm=0.794, clip=20, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=122894
2022-09-30 06:51:21 - progress_bar.py[line:274] - INFO: epoch 003:   5221 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.88, wpb=101.9, bsz=40, num_updates=36730, lr=2.78416e-05, gnorm=0.887, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122905
2022-09-30 06:51:32 - progress_bar.py[line:274] - INFO: epoch 003:   5231 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.4, ups=0.91, wpb=101.8, bsz=40, num_updates=36740, lr=2.7835e-05, gnorm=0.903, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122916
2022-09-30 06:51:43 - progress_bar.py[line:274] - INFO: epoch 003:   5241 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88, ups=0.88, wpb=100.5, bsz=40, num_updates=36750, lr=2.78284e-05, gnorm=0.977, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122928
2022-09-30 06:51:54 - progress_bar.py[line:274] - INFO: epoch 003:   5251 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.4, ups=0.92, wpb=100.6, bsz=40, num_updates=36760, lr=2.78218e-05, gnorm=1.034, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=122939
2022-09-30 06:52:05 - progress_bar.py[line:274] - INFO: epoch 003:   5261 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=101.1, bsz=40, num_updates=36770, lr=2.78152e-05, gnorm=0.814, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=122950
2022-09-30 06:52:17 - progress_bar.py[line:274] - INFO: epoch 003:   5271 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.2, ups=0.88, wpb=101.7, bsz=40, num_updates=36780, lr=2.78086e-05, gnorm=0.864, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=122962
2022-09-30 06:52:27 - progress_bar.py[line:274] - INFO: epoch 003:   5281 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.1, ups=0.94, wpb=101.2, bsz=40, num_updates=36790, lr=2.7802e-05, gnorm=0.882, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122972
2022-09-30 06:52:39 - progress_bar.py[line:274] - INFO: epoch 003:   5291 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.6, ups=0.88, wpb=101.5, bsz=40, num_updates=36800, lr=2.77954e-05, gnorm=0.878, clip=30, loss_scale=1024, train_wall=11, gb_free=9.4, ema_decay=0.9999, wall=122984
2022-09-30 06:52:50 - progress_bar.py[line:274] - INFO: epoch 003:   5301 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.5, ups=0.93, wpb=100.8, bsz=40, num_updates=36810, lr=2.77888e-05, gnorm=0.917, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122994
2022-09-30 06:53:01 - progress_bar.py[line:274] - INFO: epoch 003:   5311 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=86.6, ups=0.86, wpb=100.3, bsz=40, num_updates=36820, lr=2.77822e-05, gnorm=0.858, clip=10, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=123006
2022-09-30 06:53:12 - progress_bar.py[line:274] - INFO: epoch 003:   5321 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.89, wpb=101.1, bsz=40, num_updates=36830, lr=2.77756e-05, gnorm=0.842, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123017
2022-09-30 06:53:24 - progress_bar.py[line:274] - INFO: epoch 003:   5331 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.89, wpb=101.7, bsz=40, num_updates=36840, lr=2.7769e-05, gnorm=0.834, clip=10, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=123029
2022-09-30 06:53:35 - progress_bar.py[line:274] - INFO: epoch 003:   5341 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.4, ups=0.87, wpb=102.5, bsz=40, num_updates=36850, lr=2.77624e-05, gnorm=0.796, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123040
2022-09-30 06:53:47 - progress_bar.py[line:274] - INFO: epoch 003:   5351 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.1, ups=0.88, wpb=100.4, bsz=40, num_updates=36860, lr=2.77558e-05, gnorm=0.874, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123051
2022-09-30 06:53:58 - progress_bar.py[line:274] - INFO: epoch 003:   5361 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=36870, lr=2.77492e-05, gnorm=0.867, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=123063
2022-09-30 06:54:09 - progress_bar.py[line:274] - INFO: epoch 003:   5371 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.4, ups=0.89, wpb=101.7, bsz=40, num_updates=36880, lr=2.77426e-05, gnorm=0.8, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=123074
2022-09-30 06:54:20 - progress_bar.py[line:274] - INFO: epoch 003:   5381 / 15783 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.4, ups=0.95, wpb=103.7, bsz=40, num_updates=36890, lr=2.7736e-05, gnorm=0.861, clip=20, loss_scale=1024, train_wall=10, gb_free=10.1, ema_decay=0.9999, wall=123084
2022-09-30 06:54:31 - progress_bar.py[line:274] - INFO: epoch 003:   5391 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.9, wpb=101.4, bsz=40, num_updates=36900, lr=2.77294e-05, gnorm=0.783, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123096
2022-09-30 06:54:42 - progress_bar.py[line:274] - INFO: epoch 003:   5401 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.4, ups=0.9, wpb=101.7, bsz=40, num_updates=36910, lr=2.77228e-05, gnorm=0.848, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=123107
2022-09-30 06:54:53 - progress_bar.py[line:274] - INFO: epoch 003:   5411 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.4, ups=0.88, wpb=101.6, bsz=40, num_updates=36920, lr=2.77162e-05, gnorm=0.815, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123118
2022-09-30 06:55:04 - progress_bar.py[line:274] - INFO: epoch 003:   5421 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.9, ups=0.91, wpb=101.1, bsz=40, num_updates=36930, lr=2.77096e-05, gnorm=1.034, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123129
2022-09-30 06:55:15 - progress_bar.py[line:274] - INFO: epoch 003:   5431 / 15783 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.9, ups=0.9, wpb=101.5, bsz=40, num_updates=36940, lr=2.7703e-05, gnorm=0.89, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123140
2022-09-30 06:55:27 - progress_bar.py[line:274] - INFO: epoch 003:   5441 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.6, ups=0.87, wpb=100.3, bsz=40, num_updates=36950, lr=2.76964e-05, gnorm=0.817, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=123152
2022-09-30 06:55:38 - progress_bar.py[line:274] - INFO: epoch 003:   5451 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.5, ups=0.9, wpb=101.5, bsz=40, num_updates=36960, lr=2.76898e-05, gnorm=0.888, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123163
2022-09-30 06:55:49 - progress_bar.py[line:274] - INFO: epoch 003:   5461 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.2, ups=0.9, wpb=102.1, bsz=40, num_updates=36970, lr=2.76832e-05, gnorm=0.776, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123174
2022-09-30 06:56:00 - progress_bar.py[line:274] - INFO: epoch 003:   5471 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.4, ups=0.88, wpb=101.1, bsz=40, num_updates=36980, lr=2.76766e-05, gnorm=0.833, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=123185
2022-09-30 06:56:12 - progress_bar.py[line:274] - INFO: epoch 003:   5481 / 15783 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=88.4, ups=0.86, wpb=102.3, bsz=40, num_updates=36990, lr=2.767e-05, gnorm=0.839, clip=10, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=123197
2022-09-30 06:56:23 - progress_bar.py[line:274] - INFO: epoch 003:   5491 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.1, ups=0.89, wpb=101.7, bsz=40, num_updates=37000, lr=2.76634e-05, gnorm=0.857, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123208
2022-09-30 06:56:35 - progress_bar.py[line:274] - INFO: epoch 003:   5501 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90, ups=0.89, wpb=101.5, bsz=40, num_updates=37010, lr=2.76568e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=123219
2022-09-30 06:56:41 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 06:56:47 - progress_bar.py[line:274] - INFO: epoch 003:   5512 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=81.5, ups=0.81, wpb=100.3, bsz=40, num_updates=37020, lr=2.76502e-05, gnorm=0.961, clip=30, loss_scale=1024, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=123232
2022-09-30 06:56:58 - progress_bar.py[line:274] - INFO: epoch 003:   5522 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95, ups=0.92, wpb=102.9, bsz=40, num_updates=37030, lr=2.76436e-05, gnorm=0.79, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=123243
2022-09-30 06:57:09 - progress_bar.py[line:274] - INFO: epoch 003:   5532 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.9, wpb=102, bsz=40, num_updates=37040, lr=2.7637e-05, gnorm=0.847, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123254
2022-09-30 06:57:20 - progress_bar.py[line:274] - INFO: epoch 003:   5542 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.9, wpb=100.4, bsz=40, num_updates=37050, lr=2.76304e-05, gnorm=0.952, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123265
2022-09-30 06:57:31 - progress_bar.py[line:274] - INFO: epoch 003:   5552 / 15783 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.3, ups=0.9, wpb=102.6, bsz=40, num_updates=37060, lr=2.76238e-05, gnorm=0.727, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=123276
2022-09-30 06:57:42 - progress_bar.py[line:274] - INFO: epoch 003:   5562 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93, ups=0.91, wpb=101.9, bsz=40, num_updates=37070, lr=2.76172e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=123287
2022-09-30 06:57:53 - progress_bar.py[line:274] - INFO: epoch 003:   5572 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.5, ups=0.89, wpb=99.8, bsz=40, num_updates=37080, lr=2.76106e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123298
2022-09-30 06:58:05 - progress_bar.py[line:274] - INFO: epoch 003:   5582 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89, ups=0.89, wpb=100.4, bsz=40, num_updates=37090, lr=2.7604e-05, gnorm=0.92, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=123310
2022-09-30 06:58:16 - progress_bar.py[line:274] - INFO: epoch 003:   5592 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.9, wpb=101.6, bsz=40, num_updates=37100, lr=2.75974e-05, gnorm=0.824, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123321
2022-09-30 06:58:27 - progress_bar.py[line:274] - INFO: epoch 003:   5602 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.5, ups=0.88, wpb=102.1, bsz=40, num_updates=37110, lr=2.75908e-05, gnorm=0.666, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123332
2022-09-30 06:58:39 - progress_bar.py[line:274] - INFO: epoch 003:   5612 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.89, wpb=103, bsz=40, num_updates=37120, lr=2.75842e-05, gnorm=0.898, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123343
2022-09-30 06:58:50 - progress_bar.py[line:274] - INFO: epoch 003:   5622 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.89, wpb=102.2, bsz=40, num_updates=37130, lr=2.75776e-05, gnorm=0.9, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=123355
2022-09-30 06:59:01 - progress_bar.py[line:274] - INFO: epoch 003:   5632 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.8, ups=0.9, wpb=101, bsz=40, num_updates=37140, lr=2.7571e-05, gnorm=0.92, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123366
2022-09-30 06:59:12 - progress_bar.py[line:274] - INFO: epoch 003:   5642 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.1, ups=0.88, wpb=101.5, bsz=40, num_updates=37150, lr=2.75644e-05, gnorm=0.822, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=123377
2022-09-30 06:59:23 - progress_bar.py[line:274] - INFO: epoch 003:   5652 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.91, wpb=100.3, bsz=40, num_updates=37160, lr=2.75578e-05, gnorm=0.823, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123388
2022-09-30 06:59:35 - progress_bar.py[line:274] - INFO: epoch 003:   5662 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.5, ups=0.89, wpb=98.9, bsz=40, num_updates=37170, lr=2.75512e-05, gnorm=0.901, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123399
2022-09-30 06:59:46 - progress_bar.py[line:274] - INFO: epoch 003:   5672 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.1, ups=0.9, wpb=102.6, bsz=40, num_updates=37180, lr=2.75446e-05, gnorm=0.865, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123410
2022-09-30 06:59:57 - progress_bar.py[line:274] - INFO: epoch 003:   5682 / 15783 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=93.2, ups=0.91, wpb=102, bsz=40, num_updates=37190, lr=2.7538e-05, gnorm=0.742, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123421
2022-09-30 07:00:08 - progress_bar.py[line:274] - INFO: epoch 003:   5692 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.8, ups=0.88, wpb=102.5, bsz=40, num_updates=37200, lr=2.75314e-05, gnorm=0.824, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=123433
2022-09-30 07:00:19 - progress_bar.py[line:274] - INFO: epoch 003:   5702 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.7, ups=0.88, wpb=102.1, bsz=40, num_updates=37210, lr=2.75248e-05, gnorm=0.89, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=123444
2022-09-30 07:00:30 - progress_bar.py[line:274] - INFO: epoch 003:   5712 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.3, ups=0.93, wpb=101.8, bsz=40, num_updates=37220, lr=2.75182e-05, gnorm=0.752, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123455
2022-09-30 07:00:41 - progress_bar.py[line:274] - INFO: epoch 003:   5722 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.91, wpb=100.3, bsz=40, num_updates=37230, lr=2.75116e-05, gnorm=0.838, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123466
2022-09-30 07:00:52 - progress_bar.py[line:274] - INFO: epoch 003:   5732 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.3, ups=0.9, wpb=103, bsz=40, num_updates=37240, lr=2.7505e-05, gnorm=0.843, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123477
2022-09-30 07:01:03 - progress_bar.py[line:274] - INFO: epoch 003:   5742 / 15783 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.1, ups=0.9, wpb=102.6, bsz=40, num_updates=37250, lr=2.74984e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123488
2022-09-30 07:01:15 - progress_bar.py[line:274] - INFO: epoch 003:   5752 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.3, ups=0.9, wpb=99.6, bsz=40, num_updates=37260, lr=2.74918e-05, gnorm=0.92, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=123499
2022-09-30 07:01:26 - progress_bar.py[line:274] - INFO: epoch 003:   5762 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.3, ups=0.89, wpb=100.6, bsz=40, num_updates=37270, lr=2.74852e-05, gnorm=0.878, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123511
2022-09-30 07:01:38 - progress_bar.py[line:274] - INFO: epoch 003:   5772 / 15783 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=103.5, nsentences=40, sample_size=103.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.8, ups=0.9, wpb=103.5, bsz=40, num_updates=37280, lr=2.74786e-05, gnorm=0.924, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=123522
2022-09-30 07:01:49 - progress_bar.py[line:274] - INFO: epoch 003:   5782 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=86.6, ups=0.86, wpb=100.2, bsz=40, num_updates=37290, lr=2.7472e-05, gnorm=0.914, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=123534
2022-09-30 07:02:00 - progress_bar.py[line:274] - INFO: epoch 003:   5792 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.91, wpb=100.1, bsz=40, num_updates=37300, lr=2.74654e-05, gnorm=0.781, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123545
2022-09-30 07:02:12 - progress_bar.py[line:274] - INFO: epoch 003:   5802 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.9, wpb=100.2, bsz=40, num_updates=37310, lr=2.74588e-05, gnorm=0.874, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=123556
2022-09-30 07:02:23 - progress_bar.py[line:274] - INFO: epoch 003:   5812 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.2, ups=0.9, wpb=100.8, bsz=40, num_updates=37320, lr=2.74522e-05, gnorm=0.886, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123568
2022-09-30 07:02:34 - progress_bar.py[line:274] - INFO: epoch 003:   5822 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.9, ups=0.89, wpb=100.6, bsz=40, num_updates=37330, lr=2.74456e-05, gnorm=0.928, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123579
2022-09-30 07:02:45 - progress_bar.py[line:274] - INFO: epoch 003:   5832 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.9, wpb=102.6, bsz=40, num_updates=37340, lr=2.7439e-05, gnorm=0.753, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123590
2022-09-30 07:02:56 - progress_bar.py[line:274] - INFO: epoch 003:   5842 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.4, ups=0.9, wpb=100.6, bsz=40, num_updates=37350, lr=2.74324e-05, gnorm=0.974, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123601
2022-09-30 07:03:07 - progress_bar.py[line:274] - INFO: epoch 003:   5852 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.4, ups=0.9, wpb=101.7, bsz=40, num_updates=37360, lr=2.74258e-05, gnorm=0.873, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123612
2022-09-30 07:03:19 - progress_bar.py[line:274] - INFO: epoch 003:   5862 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.7, ups=0.9, wpb=101.1, bsz=40, num_updates=37370, lr=2.74192e-05, gnorm=0.821, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=123623
2022-09-30 07:03:30 - progress_bar.py[line:274] - INFO: epoch 003:   5872 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=37380, lr=2.74126e-05, gnorm=0.82, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=123635
2022-09-30 07:03:41 - progress_bar.py[line:274] - INFO: epoch 003:   5882 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.2, ups=0.92, wpb=101.4, bsz=40, num_updates=37390, lr=2.7406e-05, gnorm=0.886, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123645
2022-09-30 07:03:52 - progress_bar.py[line:274] - INFO: epoch 003:   5892 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=37400, lr=2.73994e-05, gnorm=0.992, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123657
2022-09-30 07:04:03 - progress_bar.py[line:274] - INFO: epoch 003:   5902 / 15783 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.6, ups=0.89, wpb=102.1, bsz=40, num_updates=37410, lr=2.73928e-05, gnorm=0.829, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123668
2022-09-30 07:04:14 - progress_bar.py[line:274] - INFO: epoch 003:   5912 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.4, ups=0.89, wpb=101.2, bsz=40, num_updates=37420, lr=2.73862e-05, gnorm=0.947, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123679
2022-09-30 07:04:26 - progress_bar.py[line:274] - INFO: epoch 003:   5922 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.1, ups=0.88, wpb=101, bsz=40, num_updates=37430, lr=2.73796e-05, gnorm=0.796, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123691
2022-09-30 07:04:37 - progress_bar.py[line:274] - INFO: epoch 003:   5932 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.9, wpb=100.8, bsz=40, num_updates=37440, lr=2.7373e-05, gnorm=0.908, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123702
2022-09-30 07:04:48 - progress_bar.py[line:274] - INFO: epoch 003:   5942 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92, ups=0.93, wpb=99, bsz=40, num_updates=37450, lr=2.73664e-05, gnorm=0.949, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123713
2022-09-30 07:04:59 - progress_bar.py[line:274] - INFO: epoch 003:   5952 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92, ups=0.9, wpb=102, bsz=40, num_updates=37460, lr=2.73598e-05, gnorm=0.876, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123724
2022-09-30 07:05:10 - progress_bar.py[line:274] - INFO: epoch 003:   5962 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.5, ups=0.9, wpb=101.1, bsz=40, num_updates=37470, lr=2.73532e-05, gnorm=0.842, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=123735
2022-09-30 07:05:21 - progress_bar.py[line:274] - INFO: epoch 003:   5972 / 15783 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.5, ups=0.9, wpb=103.6, bsz=40, num_updates=37480, lr=2.73466e-05, gnorm=0.736, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=123746
2022-09-30 07:05:32 - progress_bar.py[line:274] - INFO: epoch 003:   5982 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.91, wpb=99.9, bsz=40, num_updates=37490, lr=2.734e-05, gnorm=0.864, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123757
2022-09-30 07:05:43 - progress_bar.py[line:274] - INFO: epoch 003:   5992 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.9, wpb=100.9, bsz=40, num_updates=37500, lr=2.73334e-05, gnorm=0.837, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123768
2022-09-30 07:05:54 - progress_bar.py[line:274] - INFO: epoch 003:   6002 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=37510, lr=2.73268e-05, gnorm=0.867, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123779
2022-09-30 07:06:05 - progress_bar.py[line:274] - INFO: epoch 003:   6012 / 15783 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.7, ups=0.93, wpb=99.9, bsz=40, num_updates=37520, lr=2.73202e-05, gnorm=1.086, clip=70, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=123790
2022-09-30 07:06:15 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 07:06:17 - progress_bar.py[line:274] - INFO: epoch 003:   6023 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=83.3, ups=0.81, wpb=103, bsz=40, num_updates=37530, lr=2.73136e-05, gnorm=0.783, clip=0, loss_scale=1024, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=123802
2022-09-30 07:06:28 - progress_bar.py[line:274] - INFO: epoch 003:   6033 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.3, ups=0.91, wpb=102.2, bsz=40, num_updates=37540, lr=2.7307e-05, gnorm=0.781, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123813
2022-09-30 07:06:40 - progress_bar.py[line:274] - INFO: epoch 003:   6043 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.9, ups=0.88, wpb=101, bsz=40, num_updates=37550, lr=2.73004e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123825
2022-09-30 07:06:51 - progress_bar.py[line:274] - INFO: epoch 003:   6053 / 15783 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=88.7, ups=0.89, wpb=99.6, bsz=40, num_updates=37560, lr=2.72938e-05, gnorm=0.973, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123836
2022-09-30 07:07:02 - progress_bar.py[line:274] - INFO: epoch 003:   6063 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.1, ups=0.89, wpb=102.4, bsz=40, num_updates=37570, lr=2.72872e-05, gnorm=0.709, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123847
2022-09-30 07:07:14 - progress_bar.py[line:274] - INFO: epoch 003:   6073 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.6, ups=0.88, wpb=100.9, bsz=40, num_updates=37580, lr=2.72806e-05, gnorm=0.882, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=123858
2022-09-30 07:07:25 - progress_bar.py[line:274] - INFO: epoch 003:   6083 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92, ups=0.92, wpb=100.4, bsz=40, num_updates=37590, lr=2.7274e-05, gnorm=1.029, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=123869
2022-09-30 07:07:35 - progress_bar.py[line:274] - INFO: epoch 003:   6093 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.9, ups=0.93, wpb=101.1, bsz=40, num_updates=37600, lr=2.72674e-05, gnorm=0.833, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123880
2022-09-30 07:07:47 - progress_bar.py[line:274] - INFO: epoch 003:   6103 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.1, ups=0.89, wpb=102.6, bsz=40, num_updates=37610, lr=2.72608e-05, gnorm=0.877, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123891
2022-09-30 07:07:57 - progress_bar.py[line:274] - INFO: epoch 003:   6113 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.7, ups=0.92, wpb=102.4, bsz=40, num_updates=37620, lr=2.72542e-05, gnorm=0.877, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123902
2022-09-30 07:08:09 - progress_bar.py[line:274] - INFO: epoch 003:   6123 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.3, ups=0.89, wpb=101.6, bsz=40, num_updates=37630, lr=2.72476e-05, gnorm=0.777, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123914
2022-09-30 07:08:20 - progress_bar.py[line:274] - INFO: epoch 003:   6133 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.1, ups=0.87, wpb=102.7, bsz=40, num_updates=37640, lr=2.7241e-05, gnorm=0.86, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123925
2022-09-30 07:08:32 - progress_bar.py[line:274] - INFO: epoch 003:   6143 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.89, wpb=102.1, bsz=40, num_updates=37650, lr=2.72344e-05, gnorm=0.731, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123936
2022-09-30 07:08:43 - progress_bar.py[line:274] - INFO: epoch 003:   6153 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.89, wpb=100.9, bsz=40, num_updates=37660, lr=2.72278e-05, gnorm=0.783, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123948
2022-09-30 07:08:54 - progress_bar.py[line:274] - INFO: epoch 003:   6163 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.7, ups=0.87, wpb=102.3, bsz=40, num_updates=37670, lr=2.72212e-05, gnorm=0.971, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123959
2022-09-30 07:09:06 - progress_bar.py[line:274] - INFO: epoch 003:   6173 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.5, ups=0.88, wpb=101.9, bsz=40, num_updates=37680, lr=2.72146e-05, gnorm=0.81, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123971
2022-09-30 07:09:17 - progress_bar.py[line:274] - INFO: epoch 003:   6183 / 15783 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.8, ups=0.88, wpb=103.4, bsz=40, num_updates=37690, lr=2.7208e-05, gnorm=0.786, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123982
2022-09-30 07:09:28 - progress_bar.py[line:274] - INFO: epoch 003:   6193 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.5, ups=0.91, wpb=100.2, bsz=40, num_updates=37700, lr=2.72014e-05, gnorm=0.878, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123993
2022-09-30 07:09:39 - progress_bar.py[line:274] - INFO: epoch 003:   6203 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.9, ups=0.88, wpb=100.1, bsz=40, num_updates=37710, lr=2.71948e-05, gnorm=0.809, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=124004
2022-09-30 07:09:51 - progress_bar.py[line:274] - INFO: epoch 003:   6213 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.3, ups=0.89, wpb=102.9, bsz=40, num_updates=37720, lr=2.71882e-05, gnorm=0.734, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124016
2022-09-30 07:10:02 - progress_bar.py[line:274] - INFO: epoch 003:   6223 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=103.4, nsentences=40, sample_size=103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.2, ups=0.9, wpb=103.4, bsz=40, num_updates=37730, lr=2.71816e-05, gnorm=0.835, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124027
2022-09-30 07:10:13 - progress_bar.py[line:274] - INFO: epoch 003:   6233 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.3, ups=0.9, wpb=102, bsz=40, num_updates=37740, lr=2.7175e-05, gnorm=0.835, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=124038
2022-09-30 07:10:24 - progress_bar.py[line:274] - INFO: epoch 003:   6243 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91, ups=0.9, wpb=101.1, bsz=40, num_updates=37750, lr=2.71684e-05, gnorm=0.832, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=124049
2022-09-30 07:10:35 - progress_bar.py[line:274] - INFO: epoch 003:   6253 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.91, wpb=101.4, bsz=40, num_updates=37760, lr=2.71618e-05, gnorm=0.824, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124060
2022-09-30 07:10:46 - progress_bar.py[line:274] - INFO: epoch 003:   6263 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.6, ups=0.88, wpb=100.7, bsz=40, num_updates=37770, lr=2.71552e-05, gnorm=0.887, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124071
2022-09-30 07:10:58 - progress_bar.py[line:274] - INFO: epoch 003:   6273 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.8, ups=0.88, wpb=99.8, bsz=40, num_updates=37780, lr=2.71486e-05, gnorm=0.812, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124083
2022-09-30 07:11:08 - progress_bar.py[line:274] - INFO: epoch 003:   6283 / 15783 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.4, ups=0.94, wpb=102.5, bsz=40, num_updates=37790, lr=2.7142e-05, gnorm=0.756, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124093
2022-09-30 07:11:19 - progress_bar.py[line:274] - INFO: epoch 003:   6293 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.4, ups=0.94, wpb=102.6, bsz=40, num_updates=37800, lr=2.71354e-05, gnorm=0.907, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124104
2022-09-30 07:11:30 - progress_bar.py[line:274] - INFO: epoch 003:   6303 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.2, ups=0.89, wpb=102, bsz=40, num_updates=37810, lr=2.71288e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=124115
2022-09-30 07:11:41 - progress_bar.py[line:274] - INFO: epoch 003:   6313 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.4, ups=0.91, wpb=100.9, bsz=40, num_updates=37820, lr=2.71222e-05, gnorm=0.838, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124126
2022-09-30 07:11:53 - progress_bar.py[line:274] - INFO: epoch 003:   6323 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.3, ups=0.88, wpb=100.1, bsz=40, num_updates=37830, lr=2.71156e-05, gnorm=0.86, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124138
2022-09-30 07:12:04 - progress_bar.py[line:274] - INFO: epoch 003:   6333 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=103.1, nsentences=40, sample_size=103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.9, ups=0.9, wpb=103.1, bsz=40, num_updates=37840, lr=2.7109e-05, gnorm=1.083, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=124149
2022-09-30 07:12:15 - progress_bar.py[line:274] - INFO: epoch 003:   6343 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.1, ups=0.9, wpb=102, bsz=40, num_updates=37850, lr=2.71024e-05, gnorm=0.812, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124160
2022-09-30 07:12:26 - progress_bar.py[line:274] - INFO: epoch 003:   6353 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.7, ups=0.91, wpb=101.2, bsz=40, num_updates=37860, lr=2.70958e-05, gnorm=0.868, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124171
2022-09-30 07:12:37 - progress_bar.py[line:274] - INFO: epoch 003:   6363 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.6, ups=0.91, wpb=100.4, bsz=40, num_updates=37870, lr=2.70892e-05, gnorm=0.815, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=124182
2022-09-30 07:12:48 - progress_bar.py[line:274] - INFO: epoch 003:   6373 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.5, ups=0.89, wpb=101, bsz=40, num_updates=37880, lr=2.70826e-05, gnorm=0.916, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124193
2022-09-30 07:12:59 - progress_bar.py[line:274] - INFO: epoch 003:   6383 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.3, ups=0.9, wpb=102, bsz=40, num_updates=37890, lr=2.7076e-05, gnorm=0.829, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=124204
2022-09-30 07:13:11 - progress_bar.py[line:274] - INFO: epoch 003:   6393 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.2, ups=0.89, wpb=102, bsz=40, num_updates=37900, lr=2.70694e-05, gnorm=0.87, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124215
2022-09-30 07:13:22 - progress_bar.py[line:274] - INFO: epoch 003:   6403 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.5, ups=0.89, wpb=102.7, bsz=40, num_updates=37910, lr=2.70628e-05, gnorm=0.975, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124227
2022-09-30 07:13:33 - progress_bar.py[line:274] - INFO: epoch 003:   6413 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.8, ups=0.89, wpb=101.6, bsz=40, num_updates=37920, lr=2.70562e-05, gnorm=0.838, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124238
2022-09-30 07:13:44 - progress_bar.py[line:274] - INFO: epoch 003:   6423 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=37930, lr=2.70496e-05, gnorm=0.813, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=124249
2022-09-30 07:13:55 - progress_bar.py[line:274] - INFO: epoch 003:   6433 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=37940, lr=2.7043e-05, gnorm=0.981, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124260
2022-09-30 07:14:07 - progress_bar.py[line:274] - INFO: epoch 003:   6443 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.5, ups=0.88, wpb=100.6, bsz=40, num_updates=37950, lr=2.70364e-05, gnorm=0.836, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=124271
2022-09-30 07:14:18 - progress_bar.py[line:274] - INFO: epoch 003:   6453 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.5, ups=0.9, wpb=101.3, bsz=40, num_updates=37960, lr=2.70298e-05, gnorm=0.857, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124283
2022-09-30 07:14:29 - progress_bar.py[line:274] - INFO: epoch 003:   6463 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.1, ups=0.92, wpb=102.5, bsz=40, num_updates=37970, lr=2.70232e-05, gnorm=0.83, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124293
2022-09-30 07:14:40 - progress_bar.py[line:274] - INFO: epoch 003:   6473 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.2, ups=0.89, wpb=101.2, bsz=40, num_updates=37980, lr=2.70166e-05, gnorm=0.796, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=124305
2022-09-30 07:14:51 - progress_bar.py[line:274] - INFO: epoch 003:   6483 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.8, ups=0.89, wpb=100.4, bsz=40, num_updates=37990, lr=2.701e-05, gnorm=0.778, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124316
2022-09-30 07:15:02 - progress_bar.py[line:274] - INFO: epoch 003:   6493 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=38000, lr=2.70034e-05, gnorm=0.865, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124327
2022-09-30 07:15:13 - progress_bar.py[line:274] - INFO: epoch 003:   6503 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.8, ups=0.93, wpb=101.8, bsz=40, num_updates=38010, lr=2.69968e-05, gnorm=0.738, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=124338
2022-09-30 07:15:24 - progress_bar.py[line:274] - INFO: epoch 003:   6513 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.5, ups=0.91, wpb=101.2, bsz=40, num_updates=38020, lr=2.69902e-05, gnorm=0.821, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124349
2022-09-30 07:15:35 - progress_bar.py[line:274] - INFO: epoch 003:   6523 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.2, ups=0.9, wpb=101.5, bsz=40, num_updates=38030, lr=2.69836e-05, gnorm=0.785, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=124360
2022-09-30 07:15:46 - progress_bar.py[line:274] - INFO: epoch 003:   6533 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.8, ups=0.89, wpb=102.9, bsz=40, num_updates=38040, lr=2.6977e-05, gnorm=0.831, clip=0, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124371
2022-09-30 07:15:57 - progress_bar.py[line:274] - INFO: epoch 003:   6543 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.9, ups=0.92, wpb=100.1, bsz=40, num_updates=38050, lr=2.69704e-05, gnorm=0.763, clip=10, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124382
2022-09-30 07:16:05 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 07:16:09 - progress_bar.py[line:274] - INFO: epoch 003:   6554 / 15783 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=87.8, ups=0.85, wpb=103.2, bsz=40, num_updates=38060, lr=2.69638e-05, gnorm=0.776, clip=10, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=124394
2022-09-30 07:16:20 - progress_bar.py[line:274] - INFO: epoch 003:   6564 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.1, ups=0.88, wpb=102.8, bsz=40, num_updates=38070, lr=2.69572e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=124405
2022-09-30 07:16:31 - progress_bar.py[line:274] - INFO: epoch 003:   6574 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.1, ups=0.93, wpb=102.2, bsz=40, num_updates=38080, lr=2.69506e-05, gnorm=0.856, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=124416
2022-09-30 07:16:42 - progress_bar.py[line:274] - INFO: epoch 003:   6584 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.1, ups=0.92, wpb=101.7, bsz=40, num_updates=38090, lr=2.6944e-05, gnorm=0.841, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=124427
2022-09-30 07:16:53 - progress_bar.py[line:274] - INFO: epoch 003:   6594 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.7, ups=0.89, wpb=101.3, bsz=40, num_updates=38100, lr=2.69374e-05, gnorm=0.826, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124438
2022-09-30 07:17:05 - progress_bar.py[line:274] - INFO: epoch 003:   6604 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.5, ups=0.88, wpb=100.7, bsz=40, num_updates=38110, lr=2.69308e-05, gnorm=0.918, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124449
2022-09-30 07:17:16 - progress_bar.py[line:274] - INFO: epoch 003:   6614 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=38120, lr=2.69242e-05, gnorm=0.951, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124461
2022-09-30 07:17:27 - progress_bar.py[line:274] - INFO: epoch 003:   6624 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.9, ups=0.92, wpb=102.3, bsz=40, num_updates=38130, lr=2.69176e-05, gnorm=0.867, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124472
2022-09-30 07:17:38 - progress_bar.py[line:274] - INFO: epoch 003:   6634 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92, ups=0.9, wpb=102.8, bsz=40, num_updates=38140, lr=2.6911e-05, gnorm=0.809, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124483
2022-09-30 07:17:49 - progress_bar.py[line:274] - INFO: epoch 003:   6644 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.2, ups=0.86, wpb=102.1, bsz=40, num_updates=38150, lr=2.69044e-05, gnorm=0.854, clip=20, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=124494
2022-09-30 07:18:01 - progress_bar.py[line:274] - INFO: epoch 003:   6654 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=38160, lr=2.68978e-05, gnorm=0.948, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124506
2022-09-30 07:18:12 - progress_bar.py[line:274] - INFO: epoch 003:   6664 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=38170, lr=2.68912e-05, gnorm=0.9, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=124517
2022-09-30 07:18:23 - progress_bar.py[line:274] - INFO: epoch 003:   6674 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.8, ups=0.87, wpb=100.9, bsz=40, num_updates=38180, lr=2.68846e-05, gnorm=0.875, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=124528
2022-09-30 07:18:34 - progress_bar.py[line:274] - INFO: epoch 003:   6684 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.1, ups=0.93, wpb=101.4, bsz=40, num_updates=38190, lr=2.6878e-05, gnorm=0.944, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124539
2022-09-30 07:18:46 - progress_bar.py[line:274] - INFO: epoch 003:   6694 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.9, ups=0.89, wpb=102.3, bsz=40, num_updates=38200, lr=2.68714e-05, gnorm=0.787, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124550
2022-09-30 07:18:57 - progress_bar.py[line:274] - INFO: epoch 003:   6704 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.6, ups=0.88, wpb=99.7, bsz=40, num_updates=38210, lr=2.68648e-05, gnorm=0.88, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124562
2022-09-30 07:19:08 - progress_bar.py[line:274] - INFO: epoch 003:   6714 / 15783 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.1, ups=0.91, wpb=100.4, bsz=40, num_updates=38220, lr=2.68582e-05, gnorm=0.939, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124573
2022-09-30 07:19:19 - progress_bar.py[line:274] - INFO: epoch 003:   6724 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=38230, lr=2.68516e-05, gnorm=0.893, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124584
2022-09-30 07:19:31 - progress_bar.py[line:274] - INFO: epoch 003:   6734 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.3, ups=0.88, wpb=100.4, bsz=40, num_updates=38240, lr=2.6845e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124595
2022-09-30 07:19:42 - progress_bar.py[line:274] - INFO: epoch 003:   6744 / 15783 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.7, ups=0.89, wpb=100.5, bsz=40, num_updates=38250, lr=2.68384e-05, gnorm=0.911, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124607
2022-09-30 07:19:53 - progress_bar.py[line:274] - INFO: epoch 003:   6754 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.8, ups=0.89, wpb=101.5, bsz=40, num_updates=38260, lr=2.68318e-05, gnorm=0.86, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=124618
2022-09-30 07:20:04 - progress_bar.py[line:274] - INFO: epoch 003:   6764 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.7, ups=0.89, wpb=103, bsz=40, num_updates=38270, lr=2.68252e-05, gnorm=0.775, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=124629
2022-09-30 07:20:15 - progress_bar.py[line:274] - INFO: epoch 003:   6774 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.9, ups=0.89, wpb=102, bsz=40, num_updates=38280, lr=2.68186e-05, gnorm=0.855, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=124640
2022-09-30 07:20:26 - progress_bar.py[line:274] - INFO: epoch 003:   6784 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.6, ups=0.91, wpb=102.2, bsz=40, num_updates=38290, lr=2.6812e-05, gnorm=0.802, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=124651
2022-09-30 07:20:38 - progress_bar.py[line:274] - INFO: epoch 003:   6794 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.5, ups=0.89, wpb=101.9, bsz=40, num_updates=38300, lr=2.68054e-05, gnorm=0.855, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124663
2022-09-30 07:20:49 - progress_bar.py[line:274] - INFO: epoch 003:   6804 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=38310, lr=2.67988e-05, gnorm=0.886, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124674
2022-09-30 07:21:01 - progress_bar.py[line:274] - INFO: epoch 003:   6814 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.4, ups=0.88, wpb=101.8, bsz=40, num_updates=38320, lr=2.67922e-05, gnorm=0.923, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124685
2022-09-30 07:21:12 - progress_bar.py[line:274] - INFO: epoch 003:   6824 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.7, ups=0.9, wpb=103.2, bsz=40, num_updates=38330, lr=2.67856e-05, gnorm=0.969, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=124697
2022-09-30 07:21:22 - progress_bar.py[line:274] - INFO: epoch 003:   6834 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.4, ups=0.94, wpb=100.7, bsz=40, num_updates=38340, lr=2.6779e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124707
2022-09-30 07:21:33 - progress_bar.py[line:274] - INFO: epoch 003:   6844 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.9, wpb=100.6, bsz=40, num_updates=38350, lr=2.67724e-05, gnorm=0.794, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=124718
2022-09-30 07:21:45 - progress_bar.py[line:274] - INFO: epoch 003:   6854 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.2, ups=0.89, wpb=100.4, bsz=40, num_updates=38360, lr=2.67658e-05, gnorm=0.933, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124730
2022-09-30 07:21:56 - progress_bar.py[line:274] - INFO: epoch 003:   6864 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.8, ups=0.89, wpb=99.6, bsz=40, num_updates=38370, lr=2.67592e-05, gnorm=0.843, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124741
2022-09-30 07:22:07 - progress_bar.py[line:274] - INFO: epoch 003:   6874 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92, ups=0.93, wpb=98.8, bsz=40, num_updates=38380, lr=2.67526e-05, gnorm=0.936, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=124752
2022-09-30 07:22:18 - progress_bar.py[line:274] - INFO: epoch 003:   6884 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.89, wpb=101.7, bsz=40, num_updates=38390, lr=2.6746e-05, gnorm=0.868, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=124763
2022-09-30 07:22:29 - progress_bar.py[line:274] - INFO: epoch 003:   6894 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.89, wpb=101, bsz=40, num_updates=38400, lr=2.67394e-05, gnorm=1.004, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=124774
2022-09-30 07:22:40 - progress_bar.py[line:274] - INFO: epoch 003:   6904 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.91, wpb=98.6, bsz=40, num_updates=38410, lr=2.67328e-05, gnorm=0.972, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124785
2022-09-30 07:22:51 - progress_bar.py[line:274] - INFO: epoch 003:   6914 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.6, ups=0.9, wpb=102.2, bsz=40, num_updates=38420, lr=2.67262e-05, gnorm=0.839, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124796
2022-09-30 07:23:03 - progress_bar.py[line:274] - INFO: epoch 003:   6924 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.5, ups=0.88, wpb=101.9, bsz=40, num_updates=38430, lr=2.67196e-05, gnorm=0.96, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124808
2022-09-30 07:23:14 - progress_bar.py[line:274] - INFO: epoch 003:   6934 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.1, ups=0.92, wpb=101, bsz=40, num_updates=38440, lr=2.6713e-05, gnorm=0.932, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124818
2022-09-30 07:23:25 - progress_bar.py[line:274] - INFO: epoch 003:   6944 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.1, ups=0.9, wpb=102.2, bsz=40, num_updates=38450, lr=2.67064e-05, gnorm=0.782, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124830
2022-09-30 07:23:36 - progress_bar.py[line:274] - INFO: epoch 003:   6954 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.9, wpb=101.4, bsz=40, num_updates=38460, lr=2.66998e-05, gnorm=0.909, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124841
2022-09-30 07:23:47 - progress_bar.py[line:274] - INFO: epoch 003:   6964 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.4, ups=0.89, wpb=101.5, bsz=40, num_updates=38470, lr=2.66932e-05, gnorm=0.814, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=124852
2022-09-30 07:23:58 - progress_bar.py[line:274] - INFO: epoch 003:   6974 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.9, wpb=100.1, bsz=40, num_updates=38480, lr=2.66866e-05, gnorm=0.89, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124863
2022-09-30 07:24:09 - progress_bar.py[line:274] - INFO: epoch 003:   6984 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.88, wpb=101.9, bsz=40, num_updates=38490, lr=2.668e-05, gnorm=0.869, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=124874
2022-09-30 07:24:21 - progress_bar.py[line:274] - INFO: epoch 003:   6994 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.7, ups=0.89, wpb=101.5, bsz=40, num_updates=38500, lr=2.66734e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=124885
2022-09-30 07:24:32 - progress_bar.py[line:274] - INFO: epoch 003:   7004 / 15783 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=92.1, ups=0.91, wpb=101.5, bsz=40, num_updates=38510, lr=2.66668e-05, gnorm=0.816, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124896
2022-09-30 07:24:43 - progress_bar.py[line:274] - INFO: epoch 003:   7014 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=98.8, nsentences=40, sample_size=98.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.91, wpb=98.8, bsz=40, num_updates=38520, lr=2.66602e-05, gnorm=0.953, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124907
2022-09-30 07:24:54 - progress_bar.py[line:274] - INFO: epoch 003:   7024 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.2, ups=0.88, wpb=100.2, bsz=40, num_updates=38530, lr=2.66536e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124919
2022-09-30 07:25:05 - progress_bar.py[line:274] - INFO: epoch 003:   7034 / 15783 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=87.8, ups=0.88, wpb=100.1, bsz=40, num_updates=38540, lr=2.6647e-05, gnorm=0.783, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=124930
2022-09-30 07:25:16 - progress_bar.py[line:274] - INFO: epoch 003:   7044 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.8, ups=0.92, wpb=103, bsz=40, num_updates=38550, lr=2.66404e-05, gnorm=0.791, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124941
2022-09-30 07:25:27 - progress_bar.py[line:274] - INFO: epoch 003:   7054 / 15783 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.1, ups=0.9, wpb=102.1, bsz=40, num_updates=38560, lr=2.66338e-05, gnorm=0.843, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=124952
2022-09-30 07:25:38 - progress_bar.py[line:274] - INFO: epoch 003:   7064 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91, ups=0.91, wpb=99.7, bsz=40, num_updates=38570, lr=2.66272e-05, gnorm=0.849, clip=40, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=124963
2022-09-30 07:25:43 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 07:25:50 - progress_bar.py[line:274] - INFO: epoch 003:   7075 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=83.3, ups=0.83, wpb=100.5, bsz=40, num_updates=38580, lr=2.66206e-05, gnorm=0.897, clip=30, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=124975
2022-09-30 07:26:02 - progress_bar.py[line:274] - INFO: epoch 003:   7085 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.8, ups=0.88, wpb=100.8, bsz=40, num_updates=38590, lr=2.6614e-05, gnorm=0.924, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=124987
2022-09-30 07:26:13 - progress_bar.py[line:274] - INFO: epoch 003:   7095 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.9, wpb=100.8, bsz=40, num_updates=38600, lr=2.66074e-05, gnorm=0.901, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=124998
2022-09-30 07:26:24 - progress_bar.py[line:274] - INFO: epoch 003:   7105 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.6, ups=0.9, wpb=101.3, bsz=40, num_updates=38610, lr=2.66008e-05, gnorm=0.877, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=125009
2022-09-30 07:26:35 - progress_bar.py[line:274] - INFO: epoch 003:   7115 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.5, ups=0.93, wpb=100.3, bsz=40, num_updates=38620, lr=2.65942e-05, gnorm=0.768, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125019
2022-09-30 07:26:46 - progress_bar.py[line:274] - INFO: epoch 003:   7125 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92, ups=0.89, wpb=103, bsz=40, num_updates=38630, lr=2.65876e-05, gnorm=0.715, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125031
2022-09-30 07:26:57 - progress_bar.py[line:274] - INFO: epoch 003:   7135 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.7, ups=0.9, wpb=101.6, bsz=40, num_updates=38640, lr=2.6581e-05, gnorm=0.867, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=125042
2022-09-30 07:27:08 - progress_bar.py[line:274] - INFO: epoch 003:   7145 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.9, ups=0.89, wpb=102, bsz=40, num_updates=38650, lr=2.65744e-05, gnorm=0.882, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=125053
2022-09-30 07:27:19 - progress_bar.py[line:274] - INFO: epoch 003:   7155 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.7, ups=0.9, wpb=102.4, bsz=40, num_updates=38660, lr=2.65678e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125064
2022-09-30 07:27:30 - progress_bar.py[line:274] - INFO: epoch 003:   7165 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.5, ups=0.89, wpb=103.6, bsz=40, num_updates=38670, lr=2.65612e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125075
2022-09-30 07:27:41 - progress_bar.py[line:274] - INFO: epoch 003:   7175 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.1, ups=0.92, wpb=101.9, bsz=40, num_updates=38680, lr=2.65546e-05, gnorm=0.859, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125086
2022-09-30 07:27:53 - progress_bar.py[line:274] - INFO: epoch 003:   7185 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.9, ups=0.89, wpb=99.9, bsz=40, num_updates=38690, lr=2.6548e-05, gnorm=0.796, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125097
2022-09-30 07:28:04 - progress_bar.py[line:274] - INFO: epoch 003:   7195 / 15783 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=98.3, nsentences=40, sample_size=98.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.5, ups=0.89, wpb=98.3, bsz=40, num_updates=38700, lr=2.65414e-05, gnorm=0.945, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125109
2022-09-30 07:28:15 - progress_bar.py[line:274] - INFO: epoch 003:   7205 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.9, ups=0.92, wpb=101, bsz=40, num_updates=38710, lr=2.65348e-05, gnorm=0.851, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125120
2022-09-30 07:28:26 - progress_bar.py[line:274] - INFO: epoch 003:   7215 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.9, wpb=99.5, bsz=40, num_updates=38720, lr=2.65282e-05, gnorm=0.917, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=125131
2022-09-30 07:28:37 - progress_bar.py[line:274] - INFO: epoch 003:   7225 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.7, ups=0.93, wpb=100.5, bsz=40, num_updates=38730, lr=2.65216e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125141
2022-09-30 07:28:48 - progress_bar.py[line:274] - INFO: epoch 003:   7235 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.7, ups=0.89, wpb=101.5, bsz=40, num_updates=38740, lr=2.6515e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=125153
2022-09-30 07:28:59 - progress_bar.py[line:274] - INFO: epoch 003:   7245 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.4, ups=0.89, wpb=101.4, bsz=40, num_updates=38750, lr=2.65084e-05, gnorm=0.765, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125164
2022-09-30 07:29:10 - progress_bar.py[line:274] - INFO: epoch 003:   7255 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.2, ups=0.88, wpb=100.1, bsz=40, num_updates=38760, lr=2.65018e-05, gnorm=0.872, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=125175
2022-09-30 07:29:22 - progress_bar.py[line:274] - INFO: epoch 003:   7265 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.2, ups=0.87, wpb=100.6, bsz=40, num_updates=38770, lr=2.64952e-05, gnorm=0.958, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=125187
2022-09-30 07:29:33 - progress_bar.py[line:274] - INFO: epoch 003:   7275 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.3, ups=0.89, wpb=101.2, bsz=40, num_updates=38780, lr=2.64886e-05, gnorm=0.814, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125198
2022-09-30 07:29:44 - progress_bar.py[line:274] - INFO: epoch 003:   7285 / 15783 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.6, ups=0.9, wpb=102.4, bsz=40, num_updates=38790, lr=2.6482e-05, gnorm=0.778, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125209
2022-09-30 07:29:55 - progress_bar.py[line:274] - INFO: epoch 003:   7295 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.89, wpb=101, bsz=40, num_updates=38800, lr=2.64754e-05, gnorm=0.815, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=125220
2022-09-30 07:30:07 - progress_bar.py[line:274] - INFO: epoch 003:   7305 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.88, wpb=102.5, bsz=40, num_updates=38810, lr=2.64688e-05, gnorm=0.801, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125232
2022-09-30 07:30:18 - progress_bar.py[line:274] - INFO: epoch 003:   7315 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.4, ups=0.89, wpb=100.6, bsz=40, num_updates=38820, lr=2.64622e-05, gnorm=0.806, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=125243
2022-09-30 07:30:29 - progress_bar.py[line:274] - INFO: epoch 003:   7325 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.89, wpb=101.3, bsz=40, num_updates=38830, lr=2.64556e-05, gnorm=0.869, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=125254
2022-09-30 07:30:40 - progress_bar.py[line:274] - INFO: epoch 003:   7335 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.2, ups=0.92, wpb=100, bsz=40, num_updates=38840, lr=2.6449e-05, gnorm=0.897, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125265
2022-09-30 07:30:51 - progress_bar.py[line:274] - INFO: epoch 003:   7345 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.1, ups=0.89, wpb=102.3, bsz=40, num_updates=38850, lr=2.64424e-05, gnorm=0.831, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=125276
2022-09-30 07:31:03 - progress_bar.py[line:274] - INFO: epoch 003:   7355 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.4, ups=0.89, wpb=100.7, bsz=40, num_updates=38860, lr=2.64358e-05, gnorm=0.916, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125287
2022-09-30 07:31:14 - progress_bar.py[line:274] - INFO: epoch 003:   7365 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.91, wpb=101.2, bsz=40, num_updates=38870, lr=2.64292e-05, gnorm=0.809, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125298
2022-09-30 07:31:25 - progress_bar.py[line:274] - INFO: epoch 003:   7375 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92, ups=0.9, wpb=102.2, bsz=40, num_updates=38880, lr=2.64226e-05, gnorm=0.921, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=125310
2022-09-30 07:31:36 - progress_bar.py[line:274] - INFO: epoch 003:   7385 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.9, ups=0.88, wpb=99.9, bsz=40, num_updates=38890, lr=2.6416e-05, gnorm=0.911, clip=20, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=125321
2022-09-30 07:31:47 - progress_bar.py[line:274] - INFO: epoch 003:   7395 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.3, ups=0.88, wpb=101.5, bsz=40, num_updates=38900, lr=2.64094e-05, gnorm=0.864, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125332
2022-09-30 07:31:59 - progress_bar.py[line:274] - INFO: epoch 003:   7405 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.5, ups=0.88, wpb=102.1, bsz=40, num_updates=38910, lr=2.64028e-05, gnorm=0.751, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=125344
2022-09-30 07:32:10 - progress_bar.py[line:274] - INFO: epoch 003:   7415 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.3, ups=0.88, wpb=100.3, bsz=40, num_updates=38920, lr=2.63962e-05, gnorm=0.839, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125355
2022-09-30 07:32:22 - progress_bar.py[line:274] - INFO: epoch 003:   7425 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.3, ups=0.87, wpb=99.6, bsz=40, num_updates=38930, lr=2.63896e-05, gnorm=0.882, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125367
2022-09-30 07:32:33 - progress_bar.py[line:274] - INFO: epoch 003:   7435 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.4, ups=0.91, wpb=101.1, bsz=40, num_updates=38940, lr=2.6383e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125378
2022-09-30 07:32:44 - progress_bar.py[line:274] - INFO: epoch 003:   7445 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.2, ups=0.87, wpb=101.1, bsz=40, num_updates=38950, lr=2.63764e-05, gnorm=0.854, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125389
2022-09-30 07:32:55 - progress_bar.py[line:274] - INFO: epoch 003:   7455 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.8, ups=0.9, wpb=102.9, bsz=40, num_updates=38960, lr=2.63698e-05, gnorm=0.771, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125400
2022-09-30 07:33:07 - progress_bar.py[line:274] - INFO: epoch 003:   7465 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.8, ups=0.89, wpb=101.1, bsz=40, num_updates=38970, lr=2.63632e-05, gnorm=0.91, clip=20, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=125412
2022-09-30 07:33:18 - progress_bar.py[line:274] - INFO: epoch 003:   7475 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=86.6, ups=0.86, wpb=100.8, bsz=40, num_updates=38980, lr=2.63566e-05, gnorm=0.87, clip=30, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=125423
2022-09-30 07:33:30 - progress_bar.py[line:274] - INFO: epoch 003:   7485 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.5, ups=0.9, wpb=101, bsz=40, num_updates=38990, lr=2.635e-05, gnorm=0.799, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125434
2022-09-30 07:33:41 - progress_bar.py[line:274] - INFO: epoch 003:   7495 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.9, wpb=101.7, bsz=40, num_updates=39000, lr=2.63434e-05, gnorm=0.831, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125445
2022-09-30 07:33:52 - progress_bar.py[line:274] - INFO: epoch 003:   7505 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.9, ups=0.92, wpb=102.3, bsz=40, num_updates=39010, lr=2.63368e-05, gnorm=0.757, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=125456
2022-09-30 07:34:03 - progress_bar.py[line:274] - INFO: epoch 003:   7515 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.6, ups=0.89, wpb=101.8, bsz=40, num_updates=39020, lr=2.63302e-05, gnorm=0.86, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125468
2022-09-30 07:34:14 - progress_bar.py[line:274] - INFO: epoch 003:   7525 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.9, ups=0.89, wpb=101.7, bsz=40, num_updates=39030, lr=2.63236e-05, gnorm=1.197, clip=30, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=125479
2022-09-30 07:34:25 - progress_bar.py[line:274] - INFO: epoch 003:   7535 / 15783 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.3, ups=0.88, wpb=102.6, bsz=40, num_updates=39040, lr=2.6317e-05, gnorm=0.742, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125490
2022-09-30 07:34:36 - progress_bar.py[line:274] - INFO: epoch 003:   7545 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.6, ups=0.9, wpb=101.7, bsz=40, num_updates=39050, lr=2.63104e-05, gnorm=0.789, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125501
2022-09-30 07:34:47 - progress_bar.py[line:274] - INFO: epoch 003:   7555 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.3, ups=0.92, wpb=100.3, bsz=40, num_updates=39060, lr=2.63038e-05, gnorm=0.865, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125512
2022-09-30 07:34:59 - progress_bar.py[line:274] - INFO: epoch 003:   7565 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91, ups=0.89, wpb=101.8, bsz=40, num_updates=39070, lr=2.62972e-05, gnorm=0.728, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125523
2022-09-30 07:35:09 - progress_bar.py[line:274] - INFO: epoch 003:   7575 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.2, ups=0.94, wpb=100.2, bsz=40, num_updates=39080, lr=2.62906e-05, gnorm=0.903, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=125534
2022-09-30 07:35:20 - progress_bar.py[line:274] - INFO: epoch 003:   7585 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.3, ups=0.89, wpb=100.6, bsz=40, num_updates=39090, lr=2.6284e-05, gnorm=0.929, clip=30, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125545
2022-09-30 07:35:27 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 07:35:33 - progress_bar.py[line:274] - INFO: epoch 003:   7596 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=84, ups=0.82, wpb=102.1, bsz=40, num_updates=39100, lr=2.62774e-05, gnorm=0.925, clip=40, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=125557
2022-09-30 07:35:44 - progress_bar.py[line:274] - INFO: epoch 003:   7606 / 15783 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.5, ups=0.91, wpb=100.2, bsz=40, num_updates=39110, lr=2.62708e-05, gnorm=0.826, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125568
2022-09-30 07:35:55 - progress_bar.py[line:274] - INFO: epoch 003:   7616 / 15783 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.2, ups=0.91, wpb=101.6, bsz=40, num_updates=39120, lr=2.62642e-05, gnorm=0.86, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125579
2022-09-30 07:36:06 - progress_bar.py[line:274] - INFO: epoch 003:   7626 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.5, ups=0.89, wpb=101.3, bsz=40, num_updates=39130, lr=2.62576e-05, gnorm=0.953, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=125591
2022-09-30 07:36:17 - progress_bar.py[line:274] - INFO: epoch 003:   7636 / 15783 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=92.6, ups=0.9, wpb=103.2, bsz=40, num_updates=39140, lr=2.6251e-05, gnorm=0.82, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125602
2022-09-30 07:36:28 - progress_bar.py[line:274] - INFO: epoch 003:   7646 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.8, ups=0.91, wpb=100.9, bsz=40, num_updates=39150, lr=2.62444e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125613
2022-09-30 07:36:39 - progress_bar.py[line:274] - INFO: epoch 003:   7656 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=92.7, ups=0.91, wpb=101.6, bsz=40, num_updates=39160, lr=2.62378e-05, gnorm=0.909, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125624
2022-09-30 07:36:50 - progress_bar.py[line:274] - INFO: epoch 003:   7666 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.3, ups=0.88, wpb=100.3, bsz=40, num_updates=39170, lr=2.62312e-05, gnorm=0.976, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=125635
2022-09-30 07:37:02 - progress_bar.py[line:274] - INFO: epoch 003:   7676 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.6, ups=0.89, wpb=101.8, bsz=40, num_updates=39180, lr=2.62246e-05, gnorm=0.951, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=125646
2022-09-30 07:37:13 - progress_bar.py[line:274] - INFO: epoch 003:   7686 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.8, ups=0.89, wpb=101.8, bsz=40, num_updates=39190, lr=2.6218e-05, gnorm=0.968, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125658
2022-09-30 07:37:24 - progress_bar.py[line:274] - INFO: epoch 003:   7696 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.3, ups=0.88, wpb=101.5, bsz=40, num_updates=39200, lr=2.62114e-05, gnorm=0.84, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125669
2022-09-30 07:37:35 - progress_bar.py[line:274] - INFO: epoch 003:   7706 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.6, ups=0.89, wpb=103.7, bsz=40, num_updates=39210, lr=2.62048e-05, gnorm=0.907, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125680
2022-09-30 07:37:46 - progress_bar.py[line:274] - INFO: epoch 003:   7716 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.3, ups=0.92, wpb=100.6, bsz=40, num_updates=39220, lr=2.61982e-05, gnorm=0.895, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125691
2022-09-30 07:37:57 - progress_bar.py[line:274] - INFO: epoch 003:   7726 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.9, wpb=101.4, bsz=40, num_updates=39230, lr=2.61916e-05, gnorm=0.771, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125702
2022-09-30 07:38:09 - progress_bar.py[line:274] - INFO: epoch 003:   7736 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=86.5, ups=0.87, wpb=99.6, bsz=40, num_updates=39240, lr=2.6185e-05, gnorm=0.855, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125714
2022-09-30 07:38:20 - progress_bar.py[line:274] - INFO: epoch 003:   7746 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.6, ups=0.88, wpb=100.9, bsz=40, num_updates=39250, lr=2.61784e-05, gnorm=0.823, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125725
2022-09-30 07:38:31 - progress_bar.py[line:274] - INFO: epoch 003:   7756 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=39260, lr=2.61718e-05, gnorm=0.886, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125736
2022-09-30 07:38:43 - progress_bar.py[line:274] - INFO: epoch 003:   7766 / 15783 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=93.1, ups=0.91, wpb=102.7, bsz=40, num_updates=39270, lr=2.61652e-05, gnorm=0.737, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=125747
2022-09-30 07:38:53 - progress_bar.py[line:274] - INFO: epoch 003:   7776 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=93.3, ups=0.92, wpb=101.5, bsz=40, num_updates=39280, lr=2.61586e-05, gnorm=0.878, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125758
2022-09-30 07:39:04 - progress_bar.py[line:274] - INFO: epoch 003:   7786 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.6, ups=0.9, wpb=101.5, bsz=40, num_updates=39290, lr=2.6152e-05, gnorm=0.873, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=125769
2022-09-30 07:39:16 - progress_bar.py[line:274] - INFO: epoch 003:   7796 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.89, wpb=102.6, bsz=40, num_updates=39300, lr=2.61454e-05, gnorm=0.902, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125781
2022-09-30 07:39:27 - progress_bar.py[line:274] - INFO: epoch 003:   7806 / 15783 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.88, wpb=101.6, bsz=40, num_updates=39310, lr=2.61388e-05, gnorm=1.03, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125792
2022-09-30 07:39:38 - progress_bar.py[line:274] - INFO: epoch 003:   7816 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=99.4, nsentences=40, sample_size=99.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.9, ups=0.91, wpb=99.4, bsz=40, num_updates=39320, lr=2.61322e-05, gnorm=0.87, clip=20, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=125803
2022-09-30 07:39:50 - progress_bar.py[line:274] - INFO: epoch 003:   7826 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.8, ups=0.87, wpb=102.2, bsz=40, num_updates=39330, lr=2.61256e-05, gnorm=0.857, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125814
2022-09-30 07:40:01 - progress_bar.py[line:274] - INFO: epoch 003:   7836 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=39340, lr=2.6119e-05, gnorm=0.893, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125826
2022-09-30 07:40:12 - progress_bar.py[line:274] - INFO: epoch 003:   7846 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.2, ups=0.89, wpb=100.4, bsz=40, num_updates=39350, lr=2.61124e-05, gnorm=0.767, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125837
2022-09-30 07:40:24 - progress_bar.py[line:274] - INFO: epoch 003:   7856 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.6, ups=0.88, wpb=101.2, bsz=40, num_updates=39360, lr=2.61058e-05, gnorm=0.959, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=125849
2022-09-30 07:40:35 - progress_bar.py[line:274] - INFO: epoch 003:   7866 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91, ups=0.9, wpb=100.9, bsz=40, num_updates=39370, lr=2.60992e-05, gnorm=0.827, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=125860
2022-09-30 07:40:46 - progress_bar.py[line:274] - INFO: epoch 003:   7876 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.3, ups=0.89, wpb=101.2, bsz=40, num_updates=39380, lr=2.60926e-05, gnorm=0.937, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=125871
2022-09-30 07:40:57 - progress_bar.py[line:274] - INFO: epoch 003:   7886 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.1, ups=0.88, wpb=102.5, bsz=40, num_updates=39390, lr=2.6086e-05, gnorm=0.908, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=125882
2022-09-30 07:41:09 - progress_bar.py[line:274] - INFO: epoch 003:   7896 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.4, ups=0.89, wpb=101.4, bsz=40, num_updates=39400, lr=2.60794e-05, gnorm=0.857, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125893
2022-09-30 07:41:20 - progress_bar.py[line:274] - INFO: epoch 003:   7906 / 15783 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88, ups=0.88, wpb=100.3, bsz=40, num_updates=39410, lr=2.60728e-05, gnorm=0.959, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125905
2022-09-30 07:41:31 - progress_bar.py[line:274] - INFO: epoch 003:   7916 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.7, ups=0.89, wpb=101.6, bsz=40, num_updates=39420, lr=2.60662e-05, gnorm=0.837, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=125916
2022-09-30 07:41:43 - progress_bar.py[line:274] - INFO: epoch 003:   7926 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.6, ups=0.87, wpb=100.8, bsz=40, num_updates=39430, lr=2.60596e-05, gnorm=0.866, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125928
2022-09-30 07:41:54 - progress_bar.py[line:274] - INFO: epoch 003:   7936 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.8, ups=0.89, wpb=101.7, bsz=40, num_updates=39440, lr=2.6053e-05, gnorm=0.795, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125939
2022-09-30 07:42:05 - progress_bar.py[line:274] - INFO: epoch 003:   7946 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.4, ups=0.89, wpb=100.3, bsz=40, num_updates=39450, lr=2.60464e-05, gnorm=0.827, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=125950
2022-09-30 07:42:16 - progress_bar.py[line:274] - INFO: epoch 003:   7956 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.89, wpb=102.1, bsz=40, num_updates=39460, lr=2.60398e-05, gnorm=0.891, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125961
2022-09-30 07:42:27 - progress_bar.py[line:274] - INFO: epoch 003:   7966 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.9, wpb=99.6, bsz=40, num_updates=39470, lr=2.60332e-05, gnorm=0.813, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=125972
2022-09-30 07:42:38 - progress_bar.py[line:274] - INFO: epoch 003:   7976 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.7, ups=0.92, wpb=101.9, bsz=40, num_updates=39480, lr=2.60266e-05, gnorm=0.873, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=125983
2022-09-30 07:42:50 - progress_bar.py[line:274] - INFO: epoch 003:   7986 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88, ups=0.89, wpb=98.6, bsz=40, num_updates=39490, lr=2.602e-05, gnorm=0.863, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=125994
2022-09-30 07:43:01 - progress_bar.py[line:274] - INFO: epoch 003:   7996 / 15783 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=90.2, ups=0.88, wpb=102.8, bsz=40, num_updates=39500, lr=2.60134e-05, gnorm=0.831, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126006
2022-09-30 07:43:12 - progress_bar.py[line:274] - INFO: epoch 003:   8006 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.89, wpb=102.3, bsz=40, num_updates=39510, lr=2.60068e-05, gnorm=0.976, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126017
2022-09-30 07:43:24 - progress_bar.py[line:274] - INFO: epoch 003:   8016 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.1, ups=0.88, wpb=102.4, bsz=40, num_updates=39520, lr=2.60002e-05, gnorm=0.801, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126028
2022-09-30 07:43:35 - progress_bar.py[line:274] - INFO: epoch 003:   8026 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.3, ups=0.89, wpb=101.4, bsz=40, num_updates=39530, lr=2.59936e-05, gnorm=0.89, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=126040
2022-09-30 07:43:46 - progress_bar.py[line:274] - INFO: epoch 003:   8036 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.9, ups=0.91, wpb=101.7, bsz=40, num_updates=39540, lr=2.5987e-05, gnorm=0.852, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126051
2022-09-30 07:43:57 - progress_bar.py[line:274] - INFO: epoch 003:   8046 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.7, ups=0.89, wpb=101.6, bsz=40, num_updates=39550, lr=2.59804e-05, gnorm=0.844, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=126062
2022-09-30 07:44:08 - progress_bar.py[line:274] - INFO: epoch 003:   8056 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.89, wpb=100.9, bsz=40, num_updates=39560, lr=2.59738e-05, gnorm=0.901, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126073
2022-09-30 07:44:19 - progress_bar.py[line:274] - INFO: epoch 003:   8066 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.91, wpb=100.8, bsz=40, num_updates=39570, lr=2.59672e-05, gnorm=0.952, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126084
2022-09-30 07:44:30 - progress_bar.py[line:274] - INFO: epoch 003:   8076 / 15783 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.4, ups=0.89, wpb=100.4, bsz=40, num_updates=39580, lr=2.59606e-05, gnorm=0.935, clip=50, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126095
2022-09-30 07:44:42 - progress_bar.py[line:274] - INFO: epoch 003:   8086 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=99.6, nsentences=40, sample_size=99.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=87.9, ups=0.88, wpb=99.6, bsz=40, num_updates=39590, lr=2.5954e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126107
2022-09-30 07:44:53 - progress_bar.py[line:274] - INFO: epoch 003:   8096 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=39600, lr=2.59474e-05, gnorm=0.759, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126118
2022-09-30 07:45:04 - progress_bar.py[line:274] - INFO: epoch 003:   8106 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.2, ups=0.89, wpb=101.2, bsz=40, num_updates=39610, lr=2.59408e-05, gnorm=0.87, clip=20, loss_scale=2048, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=126129
2022-09-30 07:45:15 - progress_bar.py[line:274] - INFO: epoch 003:   8116 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=39620, lr=2.59342e-05, gnorm=0.819, clip=10, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126140
2022-09-30 07:45:27 - progress_bar.py[line:274] - INFO: epoch 003:   8126 / 15783 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=89.8, ups=0.88, wpb=101.7, bsz=40, num_updates=39630, lr=2.59276e-05, gnorm=0.908, clip=40, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126152
2022-09-30 07:45:38 - progress_bar.py[line:274] - INFO: epoch 003:   8136 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.9, ups=0.9, wpb=100.7, bsz=40, num_updates=39640, lr=2.5921e-05, gnorm=0.848, clip=10, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126163
2022-09-30 07:45:39 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 07:45:50 - progress_bar.py[line:274] - INFO: epoch 003:   8147 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=82.1, ups=0.81, wpb=101.9, bsz=40, num_updates=39650, lr=2.59144e-05, gnorm=0.951, clip=40, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=126175
2022-09-30 07:46:02 - progress_bar.py[line:274] - INFO: epoch 003:   8157 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=98.6, nsentences=40, sample_size=98.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=87.9, ups=0.89, wpb=98.6, bsz=40, num_updates=39660, lr=2.59078e-05, gnorm=0.962, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=126186
2022-09-30 07:46:13 - progress_bar.py[line:274] - INFO: epoch 003:   8167 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.89, wpb=101.9, bsz=40, num_updates=39670, lr=2.59012e-05, gnorm=0.801, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=126198
2022-09-30 07:46:23 - progress_bar.py[line:274] - INFO: epoch 003:   8177 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.5, ups=0.94, wpb=101.9, bsz=40, num_updates=39680, lr=2.58946e-05, gnorm=0.95, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126208
2022-09-30 07:46:34 - progress_bar.py[line:274] - INFO: epoch 003:   8187 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.8, ups=0.93, wpb=101.2, bsz=40, num_updates=39690, lr=2.5888e-05, gnorm=0.929, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126219
2022-09-30 07:46:46 - progress_bar.py[line:274] - INFO: epoch 003:   8197 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.5, ups=0.87, wpb=102.1, bsz=40, num_updates=39700, lr=2.58814e-05, gnorm=0.922, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126231
2022-09-30 07:46:57 - progress_bar.py[line:274] - INFO: epoch 003:   8207 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.89, wpb=102.8, bsz=40, num_updates=39710, lr=2.58748e-05, gnorm=0.874, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126242
2022-09-30 07:47:08 - progress_bar.py[line:274] - INFO: epoch 003:   8217 / 15783 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.9, wpb=100.1, bsz=40, num_updates=39720, lr=2.58682e-05, gnorm=0.958, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126253
2022-09-30 07:47:19 - progress_bar.py[line:274] - INFO: epoch 003:   8227 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.6, ups=0.91, wpb=100.6, bsz=40, num_updates=39730, lr=2.58616e-05, gnorm=0.82, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=126264
2022-09-30 07:47:30 - progress_bar.py[line:274] - INFO: epoch 003:   8237 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.6, ups=0.91, wpb=101.4, bsz=40, num_updates=39740, lr=2.5855e-05, gnorm=0.803, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126275
2022-09-30 07:47:41 - progress_bar.py[line:274] - INFO: epoch 003:   8247 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.5, ups=0.88, wpb=101, bsz=40, num_updates=39750, lr=2.58484e-05, gnorm=0.935, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126286
2022-09-30 07:47:53 - progress_bar.py[line:274] - INFO: epoch 003:   8257 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.2, ups=0.87, wpb=100, bsz=40, num_updates=39760, lr=2.58418e-05, gnorm=0.839, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126298
2022-09-30 07:48:04 - progress_bar.py[line:274] - INFO: epoch 003:   8267 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89, ups=0.89, wpb=99.8, bsz=40, num_updates=39770, lr=2.58352e-05, gnorm=0.872, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126309
2022-09-30 07:48:15 - progress_bar.py[line:274] - INFO: epoch 003:   8277 / 15783 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.5, ups=0.9, wpb=102.6, bsz=40, num_updates=39780, lr=2.58286e-05, gnorm=0.863, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126320
2022-09-30 07:48:26 - progress_bar.py[line:274] - INFO: epoch 003:   8287 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.6, ups=0.91, wpb=101, bsz=40, num_updates=39790, lr=2.5822e-05, gnorm=0.844, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=126331
2022-09-30 07:48:37 - progress_bar.py[line:274] - INFO: epoch 003:   8297 / 15783 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.7, ups=0.91, wpb=102.2, bsz=40, num_updates=39800, lr=2.58154e-05, gnorm=0.887, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126342
2022-09-30 07:48:48 - progress_bar.py[line:274] - INFO: epoch 003:   8307 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92, ups=0.9, wpb=102.1, bsz=40, num_updates=39810, lr=2.58088e-05, gnorm=0.82, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126353
2022-09-30 07:49:00 - progress_bar.py[line:274] - INFO: epoch 003:   8317 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.2, ups=0.9, wpb=101.4, bsz=40, num_updates=39820, lr=2.58022e-05, gnorm=0.926, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126364
2022-09-30 07:49:11 - progress_bar.py[line:274] - INFO: epoch 003:   8327 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.1, ups=0.9, wpb=102.3, bsz=40, num_updates=39830, lr=2.57956e-05, gnorm=0.812, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126375
2022-09-30 07:49:22 - progress_bar.py[line:274] - INFO: epoch 003:   8337 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.88, wpb=102.8, bsz=40, num_updates=39840, lr=2.5789e-05, gnorm=0.89, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=126387
2022-09-30 07:49:33 - progress_bar.py[line:274] - INFO: epoch 003:   8347 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.5, ups=0.89, wpb=102.7, bsz=40, num_updates=39850, lr=2.57824e-05, gnorm=0.829, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126398
2022-09-30 07:49:44 - progress_bar.py[line:274] - INFO: epoch 003:   8357 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.9, ups=0.9, wpb=101.8, bsz=40, num_updates=39860, lr=2.57758e-05, gnorm=0.972, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126409
2022-09-30 07:49:55 - progress_bar.py[line:274] - INFO: epoch 003:   8367 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90.5, ups=0.9, wpb=100.2, bsz=40, num_updates=39870, lr=2.57692e-05, gnorm=1, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126420
2022-09-30 07:50:07 - progress_bar.py[line:274] - INFO: epoch 003:   8377 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.1, ups=0.88, wpb=100.7, bsz=40, num_updates=39880, lr=2.57626e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126432
2022-09-30 07:50:18 - progress_bar.py[line:274] - INFO: epoch 003:   8387 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.88, wpb=102.4, bsz=40, num_updates=39890, lr=2.5756e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126443
2022-09-30 07:50:29 - progress_bar.py[line:274] - INFO: epoch 003:   8397 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.3, ups=0.89, wpb=102, bsz=40, num_updates=39900, lr=2.57494e-05, gnorm=0.707, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=126454
2022-09-30 07:50:40 - progress_bar.py[line:274] - INFO: epoch 003:   8407 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.5, ups=0.93, wpb=100.5, bsz=40, num_updates=39910, lr=2.57428e-05, gnorm=0.87, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126465
2022-09-30 07:50:51 - progress_bar.py[line:274] - INFO: epoch 003:   8417 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.7, ups=0.9, wpb=99.9, bsz=40, num_updates=39920, lr=2.57362e-05, gnorm=0.906, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126476
2022-09-30 07:51:02 - progress_bar.py[line:274] - INFO: epoch 003:   8427 / 15783 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.5, ups=0.91, wpb=101.9, bsz=40, num_updates=39930, lr=2.57296e-05, gnorm=0.717, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126487
2022-09-30 07:51:14 - progress_bar.py[line:274] - INFO: epoch 003:   8437 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=103.9, nsentences=40, sample_size=103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.8, ups=0.88, wpb=103.9, bsz=40, num_updates=39940, lr=2.5723e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126499
2022-09-30 07:51:25 - progress_bar.py[line:274] - INFO: epoch 003:   8447 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.6, ups=0.88, wpb=99.8, bsz=40, num_updates=39950, lr=2.57164e-05, gnorm=0.877, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126510
2022-09-30 07:51:37 - progress_bar.py[line:274] - INFO: epoch 003:   8457 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.5, ups=0.86, wpb=100.3, bsz=40, num_updates=39960, lr=2.57098e-05, gnorm=0.916, clip=30, loss_scale=1024, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=126522
2022-09-30 07:51:48 - progress_bar.py[line:274] - INFO: epoch 003:   8467 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.8, ups=0.89, wpb=103.3, bsz=40, num_updates=39970, lr=2.57032e-05, gnorm=0.866, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=126533
2022-09-30 07:51:59 - progress_bar.py[line:274] - INFO: epoch 003:   8477 / 15783 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=91.2, ups=0.9, wpb=101.7, bsz=40, num_updates=39980, lr=2.56966e-05, gnorm=0.691, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126544
2022-09-30 07:52:10 - progress_bar.py[line:274] - INFO: epoch 003:   8487 / 15783 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=89.4, ups=0.88, wpb=101.2, bsz=40, num_updates=39990, lr=2.569e-05, gnorm=0.816, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126555
2022-09-30 07:52:21 - progress_bar.py[line:274] - INFO: epoch 003:   8497 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.1, ups=0.93, wpb=100.1, bsz=40, num_updates=40000, lr=2.56834e-05, gnorm=0.838, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126566
2022-09-30 07:52:32 - progress_bar.py[line:274] - INFO: epoch 003:   8507 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.7, ups=0.89, wpb=100.7, bsz=40, num_updates=40010, lr=2.56768e-05, gnorm=0.776, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=126577
2022-09-30 07:52:44 - progress_bar.py[line:274] - INFO: epoch 003:   8517 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.9, wpb=101.9, bsz=40, num_updates=40020, lr=2.56702e-05, gnorm=0.808, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=126588
2022-09-30 07:52:55 - progress_bar.py[line:274] - INFO: epoch 003:   8527 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90, ups=0.89, wpb=101.1, bsz=40, num_updates=40030, lr=2.56636e-05, gnorm=0.872, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=126600
2022-09-30 07:53:06 - progress_bar.py[line:274] - INFO: epoch 003:   8537 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.9, ups=0.89, wpb=102.6, bsz=40, num_updates=40040, lr=2.5657e-05, gnorm=0.821, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126611
2022-09-30 07:53:17 - progress_bar.py[line:274] - INFO: epoch 003:   8547 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.3, ups=0.9, wpb=101.5, bsz=40, num_updates=40050, lr=2.56504e-05, gnorm=0.849, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=126622
2022-09-30 07:53:28 - progress_bar.py[line:274] - INFO: epoch 003:   8557 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.7, ups=0.91, wpb=99.9, bsz=40, num_updates=40060, lr=2.56438e-05, gnorm=0.902, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=126633
2022-09-30 07:53:40 - progress_bar.py[line:274] - INFO: epoch 003:   8567 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.8, ups=0.88, wpb=100.8, bsz=40, num_updates=40070, lr=2.56372e-05, gnorm=0.883, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=126644
2022-09-30 07:53:51 - progress_bar.py[line:274] - INFO: epoch 003:   8577 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.7, ups=0.9, wpb=102.1, bsz=40, num_updates=40080, lr=2.56306e-05, gnorm=0.88, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126656
2022-09-30 07:54:01 - progress_bar.py[line:274] - INFO: epoch 003:   8587 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.1, ups=0.94, wpb=100.5, bsz=40, num_updates=40090, lr=2.5624e-05, gnorm=0.905, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126666
2022-09-30 07:54:13 - progress_bar.py[line:274] - INFO: epoch 003:   8597 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.6, ups=0.87, wpb=102.6, bsz=40, num_updates=40100, lr=2.56174e-05, gnorm=0.792, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126678
2022-09-30 07:54:24 - progress_bar.py[line:274] - INFO: epoch 003:   8607 / 15783 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=89.5, ups=0.88, wpb=101.9, bsz=40, num_updates=40110, lr=2.56108e-05, gnorm=0.744, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126689
2022-09-30 07:54:35 - progress_bar.py[line:274] - INFO: epoch 003:   8617 / 15783 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=91.3, ups=0.9, wpb=101.5, bsz=40, num_updates=40120, lr=2.56042e-05, gnorm=0.765, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=126700
2022-09-30 07:54:47 - progress_bar.py[line:274] - INFO: epoch 003:   8627 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.89, wpb=101.4, bsz=40, num_updates=40130, lr=2.55976e-05, gnorm=0.899, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126711
2022-09-30 07:54:57 - progress_bar.py[line:274] - INFO: epoch 003:   8637 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.1, ups=0.94, wpb=102.7, bsz=40, num_updates=40140, lr=2.5591e-05, gnorm=0.947, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126722
2022-09-30 07:55:09 - progress_bar.py[line:274] - INFO: epoch 003:   8647 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.4, ups=0.88, wpb=102.2, bsz=40, num_updates=40150, lr=2.55844e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126733
2022-09-30 07:55:20 - progress_bar.py[line:274] - INFO: epoch 003:   8657 / 15783 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=103.7, nsentences=40, sample_size=103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=89.7, ups=0.87, wpb=103.7, bsz=40, num_updates=40160, lr=2.55778e-05, gnorm=0.829, clip=30, loss_scale=2048, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=126745
2022-09-30 07:55:22 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 07:55:33 - progress_bar.py[line:274] - INFO: epoch 003:   8668 / 15783 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=99.2, nsentences=40, sample_size=99.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=78.7, ups=0.79, wpb=99.2, bsz=40, num_updates=40170, lr=2.55712e-05, gnorm=0.937, clip=40, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=126758
2022-09-30 07:55:44 - progress_bar.py[line:274] - INFO: epoch 003:   8678 / 15783 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=103.8, nsentences=40, sample_size=103.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.2, ups=0.89, wpb=103.8, bsz=40, num_updates=40180, lr=2.55646e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126769
2022-09-30 07:55:55 - progress_bar.py[line:274] - INFO: epoch 003:   8688 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94, ups=0.93, wpb=100.6, bsz=40, num_updates=40190, lr=2.5558e-05, gnorm=0.943, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126780
2022-09-30 07:56:06 - progress_bar.py[line:274] - INFO: epoch 003:   8698 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.3, ups=0.9, wpb=100.5, bsz=40, num_updates=40200, lr=2.55514e-05, gnorm=1.026, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=126791
2022-09-30 07:56:17 - progress_bar.py[line:274] - INFO: epoch 003:   8708 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.9, ups=0.88, wpb=100.1, bsz=40, num_updates=40210, lr=2.55448e-05, gnorm=0.968, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126802
2022-09-30 07:56:28 - progress_bar.py[line:274] - INFO: epoch 003:   8718 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.8, ups=0.91, wpb=101.1, bsz=40, num_updates=40220, lr=2.55382e-05, gnorm=0.893, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126813
2022-09-30 07:56:39 - progress_bar.py[line:274] - INFO: epoch 003:   8728 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.7, ups=0.9, wpb=101.3, bsz=40, num_updates=40230, lr=2.55316e-05, gnorm=0.904, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126824
2022-09-30 07:56:51 - progress_bar.py[line:274] - INFO: epoch 003:   8738 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.5, ups=0.89, wpb=100.9, bsz=40, num_updates=40240, lr=2.5525e-05, gnorm=0.92, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126836
2022-09-30 07:57:02 - progress_bar.py[line:274] - INFO: epoch 003:   8748 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.9, ups=0.87, wpb=101.4, bsz=40, num_updates=40250, lr=2.55184e-05, gnorm=0.876, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126847
2022-09-30 07:57:14 - progress_bar.py[line:274] - INFO: epoch 003:   8758 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.2, ups=0.89, wpb=102.8, bsz=40, num_updates=40260, lr=2.55118e-05, gnorm=0.899, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126858
2022-09-30 07:57:25 - progress_bar.py[line:274] - INFO: epoch 003:   8768 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.89, wpb=101, bsz=40, num_updates=40270, lr=2.55052e-05, gnorm=0.993, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126870
2022-09-30 07:57:36 - progress_bar.py[line:274] - INFO: epoch 003:   8778 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.9, ups=0.88, wpb=100.5, bsz=40, num_updates=40280, lr=2.54986e-05, gnorm=0.882, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=126881
2022-09-30 07:57:47 - progress_bar.py[line:274] - INFO: epoch 003:   8788 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=91.4, ups=0.91, wpb=100.1, bsz=40, num_updates=40290, lr=2.5492e-05, gnorm=0.915, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126892
2022-09-30 07:57:58 - progress_bar.py[line:274] - INFO: epoch 003:   8798 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.6, ups=0.89, wpb=99.9, bsz=40, num_updates=40300, lr=2.54854e-05, gnorm=0.944, clip=50, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=126903
2022-09-30 07:58:09 - progress_bar.py[line:274] - INFO: epoch 003:   8808 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.2, ups=0.91, wpb=101.3, bsz=40, num_updates=40310, lr=2.54788e-05, gnorm=0.955, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=126914
2022-09-30 07:58:21 - progress_bar.py[line:274] - INFO: epoch 003:   8818 / 15783 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.7, ups=0.88, wpb=101.4, bsz=40, num_updates=40320, lr=2.54722e-05, gnorm=0.788, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=126926
2022-09-30 07:58:32 - progress_bar.py[line:274] - INFO: epoch 003:   8828 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.8, ups=0.91, wpb=102.5, bsz=40, num_updates=40330, lr=2.54656e-05, gnorm=0.813, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126937
2022-09-30 07:58:43 - progress_bar.py[line:274] - INFO: epoch 003:   8838 / 15783 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.1, ups=0.86, wpb=102.1, bsz=40, num_updates=40340, lr=2.5459e-05, gnorm=0.897, clip=30, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=126948
2022-09-30 07:58:54 - progress_bar.py[line:274] - INFO: epoch 003:   8848 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.1, ups=0.93, wpb=100.3, bsz=40, num_updates=40350, lr=2.54524e-05, gnorm=1.001, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=126959
2022-09-30 07:59:05 - progress_bar.py[line:274] - INFO: epoch 003:   8858 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.4, ups=0.9, wpb=101.2, bsz=40, num_updates=40360, lr=2.54458e-05, gnorm=0.88, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126970
2022-09-30 07:59:16 - progress_bar.py[line:274] - INFO: epoch 003:   8868 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.4, ups=0.9, wpb=102.2, bsz=40, num_updates=40370, lr=2.54392e-05, gnorm=0.849, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=126981
2022-09-30 07:59:28 - progress_bar.py[line:274] - INFO: epoch 003:   8878 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.2, ups=0.88, wpb=100.8, bsz=40, num_updates=40380, lr=2.54326e-05, gnorm=0.883, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=126993
2022-09-30 07:59:39 - progress_bar.py[line:274] - INFO: epoch 003:   8888 / 15783 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=99.8, nsentences=40, sample_size=99.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.9, wpb=99.8, bsz=40, num_updates=40390, lr=2.5426e-05, gnorm=0.829, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=127004
2022-09-30 07:59:50 - progress_bar.py[line:274] - INFO: epoch 003:   8898 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.89, wpb=100.8, bsz=40, num_updates=40400, lr=2.54194e-05, gnorm=0.9, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127015
2022-09-30 08:00:01 - progress_bar.py[line:274] - INFO: epoch 003:   8908 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.2, ups=0.88, wpb=101.7, bsz=40, num_updates=40410, lr=2.54128e-05, gnorm=0.82, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127026
2022-09-30 08:00:13 - progress_bar.py[line:274] - INFO: epoch 003:   8918 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.4, ups=0.88, wpb=100.8, bsz=40, num_updates=40420, lr=2.54062e-05, gnorm=0.912, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127038
2022-09-30 08:00:24 - progress_bar.py[line:274] - INFO: epoch 003:   8928 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=91.7, ups=0.91, wpb=100.9, bsz=40, num_updates=40430, lr=2.53996e-05, gnorm=0.867, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=127049
2022-09-30 08:00:35 - progress_bar.py[line:274] - INFO: epoch 003:   8938 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.4, ups=0.89, wpb=100.9, bsz=40, num_updates=40440, lr=2.5393e-05, gnorm=0.817, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127060
2022-09-30 08:00:47 - progress_bar.py[line:274] - INFO: epoch 003:   8948 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.88, wpb=102, bsz=40, num_updates=40450, lr=2.53864e-05, gnorm=0.908, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127071
2022-09-30 08:00:58 - progress_bar.py[line:274] - INFO: epoch 003:   8958 / 15783 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.1, ups=0.88, wpb=100.2, bsz=40, num_updates=40460, lr=2.53798e-05, gnorm=0.949, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127083
2022-09-30 08:01:09 - progress_bar.py[line:274] - INFO: epoch 003:   8968 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=40470, lr=2.53732e-05, gnorm=0.924, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=127094
2022-09-30 08:01:20 - progress_bar.py[line:274] - INFO: epoch 003:   8978 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.8, ups=0.9, wpb=101.5, bsz=40, num_updates=40480, lr=2.53666e-05, gnorm=0.809, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127105
2022-09-30 08:01:31 - progress_bar.py[line:274] - INFO: epoch 003:   8988 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.2, ups=0.89, wpb=99.3, bsz=40, num_updates=40490, lr=2.536e-05, gnorm=0.936, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127116
2022-09-30 08:01:43 - progress_bar.py[line:274] - INFO: epoch 003:   8998 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.5, ups=0.88, wpb=102.7, bsz=40, num_updates=40500, lr=2.53534e-05, gnorm=0.816, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=127128
2022-09-30 08:01:54 - progress_bar.py[line:274] - INFO: epoch 003:   9008 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.1, ups=0.88, wpb=101.6, bsz=40, num_updates=40510, lr=2.53468e-05, gnorm=0.815, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=127139
2022-09-30 08:02:06 - progress_bar.py[line:274] - INFO: epoch 003:   9018 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.3, ups=0.89, wpb=100.5, bsz=40, num_updates=40520, lr=2.53402e-05, gnorm=0.891, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127150
2022-09-30 08:02:17 - progress_bar.py[line:274] - INFO: epoch 003:   9028 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=103, nsentences=40, sample_size=103, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.7, ups=0.86, wpb=103, bsz=40, num_updates=40530, lr=2.53336e-05, gnorm=0.992, clip=50, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=127162
2022-09-30 08:02:28 - progress_bar.py[line:274] - INFO: epoch 003:   9038 / 15783 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.5, ups=0.91, wpb=101.9, bsz=40, num_updates=40540, lr=2.5327e-05, gnorm=0.817, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127173
2022-09-30 08:02:39 - progress_bar.py[line:274] - INFO: epoch 003:   9048 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.7, ups=0.92, wpb=101, bsz=40, num_updates=40550, lr=2.53204e-05, gnorm=0.862, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=127184
2022-09-30 08:02:50 - progress_bar.py[line:274] - INFO: epoch 003:   9058 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.5, ups=0.91, wpb=100.8, bsz=40, num_updates=40560, lr=2.53138e-05, gnorm=0.974, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127195
2022-09-30 08:03:01 - progress_bar.py[line:274] - INFO: epoch 003:   9068 / 15783 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=99.5, nsentences=40, sample_size=99.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.7, ups=0.89, wpb=99.5, bsz=40, num_updates=40570, lr=2.53072e-05, gnorm=0.968, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127206
2022-09-30 08:03:13 - progress_bar.py[line:274] - INFO: epoch 003:   9078 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.1, ups=0.89, wpb=101.9, bsz=40, num_updates=40580, lr=2.53006e-05, gnorm=0.809, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127217
2022-09-30 08:03:24 - progress_bar.py[line:274] - INFO: epoch 003:   9088 / 15783 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=92.3, ups=0.91, wpb=101.1, bsz=40, num_updates=40590, lr=2.5294e-05, gnorm=0.905, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=127228
2022-09-30 08:03:35 - progress_bar.py[line:274] - INFO: epoch 003:   9098 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88, ups=0.88, wpb=100.1, bsz=40, num_updates=40600, lr=2.52874e-05, gnorm=0.839, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127240
2022-09-30 08:03:46 - progress_bar.py[line:274] - INFO: epoch 003:   9108 / 15783 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.5, ups=0.9, wpb=99.7, bsz=40, num_updates=40610, lr=2.52808e-05, gnorm=0.92, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127251
2022-09-30 08:03:57 - progress_bar.py[line:274] - INFO: epoch 003:   9118 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91.2, ups=0.9, wpb=101.3, bsz=40, num_updates=40620, lr=2.52742e-05, gnorm=0.878, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127262
2022-09-30 08:04:09 - progress_bar.py[line:274] - INFO: epoch 003:   9128 / 15783 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.4, ups=0.88, wpb=100.7, bsz=40, num_updates=40630, lr=2.52676e-05, gnorm=0.812, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=127273
2022-09-30 08:04:20 - progress_bar.py[line:274] - INFO: epoch 003:   9138 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.3, ups=0.92, wpb=101.6, bsz=40, num_updates=40640, lr=2.5261e-05, gnorm=0.802, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127284
2022-09-30 08:04:31 - progress_bar.py[line:274] - INFO: epoch 003:   9148 / 15783 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.8, ups=0.89, wpb=101.3, bsz=40, num_updates=40650, lr=2.52544e-05, gnorm=0.813, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127296
2022-09-30 08:04:42 - progress_bar.py[line:274] - INFO: epoch 003:   9158 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.2, ups=0.88, wpb=101.9, bsz=40, num_updates=40660, lr=2.52478e-05, gnorm=0.836, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127307
2022-09-30 08:04:53 - progress_bar.py[line:274] - INFO: epoch 003:   9168 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.6, ups=0.91, wpb=101.2, bsz=40, num_updates=40670, lr=2.52412e-05, gnorm=0.885, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127318
2022-09-30 08:05:03 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 08:05:05 - progress_bar.py[line:274] - INFO: epoch 003:   9179 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=82.6, ups=0.81, wpb=101.5, bsz=40, num_updates=40680, lr=2.52346e-05, gnorm=0.842, clip=30, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=127330
2022-09-30 08:05:16 - progress_bar.py[line:274] - INFO: epoch 003:   9189 / 15783 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.5, ups=0.92, wpb=101.8, bsz=40, num_updates=40690, lr=2.5228e-05, gnorm=0.823, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127341
2022-09-30 08:05:28 - progress_bar.py[line:274] - INFO: epoch 003:   9199 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.9, ups=0.87, wpb=101.6, bsz=40, num_updates=40700, lr=2.52214e-05, gnorm=0.864, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127353
2022-09-30 08:05:39 - progress_bar.py[line:274] - INFO: epoch 003:   9209 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=99.9, nsentences=40, sample_size=99.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=92.4, ups=0.93, wpb=99.9, bsz=40, num_updates=40710, lr=2.52148e-05, gnorm=0.907, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127363
2022-09-30 08:05:50 - progress_bar.py[line:274] - INFO: epoch 003:   9219 / 15783 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=92.5, ups=0.89, wpb=104.4, bsz=40, num_updates=40720, lr=2.52082e-05, gnorm=0.747, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127375
2022-09-30 08:06:01 - progress_bar.py[line:274] - INFO: epoch 003:   9229 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.4, ups=0.87, wpb=100.3, bsz=40, num_updates=40730, lr=2.52016e-05, gnorm=0.976, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127386
2022-09-30 08:06:13 - progress_bar.py[line:274] - INFO: epoch 003:   9239 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.6, ups=0.87, wpb=100.1, bsz=40, num_updates=40740, lr=2.5195e-05, gnorm=0.992, clip=50, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=127398
2022-09-30 08:06:24 - progress_bar.py[line:274] - INFO: epoch 003:   9249 / 15783 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.9, ups=0.87, wpb=101.6, bsz=40, num_updates=40750, lr=2.51884e-05, gnorm=0.876, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127409
2022-09-30 08:06:35 - progress_bar.py[line:274] - INFO: epoch 003:   9259 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.1, ups=0.91, wpb=102.4, bsz=40, num_updates=40760, lr=2.51818e-05, gnorm=0.836, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127420
2022-09-30 08:06:47 - progress_bar.py[line:274] - INFO: epoch 003:   9269 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.2, ups=0.88, wpb=101.9, bsz=40, num_updates=40770, lr=2.51752e-05, gnorm=0.788, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127432
2022-09-30 08:06:58 - progress_bar.py[line:274] - INFO: epoch 003:   9279 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.87, wpb=102.4, bsz=40, num_updates=40780, lr=2.51686e-05, gnorm=0.952, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127443
2022-09-30 08:07:09 - progress_bar.py[line:274] - INFO: epoch 003:   9289 / 15783 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.6, ups=0.91, wpb=98.9, bsz=40, num_updates=40790, lr=2.5162e-05, gnorm=1, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127454
2022-09-30 08:07:20 - progress_bar.py[line:274] - INFO: epoch 003:   9299 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.1, ups=0.91, wpb=102.7, bsz=40, num_updates=40800, lr=2.51554e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=127465
2022-09-30 08:07:31 - progress_bar.py[line:274] - INFO: epoch 003:   9309 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92, ups=0.9, wpb=102.5, bsz=40, num_updates=40810, lr=2.51488e-05, gnorm=0.826, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127476
2022-09-30 08:07:42 - progress_bar.py[line:274] - INFO: epoch 003:   9319 / 15783 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.7, ups=0.94, wpb=100.9, bsz=40, num_updates=40820, lr=2.51422e-05, gnorm=0.845, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127487
2022-09-30 08:07:53 - progress_bar.py[line:274] - INFO: epoch 003:   9329 / 15783 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.7, ups=0.91, wpb=102.2, bsz=40, num_updates=40830, lr=2.51356e-05, gnorm=0.811, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127498
2022-09-30 08:08:04 - progress_bar.py[line:274] - INFO: epoch 003:   9339 / 15783 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.7, ups=0.89, wpb=101.7, bsz=40, num_updates=40840, lr=2.5129e-05, gnorm=0.912, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127509
2022-09-30 08:08:16 - progress_bar.py[line:274] - INFO: epoch 003:   9349 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.2, ups=0.86, wpb=102.1, bsz=40, num_updates=40850, lr=2.51224e-05, gnorm=0.926, clip=30, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=127521
2022-09-30 08:08:27 - progress_bar.py[line:274] - INFO: epoch 003:   9359 / 15783 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.6, ups=0.88, wpb=100.2, bsz=40, num_updates=40860, lr=2.51158e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127532
2022-09-30 08:08:38 - progress_bar.py[line:274] - INFO: epoch 003:   9369 / 15783 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=98.7, nsentences=40, sample_size=98.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=88.8, ups=0.9, wpb=98.7, bsz=40, num_updates=40870, lr=2.51092e-05, gnorm=0.892, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127543
2022-09-30 08:08:50 - progress_bar.py[line:274] - INFO: epoch 003:   9379 / 15783 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.3, ups=0.9, wpb=102.8, bsz=40, num_updates=40880, lr=2.51026e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127554
2022-09-30 08:09:01 - progress_bar.py[line:274] - INFO: epoch 003:   9389 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.6, ups=0.89, wpb=102.3, bsz=40, num_updates=40890, lr=2.5096e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127566
2022-09-30 08:09:12 - progress_bar.py[line:274] - INFO: epoch 003:   9399 / 15783 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=93, ups=0.91, wpb=102.2, bsz=40, num_updates=40900, lr=2.50894e-05, gnorm=0.776, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=127577
2022-09-30 08:09:23 - progress_bar.py[line:274] - INFO: epoch 003:   9409 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.1, ups=0.89, wpb=101.3, bsz=40, num_updates=40910, lr=2.50828e-05, gnorm=0.935, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127588
2022-09-30 08:09:34 - progress_bar.py[line:274] - INFO: epoch 003:   9419 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90, ups=0.89, wpb=101.3, bsz=40, num_updates=40920, lr=2.50762e-05, gnorm=0.832, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127599
2022-09-30 08:09:46 - progress_bar.py[line:274] - INFO: epoch 003:   9429 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.1, ups=0.88, wpb=100.7, bsz=40, num_updates=40930, lr=2.50696e-05, gnorm=0.955, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=127611
2022-09-30 08:09:57 - progress_bar.py[line:274] - INFO: epoch 003:   9439 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.3, ups=0.91, wpb=101.1, bsz=40, num_updates=40940, lr=2.5063e-05, gnorm=0.912, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127622
2022-09-30 08:10:08 - progress_bar.py[line:274] - INFO: epoch 003:   9449 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.4, ups=0.9, wpb=99.7, bsz=40, num_updates=40950, lr=2.50564e-05, gnorm=0.819, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127633
2022-09-30 08:10:19 - progress_bar.py[line:274] - INFO: epoch 003:   9459 / 15783 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.9, ups=0.89, wpb=101.5, bsz=40, num_updates=40960, lr=2.50498e-05, gnorm=0.929, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127644
2022-09-30 08:10:30 - progress_bar.py[line:274] - INFO: epoch 003:   9469 / 15783 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=90.4, ups=0.9, wpb=100, bsz=40, num_updates=40970, lr=2.50432e-05, gnorm=0.887, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127655
2022-09-30 08:10:42 - progress_bar.py[line:274] - INFO: epoch 003:   9479 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.1, ups=0.89, wpb=100.4, bsz=40, num_updates=40980, lr=2.50366e-05, gnorm=0.857, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127666
2022-09-30 08:10:53 - progress_bar.py[line:274] - INFO: epoch 003:   9489 / 15783 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=89.9, ups=0.9, wpb=100.3, bsz=40, num_updates=40990, lr=2.503e-05, gnorm=0.67, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127678
2022-09-30 08:11:04 - progress_bar.py[line:274] - INFO: epoch 003:   9499 / 15783 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=103.3, nsentences=40, sample_size=103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.2, ups=0.91, wpb=103.3, bsz=40, num_updates=41000, lr=2.50234e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127688
2022-09-30 08:11:15 - progress_bar.py[line:274] - INFO: epoch 003:   9509 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.7, ups=0.88, wpb=100.8, bsz=40, num_updates=41010, lr=2.50168e-05, gnorm=0.868, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127700
2022-09-30 08:11:26 - progress_bar.py[line:274] - INFO: epoch 003:   9519 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.1, ups=0.88, wpb=100.5, bsz=40, num_updates=41020, lr=2.50102e-05, gnorm=0.856, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=127711
2022-09-30 08:11:38 - progress_bar.py[line:274] - INFO: epoch 003:   9529 / 15783 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=104.4, nsentences=40, sample_size=104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.3, ups=0.88, wpb=104.4, bsz=40, num_updates=41030, lr=2.50036e-05, gnorm=1.001, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127723
2022-09-30 08:11:49 - progress_bar.py[line:274] - INFO: epoch 003:   9539 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.9, ups=0.9, wpb=101.4, bsz=40, num_updates=41040, lr=2.4997e-05, gnorm=0.906, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127734
2022-09-30 08:12:01 - progress_bar.py[line:274] - INFO: epoch 003:   9549 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=87.9, ups=0.88, wpb=100.3, bsz=40, num_updates=41050, lr=2.49904e-05, gnorm=0.855, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127745
2022-09-30 08:12:12 - progress_bar.py[line:274] - INFO: epoch 003:   9559 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.1, ups=0.9, wpb=99.7, bsz=40, num_updates=41060, lr=2.49838e-05, gnorm=0.91, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127756
2022-09-30 08:12:23 - progress_bar.py[line:274] - INFO: epoch 003:   9569 / 15783 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.8, ups=0.89, wpb=102.5, bsz=40, num_updates=41070, lr=2.49772e-05, gnorm=0.813, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=127768
2022-09-30 08:12:34 - progress_bar.py[line:274] - INFO: epoch 003:   9579 / 15783 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88, ups=0.87, wpb=100.8, bsz=40, num_updates=41080, lr=2.49706e-05, gnorm=0.939, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127779
2022-09-30 08:12:46 - progress_bar.py[line:274] - INFO: epoch 003:   9589 / 15783 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.3, ups=0.9, wpb=101.8, bsz=40, num_updates=41090, lr=2.4964e-05, gnorm=0.917, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127790
2022-09-30 08:12:57 - progress_bar.py[line:274] - INFO: epoch 003:   9599 / 15783 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.1, nsentences=40, sample_size=102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.4, ups=0.89, wpb=102.1, bsz=40, num_updates=41100, lr=2.49574e-05, gnorm=0.979, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127802
2022-09-30 08:13:08 - progress_bar.py[line:274] - INFO: epoch 003:   9609 / 15783 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=92.4, ups=0.9, wpb=102.7, bsz=40, num_updates=41110, lr=2.49508e-05, gnorm=0.923, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=127813
2022-09-30 08:13:19 - progress_bar.py[line:274] - INFO: epoch 003:   9619 / 15783 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=102.8, nsentences=40, sample_size=102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=92.3, ups=0.9, wpb=102.8, bsz=40, num_updates=41120, lr=2.49442e-05, gnorm=0.771, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=127824
2022-09-30 08:13:30 - progress_bar.py[line:274] - INFO: epoch 003:   9629 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.6, ups=0.91, wpb=101.9, bsz=40, num_updates=41130, lr=2.49376e-05, gnorm=0.967, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127835
2022-09-30 08:13:41 - progress_bar.py[line:274] - INFO: epoch 003:   9639 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.9, ups=0.91, wpb=101.9, bsz=40, num_updates=41140, lr=2.4931e-05, gnorm=0.836, clip=0, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=127846
2022-09-30 08:13:53 - progress_bar.py[line:274] - INFO: epoch 003:   9649 / 15783 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.5, ups=0.89, wpb=102, bsz=40, num_updates=41150, lr=2.49244e-05, gnorm=0.792, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127858
2022-09-30 08:14:04 - progress_bar.py[line:274] - INFO: epoch 003:   9659 / 15783 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.3, ups=0.89, wpb=102.7, bsz=40, num_updates=41160, lr=2.49178e-05, gnorm=0.875, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127869
2022-09-30 08:14:15 - progress_bar.py[line:274] - INFO: epoch 003:   9669 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.9, ups=0.87, wpb=101.7, bsz=40, num_updates=41170, lr=2.49112e-05, gnorm=0.843, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127880
2022-09-30 08:14:27 - progress_bar.py[line:274] - INFO: epoch 003:   9679 / 15783 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=91.6, ups=0.89, wpb=102.5, bsz=40, num_updates=41180, lr=2.49046e-05, gnorm=0.817, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127891
2022-09-30 08:14:38 - progress_bar.py[line:274] - INFO: epoch 003:   9689 / 15783 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.8, ups=0.91, wpb=102.7, bsz=40, num_updates=41190, lr=2.4898e-05, gnorm=0.937, clip=50, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127902
2022-09-30 08:14:48 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 08:14:50 - progress_bar.py[line:274] - INFO: epoch 003:   9700 / 15783 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=104.6, nsentences=40, sample_size=104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=84.1, ups=0.8, wpb=104.6, bsz=40, num_updates=41200, lr=2.48914e-05, gnorm=0.756, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=127915
2022-09-30 08:15:01 - progress_bar.py[line:274] - INFO: epoch 003:   9710 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.6, ups=0.9, wpb=102.3, bsz=40, num_updates=41210, lr=2.48848e-05, gnorm=0.957, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127926
2022-09-30 08:15:12 - progress_bar.py[line:274] - INFO: epoch 003:   9720 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.9, ups=0.93, wpb=102.5, bsz=40, num_updates=41220, lr=2.48782e-05, gnorm=0.983, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127937
2022-09-30 08:15:23 - progress_bar.py[line:274] - INFO: epoch 003:   9730 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.6, ups=0.88, wpb=100.6, bsz=40, num_updates=41230, lr=2.48716e-05, gnorm=0.932, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=127948
2022-09-30 08:15:35 - progress_bar.py[line:274] - INFO: epoch 003:   9740 / 15783 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=88.4, ups=0.89, wpb=99.3, bsz=40, num_updates=41240, lr=2.4865e-05, gnorm=0.885, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127959
2022-09-30 08:15:46 - progress_bar.py[line:274] - INFO: epoch 003:   9750 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.4, ups=0.91, wpb=101.7, bsz=40, num_updates=41250, lr=2.48584e-05, gnorm=0.748, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127970
2022-09-30 08:15:57 - progress_bar.py[line:274] - INFO: epoch 003:   9760 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.9, ups=0.91, wpb=101.8, bsz=40, num_updates=41260, lr=2.48518e-05, gnorm=0.797, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127981
2022-09-30 08:16:08 - progress_bar.py[line:274] - INFO: epoch 003:   9770 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.6, ups=0.89, wpb=101.8, bsz=40, num_updates=41270, lr=2.48452e-05, gnorm=0.859, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127993
2022-09-30 08:16:19 - progress_bar.py[line:274] - INFO: epoch 003:   9780 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.5, ups=0.9, wpb=101.6, bsz=40, num_updates=41280, lr=2.48386e-05, gnorm=0.92, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=128004
2022-09-30 08:16:30 - progress_bar.py[line:274] - INFO: epoch 003:   9790 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93.4, ups=0.93, wpb=100.2, bsz=40, num_updates=41290, lr=2.4832e-05, gnorm=0.899, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=128014
2022-09-30 08:16:41 - progress_bar.py[line:274] - INFO: epoch 003:   9800 / 15783 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.7, ups=0.89, wpb=102, bsz=40, num_updates=41300, lr=2.48254e-05, gnorm=0.842, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128026
2022-09-30 08:16:52 - progress_bar.py[line:274] - INFO: epoch 003:   9810 / 15783 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.8, ups=0.9, wpb=100.2, bsz=40, num_updates=41310, lr=2.48188e-05, gnorm=0.906, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128037
2022-09-30 08:17:03 - progress_bar.py[line:274] - INFO: epoch 003:   9820 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.2, ups=0.89, wpb=101.1, bsz=40, num_updates=41320, lr=2.48122e-05, gnorm=0.889, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128048
2022-09-30 08:17:15 - progress_bar.py[line:274] - INFO: epoch 003:   9830 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.9, ups=0.88, wpb=102.4, bsz=40, num_updates=41330, lr=2.48056e-05, gnorm=0.791, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128059
2022-09-30 08:17:25 - progress_bar.py[line:274] - INFO: epoch 003:   9840 / 15783 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=94.4, ups=0.92, wpb=102.7, bsz=40, num_updates=41340, lr=2.4799e-05, gnorm=0.806, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128070
2022-09-30 08:17:37 - progress_bar.py[line:274] - INFO: epoch 003:   9850 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.5, ups=0.88, wpb=101.6, bsz=40, num_updates=41350, lr=2.47924e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128082
2022-09-30 08:17:48 - progress_bar.py[line:274] - INFO: epoch 003:   9860 / 15783 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=98.9, nsentences=40, sample_size=98.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=87.9, ups=0.89, wpb=98.9, bsz=40, num_updates=41360, lr=2.47858e-05, gnorm=1.006, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128093
2022-09-30 08:17:59 - progress_bar.py[line:274] - INFO: epoch 003:   9870 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=99.7, nsentences=40, sample_size=99.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.92, wpb=99.7, bsz=40, num_updates=41370, lr=2.47792e-05, gnorm=0.904, clip=20, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=128104
2022-09-30 08:18:11 - progress_bar.py[line:274] - INFO: epoch 003:   9880 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101.9, nsentences=40, sample_size=101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.4, ups=0.87, wpb=101.9, bsz=40, num_updates=41380, lr=2.47726e-05, gnorm=0.836, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128115
2022-09-30 08:18:22 - progress_bar.py[line:274] - INFO: epoch 003:   9890 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=102.4, nsentences=40, sample_size=102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.3, ups=0.9, wpb=102.4, bsz=40, num_updates=41390, lr=2.4766e-05, gnorm=0.84, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128126
2022-09-30 08:18:33 - progress_bar.py[line:274] - INFO: epoch 003:   9900 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.9, ups=0.9, wpb=102, bsz=40, num_updates=41400, lr=2.47594e-05, gnorm=0.873, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=128138
2022-09-30 08:18:44 - progress_bar.py[line:274] - INFO: epoch 003:   9910 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.9, ups=0.88, wpb=100, bsz=40, num_updates=41410, lr=2.47528e-05, gnorm=0.943, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128149
2022-09-30 08:18:55 - progress_bar.py[line:274] - INFO: epoch 003:   9920 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=91, ups=0.89, wpb=101.8, bsz=40, num_updates=41420, lr=2.47462e-05, gnorm=1.041, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128160
2022-09-30 08:19:06 - progress_bar.py[line:274] - INFO: epoch 003:   9930 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.1, nsentences=40, sample_size=100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.9, wpb=100.1, bsz=40, num_updates=41430, lr=2.47396e-05, gnorm=0.852, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128171
2022-09-30 08:19:17 - progress_bar.py[line:274] - INFO: epoch 003:   9940 / 15783 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=102.5, nsentences=40, sample_size=102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.5, ups=0.91, wpb=102.5, bsz=40, num_updates=41440, lr=2.4733e-05, gnorm=0.756, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128182
2022-09-30 08:19:29 - progress_bar.py[line:274] - INFO: epoch 003:   9950 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.9, ups=0.89, wpb=101.2, bsz=40, num_updates=41450, lr=2.47264e-05, gnorm=0.863, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128193
2022-09-30 08:19:40 - progress_bar.py[line:274] - INFO: epoch 003:   9960 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.2, ups=0.88, wpb=101.4, bsz=40, num_updates=41460, lr=2.47198e-05, gnorm=0.929, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128205
2022-09-30 08:19:51 - progress_bar.py[line:274] - INFO: epoch 003:   9970 / 15783 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=100, nsentences=40, sample_size=100, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90, ups=0.9, wpb=100, bsz=40, num_updates=41470, lr=2.47132e-05, gnorm=0.781, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128216
2022-09-30 08:20:02 - progress_bar.py[line:274] - INFO: epoch 003:   9980 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.3, nsentences=40, sample_size=101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.7, ups=0.9, wpb=101.3, bsz=40, num_updates=41480, lr=2.47066e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128227
2022-09-30 08:20:13 - progress_bar.py[line:274] - INFO: epoch 003:   9990 / 15783 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.7, ups=0.91, wpb=101.7, bsz=40, num_updates=41490, lr=2.47e-05, gnorm=0.838, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128238
2022-09-30 08:20:24 - progress_bar.py[line:274] - INFO: epoch 003:  10000 / 15783 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=104.5, nsentences=40, sample_size=104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.4, ups=0.91, wpb=104.5, bsz=40, num_updates=41500, lr=2.46934e-05, gnorm=0.823, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128249
2022-09-30 08:20:35 - progress_bar.py[line:274] - INFO: epoch 003:  10010 / 15783 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.6, ups=0.88, wpb=101.7, bsz=40, num_updates=41510, lr=2.46868e-05, gnorm=0.875, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128260
2022-09-30 08:20:47 - progress_bar.py[line:274] - INFO: epoch 003:  10020 / 15783 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=102.9, nsentences=40, sample_size=102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.9, ups=0.9, wpb=102.9, bsz=40, num_updates=41520, lr=2.46802e-05, gnorm=0.769, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128271
2022-09-30 08:20:58 - progress_bar.py[line:274] - INFO: epoch 003:  10030 / 15783 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.2, nsentences=40, sample_size=101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.3, ups=0.89, wpb=101.2, bsz=40, num_updates=41530, lr=2.46736e-05, gnorm=0.812, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128283
2022-09-30 08:21:09 - progress_bar.py[line:274] - INFO: epoch 003:  10040 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91.3, ups=0.9, wpb=101, bsz=40, num_updates=41540, lr=2.4667e-05, gnorm=0.991, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128294
2022-09-30 08:21:20 - progress_bar.py[line:274] - INFO: epoch 003:  10050 / 15783 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.5, ups=0.89, wpb=101, bsz=40, num_updates=41550, lr=2.46604e-05, gnorm=0.902, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128305
2022-09-30 08:21:31 - progress_bar.py[line:274] - INFO: epoch 003:  10060 / 15783 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=88.3, ups=0.88, wpb=100.5, bsz=40, num_updates=41560, lr=2.46538e-05, gnorm=0.869, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128316
2022-09-30 08:21:43 - progress_bar.py[line:274] - INFO: epoch 003:  10070 / 15783 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.2, ups=0.89, wpb=101.1, bsz=40, num_updates=41570, lr=2.46472e-05, gnorm=1.056, clip=30, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=128328
2022-09-30 08:21:54 - progress_bar.py[line:274] - INFO: epoch 003:  10080 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.6, ups=0.89, wpb=101.5, bsz=40, num_updates=41580, lr=2.46406e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=128339
2022-09-30 08:22:05 - progress_bar.py[line:274] - INFO: epoch 003:  10090 / 15783 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.2, ups=0.9, wpb=101.1, bsz=40, num_updates=41590, lr=2.4634e-05, gnorm=0.927, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=128350
2022-09-30 08:22:16 - progress_bar.py[line:274] - INFO: epoch 003:  10100 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93.6, ups=0.92, wpb=101.4, bsz=40, num_updates=41600, lr=2.46274e-05, gnorm=0.898, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=128361
2022-09-30 08:22:27 - progress_bar.py[line:274] - INFO: epoch 003:  10110 / 15783 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=91.7, ups=0.9, wpb=101.8, bsz=40, num_updates=41610, lr=2.46208e-05, gnorm=0.76, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=128372
2022-09-30 08:22:38 - progress_bar.py[line:274] - INFO: epoch 003:  10120 / 15783 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=100.7, nsentences=40, sample_size=100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89, ups=0.88, wpb=100.7, bsz=40, num_updates=41620, lr=2.46142e-05, gnorm=0.961, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128383
2022-09-30 08:22:50 - progress_bar.py[line:274] - INFO: epoch 003:  10130 / 15783 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=88.3, ups=0.88, wpb=100.8, bsz=40, num_updates=41630, lr=2.46076e-05, gnorm=0.805, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128394
2022-09-30 08:23:01 - progress_bar.py[line:274] - INFO: epoch 003:  10140 / 15783 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=100.5, nsentences=40, sample_size=100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=88.4, ups=0.88, wpb=100.5, bsz=40, num_updates=41640, lr=2.4601e-05, gnorm=0.84, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128406
2022-09-30 08:23:12 - progress_bar.py[line:274] - INFO: epoch 003:  10150 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.8, ups=0.89, wpb=100.9, bsz=40, num_updates=41650, lr=2.45944e-05, gnorm=0.812, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128417
2022-09-30 08:23:23 - progress_bar.py[line:274] - INFO: epoch 003:  10160 / 15783 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.2, ups=0.93, wpb=102.2, bsz=40, num_updates=41660, lr=2.45878e-05, gnorm=0.795, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128428
2022-09-30 08:23:34 - progress_bar.py[line:274] - INFO: epoch 003:  10170 / 15783 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=103.6, nsentences=40, sample_size=103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=92.4, ups=0.89, wpb=103.6, bsz=40, num_updates=41670, lr=2.45812e-05, gnorm=0.837, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128439
2022-09-30 08:23:45 - progress_bar.py[line:274] - INFO: epoch 003:  10180 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=102.7, nsentences=40, sample_size=102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93.6, ups=0.91, wpb=102.7, bsz=40, num_updates=41680, lr=2.45746e-05, gnorm=0.946, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128450
2022-09-30 08:23:56 - progress_bar.py[line:274] - INFO: epoch 003:  10190 / 15783 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=89.3, ups=0.89, wpb=100.4, bsz=40, num_updates=41690, lr=2.4568e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=128461
2022-09-30 08:24:08 - progress_bar.py[line:274] - INFO: epoch 003:  10200 / 15783 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=87.2, ups=0.87, wpb=100.2, bsz=40, num_updates=41700, lr=2.45614e-05, gnorm=1.107, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128473
2022-09-30 08:24:19 - progress_bar.py[line:274] - INFO: epoch 003:  10210 / 15783 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.5, ups=0.9, wpb=100.8, bsz=40, num_updates=41710, lr=2.45548e-05, gnorm=0.844, clip=20, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128484
2022-09-30 08:24:31 - progress_bar.py[line:274] - INFO: epoch 003:  10220 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=89.5, ups=0.88, wpb=101.7, bsz=40, num_updates=41720, lr=2.45482e-05, gnorm=0.907, clip=40, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128495
2022-09-30 08:24:42 - progress_bar.py[line:274] - INFO: epoch 003:  10230 / 15783 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=101.7, nsentences=40, sample_size=101.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.5, ups=0.9, wpb=101.7, bsz=40, num_updates=41730, lr=2.45416e-05, gnorm=0.922, clip=30, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128507
2022-09-30 08:24:52 - progress_bar.py[line:274] - INFO: epoch 003:  10240 / 15783 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=100.6, nsentences=40, sample_size=100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=93.5, ups=0.93, wpb=100.6, bsz=40, num_updates=41740, lr=2.4535e-05, gnorm=0.952, clip=30, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=128517
2022-09-30 08:25:04 - progress_bar.py[line:274] - INFO: epoch 003:  10250 / 15783 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=101.8, nsentences=40, sample_size=101.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89.5, ups=0.88, wpb=101.8, bsz=40, num_updates=41750, lr=2.45284e-05, gnorm=0.757, clip=10, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128529
2022-09-30 08:25:15 - progress_bar.py[line:274] - INFO: epoch 003:  10260 / 15783 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=91.9, ups=0.9, wpb=102.2, bsz=40, num_updates=41760, lr=2.45218e-05, gnorm=0.957, clip=40, loss_scale=2048, train_wall=11, gb_free=9.6, ema_decay=0.9999, wall=128540
2022-09-30 08:25:19 - trainer.py[line:930] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-09-30 08:25:27 - progress_bar.py[line:274] - INFO: epoch 003:  10271 / 15783 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=102, nsentences=40, sample_size=102, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=84, ups=0.82, wpb=102, bsz=40, num_updates=41770, lr=2.45152e-05, gnorm=0.856, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=128552
2022-09-30 08:25:39 - progress_bar.py[line:274] - INFO: epoch 003:  10281 / 15783 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=100.2, nsentences=40, sample_size=100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=86.8, ups=0.87, wpb=100.2, bsz=40, num_updates=41780, lr=2.45086e-05, gnorm=0.936, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128563
2022-09-30 08:25:50 - progress_bar.py[line:274] - INFO: epoch 003:  10291 / 15783 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=102.2, nsentences=40, sample_size=102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=90.3, ups=0.88, wpb=102.2, bsz=40, num_updates=41790, lr=2.4502e-05, gnorm=0.975, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128575
2022-09-30 08:26:01 - progress_bar.py[line:274] - INFO: epoch 003:  10301 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=87.5, ups=0.87, wpb=100.4, bsz=40, num_updates=41800, lr=2.44954e-05, gnorm=0.904, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128586
2022-09-30 08:26:12 - progress_bar.py[line:274] - INFO: epoch 003:  10311 / 15783 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=91.9, ups=0.91, wpb=100.8, bsz=40, num_updates=41810, lr=2.44888e-05, gnorm=0.841, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128597
2022-09-30 08:26:24 - progress_bar.py[line:274] - INFO: epoch 003:  10321 / 15783 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=99.3, nsentences=40, sample_size=99.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.3, ups=0.9, wpb=99.3, bsz=40, num_updates=41820, lr=2.44822e-05, gnorm=0.9, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=128608
2022-09-30 08:26:35 - progress_bar.py[line:274] - INFO: epoch 003:  10331 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=90.2, ups=0.88, wpb=102.3, bsz=40, num_updates=41830, lr=2.44756e-05, gnorm=0.868, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128620
2022-09-30 08:26:46 - progress_bar.py[line:274] - INFO: epoch 003:  10341 / 15783 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=91.1, ups=0.9, wpb=101.5, bsz=40, num_updates=41840, lr=2.4469e-05, gnorm=0.897, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128631
2022-09-30 08:26:58 - progress_bar.py[line:274] - INFO: epoch 003:  10351 / 15783 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=100.9, nsentences=40, sample_size=100.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=87.4, ups=0.87, wpb=100.9, bsz=40, num_updates=41850, lr=2.44624e-05, gnorm=0.894, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128642
2022-09-30 08:27:09 - progress_bar.py[line:274] - INFO: epoch 003:  10361 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=101.6, nsentences=40, sample_size=101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=89.2, ups=0.88, wpb=101.6, bsz=40, num_updates=41860, lr=2.44558e-05, gnorm=0.917, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128654
2022-09-30 08:27:20 - progress_bar.py[line:274] - INFO: epoch 003:  10371 / 15783 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=103.2, nsentences=40, sample_size=103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.7, ups=0.88, wpb=103.2, bsz=40, num_updates=41870, lr=2.44492e-05, gnorm=0.943, clip=40, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=128665
2022-09-30 08:27:31 - progress_bar.py[line:274] - INFO: epoch 003:  10381 / 15783 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=99, nsentences=40, sample_size=99, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.4, ups=0.95, wpb=99, bsz=40, num_updates=41880, lr=2.44426e-05, gnorm=1.015, clip=50, loss_scale=1024, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=128676
2022-09-30 08:27:42 - progress_bar.py[line:274] - INFO: epoch 003:  10391 / 15783 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=92.1, ups=0.9, wpb=102.3, bsz=40, num_updates=41890, lr=2.4436e-05, gnorm=0.914, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128687
2022-09-30 08:27:54 - progress_bar.py[line:274] - INFO: epoch 003:  10401 / 15783 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=100.4, nsentences=40, sample_size=100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.2, ups=0.89, wpb=100.4, bsz=40, num_updates=41900, lr=2.44294e-05, gnorm=0.943, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128698
2022-09-30 08:28:05 - progress_bar.py[line:274] - INFO: epoch 003:  10411 / 15783 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=102.3, nsentences=40, sample_size=102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.9, ups=0.88, wpb=102.3, bsz=40, num_updates=41910, lr=2.44228e-05, gnorm=0.907, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128710
2022-09-30 08:28:17 - progress_bar.py[line:274] - INFO: epoch 003:  10421 / 15783 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=86.8, ups=0.86, wpb=101.1, bsz=40, num_updates=41920, lr=2.44162e-05, gnorm=0.952, clip=30, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=128722
2022-09-30 08:28:27 - progress_bar.py[line:274] - INFO: epoch 003:  10431 / 15783 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97, ups=0.96, wpb=101.5, bsz=40, num_updates=41930, lr=2.44096e-05, gnorm=0.798, clip=10, loss_scale=1024, train_wall=10, gb_free=11, ema_decay=0.9999, wall=128732
2022-09-30 08:28:39 - progress_bar.py[line:274] - INFO: epoch 003:  10441 / 15783 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=101.5, nsentences=40, sample_size=101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=89.1, ups=0.88, wpb=101.5, bsz=40, num_updates=41940, lr=2.4403e-05, gnorm=0.761, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128744
2022-09-30 08:28:50 - progress_bar.py[line:274] - INFO: epoch 003:  10451 / 15783 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=102.6, nsentences=40, sample_size=102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.1, ups=0.88, wpb=102.6, bsz=40, num_updates=41950, lr=2.43964e-05, gnorm=0.77, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128755
2022-09-30 08:29:01 - progress_bar.py[line:274] - INFO: epoch 003:  10461 / 15783 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=101.1, nsentences=40, sample_size=101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.1, ups=0.89, wpb=101.1, bsz=40, num_updates=41960, lr=2.43898e-05, gnorm=0.861, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128766
2022-09-30 08:29:13 - progress_bar.py[line:274] - INFO: epoch 003:  10471 / 15783 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=100.8, nsentences=40, sample_size=100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=91, ups=0.9, wpb=100.8, bsz=40, num_updates=41970, lr=2.43832e-05, gnorm=0.942, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128777
2022-09-30 08:29:24 - progress_bar.py[line:274] - INFO: epoch 003:  10481 / 15783 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=101, nsentences=40, sample_size=101, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=90, ups=0.89, wpb=101, bsz=40, num_updates=41980, lr=2.43766e-05, gnorm=0.92, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128789
2022-09-30 08:29:35 - progress_bar.py[line:274] - INFO: epoch 003:  10491 / 15783 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=100.3, nsentences=40, sample_size=100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=88.1, ups=0.88, wpb=100.3, bsz=40, num_updates=41990, lr=2.437e-05, gnorm=0.785, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128800
2022-09-30 08:29:46 - progress_bar.py[line:274] - INFO: epoch 003:  10501 / 15783 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=101.4, nsentences=40, sample_size=101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=93, ups=0.92, wpb=101.4, bsz=40, num_updates=42000, lr=2.43634e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128811
2022-09-30 08:29:46 - train.py[line:505] - INFO: begin validation on "valid" subset
2022-09-30 08:29:47 - train.py[line:549] - INFO: 0 / 14103
2022-09-30 08:29:47 - train.py[line:551] - INFO: load:0.66 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-09-30 08:29:48 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.82 GiB (GPU 0; 39.59 GiB total capacity; 12.87 GiB already allocated; 940.19 MiB free; 36.19 GiB reserved in total by PyTorch)
2022-09-30 08:29:48 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 6            |        cudaMalloc retries: 43        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13182 MB |   16983 MB |   17158 TB |   17158 TB |
|       from large pool |   13037 MB |   16838 MB |   17152 TB |   17152 TB |
|       from small pool |     144 MB |     145 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13182 MB |   16983 MB |   17158 TB |   17158 TB |
|       from large pool |   13037 MB |   16838 MB |   17152 TB |   17152 TB |
|       from small pool |     144 MB |     145 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   37058 MB |   37058 MB |  568328 MB |  531270 MB |
|       from large pool |   36912 MB |   36912 MB |  567474 MB |  530562 MB |
|       from small pool |     146 MB |     146 MB |     854 MB |     708 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23875 MB |   27417 MB |   20934 TB |   20934 TB |
|       from large pool |   23874 MB |   27415 MB |   20927 TB |   20927 TB |
|       from small pool |       1 MB |       1 MB |       7 TB |       7 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3660    |    3684    |     912 M  |     912 M  |
|       from large pool |     564    |     585    |     269 M  |     269 M  |
|       from small pool |    3096    |    3114    |     642 M  |     642 M  |
|---------------------------------------------------------------------------|
| Active allocs         |    3660    |    3684    |     912 M  |     912 M  |
|       from large pool |     564    |     585    |     269 M  |     269 M  |
|       from small pool |    3096    |    3114    |     642 M  |     642 M  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     117    |     117    |     993    |     876    |
|       from large pool |      44    |      44    |     566    |     522    |
|       from small pool |      73    |      73    |     427    |     354    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      74    |      79    |  674951 K  |  674951 K  |
|       from large pool |      40    |      45    |  124010 K  |  124010 K  |
|       from small pool |      34    |      41    |  550941 K  |  550941 K  |
|===========================================================================|

2022-09-30 08:29:48 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-09-30 08:29:48 - trainer.py[line:1081] - WARNING: ran out of memory in validation step, retrying batch
2022-09-30 08:29:49 - trainer.py[line:1335] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.82 GiB (GPU 0; 39.59 GiB total capacity; 20.99 GiB already allocated; 3.50 GiB free; 33.61 GiB reserved in total by PyTorch)
2022-09-30 08:29:49 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 7            |        cudaMalloc retries: 44        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   21498 MB |   25300 MB |   17159 TB |   17159 TB |
|       from large pool |   21381 MB |   25182 MB |   17152 TB |   17152 TB |
|       from small pool |     116 MB |     145 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Active memory         |   21498 MB |   25300 MB |   17159 TB |   17159 TB |
|       from large pool |   21381 MB |   25182 MB |   17152 TB |   17152 TB |
|       from small pool |     116 MB |     145 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34416 MB |   37058 MB |  573460 MB |  539044 MB |
|       from large pool |   34294 MB |   36912 MB |  572606 MB |  538312 MB |
|       from small pool |     122 MB |     146 MB |     854 MB |     732 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   12917 MB |   27417 MB |   20934 TB |   20934 TB |
|       from large pool |   12912 MB |   27415 MB |   20927 TB |   20927 TB |
|       from small pool |       5 MB |       5 MB |       7 TB |       7 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3018    |    3684    |     912 M  |     912 M  |
|       from large pool |     449    |     585    |     269 M  |     269 M  |
|       from small pool |    2569    |    3114    |     642 M  |     642 M  |
|---------------------------------------------------------------------------|
| Active allocs         |    3018    |    3684    |     912 M  |     912 M  |
|       from large pool |     449    |     585    |     269 M  |     269 M  |
|       from small pool |    2569    |    3114    |     642 M  |     642 M  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     102    |     117    |     994    |     892    |
|       from large pool |      41    |      44    |     567    |     526    |
|       from small pool |      61    |      73    |     427    |     366    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     107    |     133    |  674956 K  |  674956 K  |
|       from large pool |      52    |      57    |  124010 K  |  124010 K  |
|       from small pool |      55    |      91    |  550945 K  |  550945 K  |
|===========================================================================|

2022-09-30 08:29:49 - trainer.py[line:1338] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

Traceback (most recent call last):
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 4.82 GiB (GPU 0; 39.59 GiB total capacity; 12.87 GiB already allocated; 940.19 MiB free; 36.19 GiB reserved in total by PyTorch)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 630, in <module>
    cli_main()
  File "../../train.py", line 623, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "../../train.py", line 332, in train
    cfg, trainer, task, epoch_itr, valid_subsets, end_of_epoch
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, (pred_scores, pred, sample_ids), time_info = trainer.valid_step(sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1088, in valid_step
    return self.valid_step(sample, raise_oom=True)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1089, in valid_step
    raise e
  File "/data/private/yutianyu/OFA/trainer.py", line 1073, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 293, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 4.82 GiB (GPU 0; 39.59 GiB total capacity; 20.99 GiB already allocated; 3.50 GiB free; 33.61 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/50_way/mask_val_1500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/50_way_allcand', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/50_way_allcand/1_B20_A1_E5_0.04_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=10', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=5', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=6000', '--validate-interval-updates=6000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/50_way/50_way_ans2label.pkl', '--valid-batch-size=26', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2055534
Killing subprocess 2055535
