*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2572692
Killing subprocess 2572693
Main process received SIGINT, exiting
2022-10-15 19:37:00 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-15 19:37:00 - utils.py[line:261] - INFO: Start init
2022-10-15 19:37:00 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-15 19:37:00 - utils.py[line:261] - INFO: Start init
2022-10-15 19:37:01 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-15 19:37:01 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-15 19:37:01 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-15 19:37:01 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-15 19:37:06 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_BERT_v1_data', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_BERT_v1_data', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-15 19:37:06 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-15 19:37:06 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-10-15 19:37:10 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-15 19:37:10 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-15 19:37:10 - train.py[line:119] - INFO: model: OFAModel
2022-10-15 19:37:10 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-15 19:37:10 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-15 19:37:10 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-15 19:37:11 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-15 19:37:11 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-15 19:37:11 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-15 19:37:11 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-15 19:37:11 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-15 19:37:11 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-15 19:37:11 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-15 19:37:11 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-10-15 19:37:11 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-10-15 19:37:20 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-10-15 19:37:20 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-10-15 19:37:20 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-15 19:37:20 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-10-15 19:37:20 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-10-15 19:37:20 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E0.tsv slice_id 0 row count 2045757 total row count 4091514
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E0.tsv slice_id 1 row count 2045757 total row count 4091514
2022-10-15 19:37:24 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 511440, warmup steps 20457, warmup_factor 4.8883022926137754e-05
2022-10-15 19:37:24 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-15 19:37:24 - train.py[line:312] - INFO: Start iterating over samples
Total steps 511440, warmup steps 20457, warmup_factor 4.8883022926137754e-05
2022-10-15 19:37:41 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 102288 loss=1.296, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=94.3, ups=0.85, wpb=111, bsz=40, num_updates=10, lr=2.44415e-08, gnorm=13.275, clip=100, loss_scale=128, train_wall=15, gb_free=10.6, ema_decay=0.9999, wall=30
2022-10-15 19:37:53 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 102288 loss=1.335, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=94.6, ups=0.86, wpb=110.6, bsz=40, num_updates=20, lr=4.8883e-08, gnorm=13.425, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=42
2022-10-15 19:38:04 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 102288 loss=1.348, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=96.4, ups=0.87, wpb=111.4, bsz=40, num_updates=30, lr=7.33245e-08, gnorm=14.71, clip=100, loss_scale=128, train_wall=12, gb_free=11, ema_decay=0.9999, wall=53
2022-10-15 19:38:15 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 102288 loss=1.497, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=98.3, ups=0.91, wpb=108.4, bsz=40, num_updates=40, lr=9.7766e-08, gnorm=17.395, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64
2022-10-15 19:38:26 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 102288 loss=1.318, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=99.9, ups=0.91, wpb=109.9, bsz=40, num_updates=50, lr=1.22208e-07, gnorm=13.282, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=75
2022-10-15 19:38:38 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 102288 loss=1.344, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=98.5, ups=0.88, wpb=111.8, bsz=40, num_updates=60, lr=1.46649e-07, gnorm=13.491, clip=100, loss_scale=128, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=87
2022-10-15 19:38:49 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 102288 loss=1.397, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=99.3, ups=0.91, wpb=109, bsz=40, num_updates=70, lr=1.71091e-07, gnorm=14.182, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98
2022-10-15 19:39:00 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 102288 loss=1.324, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=80, lr=1.95532e-07, gnorm=13.164, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=109
2022-10-15 19:39:11 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 102288 loss=1.446, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=93.6, ups=0.85, wpb=109.5, bsz=40, num_updates=90, lr=2.19974e-07, gnorm=14.205, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=120
2022-10-15 19:39:23 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 102288 loss=1.306, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=100, lr=2.44415e-07, gnorm=13.208, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132
2022-10-15 19:39:34 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 102288 loss=1.342, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=96.1, ups=0.88, wpb=109.6, bsz=40, num_updates=110, lr=2.68857e-07, gnorm=13.788, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=143
2022-10-15 19:39:45 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 102288 loss=1.173, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=99.8, ups=0.89, wpb=112.2, bsz=40, num_updates=120, lr=2.93298e-07, gnorm=11.496, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=154
2022-10-15 19:39:57 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 102288 loss=1.236, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=130, lr=3.1774e-07, gnorm=12.619, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=165
2022-10-15 19:40:08 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 102288 loss=1.244, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=98.4, ups=0.9, wpb=108.8, bsz=40, num_updates=140, lr=3.42181e-07, gnorm=10.224, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=177
2022-10-15 19:40:19 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 102288 loss=1.219, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=150, lr=3.66623e-07, gnorm=10.403, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=188
2022-10-15 19:40:30 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 102288 loss=1.215, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=160, lr=3.91064e-07, gnorm=9.473, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=199
2022-10-15 19:40:41 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 102288 loss=1.134, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=170, lr=4.15506e-07, gnorm=8.696, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=210
2022-10-15 19:40:52 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 102288 loss=1.168, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=180, lr=4.39947e-07, gnorm=9.041, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=221
2022-10-15 19:41:03 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 102288 loss=0.992, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=190, lr=4.64389e-07, gnorm=7.65, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=232
2022-10-15 19:41:15 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 102288 loss=1.024, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=200, lr=4.8883e-07, gnorm=7.529, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=244
2022-10-15 19:41:26 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 102288 loss=1.025, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=210, lr=5.13272e-07, gnorm=6.951, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=255
2022-10-15 19:41:37 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 102288 loss=1.065, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=96, ups=0.87, wpb=110.8, bsz=40, num_updates=220, lr=5.37713e-07, gnorm=7.119, clip=100, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=266
2022-10-15 19:41:49 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 102288 loss=0.978, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=95.1, ups=0.87, wpb=109.1, bsz=40, num_updates=230, lr=5.62155e-07, gnorm=6.331, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=278
2022-10-15 19:42:00 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 102288 loss=0.986, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=95.7, ups=0.87, wpb=110.1, bsz=40, num_updates=240, lr=5.86596e-07, gnorm=5.789, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=289
2022-10-15 19:42:11 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 102288 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=250, lr=6.11038e-07, gnorm=5.702, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=300
2022-10-15 19:42:23 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 102288 loss=0.904, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=260, lr=6.35479e-07, gnorm=5.549, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=312
2022-10-15 19:42:34 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 102288 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=95.8, ups=0.87, wpb=110.2, bsz=40, num_updates=270, lr=6.59921e-07, gnorm=5.458, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=323
2022-10-15 19:42:45 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 102288 loss=1.003, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=280, lr=6.84362e-07, gnorm=5.869, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=334
2022-10-15 19:42:56 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 102288 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=97.6, ups=0.89, wpb=109.6, bsz=40, num_updates=290, lr=7.08804e-07, gnorm=5.302, clip=100, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=345
2022-10-15 19:43:07 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 102288 loss=0.925, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=300, lr=7.33245e-07, gnorm=4.944, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=356
2022-10-15 19:43:19 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 102288 loss=0.859, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=310, lr=7.57687e-07, gnorm=4.275, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=368
2022-10-15 19:43:30 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 102288 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=99.2, ups=0.9, wpb=110.3, bsz=40, num_updates=320, lr=7.82128e-07, gnorm=4.519, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=379
2022-10-15 19:43:41 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 102288 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=100.1, ups=0.92, wpb=109.3, bsz=40, num_updates=330, lr=8.0657e-07, gnorm=4.493, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=390
2022-10-15 19:43:52 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 102288 loss=0.875, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=340, lr=8.31011e-07, gnorm=4.236, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=401
2022-10-15 19:44:03 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 102288 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=98, ups=0.89, wpb=110.3, bsz=40, num_updates=350, lr=8.55453e-07, gnorm=4.129, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=412
2022-10-15 19:44:14 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 102288 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=360, lr=8.79894e-07, gnorm=3.998, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=423
2022-10-15 19:44:25 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 102288 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=370, lr=9.04336e-07, gnorm=3.783, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=434
2022-10-15 19:44:37 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 102288 loss=0.852, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=380, lr=9.28777e-07, gnorm=3.631, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=446
2022-10-15 19:44:48 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 102288 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=97, ups=0.87, wpb=111.4, bsz=40, num_updates=390, lr=9.53219e-07, gnorm=3.674, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=457
2022-10-15 19:44:59 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 102288 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=400, lr=9.7766e-07, gnorm=3.832, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=468
2022-10-15 19:45:10 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 102288 loss=0.874, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=410, lr=1.0021e-06, gnorm=3.559, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=479
2022-10-15 19:45:22 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 102288 loss=0.861, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=420, lr=1.02654e-06, gnorm=3.787, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=491
2022-10-15 19:45:33 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 102288 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=430, lr=1.05098e-06, gnorm=3.384, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=502
2022-10-15 19:45:44 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 102288 loss=0.837, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=440, lr=1.07543e-06, gnorm=3.032, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=513
2022-10-15 19:45:55 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 102288 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=450, lr=1.09987e-06, gnorm=3.342, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=524
2022-10-15 19:46:06 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 102288 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=101.6, ups=0.92, wpb=109.9, bsz=40, num_updates=460, lr=1.12431e-06, gnorm=3.141, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=535
2022-10-15 19:46:17 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 102288 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=97, ups=0.89, wpb=108.9, bsz=40, num_updates=470, lr=1.14875e-06, gnorm=3.106, clip=100, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=546
2022-10-15 19:46:28 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 102288 loss=0.816, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=480, lr=1.17319e-06, gnorm=3.089, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=557
2022-10-15 19:46:40 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 102288 loss=0.817, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=490, lr=1.19763e-06, gnorm=2.8, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=569
2022-10-15 19:46:50 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 102288 loss=0.834, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=105.1, ups=0.95, wpb=110.2, bsz=40, num_updates=500, lr=1.22208e-06, gnorm=2.869, clip=100, loss_scale=128, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=579
2022-10-15 19:47:01 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 102288 loss=0.815, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=510, lr=1.24652e-06, gnorm=2.587, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=590
2022-10-15 19:47:12 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 102288 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=520, lr=1.27096e-06, gnorm=2.588, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=601
2022-10-15 19:47:24 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 102288 loss=0.842, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=97.1, ups=0.89, wpb=109.5, bsz=40, num_updates=530, lr=1.2954e-06, gnorm=2.894, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=613
2022-10-15 19:47:35 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 102288 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=540, lr=1.31984e-06, gnorm=2.659, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=624
2022-10-15 19:47:46 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 102288 loss=0.821, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=100.8, ups=0.92, wpb=109.6, bsz=40, num_updates=550, lr=1.34428e-06, gnorm=2.553, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=635
2022-10-15 19:47:57 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 102288 loss=0.827, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=560, lr=1.36872e-06, gnorm=2.466, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=646
2022-10-15 19:48:08 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 102288 loss=0.813, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=98.9, ups=0.89, wpb=110.7, bsz=40, num_updates=570, lr=1.39317e-06, gnorm=2.386, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=657
2022-10-15 19:48:19 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 102288 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=580, lr=1.41761e-06, gnorm=2.514, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=668
2022-10-15 19:48:31 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 102288 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=590, lr=1.44205e-06, gnorm=2.423, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=680
2022-10-15 19:48:42 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 102288 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=101.8, ups=0.92, wpb=111.2, bsz=40, num_updates=600, lr=1.46649e-06, gnorm=2.479, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=691
2022-10-15 19:48:53 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 102288 loss=0.819, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=99.1, ups=0.9, wpb=109.9, bsz=40, num_updates=610, lr=1.49093e-06, gnorm=2.466, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=702
2022-10-15 19:49:04 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 102288 loss=0.821, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=95.9, ups=0.88, wpb=109.3, bsz=40, num_updates=620, lr=1.51537e-06, gnorm=2.273, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=713
2022-10-15 19:49:15 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=102.9, ups=0.92, wpb=111.4, bsz=40, num_updates=630, lr=1.53982e-06, gnorm=2.166, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=724
2022-10-15 19:49:26 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 102288 loss=0.827, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=101.3, ups=0.92, wpb=110.6, bsz=40, num_updates=640, lr=1.56426e-06, gnorm=2.344, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=735
2022-10-15 19:49:37 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 102288 loss=0.799, loss_v1=0, loss_v2=0, nll_loss=0.731, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=650, lr=1.5887e-06, gnorm=2.309, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=746
2022-10-15 19:49:48 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 102288 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.68, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=660, lr=1.61314e-06, gnorm=2.083, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=757
2022-10-15 19:49:59 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 102288 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=99.5, ups=0.91, wpb=109.2, bsz=40, num_updates=670, lr=1.63758e-06, gnorm=2.431, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=768
2022-10-15 19:50:11 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 102288 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98.4, ups=0.89, wpb=111.2, bsz=40, num_updates=680, lr=1.66202e-06, gnorm=2.266, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=780
2022-10-15 19:50:22 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 102288 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=98.7, ups=0.9, wpb=109.7, bsz=40, num_updates=690, lr=1.68646e-06, gnorm=2.192, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=791
2022-10-15 19:50:33 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.1, ups=0.89, wpb=111.2, bsz=40, num_updates=700, lr=1.71091e-06, gnorm=2.245, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=802
2022-10-15 19:50:44 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 102288 loss=0.813, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=710, lr=1.73535e-06, gnorm=1.982, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=813
2022-10-15 19:50:56 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 102288 loss=0.85, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=720, lr=1.75979e-06, gnorm=2.123, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=825
2022-10-15 19:51:07 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 102288 loss=0.842, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=730, lr=1.78423e-06, gnorm=2.209, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=836
2022-10-15 19:51:18 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 102288 loss=0.857, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=96.2, ups=0.88, wpb=109.1, bsz=40, num_updates=740, lr=1.80867e-06, gnorm=2.181, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=847
2022-10-15 19:51:30 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 102288 loss=0.802, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=750, lr=1.83311e-06, gnorm=2.088, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=859
2022-10-15 19:51:40 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 102288 loss=0.818, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=103.4, ups=0.93, wpb=111.4, bsz=40, num_updates=760, lr=1.85755e-06, gnorm=2.02, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=869
2022-10-15 19:51:51 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 102288 loss=0.851, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=98, ups=0.9, wpb=108.5, bsz=40, num_updates=770, lr=1.882e-06, gnorm=2.134, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=880
2022-10-15 19:52:03 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 102288 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=97.8, ups=0.9, wpb=108.6, bsz=40, num_updates=780, lr=1.90644e-06, gnorm=2.006, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=892
2022-10-15 19:52:14 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 102288 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=97.4, ups=0.88, wpb=111.1, bsz=40, num_updates=790, lr=1.93088e-06, gnorm=2.141, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=903
2022-10-15 19:52:25 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 102288 loss=0.784, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=800, lr=1.95532e-06, gnorm=1.925, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=914
2022-10-15 19:52:37 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 102288 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=98.7, ups=0.88, wpb=111.9, bsz=40, num_updates=810, lr=1.97976e-06, gnorm=1.812, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=926
2022-10-15 19:52:48 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 102288 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=820, lr=2.0042e-06, gnorm=2.014, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=937
2022-10-15 19:52:59 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 102288 loss=0.835, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=830, lr=2.02865e-06, gnorm=1.892, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=948
2022-10-15 19:53:10 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 102288 loss=0.818, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=840, lr=2.05309e-06, gnorm=1.965, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=959
2022-10-15 19:53:20 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=105.4, ups=0.95, wpb=111, bsz=40, num_updates=850, lr=2.07753e-06, gnorm=1.755, clip=100, loss_scale=256, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=969
2022-10-15 19:53:31 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 102288 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.726, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=101, ups=0.92, wpb=110.1, bsz=40, num_updates=860, lr=2.10197e-06, gnorm=1.856, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=980
2022-10-15 19:53:42 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 102288 loss=0.822, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=100.1, ups=0.91, wpb=109.4, bsz=40, num_updates=870, lr=2.12641e-06, gnorm=1.93, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=991
2022-10-15 19:53:53 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 102288 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=880, lr=2.15085e-06, gnorm=1.871, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1002
2022-10-15 19:54:05 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 102288 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=890, lr=2.17529e-06, gnorm=1.836, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1014
2022-10-15 19:54:16 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 102288 loss=0.794, loss_v1=0, loss_v2=0, nll_loss=0.725, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=98.4, ups=0.89, wpb=110.7, bsz=40, num_updates=900, lr=2.19974e-06, gnorm=1.896, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1025
2022-10-15 19:54:27 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 102288 loss=0.833, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=910, lr=2.22418e-06, gnorm=2.018, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1036
2022-10-15 19:54:38 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 102288 loss=0.794, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=100.1, ups=0.91, wpb=109.6, bsz=40, num_updates=920, lr=2.24862e-06, gnorm=1.852, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1047
2022-10-15 19:54:49 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 102288 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=930, lr=2.27306e-06, gnorm=1.913, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1058
2022-10-15 19:55:01 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 102288 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=98.3, ups=0.89, wpb=110.6, bsz=40, num_updates=940, lr=2.2975e-06, gnorm=1.885, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1070
2022-10-15 19:55:12 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 102288 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.727, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=950, lr=2.32194e-06, gnorm=1.848, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1081
2022-10-15 19:55:23 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 102288 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.4, ups=0.88, wpb=111, bsz=40, num_updates=960, lr=2.34639e-06, gnorm=1.746, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1092
2022-10-15 19:55:35 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 102288 loss=0.824, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=97.1, ups=0.88, wpb=110.5, bsz=40, num_updates=970, lr=2.37083e-06, gnorm=1.866, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1104
2022-10-15 19:55:46 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.679, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=100, ups=0.89, wpb=112.1, bsz=40, num_updates=980, lr=2.39527e-06, gnorm=1.759, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1115
2022-10-15 19:55:57 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 102288 loss=0.835, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=95.7, ups=0.88, wpb=108.7, bsz=40, num_updates=990, lr=2.41971e-06, gnorm=1.794, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1126
2022-10-15 19:56:09 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=101, ups=0.9, wpb=111.7, bsz=40, num_updates=1000, lr=2.44415e-06, gnorm=1.701, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1137
2022-10-15 19:56:09 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-15 19:56:09 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-15 19:56:10 - train.py[line:549] - INFO: 0 / 4988
2022-10-15 19:56:10 - train.py[line:551] - INFO: load:1.12 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-15 19:58:45 - train.py[line:549] - INFO: 200 / 4988
2022-10-15 19:58:45 - train.py[line:551] - INFO: load:1.14 valid_run:154.41 task_valid:150.82 collect_output:2.45
2022-10-15 20:01:13 - train.py[line:549] - INFO: 400 / 4988
2022-10-15 20:01:13 - train.py[line:551] - INFO: load:1.17 valid_run:303.11 task_valid:294.55 collect_output:6.22
2022-10-15 20:03:46 - train.py[line:549] - INFO: 600 / 4988
2022-10-15 20:03:46 - train.py[line:551] - INFO: load:1.19 valid_run:455.76 task_valid:438.13 collect_output:14.12
2022-10-15 20:06:16 - train.py[line:549] - INFO: 800 / 4988
2022-10-15 20:06:16 - train.py[line:551] - INFO: load:1.22 valid_run:605.41 task_valid:583.80 collect_output:16.95
2022-10-15 20:08:48 - train.py[line:549] - INFO: 1000 / 4988
2022-10-15 20:08:48 - train.py[line:551] - INFO: load:1.25 valid_run:757.73 task_valid:731.78 collect_output:20.19
2022-10-15 20:11:20 - train.py[line:549] - INFO: 1200 / 4988
2022-10-15 20:11:20 - train.py[line:551] - INFO: load:1.27 valid_run:909.54 task_valid:877.98 collect_output:24.70
2022-10-15 20:13:53 - train.py[line:549] - INFO: 1400 / 4988
2022-10-15 20:13:53 - train.py[line:551] - INFO: load:1.30 valid_run:1062.38 task_valid:1024.55 collect_output:29.90
2022-10-15 20:16:24 - train.py[line:549] - INFO: 1600 / 4988
2022-10-15 20:16:24 - train.py[line:551] - INFO: load:1.32 valid_run:1213.25 task_valid:1165.91 collect_output:38.37
2022-10-15 20:18:53 - train.py[line:549] - INFO: 1800 / 4988
2022-10-15 20:18:53 - train.py[line:551] - INFO: load:1.35 valid_run:1362.41 task_valid:1310.60 collect_output:41.82
2022-10-15 20:21:21 - train.py[line:549] - INFO: 2000 / 4988
2022-10-15 20:21:21 - train.py[line:551] - INFO: load:1.37 valid_run:1510.48 task_valid:1453.75 collect_output:45.74
2022-10-15 20:23:51 - train.py[line:549] - INFO: 2200 / 4988
2022-10-15 20:23:51 - train.py[line:551] - INFO: load:1.40 valid_run:1659.88 task_valid:1598.65 collect_output:49.24
2022-10-15 20:26:20 - train.py[line:549] - INFO: 2400 / 4988
2022-10-15 20:26:20 - train.py[line:551] - INFO: load:1.42 valid_run:1809.68 task_valid:1743.61 collect_output:53.11
2022-10-15 20:28:50 - train.py[line:549] - INFO: 2600 / 4988
2022-10-15 20:28:50 - train.py[line:551] - INFO: load:1.45 valid_run:1959.02 task_valid:1885.30 collect_output:59.75
2022-10-15 20:31:20 - train.py[line:549] - INFO: 2800 / 4988
2022-10-15 20:31:20 - train.py[line:551] - INFO: load:1.48 valid_run:2109.17 task_valid:2030.70 collect_output:63.48
2022-10-15 20:33:50 - train.py[line:549] - INFO: 3000 / 4988
2022-10-15 20:33:50 - train.py[line:551] - INFO: load:1.50 valid_run:2258.98 task_valid:2177.09 collect_output:65.88
2022-10-15 20:36:20 - train.py[line:549] - INFO: 3200 / 4988
2022-10-15 20:36:20 - train.py[line:551] - INFO: load:1.53 valid_run:2408.87 task_valid:2321.30 collect_output:70.55
2022-10-15 20:38:52 - train.py[line:549] - INFO: 3400 / 4988
2022-10-15 20:38:52 - train.py[line:551] - INFO: load:1.55 valid_run:2560.48 task_valid:2466.74 collect_output:75.75
2022-10-15 20:41:22 - train.py[line:549] - INFO: 3600 / 4988
2022-10-15 20:41:22 - train.py[line:551] - INFO: load:1.58 valid_run:2710.76 task_valid:2613.59 collect_output:78.20
2022-10-15 20:43:50 - train.py[line:549] - INFO: 3800 / 4988
2022-10-15 20:43:50 - train.py[line:551] - INFO: load:1.60 valid_run:2858.69 task_valid:2755.15 collect_output:83.56
2022-10-15 20:46:20 - train.py[line:549] - INFO: 4000 / 4988
2022-10-15 20:46:20 - train.py[line:551] - INFO: load:1.63 valid_run:3008.74 task_valid:2900.19 collect_output:87.58
2022-10-15 20:48:52 - train.py[line:549] - INFO: 4200 / 4988
2022-10-15 20:48:52 - train.py[line:551] - INFO: load:1.65 valid_run:3160.67 task_valid:3044.73 collect_output:93.96
2022-10-15 20:51:21 - train.py[line:549] - INFO: 4400 / 4988
2022-10-15 20:51:21 - train.py[line:551] - INFO: load:1.68 valid_run:3309.70 task_valid:3189.29 collect_output:97.42
2022-10-15 20:53:52 - train.py[line:549] - INFO: 4600 / 4988
2022-10-15 20:53:52 - train.py[line:551] - INFO: load:1.71 valid_run:3460.76 task_valid:3335.49 collect_output:101.23
2022-10-15 20:56:23 - train.py[line:549] - INFO: 4800 / 4988
2022-10-15 20:56:23 - train.py[line:551] - INFO: load:1.73 valid_run:3612.00 task_valid:3481.95 collect_output:105.02

====================================================================================================
SGG eval:     R @ 50: 0.1418;     R @ 100: 0.2160;     R @ 500: 0.3061;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0676;    mR @ 100: 0.1114;    mR @ 500: 0.1662;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.1765) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3677) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1814) (says:0.0000) (sitting on:0.2426) (standing on:0.4550) (using:0.0500) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1418;     R @ 100: 0.2160;     R @ 500: 0.3061;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0676;    mR @ 100: 0.1114;    mR @ 500: 0.1662;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.1765) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3677) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1814) (says:0.0000) (sitting on:0.2426) (standing on:0.4550) (using:0.0500) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2022-10-15 20:58:55 - train.py[line:487] - INFO: 0.21603333333333333
2022-10-15 20:58:55 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-15 20:58:55 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.416 | loss_v1 0 | loss_v2 0 | nll_loss 0.321 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.216033 | ppl 1.25 | vqa_score 0.1588 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 1000
2022-10-15 20:58:55 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2022-10-15 20:58:55 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-15 20:59:01 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-15 20:59:06 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 0.21603333333333333) (writing took 10.749377799686044 seconds)
2022-10-15 20:59:17 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 102288 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=0.3, ups=0, wpb=110.6, bsz=40, num_updates=1010, lr=2.46859e-06, gnorm=1.741, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4926
2022-10-15 20:59:28 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 102288 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=101.6, ups=0.91, wpb=111.1, bsz=40, num_updates=1020, lr=2.49303e-06, gnorm=1.669, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4937
2022-10-15 20:59:39 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=103.2, ups=0.93, wpb=111.4, bsz=40, num_updates=1030, lr=2.51748e-06, gnorm=1.491, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=4948
2022-10-15 20:59:50 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 102288 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=1040, lr=2.54192e-06, gnorm=1.676, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4959
2022-10-15 21:00:01 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 102288 loss=0.803, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=1050, lr=2.56636e-06, gnorm=1.774, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=4970
2022-10-15 21:00:12 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=1060, lr=2.5908e-06, gnorm=1.643, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=4981
2022-10-15 21:00:32 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 102288 loss=0.841, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=98.9, ups=0.92, wpb=108.1, bsz=40, num_updates=1070, lr=2.61524e-06, gnorm=1.785, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=4992
2022-10-15 21:00:44 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 102288 loss=0.805, loss_v1=0, loss_v2=0, nll_loss=0.74, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=98.6, ups=0.9, wpb=110.1, bsz=40, num_updates=1080, lr=2.63968e-06, gnorm=1.736, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5013
2022-10-15 21:00:55 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 102288 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=97.4, ups=0.9, wpb=108.8, bsz=40, num_updates=1090, lr=2.66412e-06, gnorm=1.754, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5024
2022-10-15 21:01:06 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=101.1, ups=0.92, wpb=110.2, bsz=40, num_updates=1100, lr=2.68857e-06, gnorm=1.864, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5035
2022-10-15 21:01:17 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 102288 loss=0.82, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=96, ups=0.87, wpb=110, bsz=40, num_updates=1110, lr=2.71301e-06, gnorm=1.739, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5046
2022-10-15 21:01:28 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 102288 loss=0.76, loss_v1=0, loss_v2=0, nll_loss=0.689, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=102.3, ups=0.92, wpb=111.6, bsz=40, num_updates=1120, lr=2.73745e-06, gnorm=1.618, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5057
2022-10-15 21:01:39 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 102288 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.703, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=102.1, ups=0.93, wpb=109.8, bsz=40, num_updates=1130, lr=2.76189e-06, gnorm=1.642, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5068
2022-10-15 21:01:50 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 102288 loss=0.807, loss_v1=0, loss_v2=0, nll_loss=0.741, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=1140, lr=2.78633e-06, gnorm=1.665, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5079
2022-10-15 21:02:01 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 102288 loss=0.808, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=1150, lr=2.81077e-06, gnorm=1.669, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5090
2022-10-15 21:02:12 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 102288 loss=0.799, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=1160, lr=2.83522e-06, gnorm=1.716, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5101
2022-10-15 21:02:24 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.695, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=1170, lr=2.85966e-06, gnorm=1.646, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5112
2022-10-15 21:02:35 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 102288 loss=0.824, loss_v1=0, loss_v2=0, nll_loss=0.754, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=95.9, ups=0.88, wpb=108.7, bsz=40, num_updates=1180, lr=2.8841e-06, gnorm=1.812, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5124
2022-10-15 21:02:46 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 102288 loss=0.826, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=1190, lr=2.90854e-06, gnorm=1.848, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5135
2022-10-15 21:02:57 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.7, ups=0.89, wpb=111.7, bsz=40, num_updates=1200, lr=2.93298e-06, gnorm=1.665, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5146
2022-10-15 21:03:09 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=96.3, ups=0.88, wpb=109.1, bsz=40, num_updates=1210, lr=2.95742e-06, gnorm=1.788, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5158
2022-10-15 21:03:20 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 102288 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=1220, lr=2.98186e-06, gnorm=1.736, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5169
2022-10-15 21:03:31 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 102288 loss=0.811, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=1230, lr=3.00631e-06, gnorm=1.778, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5180
2022-10-15 21:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 102288 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=98.4, ups=0.9, wpb=109, bsz=40, num_updates=1240, lr=3.03075e-06, gnorm=1.635, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5191
2022-10-15 21:03:53 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 102288 loss=0.754, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=1250, lr=3.05519e-06, gnorm=1.666, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5202
2022-10-15 21:04:04 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=1260, lr=3.07963e-06, gnorm=1.618, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5213
2022-10-15 21:04:16 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 102288 loss=0.822, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=1270, lr=3.10407e-06, gnorm=1.759, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5224
2022-10-15 21:04:26 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 102288 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=102.5, ups=0.94, wpb=109.1, bsz=40, num_updates=1280, lr=3.12851e-06, gnorm=1.569, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5235
2022-10-15 21:04:38 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 102288 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=93.7, ups=0.87, wpb=107.8, bsz=40, num_updates=1290, lr=3.15295e-06, gnorm=1.562, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5247
2022-10-15 21:04:49 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 102288 loss=0.793, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=1300, lr=3.1774e-06, gnorm=1.545, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5258
2022-10-15 21:05:00 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 102288 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=1310, lr=3.20184e-06, gnorm=1.653, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5269
2022-10-15 21:05:11 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 102288 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=101.5, ups=0.92, wpb=110.9, bsz=40, num_updates=1320, lr=3.22628e-06, gnorm=1.625, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5280
2022-10-15 21:05:22 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 102288 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.696, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=1330, lr=3.25072e-06, gnorm=1.577, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5291
2022-10-15 21:05:33 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 102288 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=97, ups=0.88, wpb=110.6, bsz=40, num_updates=1340, lr=3.27516e-06, gnorm=1.502, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5302
2022-10-15 21:05:44 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.679, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=1350, lr=3.2996e-06, gnorm=1.589, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5313
2022-10-15 21:05:55 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 102288 loss=0.792, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=102.3, ups=0.93, wpb=110.2, bsz=40, num_updates=1360, lr=3.32405e-06, gnorm=1.709, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5324
2022-10-15 21:06:06 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 102288 loss=0.799, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=1370, lr=3.34849e-06, gnorm=1.602, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5335
2022-10-15 21:06:17 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.1, ups=0.88, wpb=111.8, bsz=40, num_updates=1380, lr=3.37293e-06, gnorm=1.61, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5346
2022-10-15 21:06:29 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=1390, lr=3.39737e-06, gnorm=1.693, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5357
2022-10-15 21:06:40 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99, ups=0.89, wpb=111.1, bsz=40, num_updates=1400, lr=3.42181e-06, gnorm=1.725, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5369
2022-10-15 21:06:51 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 102288 loss=0.805, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=96.6, ups=0.88, wpb=110.1, bsz=40, num_updates=1410, lr=3.44625e-06, gnorm=1.736, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5380
2022-10-15 21:07:02 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.695, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=1420, lr=3.47069e-06, gnorm=1.601, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5391
2022-10-15 21:07:13 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 102288 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.715, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=99.4, ups=0.91, wpb=109.8, bsz=40, num_updates=1430, lr=3.49514e-06, gnorm=1.639, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5402
2022-10-15 21:07:24 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 102288 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.4, ups=0.9, wpb=110.4, bsz=40, num_updates=1440, lr=3.51958e-06, gnorm=1.74, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5413
2022-10-15 21:07:36 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=95.2, ups=0.87, wpb=109.8, bsz=40, num_updates=1450, lr=3.54402e-06, gnorm=1.632, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5425
2022-10-15 21:07:47 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.5, ups=0.87, wpb=111.1, bsz=40, num_updates=1460, lr=3.56846e-06, gnorm=1.639, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5436
2022-10-15 21:07:58 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=1470, lr=3.5929e-06, gnorm=1.677, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5447
2022-10-15 21:08:10 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 102288 loss=0.806, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=1480, lr=3.61734e-06, gnorm=1.614, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5459
2022-10-15 21:08:21 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.3, ups=0.87, wpb=112.1, bsz=40, num_updates=1490, lr=3.64179e-06, gnorm=1.551, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5470
2022-10-15 21:08:33 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 102288 loss=0.811, loss_v1=0, loss_v2=0, nll_loss=0.74, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=96, ups=0.88, wpb=109.3, bsz=40, num_updates=1500, lr=3.66623e-06, gnorm=1.676, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5482
2022-10-15 21:08:44 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 102288 loss=0.818, loss_v1=0, loss_v2=0, nll_loss=0.754, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=1510, lr=3.69067e-06, gnorm=1.63, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5493
2022-10-15 21:08:55 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.692, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=1520, lr=3.71511e-06, gnorm=1.637, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5504
2022-10-15 21:09:06 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.704, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=1530, lr=3.73955e-06, gnorm=1.604, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5515
2022-10-15 21:09:18 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 102288 loss=0.798, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=1540, lr=3.76399e-06, gnorm=1.623, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5527
2022-10-15 21:09:29 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 102288 loss=0.792, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=94.7, ups=0.87, wpb=109.2, bsz=40, num_updates=1550, lr=3.78843e-06, gnorm=1.614, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5538
2022-10-15 21:09:40 - progress_bar.py[line:274] - INFO: epoch 001:   1560 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.6, ups=0.89, wpb=109.6, bsz=40, num_updates=1560, lr=3.81288e-06, gnorm=1.597, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5549
2022-10-15 21:09:51 - progress_bar.py[line:274] - INFO: epoch 001:   1570 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=103.6, ups=0.93, wpb=111, bsz=40, num_updates=1570, lr=3.83732e-06, gnorm=1.611, clip=100, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5560
2022-10-15 21:10:02 - progress_bar.py[line:274] - INFO: epoch 001:   1580 / 102288 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=102.7, ups=0.93, wpb=110.1, bsz=40, num_updates=1580, lr=3.86176e-06, gnorm=1.622, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5571
2022-10-15 21:10:13 - progress_bar.py[line:274] - INFO: epoch 001:   1590 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=1590, lr=3.8862e-06, gnorm=1.526, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5582
2022-10-15 21:10:24 - progress_bar.py[line:274] - INFO: epoch 001:   1600 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=1600, lr=3.91064e-06, gnorm=1.557, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5593
2022-10-15 21:10:36 - progress_bar.py[line:274] - INFO: epoch 001:   1610 / 102288 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=95.2, ups=0.87, wpb=110, bsz=40, num_updates=1610, lr=3.93508e-06, gnorm=1.654, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5605
2022-10-15 21:10:47 - progress_bar.py[line:274] - INFO: epoch 001:   1620 / 102288 loss=0.79, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=99.1, ups=0.89, wpb=111.3, bsz=40, num_updates=1620, lr=3.95952e-06, gnorm=1.632, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5616
2022-10-15 21:10:58 - progress_bar.py[line:274] - INFO: epoch 001:   1630 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=101, ups=0.92, wpb=110.1, bsz=40, num_updates=1630, lr=3.98397e-06, gnorm=1.572, clip=100, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5627
2022-10-15 21:11:09 - progress_bar.py[line:274] - INFO: epoch 001:   1640 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=1640, lr=4.00841e-06, gnorm=1.574, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5638
2022-10-15 21:11:20 - progress_bar.py[line:274] - INFO: epoch 001:   1650 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=99.1, ups=0.91, wpb=109.5, bsz=40, num_updates=1650, lr=4.03285e-06, gnorm=1.586, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5649
2022-10-15 21:11:32 - progress_bar.py[line:274] - INFO: epoch 001:   1660 / 102288 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=1660, lr=4.05729e-06, gnorm=1.65, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5661
2022-10-15 21:11:43 - progress_bar.py[line:274] - INFO: epoch 001:   1670 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=1670, lr=4.08173e-06, gnorm=1.559, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5672
2022-10-15 21:11:54 - progress_bar.py[line:274] - INFO: epoch 001:   1680 / 102288 loss=0.829, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=100.8, ups=0.93, wpb=108.6, bsz=40, num_updates=1680, lr=4.10617e-06, gnorm=1.756, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5683
2022-10-15 21:12:05 - progress_bar.py[line:274] - INFO: epoch 001:   1690 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=1690, lr=4.13062e-06, gnorm=1.552, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5694
2022-10-15 21:12:15 - progress_bar.py[line:274] - INFO: epoch 001:   1700 / 102288 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=104.2, ups=0.94, wpb=110.8, bsz=40, num_updates=1700, lr=4.15506e-06, gnorm=1.528, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5704
2022-10-15 21:12:27 - progress_bar.py[line:274] - INFO: epoch 001:   1710 / 102288 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=1710, lr=4.1795e-06, gnorm=1.553, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5716
2022-10-15 21:12:38 - progress_bar.py[line:274] - INFO: epoch 001:   1720 / 102288 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=1720, lr=4.20394e-06, gnorm=1.601, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5727
2022-10-15 21:12:49 - progress_bar.py[line:274] - INFO: epoch 001:   1730 / 102288 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=1730, lr=4.22838e-06, gnorm=1.494, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5738
2022-10-15 21:13:00 - progress_bar.py[line:274] - INFO: epoch 001:   1740 / 102288 loss=0.806, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=101.9, ups=0.93, wpb=109.8, bsz=40, num_updates=1740, lr=4.25282e-06, gnorm=1.485, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5749
2022-10-15 21:13:11 - progress_bar.py[line:274] - INFO: epoch 001:   1750 / 102288 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.692, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.5, ups=0.9, wpb=109.8, bsz=40, num_updates=1750, lr=4.27726e-06, gnorm=1.539, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5760
2022-10-15 21:13:22 - progress_bar.py[line:274] - INFO: epoch 001:   1760 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=1760, lr=4.30171e-06, gnorm=1.609, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5771
2022-10-15 21:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   1770 / 102288 loss=0.814, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=96.3, ups=0.89, wpb=107.8, bsz=40, num_updates=1770, lr=4.32615e-06, gnorm=1.57, clip=100, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5782
2022-10-15 21:13:45 - progress_bar.py[line:274] - INFO: epoch 001:   1780 / 102288 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=1780, lr=4.35059e-06, gnorm=1.531, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5794
2022-10-15 21:13:56 - progress_bar.py[line:274] - INFO: epoch 001:   1790 / 102288 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.698, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=97.3, ups=0.89, wpb=109.7, bsz=40, num_updates=1790, lr=4.37503e-06, gnorm=1.538, clip=100, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5805
2022-10-15 21:14:07 - progress_bar.py[line:274] - INFO: epoch 001:   1800 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=1800, lr=4.39947e-06, gnorm=1.463, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5816
2022-10-15 21:14:18 - progress_bar.py[line:274] - INFO: epoch 001:   1810 / 102288 loss=0.804, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=100, ups=0.9, wpb=110.9, bsz=40, num_updates=1810, lr=4.42391e-06, gnorm=1.714, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5827
2022-10-15 21:14:29 - progress_bar.py[line:274] - INFO: epoch 001:   1820 / 102288 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.692, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=1820, lr=4.44836e-06, gnorm=1.741, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5838
2022-10-15 21:14:40 - progress_bar.py[line:274] - INFO: epoch 001:   1830 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=101.2, ups=0.92, wpb=110.3, bsz=40, num_updates=1830, lr=4.4728e-06, gnorm=1.556, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5849
2022-10-15 21:14:51 - progress_bar.py[line:274] - INFO: epoch 001:   1840 / 102288 loss=0.751, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=1840, lr=4.49724e-06, gnorm=1.683, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5860
2022-10-15 21:15:02 - progress_bar.py[line:274] - INFO: epoch 001:   1850 / 102288 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=1850, lr=4.52168e-06, gnorm=1.63, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5871
2022-10-15 21:15:13 - progress_bar.py[line:274] - INFO: epoch 001:   1860 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=101.1, ups=0.91, wpb=110.8, bsz=40, num_updates=1860, lr=4.54612e-06, gnorm=1.56, clip=100, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=5882
2022-10-15 21:15:24 - progress_bar.py[line:274] - INFO: epoch 001:   1870 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=102.1, ups=0.93, wpb=110.1, bsz=40, num_updates=1870, lr=4.57056e-06, gnorm=1.473, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5893
2022-10-15 21:15:35 - progress_bar.py[line:274] - INFO: epoch 001:   1880 / 102288 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.4, ups=0.9, wpb=109.1, bsz=40, num_updates=1880, lr=4.595e-06, gnorm=1.548, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5904
2022-10-15 21:15:46 - progress_bar.py[line:274] - INFO: epoch 001:   1890 / 102288 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.68, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=1890, lr=4.61945e-06, gnorm=1.595, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5915
2022-10-15 21:15:57 - progress_bar.py[line:274] - INFO: epoch 001:   1900 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=106.1, ups=0.96, wpb=110.9, bsz=40, num_updates=1900, lr=4.64389e-06, gnorm=1.542, clip=100, loss_scale=1024, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=5926
2022-10-15 21:16:08 - progress_bar.py[line:274] - INFO: epoch 001:   1910 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=96.1, ups=0.87, wpb=110.7, bsz=40, num_updates=1910, lr=4.66833e-06, gnorm=1.633, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5937
2022-10-15 21:16:19 - progress_bar.py[line:274] - INFO: epoch 001:   1920 / 102288 loss=0.835, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=98.5, ups=0.91, wpb=107.7, bsz=40, num_updates=1920, lr=4.69277e-06, gnorm=1.616, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5948
2022-10-15 21:16:24 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 21:16:31 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.72, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=88.7, ups=0.81, wpb=109.8, bsz=40, num_updates=1930, lr=4.71721e-06, gnorm=1.536, clip=100, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=5960
2022-10-15 21:16:43 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 102288 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=1940, lr=4.74165e-06, gnorm=1.451, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5972
2022-10-15 21:16:54 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.3, ups=0.88, wpb=111, bsz=40, num_updates=1950, lr=4.76609e-06, gnorm=1.54, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5983
2022-10-15 21:17:06 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.9, ups=0.87, wpb=111.3, bsz=40, num_updates=1960, lr=4.79054e-06, gnorm=1.481, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5995
2022-10-15 21:17:16 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 102288 loss=0.804, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=102.9, ups=0.94, wpb=109.3, bsz=40, num_updates=1970, lr=4.81498e-06, gnorm=1.499, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6005
2022-10-15 21:17:27 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=1980, lr=4.83942e-06, gnorm=1.442, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6016
2022-10-15 21:17:39 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 102288 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=1990, lr=4.86386e-06, gnorm=1.541, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6027
2022-10-15 21:17:50 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 102288 loss=0.806, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=2000, lr=4.8883e-06, gnorm=1.712, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6039
2022-10-15 21:17:50 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-15 21:17:51 - train.py[line:549] - INFO: 0 / 4988
2022-10-15 21:17:51 - train.py[line:551] - INFO: load:1.17 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-15 21:20:24 - train.py[line:549] - INFO: 200 / 4988
2022-10-15 21:20:24 - train.py[line:551] - INFO: load:1.19 valid_run:153.26 task_valid:149.40 collect_output:2.69
2022-10-15 21:22:53 - train.py[line:549] - INFO: 400 / 4988
2022-10-15 21:22:53 - train.py[line:551] - INFO: load:1.22 valid_run:302.10 task_valid:293.05 collect_output:6.66
2022-10-15 21:25:26 - train.py[line:549] - INFO: 600 / 4988
2022-10-15 21:25:26 - train.py[line:551] - INFO: load:1.25 valid_run:455.06 task_valid:436.56 collect_output:14.97
2022-10-15 21:27:56 - train.py[line:549] - INFO: 800 / 4988
2022-10-15 21:27:56 - train.py[line:551] - INFO: load:1.27 valid_run:604.34 task_valid:582.13 collect_output:17.59
2022-10-15 21:30:28 - train.py[line:549] - INFO: 1000 / 4988
2022-10-15 21:30:28 - train.py[line:551] - INFO: load:1.30 valid_run:756.23 task_valid:729.44 collect_output:21.19
2022-10-15 21:32:59 - train.py[line:549] - INFO: 1200 / 4988
2022-10-15 21:32:59 - train.py[line:551] - INFO: load:1.32 valid_run:907.49 task_valid:874.93 collect_output:25.98
2022-10-15 21:35:32 - train.py[line:549] - INFO: 1400 / 4988
2022-10-15 21:35:32 - train.py[line:551] - INFO: load:1.35 valid_run:1060.32 task_valid:1020.88 collect_output:31.86
2022-10-15 21:38:03 - train.py[line:549] - INFO: 1600 / 4988
2022-10-15 21:38:03 - train.py[line:551] - INFO: load:1.37 valid_run:1211.00 task_valid:1161.92 collect_output:40.50
2022-10-15 21:40:32 - train.py[line:549] - INFO: 1800 / 4988
2022-10-15 21:40:32 - train.py[line:551] - INFO: load:1.40 valid_run:1360.21 task_valid:1306.51 collect_output:44.14
2022-10-15 21:43:00 - train.py[line:549] - INFO: 2000 / 4988
2022-10-15 21:43:00 - train.py[line:551] - INFO: load:1.43 valid_run:1508.66 task_valid:1449.72 collect_output:48.37
2022-10-15 21:45:30 - train.py[line:549] - INFO: 2200 / 4988
2022-10-15 21:45:30 - train.py[line:551] - INFO: load:1.45 valid_run:1658.31 task_valid:1594.62 collect_output:52.12
2022-10-15 21:48:00 - train.py[line:549] - INFO: 2400 / 4988
2022-10-15 21:48:00 - train.py[line:551] - INFO: load:1.48 valid_run:1807.93 task_valid:1739.50 collect_output:55.86
2022-10-15 21:50:29 - train.py[line:549] - INFO: 2600 / 4988
2022-10-15 21:50:29 - train.py[line:551] - INFO: load:1.51 valid_run:1957.50 task_valid:1881.12 collect_output:62.83
2022-10-15 21:53:00 - train.py[line:549] - INFO: 2800 / 4988
2022-10-15 21:53:00 - train.py[line:551] - INFO: load:1.53 valid_run:2107.70 task_valid:2026.43 collect_output:66.74
2022-10-15 21:55:30 - train.py[line:549] - INFO: 3000 / 4988
2022-10-15 21:55:30 - train.py[line:551] - INFO: load:1.56 valid_run:2257.68 task_valid:2172.75 collect_output:69.43
2022-10-15 21:57:59 - train.py[line:549] - INFO: 3200 / 4988
2022-10-15 21:57:59 - train.py[line:551] - INFO: load:1.58 valid_run:2407.34 task_valid:2316.84 collect_output:74.01
2022-10-15 22:00:31 - train.py[line:549] - INFO: 3400 / 4988
2022-10-15 22:00:31 - train.py[line:551] - INFO: load:1.61 valid_run:2558.79 task_valid:2462.13 collect_output:79.16
2022-10-15 22:03:01 - train.py[line:549] - INFO: 3600 / 4988
2022-10-15 22:03:01 - train.py[line:551] - INFO: load:1.64 valid_run:2709.05 task_valid:2608.86 collect_output:81.69
2022-10-15 22:05:30 - train.py[line:549] - INFO: 3800 / 4988
2022-10-15 22:05:30 - train.py[line:551] - INFO: load:1.66 valid_run:2857.54 task_valid:2750.59 collect_output:87.43
2022-10-15 22:08:00 - train.py[line:549] - INFO: 4000 / 4988
2022-10-15 22:08:00 - train.py[line:551] - INFO: load:1.69 valid_run:3008.02 task_valid:2895.60 collect_output:91.88
2022-10-15 22:10:33 - train.py[line:549] - INFO: 4200 / 4988
2022-10-15 22:10:33 - train.py[line:551] - INFO: load:1.71 valid_run:3160.11 task_valid:3040.10 collect_output:98.44
2022-10-15 22:13:02 - train.py[line:549] - INFO: 4400 / 4988
2022-10-15 22:13:02 - train.py[line:551] - INFO: load:1.74 valid_run:3309.56 task_valid:3184.71 collect_output:102.25
2022-10-15 22:15:34 - train.py[line:549] - INFO: 4600 / 4988
2022-10-15 22:15:34 - train.py[line:551] - INFO: load:1.77 valid_run:3461.07 task_valid:3331.36 collect_output:106.06
2022-10-15 22:18:06 - train.py[line:549] - INFO: 4800 / 4988
2022-10-15 22:18:06 - train.py[line:551] - INFO: load:1.80 valid_run:3613.10 task_valid:3478.44 collect_output:109.89

====================================================================================================
SGG eval:     R @ 50: 0.1982;     R @ 100: 0.2717;     R @ 500: 0.3646;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0923;    mR @ 100: 0.1443;    mR @ 500: 0.1952;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0171) (covered in:0.0000) (covering:0.1429) (eating:0.3529) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.2337) (says:0.0000) (sitting on:0.3359) (standing on:0.4850) (using:0.1500) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1982;     R @ 100: 0.2717;     R @ 500: 0.3646;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0923;    mR @ 100: 0.1443;    mR @ 500: 0.1952;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0171) (covered in:0.0000) (covering:0.1429) (eating:0.3529) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.2337) (says:0.0000) (sitting on:0.3359) (standing on:0.4850) (using:0.1500) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2022-10-15 22:20:37 - train.py[line:487] - INFO: 0.27166666666666667
2022-10-15 22:20:37 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-15 22:20:37 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.423 | loss_v1 0 | loss_v2 0 | nll_loss 0.315 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.271667 | ppl 1.24 | vqa_score 0.161 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 2000 | best_R@100 0.271667
2022-10-15 22:20:37 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2022-10-15 22:20:37 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-15 22:20:43 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-15 22:20:48 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.27166666666666667) (writing took 10.840223471168429 seconds)
2022-10-15 22:20:59 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 102288 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=0.3, ups=0, wpb=109.2, bsz=40, num_updates=2010, lr=4.91274e-06, gnorm=1.594, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9828
2022-10-15 22:21:10 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 102288 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=96.6, ups=0.87, wpb=110.8, bsz=40, num_updates=2020, lr=4.93719e-06, gnorm=1.515, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9839
2022-10-15 22:21:21 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 102288 loss=0.783, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=100.5, ups=0.92, wpb=109.8, bsz=40, num_updates=2030, lr=4.96163e-06, gnorm=1.6, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9850
2022-10-15 22:21:32 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.9, ups=0.92, wpb=110, bsz=40, num_updates=2040, lr=4.98607e-06, gnorm=1.5, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9861
2022-10-15 22:21:43 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 102288 loss=0.795, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=99.3, ups=0.92, wpb=108.5, bsz=40, num_updates=2050, lr=5.01051e-06, gnorm=1.631, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=9872
2022-10-15 22:21:55 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 102288 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=2060, lr=5.03495e-06, gnorm=1.416, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9884
2022-10-15 22:22:06 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 102288 loss=0.784, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=96, ups=0.88, wpb=109.1, bsz=40, num_updates=2070, lr=5.05939e-06, gnorm=1.556, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9895
2022-10-15 22:22:17 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 102288 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.702, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=100.2, ups=0.92, wpb=109, bsz=40, num_updates=2080, lr=5.08383e-06, gnorm=1.486, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9906
2022-10-15 22:22:28 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 102288 loss=0.754, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=2090, lr=5.10828e-06, gnorm=1.543, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9917
2022-10-15 22:22:39 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 102288 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98.6, ups=0.9, wpb=109, bsz=40, num_updates=2100, lr=5.13272e-06, gnorm=1.561, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=9928
2022-10-15 22:22:51 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 102288 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.702, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=95.9, ups=0.88, wpb=109.3, bsz=40, num_updates=2110, lr=5.15716e-06, gnorm=1.492, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9940
2022-10-15 22:23:02 - progress_bar.py[line:274] - INFO: epoch 001:   2121 / 102288 loss=0.716, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.2, ups=0.88, wpb=111.5, bsz=40, num_updates=2120, lr=5.1816e-06, gnorm=1.38, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9951
2022-10-15 22:23:13 - progress_bar.py[line:274] - INFO: epoch 001:   2131 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.6, ups=0.92, wpb=109.6, bsz=40, num_updates=2130, lr=5.20604e-06, gnorm=1.535, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9962
2022-10-15 22:23:24 - progress_bar.py[line:274] - INFO: epoch 001:   2141 / 102288 loss=0.794, loss_v1=0, loss_v2=0, nll_loss=0.723, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=101.5, ups=0.92, wpb=110.7, bsz=40, num_updates=2140, lr=5.23048e-06, gnorm=1.705, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=9973
2022-10-15 22:23:35 - progress_bar.py[line:274] - INFO: epoch 001:   2151 / 102288 loss=0.803, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=100.2, ups=0.92, wpb=109.3, bsz=40, num_updates=2150, lr=5.25492e-06, gnorm=1.399, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=9984
2022-10-15 22:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   2161 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=101.1, ups=0.91, wpb=111, bsz=40, num_updates=2160, lr=5.27937e-06, gnorm=1.455, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9995
2022-10-15 22:23:57 - progress_bar.py[line:274] - INFO: epoch 001:   2171 / 102288 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=2170, lr=5.30381e-06, gnorm=1.481, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10006
2022-10-15 22:24:08 - progress_bar.py[line:274] - INFO: epoch 001:   2181 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=101.5, ups=0.91, wpb=111.2, bsz=40, num_updates=2180, lr=5.32825e-06, gnorm=1.533, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10017
2022-10-15 22:24:19 - progress_bar.py[line:274] - INFO: epoch 001:   2191 / 102288 loss=0.827, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=97, ups=0.89, wpb=108.9, bsz=40, num_updates=2190, lr=5.35269e-06, gnorm=1.502, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10028
2022-10-15 22:24:30 - progress_bar.py[line:274] - INFO: epoch 001:   2201 / 102288 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.693, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=2200, lr=5.37713e-06, gnorm=1.42, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10039
2022-10-15 22:24:41 - progress_bar.py[line:274] - INFO: epoch 001:   2211 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.673, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=2210, lr=5.40157e-06, gnorm=1.483, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10050
2022-10-15 22:24:52 - progress_bar.py[line:274] - INFO: epoch 001:   2221 / 102288 loss=0.773, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=105.7, ups=0.96, wpb=109.7, bsz=40, num_updates=2220, lr=5.42602e-06, gnorm=1.457, clip=100, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=10061
2022-10-15 22:25:03 - progress_bar.py[line:274] - INFO: epoch 001:   2231 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=2230, lr=5.45046e-06, gnorm=1.493, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10072
2022-10-15 22:25:14 - progress_bar.py[line:274] - INFO: epoch 001:   2241 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.3, ups=0.88, wpb=111.5, bsz=40, num_updates=2240, lr=5.4749e-06, gnorm=1.443, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10083
2022-10-15 22:25:26 - progress_bar.py[line:274] - INFO: epoch 001:   2251 / 102288 loss=0.773, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=2250, lr=5.49934e-06, gnorm=1.516, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10095
2022-10-15 22:25:37 - progress_bar.py[line:274] - INFO: epoch 001:   2261 / 102288 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=98.4, ups=0.9, wpb=109.4, bsz=40, num_updates=2260, lr=5.52378e-06, gnorm=1.433, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10106
2022-10-15 22:25:48 - progress_bar.py[line:274] - INFO: epoch 001:   2271 / 102288 loss=0.789, loss_v1=0, loss_v2=0, nll_loss=0.717, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98.4, ups=0.9, wpb=109, bsz=40, num_updates=2270, lr=5.54822e-06, gnorm=1.442, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10117
2022-10-15 22:25:59 - progress_bar.py[line:274] - INFO: epoch 001:   2281 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100.9, ups=0.91, wpb=111.5, bsz=40, num_updates=2280, lr=5.57266e-06, gnorm=1.279, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10128
2022-10-15 22:26:10 - progress_bar.py[line:274] - INFO: epoch 001:   2291 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.3, ups=0.89, wpb=111.9, bsz=40, num_updates=2290, lr=5.59711e-06, gnorm=1.422, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10139
2022-10-15 22:26:22 - progress_bar.py[line:274] - INFO: epoch 001:   2301 / 102288 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.68, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.5, ups=0.88, wpb=110.1, bsz=40, num_updates=2300, lr=5.62155e-06, gnorm=1.421, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10151
2022-10-15 22:26:33 - progress_bar.py[line:274] - INFO: epoch 001:   2311 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=101.4, ups=0.92, wpb=109.6, bsz=40, num_updates=2310, lr=5.64599e-06, gnorm=1.487, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10162
2022-10-15 22:26:44 - progress_bar.py[line:274] - INFO: epoch 001:   2321 / 102288 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.4, ups=0.89, wpb=109.2, bsz=40, num_updates=2320, lr=5.67043e-06, gnorm=1.567, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10173
2022-10-15 22:26:55 - progress_bar.py[line:274] - INFO: epoch 001:   2331 / 102288 loss=0.77, loss_v1=0, loss_v2=0, nll_loss=0.693, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=97.8, ups=0.89, wpb=109.9, bsz=40, num_updates=2330, lr=5.69487e-06, gnorm=1.35, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10184
2022-10-15 22:27:06 - progress_bar.py[line:274] - INFO: epoch 001:   2341 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.7, ups=0.89, wpb=109.9, bsz=40, num_updates=2340, lr=5.71931e-06, gnorm=1.472, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10195
2022-10-15 22:27:17 - progress_bar.py[line:274] - INFO: epoch 001:   2351 / 102288 loss=0.783, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.8, ups=0.89, wpb=109.4, bsz=40, num_updates=2350, lr=5.74376e-06, gnorm=1.501, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10206
2022-10-15 22:27:29 - progress_bar.py[line:274] - INFO: epoch 001:   2361 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=2360, lr=5.7682e-06, gnorm=1.451, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10218
2022-10-15 22:27:40 - progress_bar.py[line:274] - INFO: epoch 001:   2371 / 102288 loss=0.784, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98, ups=0.9, wpb=108.9, bsz=40, num_updates=2370, lr=5.79264e-06, gnorm=1.686, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10229
2022-10-15 22:27:51 - progress_bar.py[line:274] - INFO: epoch 001:   2381 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.693, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.6, ups=0.9, wpb=109.8, bsz=40, num_updates=2380, lr=5.81708e-06, gnorm=1.637, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10240
2022-10-15 22:28:02 - progress_bar.py[line:274] - INFO: epoch 001:   2391 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=102, ups=0.91, wpb=111.6, bsz=40, num_updates=2390, lr=5.84152e-06, gnorm=1.473, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10251
2022-10-15 22:28:13 - progress_bar.py[line:274] - INFO: epoch 001:   2401 / 102288 loss=0.784, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=2400, lr=5.86596e-06, gnorm=1.546, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10262
2022-10-15 22:28:25 - progress_bar.py[line:274] - INFO: epoch 001:   2411 / 102288 loss=0.789, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=97.7, ups=0.88, wpb=110.6, bsz=40, num_updates=2410, lr=5.8904e-06, gnorm=1.6, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10274
2022-10-15 22:28:36 - progress_bar.py[line:274] - INFO: epoch 001:   2421 / 102288 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=2420, lr=5.91485e-06, gnorm=1.631, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10285
2022-10-15 22:28:47 - progress_bar.py[line:274] - INFO: epoch 001:   2431 / 102288 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.2, ups=0.88, wpb=109.5, bsz=40, num_updates=2430, lr=5.93929e-06, gnorm=1.58, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10296
2022-10-15 22:28:59 - progress_bar.py[line:274] - INFO: epoch 001:   2441 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.4, ups=0.88, wpb=110.9, bsz=40, num_updates=2440, lr=5.96373e-06, gnorm=1.318, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10308
2022-10-15 22:29:10 - progress_bar.py[line:274] - INFO: epoch 001:   2451 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=95.4, ups=0.87, wpb=109.8, bsz=40, num_updates=2450, lr=5.98817e-06, gnorm=1.381, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10319
2022-10-15 22:29:21 - progress_bar.py[line:274] - INFO: epoch 001:   2461 / 102288 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.679, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=2460, lr=6.01261e-06, gnorm=1.435, clip=100, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10330
2022-10-15 22:29:32 - progress_bar.py[line:274] - INFO: epoch 001:   2471 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=101, ups=0.91, wpb=110.4, bsz=40, num_updates=2470, lr=6.03705e-06, gnorm=1.494, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10341
2022-10-15 22:29:43 - progress_bar.py[line:274] - INFO: epoch 001:   2481 / 102288 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=100, ups=0.91, wpb=109.4, bsz=40, num_updates=2480, lr=6.06149e-06, gnorm=1.39, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10352
2022-10-15 22:29:55 - progress_bar.py[line:274] - INFO: epoch 001:   2491 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.65, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=95.8, ups=0.87, wpb=109.5, bsz=40, num_updates=2490, lr=6.08594e-06, gnorm=1.37, clip=100, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10364
2022-10-15 22:30:06 - progress_bar.py[line:274] - INFO: epoch 001:   2501 / 102288 loss=0.761, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=2500, lr=6.11038e-06, gnorm=1.467, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10375
2022-10-15 22:30:17 - progress_bar.py[line:274] - INFO: epoch 001:   2511 / 102288 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=102, ups=0.92, wpb=111.4, bsz=40, num_updates=2510, lr=6.13482e-06, gnorm=1.38, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10386
2022-10-15 22:30:27 - progress_bar.py[line:274] - INFO: epoch 001:   2521 / 102288 loss=0.736, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=103.3, ups=0.94, wpb=109.9, bsz=40, num_updates=2520, lr=6.15926e-06, gnorm=1.402, clip=100, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10396
2022-10-15 22:30:38 - progress_bar.py[line:274] - INFO: epoch 001:   2531 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.654, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100.4, ups=0.91, wpb=110, bsz=40, num_updates=2530, lr=6.1837e-06, gnorm=1.466, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10407
2022-10-15 22:30:50 - progress_bar.py[line:274] - INFO: epoch 001:   2541 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=2540, lr=6.20814e-06, gnorm=1.426, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10419
2022-10-15 22:31:01 - progress_bar.py[line:274] - INFO: epoch 001:   2551 / 102288 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=2550, lr=6.23259e-06, gnorm=1.534, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10430
2022-10-15 22:31:12 - progress_bar.py[line:274] - INFO: epoch 001:   2561 / 102288 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=2560, lr=6.25703e-06, gnorm=1.427, clip=100, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10441
2022-10-15 22:31:23 - progress_bar.py[line:274] - INFO: epoch 001:   2571 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.3, ups=0.88, wpb=109.7, bsz=40, num_updates=2570, lr=6.28147e-06, gnorm=1.451, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10452
2022-10-15 22:31:35 - progress_bar.py[line:274] - INFO: epoch 001:   2581 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100.4, ups=0.89, wpb=112.4, bsz=40, num_updates=2580, lr=6.30591e-06, gnorm=1.321, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10463
2022-10-15 22:31:45 - progress_bar.py[line:274] - INFO: epoch 001:   2591 / 102288 loss=0.76, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=101.5, ups=0.92, wpb=110, bsz=40, num_updates=2590, lr=6.33035e-06, gnorm=1.378, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10474
2022-10-15 22:31:57 - progress_bar.py[line:274] - INFO: epoch 001:   2601 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=95.5, ups=0.87, wpb=110, bsz=40, num_updates=2600, lr=6.35479e-06, gnorm=1.589, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10486
2022-10-15 22:32:08 - progress_bar.py[line:274] - INFO: epoch 001:   2611 / 102288 loss=0.761, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=2610, lr=6.37923e-06, gnorm=1.48, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10497
2022-10-15 22:32:19 - progress_bar.py[line:274] - INFO: epoch 001:   2621 / 102288 loss=0.748, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=2620, lr=6.40368e-06, gnorm=1.476, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10508
2022-10-15 22:32:30 - progress_bar.py[line:274] - INFO: epoch 001:   2631 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.665, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=2630, lr=6.42812e-06, gnorm=1.461, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10519
2022-10-15 22:32:42 - progress_bar.py[line:274] - INFO: epoch 001:   2641 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=95.7, ups=0.87, wpb=110.1, bsz=40, num_updates=2640, lr=6.45256e-06, gnorm=1.35, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10531
2022-10-15 22:32:53 - progress_bar.py[line:274] - INFO: epoch 001:   2651 / 102288 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.65, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=2650, lr=6.477e-06, gnorm=1.476, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10542
2022-10-15 22:33:04 - progress_bar.py[line:274] - INFO: epoch 001:   2661 / 102288 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.673, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=2660, lr=6.50144e-06, gnorm=1.518, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10553
2022-10-15 22:33:15 - progress_bar.py[line:274] - INFO: epoch 001:   2671 / 102288 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=100.5, ups=0.92, wpb=109.7, bsz=40, num_updates=2670, lr=6.52588e-06, gnorm=1.525, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10564
2022-10-15 22:33:26 - progress_bar.py[line:274] - INFO: epoch 001:   2681 / 102288 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.698, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.4, ups=0.9, wpb=110.6, bsz=40, num_updates=2680, lr=6.55033e-06, gnorm=1.582, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10575
2022-10-15 22:33:37 - progress_bar.py[line:274] - INFO: epoch 001:   2691 / 102288 loss=0.803, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=97.2, ups=0.89, wpb=108.9, bsz=40, num_updates=2690, lr=6.57477e-06, gnorm=1.514, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10586
2022-10-15 22:33:49 - progress_bar.py[line:274] - INFO: epoch 001:   2701 / 102288 loss=0.735, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=95.4, ups=0.87, wpb=110.2, bsz=40, num_updates=2700, lr=6.59921e-06, gnorm=1.363, clip=100, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10598
2022-10-15 22:34:01 - progress_bar.py[line:274] - INFO: epoch 001:   2711 / 102288 loss=0.761, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=95.4, ups=0.86, wpb=110.3, bsz=40, num_updates=2710, lr=6.62365e-06, gnorm=1.471, clip=100, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10610
2022-10-15 22:34:11 - progress_bar.py[line:274] - INFO: epoch 001:   2721 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=100.8, ups=0.92, wpb=110.1, bsz=40, num_updates=2720, lr=6.64809e-06, gnorm=1.409, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10620
2022-10-15 22:34:23 - progress_bar.py[line:274] - INFO: epoch 001:   2731 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=2730, lr=6.67253e-06, gnorm=1.403, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10632
2022-10-15 22:34:29 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 22:34:35 - progress_bar.py[line:274] - INFO: epoch 001:   2742 / 102288 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.629, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=90.3, ups=0.82, wpb=110.7, bsz=40, num_updates=2740, lr=6.69697e-06, gnorm=1.338, clip=100, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=10644
2022-10-15 22:34:46 - progress_bar.py[line:274] - INFO: epoch 001:   2752 / 102288 loss=0.741, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.3, ups=0.89, wpb=111.6, bsz=40, num_updates=2750, lr=6.72142e-06, gnorm=1.3, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10655
2022-10-15 22:34:57 - progress_bar.py[line:274] - INFO: epoch 001:   2762 / 102288 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=2760, lr=6.74586e-06, gnorm=1.347, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10666
2022-10-15 22:35:09 - progress_bar.py[line:274] - INFO: epoch 001:   2772 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.6, ups=0.89, wpb=111.6, bsz=40, num_updates=2770, lr=6.7703e-06, gnorm=1.438, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10678
2022-10-15 22:35:20 - progress_bar.py[line:274] - INFO: epoch 001:   2782 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.6, ups=0.88, wpb=110.2, bsz=40, num_updates=2780, lr=6.79474e-06, gnorm=1.423, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10689
2022-10-15 22:35:31 - progress_bar.py[line:274] - INFO: epoch 001:   2792 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.5, ups=0.91, wpb=109.9, bsz=40, num_updates=2790, lr=6.81918e-06, gnorm=1.346, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10700
2022-10-15 22:35:42 - progress_bar.py[line:274] - INFO: epoch 001:   2802 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=102.1, ups=0.93, wpb=110.2, bsz=40, num_updates=2800, lr=6.84362e-06, gnorm=1.438, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10711
2022-10-15 22:35:53 - progress_bar.py[line:274] - INFO: epoch 001:   2812 / 102288 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.9, ups=0.88, wpb=112.4, bsz=40, num_updates=2810, lr=6.86806e-06, gnorm=1.524, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10722
2022-10-15 22:36:04 - progress_bar.py[line:274] - INFO: epoch 001:   2822 / 102288 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.694, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.8, ups=0.9, wpb=109.2, bsz=40, num_updates=2820, lr=6.89251e-06, gnorm=1.555, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10733
2022-10-15 22:36:16 - progress_bar.py[line:274] - INFO: epoch 001:   2832 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.1, ups=0.9, wpb=110.4, bsz=40, num_updates=2830, lr=6.91695e-06, gnorm=1.554, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10745
2022-10-15 22:36:27 - progress_bar.py[line:274] - INFO: epoch 001:   2842 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.9, ups=0.89, wpb=111.4, bsz=40, num_updates=2840, lr=6.94139e-06, gnorm=1.282, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10756
2022-10-15 22:36:38 - progress_bar.py[line:274] - INFO: epoch 001:   2852 / 102288 loss=0.76, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=2850, lr=6.96583e-06, gnorm=1.443, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10767
2022-10-15 22:36:49 - progress_bar.py[line:274] - INFO: epoch 001:   2862 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=96.9, ups=0.88, wpb=110.3, bsz=40, num_updates=2860, lr=6.99027e-06, gnorm=1.389, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10778
2022-10-15 22:37:01 - progress_bar.py[line:274] - INFO: epoch 001:   2872 / 102288 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=2870, lr=7.01471e-06, gnorm=1.295, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10790
2022-10-15 22:37:12 - progress_bar.py[line:274] - INFO: epoch 001:   2882 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=2880, lr=7.03916e-06, gnorm=1.318, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10801
2022-10-15 22:37:23 - progress_bar.py[line:274] - INFO: epoch 001:   2892 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=2890, lr=7.0636e-06, gnorm=1.461, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10812
2022-10-15 22:37:34 - progress_bar.py[line:274] - INFO: epoch 001:   2902 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=102.2, ups=0.93, wpb=110.3, bsz=40, num_updates=2900, lr=7.08804e-06, gnorm=1.386, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10823
2022-10-15 22:37:46 - progress_bar.py[line:274] - INFO: epoch 001:   2912 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.3, ups=0.87, wpb=111, bsz=40, num_updates=2910, lr=7.11248e-06, gnorm=1.408, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10835
2022-10-15 22:37:57 - progress_bar.py[line:274] - INFO: epoch 001:   2922 / 102288 loss=0.741, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=2920, lr=7.13692e-06, gnorm=1.254, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10846
2022-10-15 22:38:08 - progress_bar.py[line:274] - INFO: epoch 001:   2932 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=2930, lr=7.16136e-06, gnorm=1.478, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10857
2022-10-15 22:38:19 - progress_bar.py[line:274] - INFO: epoch 001:   2942 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=102.4, ups=0.92, wpb=111.5, bsz=40, num_updates=2940, lr=7.1858e-06, gnorm=1.265, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10868
2022-10-15 22:38:30 - progress_bar.py[line:274] - INFO: epoch 001:   2952 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=2950, lr=7.21025e-06, gnorm=1.349, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10879
2022-10-15 22:38:41 - progress_bar.py[line:274] - INFO: epoch 001:   2962 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.692, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.4, ups=0.9, wpb=108.9, bsz=40, num_updates=2960, lr=7.23469e-06, gnorm=1.377, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10890
2022-10-15 22:38:53 - progress_bar.py[line:274] - INFO: epoch 001:   2972 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=2970, lr=7.25913e-06, gnorm=1.438, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10902
2022-10-15 22:39:04 - progress_bar.py[line:274] - INFO: epoch 001:   2982 / 102288 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=102.6, ups=0.92, wpb=111.5, bsz=40, num_updates=2980, lr=7.28357e-06, gnorm=1.346, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10913
2022-10-15 22:39:14 - progress_bar.py[line:274] - INFO: epoch 001:   2992 / 102288 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=2990, lr=7.30801e-06, gnorm=1.381, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10923
2022-10-15 22:39:26 - progress_bar.py[line:274] - INFO: epoch 001:   3002 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=3000, lr=7.33245e-06, gnorm=1.313, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10935
2022-10-15 22:39:26 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-15 22:39:27 - train.py[line:549] - INFO: 0 / 4988
2022-10-15 22:39:27 - train.py[line:551] - INFO: load:1.17 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-15 22:39:43 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.90 GiB already allocated; 6.19 GiB free; 30.91 GiB reserved in total by PyTorch)
2022-10-15 22:39:43 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 15        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9108 MB |   14338 MB |    1588 TB |    1588 TB |
|       from large pool |    8963 MB |   14193 MB |    1588 TB |    1588 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9108 MB |   14338 MB |    1588 TB |    1588 TB |
|       from large pool |    8963 MB |   14193 MB |    1588 TB |    1588 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31656 MB |   37302 MB |  164732 MB |  133076 MB |
|       from large pool |   31510 MB |   37156 MB |  164444 MB |  132934 MB |
|       from small pool |     146 MB |     152 MB |     288 MB |     142 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22547 MB |   27178 MB |    1629 TB |    1629 TB |
|       from large pool |   22546 MB |   27176 MB |    1628 TB |    1628 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |   71785 K  |   71781 K  |
|       from large pool |     563    |     575    |   23863 K  |   23863 K  |
|       from small pool |    3106    |    3116    |   47921 K  |   47918 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |   71785 K  |   71781 K  |
|       from large pool |     563    |     575    |   23863 K  |   23863 K  |
|       from small pool |    3106    |    3116    |   47921 K  |   47918 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     173    |     179    |     457    |     284    |
|       from large pool |     100    |     103    |     313    |     213    |
|       from small pool |      73    |      76    |     144    |      71    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     119    |     137    |   49222 K  |   49222 K  |
|       from large pool |      82    |      87    |    8188 K  |    8188 K  |
|       from small pool |      37    |      53    |   41033 K  |   41033 K  |
|===========================================================================|

2022-10-15 22:39:43 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-15 22:39:43 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-15 22:42:01 - train.py[line:549] - INFO: 200 / 4988
2022-10-15 22:42:01 - train.py[line:551] - INFO: load:1.20 valid_run:153.62 task_valid:148.84 collect_output:2.30
2022-10-15 22:44:29 - train.py[line:549] - INFO: 400 / 4988
2022-10-15 22:44:29 - train.py[line:551] - INFO: load:1.22 valid_run:301.72 task_valid:292.15 collect_output:6.00
2022-10-15 22:47:01 - train.py[line:549] - INFO: 600 / 4988
2022-10-15 22:47:01 - train.py[line:551] - INFO: load:1.25 valid_run:453.36 task_valid:435.11 collect_output:13.64
2022-10-15 22:49:29 - train.py[line:549] - INFO: 800 / 4988
2022-10-15 22:49:29 - train.py[line:551] - INFO: load:1.28 valid_run:602.06 task_valid:580.02 collect_output:16.43
2022-10-15 22:52:01 - train.py[line:549] - INFO: 1000 / 4988
2022-10-15 22:52:01 - train.py[line:551] - INFO: load:1.30 valid_run:753.98 task_valid:727.29 collect_output:20.09
2022-10-15 22:54:33 - train.py[line:549] - INFO: 1200 / 4988
2022-10-15 22:54:33 - train.py[line:551] - INFO: load:1.33 valid_run:905.53 task_valid:872.83 collect_output:25.08
2022-10-15 22:57:06 - train.py[line:549] - INFO: 1400 / 4988
2022-10-15 22:57:06 - train.py[line:551] - INFO: load:1.35 valid_run:1058.44 task_valid:1018.92 collect_output:30.91
2022-10-15 22:59:37 - train.py[line:549] - INFO: 1600 / 4988
2022-10-15 22:59:37 - train.py[line:551] - INFO: load:1.38 valid_run:1209.33 task_valid:1160.20 collect_output:39.52
2022-10-15 23:02:06 - train.py[line:549] - INFO: 1800 / 4988
2022-10-15 23:02:06 - train.py[line:551] - INFO: load:1.40 valid_run:1358.78 task_valid:1304.98 collect_output:43.17
2022-10-15 23:04:35 - train.py[line:549] - INFO: 2000 / 4988
2022-10-15 23:04:35 - train.py[line:551] - INFO: load:1.43 valid_run:1507.53 task_valid:1448.35 collect_output:47.51
2022-10-15 23:07:05 - train.py[line:549] - INFO: 2200 / 4988
2022-10-15 23:07:05 - train.py[line:551] - INFO: load:1.45 valid_run:1657.14 task_valid:1593.30 collect_output:51.16
2022-10-15 23:09:35 - train.py[line:549] - INFO: 2400 / 4988
2022-10-15 23:09:35 - train.py[line:551] - INFO: load:1.48 valid_run:1806.86 task_valid:1738.23 collect_output:54.94
2022-10-15 23:12:05 - train.py[line:549] - INFO: 2600 / 4988
2022-10-15 23:12:05 - train.py[line:551] - INFO: load:1.51 valid_run:1956.57 task_valid:1880.19 collect_output:61.65
2022-10-15 23:14:35 - train.py[line:549] - INFO: 2800 / 4988
2022-10-15 23:14:35 - train.py[line:551] - INFO: load:1.53 valid_run:2107.03 task_valid:2025.81 collect_output:65.49
2022-10-15 23:17:05 - train.py[line:549] - INFO: 3000 / 4988
2022-10-15 23:17:05 - train.py[line:551] - INFO: load:1.56 valid_run:2256.85 task_valid:2172.14 collect_output:67.98
2022-10-15 23:19:35 - train.py[line:549] - INFO: 3200 / 4988
2022-10-15 23:19:35 - train.py[line:551] - INFO: load:1.59 valid_run:2406.74 task_valid:2316.31 collect_output:72.68
2022-10-15 23:22:07 - train.py[line:549] - INFO: 3400 / 4988
2022-10-15 23:22:07 - train.py[line:551] - INFO: load:1.61 valid_run:2558.43 task_valid:2461.75 collect_output:77.92
2022-10-15 23:24:37 - train.py[line:549] - INFO: 3600 / 4988
2022-10-15 23:24:37 - train.py[line:551] - INFO: load:1.64 valid_run:2709.03 task_valid:2608.71 collect_output:80.55
2022-10-15 23:27:05 - train.py[line:549] - INFO: 3800 / 4988
2022-10-15 23:27:05 - train.py[line:551] - INFO: load:1.66 valid_run:2857.18 task_valid:2750.11 collect_output:86.31
2022-10-15 23:29:36 - train.py[line:549] - INFO: 4000 / 4988
2022-10-15 23:29:36 - train.py[line:551] - INFO: load:1.69 valid_run:3007.74 task_valid:2895.53 collect_output:90.35
2022-10-15 23:32:08 - train.py[line:549] - INFO: 4200 / 4988
2022-10-15 23:32:08 - train.py[line:551] - INFO: load:1.72 valid_run:3159.95 task_valid:3040.43 collect_output:96.62
2022-10-15 23:34:38 - train.py[line:549] - INFO: 4400 / 4988
2022-10-15 23:34:38 - train.py[line:551] - INFO: load:1.74 valid_run:3309.74 task_valid:3185.45 collect_output:100.29
2022-10-15 23:37:10 - train.py[line:549] - INFO: 4600 / 4988
2022-10-15 23:37:10 - train.py[line:551] - INFO: load:1.77 valid_run:3461.61 task_valid:3332.22 collect_output:104.22
2022-10-15 23:39:42 - train.py[line:549] - INFO: 4800 / 4988
2022-10-15 23:39:42 - train.py[line:551] - INFO: load:1.80 valid_run:3613.43 task_valid:3479.23 collect_output:107.86

====================================================================================================
SGG eval:     R @ 50: 0.2760;     R @ 100: 0.3345;     R @ 500: 0.4153;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1307;    mR @ 100: 0.1712;    mR @ 500: 0.2375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0293) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.3471) (says:0.0000) (sitting on:0.4575) (standing on:0.4550) (using:0.1500) (walking in:0.0000) (walking on:0.0766) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2760;     R @ 100: 0.3345;     R @ 500: 0.4153;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1307;    mR @ 100: 0.1712;    mR @ 500: 0.2375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0293) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.3471) (says:0.0000) (sitting on:0.4575) (standing on:0.4550) (using:0.1500) (walking in:0.0000) (walking on:0.0766) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2022-10-15 23:42:13 - train.py[line:487] - INFO: 0.3345333333333333
2022-10-15 23:42:13 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-15 23:42:13 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.349 | loss_v1 0 | loss_v2 0 | nll_loss 0.216 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.334533 | ppl 1.16 | vqa_score 0.1836 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 3000 | best_R@100 0.334533
2022-10-15 23:42:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2022-10-15 23:42:13 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-15 23:42:20 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-15 23:42:25 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 0.3345333333333333) (writing took 11.376209021080285 seconds)
2022-10-15 23:42:36 - progress_bar.py[line:274] - INFO: epoch 001:   3012 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=0.3, ups=0, wpb=110.4, bsz=40, num_updates=3010, lr=7.35689e-06, gnorm=1.329, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14725
2022-10-15 23:42:47 - progress_bar.py[line:274] - INFO: epoch 001:   3022 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=101.3, ups=0.92, wpb=110, bsz=40, num_updates=3020, lr=7.38134e-06, gnorm=1.32, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14736
2022-10-15 23:42:58 - progress_bar.py[line:274] - INFO: epoch 001:   3032 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97, ups=0.87, wpb=111.7, bsz=40, num_updates=3030, lr=7.40578e-06, gnorm=1.245, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14747
2022-10-15 23:43:10 - progress_bar.py[line:274] - INFO: epoch 001:   3042 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.3, ups=0.89, wpb=109.3, bsz=40, num_updates=3040, lr=7.43022e-06, gnorm=1.543, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=14759
2022-10-15 23:43:21 - progress_bar.py[line:274] - INFO: epoch 001:   3052 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=99, ups=0.9, wpb=109.5, bsz=40, num_updates=3050, lr=7.45466e-06, gnorm=1.335, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14770
2022-10-15 23:43:32 - progress_bar.py[line:274] - INFO: epoch 001:   3062 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=3060, lr=7.4791e-06, gnorm=1.482, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14781
2022-10-15 23:43:43 - progress_bar.py[line:274] - INFO: epoch 001:   3072 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.692, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=3070, lr=7.50354e-06, gnorm=1.462, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14792
2022-10-15 23:43:54 - progress_bar.py[line:274] - INFO: epoch 001:   3082 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=3080, lr=7.52799e-06, gnorm=1.563, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14803
2022-10-15 23:44:06 - progress_bar.py[line:274] - INFO: epoch 001:   3092 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=3090, lr=7.55243e-06, gnorm=1.328, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14815
2022-10-15 23:44:17 - progress_bar.py[line:274] - INFO: epoch 001:   3102 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.65, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=3100, lr=7.57687e-06, gnorm=1.244, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=14826
2022-10-15 23:44:28 - progress_bar.py[line:274] - INFO: epoch 001:   3112 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=3110, lr=7.60131e-06, gnorm=1.329, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14837
2022-10-15 23:44:39 - progress_bar.py[line:274] - INFO: epoch 001:   3122 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.8, ups=0.89, wpb=108.6, bsz=40, num_updates=3120, lr=7.62575e-06, gnorm=1.265, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14848
2022-10-15 23:44:51 - progress_bar.py[line:274] - INFO: epoch 001:   3132 / 102288 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=3130, lr=7.65019e-06, gnorm=1.226, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14860
2022-10-15 23:45:02 - progress_bar.py[line:274] - INFO: epoch 001:   3142 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.633, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=3140, lr=7.67463e-06, gnorm=1.398, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=14871
2022-10-15 23:45:13 - progress_bar.py[line:274] - INFO: epoch 001:   3152 / 102288 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.1, ups=0.87, wpb=110.6, bsz=40, num_updates=3150, lr=7.69908e-06, gnorm=1.395, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14882
2022-10-15 23:45:25 - progress_bar.py[line:274] - INFO: epoch 001:   3162 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.5, ups=0.88, wpb=109.9, bsz=40, num_updates=3160, lr=7.72352e-06, gnorm=1.378, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14894
2022-10-15 23:45:36 - progress_bar.py[line:274] - INFO: epoch 001:   3172 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=3170, lr=7.74796e-06, gnorm=1.337, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14905
2022-10-15 23:45:47 - progress_bar.py[line:274] - INFO: epoch 001:   3182 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.695, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=3180, lr=7.7724e-06, gnorm=1.294, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14916
2022-10-15 23:45:58 - progress_bar.py[line:274] - INFO: epoch 001:   3192 / 102288 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.704, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=3190, lr=7.79684e-06, gnorm=1.265, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14927
2022-10-15 23:46:09 - progress_bar.py[line:274] - INFO: epoch 001:   3202 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.66, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.8, ups=0.91, wpb=110.4, bsz=40, num_updates=3200, lr=7.82128e-06, gnorm=1.27, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14938
2022-10-15 23:46:21 - progress_bar.py[line:274] - INFO: epoch 001:   3212 / 102288 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99.1, ups=0.88, wpb=112.5, bsz=40, num_updates=3210, lr=7.84573e-06, gnorm=1.35, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14950
2022-10-15 23:46:32 - progress_bar.py[line:274] - INFO: epoch 001:   3222 / 102288 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=101.8, ups=0.92, wpb=111, bsz=40, num_updates=3220, lr=7.87017e-06, gnorm=1.448, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14961
2022-10-15 23:46:43 - progress_bar.py[line:274] - INFO: epoch 001:   3232 / 102288 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=100.3, ups=0.91, wpb=109.8, bsz=40, num_updates=3230, lr=7.89461e-06, gnorm=1.353, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14972
2022-10-15 23:46:54 - progress_bar.py[line:274] - INFO: epoch 001:   3242 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.692, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=94.9, ups=0.87, wpb=109.2, bsz=40, num_updates=3240, lr=7.91905e-06, gnorm=1.272, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14983
2022-10-15 23:47:05 - progress_bar.py[line:274] - INFO: epoch 001:   3252 / 102288 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=3250, lr=7.94349e-06, gnorm=1.254, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14994
2022-10-15 23:47:16 - progress_bar.py[line:274] - INFO: epoch 001:   3262 / 102288 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=101.4, ups=0.92, wpb=110.7, bsz=40, num_updates=3260, lr=7.96793e-06, gnorm=1.411, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15005
2022-10-15 23:47:27 - progress_bar.py[line:274] - INFO: epoch 001:   3272 / 102288 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=3270, lr=7.99237e-06, gnorm=1.292, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15016
2022-10-15 23:47:38 - progress_bar.py[line:274] - INFO: epoch 001:   3282 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=101.4, ups=0.91, wpb=110.8, bsz=40, num_updates=3280, lr=8.01682e-06, gnorm=1.31, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15027
2022-10-15 23:47:50 - progress_bar.py[line:274] - INFO: epoch 001:   3292 / 102288 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.4, ups=0.89, wpb=111.7, bsz=40, num_updates=3290, lr=8.04126e-06, gnorm=1.222, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15038
2022-10-15 23:48:01 - progress_bar.py[line:274] - INFO: epoch 001:   3302 / 102288 loss=0.754, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=3300, lr=8.0657e-06, gnorm=1.388, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15050
2022-10-15 23:48:12 - progress_bar.py[line:274] - INFO: epoch 001:   3312 / 102288 loss=0.735, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.8, ups=0.92, wpb=108.9, bsz=40, num_updates=3310, lr=8.09014e-06, gnorm=1.288, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15061
2022-10-15 23:48:23 - progress_bar.py[line:274] - INFO: epoch 001:   3322 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=3320, lr=8.11458e-06, gnorm=1.381, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15072
2022-10-15 23:48:34 - progress_bar.py[line:274] - INFO: epoch 001:   3332 / 102288 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=96.2, ups=0.87, wpb=111.2, bsz=40, num_updates=3330, lr=8.13902e-06, gnorm=1.254, clip=90, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=15083
2022-10-15 23:48:45 - progress_bar.py[line:274] - INFO: epoch 001:   3342 / 102288 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=101.6, ups=0.93, wpb=109.5, bsz=40, num_updates=3340, lr=8.16346e-06, gnorm=1.312, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15094
2022-10-15 23:48:56 - progress_bar.py[line:274] - INFO: epoch 001:   3352 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=3350, lr=8.18791e-06, gnorm=1.364, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15105
2022-10-15 23:49:07 - progress_bar.py[line:274] - INFO: epoch 001:   3362 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=3360, lr=8.21235e-06, gnorm=1.335, clip=100, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15116
2022-10-15 23:49:11 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 23:49:19 - progress_bar.py[line:274] - INFO: epoch 001:   3373 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=91.3, ups=0.83, wpb=110.6, bsz=40, num_updates=3370, lr=8.23679e-06, gnorm=1.342, clip=100, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=15128
2022-10-15 23:49:31 - progress_bar.py[line:274] - INFO: epoch 001:   3383 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.8, ups=0.89, wpb=110.1, bsz=40, num_updates=3380, lr=8.26123e-06, gnorm=1.271, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15140
2022-10-15 23:49:42 - progress_bar.py[line:274] - INFO: epoch 001:   3393 / 102288 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.5, ups=0.91, wpb=108.8, bsz=40, num_updates=3390, lr=8.28567e-06, gnorm=1.378, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15151
2022-10-15 23:49:53 - progress_bar.py[line:274] - INFO: epoch 001:   3403 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=3400, lr=8.31011e-06, gnorm=1.236, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15162
2022-10-15 23:50:04 - progress_bar.py[line:274] - INFO: epoch 001:   3413 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.2, ups=0.89, wpb=110.6, bsz=40, num_updates=3410, lr=8.33456e-06, gnorm=1.416, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15173
2022-10-15 23:50:15 - progress_bar.py[line:274] - INFO: epoch 001:   3423 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.6, ups=0.89, wpb=109.7, bsz=40, num_updates=3420, lr=8.359e-06, gnorm=1.397, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15184
2022-10-15 23:50:27 - progress_bar.py[line:274] - INFO: epoch 001:   3433 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=96.5, ups=0.88, wpb=109.5, bsz=40, num_updates=3430, lr=8.38344e-06, gnorm=1.362, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15196
2022-10-15 23:50:38 - progress_bar.py[line:274] - INFO: epoch 001:   3443 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=3440, lr=8.40788e-06, gnorm=1.663, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15207
2022-10-15 23:50:49 - progress_bar.py[line:274] - INFO: epoch 001:   3453 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.3, ups=0.89, wpb=111.6, bsz=40, num_updates=3450, lr=8.43232e-06, gnorm=1.311, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15218
2022-10-15 23:51:00 - progress_bar.py[line:274] - INFO: epoch 001:   3463 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=105.8, ups=0.96, wpb=110.5, bsz=40, num_updates=3460, lr=8.45676e-06, gnorm=1.367, clip=100, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=15229
2022-10-15 23:51:10 - progress_bar.py[line:274] - INFO: epoch 001:   3473 / 102288 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=100.6, ups=0.91, wpb=110, bsz=40, num_updates=3470, lr=8.4812e-06, gnorm=1.368, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15239
2022-10-15 23:51:22 - progress_bar.py[line:274] - INFO: epoch 001:   3483 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=3480, lr=8.50565e-06, gnorm=1.451, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15251
2022-10-15 23:51:33 - progress_bar.py[line:274] - INFO: epoch 001:   3493 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.689, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.7, ups=0.88, wpb=109.5, bsz=40, num_updates=3490, lr=8.53009e-06, gnorm=1.377, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15262
2022-10-15 23:51:44 - progress_bar.py[line:274] - INFO: epoch 001:   3503 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.7, ups=0.91, wpb=110, bsz=40, num_updates=3500, lr=8.55453e-06, gnorm=1.303, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15273
2022-10-15 23:51:55 - progress_bar.py[line:274] - INFO: epoch 001:   3513 / 102288 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98.4, ups=0.9, wpb=109.1, bsz=40, num_updates=3510, lr=8.57897e-06, gnorm=1.318, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15284
2022-10-15 23:52:06 - progress_bar.py[line:274] - INFO: epoch 001:   3523 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=3520, lr=8.60341e-06, gnorm=1.355, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15295
2022-10-15 23:52:18 - progress_bar.py[line:274] - INFO: epoch 001:   3533 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=3530, lr=8.62785e-06, gnorm=1.33, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15307
2022-10-15 23:52:29 - progress_bar.py[line:274] - INFO: epoch 001:   3543 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=3540, lr=8.6523e-06, gnorm=1.334, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15318
2022-10-15 23:52:40 - progress_bar.py[line:274] - INFO: epoch 001:   3553 / 102288 loss=0.741, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=3550, lr=8.67674e-06, gnorm=1.36, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15329
2022-10-15 23:52:52 - progress_bar.py[line:274] - INFO: epoch 001:   3563 / 102288 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=3560, lr=8.70118e-06, gnorm=1.211, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15341
2022-10-15 23:53:02 - progress_bar.py[line:274] - INFO: epoch 001:   3573 / 102288 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=101.3, ups=0.92, wpb=109.7, bsz=40, num_updates=3570, lr=8.72562e-06, gnorm=1.34, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15351
2022-10-15 23:53:14 - progress_bar.py[line:274] - INFO: epoch 001:   3583 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=3580, lr=8.75006e-06, gnorm=1.255, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15363
2022-10-15 23:53:25 - progress_bar.py[line:274] - INFO: epoch 001:   3593 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=3590, lr=8.7745e-06, gnorm=1.376, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15374
2022-10-15 23:53:36 - progress_bar.py[line:274] - INFO: epoch 001:   3603 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=101.2, ups=0.91, wpb=110.7, bsz=40, num_updates=3600, lr=8.79894e-06, gnorm=1.295, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15385
2022-10-15 23:53:47 - progress_bar.py[line:274] - INFO: epoch 001:   3613 / 102288 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=3610, lr=8.82339e-06, gnorm=1.291, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15396
2022-10-15 23:53:58 - progress_bar.py[line:274] - INFO: epoch 001:   3623 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=3620, lr=8.84783e-06, gnorm=1.372, clip=90, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=15407
2022-10-15 23:54:10 - progress_bar.py[line:274] - INFO: epoch 001:   3633 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.1, ups=0.89, wpb=110.5, bsz=40, num_updates=3630, lr=8.87227e-06, gnorm=1.304, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15419
2022-10-15 23:54:21 - progress_bar.py[line:274] - INFO: epoch 001:   3643 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=3640, lr=8.89671e-06, gnorm=1.3, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15430
2022-10-15 23:54:32 - progress_bar.py[line:274] - INFO: epoch 001:   3653 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=3650, lr=8.92115e-06, gnorm=1.272, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15441
2022-10-15 23:54:43 - progress_bar.py[line:274] - INFO: epoch 001:   3663 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=102.1, ups=0.91, wpb=111.7, bsz=40, num_updates=3660, lr=8.94559e-06, gnorm=1.231, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=15452
2022-10-15 23:54:54 - progress_bar.py[line:274] - INFO: epoch 001:   3673 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.665, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.6, ups=0.88, wpb=109.6, bsz=40, num_updates=3670, lr=8.97003e-06, gnorm=1.437, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15463
2022-10-15 23:55:05 - progress_bar.py[line:274] - INFO: epoch 001:   3683 / 102288 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=3680, lr=8.99448e-06, gnorm=1.247, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=15474
2022-10-15 23:55:16 - progress_bar.py[line:274] - INFO: epoch 001:   3693 / 102288 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.4, ups=0.91, wpb=109.9, bsz=40, num_updates=3690, lr=9.01892e-06, gnorm=1.242, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15485
2022-10-15 23:55:28 - progress_bar.py[line:274] - INFO: epoch 001:   3703 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.3, ups=0.88, wpb=110.1, bsz=40, num_updates=3700, lr=9.04336e-06, gnorm=1.269, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15497
2022-10-15 23:55:38 - progress_bar.py[line:274] - INFO: epoch 001:   3713 / 102288 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=103, ups=0.93, wpb=110.4, bsz=40, num_updates=3710, lr=9.0678e-06, gnorm=1.314, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15507
2022-10-15 23:55:49 - progress_bar.py[line:274] - INFO: epoch 001:   3723 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.9, ups=0.9, wpb=109.7, bsz=40, num_updates=3720, lr=9.09224e-06, gnorm=1.252, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15518
2022-10-15 23:56:00 - progress_bar.py[line:274] - INFO: epoch 001:   3733 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.3, ups=0.92, wpb=109.3, bsz=40, num_updates=3730, lr=9.11668e-06, gnorm=1.32, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15529
2022-10-15 23:56:11 - progress_bar.py[line:274] - INFO: epoch 001:   3743 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=3740, lr=9.14113e-06, gnorm=1.29, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15540
2022-10-15 23:56:22 - progress_bar.py[line:274] - INFO: epoch 001:   3753 / 102288 loss=0.735, loss_v1=0, loss_v2=0, nll_loss=0.65, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=101.1, ups=0.92, wpb=109.9, bsz=40, num_updates=3750, lr=9.16557e-06, gnorm=1.303, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15551
2022-10-15 23:56:33 - progress_bar.py[line:274] - INFO: epoch 001:   3763 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=3760, lr=9.19001e-06, gnorm=1.469, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15562
2022-10-15 23:56:45 - progress_bar.py[line:274] - INFO: epoch 001:   3773 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=3770, lr=9.21445e-06, gnorm=1.301, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15574
2022-10-15 23:56:56 - progress_bar.py[line:274] - INFO: epoch 001:   3783 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=3780, lr=9.23889e-06, gnorm=1.145, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15585
2022-10-15 23:57:07 - progress_bar.py[line:274] - INFO: epoch 001:   3793 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.8, ups=0.89, wpb=109.4, bsz=40, num_updates=3790, lr=9.26333e-06, gnorm=1.195, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15596
2022-10-15 23:57:18 - progress_bar.py[line:274] - INFO: epoch 001:   3803 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98, ups=0.88, wpb=111.5, bsz=40, num_updates=3800, lr=9.28777e-06, gnorm=1.189, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15607
2022-10-15 23:57:30 - progress_bar.py[line:274] - INFO: epoch 001:   3813 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=3810, lr=9.31222e-06, gnorm=1.246, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15619
2022-10-15 23:57:40 - progress_bar.py[line:274] - INFO: epoch 001:   3823 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=103, ups=0.94, wpb=109.7, bsz=40, num_updates=3820, lr=9.33666e-06, gnorm=1.288, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15629
2022-10-15 23:57:51 - progress_bar.py[line:274] - INFO: epoch 001:   3833 / 102288 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=3830, lr=9.3611e-06, gnorm=1.243, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15640
2022-10-15 23:58:03 - progress_bar.py[line:274] - INFO: epoch 001:   3843 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=3840, lr=9.38554e-06, gnorm=1.171, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15652
2022-10-15 23:58:14 - progress_bar.py[line:274] - INFO: epoch 001:   3853 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=96.1, ups=0.87, wpb=110.5, bsz=40, num_updates=3850, lr=9.40998e-06, gnorm=1.289, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15663
2022-10-15 23:58:25 - progress_bar.py[line:274] - INFO: epoch 001:   3863 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=3860, lr=9.43442e-06, gnorm=1.451, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15674
2022-10-15 23:58:36 - progress_bar.py[line:274] - INFO: epoch 001:   3873 / 102288 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=97.3, ups=0.89, wpb=109.2, bsz=40, num_updates=3870, lr=9.45886e-06, gnorm=1.226, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15685
2022-10-15 23:58:48 - progress_bar.py[line:274] - INFO: epoch 001:   3883 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.5, ups=0.89, wpb=109.2, bsz=40, num_updates=3880, lr=9.48331e-06, gnorm=1.323, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15697
2022-10-15 23:58:59 - progress_bar.py[line:274] - INFO: epoch 001:   3893 / 102288 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=3890, lr=9.50775e-06, gnorm=1.177, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15708
2022-10-15 23:59:10 - progress_bar.py[line:274] - INFO: epoch 001:   3903 / 102288 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=3900, lr=9.53219e-06, gnorm=1.219, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15719
2022-10-15 23:59:21 - progress_bar.py[line:274] - INFO: epoch 001:   3913 / 102288 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=3910, lr=9.55663e-06, gnorm=1.247, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15730
2022-10-15 23:59:32 - progress_bar.py[line:274] - INFO: epoch 001:   3923 / 102288 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=103.1, ups=0.93, wpb=111.2, bsz=40, num_updates=3920, lr=9.58107e-06, gnorm=1.33, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15741
2022-10-15 23:59:43 - progress_bar.py[line:274] - INFO: epoch 001:   3933 / 102288 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=94.2, ups=0.87, wpb=108.3, bsz=40, num_updates=3930, lr=9.60551e-06, gnorm=1.25, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15752
2022-10-15 23:59:54 - progress_bar.py[line:274] - INFO: epoch 001:   3943 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.3, ups=0.92, wpb=109.5, bsz=40, num_updates=3940, lr=9.62996e-06, gnorm=1.285, clip=90, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=15763
2022-10-16 00:00:05 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 00:00:06 - progress_bar.py[line:274] - INFO: epoch 001:   3954 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=92.7, ups=0.83, wpb=112.1, bsz=40, num_updates=3950, lr=9.6544e-06, gnorm=1.304, clip=100, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=15775
2022-10-16 00:00:18 - progress_bar.py[line:274] - INFO: epoch 001:   3964 / 102288 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.612, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.5, ups=0.9, wpb=111.2, bsz=40, num_updates=3960, lr=9.67884e-06, gnorm=1.434, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15787
2022-10-16 00:00:29 - progress_bar.py[line:274] - INFO: epoch 001:   3974 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=3970, lr=9.70328e-06, gnorm=1.324, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15798
2022-10-16 00:00:40 - progress_bar.py[line:274] - INFO: epoch 001:   3984 / 102288 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=3980, lr=9.72772e-06, gnorm=1.221, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15809
2022-10-16 00:00:51 - progress_bar.py[line:274] - INFO: epoch 001:   3994 / 102288 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=101.6, ups=0.9, wpb=112.9, bsz=40, num_updates=3990, lr=9.75216e-06, gnorm=1.225, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15820
2022-10-16 00:01:02 - progress_bar.py[line:274] - INFO: epoch 001:   4004 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.7, ups=0.91, wpb=109, bsz=40, num_updates=4000, lr=9.7766e-06, gnorm=1.341, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15831
2022-10-16 00:01:02 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 00:01:03 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 00:01:03 - train.py[line:551] - INFO: load:1.10 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 00:03:35 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 00:03:35 - train.py[line:551] - INFO: load:1.12 valid_run:151.62 task_valid:148.37 collect_output:2.23
2022-10-16 00:06:03 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 00:06:03 - train.py[line:551] - INFO: load:1.15 valid_run:299.60 task_valid:291.48 collect_output:6.08
2022-10-16 00:08:35 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 00:08:35 - train.py[line:551] - INFO: load:1.18 valid_run:451.26 task_valid:434.54 collect_output:13.65
2022-10-16 00:11:04 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 00:11:04 - train.py[line:551] - INFO: load:1.20 valid_run:600.39 task_valid:579.61 collect_output:16.66
2022-10-16 00:13:36 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 00:13:36 - train.py[line:551] - INFO: load:1.23 valid_run:752.57 task_valid:727.22 collect_output:20.18
2022-10-16 00:16:07 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 00:16:07 - train.py[line:551] - INFO: load:1.26 valid_run:903.73 task_valid:872.64 collect_output:24.90
2022-10-16 00:18:41 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 00:18:41 - train.py[line:551] - INFO: load:1.28 valid_run:1056.93 task_valid:1018.95 collect_output:30.78
2022-10-16 00:21:12 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 00:21:12 - train.py[line:551] - INFO: load:1.31 valid_run:1208.16 task_valid:1160.44 collect_output:39.41
2022-10-16 00:23:42 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 00:23:42 - train.py[line:551] - INFO: load:1.34 valid_run:1357.69 task_valid:1305.24 collect_output:43.06
2022-10-16 00:26:10 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 00:26:10 - train.py[line:551] - INFO: load:1.36 valid_run:1506.31 task_valid:1448.66 collect_output:47.20
2022-10-16 00:28:40 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 00:28:40 - train.py[line:551] - INFO: load:1.39 valid_run:1656.02 task_valid:1593.84 collect_output:50.67
2022-10-16 00:31:10 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 00:31:10 - train.py[line:551] - INFO: load:1.42 valid_run:1806.18 task_valid:1739.00 collect_output:54.64
2022-10-16 00:33:40 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 00:33:40 - train.py[line:551] - INFO: load:1.45 valid_run:1955.69 task_valid:1880.65 collect_output:61.48
2022-10-16 00:36:10 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 00:36:10 - train.py[line:551] - INFO: load:1.48 valid_run:2106.09 task_valid:2026.14 collect_output:65.35
2022-10-16 00:38:40 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 00:38:40 - train.py[line:551] - INFO: load:1.50 valid_run:2256.11 task_valid:2172.65 collect_output:67.84
2022-10-16 00:41:10 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 00:41:10 - train.py[line:551] - INFO: load:1.53 valid_run:2406.05 task_valid:2316.94 collect_output:72.45
2022-10-16 00:43:42 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 00:43:42 - train.py[line:551] - INFO: load:1.56 valid_run:2558.09 task_valid:2462.74 collect_output:77.58
2022-10-16 00:46:14 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 00:46:14 - train.py[line:551] - INFO: load:1.58 valid_run:2709.70 task_valid:2610.62 collect_output:80.01
2022-10-16 00:48:43 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 00:48:43 - train.py[line:551] - INFO: load:1.61 valid_run:2858.33 task_valid:2752.97 collect_output:85.17
2022-10-16 00:51:14 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 00:51:14 - train.py[line:551] - INFO: load:1.64 valid_run:3008.99 task_valid:2898.63 collect_output:88.97
2022-10-16 00:53:46 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 00:53:46 - train.py[line:551] - INFO: load:1.67 valid_run:3161.72 task_valid:3043.93 collect_output:95.28
2022-10-16 00:56:16 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 00:56:16 - train.py[line:551] - INFO: load:1.69 valid_run:3311.58 task_valid:3189.34 collect_output:98.65
2022-10-16 00:58:48 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 00:58:48 - train.py[line:551] - INFO: load:1.72 valid_run:3463.37 task_valid:3336.26 collect_output:102.37
2022-10-16 01:01:20 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 01:01:20 - train.py[line:551] - INFO: load:1.75 valid_run:3615.53 task_valid:3483.65 collect_output:105.92

====================================================================================================
SGG eval:     R @ 50: 0.3524;     R @ 100: 0.4216;     R @ 500: 0.5046;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1572;    mR @ 100: 0.2230;    mR @ 500: 0.2996;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0854) (covered in:0.0625) (covering:0.2143) (eating:0.4412) (flying in:0.5000) (growing on:0.2500) (hanging from:0.4677) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2917) (playing:0.0000) (riding:0.6245) (says:0.0000) (sitting on:0.5471) (standing on:0.4450) (using:0.2000) (walking in:0.0000) (walking on:0.2477) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3524;     R @ 100: 0.4216;     R @ 500: 0.5046;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1572;    mR @ 100: 0.2230;    mR @ 500: 0.2996;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0854) (covered in:0.0625) (covering:0.2143) (eating:0.4412) (flying in:0.5000) (growing on:0.2500) (hanging from:0.4677) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2917) (playing:0.0000) (riding:0.6245) (says:0.0000) (sitting on:0.5471) (standing on:0.4450) (using:0.2000) (walking in:0.0000) (walking on:0.2477) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2022-10-16 01:03:52 - train.py[line:487] - INFO: 0.4216190476190476
2022-10-16 01:03:52 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 01:03:52 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.419 | loss_v1 0 | loss_v2 0 | nll_loss 0.302 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.421619 | ppl 1.23 | vqa_score 0.2252 | wps 119 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.421619
2022-10-16 01:03:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2022-10-16 01:03:52 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-16 01:03:58 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-16 01:04:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.4216190476190476) (writing took 11.34357259888202 seconds)
2022-10-16 01:04:14 - progress_bar.py[line:274] - INFO: epoch 001:   4014 / 102288 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=0.3, ups=0, wpb=111.1, bsz=40, num_updates=4010, lr=9.80105e-06, gnorm=1.217, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19623
2022-10-16 01:04:25 - progress_bar.py[line:274] - INFO: epoch 001:   4024 / 102288 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.613, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.5, ups=0.91, wpb=111.2, bsz=40, num_updates=4020, lr=9.82549e-06, gnorm=1.365, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19634
2022-10-16 01:04:37 - progress_bar.py[line:274] - INFO: epoch 001:   4034 / 102288 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.2, ups=0.88, wpb=109.6, bsz=40, num_updates=4030, lr=9.84993e-06, gnorm=1.334, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19646
2022-10-16 01:04:48 - progress_bar.py[line:274] - INFO: epoch 001:   4044 / 102288 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.624, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=4040, lr=9.87437e-06, gnorm=1.238, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19657
2022-10-16 01:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   4054 / 102288 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99.7, ups=0.9, wpb=110.7, bsz=40, num_updates=4050, lr=9.89881e-06, gnorm=1.216, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19668
2022-10-16 01:05:10 - progress_bar.py[line:274] - INFO: epoch 001:   4064 / 102288 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.9, ups=0.88, wpb=111.4, bsz=40, num_updates=4060, lr=9.92325e-06, gnorm=1.359, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19679
2022-10-16 01:05:22 - progress_bar.py[line:274] - INFO: epoch 001:   4074 / 102288 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=94.2, ups=0.86, wpb=110.1, bsz=40, num_updates=4070, lr=9.9477e-06, gnorm=1.269, clip=90, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=19691
2022-10-16 01:05:33 - progress_bar.py[line:274] - INFO: epoch 001:   4084 / 102288 loss=0.761, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.1, ups=0.9, wpb=108.8, bsz=40, num_updates=4080, lr=9.97214e-06, gnorm=1.476, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=19702
2022-10-16 01:05:45 - progress_bar.py[line:274] - INFO: epoch 001:   4094 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=4090, lr=9.99658e-06, gnorm=1.168, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19714
2022-10-16 01:05:56 - progress_bar.py[line:274] - INFO: epoch 001:   4104 / 102288 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=96, ups=0.88, wpb=109.2, bsz=40, num_updates=4100, lr=1.0021e-05, gnorm=1.328, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19725
2022-10-16 01:06:07 - progress_bar.py[line:274] - INFO: epoch 001:   4114 / 102288 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.4, ups=0.88, wpb=111, bsz=40, num_updates=4110, lr=1.00455e-05, gnorm=1.168, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19736
2022-10-16 01:06:19 - progress_bar.py[line:274] - INFO: epoch 001:   4124 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.3, ups=0.88, wpb=110.7, bsz=40, num_updates=4120, lr=1.00699e-05, gnorm=1.127, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19748
2022-10-16 01:06:30 - progress_bar.py[line:274] - INFO: epoch 001:   4134 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97, ups=0.89, wpb=109.3, bsz=40, num_updates=4130, lr=1.00943e-05, gnorm=1.124, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19759
2022-10-16 01:06:41 - progress_bar.py[line:274] - INFO: epoch 001:   4144 / 102288 loss=0.716, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.5, ups=0.9, wpb=109, bsz=40, num_updates=4140, lr=1.01188e-05, gnorm=1.154, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19770
2022-10-16 01:06:52 - progress_bar.py[line:274] - INFO: epoch 001:   4154 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=4150, lr=1.01432e-05, gnorm=1.307, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19781
2022-10-16 01:07:04 - progress_bar.py[line:274] - INFO: epoch 001:   4164 / 102288 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=95.6, ups=0.88, wpb=108.5, bsz=40, num_updates=4160, lr=1.01677e-05, gnorm=1.394, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19793
2022-10-16 01:07:15 - progress_bar.py[line:274] - INFO: epoch 001:   4174 / 102288 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.5, ups=0.89, wpb=109.7, bsz=40, num_updates=4170, lr=1.01921e-05, gnorm=1.33, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19804
2022-10-16 01:07:26 - progress_bar.py[line:274] - INFO: epoch 001:   4184 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.7, ups=0.88, wpb=110.7, bsz=40, num_updates=4180, lr=1.02166e-05, gnorm=1.187, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19815
2022-10-16 01:07:37 - progress_bar.py[line:274] - INFO: epoch 001:   4194 / 102288 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.8, ups=0.91, wpb=109.6, bsz=40, num_updates=4190, lr=1.0241e-05, gnorm=1.194, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19826
2022-10-16 01:07:48 - progress_bar.py[line:274] - INFO: epoch 001:   4204 / 102288 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.613, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=4200, lr=1.02654e-05, gnorm=1.293, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19837
2022-10-16 01:08:00 - progress_bar.py[line:274] - INFO: epoch 001:   4214 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=4210, lr=1.02899e-05, gnorm=1.222, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19849
2022-10-16 01:08:11 - progress_bar.py[line:274] - INFO: epoch 001:   4224 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.2, ups=0.91, wpb=111.1, bsz=40, num_updates=4220, lr=1.03143e-05, gnorm=1.124, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19860
2022-10-16 01:08:22 - progress_bar.py[line:274] - INFO: epoch 001:   4234 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=4230, lr=1.03388e-05, gnorm=1.15, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19871
2022-10-16 01:08:33 - progress_bar.py[line:274] - INFO: epoch 001:   4244 / 102288 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.3, ups=0.89, wpb=109.1, bsz=40, num_updates=4240, lr=1.03632e-05, gnorm=1.192, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19882
2022-10-16 01:08:45 - progress_bar.py[line:274] - INFO: epoch 001:   4254 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=95.9, ups=0.87, wpb=110.3, bsz=40, num_updates=4250, lr=1.03876e-05, gnorm=1.183, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19894
2022-10-16 01:08:56 - progress_bar.py[line:274] - INFO: epoch 001:   4264 / 102288 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.7, ups=0.88, wpb=111.2, bsz=40, num_updates=4260, lr=1.04121e-05, gnorm=1.108, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19905
2022-10-16 01:09:07 - progress_bar.py[line:274] - INFO: epoch 001:   4274 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=4270, lr=1.04365e-05, gnorm=1.197, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19916
2022-10-16 01:09:19 - progress_bar.py[line:274] - INFO: epoch 001:   4284 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.2, ups=0.87, wpb=111.7, bsz=40, num_updates=4280, lr=1.0461e-05, gnorm=1.198, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19928
2022-10-16 01:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   4294 / 102288 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.9, ups=0.89, wpb=108.6, bsz=40, num_updates=4290, lr=1.04854e-05, gnorm=1.143, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19939
2022-10-16 01:09:41 - progress_bar.py[line:274] - INFO: epoch 001:   4304 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.6, ups=0.89, wpb=111, bsz=40, num_updates=4300, lr=1.05098e-05, gnorm=1.129, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19950
2022-10-16 01:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   4314 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=4310, lr=1.05343e-05, gnorm=1.192, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19961
2022-10-16 01:10:04 - progress_bar.py[line:274] - INFO: epoch 001:   4324 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.66, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.5, ups=0.9, wpb=109.4, bsz=40, num_updates=4320, lr=1.05587e-05, gnorm=1.322, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19972
2022-10-16 01:10:15 - progress_bar.py[line:274] - INFO: epoch 001:   4334 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=4330, lr=1.05832e-05, gnorm=1.25, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19984
2022-10-16 01:10:26 - progress_bar.py[line:274] - INFO: epoch 001:   4344 / 102288 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=95.8, ups=0.87, wpb=110.6, bsz=40, num_updates=4340, lr=1.06076e-05, gnorm=1.213, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19995
2022-10-16 01:10:37 - progress_bar.py[line:274] - INFO: epoch 001:   4354 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.6, ups=0.91, wpb=110.4, bsz=40, num_updates=4350, lr=1.06321e-05, gnorm=1.085, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20006
2022-10-16 01:10:48 - progress_bar.py[line:274] - INFO: epoch 001:   4364 / 102288 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.4, ups=0.91, wpb=109, bsz=40, num_updates=4360, lr=1.06565e-05, gnorm=1.193, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20017
2022-10-16 01:10:59 - progress_bar.py[line:274] - INFO: epoch 001:   4374 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=4370, lr=1.06809e-05, gnorm=1.187, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20028
2022-10-16 01:11:11 - progress_bar.py[line:274] - INFO: epoch 001:   4384 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.2, ups=0.89, wpb=109.5, bsz=40, num_updates=4380, lr=1.07054e-05, gnorm=1.421, clip=90, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20040
2022-10-16 01:11:22 - progress_bar.py[line:274] - INFO: epoch 001:   4394 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=4390, lr=1.07298e-05, gnorm=1.214, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20051
2022-10-16 01:11:33 - progress_bar.py[line:274] - INFO: epoch 001:   4404 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=101.2, ups=0.91, wpb=110.9, bsz=40, num_updates=4400, lr=1.07543e-05, gnorm=1.132, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20062
2022-10-16 01:11:44 - progress_bar.py[line:274] - INFO: epoch 001:   4414 / 102288 loss=0.735, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=96.9, ups=0.88, wpb=109.8, bsz=40, num_updates=4410, lr=1.07787e-05, gnorm=1.225, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20073
2022-10-16 01:11:56 - progress_bar.py[line:274] - INFO: epoch 001:   4424 / 102288 loss=0.785, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=95.3, ups=0.88, wpb=108.8, bsz=40, num_updates=4420, lr=1.08031e-05, gnorm=1.213, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20085
2022-10-16 01:12:06 - progress_bar.py[line:274] - INFO: epoch 001:   4434 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100.9, ups=0.92, wpb=109.4, bsz=40, num_updates=4430, lr=1.08276e-05, gnorm=1.142, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20095
2022-10-16 01:12:18 - progress_bar.py[line:274] - INFO: epoch 001:   4444 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.8, ups=0.89, wpb=111.2, bsz=40, num_updates=4440, lr=1.0852e-05, gnorm=1.202, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20107
2022-10-16 01:12:29 - progress_bar.py[line:274] - INFO: epoch 001:   4454 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.1, ups=0.88, wpb=109.3, bsz=40, num_updates=4450, lr=1.08765e-05, gnorm=1.238, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20118
2022-10-16 01:12:40 - progress_bar.py[line:274] - INFO: epoch 001:   4464 / 102288 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=101.1, ups=0.91, wpb=110.5, bsz=40, num_updates=4460, lr=1.09009e-05, gnorm=1.094, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20129
2022-10-16 01:12:51 - progress_bar.py[line:274] - INFO: epoch 001:   4474 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.7, ups=0.88, wpb=109.8, bsz=40, num_updates=4470, lr=1.09254e-05, gnorm=1.182, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20140
2022-10-16 01:13:02 - progress_bar.py[line:274] - INFO: epoch 001:   4484 / 102288 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98.7, ups=0.9, wpb=109.4, bsz=40, num_updates=4480, lr=1.09498e-05, gnorm=1.224, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20151
2022-10-16 01:13:14 - progress_bar.py[line:274] - INFO: epoch 001:   4494 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=4490, lr=1.09742e-05, gnorm=1.105, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20163
2022-10-16 01:13:25 - progress_bar.py[line:274] - INFO: epoch 001:   4504 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=4500, lr=1.09987e-05, gnorm=1.127, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20174
2022-10-16 01:13:35 - progress_bar.py[line:274] - INFO: epoch 001:   4514 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.633, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=105.1, ups=0.94, wpb=111.7, bsz=40, num_updates=4510, lr=1.10231e-05, gnorm=1.124, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20184
2022-10-16 01:13:47 - progress_bar.py[line:274] - INFO: epoch 001:   4524 / 102288 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98, ups=0.88, wpb=111.5, bsz=40, num_updates=4520, lr=1.10476e-05, gnorm=0.996, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20196
2022-10-16 01:13:58 - progress_bar.py[line:274] - INFO: epoch 001:   4534 / 102288 loss=0.736, loss_v1=0, loss_v2=0, nll_loss=0.654, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=4530, lr=1.1072e-05, gnorm=1.097, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20207
2022-10-16 01:14:09 - progress_bar.py[line:274] - INFO: epoch 001:   4544 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=4540, lr=1.10964e-05, gnorm=1.19, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20218
2022-10-16 01:14:21 - progress_bar.py[line:274] - INFO: epoch 001:   4554 / 102288 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=4550, lr=1.11209e-05, gnorm=1.08, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20230
2022-10-16 01:14:32 - progress_bar.py[line:274] - INFO: epoch 001:   4564 / 102288 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=4560, lr=1.11453e-05, gnorm=1.114, clip=80, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20241
2022-10-16 01:14:43 - progress_bar.py[line:274] - INFO: epoch 001:   4574 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.1, ups=0.89, wpb=109.3, bsz=40, num_updates=4570, lr=1.11698e-05, gnorm=1.225, clip=90, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20252
2022-10-16 01:14:54 - progress_bar.py[line:274] - INFO: epoch 001:   4584 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.3, ups=0.9, wpb=108.8, bsz=40, num_updates=4580, lr=1.11942e-05, gnorm=1.081, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20263
2022-10-16 01:15:06 - progress_bar.py[line:274] - INFO: epoch 001:   4594 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=95.1, ups=0.87, wpb=109.1, bsz=40, num_updates=4590, lr=1.12187e-05, gnorm=1.336, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20275
2022-10-16 01:15:17 - progress_bar.py[line:274] - INFO: epoch 001:   4604 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.8, ups=0.89, wpb=109.5, bsz=40, num_updates=4600, lr=1.12431e-05, gnorm=1.116, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20286
2022-10-16 01:15:28 - progress_bar.py[line:274] - INFO: epoch 001:   4614 / 102288 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.1, ups=0.91, wpb=109.5, bsz=40, num_updates=4610, lr=1.12675e-05, gnorm=1.129, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20297
2022-10-16 01:15:39 - progress_bar.py[line:274] - INFO: epoch 001:   4624 / 102288 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=4620, lr=1.1292e-05, gnorm=1.113, clip=60, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20308
2022-10-16 01:15:50 - progress_bar.py[line:274] - INFO: epoch 001:   4634 / 102288 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=97.9, ups=0.88, wpb=111.4, bsz=40, num_updates=4630, lr=1.13164e-05, gnorm=0.991, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20319
2022-10-16 01:16:01 - progress_bar.py[line:274] - INFO: epoch 001:   4644 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=101.8, ups=0.9, wpb=112.7, bsz=40, num_updates=4640, lr=1.13409e-05, gnorm=1.009, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20330
2022-10-16 01:16:12 - progress_bar.py[line:274] - INFO: epoch 001:   4654 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=4650, lr=1.13653e-05, gnorm=1.114, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20341
2022-10-16 01:16:24 - progress_bar.py[line:274] - INFO: epoch 001:   4664 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=94.7, ups=0.87, wpb=109.1, bsz=40, num_updates=4660, lr=1.13897e-05, gnorm=1.11, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20353
2022-10-16 01:16:36 - progress_bar.py[line:274] - INFO: epoch 001:   4674 / 102288 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=96.2, ups=0.87, wpb=110.9, bsz=40, num_updates=4670, lr=1.14142e-05, gnorm=1.091, clip=70, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20365
2022-10-16 01:16:47 - progress_bar.py[line:274] - INFO: epoch 001:   4684 / 102288 loss=0.741, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.8, ups=0.91, wpb=108.9, bsz=40, num_updates=4680, lr=1.14386e-05, gnorm=1.229, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20376
2022-10-16 01:16:58 - progress_bar.py[line:274] - INFO: epoch 001:   4694 / 102288 loss=0.751, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96, ups=0.88, wpb=109, bsz=40, num_updates=4690, lr=1.14631e-05, gnorm=1.101, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20387
2022-10-16 01:17:09 - progress_bar.py[line:274] - INFO: epoch 001:   4704 / 102288 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.621, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=4700, lr=1.14875e-05, gnorm=1.026, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20398
2022-10-16 01:17:20 - progress_bar.py[line:274] - INFO: epoch 001:   4714 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.9, ups=0.89, wpb=109.4, bsz=40, num_updates=4710, lr=1.1512e-05, gnorm=1.086, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20409
2022-10-16 01:17:32 - progress_bar.py[line:274] - INFO: epoch 001:   4724 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=4720, lr=1.15364e-05, gnorm=1.167, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20421
2022-10-16 01:17:43 - progress_bar.py[line:274] - INFO: epoch 001:   4734 / 102288 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=4730, lr=1.15608e-05, gnorm=1.077, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20432
2022-10-16 01:17:54 - progress_bar.py[line:274] - INFO: epoch 001:   4744 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=4740, lr=1.15853e-05, gnorm=1.068, clip=80, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=20443
2022-10-16 01:18:05 - progress_bar.py[line:274] - INFO: epoch 001:   4754 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=96.4, ups=0.88, wpb=109.3, bsz=40, num_updates=4750, lr=1.16097e-05, gnorm=1.186, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20454
2022-10-16 01:18:17 - progress_bar.py[line:274] - INFO: epoch 001:   4764 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=4760, lr=1.16342e-05, gnorm=1.073, clip=80, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20466
2022-10-16 01:18:28 - progress_bar.py[line:274] - INFO: epoch 001:   4774 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=4770, lr=1.16586e-05, gnorm=1.205, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20477
2022-10-16 01:18:39 - progress_bar.py[line:274] - INFO: epoch 001:   4784 / 102288 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=4780, lr=1.1683e-05, gnorm=1.304, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20488
2022-10-16 01:18:50 - progress_bar.py[line:274] - INFO: epoch 001:   4794 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=4790, lr=1.17075e-05, gnorm=1.062, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20499
2022-10-16 01:19:01 - progress_bar.py[line:274] - INFO: epoch 001:   4804 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=101.5, ups=0.93, wpb=109, bsz=40, num_updates=4800, lr=1.17319e-05, gnorm=1.213, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20510
2022-10-16 01:19:13 - progress_bar.py[line:274] - INFO: epoch 001:   4814 / 102288 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=4810, lr=1.17564e-05, gnorm=1.127, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20522
2022-10-16 01:19:24 - progress_bar.py[line:274] - INFO: epoch 001:   4824 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=4820, lr=1.17808e-05, gnorm=1.072, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20533
2022-10-16 01:19:35 - progress_bar.py[line:274] - INFO: epoch 001:   4834 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=4830, lr=1.18053e-05, gnorm=1.169, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20544
2022-10-16 01:19:46 - progress_bar.py[line:274] - INFO: epoch 001:   4844 / 102288 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=4840, lr=1.18297e-05, gnorm=1.119, clip=90, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20555
2022-10-16 01:19:57 - progress_bar.py[line:274] - INFO: epoch 001:   4854 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.4, ups=0.9, wpb=109.8, bsz=40, num_updates=4850, lr=1.18541e-05, gnorm=1.16, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20566
2022-10-16 01:20:08 - progress_bar.py[line:274] - INFO: epoch 001:   4864 / 102288 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=4860, lr=1.18786e-05, gnorm=1.135, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20577
2022-10-16 01:20:19 - progress_bar.py[line:274] - INFO: epoch 001:   4874 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=4870, lr=1.1903e-05, gnorm=1.332, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20588
2022-10-16 01:20:31 - progress_bar.py[line:274] - INFO: epoch 001:   4884 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=4880, lr=1.19275e-05, gnorm=1.217, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20600
2022-10-16 01:20:42 - progress_bar.py[line:274] - INFO: epoch 001:   4894 / 102288 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=95.5, ups=0.88, wpb=108.3, bsz=40, num_updates=4890, lr=1.19519e-05, gnorm=1.095, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20611
2022-10-16 01:20:53 - progress_bar.py[line:274] - INFO: epoch 001:   4904 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=101.5, ups=0.92, wpb=110.4, bsz=40, num_updates=4900, lr=1.19763e-05, gnorm=1.049, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20622
2022-10-16 01:21:04 - progress_bar.py[line:274] - INFO: epoch 001:   4914 / 102288 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.619, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=4910, lr=1.20008e-05, gnorm=1.141, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20633
2022-10-16 01:21:15 - progress_bar.py[line:274] - INFO: epoch 001:   4924 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=4920, lr=1.20252e-05, gnorm=1.086, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20644
2022-10-16 01:21:26 - progress_bar.py[line:274] - INFO: epoch 001:   4934 / 102288 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=4930, lr=1.20497e-05, gnorm=1.109, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20655
2022-10-16 01:21:37 - progress_bar.py[line:274] - INFO: epoch 001:   4944 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=101.6, ups=0.92, wpb=111, bsz=40, num_updates=4940, lr=1.20741e-05, gnorm=1.13, clip=70, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20666
2022-10-16 01:21:42 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 01:21:50 - progress_bar.py[line:274] - INFO: epoch 001:   4955 / 102288 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=89.8, ups=0.82, wpb=109.9, bsz=40, num_updates=4950, lr=1.20985e-05, gnorm=1.151, clip=70, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=20679
2022-10-16 01:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   4965 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=103.3, ups=0.93, wpb=110.8, bsz=40, num_updates=4960, lr=1.2123e-05, gnorm=0.99, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20689
2022-10-16 01:22:12 - progress_bar.py[line:274] - INFO: epoch 001:   4975 / 102288 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=96.2, ups=0.87, wpb=110.9, bsz=40, num_updates=4970, lr=1.21474e-05, gnorm=1.251, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20701
2022-10-16 01:22:23 - progress_bar.py[line:274] - INFO: epoch 001:   4985 / 102288 loss=0.736, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100, ups=0.91, wpb=110.4, bsz=40, num_updates=4980, lr=1.21719e-05, gnorm=1.155, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20712
2022-10-16 01:22:34 - progress_bar.py[line:274] - INFO: epoch 001:   4995 / 102288 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=4990, lr=1.21963e-05, gnorm=1.174, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20723
2022-10-16 01:22:45 - progress_bar.py[line:274] - INFO: epoch 001:   5005 / 102288 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=5000, lr=1.22208e-05, gnorm=1.17, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20734
2022-10-16 01:22:45 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 01:22:47 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 01:22:47 - train.py[line:551] - INFO: load:0.97 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 01:25:18 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 01:25:18 - train.py[line:551] - INFO: load:1.00 valid_run:151.60 task_valid:147.99 collect_output:2.58
2022-10-16 01:27:46 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 01:27:46 - train.py[line:551] - INFO: load:1.02 valid_run:299.36 task_valid:291.03 collect_output:6.31
2022-10-16 01:30:18 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 01:30:18 - train.py[line:551] - INFO: load:1.05 valid_run:450.97 task_valid:434.01 collect_output:13.94
2022-10-16 01:32:46 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 01:32:46 - train.py[line:551] - INFO: load:1.07 valid_run:599.65 task_valid:578.98 collect_output:16.62
2022-10-16 01:35:18 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 01:35:18 - train.py[line:551] - INFO: load:1.10 valid_run:751.59 task_valid:726.47 collect_output:20.07
2022-10-16 01:37:50 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 01:37:50 - train.py[line:551] - INFO: load:1.12 valid_run:902.72 task_valid:871.83 collect_output:24.85
2022-10-16 01:40:22 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 01:40:22 - train.py[line:551] - INFO: load:1.15 valid_run:1055.47 task_valid:1017.80 collect_output:30.65
2022-10-16 01:42:53 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 01:42:53 - train.py[line:551] - INFO: load:1.17 valid_run:1206.00 task_valid:1158.88 collect_output:39.08
2022-10-16 01:45:22 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 01:45:22 - train.py[line:551] - INFO: load:1.20 valid_run:1355.24 task_valid:1303.59 collect_output:42.61
2022-10-16 01:47:51 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 01:47:51 - train.py[line:551] - INFO: load:1.22 valid_run:1503.53 task_valid:1446.86 collect_output:46.59
2022-10-16 01:50:20 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 01:50:20 - train.py[line:551] - INFO: load:1.25 valid_run:1652.85 task_valid:1591.67 collect_output:50.08
2022-10-16 01:52:50 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 01:52:50 - train.py[line:551] - INFO: load:1.27 valid_run:1802.57 task_valid:1736.68 collect_output:53.78
2022-10-16 01:55:19 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 01:55:19 - train.py[line:551] - INFO: load:1.30 valid_run:1952.15 task_valid:1878.68 collect_output:60.36
2022-10-16 01:57:50 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 01:57:50 - train.py[line:551] - INFO: load:1.32 valid_run:2102.40 task_valid:2024.13 collect_output:64.12
2022-10-16 02:00:20 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 02:00:20 - train.py[line:551] - INFO: load:1.35 valid_run:2252.66 task_valid:2171.04 collect_output:66.36
2022-10-16 02:02:50 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 02:02:50 - train.py[line:551] - INFO: load:1.39 valid_run:2402.99 task_valid:2315.65 collect_output:70.95
2022-10-16 02:05:22 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 02:05:22 - train.py[line:551] - INFO: load:1.41 valid_run:2554.61 task_valid:2461.49 collect_output:75.64
2022-10-16 02:07:53 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 02:07:53 - train.py[line:551] - INFO: load:1.44 valid_run:2705.49 task_valid:2608.95 collect_output:77.96
2022-10-16 02:10:21 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 02:10:21 - train.py[line:551] - INFO: load:1.46 valid_run:2853.61 task_valid:2750.96 collect_output:82.95
2022-10-16 02:12:52 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 02:12:52 - train.py[line:551] - INFO: load:1.49 valid_run:3004.13 task_valid:2896.39 collect_output:86.91
2022-10-16 02:15:24 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 02:15:24 - train.py[line:551] - INFO: load:1.52 valid_run:3156.17 task_valid:3041.37 collect_output:92.91
2022-10-16 02:17:54 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 02:17:54 - train.py[line:551] - INFO: load:1.54 valid_run:3305.70 task_valid:3186.44 collect_output:96.24
2022-10-16 02:20:25 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 02:20:25 - train.py[line:551] - INFO: load:1.57 valid_run:3457.04 task_valid:3333.09 collect_output:99.83
2022-10-16 02:22:57 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 02:22:57 - train.py[line:551] - INFO: load:1.60 valid_run:3608.89 task_valid:3480.53 collect_output:103.15

====================================================================================================
SGG eval:     R @ 50: 0.4153;     R @ 100: 0.4763;     R @ 500: 0.5318;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2044;    mR @ 100: 0.2725;    mR @ 500: 0.3280;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1512) (covered in:0.1250) (covering:0.2857) (eating:0.5294) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4290) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.4583) (playing:0.0000) (riding:0.7137) (says:0.0000) (sitting on:0.6429) (standing on:0.3500) (using:0.3000) (walking in:0.0000) (walking on:0.4865) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4153;     R @ 100: 0.4763;     R @ 500: 0.5318;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2044;    mR @ 100: 0.2725;    mR @ 500: 0.3280;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1512) (covered in:0.1250) (covering:0.2857) (eating:0.5294) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4290) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.4583) (playing:0.0000) (riding:0.7137) (says:0.0000) (sitting on:0.6429) (standing on:0.3500) (using:0.3000) (walking in:0.0000) (walking on:0.4865) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================

2022-10-16 02:25:28 - train.py[line:487] - INFO: 0.4763471861471862
2022-10-16 02:25:28 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 02:25:28 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.388 | loss_v1 0 | loss_v2 0 | nll_loss 0.258 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.476347 | ppl 1.2 | vqa_score 0.2759 | wps 119.3 | wpb 89.9 | bsz 30 | num_updates 5000 | best_R@100 0.476347
2022-10-16 02:25:28 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 5000 updates
2022-10-16 02:25:28 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-16 02:25:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-16 02:25:40 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 0.4763471861471862) (writing took 12.025970473885536 seconds)
2022-10-16 02:25:52 - progress_bar.py[line:274] - INFO: epoch 001:   5015 / 102288 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=0.3, ups=0, wpb=111.5, bsz=40, num_updates=5010, lr=1.22452e-05, gnorm=1.038, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24521
2022-10-16 02:26:03 - progress_bar.py[line:274] - INFO: epoch 001:   5025 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=5020, lr=1.22696e-05, gnorm=1.182, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24532
2022-10-16 02:26:14 - progress_bar.py[line:274] - INFO: epoch 001:   5035 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=96.9, ups=0.89, wpb=108.9, bsz=40, num_updates=5030, lr=1.22941e-05, gnorm=1.171, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24543
2022-10-16 02:26:26 - progress_bar.py[line:274] - INFO: epoch 001:   5045 / 102288 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=96.2, ups=0.88, wpb=109.4, bsz=40, num_updates=5040, lr=1.23185e-05, gnorm=1.104, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24555
2022-10-16 02:26:37 - progress_bar.py[line:274] - INFO: epoch 001:   5055 / 102288 loss=0.735, loss_v1=0, loss_v2=0, nll_loss=0.65, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.6, ups=0.9, wpb=109.3, bsz=40, num_updates=5050, lr=1.2343e-05, gnorm=1.097, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24566
2022-10-16 02:26:48 - progress_bar.py[line:274] - INFO: epoch 001:   5065 / 102288 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=98.9, ups=0.9, wpb=109.4, bsz=40, num_updates=5060, lr=1.23674e-05, gnorm=1.154, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24577
2022-10-16 02:26:59 - progress_bar.py[line:274] - INFO: epoch 001:   5075 / 102288 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=5070, lr=1.23918e-05, gnorm=1.051, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24588
2022-10-16 02:27:11 - progress_bar.py[line:274] - INFO: epoch 001:   5085 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=96.6, ups=0.88, wpb=109.6, bsz=40, num_updates=5080, lr=1.24163e-05, gnorm=1.172, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24600
2022-10-16 02:27:22 - progress_bar.py[line:274] - INFO: epoch 001:   5095 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.629, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.6, ups=0.88, wpb=112.1, bsz=40, num_updates=5090, lr=1.24407e-05, gnorm=1.19, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24611
2022-10-16 02:27:33 - progress_bar.py[line:274] - INFO: epoch 001:   5105 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.4, ups=0.9, wpb=111.1, bsz=40, num_updates=5100, lr=1.24652e-05, gnorm=1.132, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24622
2022-10-16 02:27:44 - progress_bar.py[line:274] - INFO: epoch 001:   5115 / 102288 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=100.4, ups=0.9, wpb=111.2, bsz=40, num_updates=5110, lr=1.24896e-05, gnorm=1.123, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24633
2022-10-16 02:27:56 - progress_bar.py[line:274] - INFO: epoch 001:   5125 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=5120, lr=1.25141e-05, gnorm=1.222, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24645
2022-10-16 02:28:07 - progress_bar.py[line:274] - INFO: epoch 001:   5135 / 102288 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.624, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=5130, lr=1.25385e-05, gnorm=1.227, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24656
2022-10-16 02:28:18 - progress_bar.py[line:274] - INFO: epoch 001:   5145 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=103, ups=0.93, wpb=110.9, bsz=40, num_updates=5140, lr=1.25629e-05, gnorm=1.169, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24667
2022-10-16 02:28:29 - progress_bar.py[line:274] - INFO: epoch 001:   5155 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=101.3, ups=0.9, wpb=112, bsz=40, num_updates=5150, lr=1.25874e-05, gnorm=1.144, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24678
2022-10-16 02:28:40 - progress_bar.py[line:274] - INFO: epoch 001:   5165 / 102288 loss=0.773, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=5160, lr=1.26118e-05, gnorm=1.235, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24689
2022-10-16 02:28:51 - progress_bar.py[line:274] - INFO: epoch 001:   5175 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=101.7, ups=0.9, wpb=112.5, bsz=40, num_updates=5170, lr=1.26363e-05, gnorm=1.225, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24700
2022-10-16 02:29:02 - progress_bar.py[line:274] - INFO: epoch 001:   5185 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.629, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=5180, lr=1.26607e-05, gnorm=1.006, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24711
2022-10-16 02:29:13 - progress_bar.py[line:274] - INFO: epoch 001:   5195 / 102288 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=5190, lr=1.26851e-05, gnorm=1.07, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24722
2022-10-16 02:29:25 - progress_bar.py[line:274] - INFO: epoch 001:   5205 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=96.4, ups=0.87, wpb=110.7, bsz=40, num_updates=5200, lr=1.27096e-05, gnorm=1.105, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24734
2022-10-16 02:29:36 - progress_bar.py[line:274] - INFO: epoch 001:   5215 / 102288 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.4, ups=0.91, wpb=109.4, bsz=40, num_updates=5210, lr=1.2734e-05, gnorm=1.171, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24745
2022-10-16 02:29:47 - progress_bar.py[line:274] - INFO: epoch 001:   5225 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.66, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=96.5, ups=0.88, wpb=109.6, bsz=40, num_updates=5220, lr=1.27585e-05, gnorm=1.11, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24756
2022-10-16 02:29:58 - progress_bar.py[line:274] - INFO: epoch 001:   5235 / 102288 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=5230, lr=1.27829e-05, gnorm=1.184, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24767
2022-10-16 02:30:09 - progress_bar.py[line:274] - INFO: epoch 001:   5245 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=100.5, ups=0.92, wpb=109, bsz=40, num_updates=5240, lr=1.28074e-05, gnorm=1.237, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24778
2022-10-16 02:30:21 - progress_bar.py[line:274] - INFO: epoch 001:   5255 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.629, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=96.6, ups=0.88, wpb=110, bsz=40, num_updates=5250, lr=1.28318e-05, gnorm=1.11, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24790
2022-10-16 02:30:32 - progress_bar.py[line:274] - INFO: epoch 001:   5265 / 102288 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=5260, lr=1.28562e-05, gnorm=1.09, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24801
2022-10-16 02:30:43 - progress_bar.py[line:274] - INFO: epoch 001:   5275 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=95.1, ups=0.87, wpb=109.3, bsz=40, num_updates=5270, lr=1.28807e-05, gnorm=1.233, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24812
2022-10-16 02:30:54 - progress_bar.py[line:274] - INFO: epoch 001:   5285 / 102288 loss=0.735, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.1, ups=0.9, wpb=109.5, bsz=40, num_updates=5280, lr=1.29051e-05, gnorm=1.236, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24823
2022-10-16 02:31:05 - progress_bar.py[line:274] - INFO: epoch 001:   5295 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=100, ups=0.92, wpb=109.1, bsz=40, num_updates=5290, lr=1.29296e-05, gnorm=1.123, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24834
2022-10-16 02:31:16 - progress_bar.py[line:274] - INFO: epoch 001:   5305 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=5300, lr=1.2954e-05, gnorm=1.296, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24845
2022-10-16 02:31:27 - progress_bar.py[line:274] - INFO: epoch 001:   5315 / 102288 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100.3, ups=0.91, wpb=109.7, bsz=40, num_updates=5310, lr=1.29784e-05, gnorm=1.165, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24856
2022-10-16 02:31:38 - progress_bar.py[line:274] - INFO: epoch 001:   5325 / 102288 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100, ups=0.9, wpb=110.9, bsz=40, num_updates=5320, lr=1.30029e-05, gnorm=1.092, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24867
2022-10-16 02:31:49 - progress_bar.py[line:274] - INFO: epoch 001:   5335 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.633, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.3, ups=0.9, wpb=108.8, bsz=40, num_updates=5330, lr=1.30273e-05, gnorm=1.164, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24878
2022-10-16 02:32:01 - progress_bar.py[line:274] - INFO: epoch 001:   5345 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=5340, lr=1.30518e-05, gnorm=1.261, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24889
2022-10-16 02:32:12 - progress_bar.py[line:274] - INFO: epoch 001:   5355 / 102288 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=5350, lr=1.30762e-05, gnorm=1.245, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24901
2022-10-16 02:32:23 - progress_bar.py[line:274] - INFO: epoch 001:   5365 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=5360, lr=1.31007e-05, gnorm=1.053, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24912
2022-10-16 02:32:34 - progress_bar.py[line:274] - INFO: epoch 001:   5375 / 102288 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=95.8, ups=0.87, wpb=110.1, bsz=40, num_updates=5370, lr=1.31251e-05, gnorm=1.232, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24923
2022-10-16 02:32:45 - progress_bar.py[line:274] - INFO: epoch 001:   5385 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=5380, lr=1.31495e-05, gnorm=1.208, clip=80, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24934
2022-10-16 02:32:56 - progress_bar.py[line:274] - INFO: epoch 001:   5395 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.629, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.3, ups=0.91, wpb=108.6, bsz=40, num_updates=5390, lr=1.3174e-05, gnorm=1.296, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24945
2022-10-16 02:33:07 - progress_bar.py[line:274] - INFO: epoch 001:   5405 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.1, ups=0.9, wpb=109.9, bsz=40, num_updates=5400, lr=1.31984e-05, gnorm=1.138, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24956
2022-10-16 02:33:19 - progress_bar.py[line:274] - INFO: epoch 001:   5415 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=5410, lr=1.32229e-05, gnorm=1.149, clip=80, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24968
2022-10-16 02:33:30 - progress_bar.py[line:274] - INFO: epoch 001:   5425 / 102288 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.5, ups=0.9, wpb=111.2, bsz=40, num_updates=5420, lr=1.32473e-05, gnorm=1.107, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24979
2022-10-16 02:33:41 - progress_bar.py[line:274] - INFO: epoch 001:   5435 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=5430, lr=1.32717e-05, gnorm=1.099, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24990
2022-10-16 02:33:52 - progress_bar.py[line:274] - INFO: epoch 001:   5445 / 102288 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=101.3, ups=0.92, wpb=110.5, bsz=40, num_updates=5440, lr=1.32962e-05, gnorm=1.294, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25001
2022-10-16 02:34:03 - progress_bar.py[line:274] - INFO: epoch 001:   5455 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=5450, lr=1.33206e-05, gnorm=1.437, clip=90, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25012
2022-10-16 02:34:14 - progress_bar.py[line:274] - INFO: epoch 001:   5465 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.8, ups=0.9, wpb=110.3, bsz=40, num_updates=5460, lr=1.33451e-05, gnorm=1.355, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25023
2022-10-16 02:34:25 - progress_bar.py[line:274] - INFO: epoch 001:   5475 / 102288 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=5470, lr=1.33695e-05, gnorm=1.274, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25034
2022-10-16 02:34:36 - progress_bar.py[line:274] - INFO: epoch 001:   5485 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.6, ups=0.92, wpb=110.9, bsz=40, num_updates=5480, lr=1.33939e-05, gnorm=1.149, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25045
2022-10-16 02:34:47 - progress_bar.py[line:274] - INFO: epoch 001:   5495 / 102288 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.5, ups=0.93, wpb=109.3, bsz=40, num_updates=5490, lr=1.34184e-05, gnorm=1.218, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25056
2022-10-16 02:34:58 - progress_bar.py[line:274] - INFO: epoch 001:   5505 / 102288 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.2, ups=0.88, wpb=109.2, bsz=40, num_updates=5500, lr=1.34428e-05, gnorm=1.282, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25067
2022-10-16 02:35:09 - progress_bar.py[line:274] - INFO: epoch 001:   5515 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=100.9, ups=0.9, wpb=111.5, bsz=40, num_updates=5510, lr=1.34673e-05, gnorm=1.236, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25078
2022-10-16 02:35:20 - progress_bar.py[line:274] - INFO: epoch 001:   5525 / 102288 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=100.9, ups=0.92, wpb=110.1, bsz=40, num_updates=5520, lr=1.34917e-05, gnorm=1.506, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25089
2022-10-16 02:35:31 - progress_bar.py[line:274] - INFO: epoch 001:   5535 / 102288 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=101.7, ups=0.92, wpb=110.9, bsz=40, num_updates=5530, lr=1.35162e-05, gnorm=1.388, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25100
2022-10-16 02:35:42 - progress_bar.py[line:274] - INFO: epoch 001:   5545 / 102288 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=5540, lr=1.35406e-05, gnorm=1.381, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25111
2022-10-16 02:35:54 - progress_bar.py[line:274] - INFO: epoch 001:   5555 / 102288 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=5550, lr=1.3565e-05, gnorm=1.326, clip=100, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=25123
2022-10-16 02:35:57 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 02:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   5566 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=89.4, ups=0.81, wpb=109.7, bsz=40, num_updates=5560, lr=1.35895e-05, gnorm=1.391, clip=100, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=25135
2022-10-16 02:36:17 - progress_bar.py[line:274] - INFO: epoch 001:   5576 / 102288 loss=0.761, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.2, ups=0.89, wpb=107.8, bsz=40, num_updates=5570, lr=1.36139e-05, gnorm=1.388, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25146
2022-10-16 02:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   5586 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=5580, lr=1.36384e-05, gnorm=1.29, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25157
2022-10-16 02:36:40 - progress_bar.py[line:274] - INFO: epoch 001:   5596 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=5590, lr=1.36628e-05, gnorm=1.551, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25169
2022-10-16 02:36:51 - progress_bar.py[line:274] - INFO: epoch 001:   5606 / 102288 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.621, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=5600, lr=1.36872e-05, gnorm=1.487, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25180
2022-10-16 02:37:02 - progress_bar.py[line:274] - INFO: epoch 001:   5616 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=5610, lr=1.37117e-05, gnorm=1.296, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25191
2022-10-16 02:37:14 - progress_bar.py[line:274] - INFO: epoch 001:   5626 / 102288 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=95.4, ups=0.87, wpb=110.2, bsz=40, num_updates=5620, lr=1.37361e-05, gnorm=1.319, clip=100, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=25203
2022-10-16 02:37:25 - progress_bar.py[line:274] - INFO: epoch 001:   5636 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.9, ups=0.9, wpb=109.4, bsz=40, num_updates=5630, lr=1.37606e-05, gnorm=1.288, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25214
2022-10-16 02:37:36 - progress_bar.py[line:274] - INFO: epoch 001:   5646 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=5640, lr=1.3785e-05, gnorm=1.383, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25225
2022-10-16 02:37:47 - progress_bar.py[line:274] - INFO: epoch 001:   5656 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=104.7, ups=0.94, wpb=110.8, bsz=40, num_updates=5650, lr=1.38095e-05, gnorm=1.267, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25236
2022-10-16 02:37:58 - progress_bar.py[line:274] - INFO: epoch 001:   5666 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.621, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=100.9, ups=0.92, wpb=109.6, bsz=40, num_updates=5660, lr=1.38339e-05, gnorm=1.402, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25247
2022-10-16 02:38:09 - progress_bar.py[line:274] - INFO: epoch 001:   5676 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=5670, lr=1.38583e-05, gnorm=1.3, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25258
2022-10-16 02:38:20 - progress_bar.py[line:274] - INFO: epoch 001:   5686 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=94.6, ups=0.87, wpb=108.9, bsz=40, num_updates=5680, lr=1.38828e-05, gnorm=1.29, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25269
2022-10-16 02:38:31 - progress_bar.py[line:274] - INFO: epoch 001:   5696 / 102288 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=5690, lr=1.39072e-05, gnorm=1.26, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25280
2022-10-16 02:38:43 - progress_bar.py[line:274] - INFO: epoch 001:   5706 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=95.7, ups=0.87, wpb=110.3, bsz=40, num_updates=5700, lr=1.39317e-05, gnorm=1.292, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25292
2022-10-16 02:38:54 - progress_bar.py[line:274] - INFO: epoch 001:   5716 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.8, ups=0.89, wpb=109.5, bsz=40, num_updates=5710, lr=1.39561e-05, gnorm=1.376, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25303
2022-10-16 02:39:05 - progress_bar.py[line:274] - INFO: epoch 001:   5726 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.4, ups=0.89, wpb=112.6, bsz=40, num_updates=5720, lr=1.39805e-05, gnorm=1.324, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25314
2022-10-16 02:39:16 - progress_bar.py[line:274] - INFO: epoch 001:   5736 / 102288 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=97.3, ups=0.89, wpb=108.9, bsz=40, num_updates=5730, lr=1.4005e-05, gnorm=1.363, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25325
2022-10-16 02:39:27 - progress_bar.py[line:274] - INFO: epoch 001:   5746 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=101.7, ups=0.93, wpb=109.7, bsz=40, num_updates=5740, lr=1.40294e-05, gnorm=1.391, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25336
2022-10-16 02:39:39 - progress_bar.py[line:274] - INFO: epoch 001:   5756 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=5750, lr=1.40539e-05, gnorm=1.369, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25348
2022-10-16 02:39:50 - progress_bar.py[line:274] - INFO: epoch 001:   5766 / 102288 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=94.7, ups=0.85, wpb=111.5, bsz=40, num_updates=5760, lr=1.40783e-05, gnorm=1.556, clip=90, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=25359
2022-10-16 02:40:01 - progress_bar.py[line:274] - INFO: epoch 001:   5776 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=103.6, ups=0.93, wpb=111.7, bsz=40, num_updates=5770, lr=1.41028e-05, gnorm=1.432, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=25370
2022-10-16 02:40:13 - progress_bar.py[line:274] - INFO: epoch 001:   5786 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=95.3, ups=0.87, wpb=109.8, bsz=40, num_updates=5780, lr=1.41272e-05, gnorm=1.292, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25382
2022-10-16 02:40:24 - progress_bar.py[line:274] - INFO: epoch 001:   5796 / 102288 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=5790, lr=1.41516e-05, gnorm=1.334, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25393
2022-10-16 02:40:35 - progress_bar.py[line:274] - INFO: epoch 001:   5806 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.8, ups=0.9, wpb=109.4, bsz=40, num_updates=5800, lr=1.41761e-05, gnorm=1.463, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25404
2022-10-16 02:40:46 - progress_bar.py[line:274] - INFO: epoch 001:   5816 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.1, ups=0.92, wpb=109.2, bsz=40, num_updates=5810, lr=1.42005e-05, gnorm=1.541, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25415
2022-10-16 02:40:57 - progress_bar.py[line:274] - INFO: epoch 001:   5826 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=5820, lr=1.4225e-05, gnorm=1.452, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25426
2022-10-16 02:41:08 - progress_bar.py[line:274] - INFO: epoch 001:   5836 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.587, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=97.3, ups=0.88, wpb=110.6, bsz=40, num_updates=5830, lr=1.42494e-05, gnorm=1.275, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25437
2022-10-16 02:41:20 - progress_bar.py[line:274] - INFO: epoch 001:   5846 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.1, ups=0.89, wpb=109.7, bsz=40, num_updates=5840, lr=1.42738e-05, gnorm=1.381, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25449
2022-10-16 02:41:31 - progress_bar.py[line:274] - INFO: epoch 001:   5856 / 102288 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=101.5, ups=0.91, wpb=112.1, bsz=40, num_updates=5850, lr=1.42983e-05, gnorm=1.262, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25460
2022-10-16 02:41:41 - progress_bar.py[line:274] - INFO: epoch 001:   5866 / 102288 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=100.4, ups=0.92, wpb=108.9, bsz=40, num_updates=5860, lr=1.43227e-05, gnorm=1.39, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25470
2022-10-16 02:41:53 - progress_bar.py[line:274] - INFO: epoch 001:   5876 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=96.7, ups=0.88, wpb=109.8, bsz=40, num_updates=5870, lr=1.43472e-05, gnorm=1.246, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25482
2022-10-16 02:42:04 - progress_bar.py[line:274] - INFO: epoch 001:   5886 / 102288 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.4, ups=0.89, wpb=110.7, bsz=40, num_updates=5880, lr=1.43716e-05, gnorm=1.52, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25493
2022-10-16 02:42:15 - progress_bar.py[line:274] - INFO: epoch 001:   5896 / 102288 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=5890, lr=1.43961e-05, gnorm=1.438, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25504
2022-10-16 02:42:26 - progress_bar.py[line:274] - INFO: epoch 001:   5906 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=102.4, ups=0.93, wpb=110.3, bsz=40, num_updates=5900, lr=1.44205e-05, gnorm=1.453, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25515
2022-10-16 02:42:37 - progress_bar.py[line:274] - INFO: epoch 001:   5916 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=5910, lr=1.44449e-05, gnorm=1.525, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25526
2022-10-16 02:42:49 - progress_bar.py[line:274] - INFO: epoch 001:   5926 / 102288 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.586, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=5920, lr=1.44694e-05, gnorm=1.422, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25538
2022-10-16 02:43:00 - progress_bar.py[line:274] - INFO: epoch 001:   5936 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=5930, lr=1.44938e-05, gnorm=1.299, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25549
2022-10-16 02:43:11 - progress_bar.py[line:274] - INFO: epoch 001:   5946 / 102288 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=5940, lr=1.45183e-05, gnorm=1.276, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25560
2022-10-16 02:43:22 - progress_bar.py[line:274] - INFO: epoch 001:   5956 / 102288 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.7, ups=0.92, wpb=109.9, bsz=40, num_updates=5950, lr=1.45427e-05, gnorm=1.437, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25571
2022-10-16 02:43:33 - progress_bar.py[line:274] - INFO: epoch 001:   5966 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=101.3, ups=0.92, wpb=110.6, bsz=40, num_updates=5960, lr=1.45671e-05, gnorm=1.359, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25582
2022-10-16 02:43:44 - progress_bar.py[line:274] - INFO: epoch 001:   5976 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=5970, lr=1.45916e-05, gnorm=1.438, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25593
2022-10-16 02:43:56 - progress_bar.py[line:274] - INFO: epoch 001:   5986 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=5980, lr=1.4616e-05, gnorm=1.361, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25605
2022-10-16 02:44:06 - progress_bar.py[line:274] - INFO: epoch 001:   5996 / 102288 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.1, ups=0.93, wpb=108.7, bsz=40, num_updates=5990, lr=1.46405e-05, gnorm=1.555, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25615
2022-10-16 02:44:18 - progress_bar.py[line:274] - INFO: epoch 001:   6006 / 102288 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=97.5, ups=0.89, wpb=109.3, bsz=40, num_updates=6000, lr=1.46649e-05, gnorm=1.574, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25626
2022-10-16 02:44:18 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 02:44:19 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 02:44:19 - train.py[line:551] - INFO: load:0.93 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 02:46:50 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 02:46:50 - train.py[line:551] - INFO: load:0.96 valid_run:151.54 task_valid:148.01 collect_output:2.46
2022-10-16 02:49:19 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 02:49:19 - train.py[line:551] - INFO: load:0.98 valid_run:299.83 task_valid:291.21 collect_output:6.50
2022-10-16 02:51:50 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 02:51:50 - train.py[line:551] - INFO: load:1.01 valid_run:451.45 task_valid:434.14 collect_output:14.17
2022-10-16 02:54:19 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 02:54:19 - train.py[line:551] - INFO: load:1.04 valid_run:600.04 task_valid:578.92 collect_output:16.97
2022-10-16 02:56:51 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 02:56:51 - train.py[line:551] - INFO: load:1.06 valid_run:751.99 task_valid:726.38 collect_output:20.40
2022-10-16 02:59:23 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 02:59:23 - train.py[line:551] - INFO: load:1.09 valid_run:903.46 task_valid:872.01 collect_output:25.20
2022-10-16 03:01:56 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 03:01:56 - train.py[line:551] - INFO: load:1.11 valid_run:1056.51 task_valid:1018.29 collect_output:30.92
2022-10-16 03:04:26 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 03:04:26 - train.py[line:551] - INFO: load:1.14 valid_run:1206.99 task_valid:1159.56 collect_output:39.10
2022-10-16 03:06:56 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 03:06:56 - train.py[line:551] - INFO: load:1.17 valid_run:1356.25 task_valid:1304.31 collect_output:42.59
2022-10-16 03:09:24 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 03:09:24 - train.py[line:551] - INFO: load:1.19 valid_run:1504.84 task_valid:1447.83 collect_output:46.59
2022-10-16 03:11:54 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 03:11:54 - train.py[line:551] - INFO: load:1.22 valid_run:1654.94 task_valid:1593.11 collect_output:50.31
2022-10-16 03:14:24 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 03:14:24 - train.py[line:551] - INFO: load:1.25 valid_run:1804.89 task_valid:1738.51 collect_output:53.79
2022-10-16 03:16:54 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 03:16:54 - train.py[line:551] - INFO: load:1.28 valid_run:1954.54 task_valid:1880.75 collect_output:60.12
2022-10-16 03:19:28 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 03:19:28 - train.py[line:551] - INFO: load:1.31 valid_run:2108.21 task_valid:2029.17 collect_output:64.19
2022-10-16 03:21:59 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 03:21:59 - train.py[line:551] - INFO: load:1.34 valid_run:2259.02 task_valid:2176.59 collect_output:66.44
2022-10-16 03:24:29 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 03:24:29 - train.py[line:551] - INFO: load:1.36 valid_run:2409.25 task_valid:2321.29 collect_output:70.83
2022-10-16 03:27:01 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 03:27:01 - train.py[line:551] - INFO: load:1.39 valid_run:2560.84 task_valid:2467.19 collect_output:75.42
2022-10-16 03:29:31 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 03:29:31 - train.py[line:551] - INFO: load:1.41 valid_run:2711.52 task_valid:2614.42 collect_output:77.82
2022-10-16 03:32:00 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 03:32:00 - train.py[line:551] - INFO: load:1.44 valid_run:2860.27 task_valid:2756.75 collect_output:83.12
2022-10-16 03:34:31 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 03:34:31 - train.py[line:551] - INFO: load:1.47 valid_run:3010.81 task_valid:2902.56 collect_output:86.74
2022-10-16 03:37:03 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 03:37:03 - train.py[line:551] - INFO: load:1.49 valid_run:3162.84 task_valid:3047.79 collect_output:92.42
2022-10-16 03:39:33 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 03:39:33 - train.py[line:551] - INFO: load:1.52 valid_run:3312.53 task_valid:3192.96 collect_output:95.86
2022-10-16 03:42:04 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 03:42:04 - train.py[line:551] - INFO: load:1.55 valid_run:3463.79 task_valid:3339.27 collect_output:99.76
2022-10-16 03:44:35 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 03:44:35 - train.py[line:551] - INFO: load:1.57 valid_run:3615.05 task_valid:3485.66 collect_output:103.62

====================================================================================================
SGG eval:     R @ 50: 0.4691;     R @ 100: 0.5197;     R @ 500: 0.5738;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2746;    mR @ 100: 0.3320;    mR @ 500: 0.3816;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2585) (covered in:0.1875) (covering:0.2857) (eating:0.6471) (flying in:1.0000) (growing on:0.3750) (hanging from:0.3871) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.5833) (playing:0.0000) (riding:0.7761) (says:0.0000) (sitting on:0.6675) (standing on:0.2850) (using:0.3500) (walking in:0.0000) (walking on:0.6486) (watching:0.0556) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4691;     R @ 100: 0.5197;     R @ 500: 0.5738;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2746;    mR @ 100: 0.3320;    mR @ 500: 0.3816;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2585) (covered in:0.1875) (covering:0.2857) (eating:0.6471) (flying in:1.0000) (growing on:0.3750) (hanging from:0.3871) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.5833) (playing:0.0000) (riding:0.7761) (says:0.0000) (sitting on:0.6675) (standing on:0.2850) (using:0.3500) (walking in:0.0000) (walking on:0.6486) (watching:0.0556) 
--------------------------------------------------------
====================================================================================================

2022-10-16 03:47:06 - train.py[line:487] - INFO: 0.5197380952380952
2022-10-16 03:47:06 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 03:47:06 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.364 | loss_v1 0 | loss_v2 0 | nll_loss 0.225 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.519738 | ppl 1.17 | vqa_score 0.3435 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.519738
2022-10-16 03:47:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-10-16 03:47:06 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-16 03:47:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-16 03:47:17 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.5197380952380952) (writing took 10.794006980024278 seconds)
2022-10-16 03:47:28 - progress_bar.py[line:274] - INFO: epoch 001:   6016 / 102288 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=0.3, ups=0, wpb=108.8, bsz=40, num_updates=6010, lr=1.46893e-05, gnorm=1.409, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29417
2022-10-16 03:47:40 - progress_bar.py[line:274] - INFO: epoch 001:   6026 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.1, ups=0.89, wpb=111.2, bsz=40, num_updates=6020, lr=1.47138e-05, gnorm=1.505, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29429
2022-10-16 03:47:51 - progress_bar.py[line:274] - INFO: epoch 001:   6036 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=6030, lr=1.47382e-05, gnorm=1.473, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29440
2022-10-16 03:48:02 - progress_bar.py[line:274] - INFO: epoch 001:   6046 / 102288 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=6040, lr=1.47627e-05, gnorm=1.36, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29451
2022-10-16 03:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   6056 / 102288 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.3, ups=0.88, wpb=109.1, bsz=40, num_updates=6050, lr=1.47871e-05, gnorm=1.502, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29462
2022-10-16 03:48:25 - progress_bar.py[line:274] - INFO: epoch 001:   6066 / 102288 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=96.3, ups=0.88, wpb=109.2, bsz=40, num_updates=6060, lr=1.48116e-05, gnorm=1.359, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29474
2022-10-16 03:48:35 - progress_bar.py[line:274] - INFO: epoch 001:   6076 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=104.3, ups=0.93, wpb=112.2, bsz=40, num_updates=6070, lr=1.4836e-05, gnorm=1.416, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29484
2022-10-16 03:48:40 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 03:48:47 - progress_bar.py[line:274] - INFO: epoch 001:   6087 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=94.1, ups=0.85, wpb=110.6, bsz=40, num_updates=6080, lr=1.48604e-05, gnorm=1.344, clip=100, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=29496
2022-10-16 03:48:58 - progress_bar.py[line:274] - INFO: epoch 001:   6097 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=103.4, ups=0.94, wpb=110, bsz=40, num_updates=6090, lr=1.48849e-05, gnorm=1.434, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29507
2022-10-16 03:49:09 - progress_bar.py[line:274] - INFO: epoch 001:   6107 / 102288 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=6100, lr=1.49093e-05, gnorm=1.335, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29518
2022-10-16 03:49:20 - progress_bar.py[line:274] - INFO: epoch 001:   6117 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=6110, lr=1.49338e-05, gnorm=1.331, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=29529
2022-10-16 03:49:31 - progress_bar.py[line:274] - INFO: epoch 001:   6127 / 102288 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=6120, lr=1.49582e-05, gnorm=1.336, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29540
2022-10-16 03:49:43 - progress_bar.py[line:274] - INFO: epoch 001:   6137 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=6130, lr=1.49826e-05, gnorm=1.409, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29552
2022-10-16 03:49:54 - progress_bar.py[line:274] - INFO: epoch 001:   6147 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=6140, lr=1.50071e-05, gnorm=1.299, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29563
2022-10-16 03:50:05 - progress_bar.py[line:274] - INFO: epoch 001:   6157 / 102288 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=95.7, ups=0.88, wpb=108.4, bsz=40, num_updates=6150, lr=1.50315e-05, gnorm=1.344, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29574
2022-10-16 03:50:16 - progress_bar.py[line:274] - INFO: epoch 001:   6167 / 102288 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99, ups=0.89, wpb=110.6, bsz=40, num_updates=6160, lr=1.5056e-05, gnorm=1.486, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29585
2022-10-16 03:50:27 - progress_bar.py[line:274] - INFO: epoch 001:   6177 / 102288 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=6170, lr=1.50804e-05, gnorm=1.303, clip=90, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=29596
2022-10-16 03:50:38 - progress_bar.py[line:274] - INFO: epoch 001:   6187 / 102288 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=6180, lr=1.51049e-05, gnorm=1.35, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=29607
2022-10-16 03:50:50 - progress_bar.py[line:274] - INFO: epoch 001:   6197 / 102288 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=6190, lr=1.51293e-05, gnorm=1.265, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29619
2022-10-16 03:51:01 - progress_bar.py[line:274] - INFO: epoch 001:   6207 / 102288 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=6200, lr=1.51537e-05, gnorm=1.367, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29630
2022-10-16 03:51:12 - progress_bar.py[line:274] - INFO: epoch 001:   6217 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=101.9, ups=0.94, wpb=108.1, bsz=40, num_updates=6210, lr=1.51782e-05, gnorm=1.395, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29641
2022-10-16 03:51:23 - progress_bar.py[line:274] - INFO: epoch 001:   6227 / 102288 loss=0.716, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=100.4, ups=0.92, wpb=109.5, bsz=40, num_updates=6220, lr=1.52026e-05, gnorm=1.494, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29652
2022-10-16 03:51:34 - progress_bar.py[line:274] - INFO: epoch 001:   6237 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=6230, lr=1.52271e-05, gnorm=1.454, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29663
2022-10-16 03:51:45 - progress_bar.py[line:274] - INFO: epoch 001:   6247 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=6240, lr=1.52515e-05, gnorm=1.413, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=29674
2022-10-16 03:51:57 - progress_bar.py[line:274] - INFO: epoch 001:   6257 / 102288 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=6250, lr=1.52759e-05, gnorm=1.324, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29686
2022-10-16 03:52:07 - progress_bar.py[line:274] - INFO: epoch 001:   6267 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=102.8, ups=0.93, wpb=110.9, bsz=40, num_updates=6260, lr=1.53004e-05, gnorm=1.339, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29696
2022-10-16 03:52:19 - progress_bar.py[line:274] - INFO: epoch 001:   6277 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=6270, lr=1.53248e-05, gnorm=1.33, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29708
2022-10-16 03:52:29 - progress_bar.py[line:274] - INFO: epoch 001:   6287 / 102288 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=6280, lr=1.53493e-05, gnorm=1.318, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29718
2022-10-16 03:52:41 - progress_bar.py[line:274] - INFO: epoch 001:   6297 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.6, ups=0.89, wpb=109.1, bsz=40, num_updates=6290, lr=1.53737e-05, gnorm=1.414, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29730
2022-10-16 03:52:52 - progress_bar.py[line:274] - INFO: epoch 001:   6307 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.58, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=94.9, ups=0.87, wpb=109.2, bsz=40, num_updates=6300, lr=1.53982e-05, gnorm=1.348, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=29741
2022-10-16 03:53:03 - progress_bar.py[line:274] - INFO: epoch 001:   6317 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=6310, lr=1.54226e-05, gnorm=1.477, clip=90, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=29752
2022-10-16 03:53:14 - progress_bar.py[line:274] - INFO: epoch 001:   6327 / 102288 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.3, ups=0.91, wpb=108.4, bsz=40, num_updates=6320, lr=1.5447e-05, gnorm=1.271, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=29763
2022-10-16 03:53:26 - progress_bar.py[line:274] - INFO: epoch 001:   6337 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.5, ups=0.88, wpb=111.4, bsz=40, num_updates=6330, lr=1.54715e-05, gnorm=1.203, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29775
2022-10-16 03:53:37 - progress_bar.py[line:274] - INFO: epoch 001:   6347 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=6340, lr=1.54959e-05, gnorm=1.468, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29786
2022-10-16 03:53:48 - progress_bar.py[line:274] - INFO: epoch 001:   6357 / 102288 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=6350, lr=1.55204e-05, gnorm=1.507, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29797
2022-10-16 03:53:59 - progress_bar.py[line:274] - INFO: epoch 001:   6367 / 102288 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=6360, lr=1.55448e-05, gnorm=1.526, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29808
2022-10-16 03:54:11 - progress_bar.py[line:274] - INFO: epoch 001:   6377 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=6370, lr=1.55692e-05, gnorm=1.323, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29820
2022-10-16 03:54:22 - progress_bar.py[line:274] - INFO: epoch 001:   6387 / 102288 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=6380, lr=1.55937e-05, gnorm=1.316, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29831
2022-10-16 03:54:33 - progress_bar.py[line:274] - INFO: epoch 001:   6397 / 102288 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=6390, lr=1.56181e-05, gnorm=1.25, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29842
2022-10-16 03:54:44 - progress_bar.py[line:274] - INFO: epoch 001:   6407 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.8, ups=0.89, wpb=109.9, bsz=40, num_updates=6400, lr=1.56426e-05, gnorm=1.253, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29853
2022-10-16 03:54:55 - progress_bar.py[line:274] - INFO: epoch 001:   6417 / 102288 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=6410, lr=1.5667e-05, gnorm=1.375, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=29864
2022-10-16 03:55:07 - progress_bar.py[line:274] - INFO: epoch 001:   6427 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.9, ups=0.89, wpb=110.7, bsz=40, num_updates=6420, lr=1.56915e-05, gnorm=1.469, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=29876
2022-10-16 03:55:18 - progress_bar.py[line:274] - INFO: epoch 001:   6437 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=6430, lr=1.57159e-05, gnorm=1.517, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29887
2022-10-16 03:55:29 - progress_bar.py[line:274] - INFO: epoch 001:   6447 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=100.3, ups=0.92, wpb=109.4, bsz=40, num_updates=6440, lr=1.57403e-05, gnorm=1.437, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29898
2022-10-16 03:55:40 - progress_bar.py[line:274] - INFO: epoch 001:   6457 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98, ups=0.9, wpb=108.4, bsz=40, num_updates=6450, lr=1.57648e-05, gnorm=1.337, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29909
2022-10-16 03:55:51 - progress_bar.py[line:274] - INFO: epoch 001:   6467 / 102288 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=103.1, ups=0.93, wpb=111, bsz=40, num_updates=6460, lr=1.57892e-05, gnorm=1.295, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=29920
2022-10-16 03:56:02 - progress_bar.py[line:274] - INFO: epoch 001:   6477 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=6470, lr=1.58137e-05, gnorm=1.337, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29931
2022-10-16 03:56:13 - progress_bar.py[line:274] - INFO: epoch 001:   6487 / 102288 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=6480, lr=1.58381e-05, gnorm=1.295, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29942
2022-10-16 03:56:24 - progress_bar.py[line:274] - INFO: epoch 001:   6497 / 102288 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=104.1, ups=0.94, wpb=110.7, bsz=40, num_updates=6490, lr=1.58625e-05, gnorm=1.312, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=29953
2022-10-16 03:56:35 - progress_bar.py[line:274] - INFO: epoch 001:   6507 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=6500, lr=1.5887e-05, gnorm=1.265, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=29964
2022-10-16 03:56:46 - progress_bar.py[line:274] - INFO: epoch 001:   6517 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=6510, lr=1.59114e-05, gnorm=1.301, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29975
2022-10-16 03:56:57 - progress_bar.py[line:274] - INFO: epoch 001:   6527 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=6520, lr=1.59359e-05, gnorm=1.369, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29986
2022-10-16 03:57:08 - progress_bar.py[line:274] - INFO: epoch 001:   6537 / 102288 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=100.9, ups=0.92, wpb=110.2, bsz=40, num_updates=6530, lr=1.59603e-05, gnorm=1.409, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29997
2022-10-16 03:57:19 - progress_bar.py[line:274] - INFO: epoch 001:   6547 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.5, ups=0.91, wpb=110.9, bsz=40, num_updates=6540, lr=1.59847e-05, gnorm=1.254, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30008
2022-10-16 03:57:30 - progress_bar.py[line:274] - INFO: epoch 001:   6557 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.7, ups=0.9, wpb=111.5, bsz=40, num_updates=6550, lr=1.60092e-05, gnorm=1.225, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30019
2022-10-16 03:57:41 - progress_bar.py[line:274] - INFO: epoch 001:   6567 / 102288 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=6560, lr=1.60336e-05, gnorm=1.337, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30030
2022-10-16 03:57:53 - progress_bar.py[line:274] - INFO: epoch 001:   6577 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=97.7, ups=0.88, wpb=111, bsz=40, num_updates=6570, lr=1.60581e-05, gnorm=1.312, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30042
2022-10-16 03:58:04 - progress_bar.py[line:274] - INFO: epoch 001:   6587 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=6580, lr=1.60825e-05, gnorm=1.208, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30053
2022-10-16 03:58:14 - progress_bar.py[line:274] - INFO: epoch 001:   6597 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=106.9, ups=0.97, wpb=110.4, bsz=40, num_updates=6590, lr=1.6107e-05, gnorm=1.393, clip=100, loss_scale=1024, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=30063
2022-10-16 03:58:25 - progress_bar.py[line:274] - INFO: epoch 001:   6607 / 102288 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=6600, lr=1.61314e-05, gnorm=1.505, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30074
2022-10-16 03:58:37 - progress_bar.py[line:274] - INFO: epoch 001:   6617 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=6610, lr=1.61558e-05, gnorm=1.403, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30086
2022-10-16 03:58:47 - progress_bar.py[line:274] - INFO: epoch 001:   6627 / 102288 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=101.8, ups=0.92, wpb=111, bsz=40, num_updates=6620, lr=1.61803e-05, gnorm=1.409, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30096
2022-10-16 03:58:59 - progress_bar.py[line:274] - INFO: epoch 001:   6637 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=6630, lr=1.62047e-05, gnorm=1.291, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30108
2022-10-16 03:59:10 - progress_bar.py[line:274] - INFO: epoch 001:   6647 / 102288 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.8, ups=0.9, wpb=109.3, bsz=40, num_updates=6640, lr=1.62292e-05, gnorm=1.199, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30119
2022-10-16 03:59:21 - progress_bar.py[line:274] - INFO: epoch 001:   6657 / 102288 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.586, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=6650, lr=1.62536e-05, gnorm=1.257, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30130
2022-10-16 03:59:32 - progress_bar.py[line:274] - INFO: epoch 001:   6667 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.6, ups=0.91, wpb=109.9, bsz=40, num_updates=6660, lr=1.6278e-05, gnorm=1.388, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30141
2022-10-16 03:59:43 - progress_bar.py[line:274] - INFO: epoch 001:   6677 / 102288 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=95.8, ups=0.89, wpb=107.3, bsz=40, num_updates=6670, lr=1.63025e-05, gnorm=1.425, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30152
2022-10-16 03:59:54 - progress_bar.py[line:274] - INFO: epoch 001:   6687 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.7, ups=0.92, wpb=111, bsz=40, num_updates=6680, lr=1.63269e-05, gnorm=1.311, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30163
2022-10-16 04:00:05 - progress_bar.py[line:274] - INFO: epoch 001:   6697 / 102288 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=6690, lr=1.63514e-05, gnorm=1.434, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30174
2022-10-16 04:00:17 - progress_bar.py[line:274] - INFO: epoch 001:   6707 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=93.8, ups=0.86, wpb=109.4, bsz=40, num_updates=6700, lr=1.63758e-05, gnorm=1.389, clip=100, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=30186
2022-10-16 04:00:28 - progress_bar.py[line:274] - INFO: epoch 001:   6717 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.9, ups=0.91, wpb=110, bsz=40, num_updates=6710, lr=1.64003e-05, gnorm=1.485, clip=100, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30197
2022-10-16 04:00:39 - progress_bar.py[line:274] - INFO: epoch 001:   6727 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.9, ups=0.89, wpb=110.5, bsz=40, num_updates=6720, lr=1.64247e-05, gnorm=1.267, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30208
2022-10-16 04:00:50 - progress_bar.py[line:274] - INFO: epoch 001:   6737 / 102288 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=6730, lr=1.64491e-05, gnorm=1.361, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30219
2022-10-16 04:01:02 - progress_bar.py[line:274] - INFO: epoch 001:   6747 / 102288 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=96, ups=0.87, wpb=110.8, bsz=40, num_updates=6740, lr=1.64736e-05, gnorm=1.355, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30231
2022-10-16 04:01:13 - progress_bar.py[line:274] - INFO: epoch 001:   6757 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=6750, lr=1.6498e-05, gnorm=1.419, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30242
2022-10-16 04:01:24 - progress_bar.py[line:274] - INFO: epoch 001:   6767 / 102288 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=6760, lr=1.65225e-05, gnorm=1.344, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30253
2022-10-16 04:01:35 - progress_bar.py[line:274] - INFO: epoch 001:   6777 / 102288 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=102.7, ups=0.93, wpb=110.6, bsz=40, num_updates=6770, lr=1.65469e-05, gnorm=1.3, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30264
2022-10-16 04:01:46 - progress_bar.py[line:274] - INFO: epoch 001:   6787 / 102288 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=102.9, ups=0.94, wpb=109.1, bsz=40, num_updates=6780, lr=1.65713e-05, gnorm=1.385, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30275
2022-10-16 04:01:57 - progress_bar.py[line:274] - INFO: epoch 001:   6797 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=6790, lr=1.65958e-05, gnorm=1.239, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30286
2022-10-16 04:02:08 - progress_bar.py[line:274] - INFO: epoch 001:   6807 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.5, ups=0.87, wpb=110.8, bsz=40, num_updates=6800, lr=1.66202e-05, gnorm=1.238, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30297
2022-10-16 04:02:19 - progress_bar.py[line:274] - INFO: epoch 001:   6817 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=6810, lr=1.66447e-05, gnorm=1.321, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30308
2022-10-16 04:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   6827 / 102288 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=6820, lr=1.66691e-05, gnorm=1.339, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30320
2022-10-16 04:02:42 - progress_bar.py[line:274] - INFO: epoch 001:   6837 / 102288 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.6, ups=0.89, wpb=108.2, bsz=40, num_updates=6830, lr=1.66936e-05, gnorm=1.357, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30331
2022-10-16 04:02:53 - progress_bar.py[line:274] - INFO: epoch 001:   6847 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.4, ups=0.9, wpb=110.3, bsz=40, num_updates=6840, lr=1.6718e-05, gnorm=1.165, clip=80, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30342
2022-10-16 04:03:04 - progress_bar.py[line:274] - INFO: epoch 001:   6857 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=6850, lr=1.67424e-05, gnorm=1.388, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30353
2022-10-16 04:03:15 - progress_bar.py[line:274] - INFO: epoch 001:   6867 / 102288 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=6860, lr=1.67669e-05, gnorm=1.203, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30364
2022-10-16 04:03:26 - progress_bar.py[line:274] - INFO: epoch 001:   6877 / 102288 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.8, ups=0.91, wpb=109, bsz=40, num_updates=6870, lr=1.67913e-05, gnorm=1.438, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30375
2022-10-16 04:03:37 - progress_bar.py[line:274] - INFO: epoch 001:   6887 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102.2, ups=0.92, wpb=111.6, bsz=40, num_updates=6880, lr=1.68158e-05, gnorm=1.256, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30386
2022-10-16 04:03:49 - progress_bar.py[line:274] - INFO: epoch 001:   6897 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=6890, lr=1.68402e-05, gnorm=1.42, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30398
2022-10-16 04:04:00 - progress_bar.py[line:274] - INFO: epoch 001:   6907 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=6900, lr=1.68646e-05, gnorm=1.281, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30409
2022-10-16 04:04:10 - progress_bar.py[line:274] - INFO: epoch 001:   6917 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=105.4, ups=0.96, wpb=110.3, bsz=40, num_updates=6910, lr=1.68891e-05, gnorm=1.393, clip=100, loss_scale=1024, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=30419
2022-10-16 04:04:22 - progress_bar.py[line:274] - INFO: epoch 001:   6927 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=6920, lr=1.69135e-05, gnorm=1.41, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30431
2022-10-16 04:04:33 - progress_bar.py[line:274] - INFO: epoch 001:   6937 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.7, ups=0.91, wpb=110, bsz=40, num_updates=6930, lr=1.6938e-05, gnorm=1.398, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30442
2022-10-16 04:04:44 - progress_bar.py[line:274] - INFO: epoch 001:   6947 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98, ups=0.89, wpb=109.6, bsz=40, num_updates=6940, lr=1.69624e-05, gnorm=1.263, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30453
2022-10-16 04:04:55 - progress_bar.py[line:274] - INFO: epoch 001:   6957 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=103, ups=0.92, wpb=112, bsz=40, num_updates=6950, lr=1.69869e-05, gnorm=1.361, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30464
2022-10-16 04:05:06 - progress_bar.py[line:274] - INFO: epoch 001:   6967 / 102288 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=6960, lr=1.70113e-05, gnorm=1.446, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30475
2022-10-16 04:05:17 - progress_bar.py[line:274] - INFO: epoch 001:   6977 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101.7, ups=0.91, wpb=112.3, bsz=40, num_updates=6970, lr=1.70357e-05, gnorm=1.317, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30486
2022-10-16 04:05:28 - progress_bar.py[line:274] - INFO: epoch 001:   6987 / 102288 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.1, ups=0.88, wpb=108.9, bsz=40, num_updates=6980, lr=1.70602e-05, gnorm=1.359, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30497
2022-10-16 04:05:39 - progress_bar.py[line:274] - INFO: epoch 001:   6997 / 102288 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=6990, lr=1.70846e-05, gnorm=1.198, clip=80, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30508
2022-10-16 04:05:51 - progress_bar.py[line:274] - INFO: epoch 001:   7007 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=7000, lr=1.71091e-05, gnorm=1.176, clip=70, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30520
2022-10-16 04:05:51 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 04:05:52 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 04:05:52 - train.py[line:551] - INFO: load:1.04 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 04:05:53 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.86 GiB already allocated; 5.10 GiB free; 32.00 GiB reserved in total by PyTorch)
2022-10-16 04:05:53 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-16 04:05:53 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 14        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9076 MB |   10300 MB |    4431 TB |    4431 TB |
|       from large pool |    8931 MB |   10155 MB |    4429 TB |    4429 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9076 MB |   10300 MB |    4431 TB |    4431 TB |
|       from large pool |    8931 MB |   10155 MB |    4429 TB |    4429 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32770 MB |   37398 MB |  147614 MB |  114844 MB |
|       from large pool |   32624 MB |   37246 MB |  147394 MB |  114770 MB |
|       from small pool |     146 MB |     152 MB |     220 MB |      74 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23693 MB |   23693 MB |    4218 TB |    4218 TB |
|       from large pool |   23692 MB |   23692 MB |    4217 TB |    4217 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  204370 K  |  204367 K  |
|       from large pool |     563    |     575    |   66090 K  |   66089 K  |
|       from small pool |    3095    |    3114    |  138280 K  |  138277 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  204370 K  |  204367 K  |
|       from large pool |     563    |     575    |   66090 K  |   66089 K  |
|       from small pool |    3095    |    3114    |  138280 K  |  138277 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     185    |     194    |     407    |     222    |
|       from large pool |     112    |     118    |     297    |     185    |
|       from small pool |      73    |      76    |     110    |      37    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     130    |     136    |  145889 K  |  145889 K  |
|       from large pool |      85    |      89    |   25749 K  |   25749 K  |
|       from small pool |      45    |      52    |  120139 K  |  120139 K  |
|===========================================================================|

2022-10-16 04:05:53 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-16 04:08:25 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 04:08:25 - train.py[line:551] - INFO: load:1.06 valid_run:152.70 task_valid:147.81 collect_output:3.86
2022-10-16 04:10:53 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 04:10:53 - train.py[line:551] - INFO: load:1.09 valid_run:300.46 task_valid:290.73 collect_output:7.67
2022-10-16 04:13:24 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 04:13:24 - train.py[line:551] - INFO: load:1.11 valid_run:452.03 task_valid:433.66 collect_output:15.30
2022-10-16 04:15:53 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 04:15:53 - train.py[line:551] - INFO: load:1.14 valid_run:600.75 task_valid:578.42 collect_output:18.25
2022-10-16 04:18:25 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 04:18:25 - train.py[line:551] - INFO: load:1.16 valid_run:752.83 task_valid:725.83 collect_output:21.92
2022-10-16 04:20:56 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 04:20:56 - train.py[line:551] - INFO: load:1.19 valid_run:903.92 task_valid:871.31 collect_output:26.52
2022-10-16 04:23:29 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 04:23:29 - train.py[line:551] - INFO: load:1.21 valid_run:1056.40 task_valid:1017.32 collect_output:31.94
2022-10-16 04:26:00 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 04:26:00 - train.py[line:551] - INFO: load:1.24 valid_run:1207.47 task_valid:1159.01 collect_output:40.24
2022-10-16 04:28:30 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 04:28:30 - train.py[line:551] - INFO: load:1.27 valid_run:1357.23 task_valid:1304.44 collect_output:43.49
2022-10-16 04:30:58 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 04:30:58 - train.py[line:551] - INFO: load:1.30 valid_run:1505.89 task_valid:1448.31 collect_output:47.21
2022-10-16 04:33:28 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 04:33:28 - train.py[line:551] - INFO: load:1.32 valid_run:1655.75 task_valid:1593.75 collect_output:50.53
2022-10-16 04:35:59 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 04:35:59 - train.py[line:551] - INFO: load:1.35 valid_run:1805.91 task_valid:1739.27 collect_output:54.00
2022-10-16 04:38:28 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 04:38:28 - train.py[line:551] - INFO: load:1.37 valid_run:1955.62 task_valid:1881.62 collect_output:60.23
2022-10-16 04:40:59 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 04:40:59 - train.py[line:551] - INFO: load:1.40 valid_run:2106.52 task_valid:2028.02 collect_output:63.52
2022-10-16 04:43:30 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 04:43:30 - train.py[line:551] - INFO: load:1.43 valid_run:2256.78 task_valid:2174.99 collect_output:65.75
2022-10-16 04:46:00 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 04:46:00 - train.py[line:551] - INFO: load:1.45 valid_run:2407.08 task_valid:2320.08 collect_output:69.84
2022-10-16 04:48:32 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 04:48:32 - train.py[line:551] - INFO: load:1.48 valid_run:2558.85 task_valid:2466.29 collect_output:74.28
2022-10-16 04:51:03 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 04:51:03 - train.py[line:551] - INFO: load:1.50 valid_run:2709.81 task_valid:2614.03 collect_output:76.42
2022-10-16 04:53:31 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 04:53:31 - train.py[line:551] - INFO: load:1.53 valid_run:2858.14 task_valid:2756.07 collect_output:81.56
2022-10-16 04:56:01 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 04:56:01 - train.py[line:551] - INFO: load:1.56 valid_run:3008.16 task_valid:2901.33 collect_output:85.26
2022-10-16 04:58:33 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 04:58:33 - train.py[line:551] - INFO: load:1.58 valid_run:3159.92 task_valid:3046.05 collect_output:91.29
2022-10-16 05:01:02 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 05:01:02 - train.py[line:551] - INFO: load:1.61 valid_run:3309.07 task_valid:3190.50 collect_output:94.97
2022-10-16 05:03:33 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 05:03:33 - train.py[line:551] - INFO: load:1.63 valid_run:3460.06 task_valid:3336.75 collect_output:98.68
2022-10-16 05:06:05 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 05:06:05 - train.py[line:551] - INFO: load:1.66 valid_run:3611.23 task_valid:3483.34 collect_output:102.23

====================================================================================================
SGG eval:     R @ 50: 0.5151;     R @ 100: 0.5638;     R @ 500: 0.5981;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3261;    mR @ 100: 0.3850;    mR @ 500: 0.4161;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4415) (covered in:0.5000) (covering:0.3571) (eating:0.7647) (flying in:1.0000) (growing on:0.5000) (hanging from:0.2774) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7083) (playing:0.0000) (riding:0.8546) (says:0.0000) (sitting on:0.7205) (standing on:0.2100) (using:0.3500) (walking in:0.0000) (walking on:0.7432) (watching:0.1389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5151;     R @ 100: 0.5638;     R @ 500: 0.5981;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3261;    mR @ 100: 0.3850;    mR @ 500: 0.4161;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4415) (covered in:0.5000) (covering:0.3571) (eating:0.7647) (flying in:1.0000) (growing on:0.5000) (hanging from:0.2774) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7083) (playing:0.0000) (riding:0.8546) (says:0.0000) (sitting on:0.7205) (standing on:0.2100) (using:0.3500) (walking in:0.0000) (walking on:0.7432) (watching:0.1389) 
--------------------------------------------------------
====================================================================================================

2022-10-16 05:08:35 - train.py[line:487] - INFO: 0.5637714285714286
2022-10-16 05:08:36 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 05:08:36 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.354 | loss_v1 0 | loss_v2 0 | nll_loss 0.206 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.563771 | ppl 1.15 | vqa_score 0.393 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 7000 | best_R@100 0.563771
2022-10-16 05:08:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 7000 updates
2022-10-16 05:08:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-16 05:08:41 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-16 05:08:46 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 0.5637714285714286) (writing took 10.692898421082646 seconds)
2022-10-16 05:08:57 - progress_bar.py[line:274] - INFO: epoch 001:   7017 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=0.3, ups=0, wpb=110, bsz=40, num_updates=7010, lr=1.71335e-05, gnorm=1.449, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34306
2022-10-16 05:09:09 - progress_bar.py[line:274] - INFO: epoch 001:   7027 / 102288 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.3, ups=0.88, wpb=109.5, bsz=40, num_updates=7020, lr=1.71579e-05, gnorm=1.293, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34318
2022-10-16 05:09:20 - progress_bar.py[line:274] - INFO: epoch 001:   7037 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.2, ups=0.9, wpb=110.8, bsz=40, num_updates=7030, lr=1.71824e-05, gnorm=1.285, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34329
2022-10-16 05:09:31 - progress_bar.py[line:274] - INFO: epoch 001:   7047 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=7040, lr=1.72068e-05, gnorm=1.412, clip=100, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=34340
2022-10-16 05:09:42 - progress_bar.py[line:274] - INFO: epoch 001:   7057 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=7050, lr=1.72313e-05, gnorm=1.476, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34351
2022-10-16 05:09:53 - progress_bar.py[line:274] - INFO: epoch 001:   7067 / 102288 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.7, ups=0.9, wpb=109.2, bsz=40, num_updates=7060, lr=1.72557e-05, gnorm=1.444, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34362
2022-10-16 05:10:05 - progress_bar.py[line:274] - INFO: epoch 001:   7077 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=95, ups=0.87, wpb=109.2, bsz=40, num_updates=7070, lr=1.72801e-05, gnorm=1.264, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34374
2022-10-16 05:10:08 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 05:10:17 - progress_bar.py[line:274] - INFO: epoch 001:   7088 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.9, ups=0.82, wpb=111, bsz=40, num_updates=7080, lr=1.73046e-05, gnorm=1.27, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=34386
2022-10-16 05:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   7098 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=7090, lr=1.7329e-05, gnorm=1.355, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34397
2022-10-16 05:10:40 - progress_bar.py[line:274] - INFO: epoch 001:   7108 / 102288 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=7100, lr=1.73535e-05, gnorm=1.365, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34409
2022-10-16 05:10:51 - progress_bar.py[line:274] - INFO: epoch 001:   7118 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=102.6, ups=0.94, wpb=109.3, bsz=40, num_updates=7110, lr=1.73779e-05, gnorm=1.299, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34420
2022-10-16 05:11:02 - progress_bar.py[line:274] - INFO: epoch 001:   7128 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=7120, lr=1.74024e-05, gnorm=1.434, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34431
2022-10-16 05:11:13 - progress_bar.py[line:274] - INFO: epoch 001:   7138 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=7130, lr=1.74268e-05, gnorm=1.362, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34442
2022-10-16 05:11:24 - progress_bar.py[line:274] - INFO: epoch 001:   7148 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=101, ups=0.91, wpb=111.6, bsz=40, num_updates=7140, lr=1.74512e-05, gnorm=1.341, clip=100, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=34453
2022-10-16 05:11:35 - progress_bar.py[line:274] - INFO: epoch 001:   7158 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.1, ups=0.92, wpb=110.4, bsz=40, num_updates=7150, lr=1.74757e-05, gnorm=1.332, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34464
2022-10-16 05:11:46 - progress_bar.py[line:274] - INFO: epoch 001:   7168 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.9, ups=0.91, wpb=112.4, bsz=40, num_updates=7160, lr=1.75001e-05, gnorm=1.199, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34475
2022-10-16 05:11:57 - progress_bar.py[line:274] - INFO: epoch 001:   7178 / 102288 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.3, ups=0.88, wpb=109.2, bsz=40, num_updates=7170, lr=1.75246e-05, gnorm=1.466, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34486
2022-10-16 05:12:08 - progress_bar.py[line:274] - INFO: epoch 001:   7188 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=102, ups=0.92, wpb=111, bsz=40, num_updates=7180, lr=1.7549e-05, gnorm=1.507, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34497
2022-10-16 05:12:20 - progress_bar.py[line:274] - INFO: epoch 001:   7198 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96, ups=0.87, wpb=110, bsz=40, num_updates=7190, lr=1.75734e-05, gnorm=1.102, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34509
2022-10-16 05:12:31 - progress_bar.py[line:274] - INFO: epoch 001:   7208 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=7200, lr=1.75979e-05, gnorm=1.352, clip=90, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34520
2022-10-16 05:12:42 - progress_bar.py[line:274] - INFO: epoch 001:   7218 / 102288 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97, ups=0.89, wpb=109.2, bsz=40, num_updates=7210, lr=1.76223e-05, gnorm=1.372, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34531
2022-10-16 05:12:53 - progress_bar.py[line:274] - INFO: epoch 001:   7228 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=101, ups=0.92, wpb=110, bsz=40, num_updates=7220, lr=1.76468e-05, gnorm=1.317, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34542
2022-10-16 05:13:04 - progress_bar.py[line:274] - INFO: epoch 001:   7238 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=7230, lr=1.76712e-05, gnorm=1.294, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34553
2022-10-16 05:13:16 - progress_bar.py[line:274] - INFO: epoch 001:   7248 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.8, ups=0.88, wpb=110, bsz=40, num_updates=7240, lr=1.76957e-05, gnorm=1.567, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34565
2022-10-16 05:13:27 - progress_bar.py[line:274] - INFO: epoch 001:   7258 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=7250, lr=1.77201e-05, gnorm=1.21, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34576
2022-10-16 05:13:38 - progress_bar.py[line:274] - INFO: epoch 001:   7268 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=102.6, ups=0.92, wpb=112, bsz=40, num_updates=7260, lr=1.77445e-05, gnorm=1.272, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34587
2022-10-16 05:13:49 - progress_bar.py[line:274] - INFO: epoch 001:   7278 / 102288 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=7270, lr=1.7769e-05, gnorm=1.292, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34598
2022-10-16 05:14:00 - progress_bar.py[line:274] - INFO: epoch 001:   7288 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=7280, lr=1.77934e-05, gnorm=1.421, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34609
2022-10-16 05:14:11 - progress_bar.py[line:274] - INFO: epoch 001:   7298 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=97.6, ups=0.89, wpb=109.2, bsz=40, num_updates=7290, lr=1.78179e-05, gnorm=1.417, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34620
2022-10-16 05:14:22 - progress_bar.py[line:274] - INFO: epoch 001:   7308 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=7300, lr=1.78423e-05, gnorm=1.359, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34631
2022-10-16 05:14:33 - progress_bar.py[line:274] - INFO: epoch 001:   7318 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=102.3, ups=0.92, wpb=111.6, bsz=40, num_updates=7310, lr=1.78667e-05, gnorm=1.224, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34642
2022-10-16 05:14:45 - progress_bar.py[line:274] - INFO: epoch 001:   7328 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.2, ups=0.87, wpb=110.4, bsz=40, num_updates=7320, lr=1.78912e-05, gnorm=1.189, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34654
2022-10-16 05:14:56 - progress_bar.py[line:274] - INFO: epoch 001:   7338 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=7330, lr=1.79156e-05, gnorm=1.319, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34665
2022-10-16 05:15:07 - progress_bar.py[line:274] - INFO: epoch 001:   7348 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=7340, lr=1.79401e-05, gnorm=1.318, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34676
2022-10-16 05:15:18 - progress_bar.py[line:274] - INFO: epoch 001:   7358 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100.9, ups=0.92, wpb=110, bsz=40, num_updates=7350, lr=1.79645e-05, gnorm=1.41, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34687
2022-10-16 05:15:30 - progress_bar.py[line:274] - INFO: epoch 001:   7368 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.2, ups=0.88, wpb=109.4, bsz=40, num_updates=7360, lr=1.7989e-05, gnorm=1.402, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34699
2022-10-16 05:15:41 - progress_bar.py[line:274] - INFO: epoch 001:   7378 / 102288 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99, ups=0.9, wpb=109.5, bsz=40, num_updates=7370, lr=1.80134e-05, gnorm=1.429, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34710
2022-10-16 05:15:52 - progress_bar.py[line:274] - INFO: epoch 001:   7388 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.4, ups=0.91, wpb=108.6, bsz=40, num_updates=7380, lr=1.80378e-05, gnorm=1.277, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34721
2022-10-16 05:16:03 - progress_bar.py[line:274] - INFO: epoch 001:   7398 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=7390, lr=1.80623e-05, gnorm=1.452, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34732
2022-10-16 05:16:14 - progress_bar.py[line:274] - INFO: epoch 001:   7408 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=7400, lr=1.80867e-05, gnorm=1.254, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34743
2022-10-16 05:16:25 - progress_bar.py[line:274] - INFO: epoch 001:   7418 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.7, ups=0.92, wpb=109.8, bsz=40, num_updates=7410, lr=1.81112e-05, gnorm=1.196, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34754
2022-10-16 05:16:36 - progress_bar.py[line:274] - INFO: epoch 001:   7428 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=7420, lr=1.81356e-05, gnorm=1.267, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34765
2022-10-16 05:16:48 - progress_bar.py[line:274] - INFO: epoch 001:   7438 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.8, ups=0.88, wpb=111.2, bsz=40, num_updates=7430, lr=1.816e-05, gnorm=1.343, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34777
2022-10-16 05:16:59 - progress_bar.py[line:274] - INFO: epoch 001:   7448 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=7440, lr=1.81845e-05, gnorm=1.299, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34788
2022-10-16 05:17:10 - progress_bar.py[line:274] - INFO: epoch 001:   7458 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=7450, lr=1.82089e-05, gnorm=1.214, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34799
2022-10-16 05:17:21 - progress_bar.py[line:274] - INFO: epoch 001:   7468 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=7460, lr=1.82334e-05, gnorm=1.554, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34810
2022-10-16 05:17:32 - progress_bar.py[line:274] - INFO: epoch 001:   7478 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.4, ups=0.91, wpb=108.6, bsz=40, num_updates=7470, lr=1.82578e-05, gnorm=1.263, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34821
2022-10-16 05:17:44 - progress_bar.py[line:274] - INFO: epoch 001:   7488 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=7480, lr=1.82823e-05, gnorm=1.236, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34833
2022-10-16 05:17:55 - progress_bar.py[line:274] - INFO: epoch 001:   7498 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=7490, lr=1.83067e-05, gnorm=1.23, clip=90, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=34844
2022-10-16 05:18:06 - progress_bar.py[line:274] - INFO: epoch 001:   7508 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.5, ups=0.87, wpb=112, bsz=40, num_updates=7500, lr=1.83311e-05, gnorm=1.245, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34855
2022-10-16 05:18:18 - progress_bar.py[line:274] - INFO: epoch 001:   7518 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=95.5, ups=0.87, wpb=109.9, bsz=40, num_updates=7510, lr=1.83556e-05, gnorm=1.232, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34867
2022-10-16 05:18:29 - progress_bar.py[line:274] - INFO: epoch 001:   7528 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.2, ups=0.91, wpb=109.6, bsz=40, num_updates=7520, lr=1.838e-05, gnorm=1.175, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34878
2022-10-16 05:18:41 - progress_bar.py[line:274] - INFO: epoch 001:   7538 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.3, ups=0.87, wpb=111.5, bsz=40, num_updates=7530, lr=1.84045e-05, gnorm=1.258, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34889
2022-10-16 05:18:52 - progress_bar.py[line:274] - INFO: epoch 001:   7548 / 102288 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=96.1, ups=0.88, wpb=109.3, bsz=40, num_updates=7540, lr=1.84289e-05, gnorm=1.152, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34901
2022-10-16 05:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   7558 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.5, ups=0.89, wpb=109.1, bsz=40, num_updates=7550, lr=1.84533e-05, gnorm=1.26, clip=90, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=34912
2022-10-16 05:19:14 - progress_bar.py[line:274] - INFO: epoch 001:   7568 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101, ups=0.91, wpb=111.6, bsz=40, num_updates=7560, lr=1.84778e-05, gnorm=1.305, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34923
2022-10-16 05:19:25 - progress_bar.py[line:274] - INFO: epoch 001:   7578 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.6, ups=0.9, wpb=109, bsz=40, num_updates=7570, lr=1.85022e-05, gnorm=1.316, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34934
2022-10-16 05:19:37 - progress_bar.py[line:274] - INFO: epoch 001:   7588 / 102288 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=7580, lr=1.85267e-05, gnorm=1.203, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34946
2022-10-16 05:19:48 - progress_bar.py[line:274] - INFO: epoch 001:   7598 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=7590, lr=1.85511e-05, gnorm=1.262, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34957
2022-10-16 05:19:59 - progress_bar.py[line:274] - INFO: epoch 001:   7608 / 102288 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=7600, lr=1.85755e-05, gnorm=1.172, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=34968
2022-10-16 05:20:10 - progress_bar.py[line:274] - INFO: epoch 001:   7618 / 102288 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=7610, lr=1.86e-05, gnorm=1.174, clip=90, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34979
2022-10-16 05:20:21 - progress_bar.py[line:274] - INFO: epoch 001:   7628 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.3, ups=0.9, wpb=112.1, bsz=40, num_updates=7620, lr=1.86244e-05, gnorm=1.2, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34990
2022-10-16 05:20:32 - progress_bar.py[line:274] - INFO: epoch 001:   7638 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=100.3, ups=0.92, wpb=109.3, bsz=40, num_updates=7630, lr=1.86489e-05, gnorm=1.239, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35001
2022-10-16 05:20:43 - progress_bar.py[line:274] - INFO: epoch 001:   7648 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.1, ups=0.92, wpb=110, bsz=40, num_updates=7640, lr=1.86733e-05, gnorm=1.325, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35012
2022-10-16 05:20:54 - progress_bar.py[line:274] - INFO: epoch 001:   7658 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.6, ups=0.92, wpb=111, bsz=40, num_updates=7650, lr=1.86978e-05, gnorm=1.315, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35023
2022-10-16 05:21:05 - progress_bar.py[line:274] - INFO: epoch 001:   7668 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.9, ups=0.88, wpb=111.4, bsz=40, num_updates=7660, lr=1.87222e-05, gnorm=1.316, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35034
2022-10-16 05:21:16 - progress_bar.py[line:274] - INFO: epoch 001:   7678 / 102288 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=100.3, ups=0.92, wpb=109, bsz=40, num_updates=7670, lr=1.87466e-05, gnorm=1.343, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35045
2022-10-16 05:21:27 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 05:21:28 - progress_bar.py[line:274] - INFO: epoch 001:   7689 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=91.7, ups=0.83, wpb=109.9, bsz=40, num_updates=7680, lr=1.87711e-05, gnorm=1.137, clip=90, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=35057
2022-10-16 05:21:40 - progress_bar.py[line:274] - INFO: epoch 001:   7699 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.2, ups=0.87, wpb=110.7, bsz=40, num_updates=7690, lr=1.87955e-05, gnorm=1.145, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35069
2022-10-16 05:21:51 - progress_bar.py[line:274] - INFO: epoch 001:   7709 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.8, ups=0.88, wpb=108.6, bsz=40, num_updates=7700, lr=1.882e-05, gnorm=1.327, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35080
2022-10-16 05:22:02 - progress_bar.py[line:274] - INFO: epoch 001:   7719 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.2, ups=0.9, wpb=108.6, bsz=40, num_updates=7710, lr=1.88444e-05, gnorm=1.429, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35091
2022-10-16 05:22:14 - progress_bar.py[line:274] - INFO: epoch 001:   7729 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.8, ups=0.9, wpb=110.4, bsz=40, num_updates=7720, lr=1.88688e-05, gnorm=1.245, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35102
2022-10-16 05:22:25 - progress_bar.py[line:274] - INFO: epoch 001:   7739 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=7730, lr=1.88933e-05, gnorm=1.256, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35114
2022-10-16 05:22:36 - progress_bar.py[line:274] - INFO: epoch 001:   7749 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.6, ups=0.92, wpb=109.6, bsz=40, num_updates=7740, lr=1.89177e-05, gnorm=1.064, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35125
2022-10-16 05:22:47 - progress_bar.py[line:274] - INFO: epoch 001:   7759 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.2, ups=0.9, wpb=110.6, bsz=40, num_updates=7750, lr=1.89422e-05, gnorm=1.188, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35136
2022-10-16 05:22:58 - progress_bar.py[line:274] - INFO: epoch 001:   7769 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=7760, lr=1.89666e-05, gnorm=1.182, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35147
2022-10-16 05:23:09 - progress_bar.py[line:274] - INFO: epoch 001:   7779 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=7770, lr=1.89911e-05, gnorm=1.244, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35158
2022-10-16 05:23:21 - progress_bar.py[line:274] - INFO: epoch 001:   7789 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=7780, lr=1.90155e-05, gnorm=1.169, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35170
2022-10-16 05:23:32 - progress_bar.py[line:274] - INFO: epoch 001:   7799 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=7790, lr=1.90399e-05, gnorm=1.174, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35181
2022-10-16 05:23:43 - progress_bar.py[line:274] - INFO: epoch 001:   7809 / 102288 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=7800, lr=1.90644e-05, gnorm=1.326, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35192
2022-10-16 05:23:54 - progress_bar.py[line:274] - INFO: epoch 001:   7819 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100.6, ups=0.91, wpb=110, bsz=40, num_updates=7810, lr=1.90888e-05, gnorm=1.277, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=35203
2022-10-16 05:24:05 - progress_bar.py[line:274] - INFO: epoch 001:   7829 / 102288 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=101.2, ups=0.92, wpb=110.6, bsz=40, num_updates=7820, lr=1.91133e-05, gnorm=1.246, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35214
2022-10-16 05:24:16 - progress_bar.py[line:274] - INFO: epoch 001:   7839 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=7830, lr=1.91377e-05, gnorm=1.208, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35225
2022-10-16 05:24:27 - progress_bar.py[line:274] - INFO: epoch 001:   7849 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.6, ups=0.88, wpb=110.7, bsz=40, num_updates=7840, lr=1.91621e-05, gnorm=1.275, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35236
2022-10-16 05:24:39 - progress_bar.py[line:274] - INFO: epoch 001:   7859 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.8, ups=0.9, wpb=110.3, bsz=40, num_updates=7850, lr=1.91866e-05, gnorm=1.347, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=35247
2022-10-16 05:24:50 - progress_bar.py[line:274] - INFO: epoch 001:   7869 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=7860, lr=1.9211e-05, gnorm=1.199, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35259
2022-10-16 05:25:01 - progress_bar.py[line:274] - INFO: epoch 001:   7879 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=96.1, ups=0.88, wpb=109.1, bsz=40, num_updates=7870, lr=1.92355e-05, gnorm=1.271, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35270
2022-10-16 05:25:12 - progress_bar.py[line:274] - INFO: epoch 001:   7889 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=7880, lr=1.92599e-05, gnorm=1.308, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35281
2022-10-16 05:25:23 - progress_bar.py[line:274] - INFO: epoch 001:   7899 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.8, ups=0.92, wpb=111.1, bsz=40, num_updates=7890, lr=1.92844e-05, gnorm=1.211, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35292
2022-10-16 05:25:35 - progress_bar.py[line:274] - INFO: epoch 001:   7909 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.1, ups=0.88, wpb=112.5, bsz=40, num_updates=7900, lr=1.93088e-05, gnorm=1.287, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35304
2022-10-16 05:25:46 - progress_bar.py[line:274] - INFO: epoch 001:   7919 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=7910, lr=1.93332e-05, gnorm=1.263, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35315
2022-10-16 05:25:57 - progress_bar.py[line:274] - INFO: epoch 001:   7929 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=100.6, ups=0.92, wpb=109.6, bsz=40, num_updates=7920, lr=1.93577e-05, gnorm=1.268, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35326
2022-10-16 05:26:08 - progress_bar.py[line:274] - INFO: epoch 001:   7939 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.2, ups=0.9, wpb=111.8, bsz=40, num_updates=7930, lr=1.93821e-05, gnorm=1.18, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35337
2022-10-16 05:26:19 - progress_bar.py[line:274] - INFO: epoch 001:   7949 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=103.9, ups=0.94, wpb=110.4, bsz=40, num_updates=7940, lr=1.94066e-05, gnorm=1.088, clip=70, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=35348
2022-10-16 05:26:29 - progress_bar.py[line:274] - INFO: epoch 001:   7959 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=103.3, ups=0.93, wpb=110.9, bsz=40, num_updates=7950, lr=1.9431e-05, gnorm=1.114, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35358
2022-10-16 05:26:41 - progress_bar.py[line:274] - INFO: epoch 001:   7969 / 102288 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=7960, lr=1.94554e-05, gnorm=1.345, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35370
2022-10-16 05:26:52 - progress_bar.py[line:274] - INFO: epoch 001:   7979 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=7970, lr=1.94799e-05, gnorm=1.171, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35381
2022-10-16 05:27:03 - progress_bar.py[line:274] - INFO: epoch 001:   7989 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.1, ups=0.9, wpb=108.7, bsz=40, num_updates=7980, lr=1.95043e-05, gnorm=1.271, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35392
2022-10-16 05:27:14 - progress_bar.py[line:274] - INFO: epoch 001:   7999 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.4, ups=0.92, wpb=110.4, bsz=40, num_updates=7990, lr=1.95288e-05, gnorm=1.132, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35403
2022-10-16 05:27:25 - progress_bar.py[line:274] - INFO: epoch 001:   8009 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=8000, lr=1.95532e-05, gnorm=1.215, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35414
2022-10-16 05:27:25 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 05:27:26 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 05:27:26 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 05:29:58 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 05:29:58 - train.py[line:551] - INFO: load:1.01 valid_run:151.88 task_valid:147.73 collect_output:3.15
2022-10-16 05:32:26 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 05:32:26 - train.py[line:551] - INFO: load:1.04 valid_run:299.66 task_valid:290.69 collect_output:6.96
2022-10-16 05:34:59 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 05:34:59 - train.py[line:551] - INFO: load:1.06 valid_run:452.23 task_valid:433.86 collect_output:15.36
2022-10-16 05:37:27 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 05:37:27 - train.py[line:551] - INFO: load:1.09 valid_run:600.77 task_valid:578.74 collect_output:18.02
2022-10-16 05:40:00 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 05:40:00 - train.py[line:551] - INFO: load:1.12 valid_run:753.23 task_valid:726.61 collect_output:21.48
2022-10-16 05:42:32 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 05:42:32 - train.py[line:551] - INFO: load:1.14 valid_run:904.99 task_valid:872.70 collect_output:26.01
2022-10-16 05:45:05 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 05:45:05 - train.py[line:551] - INFO: load:1.17 valid_run:1058.06 task_valid:1019.61 collect_output:31.10
2022-10-16 05:47:36 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 05:47:36 - train.py[line:551] - INFO: load:1.20 valid_run:1209.04 task_valid:1161.33 collect_output:39.22
2022-10-16 05:50:06 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 05:50:06 - train.py[line:551] - INFO: load:1.22 valid_run:1358.92 task_valid:1306.59 collect_output:42.74
2022-10-16 05:52:35 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 05:52:35 - train.py[line:551] - INFO: load:1.25 valid_run:1507.57 task_valid:1450.32 collect_output:46.56
2022-10-16 05:55:04 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 05:55:04 - train.py[line:551] - INFO: load:1.28 valid_run:1657.39 task_valid:1595.64 collect_output:49.88
2022-10-16 05:57:35 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 05:57:35 - train.py[line:551] - INFO: load:1.30 valid_run:1807.64 task_valid:1741.35 collect_output:53.29
2022-10-16 06:00:05 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 06:00:05 - train.py[line:551] - INFO: load:1.33 valid_run:1957.69 task_valid:1883.91 collect_output:59.52
2022-10-16 06:02:36 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 06:02:36 - train.py[line:551] - INFO: load:1.36 valid_run:2108.24 task_valid:2029.75 collect_output:63.15
2022-10-16 06:05:06 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 06:05:06 - train.py[line:551] - INFO: load:1.38 valid_run:2258.59 task_valid:2176.88 collect_output:65.30
2022-10-16 06:07:36 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 06:07:36 - train.py[line:551] - INFO: load:1.41 valid_run:2408.82 task_valid:2321.67 collect_output:69.66
2022-10-16 06:10:08 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 06:10:08 - train.py[line:551] - INFO: load:1.44 valid_run:2560.18 task_valid:2467.27 collect_output:74.40
2022-10-16 06:12:38 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 06:12:38 - train.py[line:551] - INFO: load:1.47 valid_run:2710.49 task_valid:2614.14 collect_output:76.86
2022-10-16 06:15:06 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 06:15:06 - train.py[line:551] - INFO: load:1.49 valid_run:2858.47 task_valid:2755.72 collect_output:82.24
2022-10-16 06:17:36 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 06:17:36 - train.py[line:551] - INFO: load:1.52 valid_run:3008.72 task_valid:2901.15 collect_output:86.05
2022-10-16 06:20:08 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 06:20:08 - train.py[line:551] - INFO: load:1.54 valid_run:3160.37 task_valid:3045.75 collect_output:92.06
2022-10-16 06:22:37 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 06:22:37 - train.py[line:551] - INFO: load:1.57 valid_run:3309.58 task_valid:3190.27 collect_output:95.75
2022-10-16 06:25:08 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 06:25:08 - train.py[line:551] - INFO: load:1.59 valid_run:3460.36 task_valid:3336.42 collect_output:99.37
2022-10-16 06:27:39 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 06:27:39 - train.py[line:551] - INFO: load:1.62 valid_run:3611.45 task_valid:3482.90 collect_output:103.00

====================================================================================================
SGG eval:     R @ 50: 0.5442;     R @ 100: 0.5759;     R @ 500: 0.6130;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3709;    mR @ 100: 0.4113;    mR @ 500: 0.4493;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4707) (covered in:0.6667) (covering:0.4286) (eating:0.7647) (flying in:1.0000) (growing on:0.5000) (hanging from:0.2581) (lying on:0.1167) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7500) (playing:0.0000) (riding:0.8889) (says:0.0000) (sitting on:0.7347) (standing on:0.1800) (using:0.3500) (walking in:0.0000) (walking on:0.7973) (watching:0.2361) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5442;     R @ 100: 0.5759;     R @ 500: 0.6130;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3709;    mR @ 100: 0.4113;    mR @ 500: 0.4493;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4707) (covered in:0.6667) (covering:0.4286) (eating:0.7647) (flying in:1.0000) (growing on:0.5000) (hanging from:0.2581) (lying on:0.1167) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7500) (playing:0.0000) (riding:0.8889) (says:0.0000) (sitting on:0.7347) (standing on:0.1800) (using:0.3500) (walking in:0.0000) (walking on:0.7973) (watching:0.2361) 
--------------------------------------------------------
====================================================================================================

2022-10-16 06:30:10 - train.py[line:487] - INFO: 0.5758714285714286
2022-10-16 06:30:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 06:30:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.362 | loss_v1 0 | loss_v2 0 | nll_loss 0.221 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.575871 | ppl 1.17 | vqa_score 0.42 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 8000 | best_R@100 0.575871
2022-10-16 06:30:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2022-10-16 06:30:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-16 06:30:16 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-16 06:30:21 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.5758714285714286) (writing took 10.661945272702724 seconds)
2022-10-16 06:30:33 - progress_bar.py[line:274] - INFO: epoch 001:   8019 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=0.3, ups=0, wpb=110.1, bsz=40, num_updates=8010, lr=1.95777e-05, gnorm=1.173, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39202
2022-10-16 06:30:44 - progress_bar.py[line:274] - INFO: epoch 001:   8029 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.2, ups=0.9, wpb=111.8, bsz=40, num_updates=8020, lr=1.96021e-05, gnorm=1.292, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39213
2022-10-16 06:30:55 - progress_bar.py[line:274] - INFO: epoch 001:   8039 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98, ups=0.89, wpb=110.2, bsz=40, num_updates=8030, lr=1.96265e-05, gnorm=1.173, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39224
2022-10-16 06:31:06 - progress_bar.py[line:274] - INFO: epoch 001:   8049 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.3, ups=0.92, wpb=110.5, bsz=40, num_updates=8040, lr=1.9651e-05, gnorm=1.247, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39235
2022-10-16 06:31:17 - progress_bar.py[line:274] - INFO: epoch 001:   8059 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.2, ups=0.87, wpb=110.2, bsz=40, num_updates=8050, lr=1.96754e-05, gnorm=1.259, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39246
2022-10-16 06:31:29 - progress_bar.py[line:274] - INFO: epoch 001:   8069 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=8060, lr=1.96999e-05, gnorm=1.268, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39258
2022-10-16 06:31:40 - progress_bar.py[line:274] - INFO: epoch 001:   8079 / 102288 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=8070, lr=1.97243e-05, gnorm=1.302, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39269
2022-10-16 06:31:51 - progress_bar.py[line:274] - INFO: epoch 001:   8089 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=102.3, ups=0.93, wpb=110.2, bsz=40, num_updates=8080, lr=1.97487e-05, gnorm=1.163, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39280
2022-10-16 06:32:02 - progress_bar.py[line:274] - INFO: epoch 001:   8099 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=8090, lr=1.97732e-05, gnorm=1.227, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39291
2022-10-16 06:32:13 - progress_bar.py[line:274] - INFO: epoch 001:   8109 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=102.1, ups=0.93, wpb=109.9, bsz=40, num_updates=8100, lr=1.97976e-05, gnorm=1.097, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39302
2022-10-16 06:32:24 - progress_bar.py[line:274] - INFO: epoch 001:   8119 / 102288 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=8110, lr=1.98221e-05, gnorm=1.333, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39313
2022-10-16 06:32:36 - progress_bar.py[line:274] - INFO: epoch 001:   8129 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=8120, lr=1.98465e-05, gnorm=1.298, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39325
2022-10-16 06:32:47 - progress_bar.py[line:274] - INFO: epoch 001:   8139 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=8130, lr=1.98709e-05, gnorm=1.35, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=39336
2022-10-16 06:32:58 - progress_bar.py[line:274] - INFO: epoch 001:   8149 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.4, ups=0.88, wpb=111.9, bsz=40, num_updates=8140, lr=1.98954e-05, gnorm=1.221, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39347
2022-10-16 06:33:09 - progress_bar.py[line:274] - INFO: epoch 001:   8159 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=8150, lr=1.99198e-05, gnorm=1.208, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39358
2022-10-16 06:33:20 - progress_bar.py[line:274] - INFO: epoch 001:   8169 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=8160, lr=1.99443e-05, gnorm=1.233, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39369
2022-10-16 06:33:31 - progress_bar.py[line:274] - INFO: epoch 001:   8179 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=101.7, ups=0.93, wpb=109.4, bsz=40, num_updates=8170, lr=1.99687e-05, gnorm=1.561, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39380
2022-10-16 06:33:42 - progress_bar.py[line:274] - INFO: epoch 001:   8189 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=8180, lr=1.99932e-05, gnorm=1.231, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39391
2022-10-16 06:33:54 - progress_bar.py[line:274] - INFO: epoch 001:   8199 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=8190, lr=2.00176e-05, gnorm=1.274, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39403
2022-10-16 06:34:05 - progress_bar.py[line:274] - INFO: epoch 001:   8209 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.6, ups=0.89, wpb=110.1, bsz=40, num_updates=8200, lr=2.0042e-05, gnorm=1.299, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39414
2022-10-16 06:34:16 - progress_bar.py[line:274] - INFO: epoch 001:   8219 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=8210, lr=2.00665e-05, gnorm=1.164, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39425
2022-10-16 06:34:28 - progress_bar.py[line:274] - INFO: epoch 001:   8229 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=8220, lr=2.00909e-05, gnorm=1.22, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39436
2022-10-16 06:34:39 - progress_bar.py[line:274] - INFO: epoch 001:   8239 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.7, ups=0.91, wpb=110.2, bsz=40, num_updates=8230, lr=2.01154e-05, gnorm=1.223, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39448
2022-10-16 06:34:50 - progress_bar.py[line:274] - INFO: epoch 001:   8249 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.4, ups=0.9, wpb=108.6, bsz=40, num_updates=8240, lr=2.01398e-05, gnorm=1.492, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39459
2022-10-16 06:35:01 - progress_bar.py[line:274] - INFO: epoch 001:   8259 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.7, ups=0.91, wpb=111.3, bsz=40, num_updates=8250, lr=2.01642e-05, gnorm=1.223, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39470
2022-10-16 06:35:12 - progress_bar.py[line:274] - INFO: epoch 001:   8269 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=8260, lr=2.01887e-05, gnorm=1.124, clip=70, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39481
2022-10-16 06:35:24 - progress_bar.py[line:274] - INFO: epoch 001:   8279 / 102288 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=95.5, ups=0.88, wpb=108.3, bsz=40, num_updates=8270, lr=2.02131e-05, gnorm=1.164, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39492
2022-10-16 06:35:35 - progress_bar.py[line:274] - INFO: epoch 001:   8289 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=8280, lr=2.02376e-05, gnorm=1.317, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39504
2022-10-16 06:35:39 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 06:35:47 - progress_bar.py[line:274] - INFO: epoch 001:   8300 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=94.3, ups=0.84, wpb=111.6, bsz=40, num_updates=8290, lr=2.0262e-05, gnorm=1.204, clip=70, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=39516
2022-10-16 06:35:58 - progress_bar.py[line:274] - INFO: epoch 001:   8310 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101.3, ups=0.92, wpb=110.2, bsz=40, num_updates=8300, lr=2.02865e-05, gnorm=1.242, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39527
2022-10-16 06:36:09 - progress_bar.py[line:274] - INFO: epoch 001:   8320 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=8310, lr=2.03109e-05, gnorm=1.281, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39538
2022-10-16 06:36:20 - progress_bar.py[line:274] - INFO: epoch 001:   8330 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=8320, lr=2.03353e-05, gnorm=1.365, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39549
2022-10-16 06:36:32 - progress_bar.py[line:274] - INFO: epoch 001:   8340 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=95.2, ups=0.87, wpb=109.6, bsz=40, num_updates=8330, lr=2.03598e-05, gnorm=1.281, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39561
2022-10-16 06:36:43 - progress_bar.py[line:274] - INFO: epoch 001:   8350 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=8340, lr=2.03842e-05, gnorm=1.309, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39572
2022-10-16 06:36:54 - progress_bar.py[line:274] - INFO: epoch 001:   8360 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=8350, lr=2.04087e-05, gnorm=1.403, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39583
2022-10-16 06:37:05 - progress_bar.py[line:274] - INFO: epoch 001:   8370 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=8360, lr=2.04331e-05, gnorm=1.319, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=39594
2022-10-16 06:37:16 - progress_bar.py[line:274] - INFO: epoch 001:   8380 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.6, ups=0.91, wpb=108.8, bsz=40, num_updates=8370, lr=2.04575e-05, gnorm=1.32, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39605
2022-10-16 06:37:28 - progress_bar.py[line:274] - INFO: epoch 001:   8390 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=8380, lr=2.0482e-05, gnorm=1.286, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39617
2022-10-16 06:37:39 - progress_bar.py[line:274] - INFO: epoch 001:   8400 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.2, ups=0.9, wpb=110.6, bsz=40, num_updates=8390, lr=2.05064e-05, gnorm=1.398, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39628
2022-10-16 06:37:50 - progress_bar.py[line:274] - INFO: epoch 001:   8410 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=8400, lr=2.05309e-05, gnorm=1.314, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39639
2022-10-16 06:38:02 - progress_bar.py[line:274] - INFO: epoch 001:   8420 / 102288 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.7, ups=0.87, wpb=110.7, bsz=40, num_updates=8410, lr=2.05553e-05, gnorm=1.211, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39651
2022-10-16 06:38:13 - progress_bar.py[line:274] - INFO: epoch 001:   8430 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.2, ups=0.89, wpb=109.8, bsz=40, num_updates=8420, lr=2.05798e-05, gnorm=1.214, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39662
2022-10-16 06:38:24 - progress_bar.py[line:274] - INFO: epoch 001:   8440 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=8430, lr=2.06042e-05, gnorm=1.215, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39673
2022-10-16 06:38:36 - progress_bar.py[line:274] - INFO: epoch 001:   8450 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=8440, lr=2.06286e-05, gnorm=1.303, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39685
2022-10-16 06:38:47 - progress_bar.py[line:274] - INFO: epoch 001:   8460 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.1, ups=0.89, wpb=112.1, bsz=40, num_updates=8450, lr=2.06531e-05, gnorm=1.239, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39696
2022-10-16 06:38:58 - progress_bar.py[line:274] - INFO: epoch 001:   8470 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98, ups=0.87, wpb=112.7, bsz=40, num_updates=8460, lr=2.06775e-05, gnorm=1.315, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39707
2022-10-16 06:39:10 - progress_bar.py[line:274] - INFO: epoch 001:   8480 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.3, ups=0.87, wpb=109.8, bsz=40, num_updates=8470, lr=2.0702e-05, gnorm=1.314, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39719
2022-10-16 06:39:21 - progress_bar.py[line:274] - INFO: epoch 001:   8490 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=8480, lr=2.07264e-05, gnorm=1.193, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39730
2022-10-16 06:39:32 - progress_bar.py[line:274] - INFO: epoch 001:   8500 / 102288 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=8490, lr=2.07508e-05, gnorm=1.24, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39741
2022-10-16 06:39:44 - progress_bar.py[line:274] - INFO: epoch 001:   8510 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=94.1, ups=0.86, wpb=109.5, bsz=40, num_updates=8500, lr=2.07753e-05, gnorm=1.11, clip=70, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=39753
2022-10-16 06:39:55 - progress_bar.py[line:274] - INFO: epoch 001:   8520 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=8510, lr=2.07997e-05, gnorm=1.183, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39764
2022-10-16 06:40:06 - progress_bar.py[line:274] - INFO: epoch 001:   8530 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.6, ups=0.92, wpb=108.6, bsz=40, num_updates=8520, lr=2.08242e-05, gnorm=1.457, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39775
2022-10-16 06:40:18 - progress_bar.py[line:274] - INFO: epoch 001:   8540 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=8530, lr=2.08486e-05, gnorm=1.147, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=39787
2022-10-16 06:40:29 - progress_bar.py[line:274] - INFO: epoch 001:   8550 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.6, ups=0.88, wpb=110.7, bsz=40, num_updates=8540, lr=2.08731e-05, gnorm=1.185, clip=80, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=39798
2022-10-16 06:40:40 - progress_bar.py[line:274] - INFO: epoch 001:   8560 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=102.6, ups=0.93, wpb=110.5, bsz=40, num_updates=8550, lr=2.08975e-05, gnorm=1.15, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39809
2022-10-16 06:40:51 - progress_bar.py[line:274] - INFO: epoch 001:   8570 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.1, ups=0.91, wpb=110.2, bsz=40, num_updates=8560, lr=2.09219e-05, gnorm=1.239, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=39820
2022-10-16 06:41:02 - progress_bar.py[line:274] - INFO: epoch 001:   8580 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=102.1, ups=0.92, wpb=111.2, bsz=40, num_updates=8570, lr=2.09464e-05, gnorm=1.344, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39831
2022-10-16 06:41:13 - progress_bar.py[line:274] - INFO: epoch 001:   8590 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=8580, lr=2.09708e-05, gnorm=1.192, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39842
2022-10-16 06:41:24 - progress_bar.py[line:274] - INFO: epoch 001:   8600 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.4, ups=0.87, wpb=110.2, bsz=40, num_updates=8590, lr=2.09953e-05, gnorm=1.291, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39853
2022-10-16 06:41:36 - progress_bar.py[line:274] - INFO: epoch 001:   8610 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100, ups=0.91, wpb=110.4, bsz=40, num_updates=8600, lr=2.10197e-05, gnorm=1.268, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39864
2022-10-16 06:41:47 - progress_bar.py[line:274] - INFO: epoch 001:   8620 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100.2, ups=0.9, wpb=110.7, bsz=40, num_updates=8610, lr=2.10441e-05, gnorm=1.42, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39876
2022-10-16 06:41:58 - progress_bar.py[line:274] - INFO: epoch 001:   8630 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.6, ups=0.87, wpb=109.9, bsz=40, num_updates=8620, lr=2.10686e-05, gnorm=1.272, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39887
2022-10-16 06:42:09 - progress_bar.py[line:274] - INFO: epoch 001:   8640 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=102.1, ups=0.93, wpb=110.3, bsz=40, num_updates=8630, lr=2.1093e-05, gnorm=1.279, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39898
2022-10-16 06:42:21 - progress_bar.py[line:274] - INFO: epoch 001:   8650 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.8, ups=0.87, wpb=111.2, bsz=40, num_updates=8640, lr=2.11175e-05, gnorm=1.281, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39910
2022-10-16 06:42:32 - progress_bar.py[line:274] - INFO: epoch 001:   8660 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.7, ups=0.9, wpb=109.5, bsz=40, num_updates=8650, lr=2.11419e-05, gnorm=1.149, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39921
2022-10-16 06:42:43 - progress_bar.py[line:274] - INFO: epoch 001:   8670 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=8660, lr=2.11663e-05, gnorm=1.197, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39932
2022-10-16 06:42:54 - progress_bar.py[line:274] - INFO: epoch 001:   8680 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.7, ups=0.89, wpb=109.5, bsz=40, num_updates=8670, lr=2.11908e-05, gnorm=1.347, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39943
2022-10-16 06:43:05 - progress_bar.py[line:274] - INFO: epoch 001:   8690 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.1, ups=0.9, wpb=110.3, bsz=40, num_updates=8680, lr=2.12152e-05, gnorm=1.206, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39954
2022-10-16 06:43:16 - progress_bar.py[line:274] - INFO: epoch 001:   8700 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=101.5, ups=0.92, wpb=110.6, bsz=40, num_updates=8690, lr=2.12397e-05, gnorm=1.341, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39965
2022-10-16 06:43:27 - progress_bar.py[line:274] - INFO: epoch 001:   8710 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.5, ups=0.92, wpb=109.6, bsz=40, num_updates=8700, lr=2.12641e-05, gnorm=1.079, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39976
2022-10-16 06:43:38 - progress_bar.py[line:274] - INFO: epoch 001:   8720 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=102.9, ups=0.93, wpb=111, bsz=40, num_updates=8710, lr=2.12886e-05, gnorm=1.019, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39987
2022-10-16 06:43:49 - progress_bar.py[line:274] - INFO: epoch 001:   8730 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.2, ups=0.91, wpb=110.1, bsz=40, num_updates=8720, lr=2.1313e-05, gnorm=1.291, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39998
2022-10-16 06:44:00 - progress_bar.py[line:274] - INFO: epoch 001:   8740 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.5, ups=0.87, wpb=109.6, bsz=40, num_updates=8730, lr=2.13374e-05, gnorm=1.314, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40009
2022-10-16 06:44:12 - progress_bar.py[line:274] - INFO: epoch 001:   8750 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=8740, lr=2.13619e-05, gnorm=1.151, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=40021
2022-10-16 06:44:23 - progress_bar.py[line:274] - INFO: epoch 001:   8760 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=8750, lr=2.13863e-05, gnorm=1.121, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40032
2022-10-16 06:44:34 - progress_bar.py[line:274] - INFO: epoch 001:   8770 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.4, ups=0.89, wpb=109.9, bsz=40, num_updates=8760, lr=2.14108e-05, gnorm=1.109, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40043
2022-10-16 06:44:45 - progress_bar.py[line:274] - INFO: epoch 001:   8780 / 102288 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=100.2, ups=0.92, wpb=109.2, bsz=40, num_updates=8770, lr=2.14352e-05, gnorm=1.101, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40054
2022-10-16 06:44:57 - progress_bar.py[line:274] - INFO: epoch 001:   8790 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.4, ups=0.88, wpb=109.3, bsz=40, num_updates=8780, lr=2.14596e-05, gnorm=1.079, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40066
2022-10-16 06:45:08 - progress_bar.py[line:274] - INFO: epoch 001:   8800 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=8790, lr=2.14841e-05, gnorm=1.209, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40077
2022-10-16 06:45:19 - progress_bar.py[line:274] - INFO: epoch 001:   8810 / 102288 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.4, ups=0.92, wpb=109.1, bsz=40, num_updates=8800, lr=2.15085e-05, gnorm=1.303, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40088
2022-10-16 06:45:30 - progress_bar.py[line:274] - INFO: epoch 001:   8820 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=8810, lr=2.1533e-05, gnorm=1.181, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40099
2022-10-16 06:45:41 - progress_bar.py[line:274] - INFO: epoch 001:   8830 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.4, ups=0.91, wpb=109.8, bsz=40, num_updates=8820, lr=2.15574e-05, gnorm=1.219, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40110
2022-10-16 06:45:52 - progress_bar.py[line:274] - INFO: epoch 001:   8840 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=8830, lr=2.15819e-05, gnorm=1.189, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40121
2022-10-16 06:46:03 - progress_bar.py[line:274] - INFO: epoch 001:   8850 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=8840, lr=2.16063e-05, gnorm=1.129, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40132
2022-10-16 06:46:15 - progress_bar.py[line:274] - INFO: epoch 001:   8860 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=8850, lr=2.16307e-05, gnorm=1.115, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40144
2022-10-16 06:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   8870 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=8860, lr=2.16552e-05, gnorm=1.232, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40155
2022-10-16 06:46:37 - progress_bar.py[line:274] - INFO: epoch 001:   8880 / 102288 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.1, ups=0.87, wpb=109.3, bsz=40, num_updates=8870, lr=2.16796e-05, gnorm=1.217, clip=100, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=40166
2022-10-16 06:46:49 - progress_bar.py[line:274] - INFO: epoch 001:   8890 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=96.2, ups=0.88, wpb=109.2, bsz=40, num_updates=8880, lr=2.17041e-05, gnorm=1.273, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40178
2022-10-16 06:47:00 - progress_bar.py[line:274] - INFO: epoch 001:   8900 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.7, ups=0.9, wpb=109.2, bsz=40, num_updates=8890, lr=2.17285e-05, gnorm=1.102, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40189
2022-10-16 06:47:11 - progress_bar.py[line:274] - INFO: epoch 001:   8910 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=8900, lr=2.17529e-05, gnorm=1.115, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40200
2022-10-16 06:47:22 - progress_bar.py[line:274] - INFO: epoch 001:   8920 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=8910, lr=2.17774e-05, gnorm=1.112, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40211
2022-10-16 06:47:34 - progress_bar.py[line:274] - INFO: epoch 001:   8930 / 102288 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=8920, lr=2.18018e-05, gnorm=1.339, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40222
2022-10-16 06:47:45 - progress_bar.py[line:274] - INFO: epoch 001:   8940 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=8930, lr=2.18263e-05, gnorm=1.19, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40234
2022-10-16 06:47:56 - progress_bar.py[line:274] - INFO: epoch 001:   8950 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.2, ups=0.92, wpb=110.3, bsz=40, num_updates=8940, lr=2.18507e-05, gnorm=1.163, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40245
2022-10-16 06:48:07 - progress_bar.py[line:274] - INFO: epoch 001:   8960 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.7, ups=0.87, wpb=111.2, bsz=40, num_updates=8950, lr=2.18752e-05, gnorm=1.115, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40256
2022-10-16 06:48:19 - progress_bar.py[line:274] - INFO: epoch 001:   8970 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.5, ups=0.88, wpb=111.9, bsz=40, num_updates=8960, lr=2.18996e-05, gnorm=1.143, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40267
2022-10-16 06:48:30 - progress_bar.py[line:274] - INFO: epoch 001:   8980 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=99.5, ups=0.92, wpb=108.6, bsz=40, num_updates=8970, lr=2.1924e-05, gnorm=1.154, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40278
2022-10-16 06:48:41 - progress_bar.py[line:274] - INFO: epoch 001:   8990 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.6, ups=0.89, wpb=111.2, bsz=40, num_updates=8980, lr=2.19485e-05, gnorm=1.059, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40290
2022-10-16 06:48:52 - progress_bar.py[line:274] - INFO: epoch 001:   9000 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.9, ups=0.89, wpb=108.4, bsz=40, num_updates=8990, lr=2.19729e-05, gnorm=1.182, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40301
2022-10-16 06:49:03 - progress_bar.py[line:274] - INFO: epoch 001:   9010 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=9000, lr=2.19974e-05, gnorm=1.171, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40312
2022-10-16 06:49:03 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 06:49:05 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 06:49:05 - train.py[line:551] - INFO: load:1.16 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 06:51:37 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 06:51:37 - train.py[line:551] - INFO: load:1.19 valid_run:152.13 task_valid:148.24 collect_output:2.81
2022-10-16 06:54:06 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 06:54:06 - train.py[line:551] - INFO: load:1.22 valid_run:300.67 task_valid:291.65 collect_output:6.71
2022-10-16 06:56:38 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 06:56:38 - train.py[line:551] - INFO: load:1.25 valid_run:453.50 task_valid:435.12 collect_output:14.92
2022-10-16 06:59:08 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 06:59:08 - train.py[line:551] - INFO: load:1.29 valid_run:602.64 task_valid:580.56 collect_output:17.55
2022-10-16 07:01:40 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 07:01:40 - train.py[line:551] - INFO: load:1.32 valid_run:755.18 task_valid:728.58 collect_output:20.94
2022-10-16 07:04:12 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 07:04:12 - train.py[line:551] - INFO: load:1.35 valid_run:906.89 task_valid:874.47 collect_output:25.67
2022-10-16 07:06:45 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 07:06:45 - train.py[line:551] - INFO: load:1.37 valid_run:1060.02 task_valid:1020.92 collect_output:31.17
2022-10-16 07:09:16 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 07:09:16 - train.py[line:551] - INFO: load:1.40 valid_run:1211.05 task_valid:1162.60 collect_output:39.46
2022-10-16 07:11:46 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 07:11:46 - train.py[line:551] - INFO: load:1.43 valid_run:1360.87 task_valid:1307.81 collect_output:42.99
2022-10-16 07:14:15 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 07:14:15 - train.py[line:551] - INFO: load:1.45 valid_run:1509.67 task_valid:1451.57 collect_output:46.91
2022-10-16 07:16:45 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 07:16:45 - train.py[line:551] - INFO: load:1.48 valid_run:1659.59 task_valid:1596.82 collect_output:50.51
2022-10-16 07:19:15 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 07:19:15 - train.py[line:551] - INFO: load:1.51 valid_run:1809.94 task_valid:1742.47 collect_output:54.12
2022-10-16 07:21:45 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 07:21:45 - train.py[line:551] - INFO: load:1.53 valid_run:1959.79 task_valid:1884.47 collect_output:60.89
2022-10-16 07:24:16 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 07:24:16 - train.py[line:551] - INFO: load:1.56 valid_run:2110.16 task_valid:2030.03 collect_output:64.72
2022-10-16 07:26:46 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 07:26:46 - train.py[line:551] - INFO: load:1.58 valid_run:2259.95 task_valid:2176.42 collect_output:67.12
2022-10-16 07:29:16 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 07:29:16 - train.py[line:551] - INFO: load:1.61 valid_run:2409.90 task_valid:2320.44 collect_output:72.05
2022-10-16 07:31:47 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 07:31:47 - train.py[line:551] - INFO: load:1.63 valid_run:2561.47 task_valid:2465.83 collect_output:77.25
2022-10-16 07:34:18 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 07:34:18 - train.py[line:551] - INFO: load:1.66 valid_run:2711.93 task_valid:2612.80 collect_output:79.72
2022-10-16 07:36:46 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 07:36:46 - train.py[line:551] - INFO: load:1.68 valid_run:2860.01 task_valid:2754.10 collect_output:85.50
2022-10-16 07:39:16 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 07:39:16 - train.py[line:551] - INFO: load:1.71 valid_run:3010.33 task_valid:2899.07 collect_output:89.83
2022-10-16 07:41:48 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 07:41:48 - train.py[line:551] - INFO: load:1.73 valid_run:3162.29 task_valid:3043.43 collect_output:96.44
2022-10-16 07:44:18 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 07:44:18 - train.py[line:551] - INFO: load:1.76 valid_run:3311.62 task_valid:3187.91 collect_output:100.30
2022-10-16 07:46:49 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 07:46:49 - train.py[line:551] - INFO: load:1.79 valid_run:3462.90 task_valid:3334.07 collect_output:104.40
2022-10-16 07:49:21 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 07:49:21 - train.py[line:551] - INFO: load:1.81 valid_run:3614.38 task_valid:3480.53 collect_output:108.41

====================================================================================================
SGG eval:     R @ 50: 0.5501;     R @ 100: 0.5748;     R @ 500: 0.6083;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3902;    mR @ 100: 0.4189;    mR @ 500: 0.4504;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5195) (covered in:0.8750) (covering:0.4286) (eating:0.7059) (flying in:1.0000) (growing on:0.3750) (hanging from:0.2903) (lying on:0.1500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8333) (playing:0.0000) (riding:0.9036) (says:0.0000) (sitting on:0.7324) (standing on:0.1400) (using:0.3500) (walking in:0.0000) (walking on:0.8108) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2022-10-16 07:51:51 - train.py[line:487] - INFO: 0.5747714285714286

====================================================================================================
SGG eval:     R @ 50: 0.5501;     R @ 100: 0.5748;     R @ 500: 0.6083;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3902;    mR @ 100: 0.4189;    mR @ 500: 0.4504;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5195) (covered in:0.8750) (covering:0.4286) (eating:0.7059) (flying in:1.0000) (growing on:0.3750) (hanging from:0.2903) (lying on:0.1500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8333) (playing:0.0000) (riding:0.9036) (says:0.0000) (sitting on:0.7324) (standing on:0.1400) (using:0.3500) (walking in:0.0000) (walking on:0.8108) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2022-10-16 07:51:52 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 07:51:52 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.345 | loss_v1 0 | loss_v2 0 | nll_loss 0.188 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.574771 | ppl 1.14 | vqa_score 0.4347 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 9000 | best_R@100 0.575871
2022-10-16 07:51:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 9000 updates
2022-10-16 07:51:52 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_9000.pt
2022-10-16 07:51:57 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_9000.pt
2022-10-16 07:52:00 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 0.5747714285714286) (writing took 8.408988212700933 seconds)
2022-10-16 07:52:11 - progress_bar.py[line:274] - INFO: epoch 001:   9020 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=0.3, ups=0, wpb=111.7, bsz=40, num_updates=9010, lr=2.20218e-05, gnorm=1.251, clip=80, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44100
2022-10-16 07:52:22 - progress_bar.py[line:274] - INFO: epoch 001:   9030 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=9020, lr=2.20462e-05, gnorm=1.269, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44111
2022-10-16 07:52:33 - progress_bar.py[line:274] - INFO: epoch 001:   9040 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=9030, lr=2.20707e-05, gnorm=1.136, clip=70, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44122
2022-10-16 07:52:44 - progress_bar.py[line:274] - INFO: epoch 001:   9050 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100.2, ups=0.91, wpb=109.5, bsz=40, num_updates=9040, lr=2.20951e-05, gnorm=1.137, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44133
2022-10-16 07:52:55 - progress_bar.py[line:274] - INFO: epoch 001:   9060 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.5, ups=0.9, wpb=111, bsz=40, num_updates=9050, lr=2.21196e-05, gnorm=1.109, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44144
2022-10-16 07:53:06 - progress_bar.py[line:274] - INFO: epoch 001:   9070 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=9060, lr=2.2144e-05, gnorm=1.24, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44155
2022-10-16 07:53:17 - progress_bar.py[line:274] - INFO: epoch 001:   9080 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.6, ups=0.88, wpb=109.4, bsz=40, num_updates=9070, lr=2.21685e-05, gnorm=1.19, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44166
2022-10-16 07:53:29 - progress_bar.py[line:274] - INFO: epoch 001:   9090 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=9080, lr=2.21929e-05, gnorm=1.234, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44178
2022-10-16 07:53:40 - progress_bar.py[line:274] - INFO: epoch 001:   9100 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=9090, lr=2.22173e-05, gnorm=1.249, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44189
2022-10-16 07:53:51 - progress_bar.py[line:274] - INFO: epoch 001:   9110 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=9100, lr=2.22418e-05, gnorm=1.133, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44200
2022-10-16 07:54:02 - progress_bar.py[line:274] - INFO: epoch 001:   9120 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=9110, lr=2.22662e-05, gnorm=1.154, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44211
2022-10-16 07:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   9130 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=106.6, ups=0.96, wpb=111.4, bsz=40, num_updates=9120, lr=2.22907e-05, gnorm=1.192, clip=90, loss_scale=1024, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=44222
2022-10-16 07:54:21 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 07:54:25 - progress_bar.py[line:274] - INFO: epoch 001:   9141 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.8, ups=0.84, wpb=110.6, bsz=40, num_updates=9130, lr=2.23151e-05, gnorm=1.128, clip=80, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=44234
2022-10-16 07:54:36 - progress_bar.py[line:274] - INFO: epoch 001:   9151 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=9140, lr=2.23395e-05, gnorm=1.301, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44245
2022-10-16 07:54:47 - progress_bar.py[line:274] - INFO: epoch 001:   9161 / 102288 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=97.6, ups=0.9, wpb=107.9, bsz=40, num_updates=9150, lr=2.2364e-05, gnorm=1.4, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44256
2022-10-16 07:54:58 - progress_bar.py[line:274] - INFO: epoch 001:   9171 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98, ups=0.9, wpb=109.5, bsz=40, num_updates=9160, lr=2.23884e-05, gnorm=1.135, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44267
2022-10-16 07:55:09 - progress_bar.py[line:274] - INFO: epoch 001:   9181 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=9170, lr=2.24129e-05, gnorm=1.177, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44278
2022-10-16 07:55:20 - progress_bar.py[line:274] - INFO: epoch 001:   9191 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101.1, ups=0.9, wpb=112.1, bsz=40, num_updates=9180, lr=2.24373e-05, gnorm=1.456, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44289
2022-10-16 07:55:31 - progress_bar.py[line:274] - INFO: epoch 001:   9201 / 102288 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.5, ups=0.91, wpb=109.8, bsz=40, num_updates=9190, lr=2.24617e-05, gnorm=1.275, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44300
2022-10-16 07:55:42 - progress_bar.py[line:274] - INFO: epoch 001:   9211 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=9200, lr=2.24862e-05, gnorm=1.053, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44311
2022-10-16 07:55:54 - progress_bar.py[line:274] - INFO: epoch 001:   9221 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=9210, lr=2.25106e-05, gnorm=1.154, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44323
2022-10-16 07:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   9231 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99, ups=0.88, wpb=112.1, bsz=40, num_updates=9220, lr=2.25351e-05, gnorm=1.258, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44334
2022-10-16 07:56:16 - progress_bar.py[line:274] - INFO: epoch 001:   9241 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=9230, lr=2.25595e-05, gnorm=1.246, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44345
2022-10-16 07:56:27 - progress_bar.py[line:274] - INFO: epoch 001:   9251 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.1, ups=0.9, wpb=108.5, bsz=40, num_updates=9240, lr=2.2584e-05, gnorm=1.25, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44356
2022-10-16 07:56:38 - progress_bar.py[line:274] - INFO: epoch 001:   9261 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.9, ups=0.91, wpb=111.5, bsz=40, num_updates=9250, lr=2.26084e-05, gnorm=1.18, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44367
2022-10-16 07:56:50 - progress_bar.py[line:274] - INFO: epoch 001:   9271 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=9260, lr=2.26328e-05, gnorm=1.249, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44379
2022-10-16 07:57:00 - progress_bar.py[line:274] - INFO: epoch 001:   9281 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=102.5, ups=0.92, wpb=112, bsz=40, num_updates=9270, lr=2.26573e-05, gnorm=1.011, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44389
2022-10-16 07:57:12 - progress_bar.py[line:274] - INFO: epoch 001:   9291 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.4, ups=0.91, wpb=109.8, bsz=40, num_updates=9280, lr=2.26817e-05, gnorm=1.174, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44401
2022-10-16 07:57:22 - progress_bar.py[line:274] - INFO: epoch 001:   9301 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.9, ups=0.92, wpb=110.2, bsz=40, num_updates=9290, lr=2.27062e-05, gnorm=1.179, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44411
2022-10-16 07:57:34 - progress_bar.py[line:274] - INFO: epoch 001:   9311 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=9300, lr=2.27306e-05, gnorm=1.151, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44423
2022-10-16 07:57:45 - progress_bar.py[line:274] - INFO: epoch 001:   9321 / 102288 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.2, ups=0.9, wpb=108.5, bsz=40, num_updates=9310, lr=2.2755e-05, gnorm=1.127, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44434
2022-10-16 07:57:56 - progress_bar.py[line:274] - INFO: epoch 001:   9331 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.9, ups=0.9, wpb=110.4, bsz=40, num_updates=9320, lr=2.27795e-05, gnorm=1.046, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44445
2022-10-16 07:58:07 - progress_bar.py[line:274] - INFO: epoch 001:   9341 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=9330, lr=2.28039e-05, gnorm=1.098, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44456
2022-10-16 07:58:19 - progress_bar.py[line:274] - INFO: epoch 001:   9351 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.2, ups=0.87, wpb=110.5, bsz=40, num_updates=9340, lr=2.28284e-05, gnorm=1.228, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44468
2022-10-16 07:58:30 - progress_bar.py[line:274] - INFO: epoch 001:   9361 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=9350, lr=2.28528e-05, gnorm=1.048, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44479
2022-10-16 07:58:41 - progress_bar.py[line:274] - INFO: epoch 001:   9371 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=9360, lr=2.28773e-05, gnorm=1.127, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44490
2022-10-16 07:58:52 - progress_bar.py[line:274] - INFO: epoch 001:   9381 / 102288 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.1, ups=0.9, wpb=108.2, bsz=40, num_updates=9370, lr=2.29017e-05, gnorm=1.32, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44501
2022-10-16 07:59:04 - progress_bar.py[line:274] - INFO: epoch 001:   9391 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.1, ups=0.9, wpb=110.4, bsz=40, num_updates=9380, lr=2.29261e-05, gnorm=1.236, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44513
2022-10-16 07:59:15 - progress_bar.py[line:274] - INFO: epoch 001:   9401 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.5, ups=0.91, wpb=109.9, bsz=40, num_updates=9390, lr=2.29506e-05, gnorm=1.179, clip=80, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=44524
2022-10-16 07:59:26 - progress_bar.py[line:274] - INFO: epoch 001:   9411 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=9400, lr=2.2975e-05, gnorm=1.13, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44535
2022-10-16 07:59:36 - progress_bar.py[line:274] - INFO: epoch 001:   9421 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=105, ups=0.95, wpb=110.2, bsz=40, num_updates=9410, lr=2.29995e-05, gnorm=1.014, clip=70, loss_scale=512, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=44545
2022-10-16 07:59:47 - progress_bar.py[line:274] - INFO: epoch 001:   9431 / 102288 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=100.1, ups=0.92, wpb=109.1, bsz=40, num_updates=9420, lr=2.30239e-05, gnorm=1.399, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44556
2022-10-16 07:59:58 - progress_bar.py[line:274] - INFO: epoch 001:   9441 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=9430, lr=2.30483e-05, gnorm=1.116, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44567
2022-10-16 08:00:10 - progress_bar.py[line:274] - INFO: epoch 001:   9451 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.9, ups=0.89, wpb=111.8, bsz=40, num_updates=9440, lr=2.30728e-05, gnorm=1.043, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44578
2022-10-16 08:00:20 - progress_bar.py[line:274] - INFO: epoch 001:   9461 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=9450, lr=2.30972e-05, gnorm=1.155, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44589
2022-10-16 08:00:32 - progress_bar.py[line:274] - INFO: epoch 001:   9471 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=9460, lr=2.31217e-05, gnorm=1.006, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44601
2022-10-16 08:00:43 - progress_bar.py[line:274] - INFO: epoch 001:   9481 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.1, ups=0.88, wpb=110.6, bsz=40, num_updates=9470, lr=2.31461e-05, gnorm=1.082, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44612
2022-10-16 08:00:55 - progress_bar.py[line:274] - INFO: epoch 001:   9491 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=9480, lr=2.31706e-05, gnorm=1.184, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44623
2022-10-16 08:01:06 - progress_bar.py[line:274] - INFO: epoch 001:   9501 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.1, ups=0.91, wpb=110.2, bsz=40, num_updates=9490, lr=2.3195e-05, gnorm=1.101, clip=80, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=44635
2022-10-16 08:01:17 - progress_bar.py[line:274] - INFO: epoch 001:   9511 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=9500, lr=2.32194e-05, gnorm=1.181, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44646
2022-10-16 08:01:28 - progress_bar.py[line:274] - INFO: epoch 001:   9521 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=102.2, ups=0.93, wpb=110, bsz=40, num_updates=9510, lr=2.32439e-05, gnorm=1.088, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44657
2022-10-16 08:01:39 - progress_bar.py[line:274] - INFO: epoch 001:   9531 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.9, ups=0.92, wpb=110, bsz=40, num_updates=9520, lr=2.32683e-05, gnorm=1.127, clip=80, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=44668
2022-10-16 08:01:50 - progress_bar.py[line:274] - INFO: epoch 001:   9541 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.8, ups=0.92, wpb=109.7, bsz=40, num_updates=9530, lr=2.32928e-05, gnorm=1.19, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44679
2022-10-16 08:02:01 - progress_bar.py[line:274] - INFO: epoch 001:   9551 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.9, ups=0.87, wpb=110.1, bsz=40, num_updates=9540, lr=2.33172e-05, gnorm=1.093, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44690
2022-10-16 08:02:12 - progress_bar.py[line:274] - INFO: epoch 001:   9561 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=9550, lr=2.33416e-05, gnorm=1.165, clip=90, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=44701
2022-10-16 08:02:24 - progress_bar.py[line:274] - INFO: epoch 001:   9571 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=95.8, ups=0.88, wpb=108.4, bsz=40, num_updates=9560, lr=2.33661e-05, gnorm=1.234, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44713
2022-10-16 08:02:35 - progress_bar.py[line:274] - INFO: epoch 001:   9581 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=9570, lr=2.33905e-05, gnorm=1.086, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44724
2022-10-16 08:02:46 - progress_bar.py[line:274] - INFO: epoch 001:   9591 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.3, ups=0.88, wpb=109.4, bsz=40, num_updates=9580, lr=2.3415e-05, gnorm=1.32, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44735
2022-10-16 08:02:57 - progress_bar.py[line:274] - INFO: epoch 001:   9601 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=103.6, ups=0.93, wpb=111.3, bsz=40, num_updates=9590, lr=2.34394e-05, gnorm=1.165, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44746
2022-10-16 08:03:09 - progress_bar.py[line:274] - INFO: epoch 001:   9611 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.8, ups=0.87, wpb=110.1, bsz=40, num_updates=9600, lr=2.34639e-05, gnorm=1.171, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44758
2022-10-16 08:03:20 - progress_bar.py[line:274] - INFO: epoch 001:   9621 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=9610, lr=2.34883e-05, gnorm=1.383, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44769
2022-10-16 08:03:31 - progress_bar.py[line:274] - INFO: epoch 001:   9631 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=9620, lr=2.35127e-05, gnorm=1.452, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44780
2022-10-16 08:03:43 - progress_bar.py[line:274] - INFO: epoch 001:   9641 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.5, ups=0.87, wpb=111.2, bsz=40, num_updates=9630, lr=2.35372e-05, gnorm=1.093, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44792
2022-10-16 08:03:54 - progress_bar.py[line:274] - INFO: epoch 001:   9651 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.6, ups=0.89, wpb=111.6, bsz=40, num_updates=9640, lr=2.35616e-05, gnorm=1.061, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44803
2022-10-16 08:04:05 - progress_bar.py[line:274] - INFO: epoch 001:   9661 / 102288 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.3, ups=0.89, wpb=108.9, bsz=40, num_updates=9650, lr=2.35861e-05, gnorm=1.136, clip=70, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44814
2022-10-16 08:04:16 - progress_bar.py[line:274] - INFO: epoch 001:   9671 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=9660, lr=2.36105e-05, gnorm=1.031, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44825
2022-10-16 08:04:28 - progress_bar.py[line:274] - INFO: epoch 001:   9681 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=9670, lr=2.36349e-05, gnorm=1.202, clip=80, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44837
2022-10-16 08:04:38 - progress_bar.py[line:274] - INFO: epoch 001:   9691 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.8, ups=0.92, wpb=109.1, bsz=40, num_updates=9680, lr=2.36594e-05, gnorm=1.18, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44847
2022-10-16 08:04:50 - progress_bar.py[line:274] - INFO: epoch 001:   9701 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=9690, lr=2.36838e-05, gnorm=1.215, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44859
2022-10-16 08:05:01 - progress_bar.py[line:274] - INFO: epoch 001:   9711 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=9700, lr=2.37083e-05, gnorm=1.091, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44870
2022-10-16 08:05:12 - progress_bar.py[line:274] - INFO: epoch 001:   9721 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=9710, lr=2.37327e-05, gnorm=1.36, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44881
2022-10-16 08:05:23 - progress_bar.py[line:274] - INFO: epoch 001:   9731 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.3, ups=0.91, wpb=110.9, bsz=40, num_updates=9720, lr=2.37571e-05, gnorm=1.18, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44892
2022-10-16 08:05:34 - progress_bar.py[line:274] - INFO: epoch 001:   9741 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=9730, lr=2.37816e-05, gnorm=1.283, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44903
2022-10-16 08:05:46 - progress_bar.py[line:274] - INFO: epoch 001:   9751 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=9740, lr=2.3806e-05, gnorm=1.133, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44915
2022-10-16 08:05:57 - progress_bar.py[line:274] - INFO: epoch 001:   9761 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=9750, lr=2.38305e-05, gnorm=1.247, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44926
2022-10-16 08:06:08 - progress_bar.py[line:274] - INFO: epoch 001:   9771 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=9760, lr=2.38549e-05, gnorm=1.098, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44937
2022-10-16 08:06:20 - progress_bar.py[line:274] - INFO: epoch 001:   9781 / 102288 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=94.9, ups=0.88, wpb=108.4, bsz=40, num_updates=9770, lr=2.38794e-05, gnorm=1.108, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44949
2022-10-16 08:06:31 - progress_bar.py[line:274] - INFO: epoch 001:   9791 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.8, ups=0.9, wpb=110.2, bsz=40, num_updates=9780, lr=2.39038e-05, gnorm=1.048, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44960
2022-10-16 08:06:42 - progress_bar.py[line:274] - INFO: epoch 001:   9801 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=9790, lr=2.39282e-05, gnorm=1.085, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44971
2022-10-16 08:06:53 - progress_bar.py[line:274] - INFO: epoch 001:   9811 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.3, ups=0.89, wpb=109, bsz=40, num_updates=9800, lr=2.39527e-05, gnorm=1.159, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44982
2022-10-16 08:07:04 - progress_bar.py[line:274] - INFO: epoch 001:   9821 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=103.2, ups=0.93, wpb=111, bsz=40, num_updates=9810, lr=2.39771e-05, gnorm=0.958, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44993
2022-10-16 08:07:15 - progress_bar.py[line:274] - INFO: epoch 001:   9831 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=9820, lr=2.40016e-05, gnorm=1.069, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45004
2022-10-16 08:07:26 - progress_bar.py[line:274] - INFO: epoch 001:   9841 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.7, ups=0.92, wpb=109.9, bsz=40, num_updates=9830, lr=2.4026e-05, gnorm=1.04, clip=60, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=45015
2022-10-16 08:07:37 - progress_bar.py[line:274] - INFO: epoch 001:   9851 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=9840, lr=2.40504e-05, gnorm=1.106, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45026
2022-10-16 08:07:49 - progress_bar.py[line:274] - INFO: epoch 001:   9861 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96, ups=0.88, wpb=109.2, bsz=40, num_updates=9850, lr=2.40749e-05, gnorm=1.075, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45038
2022-10-16 08:08:00 - progress_bar.py[line:274] - INFO: epoch 001:   9871 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.8, ups=0.89, wpb=110.4, bsz=40, num_updates=9860, lr=2.40993e-05, gnorm=1.09, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45049
2022-10-16 08:08:12 - progress_bar.py[line:274] - INFO: epoch 001:   9881 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.3, ups=0.88, wpb=109.5, bsz=40, num_updates=9870, lr=2.41238e-05, gnorm=1.229, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45061
2022-10-16 08:08:23 - progress_bar.py[line:274] - INFO: epoch 001:   9891 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.5, ups=0.9, wpb=109.2, bsz=40, num_updates=9880, lr=2.41482e-05, gnorm=1.125, clip=80, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45072
2022-10-16 08:08:34 - progress_bar.py[line:274] - INFO: epoch 001:   9901 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.9, ups=0.91, wpb=110.3, bsz=40, num_updates=9890, lr=2.41727e-05, gnorm=1.11, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45083
2022-10-16 08:08:45 - progress_bar.py[line:274] - INFO: epoch 001:   9911 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=94.8, ups=0.87, wpb=109.4, bsz=40, num_updates=9900, lr=2.41971e-05, gnorm=1.091, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45094
2022-10-16 08:08:56 - progress_bar.py[line:274] - INFO: epoch 001:   9921 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.8, ups=0.91, wpb=109.2, bsz=40, num_updates=9910, lr=2.42215e-05, gnorm=1.157, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45105
2022-10-16 08:09:08 - progress_bar.py[line:274] - INFO: epoch 001:   9931 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.8, ups=0.86, wpb=110.2, bsz=40, num_updates=9920, lr=2.4246e-05, gnorm=1.191, clip=70, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=45117
2022-10-16 08:09:19 - progress_bar.py[line:274] - INFO: epoch 001:   9941 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=9930, lr=2.42704e-05, gnorm=1.178, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45128
2022-10-16 08:09:22 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 08:09:31 - progress_bar.py[line:274] - INFO: epoch 001:   9952 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=90.3, ups=0.81, wpb=111.3, bsz=40, num_updates=9940, lr=2.42949e-05, gnorm=1.099, clip=90, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=45140
2022-10-16 08:09:43 - progress_bar.py[line:274] - INFO: epoch 001:   9962 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=9950, lr=2.43193e-05, gnorm=1.063, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45152
2022-10-16 08:09:54 - progress_bar.py[line:274] - INFO: epoch 001:   9972 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.8, ups=0.91, wpb=110, bsz=40, num_updates=9960, lr=2.43437e-05, gnorm=1.176, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45163
2022-10-16 08:10:05 - progress_bar.py[line:274] - INFO: epoch 001:   9982 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.8, ups=0.88, wpb=110.6, bsz=40, num_updates=9970, lr=2.43682e-05, gnorm=1.213, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45174
2022-10-16 08:10:16 - progress_bar.py[line:274] - INFO: epoch 001:   9992 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102.2, ups=0.93, wpb=110.1, bsz=40, num_updates=9980, lr=2.43926e-05, gnorm=0.99, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45185
2022-10-16 08:10:27 - progress_bar.py[line:274] - INFO: epoch 001:  10002 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.2, ups=0.89, wpb=111.2, bsz=40, num_updates=9990, lr=2.44171e-05, gnorm=1.072, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45196
2022-10-16 08:10:38 - progress_bar.py[line:274] - INFO: epoch 001:  10012 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.1, ups=0.88, wpb=110.8, bsz=40, num_updates=10000, lr=2.44415e-05, gnorm=1.15, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45207
2022-10-16 08:10:38 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 08:10:40 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 08:10:40 - train.py[line:551] - INFO: load:1.23 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 08:13:12 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 08:13:12 - train.py[line:551] - INFO: load:1.26 valid_run:151.75 task_valid:148.54 collect_output:2.02
2022-10-16 08:15:40 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 08:15:40 - train.py[line:551] - INFO: load:1.28 valid_run:300.40 task_valid:292.27 collect_output:5.78
2022-10-16 08:16:27 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.49 GiB (GPU 1; 39.59 GiB total capacity; 9.05 GiB already allocated; 5.95 GiB free; 31.15 GiB reserved in total by PyTorch)
2022-10-16 08:16:27 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-16 08:16:27 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 24        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9267 MB |   15799 MB |    6611 TB |    6611 TB |
|       from large pool |    9122 MB |   15654 MB |    6609 TB |    6609 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9267 MB |   15799 MB |    6611 TB |    6611 TB |
|       from large pool |    9122 MB |   15654 MB |    6609 TB |    6609 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31898 MB |   33158 MB |  238802 MB |  206904 MB |
|       from large pool |   31752 MB |   33006 MB |  238536 MB |  206784 MB |
|       from small pool |     146 MB |     152 MB |     266 MB |     120 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22630 MB |   27183 MB |    6353 TB |    6353 TB |
|       from large pool |   22629 MB |   27181 MB |    6351 TB |    6351 TB |
|       from small pool |       1 MB |       2 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  306474 K  |  306470 K  |
|       from large pool |     563    |     575    |   98514 K  |   98513 K  |
|       from small pool |    3106    |    3116    |  207960 K  |  207956 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  306474 K  |  306470 K  |
|       from large pool |     563    |     575    |   98514 K  |   98513 K  |
|       from small pool |    3106    |    3116    |  207960 K  |  207956 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     159    |     163    |     483    |     324    |
|       from large pool |      86    |      87    |     350    |     264    |
|       from small pool |      73    |      76    |     133    |      60    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      99    |     112    |  220873 K  |  220873 K  |
|       from large pool |      65    |      70    |   39500 K  |   39500 K  |
|       from small pool |      34    |      49    |  181373 K  |  181373 K  |
|===========================================================================|

2022-10-16 08:16:27 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-16 08:18:14 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 08:18:14 - train.py[line:551] - INFO: load:1.31 valid_run:453.48 task_valid:435.93 collect_output:14.04
2022-10-16 08:20:43 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 08:20:43 - train.py[line:551] - INFO: load:1.33 valid_run:602.63 task_valid:581.27 collect_output:16.74
2022-10-16 08:23:15 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 08:23:15 - train.py[line:551] - INFO: load:1.36 valid_run:755.15 task_valid:729.22 collect_output:20.11
2022-10-16 08:25:47 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 08:25:47 - train.py[line:551] - INFO: load:1.38 valid_run:906.99 task_valid:874.91 collect_output:25.13
2022-10-16 08:28:21 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 08:28:21 - train.py[line:551] - INFO: load:1.41 valid_run:1060.16 task_valid:1021.51 collect_output:30.64
2022-10-16 08:30:52 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 08:30:52 - train.py[line:551] - INFO: load:1.44 valid_run:1211.20 task_valid:1163.15 collect_output:38.94
2022-10-16 08:33:21 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 08:33:21 - train.py[line:551] - INFO: load:1.46 valid_run:1360.96 task_valid:1308.30 collect_output:42.46
2022-10-16 08:35:50 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 08:35:50 - train.py[line:551] - INFO: load:1.49 valid_run:1509.55 task_valid:1451.72 collect_output:46.59
2022-10-16 08:38:20 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 08:38:20 - train.py[line:551] - INFO: load:1.52 valid_run:1659.15 task_valid:1596.71 collect_output:50.20
2022-10-16 08:40:49 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 08:40:49 - train.py[line:551] - INFO: load:1.54 valid_run:1808.80 task_valid:1741.56 collect_output:53.98
2022-10-16 08:43:19 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 08:43:19 - train.py[line:551] - INFO: load:1.57 valid_run:1958.26 task_valid:1883.37 collect_output:60.63
2022-10-16 08:45:49 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 08:45:49 - train.py[line:551] - INFO: load:1.60 valid_run:2108.42 task_valid:2028.63 collect_output:64.51
2022-10-16 08:48:19 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 08:48:19 - train.py[line:551] - INFO: load:1.62 valid_run:2258.29 task_valid:2175.06 collect_output:66.95
2022-10-16 08:50:49 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 08:50:49 - train.py[line:551] - INFO: load:1.65 valid_run:2407.99 task_valid:2319.13 collect_output:71.58
2022-10-16 08:53:20 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 08:53:20 - train.py[line:551] - INFO: load:1.68 valid_run:2559.43 task_valid:2464.65 collect_output:76.51
2022-10-16 08:55:51 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 08:55:51 - train.py[line:551] - INFO: load:1.70 valid_run:2709.87 task_valid:2611.74 collect_output:78.85
2022-10-16 08:58:19 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 08:58:19 - train.py[line:551] - INFO: load:1.73 valid_run:2858.31 task_valid:2753.63 collect_output:84.38
2022-10-16 09:00:49 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 09:00:49 - train.py[line:551] - INFO: load:1.75 valid_run:3008.35 task_valid:2898.87 collect_output:88.16
2022-10-16 09:03:21 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 09:03:21 - train.py[line:551] - INFO: load:1.78 valid_run:3160.11 task_valid:3043.37 collect_output:94.41
2022-10-16 09:05:50 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 09:05:50 - train.py[line:551] - INFO: load:1.81 valid_run:3309.22 task_valid:3187.89 collect_output:98.00
2022-10-16 09:08:22 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 09:08:22 - train.py[line:551] - INFO: load:1.83 valid_run:3460.24 task_valid:3334.08 collect_output:101.78
2022-10-16 09:10:53 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 09:10:53 - train.py[line:551] - INFO: load:1.86 valid_run:3611.62 task_valid:3480.70 collect_output:105.55

====================================================================================================
SGG eval:     R @ 50: 0.5491;     R @ 100: 0.5768;     R @ 500: 0.6110;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4060;    mR @ 100: 0.4314;    mR @ 500: 0.4621;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5366) (covered in:0.8750) (covering:0.3571) (eating:0.7647) (flying in:1.0000) (growing on:0.3750) (hanging from:0.2903) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8750) (playing:0.0000) (riding:0.9036) (says:0.0000) (sitting on:0.7143) (standing on:0.1200) (using:0.4500) (walking in:0.0000) (walking on:0.8378) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2022-10-16 09:13:24 - train.py[line:487] - INFO: 0.5768380952380953

====================================================================================================
SGG eval:     R @ 50: 0.5491;     R @ 100: 0.5768;     R @ 500: 0.6110;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4060;    mR @ 100: 0.4314;    mR @ 500: 0.4621;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5366) (covered in:0.8750) (covering:0.3571) (eating:0.7647) (flying in:1.0000) (growing on:0.3750) (hanging from:0.2903) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8750) (playing:0.0000) (riding:0.9036) (says:0.0000) (sitting on:0.7143) (standing on:0.1200) (using:0.4500) (walking in:0.0000) (walking on:0.8378) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2022-10-16 09:13:24 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 09:13:24 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.342 | loss_v1 0 | loss_v2 0 | nll_loss 0.187 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.576838 | ppl 1.14 | vqa_score 0.4583 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 10000 | best_R@100 0.576838
2022-10-16 09:13:24 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2022-10-16 09:13:24 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_10000.pt
2022-10-16 09:13:30 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_10000.pt
2022-10-16 09:13:35 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.5768380952380953) (writing took 10.720179259777069 seconds)
2022-10-16 09:13:47 - progress_bar.py[line:274] - INFO: epoch 001:  10022 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=0.3, ups=0, wpb=111.6, bsz=40, num_updates=10010, lr=2.4466e-05, gnorm=1.159, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=48995
2022-10-16 09:13:58 - progress_bar.py[line:274] - INFO: epoch 001:  10032 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=10020, lr=2.44904e-05, gnorm=1.113, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=49007
2022-10-16 09:14:09 - progress_bar.py[line:274] - INFO: epoch 001:  10042 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=10030, lr=2.45148e-05, gnorm=1.137, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49018
2022-10-16 09:14:20 - progress_bar.py[line:274] - INFO: epoch 001:  10052 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.8, ups=0.9, wpb=112.5, bsz=40, num_updates=10040, lr=2.45393e-05, gnorm=1.072, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49029
2022-10-16 09:14:31 - progress_bar.py[line:274] - INFO: epoch 001:  10062 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=10050, lr=2.45637e-05, gnorm=1.15, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49040
2022-10-16 09:14:42 - progress_bar.py[line:274] - INFO: epoch 001:  10072 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=10060, lr=2.45882e-05, gnorm=1.196, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49051
2022-10-16 09:14:53 - progress_bar.py[line:274] - INFO: epoch 001:  10082 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=10070, lr=2.46126e-05, gnorm=1.064, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49062
2022-10-16 09:15:05 - progress_bar.py[line:274] - INFO: epoch 001:  10092 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=10080, lr=2.4637e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49074
2022-10-16 09:15:16 - progress_bar.py[line:274] - INFO: epoch 001:  10102 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=10090, lr=2.46615e-05, gnorm=1.17, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49085
2022-10-16 09:15:27 - progress_bar.py[line:274] - INFO: epoch 001:  10112 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.4, ups=0.89, wpb=109.1, bsz=40, num_updates=10100, lr=2.46859e-05, gnorm=1.171, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=49096
2022-10-16 09:15:38 - progress_bar.py[line:274] - INFO: epoch 001:  10122 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102.8, ups=0.93, wpb=110.6, bsz=40, num_updates=10110, lr=2.47104e-05, gnorm=1.095, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49107
2022-10-16 09:15:49 - progress_bar.py[line:274] - INFO: epoch 001:  10132 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.7, ups=0.89, wpb=111.8, bsz=40, num_updates=10120, lr=2.47348e-05, gnorm=1.217, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49118
2022-10-16 09:16:00 - progress_bar.py[line:274] - INFO: epoch 001:  10142 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=10130, lr=2.47593e-05, gnorm=1.139, clip=80, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49129
2022-10-16 09:16:11 - progress_bar.py[line:274] - INFO: epoch 001:  10152 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.2, ups=0.9, wpb=111.9, bsz=40, num_updates=10140, lr=2.47837e-05, gnorm=1.035, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49140
2022-10-16 09:16:23 - progress_bar.py[line:274] - INFO: epoch 001:  10162 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=10150, lr=2.48081e-05, gnorm=0.965, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49152
2022-10-16 09:16:35 - progress_bar.py[line:274] - INFO: epoch 001:  10172 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=10160, lr=2.48326e-05, gnorm=1.155, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49163
2022-10-16 09:16:46 - progress_bar.py[line:274] - INFO: epoch 001:  10182 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=102, ups=0.93, wpb=109.9, bsz=40, num_updates=10170, lr=2.4857e-05, gnorm=1.204, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=49175
2022-10-16 09:16:58 - progress_bar.py[line:274] - INFO: epoch 001:  10192 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=10180, lr=2.48815e-05, gnorm=1.207, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49187
2022-10-16 09:17:09 - progress_bar.py[line:274] - INFO: epoch 001:  10202 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=10190, lr=2.49059e-05, gnorm=1.032, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49198
2022-10-16 09:17:20 - progress_bar.py[line:274] - INFO: epoch 001:  10212 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=10200, lr=2.49303e-05, gnorm=1.011, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49209
2022-10-16 09:17:31 - progress_bar.py[line:274] - INFO: epoch 001:  10222 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99, ups=0.91, wpb=109.3, bsz=40, num_updates=10210, lr=2.49548e-05, gnorm=0.974, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49220
2022-10-16 09:17:42 - progress_bar.py[line:274] - INFO: epoch 001:  10232 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=10220, lr=2.49792e-05, gnorm=1.075, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49231
2022-10-16 09:17:53 - progress_bar.py[line:274] - INFO: epoch 001:  10242 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.4, ups=0.89, wpb=110.7, bsz=40, num_updates=10230, lr=2.50037e-05, gnorm=1.055, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49242
2022-10-16 09:18:05 - progress_bar.py[line:274] - INFO: epoch 001:  10252 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.5, ups=0.89, wpb=108.3, bsz=40, num_updates=10240, lr=2.50281e-05, gnorm=1.207, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49254
2022-10-16 09:18:16 - progress_bar.py[line:274] - INFO: epoch 001:  10262 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97, ups=0.88, wpb=110.6, bsz=40, num_updates=10250, lr=2.50525e-05, gnorm=1.147, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49265
2022-10-16 09:18:27 - progress_bar.py[line:274] - INFO: epoch 001:  10272 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.4, ups=0.9, wpb=110.6, bsz=40, num_updates=10260, lr=2.5077e-05, gnorm=1.21, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49276
2022-10-16 09:18:39 - progress_bar.py[line:274] - INFO: epoch 001:  10282 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.1, ups=0.88, wpb=109, bsz=40, num_updates=10270, lr=2.51014e-05, gnorm=1.1, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49288
2022-10-16 09:18:50 - progress_bar.py[line:274] - INFO: epoch 001:  10292 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.8, ups=0.9, wpb=109.2, bsz=40, num_updates=10280, lr=2.51259e-05, gnorm=1.133, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49299
2022-10-16 09:19:01 - progress_bar.py[line:274] - INFO: epoch 001:  10302 / 102288 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=95.5, ups=0.88, wpb=108.4, bsz=40, num_updates=10290, lr=2.51503e-05, gnorm=1.162, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49310
2022-10-16 09:19:12 - progress_bar.py[line:274] - INFO: epoch 001:  10312 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100, ups=0.91, wpb=110.1, bsz=40, num_updates=10300, lr=2.51748e-05, gnorm=1.1, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49321
2022-10-16 09:19:23 - progress_bar.py[line:274] - INFO: epoch 001:  10322 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.4, ups=0.9, wpb=108.7, bsz=40, num_updates=10310, lr=2.51992e-05, gnorm=1.143, clip=90, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=49332
2022-10-16 09:19:34 - progress_bar.py[line:274] - INFO: epoch 001:  10332 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=102.5, ups=0.92, wpb=111.1, bsz=40, num_updates=10320, lr=2.52236e-05, gnorm=1.127, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49343
2022-10-16 09:19:46 - progress_bar.py[line:274] - INFO: epoch 001:  10342 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=10330, lr=2.52481e-05, gnorm=1.118, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49355
2022-10-16 09:19:57 - progress_bar.py[line:274] - INFO: epoch 001:  10352 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=10340, lr=2.52725e-05, gnorm=0.933, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49366
2022-10-16 09:20:08 - progress_bar.py[line:274] - INFO: epoch 001:  10362 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=10350, lr=2.5297e-05, gnorm=1.007, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49377
2022-10-16 09:20:19 - progress_bar.py[line:274] - INFO: epoch 001:  10372 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.9, ups=0.9, wpb=111.8, bsz=40, num_updates=10360, lr=2.53214e-05, gnorm=1.242, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49388
2022-10-16 09:20:30 - progress_bar.py[line:274] - INFO: epoch 001:  10382 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.7, ups=0.88, wpb=109.3, bsz=40, num_updates=10370, lr=2.53458e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49399
2022-10-16 09:20:41 - progress_bar.py[line:274] - INFO: epoch 001:  10392 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=105.4, ups=0.94, wpb=111.6, bsz=40, num_updates=10380, lr=2.53703e-05, gnorm=0.989, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49410
2022-10-16 09:20:52 - progress_bar.py[line:274] - INFO: epoch 001:  10402 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.7, ups=0.9, wpb=110.1, bsz=40, num_updates=10390, lr=2.53947e-05, gnorm=0.949, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49421
2022-10-16 09:21:03 - progress_bar.py[line:274] - INFO: epoch 001:  10412 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=10400, lr=2.54192e-05, gnorm=1.17, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49432
2022-10-16 09:21:14 - progress_bar.py[line:274] - INFO: epoch 001:  10422 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.7, ups=0.92, wpb=111, bsz=40, num_updates=10410, lr=2.54436e-05, gnorm=1.083, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49443
2022-10-16 09:21:25 - progress_bar.py[line:274] - INFO: epoch 001:  10432 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=10420, lr=2.54681e-05, gnorm=0.985, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49454
2022-10-16 09:21:37 - progress_bar.py[line:274] - INFO: epoch 001:  10442 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.9, ups=0.87, wpb=110.8, bsz=40, num_updates=10430, lr=2.54925e-05, gnorm=0.885, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49466
2022-10-16 09:21:48 - progress_bar.py[line:274] - INFO: epoch 001:  10452 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.6, ups=0.91, wpb=108.9, bsz=40, num_updates=10440, lr=2.55169e-05, gnorm=1.091, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49477
2022-10-16 09:22:00 - progress_bar.py[line:274] - INFO: epoch 001:  10462 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97, ups=0.87, wpb=111.6, bsz=40, num_updates=10450, lr=2.55414e-05, gnorm=1.074, clip=60, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=49488
2022-10-16 09:22:11 - progress_bar.py[line:274] - INFO: epoch 001:  10472 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.3, ups=0.9, wpb=109.4, bsz=40, num_updates=10460, lr=2.55658e-05, gnorm=1.132, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49500
2022-10-16 09:22:22 - progress_bar.py[line:274] - INFO: epoch 001:  10482 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.2, ups=0.9, wpb=111.2, bsz=40, num_updates=10470, lr=2.55903e-05, gnorm=0.936, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49511
2022-10-16 09:22:33 - progress_bar.py[line:274] - INFO: epoch 001:  10492 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.9, ups=0.9, wpb=112.1, bsz=40, num_updates=10480, lr=2.56147e-05, gnorm=1.004, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49522
2022-10-16 09:22:44 - progress_bar.py[line:274] - INFO: epoch 001:  10502 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.2, ups=0.89, wpb=109.2, bsz=40, num_updates=10490, lr=2.56391e-05, gnorm=1.065, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49533
2022-10-16 09:22:55 - progress_bar.py[line:274] - INFO: epoch 001:  10512 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.9, ups=0.89, wpb=108.6, bsz=40, num_updates=10500, lr=2.56636e-05, gnorm=1.1, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49544
2022-10-16 09:23:07 - progress_bar.py[line:274] - INFO: epoch 001:  10522 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.9, ups=0.91, wpb=107.6, bsz=40, num_updates=10510, lr=2.5688e-05, gnorm=1.293, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49555
2022-10-16 09:23:18 - progress_bar.py[line:274] - INFO: epoch 001:  10532 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=10520, lr=2.57125e-05, gnorm=1.154, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49567
2022-10-16 09:23:29 - progress_bar.py[line:274] - INFO: epoch 001:  10542 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=10530, lr=2.57369e-05, gnorm=1.12, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49578
2022-10-16 09:23:40 - progress_bar.py[line:274] - INFO: epoch 001:  10552 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=104.4, ups=0.95, wpb=109.7, bsz=40, num_updates=10540, lr=2.57614e-05, gnorm=1.216, clip=80, loss_scale=1024, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=49588
2022-10-16 09:23:51 - progress_bar.py[line:274] - INFO: epoch 001:  10562 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.1, ups=0.91, wpb=110.9, bsz=40, num_updates=10550, lr=2.57858e-05, gnorm=1.149, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49599
2022-10-16 09:24:02 - progress_bar.py[line:274] - INFO: epoch 001:  10572 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=10560, lr=2.58102e-05, gnorm=1.237, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49610
2022-10-16 09:24:13 - progress_bar.py[line:274] - INFO: epoch 001:  10582 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=10570, lr=2.58347e-05, gnorm=1.038, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49622
2022-10-16 09:24:24 - progress_bar.py[line:274] - INFO: epoch 001:  10592 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.2, ups=0.9, wpb=111.2, bsz=40, num_updates=10580, lr=2.58591e-05, gnorm=1.085, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49633
2022-10-16 09:24:35 - progress_bar.py[line:274] - INFO: epoch 001:  10602 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.4, ups=0.91, wpb=109.8, bsz=40, num_updates=10590, lr=2.58836e-05, gnorm=1.017, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49644
2022-10-16 09:24:46 - progress_bar.py[line:274] - INFO: epoch 001:  10612 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.5, ups=0.92, wpb=110.7, bsz=40, num_updates=10600, lr=2.5908e-05, gnorm=1.291, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49655
2022-10-16 09:24:57 - progress_bar.py[line:274] - INFO: epoch 001:  10622 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.7, ups=0.92, wpb=109.4, bsz=40, num_updates=10610, lr=2.59324e-05, gnorm=1.128, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49666
2022-10-16 09:25:08 - progress_bar.py[line:274] - INFO: epoch 001:  10632 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.9, ups=0.92, wpb=109.6, bsz=40, num_updates=10620, lr=2.59569e-05, gnorm=1.161, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49677
2022-10-16 09:25:19 - progress_bar.py[line:274] - INFO: epoch 001:  10642 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=10630, lr=2.59813e-05, gnorm=1.022, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49688
2022-10-16 09:25:30 - progress_bar.py[line:274] - INFO: epoch 001:  10652 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102.6, ups=0.92, wpb=111.9, bsz=40, num_updates=10640, lr=2.60058e-05, gnorm=1.081, clip=70, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=49699
2022-10-16 09:25:41 - progress_bar.py[line:274] - INFO: epoch 001:  10662 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.5, ups=0.89, wpb=109.6, bsz=40, num_updates=10650, lr=2.60302e-05, gnorm=1.192, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=49710
2022-10-16 09:25:52 - progress_bar.py[line:274] - INFO: epoch 001:  10672 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=10660, lr=2.60547e-05, gnorm=1.08, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49721
2022-10-16 09:26:04 - progress_bar.py[line:274] - INFO: epoch 001:  10682 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=10670, lr=2.60791e-05, gnorm=1.084, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49733
2022-10-16 09:26:15 - progress_bar.py[line:274] - INFO: epoch 001:  10692 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=10680, lr=2.61035e-05, gnorm=1.058, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49744
2022-10-16 09:26:26 - progress_bar.py[line:274] - INFO: epoch 001:  10702 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.7, ups=0.92, wpb=112.2, bsz=40, num_updates=10690, lr=2.6128e-05, gnorm=1.22, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49755
2022-10-16 09:26:37 - progress_bar.py[line:274] - INFO: epoch 001:  10712 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=10700, lr=2.61524e-05, gnorm=1.037, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49766
2022-10-16 09:26:49 - progress_bar.py[line:274] - INFO: epoch 001:  10722 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.6, ups=0.88, wpb=109.6, bsz=40, num_updates=10710, lr=2.61769e-05, gnorm=1.032, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49778
2022-10-16 09:27:00 - progress_bar.py[line:274] - INFO: epoch 001:  10732 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=10720, lr=2.62013e-05, gnorm=1.183, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49789
2022-10-16 09:27:11 - progress_bar.py[line:274] - INFO: epoch 001:  10742 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.6, ups=0.92, wpb=109.8, bsz=40, num_updates=10730, lr=2.62257e-05, gnorm=1.113, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49800
2022-10-16 09:27:22 - progress_bar.py[line:274] - INFO: epoch 001:  10752 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.1, ups=0.9, wpb=110.3, bsz=40, num_updates=10740, lr=2.62502e-05, gnorm=1.018, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49811
2022-10-16 09:27:34 - progress_bar.py[line:274] - INFO: epoch 001:  10762 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.8, ups=0.88, wpb=111.3, bsz=40, num_updates=10750, lr=2.62746e-05, gnorm=0.96, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49823
2022-10-16 09:27:45 - progress_bar.py[line:274] - INFO: epoch 001:  10772 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.1, ups=0.89, wpb=108.6, bsz=40, num_updates=10760, lr=2.62991e-05, gnorm=1.078, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49834
2022-10-16 09:27:56 - progress_bar.py[line:274] - INFO: epoch 001:  10782 / 102288 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=10770, lr=2.63235e-05, gnorm=1.043, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49845
2022-10-16 09:28:07 - progress_bar.py[line:274] - INFO: epoch 001:  10792 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=101.4, ups=0.91, wpb=111.2, bsz=40, num_updates=10780, lr=2.63479e-05, gnorm=1.002, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49856
2022-10-16 09:28:18 - progress_bar.py[line:274] - INFO: epoch 001:  10802 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=10790, lr=2.63724e-05, gnorm=1.024, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49867
2022-10-16 09:28:29 - progress_bar.py[line:274] - INFO: epoch 001:  10812 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.2, ups=0.91, wpb=110.6, bsz=40, num_updates=10800, lr=2.63968e-05, gnorm=1.016, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49878
2022-10-16 09:28:41 - progress_bar.py[line:274] - INFO: epoch 001:  10822 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.7, ups=0.87, wpb=109.4, bsz=40, num_updates=10810, lr=2.64213e-05, gnorm=1.031, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49890
2022-10-16 09:28:52 - progress_bar.py[line:274] - INFO: epoch 001:  10832 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.1, ups=0.88, wpb=110.4, bsz=40, num_updates=10820, lr=2.64457e-05, gnorm=1.183, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49901
2022-10-16 09:29:03 - progress_bar.py[line:274] - INFO: epoch 001:  10842 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=10830, lr=2.64702e-05, gnorm=1.241, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49912
2022-10-16 09:29:15 - progress_bar.py[line:274] - INFO: epoch 001:  10852 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=10840, lr=2.64946e-05, gnorm=1.216, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49924
2022-10-16 09:29:26 - progress_bar.py[line:274] - INFO: epoch 001:  10862 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.9, ups=0.9, wpb=110.9, bsz=40, num_updates=10850, lr=2.6519e-05, gnorm=1.153, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49935
2022-10-16 09:29:37 - progress_bar.py[line:274] - INFO: epoch 001:  10872 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.9, ups=0.91, wpb=109.3, bsz=40, num_updates=10860, lr=2.65435e-05, gnorm=1.136, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49946
2022-10-16 09:29:48 - progress_bar.py[line:274] - INFO: epoch 001:  10882 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.3, ups=0.91, wpb=110.4, bsz=40, num_updates=10870, lr=2.65679e-05, gnorm=1.136, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49957
2022-10-16 09:29:59 - progress_bar.py[line:274] - INFO: epoch 001:  10892 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.9, ups=0.9, wpb=110.9, bsz=40, num_updates=10880, lr=2.65924e-05, gnorm=1.038, clip=70, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49968
2022-10-16 09:30:10 - progress_bar.py[line:274] - INFO: epoch 001:  10902 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.1, ups=0.91, wpb=111.3, bsz=40, num_updates=10890, lr=2.66168e-05, gnorm=1.211, clip=70, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49979
2022-10-16 09:30:21 - progress_bar.py[line:274] - INFO: epoch 001:  10912 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=10900, lr=2.66412e-05, gnorm=1.084, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49990
2022-10-16 09:30:33 - progress_bar.py[line:274] - INFO: epoch 001:  10922 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=10910, lr=2.66657e-05, gnorm=1.207, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50002
2022-10-16 09:30:44 - progress_bar.py[line:274] - INFO: epoch 001:  10932 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=10920, lr=2.66901e-05, gnorm=0.934, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50013
2022-10-16 09:30:55 - progress_bar.py[line:274] - INFO: epoch 001:  10942 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=10930, lr=2.67146e-05, gnorm=1.168, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50024
2022-10-16 09:31:06 - progress_bar.py[line:274] - INFO: epoch 001:  10952 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.88, wpb=111.5, bsz=40, num_updates=10940, lr=2.6739e-05, gnorm=1.159, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50035
2022-10-16 09:31:17 - progress_bar.py[line:274] - INFO: epoch 001:  10962 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=102.5, ups=0.93, wpb=110.3, bsz=40, num_updates=10950, lr=2.67635e-05, gnorm=1.193, clip=70, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50046
2022-10-16 09:31:28 - progress_bar.py[line:274] - INFO: epoch 001:  10972 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.1, ups=0.89, wpb=109, bsz=40, num_updates=10960, lr=2.67879e-05, gnorm=0.994, clip=40, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=50057
2022-10-16 09:31:29 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-16 09:31:41 - progress_bar.py[line:274] - INFO: epoch 001:  10983 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=88, ups=0.81, wpb=109.2, bsz=40, num_updates=10970, lr=2.68123e-05, gnorm=1.059, clip=60, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=50070
2022-10-16 09:31:52 - progress_bar.py[line:274] - INFO: epoch 001:  10993 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=10980, lr=2.68368e-05, gnorm=1.151, clip=80, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=50081
2022-10-16 09:32:03 - progress_bar.py[line:274] - INFO: epoch 001:  11003 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.4, ups=0.88, wpb=109.5, bsz=40, num_updates=10990, lr=2.68612e-05, gnorm=1.18, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50092
2022-10-16 09:32:15 - progress_bar.py[line:274] - INFO: epoch 001:  11013 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.6, ups=0.87, wpb=111.2, bsz=40, num_updates=11000, lr=2.68857e-05, gnorm=1.157, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50104
2022-10-16 09:32:15 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 09:32:16 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 09:32:16 - train.py[line:551] - INFO: load:1.07 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 09:32:33 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.88 GiB already allocated; 2.37 GiB free; 34.73 GiB reserved in total by PyTorch)
2022-10-16 09:32:33 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 18        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9094 MB |   14325 MB |    7255 TB |    7255 TB |
|       from large pool |    8950 MB |   14180 MB |    7253 TB |    7253 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9094 MB |   14325 MB |    7255 TB |    7255 TB |
|       from large pool |    8950 MB |   14180 MB |    7253 TB |    7253 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   35566 MB |   37926 MB |  202062 MB |  166496 MB |
|       from large pool |   35420 MB |   37774 MB |  201740 MB |  166320 MB |
|       from small pool |     146 MB |     152 MB |     322 MB |     176 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   26471 MB |   26471 MB |    7195 TB |    7195 TB |
|       from large pool |   26469 MB |   26469 MB |    7192 TB |    7192 TB |
|       from small pool |       1 MB |       2 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  337209 K  |  337205 K  |
|       from large pool |     563    |     575    |  108388 K  |  108388 K  |
|       from small pool |    3106    |    3116    |  228820 K  |  228817 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  337209 K  |  337205 K  |
|       from large pool |     563    |     575    |  108388 K  |  108388 K  |
|       from small pool |    3106    |    3116    |  228820 K  |  228817 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     150    |     156    |     509    |     359    |
|       from large pool |      77    |      80    |     348    |     271    |
|       from small pool |      73    |      76    |     161    |      88    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     110    |     120    |  238460 K  |  238460 K  |
|       from large pool |      67    |      69    |   38932 K  |   38932 K  |
|       from small pool |      43    |      56    |  199528 K  |  199528 K  |
|===========================================================================|

2022-10-16 09:32:33 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-16 09:32:33 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-16 09:34:50 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 09:34:50 - train.py[line:551] - INFO: load:1.10 valid_run:153.41 task_valid:148.53 collect_output:2.70
2022-10-16 09:37:18 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 09:37:18 - train.py[line:551] - INFO: load:1.12 valid_run:301.90 task_valid:292.30 collect_output:6.30
2022-10-16 09:39:51 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 09:39:51 - train.py[line:551] - INFO: load:1.15 valid_run:454.67 task_valid:435.86 collect_output:14.45
2022-10-16 09:42:21 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 09:42:21 - train.py[line:551] - INFO: load:1.17 valid_run:604.14 task_valid:581.64 collect_output:17.04
2022-10-16 09:44:53 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 09:44:53 - train.py[line:551] - INFO: load:1.20 valid_run:756.78 task_valid:729.78 collect_output:20.28
2022-10-16 09:47:25 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 09:47:25 - train.py[line:551] - INFO: load:1.23 valid_run:908.53 task_valid:875.87 collect_output:24.73
2022-10-16 09:49:58 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 09:49:58 - train.py[line:551] - INFO: load:1.25 valid_run:1061.19 task_valid:1022.01 collect_output:30.22
2022-10-16 09:52:29 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 09:52:29 - train.py[line:551] - INFO: load:1.28 valid_run:1211.95 task_valid:1163.17 collect_output:38.82
2022-10-16 09:54:58 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 09:54:58 - train.py[line:551] - INFO: load:1.30 valid_run:1361.25 task_valid:1308.08 collect_output:42.22
2022-10-16 09:57:26 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 09:57:26 - train.py[line:551] - INFO: load:1.33 valid_run:1509.46 task_valid:1451.26 collect_output:46.26
2022-10-16 09:59:56 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 09:59:56 - train.py[line:551] - INFO: load:1.35 valid_run:1658.75 task_valid:1596.16 collect_output:49.65
2022-10-16 10:02:26 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 10:02:26 - train.py[line:551] - INFO: load:1.38 valid_run:1808.62 task_valid:1741.19 collect_output:53.47
2022-10-16 10:04:55 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 10:04:55 - train.py[line:551] - INFO: load:1.40 valid_run:1958.06 task_valid:1883.07 collect_output:60.03
2022-10-16 10:07:25 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 10:07:25 - train.py[line:551] - INFO: load:1.43 valid_run:2108.17 task_valid:2028.52 collect_output:63.70
2022-10-16 10:09:55 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 10:09:55 - train.py[line:551] - INFO: load:1.46 valid_run:2257.93 task_valid:2174.95 collect_output:66.02
2022-10-16 10:12:25 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 10:12:25 - train.py[line:551] - INFO: load:1.48 valid_run:2407.76 task_valid:2319.07 collect_output:70.73
2022-10-16 10:14:56 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 10:14:56 - train.py[line:551] - INFO: load:1.51 valid_run:2559.13 task_valid:2464.59 collect_output:75.57
2022-10-16 10:17:27 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 10:17:27 - train.py[line:551] - INFO: load:1.54 valid_run:2709.46 task_valid:2611.60 collect_output:77.83
2022-10-16 10:19:55 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 10:19:55 - train.py[line:551] - INFO: load:1.56 valid_run:2857.28 task_valid:2753.12 collect_output:83.13
2022-10-16 10:22:25 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 10:22:25 - train.py[line:551] - INFO: load:1.59 valid_run:3007.44 task_valid:2898.18 collect_output:87.24
2022-10-16 10:24:57 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 10:24:57 - train.py[line:551] - INFO: load:1.61 valid_run:3159.26 task_valid:3043.04 collect_output:93.16
2022-10-16 10:27:26 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 10:27:26 - train.py[line:551] - INFO: load:1.64 valid_run:3308.58 task_valid:3187.60 collect_output:96.91
2022-10-16 10:29:57 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 10:29:57 - train.py[line:551] - INFO: load:1.66 valid_run:3459.47 task_valid:3333.72 collect_output:100.69
2022-10-16 10:32:29 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 10:32:29 - train.py[line:551] - INFO: load:1.69 valid_run:3611.10 task_valid:3480.60 collect_output:104.43

====================================================================================================
SGG eval:     R @ 50: 0.5454;     R @ 100: 0.5812;     R @ 500: 0.6103;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3830;    mR @ 100: 0.4266;    mR @ 500: 0.4655;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6098) (covered in:0.8750) (covering:0.2857) (eating:0.7647) (flying in:0.6818) (growing on:0.3750) (hanging from:0.2516) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8840) (says:0.0000) (sitting on:0.7052) (standing on:0.1283) (using:0.6000) (walking in:0.0000) (walking on:0.8649) (watching:0.3403) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5454;     R @ 100: 0.5812;     R @ 500: 0.6103;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3830;    mR @ 100: 0.4266;    mR @ 500: 0.4655;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6098) (covered in:0.8750) (covering:0.2857) (eating:0.7647) (flying in:0.6818) (growing on:0.3750) (hanging from:0.2516) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8840) (says:0.0000) (sitting on:0.7052) (standing on:0.1283) (using:0.6000) (walking in:0.0000) (walking on:0.8649) (watching:0.3403) 
--------------------------------------------------------
====================================================================================================

2022-10-16 10:35:01 - train.py[line:487] - INFO: 0.581165367965368
2022-10-16 10:35:01 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 10:35:01 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.353 | loss_v1 0 | loss_v2 0 | nll_loss 0.201 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.581165 | ppl 1.15 | vqa_score 0.482 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 11000 | best_R@100 0.581165
2022-10-16 10:35:01 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 11000 updates
2022-10-16 10:35:01 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_11000.pt
2022-10-16 10:35:07 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_11000.pt
2022-10-16 10:35:13 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 0.581165367965368) (writing took 11.751741806045175 seconds)
2022-10-16 10:35:24 - progress_bar.py[line:274] - INFO: epoch 001:  11023 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=0.3, ups=0, wpb=110.1, bsz=40, num_updates=11010, lr=2.69101e-05, gnorm=1.123, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=53893
2022-10-16 10:35:35 - progress_bar.py[line:274] - INFO: epoch 001:  11033 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.2, ups=0.89, wpb=110.7, bsz=40, num_updates=11020, lr=2.69345e-05, gnorm=0.964, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=53904
2022-10-16 10:35:46 - progress_bar.py[line:274] - INFO: epoch 001:  11043 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.9, ups=0.91, wpb=109.2, bsz=40, num_updates=11030, lr=2.6959e-05, gnorm=1.058, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=53915
2022-10-16 10:35:57 - progress_bar.py[line:274] - INFO: epoch 001:  11053 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=11040, lr=2.69834e-05, gnorm=1.065, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=53926
2022-10-16 10:36:08 - progress_bar.py[line:274] - INFO: epoch 001:  11063 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.6, ups=0.9, wpb=111.7, bsz=40, num_updates=11050, lr=2.70079e-05, gnorm=1.06, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=53937
2022-10-16 10:36:20 - progress_bar.py[line:274] - INFO: epoch 001:  11073 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99, ups=0.89, wpb=111.2, bsz=40, num_updates=11060, lr=2.70323e-05, gnorm=1.164, clip=80, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=53949
2022-10-16 10:36:30 - progress_bar.py[line:274] - INFO: epoch 001:  11083 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=103.5, ups=0.93, wpb=111.7, bsz=40, num_updates=11070, lr=2.70568e-05, gnorm=1.031, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=53959
2022-10-16 10:36:41 - progress_bar.py[line:274] - INFO: epoch 001:  11093 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.6, ups=0.93, wpb=109.8, bsz=40, num_updates=11080, lr=2.70812e-05, gnorm=1.145, clip=80, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=53970
2022-10-16 10:36:53 - progress_bar.py[line:274] - INFO: epoch 001:  11103 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.7, ups=0.89, wpb=108.7, bsz=40, num_updates=11090, lr=2.71056e-05, gnorm=1.278, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=53982
2022-10-16 10:37:04 - progress_bar.py[line:274] - INFO: epoch 001:  11113 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=11100, lr=2.71301e-05, gnorm=1.246, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=53993
2022-10-16 10:37:15 - progress_bar.py[line:274] - INFO: epoch 001:  11123 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.5, ups=0.91, wpb=110.4, bsz=40, num_updates=11110, lr=2.71545e-05, gnorm=1.135, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54004
2022-10-16 10:37:26 - progress_bar.py[line:274] - INFO: epoch 001:  11133 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=11120, lr=2.7179e-05, gnorm=0.998, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54015
2022-10-16 10:37:37 - progress_bar.py[line:274] - INFO: epoch 001:  11143 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97, ups=0.89, wpb=108.7, bsz=40, num_updates=11130, lr=2.72034e-05, gnorm=1.183, clip=70, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54026
2022-10-16 10:37:52 - progress_bar.py[line:274] - INFO: epoch 001:  11153 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=11140, lr=2.72278e-05, gnorm=1.058, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54038
2022-10-16 10:38:03 - progress_bar.py[line:274] - INFO: epoch 001:  11163 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.6, ups=0.91, wpb=109.8, bsz=40, num_updates=11150, lr=2.72523e-05, gnorm=1.018, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54052
2022-10-16 10:38:15 - progress_bar.py[line:274] - INFO: epoch 001:  11173 / 102288 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.6, ups=0.89, wpb=109.2, bsz=40, num_updates=11160, lr=2.72767e-05, gnorm=1.22, clip=70, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54064
2022-10-16 10:38:27 - progress_bar.py[line:274] - INFO: epoch 001:  11183 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=11170, lr=2.73012e-05, gnorm=0.991, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54075
2022-10-16 10:38:39 - progress_bar.py[line:274] - INFO: epoch 001:  11193 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.9, ups=0.88, wpb=110.6, bsz=40, num_updates=11180, lr=2.73256e-05, gnorm=0.953, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54088
2022-10-16 10:38:50 - progress_bar.py[line:274] - INFO: epoch 001:  11203 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.2, ups=0.89, wpb=111.2, bsz=40, num_updates=11190, lr=2.73501e-05, gnorm=1.207, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54099
2022-10-16 10:39:02 - progress_bar.py[line:274] - INFO: epoch 001:  11213 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.9, ups=0.86, wpb=110.7, bsz=40, num_updates=11200, lr=2.73745e-05, gnorm=1.09, clip=70, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=54111
2022-10-16 10:39:13 - progress_bar.py[line:274] - INFO: epoch 001:  11223 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=11210, lr=2.73989e-05, gnorm=1.179, clip=80, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54122
2022-10-16 10:39:24 - progress_bar.py[line:274] - INFO: epoch 001:  11233 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.1, ups=0.87, wpb=110.6, bsz=40, num_updates=11220, lr=2.74234e-05, gnorm=1.185, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54133
2022-10-16 10:39:36 - progress_bar.py[line:274] - INFO: epoch 001:  11243 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.3, ups=0.89, wpb=109.6, bsz=40, num_updates=11230, lr=2.74478e-05, gnorm=1.08, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54145
2022-10-16 10:39:47 - progress_bar.py[line:274] - INFO: epoch 001:  11253 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.9, ups=0.88, wpb=110.4, bsz=40, num_updates=11240, lr=2.74723e-05, gnorm=1.065, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54156
2022-10-16 10:39:58 - progress_bar.py[line:274] - INFO: epoch 001:  11263 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.6, ups=0.91, wpb=108.9, bsz=40, num_updates=11250, lr=2.74967e-05, gnorm=1.171, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54167
2022-10-16 10:40:09 - progress_bar.py[line:274] - INFO: epoch 001:  11273 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.4, ups=0.91, wpb=108.6, bsz=40, num_updates=11260, lr=2.75211e-05, gnorm=0.995, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54178
2022-10-16 10:40:20 - progress_bar.py[line:274] - INFO: epoch 001:  11283 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98, ups=0.88, wpb=111.4, bsz=40, num_updates=11270, lr=2.75456e-05, gnorm=1.186, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54189
2022-10-16 10:40:32 - progress_bar.py[line:274] - INFO: epoch 001:  11293 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=94.6, ups=0.87, wpb=108.7, bsz=40, num_updates=11280, lr=2.757e-05, gnorm=1.16, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54201
2022-10-16 10:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  11303 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.2, ups=0.9, wpb=109.6, bsz=40, num_updates=11290, lr=2.75945e-05, gnorm=1.121, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54212
2022-10-16 10:40:54 - progress_bar.py[line:274] - INFO: epoch 001:  11313 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=11300, lr=2.76189e-05, gnorm=0.988, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54223
2022-10-16 10:41:05 - progress_bar.py[line:274] - INFO: epoch 001:  11323 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.3, ups=0.9, wpb=108.8, bsz=40, num_updates=11310, lr=2.76433e-05, gnorm=1.109, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54234
2022-10-16 10:41:17 - progress_bar.py[line:274] - INFO: epoch 001:  11333 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.2, ups=0.91, wpb=110.4, bsz=40, num_updates=11320, lr=2.76678e-05, gnorm=1.051, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54245
2022-10-16 10:41:28 - progress_bar.py[line:274] - INFO: epoch 001:  11343 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=11330, lr=2.76922e-05, gnorm=1.161, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54257
2022-10-16 10:41:39 - progress_bar.py[line:274] - INFO: epoch 001:  11353 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=104.1, ups=0.94, wpb=110.4, bsz=40, num_updates=11340, lr=2.77167e-05, gnorm=1.197, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54268
2022-10-16 10:41:50 - progress_bar.py[line:274] - INFO: epoch 001:  11363 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.4, ups=0.91, wpb=108.4, bsz=40, num_updates=11350, lr=2.77411e-05, gnorm=1.015, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54279
2022-10-16 10:42:01 - progress_bar.py[line:274] - INFO: epoch 001:  11373 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.6, ups=0.89, wpb=111.5, bsz=40, num_updates=11360, lr=2.77656e-05, gnorm=1.136, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54290
2022-10-16 10:42:12 - progress_bar.py[line:274] - INFO: epoch 001:  11383 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=11370, lr=2.779e-05, gnorm=1.039, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54301
2022-10-16 10:42:23 - progress_bar.py[line:274] - INFO: epoch 001:  11393 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=103.9, ups=0.95, wpb=109.6, bsz=40, num_updates=11380, lr=2.78144e-05, gnorm=1.139, clip=60, loss_scale=1024, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=54312
2022-10-16 10:42:34 - progress_bar.py[line:274] - INFO: epoch 001:  11403 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95, ups=0.87, wpb=108.8, bsz=40, num_updates=11390, lr=2.78389e-05, gnorm=1.113, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54323
2022-10-16 10:42:46 - progress_bar.py[line:274] - INFO: epoch 001:  11413 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=11400, lr=2.78633e-05, gnorm=0.965, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=54335
2022-10-16 10:42:57 - progress_bar.py[line:274] - INFO: epoch 001:  11423 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.9, ups=0.91, wpb=110.5, bsz=40, num_updates=11410, lr=2.78878e-05, gnorm=1.077, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54346
2022-10-16 10:43:08 - progress_bar.py[line:274] - INFO: epoch 001:  11433 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=11420, lr=2.79122e-05, gnorm=1.024, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54357
2022-10-16 10:43:19 - progress_bar.py[line:274] - INFO: epoch 001:  11443 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.5, ups=0.89, wpb=109.6, bsz=40, num_updates=11430, lr=2.79366e-05, gnorm=1.209, clip=90, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54368
2022-10-16 10:43:30 - progress_bar.py[line:274] - INFO: epoch 001:  11453 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=11440, lr=2.79611e-05, gnorm=1.226, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54379
2022-10-16 10:43:42 - progress_bar.py[line:274] - INFO: epoch 001:  11463 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=11450, lr=2.79855e-05, gnorm=1.068, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54391
2022-10-16 10:43:53 - progress_bar.py[line:274] - INFO: epoch 001:  11473 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.9, ups=0.88, wpb=111.6, bsz=40, num_updates=11460, lr=2.801e-05, gnorm=1.046, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54402
2022-10-16 10:44:05 - progress_bar.py[line:274] - INFO: epoch 001:  11483 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=11470, lr=2.80344e-05, gnorm=1.212, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54413
2022-10-16 10:44:12 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-16 10:44:17 - progress_bar.py[line:274] - INFO: epoch 001:  11494 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.4, ups=0.84, wpb=109.4, bsz=40, num_updates=11480, lr=2.80589e-05, gnorm=1.065, clip=60, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=54426
2022-10-16 10:44:28 - progress_bar.py[line:274] - INFO: epoch 001:  11504 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.4, ups=0.91, wpb=110.6, bsz=40, num_updates=11490, lr=2.80833e-05, gnorm=1.118, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54437
2022-10-16 10:44:39 - progress_bar.py[line:274] - INFO: epoch 001:  11514 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.6, ups=0.88, wpb=111.3, bsz=40, num_updates=11500, lr=2.81077e-05, gnorm=1.026, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54448
2022-10-16 10:44:50 - progress_bar.py[line:274] - INFO: epoch 001:  11524 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=11510, lr=2.81322e-05, gnorm=0.902, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54459
2022-10-16 10:45:02 - progress_bar.py[line:274] - INFO: epoch 001:  11534 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=11520, lr=2.81566e-05, gnorm=1.028, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54471
2022-10-16 10:45:13 - progress_bar.py[line:274] - INFO: epoch 001:  11544 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.2, ups=0.89, wpb=111.2, bsz=40, num_updates=11530, lr=2.81811e-05, gnorm=1.034, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54482
2022-10-16 10:45:24 - progress_bar.py[line:274] - INFO: epoch 001:  11554 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=103.8, ups=0.94, wpb=110.8, bsz=40, num_updates=11540, lr=2.82055e-05, gnorm=1.017, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54493
2022-10-16 10:45:35 - progress_bar.py[line:274] - INFO: epoch 001:  11564 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=11550, lr=2.82299e-05, gnorm=1.121, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54504
2022-10-16 10:45:46 - progress_bar.py[line:274] - INFO: epoch 001:  11574 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=11560, lr=2.82544e-05, gnorm=1.156, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54515
2022-10-16 10:45:57 - progress_bar.py[line:274] - INFO: epoch 001:  11584 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.4, ups=0.9, wpb=111.6, bsz=40, num_updates=11570, lr=2.82788e-05, gnorm=1.113, clip=80, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54526
2022-10-16 10:46:08 - progress_bar.py[line:274] - INFO: epoch 001:  11594 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=11580, lr=2.83033e-05, gnorm=1.08, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54537
2022-10-16 10:46:19 - progress_bar.py[line:274] - INFO: epoch 001:  11604 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=11590, lr=2.83277e-05, gnorm=1.096, clip=60, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=54548
2022-10-16 10:46:31 - progress_bar.py[line:274] - INFO: epoch 001:  11614 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=11600, lr=2.83522e-05, gnorm=1.13, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54560
2022-10-16 10:46:42 - progress_bar.py[line:274] - INFO: epoch 001:  11624 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=95.1, ups=0.88, wpb=108.1, bsz=40, num_updates=11610, lr=2.83766e-05, gnorm=1.1, clip=70, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=54571
2022-10-16 10:46:54 - progress_bar.py[line:274] - INFO: epoch 001:  11634 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.1, ups=0.89, wpb=110.8, bsz=40, num_updates=11620, lr=2.8401e-05, gnorm=1.077, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54583
2022-10-16 10:46:58 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 10:47:06 - progress_bar.py[line:274] - INFO: epoch 001:  11645 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=92.4, ups=0.84, wpb=110, bsz=40, num_updates=11630, lr=2.84255e-05, gnorm=1.266, clip=70, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=54594
2022-10-16 10:47:17 - progress_bar.py[line:274] - INFO: epoch 001:  11655 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=11640, lr=2.84499e-05, gnorm=1.123, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54606
2022-10-16 10:47:28 - progress_bar.py[line:274] - INFO: epoch 001:  11665 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=11650, lr=2.84744e-05, gnorm=1.094, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54617
2022-10-16 10:47:39 - progress_bar.py[line:274] - INFO: epoch 001:  11675 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=11660, lr=2.84988e-05, gnorm=1, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54628
2022-10-16 10:47:50 - progress_bar.py[line:274] - INFO: epoch 001:  11685 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.6, ups=0.91, wpb=109.9, bsz=40, num_updates=11670, lr=2.85232e-05, gnorm=0.937, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54639
2022-10-16 10:48:02 - progress_bar.py[line:274] - INFO: epoch 001:  11695 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.4, ups=0.87, wpb=110.5, bsz=40, num_updates=11680, lr=2.85477e-05, gnorm=1.198, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54651
2022-10-16 10:48:13 - progress_bar.py[line:274] - INFO: epoch 001:  11705 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.9, ups=0.88, wpb=108.8, bsz=40, num_updates=11690, lr=2.85721e-05, gnorm=1.07, clip=80, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54662
2022-10-16 10:48:24 - progress_bar.py[line:274] - INFO: epoch 001:  11715 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=11700, lr=2.85966e-05, gnorm=1.098, clip=80, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54673
2022-10-16 10:48:36 - progress_bar.py[line:274] - INFO: epoch 001:  11725 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.4, ups=0.9, wpb=109, bsz=40, num_updates=11710, lr=2.8621e-05, gnorm=1.305, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54685
2022-10-16 10:48:47 - progress_bar.py[line:274] - INFO: epoch 001:  11735 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=11720, lr=2.86455e-05, gnorm=1.037, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54696
2022-10-16 10:48:58 - progress_bar.py[line:274] - INFO: epoch 001:  11745 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=11730, lr=2.86699e-05, gnorm=1.152, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54707
2022-10-16 10:49:09 - progress_bar.py[line:274] - INFO: epoch 001:  11755 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=11740, lr=2.86943e-05, gnorm=1.042, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54718
2022-10-16 10:49:20 - progress_bar.py[line:274] - INFO: epoch 001:  11765 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.5, ups=0.92, wpb=110.9, bsz=40, num_updates=11750, lr=2.87188e-05, gnorm=1.179, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54729
2022-10-16 10:49:32 - progress_bar.py[line:274] - INFO: epoch 001:  11775 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.1, ups=0.87, wpb=111.8, bsz=40, num_updates=11760, lr=2.87432e-05, gnorm=1.107, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54741
2022-10-16 10:49:43 - progress_bar.py[line:274] - INFO: epoch 001:  11785 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=103.6, ups=0.92, wpb=112.3, bsz=40, num_updates=11770, lr=2.87677e-05, gnorm=1.027, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54752
2022-10-16 10:49:54 - progress_bar.py[line:274] - INFO: epoch 001:  11795 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.7, ups=0.88, wpb=109.4, bsz=40, num_updates=11780, lr=2.87921e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54763
2022-10-16 10:50:05 - progress_bar.py[line:274] - INFO: epoch 001:  11805 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.6, ups=0.9, wpb=111.3, bsz=40, num_updates=11790, lr=2.88165e-05, gnorm=1.079, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54774
2022-10-16 10:50:17 - progress_bar.py[line:274] - INFO: epoch 001:  11815 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94, ups=0.86, wpb=109.5, bsz=40, num_updates=11800, lr=2.8841e-05, gnorm=0.998, clip=40, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=54786
2022-10-16 10:50:28 - progress_bar.py[line:274] - INFO: epoch 001:  11825 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=102.6, ups=0.93, wpb=109.9, bsz=40, num_updates=11810, lr=2.88654e-05, gnorm=1.124, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54797
2022-10-16 10:50:39 - progress_bar.py[line:274] - INFO: epoch 001:  11835 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=11820, lr=2.88899e-05, gnorm=1.131, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54808
2022-10-16 10:50:50 - progress_bar.py[line:274] - INFO: epoch 001:  11845 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.9, ups=0.89, wpb=110.3, bsz=40, num_updates=11830, lr=2.89143e-05, gnorm=1.077, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54819
2022-10-16 10:51:01 - progress_bar.py[line:274] - INFO: epoch 001:  11855 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=103, ups=0.93, wpb=111, bsz=40, num_updates=11840, lr=2.89387e-05, gnorm=1.335, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54830
2022-10-16 10:51:12 - progress_bar.py[line:274] - INFO: epoch 001:  11865 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=11850, lr=2.89632e-05, gnorm=0.999, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54841
2022-10-16 10:51:23 - progress_bar.py[line:274] - INFO: epoch 001:  11875 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.6, ups=0.89, wpb=110, bsz=40, num_updates=11860, lr=2.89876e-05, gnorm=1.027, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=54852
2022-10-16 10:51:34 - progress_bar.py[line:274] - INFO: epoch 001:  11885 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102.4, ups=0.93, wpb=110.5, bsz=40, num_updates=11870, lr=2.90121e-05, gnorm=1.189, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54863
2022-10-16 10:51:45 - progress_bar.py[line:274] - INFO: epoch 001:  11895 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.4, ups=0.93, wpb=109.2, bsz=40, num_updates=11880, lr=2.90365e-05, gnorm=1.072, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54874
2022-10-16 10:51:56 - progress_bar.py[line:274] - INFO: epoch 001:  11905 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.3, ups=0.87, wpb=110.8, bsz=40, num_updates=11890, lr=2.9061e-05, gnorm=1.084, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54885
2022-10-16 10:52:08 - progress_bar.py[line:274] - INFO: epoch 001:  11915 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.5, ups=0.9, wpb=112.2, bsz=40, num_updates=11900, lr=2.90854e-05, gnorm=1.061, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54897
2022-10-16 10:52:19 - progress_bar.py[line:274] - INFO: epoch 001:  11925 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=11910, lr=2.91098e-05, gnorm=0.995, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54908
2022-10-16 10:52:30 - progress_bar.py[line:274] - INFO: epoch 001:  11935 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.4, ups=0.9, wpb=109, bsz=40, num_updates=11920, lr=2.91343e-05, gnorm=1.093, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54919
2022-10-16 10:52:41 - progress_bar.py[line:274] - INFO: epoch 001:  11945 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=11930, lr=2.91587e-05, gnorm=1.027, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54930
2022-10-16 10:52:53 - progress_bar.py[line:274] - INFO: epoch 001:  11955 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=11940, lr=2.91832e-05, gnorm=1.137, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54942
2022-10-16 10:53:04 - progress_bar.py[line:274] - INFO: epoch 001:  11965 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.7, ups=0.87, wpb=110.2, bsz=40, num_updates=11950, lr=2.92076e-05, gnorm=1.07, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54953
2022-10-16 10:53:16 - progress_bar.py[line:274] - INFO: epoch 001:  11975 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=11960, lr=2.9232e-05, gnorm=1.03, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54965
2022-10-16 10:53:27 - progress_bar.py[line:274] - INFO: epoch 001:  11985 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=11970, lr=2.92565e-05, gnorm=1.14, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54976
2022-10-16 10:53:38 - progress_bar.py[line:274] - INFO: epoch 001:  11995 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=102.8, ups=0.93, wpb=111, bsz=40, num_updates=11980, lr=2.92809e-05, gnorm=1.146, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54987
2022-10-16 10:53:49 - progress_bar.py[line:274] - INFO: epoch 001:  12005 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.6, ups=0.91, wpb=109.1, bsz=40, num_updates=11990, lr=2.93054e-05, gnorm=1.045, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54998
2022-10-16 10:54:00 - progress_bar.py[line:274] - INFO: epoch 001:  12015 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=12000, lr=2.93298e-05, gnorm=0.954, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55009
2022-10-16 10:54:00 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 10:54:02 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 10:54:02 - train.py[line:551] - INFO: load:1.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 10:54:17 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.88 GiB already allocated; 6.18 GiB free; 30.92 GiB reserved in total by PyTorch)
2022-10-16 10:54:17 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 19        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9089 MB |   14320 MB |    7963 TB |    7963 TB |
|       from large pool |    8945 MB |   14175 MB |    7961 TB |    7961 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9089 MB |   14320 MB |    7963 TB |    7963 TB |
|       from large pool |    8945 MB |   14175 MB |    7961 TB |    7961 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31664 MB |   31686 MB |  213314 MB |  181650 MB |
|       from large pool |   31518 MB |   31540 MB |  212968 MB |  181450 MB |
|       from small pool |     146 MB |     146 MB |     346 MB |     200 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22574 MB |   27124 MB |    7882 TB |    7882 TB |
|       from large pool |   22572 MB |   27122 MB |    7879 TB |    7879 TB |
|       from small pool |       1 MB |       1 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  370392 K  |  370388 K  |
|       from large pool |     563    |     575    |  118957 K  |  118957 K  |
|       from small pool |    3106    |    3116    |  251434 K  |  251431 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  370392 K  |  370388 K  |
|       from large pool |     563    |     575    |  118957 K  |  118957 K  |
|       from small pool |    3106    |    3116    |  251434 K  |  251431 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     149    |     150    |     551    |     402    |
|       from large pool |      76    |      77    |     378    |     302    |
|       from small pool |      73    |      73    |     173    |     100    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     100    |     109    |  264205 K  |  264205 K  |
|       from large pool |      63    |      64    |   44749 K  |   44749 K  |
|       from small pool |      37    |      49    |  219455 K  |  219455 K  |
|===========================================================================|

2022-10-16 10:54:17 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-16 10:54:17 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-16 10:56:35 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 10:56:35 - train.py[line:551] - INFO: load:1.09 valid_run:153.01 task_valid:148.79 collect_output:1.89
2022-10-16 10:59:03 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 10:59:03 - train.py[line:551] - INFO: load:1.11 valid_run:301.51 task_valid:292.47 collect_output:5.51
2022-10-16 11:01:35 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 11:01:35 - train.py[line:551] - INFO: load:1.14 valid_run:453.52 task_valid:436.15 collect_output:12.75
2022-10-16 11:04:04 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 11:04:04 - train.py[line:551] - INFO: load:1.17 valid_run:602.07 task_valid:581.02 collect_output:15.45
2022-10-16 11:06:36 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 11:06:36 - train.py[line:551] - INFO: load:1.20 valid_run:753.92 task_valid:728.42 collect_output:18.88
2022-10-16 11:09:07 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 11:09:07 - train.py[line:551] - INFO: load:1.22 valid_run:905.27 task_valid:873.92 collect_output:23.69
2022-10-16 11:11:40 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 11:11:40 - train.py[line:551] - INFO: load:1.25 valid_run:1057.84 task_valid:1020.00 collect_output:29.17
2022-10-16 11:14:10 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 11:14:10 - train.py[line:551] - INFO: load:1.27 valid_run:1208.29 task_valid:1161.00 collect_output:37.61
2022-10-16 11:16:40 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 11:16:40 - train.py[line:551] - INFO: load:1.30 valid_run:1357.46 task_valid:1305.72 collect_output:41.02
2022-10-16 11:19:08 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 11:19:08 - train.py[line:551] - INFO: load:1.33 valid_run:1505.55 task_valid:1448.85 collect_output:44.97
2022-10-16 11:21:38 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 11:21:38 - train.py[line:551] - INFO: load:1.35 valid_run:1655.23 task_valid:1593.90 collect_output:48.58
2022-10-16 11:24:07 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 11:24:07 - train.py[line:551] - INFO: load:1.38 valid_run:1804.79 task_valid:1738.83 collect_output:52.19
2022-10-16 11:26:37 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 11:26:37 - train.py[line:551] - INFO: load:1.41 valid_run:1954.10 task_valid:1880.51 collect_output:58.82
2022-10-16 11:29:07 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 11:29:07 - train.py[line:551] - INFO: load:1.43 valid_run:2104.19 task_valid:2025.90 collect_output:62.55
2022-10-16 11:31:36 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 11:31:36 - train.py[line:551] - INFO: load:1.46 valid_run:2253.92 task_valid:2172.12 collect_output:65.04
2022-10-16 11:34:06 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 11:34:06 - train.py[line:551] - INFO: load:1.48 valid_run:2403.66 task_valid:2316.38 collect_output:69.51
2022-10-16 11:36:38 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 11:36:38 - train.py[line:551] - INFO: load:1.51 valid_run:2555.03 task_valid:2461.82 collect_output:74.45
2022-10-16 11:39:08 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 11:39:08 - train.py[line:551] - INFO: load:1.53 valid_run:2705.52 task_valid:2608.82 collect_output:76.91
2022-10-16 11:41:36 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 11:41:36 - train.py[line:551] - INFO: load:1.56 valid_run:2853.62 task_valid:2750.36 collect_output:82.44
2022-10-16 11:44:07 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 11:44:07 - train.py[line:551] - INFO: load:1.59 valid_run:3003.91 task_valid:2895.67 collect_output:86.39
2022-10-16 11:46:39 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 11:46:39 - train.py[line:551] - INFO: load:1.62 valid_run:3155.87 task_valid:3040.54 collect_output:92.37
2022-10-16 11:49:08 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 11:49:08 - train.py[line:551] - INFO: load:1.64 valid_run:3305.53 task_valid:3185.56 collect_output:95.90
2022-10-16 11:51:41 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 11:51:41 - train.py[line:551] - INFO: load:1.67 valid_run:3457.54 task_valid:3332.79 collect_output:99.54
2022-10-16 11:54:13 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 11:54:13 - train.py[line:551] - INFO: load:1.70 valid_run:3609.57 task_valid:3480.13 collect_output:103.11

====================================================================================================
SGG eval:     R @ 50: 0.5425;     R @ 100: 0.5815;     R @ 500: 0.6054;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3849;    mR @ 100: 0.4185;    mR @ 500: 0.4542;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5854) (covered in:0.8750) (covering:0.3429) (eating:0.7059) (flying in:0.5000) (growing on:0.3750) (hanging from:0.3484) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8693) (says:0.0000) (sitting on:0.7154) (standing on:0.1283) (using:0.6000) (walking in:0.0000) (walking on:0.8378) (watching:0.3194) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5425;     R @ 100: 0.5815;     R @ 500: 0.6054;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3849;    mR @ 100: 0.4185;    mR @ 500: 0.4542;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5854) (covered in:0.8750) (covering:0.3429) (eating:0.7059) (flying in:0.5000) (growing on:0.3750) (hanging from:0.3484) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8693) (says:0.0000) (sitting on:0.7154) (standing on:0.1283) (using:0.6000) (walking in:0.0000) (walking on:0.8378) (watching:0.3194) 
--------------------------------------------------------
====================================================================================================

2022-10-16 11:56:44 - train.py[line:487] - INFO: 0.5814605042016807
2022-10-16 11:56:44 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 11:56:44 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.339 | loss_v1 0 | loss_v2 0 | nll_loss 0.176 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.581461 | ppl 1.13 | vqa_score 0.4944 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 12000 | best_R@100 0.581461
2022-10-16 11:56:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2022-10-16 11:56:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_12000.pt
2022-10-16 11:56:50 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_12000.pt
2022-10-16 11:56:56 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.5814605042016807) (writing took 11.123343741055578 seconds)
2022-10-16 11:57:07 - progress_bar.py[line:274] - INFO: epoch 001:  12025 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=0.3, ups=0, wpb=111.1, bsz=40, num_updates=12010, lr=2.93543e-05, gnorm=1.101, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=58796
2022-10-16 11:57:18 - progress_bar.py[line:274] - INFO: epoch 001:  12035 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.4, ups=0.9, wpb=111.4, bsz=40, num_updates=12020, lr=2.93787e-05, gnorm=0.968, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=58807
2022-10-16 11:57:29 - progress_bar.py[line:274] - INFO: epoch 001:  12045 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.6, ups=0.91, wpb=110.5, bsz=40, num_updates=12030, lr=2.94031e-05, gnorm=0.986, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58818
2022-10-16 11:57:40 - progress_bar.py[line:274] - INFO: epoch 001:  12055 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102.3, ups=0.93, wpb=110.3, bsz=40, num_updates=12040, lr=2.94276e-05, gnorm=1.042, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58829
2022-10-16 11:57:51 - progress_bar.py[line:274] - INFO: epoch 001:  12065 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=12050, lr=2.9452e-05, gnorm=1.116, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=58840
2022-10-16 11:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  12075 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=12060, lr=2.94765e-05, gnorm=0.966, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=58851
2022-10-16 11:58:13 - progress_bar.py[line:274] - INFO: epoch 001:  12085 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=12070, lr=2.95009e-05, gnorm=0.979, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=58862
2022-10-16 11:58:24 - progress_bar.py[line:274] - INFO: epoch 001:  12095 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.8, ups=0.91, wpb=110.3, bsz=40, num_updates=12080, lr=2.95253e-05, gnorm=1.019, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=58873
2022-10-16 11:58:35 - progress_bar.py[line:274] - INFO: epoch 001:  12105 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.2, ups=0.91, wpb=109.8, bsz=40, num_updates=12090, lr=2.95498e-05, gnorm=1.169, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58884
2022-10-16 11:58:46 - progress_bar.py[line:274] - INFO: epoch 001:  12115 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.1, ups=0.9, wpb=108.8, bsz=40, num_updates=12100, lr=2.95742e-05, gnorm=1.007, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=58895
2022-10-16 11:58:58 - progress_bar.py[line:274] - INFO: epoch 001:  12125 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=12110, lr=2.95987e-05, gnorm=1.011, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58907
2022-10-16 11:59:09 - progress_bar.py[line:274] - INFO: epoch 001:  12135 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.1, ups=0.89, wpb=108.9, bsz=40, num_updates=12120, lr=2.96231e-05, gnorm=1.066, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58918
2022-10-16 11:59:20 - progress_bar.py[line:274] - INFO: epoch 001:  12145 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=12130, lr=2.96476e-05, gnorm=0.882, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=58929
2022-10-16 11:59:31 - progress_bar.py[line:274] - INFO: epoch 001:  12155 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.9, wpb=109.2, bsz=40, num_updates=12140, lr=2.9672e-05, gnorm=1.031, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=58940
2022-10-16 11:59:42 - progress_bar.py[line:274] - INFO: epoch 001:  12165 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.6, ups=0.91, wpb=110.1, bsz=40, num_updates=12150, lr=2.96964e-05, gnorm=1.044, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58951
2022-10-16 11:59:53 - progress_bar.py[line:274] - INFO: epoch 001:  12175 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=94.7, ups=0.87, wpb=109.1, bsz=40, num_updates=12160, lr=2.97209e-05, gnorm=1.034, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58962
2022-10-16 12:00:05 - progress_bar.py[line:274] - INFO: epoch 001:  12185 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=12170, lr=2.97453e-05, gnorm=0.916, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58974
2022-10-16 12:00:19 - progress_bar.py[line:274] - INFO: epoch 001:  12195 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=12180, lr=2.97698e-05, gnorm=0.872, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58985
2022-10-16 12:00:30 - progress_bar.py[line:274] - INFO: epoch 001:  12205 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.2, ups=0.91, wpb=108.6, bsz=40, num_updates=12190, lr=2.97942e-05, gnorm=0.894, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58999
2022-10-16 12:00:42 - progress_bar.py[line:274] - INFO: epoch 001:  12215 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.8, ups=0.88, wpb=110.5, bsz=40, num_updates=12200, lr=2.98186e-05, gnorm=1.147, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59011
2022-10-16 12:00:53 - progress_bar.py[line:274] - INFO: epoch 001:  12225 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.9, ups=0.88, wpb=109.3, bsz=40, num_updates=12210, lr=2.98431e-05, gnorm=1.056, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=59022
2022-10-16 12:01:04 - progress_bar.py[line:274] - INFO: epoch 001:  12235 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.2, ups=0.89, wpb=111.7, bsz=40, num_updates=12220, lr=2.98675e-05, gnorm=0.976, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59033
2022-10-16 12:01:15 - progress_bar.py[line:274] - INFO: epoch 001:  12245 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=12230, lr=2.9892e-05, gnorm=1.032, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59044
2022-10-16 12:01:27 - progress_bar.py[line:274] - INFO: epoch 001:  12255 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.5, ups=0.88, wpb=110.1, bsz=40, num_updates=12240, lr=2.99164e-05, gnorm=0.991, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59056
2022-10-16 12:01:38 - progress_bar.py[line:274] - INFO: epoch 001:  12265 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.9, ups=0.89, wpb=111.2, bsz=40, num_updates=12250, lr=2.99409e-05, gnorm=0.918, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59067
2022-10-16 12:01:49 - progress_bar.py[line:274] - INFO: epoch 001:  12275 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.8, ups=0.88, wpb=109.1, bsz=40, num_updates=12260, lr=2.99653e-05, gnorm=1.053, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59078
2022-10-16 12:02:01 - progress_bar.py[line:274] - INFO: epoch 001:  12285 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=12270, lr=2.99897e-05, gnorm=1.036, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59090
2022-10-16 12:02:11 - progress_bar.py[line:274] - INFO: epoch 001:  12295 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.9, ups=0.92, wpb=109.1, bsz=40, num_updates=12280, lr=3.00142e-05, gnorm=0.935, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59100
2022-10-16 12:02:23 - progress_bar.py[line:274] - INFO: epoch 001:  12305 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.9, ups=0.88, wpb=109, bsz=40, num_updates=12290, lr=3.00386e-05, gnorm=0.965, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59112
2022-10-16 12:02:34 - progress_bar.py[line:274] - INFO: epoch 001:  12315 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=12300, lr=3.00631e-05, gnorm=1.084, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59123
2022-10-16 12:02:45 - progress_bar.py[line:274] - INFO: epoch 001:  12325 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=12310, lr=3.00875e-05, gnorm=1.073, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59134
2022-10-16 12:02:57 - progress_bar.py[line:274] - INFO: epoch 001:  12335 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.7, ups=0.88, wpb=111, bsz=40, num_updates=12320, lr=3.01119e-05, gnorm=1.057, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59146
2022-10-16 12:03:08 - progress_bar.py[line:274] - INFO: epoch 001:  12345 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.9, ups=0.89, wpb=110.3, bsz=40, num_updates=12330, lr=3.01364e-05, gnorm=0.985, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59157
2022-10-16 12:03:20 - progress_bar.py[line:274] - INFO: epoch 001:  12355 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.8, ups=0.88, wpb=109.3, bsz=40, num_updates=12340, lr=3.01608e-05, gnorm=0.948, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59169
2022-10-16 12:03:31 - progress_bar.py[line:274] - INFO: epoch 001:  12365 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=12350, lr=3.01853e-05, gnorm=1.003, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59180
2022-10-16 12:03:42 - progress_bar.py[line:274] - INFO: epoch 001:  12375 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.9, ups=0.92, wpb=110.2, bsz=40, num_updates=12360, lr=3.02097e-05, gnorm=1.086, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59191
2022-10-16 12:03:52 - progress_bar.py[line:274] - INFO: epoch 001:  12385 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=103.8, ups=0.95, wpb=109.6, bsz=40, num_updates=12370, lr=3.02341e-05, gnorm=1.014, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59201
2022-10-16 12:04:03 - progress_bar.py[line:274] - INFO: epoch 001:  12395 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=12380, lr=3.02586e-05, gnorm=1.177, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59212
2022-10-16 12:04:15 - progress_bar.py[line:274] - INFO: epoch 001:  12405 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.2, ups=0.9, wpb=109.6, bsz=40, num_updates=12390, lr=3.0283e-05, gnorm=1.064, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59224
2022-10-16 12:04:26 - progress_bar.py[line:274] - INFO: epoch 001:  12415 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=12400, lr=3.03075e-05, gnorm=1.053, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59235
2022-10-16 12:04:37 - progress_bar.py[line:274] - INFO: epoch 001:  12425 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=12410, lr=3.03319e-05, gnorm=1.013, clip=60, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=59246
2022-10-16 12:04:49 - progress_bar.py[line:274] - INFO: epoch 001:  12435 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=12420, lr=3.03564e-05, gnorm=0.943, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59258
2022-10-16 12:05:00 - progress_bar.py[line:274] - INFO: epoch 001:  12445 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=12430, lr=3.03808e-05, gnorm=1.014, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59269
2022-10-16 12:05:11 - progress_bar.py[line:274] - INFO: epoch 001:  12455 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.4, ups=0.9, wpb=111, bsz=40, num_updates=12440, lr=3.04052e-05, gnorm=0.909, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59280
2022-10-16 12:05:22 - progress_bar.py[line:274] - INFO: epoch 001:  12465 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=12450, lr=3.04297e-05, gnorm=0.896, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59291
2022-10-16 12:05:33 - progress_bar.py[line:274] - INFO: epoch 001:  12475 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=12460, lr=3.04541e-05, gnorm=1.19, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59302
2022-10-16 12:05:45 - progress_bar.py[line:274] - INFO: epoch 001:  12485 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.9, ups=0.87, wpb=110.5, bsz=40, num_updates=12470, lr=3.04786e-05, gnorm=0.994, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59314
2022-10-16 12:05:56 - progress_bar.py[line:274] - INFO: epoch 001:  12495 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.8, ups=0.87, wpb=109.9, bsz=40, num_updates=12480, lr=3.0503e-05, gnorm=0.927, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59325
2022-10-16 12:06:08 - progress_bar.py[line:274] - INFO: epoch 001:  12505 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.8, ups=0.88, wpb=110, bsz=40, num_updates=12490, lr=3.05274e-05, gnorm=0.99, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59337
2022-10-16 12:06:19 - progress_bar.py[line:274] - INFO: epoch 001:  12515 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=12500, lr=3.05519e-05, gnorm=1.028, clip=60, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=59348
2022-10-16 12:06:30 - progress_bar.py[line:274] - INFO: epoch 001:  12525 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=12510, lr=3.05763e-05, gnorm=1.031, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59359
2022-10-16 12:06:41 - progress_bar.py[line:274] - INFO: epoch 001:  12535 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=102, ups=0.92, wpb=110.5, bsz=40, num_updates=12520, lr=3.06008e-05, gnorm=1.004, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59370
2022-10-16 12:06:52 - progress_bar.py[line:274] - INFO: epoch 001:  12545 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=12530, lr=3.06252e-05, gnorm=0.986, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=59381
2022-10-16 12:07:04 - progress_bar.py[line:274] - INFO: epoch 001:  12555 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.7, ups=0.88, wpb=109.8, bsz=40, num_updates=12540, lr=3.06497e-05, gnorm=0.98, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59392
2022-10-16 12:07:15 - progress_bar.py[line:274] - INFO: epoch 001:  12565 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=12550, lr=3.06741e-05, gnorm=0.936, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=59404
2022-10-16 12:07:26 - progress_bar.py[line:274] - INFO: epoch 001:  12575 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=12560, lr=3.06985e-05, gnorm=0.93, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59415
2022-10-16 12:07:35 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 12:07:38 - progress_bar.py[line:274] - INFO: epoch 001:  12586 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=92.6, ups=0.83, wpb=111.7, bsz=40, num_updates=12570, lr=3.0723e-05, gnorm=1.032, clip=60, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=59427
2022-10-16 12:07:49 - progress_bar.py[line:274] - INFO: epoch 001:  12596 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.8, ups=0.88, wpb=110.6, bsz=40, num_updates=12580, lr=3.07474e-05, gnorm=0.953, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59438
2022-10-16 12:08:00 - progress_bar.py[line:274] - INFO: epoch 001:  12606 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.6, ups=0.9, wpb=109.3, bsz=40, num_updates=12590, lr=3.07719e-05, gnorm=0.986, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59449
2022-10-16 12:08:12 - progress_bar.py[line:274] - INFO: epoch 001:  12616 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=12600, lr=3.07963e-05, gnorm=1.016, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59461
2022-10-16 12:08:23 - progress_bar.py[line:274] - INFO: epoch 001:  12626 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=12610, lr=3.08207e-05, gnorm=1.031, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59472
2022-10-16 12:08:34 - progress_bar.py[line:274] - INFO: epoch 001:  12636 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=12620, lr=3.08452e-05, gnorm=1.083, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59483
2022-10-16 12:08:45 - progress_bar.py[line:274] - INFO: epoch 001:  12646 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.5, ups=0.93, wpb=108.4, bsz=40, num_updates=12630, lr=3.08696e-05, gnorm=1.053, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59494
2022-10-16 12:08:56 - progress_bar.py[line:274] - INFO: epoch 001:  12656 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.8, ups=0.9, wpb=109.3, bsz=40, num_updates=12640, lr=3.08941e-05, gnorm=0.967, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59505
2022-10-16 12:09:07 - progress_bar.py[line:274] - INFO: epoch 001:  12666 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.4, ups=0.91, wpb=111, bsz=40, num_updates=12650, lr=3.09185e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=59516
2022-10-16 12:09:18 - progress_bar.py[line:274] - INFO: epoch 001:  12676 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=12660, lr=3.0943e-05, gnorm=1.006, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59527
2022-10-16 12:09:30 - progress_bar.py[line:274] - INFO: epoch 001:  12686 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=12670, lr=3.09674e-05, gnorm=1.378, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59539
2022-10-16 12:09:41 - progress_bar.py[line:274] - INFO: epoch 001:  12696 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.2, ups=0.89, wpb=109.8, bsz=40, num_updates=12680, lr=3.09918e-05, gnorm=1.002, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59550
2022-10-16 12:09:52 - progress_bar.py[line:274] - INFO: epoch 001:  12706 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=12690, lr=3.10163e-05, gnorm=1.093, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59561
2022-10-16 12:10:03 - progress_bar.py[line:274] - INFO: epoch 001:  12716 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=12700, lr=3.10407e-05, gnorm=1.138, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59572
2022-10-16 12:10:15 - progress_bar.py[line:274] - INFO: epoch 001:  12726 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.3, ups=0.88, wpb=110.6, bsz=40, num_updates=12710, lr=3.10652e-05, gnorm=1.101, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59584
2022-10-16 12:10:25 - progress_bar.py[line:274] - INFO: epoch 001:  12736 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102.6, ups=0.93, wpb=110.7, bsz=40, num_updates=12720, lr=3.10896e-05, gnorm=0.95, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=59594
2022-10-16 12:10:37 - progress_bar.py[line:274] - INFO: epoch 001:  12746 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=12730, lr=3.1114e-05, gnorm=0.933, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59606
2022-10-16 12:10:48 - progress_bar.py[line:274] - INFO: epoch 001:  12756 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.3, ups=0.87, wpb=108.9, bsz=40, num_updates=12740, lr=3.11385e-05, gnorm=0.919, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=59617
2022-10-16 12:10:59 - progress_bar.py[line:274] - INFO: epoch 001:  12766 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.5, ups=0.9, wpb=110.7, bsz=40, num_updates=12750, lr=3.11629e-05, gnorm=1.027, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59628
2022-10-16 12:11:11 - progress_bar.py[line:274] - INFO: epoch 001:  12776 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.89, wpb=111, bsz=40, num_updates=12760, lr=3.11874e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=59640
2022-10-16 12:11:22 - progress_bar.py[line:274] - INFO: epoch 001:  12786 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=12770, lr=3.12118e-05, gnorm=0.913, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59651
2022-10-16 12:11:33 - progress_bar.py[line:274] - INFO: epoch 001:  12796 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.3, ups=0.91, wpb=109.7, bsz=40, num_updates=12780, lr=3.12363e-05, gnorm=0.991, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59662
2022-10-16 12:11:44 - progress_bar.py[line:274] - INFO: epoch 001:  12806 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.5, ups=0.9, wpb=109.5, bsz=40, num_updates=12790, lr=3.12607e-05, gnorm=1.068, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59673
2022-10-16 12:11:55 - progress_bar.py[line:274] - INFO: epoch 001:  12816 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.5, ups=0.92, wpb=109.9, bsz=40, num_updates=12800, lr=3.12851e-05, gnorm=0.991, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59684
2022-10-16 12:12:06 - progress_bar.py[line:274] - INFO: epoch 001:  12826 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.6, ups=0.91, wpb=110.5, bsz=40, num_updates=12810, lr=3.13096e-05, gnorm=1.033, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59695
2022-10-16 12:12:17 - progress_bar.py[line:274] - INFO: epoch 001:  12836 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.7, ups=0.93, wpb=109.9, bsz=40, num_updates=12820, lr=3.1334e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59706
2022-10-16 12:12:28 - progress_bar.py[line:274] - INFO: epoch 001:  12846 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=12830, lr=3.13585e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59717
2022-10-16 12:12:40 - progress_bar.py[line:274] - INFO: epoch 001:  12856 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97, ups=0.88, wpb=109.9, bsz=40, num_updates=12840, lr=3.13829e-05, gnorm=1.04, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=59729
2022-10-16 12:12:51 - progress_bar.py[line:274] - INFO: epoch 001:  12866 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=12850, lr=3.14073e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59740
2022-10-16 12:13:02 - progress_bar.py[line:274] - INFO: epoch 001:  12876 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.3, ups=0.89, wpb=109.4, bsz=40, num_updates=12860, lr=3.14318e-05, gnorm=1.024, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59751
2022-10-16 12:13:13 - progress_bar.py[line:274] - INFO: epoch 001:  12886 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.8, ups=0.88, wpb=109, bsz=40, num_updates=12870, lr=3.14562e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59762
2022-10-16 12:13:24 - progress_bar.py[line:274] - INFO: epoch 001:  12896 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101, ups=0.9, wpb=112, bsz=40, num_updates=12880, lr=3.14807e-05, gnorm=0.967, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59773
2022-10-16 12:13:36 - progress_bar.py[line:274] - INFO: epoch 001:  12906 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97, ups=0.87, wpb=111.5, bsz=40, num_updates=12890, lr=3.15051e-05, gnorm=0.986, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59785
2022-10-16 12:13:47 - progress_bar.py[line:274] - INFO: epoch 001:  12916 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=12900, lr=3.15295e-05, gnorm=1.004, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59796
2022-10-16 12:13:59 - progress_bar.py[line:274] - INFO: epoch 001:  12926 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=12910, lr=3.1554e-05, gnorm=0.859, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59808
2022-10-16 12:14:10 - progress_bar.py[line:274] - INFO: epoch 001:  12936 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.5, ups=0.87, wpb=111, bsz=40, num_updates=12920, lr=3.15784e-05, gnorm=0.911, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59819
2022-10-16 12:14:22 - progress_bar.py[line:274] - INFO: epoch 001:  12946 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=12930, lr=3.16029e-05, gnorm=0.999, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59831
2022-10-16 12:14:33 - progress_bar.py[line:274] - INFO: epoch 001:  12956 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=12940, lr=3.16273e-05, gnorm=1.05, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59842
2022-10-16 12:14:44 - progress_bar.py[line:274] - INFO: epoch 001:  12966 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.3, ups=0.9, wpb=111.6, bsz=40, num_updates=12950, lr=3.16518e-05, gnorm=1.065, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59853
2022-10-16 12:14:55 - progress_bar.py[line:274] - INFO: epoch 001:  12976 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=12960, lr=3.16762e-05, gnorm=1.015, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59864
2022-10-16 12:15:06 - progress_bar.py[line:274] - INFO: epoch 001:  12986 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=12970, lr=3.17006e-05, gnorm=0.857, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59875
2022-10-16 12:15:17 - progress_bar.py[line:274] - INFO: epoch 001:  12996 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.4, ups=0.9, wpb=111.1, bsz=40, num_updates=12980, lr=3.17251e-05, gnorm=0.929, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59886
2022-10-16 12:15:29 - progress_bar.py[line:274] - INFO: epoch 001:  13006 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=12990, lr=3.17495e-05, gnorm=1.073, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=59898
2022-10-16 12:15:40 - progress_bar.py[line:274] - INFO: epoch 001:  13016 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=13000, lr=3.1774e-05, gnorm=1.136, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59909
2022-10-16 12:15:40 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 12:15:41 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 12:15:41 - train.py[line:551] - INFO: load:0.96 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 12:18:14 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 12:18:14 - train.py[line:551] - INFO: load:0.98 valid_run:152.49 task_valid:148.98 collect_output:2.48
2022-10-16 12:20:42 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 12:20:42 - train.py[line:551] - INFO: load:1.01 valid_run:300.49 task_valid:292.03 collect_output:6.42
2022-10-16 12:23:13 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 12:23:13 - train.py[line:551] - INFO: load:1.03 valid_run:451.93 task_valid:435.05 collect_output:13.83
2022-10-16 12:25:42 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 12:25:42 - train.py[line:551] - INFO: load:1.06 valid_run:600.40 task_valid:579.82 collect_output:16.52
2022-10-16 12:28:14 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 12:28:14 - train.py[line:551] - INFO: load:1.08 valid_run:752.36 task_valid:727.32 collect_output:19.96
2022-10-16 12:30:45 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 12:30:45 - train.py[line:551] - INFO: load:1.11 valid_run:903.63 task_valid:872.76 collect_output:24.77
2022-10-16 12:33:18 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 12:33:18 - train.py[line:551] - INFO: load:1.14 valid_run:1056.07 task_valid:1018.71 collect_output:30.29
2022-10-16 12:35:48 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 12:35:48 - train.py[line:551] - INFO: load:1.16 valid_run:1206.63 task_valid:1159.69 collect_output:38.87
2022-10-16 12:38:17 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 12:38:17 - train.py[line:551] - INFO: load:1.19 valid_run:1355.83 task_valid:1304.35 collect_output:42.40
2022-10-16 12:40:46 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 12:40:46 - train.py[line:551] - INFO: load:1.21 valid_run:1504.21 task_valid:1447.71 collect_output:46.40
2022-10-16 12:43:15 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 12:43:15 - train.py[line:551] - INFO: load:1.24 valid_run:1653.75 task_valid:1592.57 collect_output:50.10
2022-10-16 12:45:45 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 12:45:45 - train.py[line:551] - INFO: load:1.27 valid_run:1803.26 task_valid:1737.42 collect_output:53.74
2022-10-16 12:48:15 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 12:48:15 - train.py[line:551] - INFO: load:1.30 valid_run:1952.66 task_valid:1879.24 collect_output:60.29
2022-10-16 12:50:45 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 12:50:45 - train.py[line:551] - INFO: load:1.33 valid_run:2102.90 task_valid:2024.80 collect_output:63.98
2022-10-16 12:53:15 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 12:53:15 - train.py[line:551] - INFO: load:1.36 valid_run:2252.66 task_valid:2171.10 collect_output:66.44
2022-10-16 12:55:44 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 12:55:44 - train.py[line:551] - INFO: load:1.38 valid_run:2402.34 task_valid:2315.21 collect_output:70.98
2022-10-16 12:58:16 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 12:58:16 - train.py[line:551] - INFO: load:1.41 valid_run:2553.65 task_valid:2460.61 collect_output:75.88
2022-10-16 13:00:47 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 13:00:47 - train.py[line:551] - INFO: load:1.44 valid_run:2704.78 task_valid:2608.18 collect_output:78.35
2022-10-16 13:03:16 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 13:03:16 - train.py[line:551] - INFO: load:1.46 valid_run:2853.52 task_valid:2750.21 collect_output:83.96
2022-10-16 13:05:46 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 13:05:46 - train.py[line:551] - INFO: load:1.49 valid_run:3004.16 task_valid:2895.80 collect_output:87.86
2022-10-16 13:08:19 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 13:08:19 - train.py[line:551] - INFO: load:1.52 valid_run:3156.42 task_valid:3040.64 collect_output:94.17
2022-10-16 13:10:49 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 13:10:49 - train.py[line:551] - INFO: load:1.54 valid_run:3306.31 task_valid:3185.69 collect_output:97.91
2022-10-16 13:13:21 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 13:13:21 - train.py[line:551] - INFO: load:1.57 valid_run:3458.19 task_valid:3332.64 collect_output:101.72
2022-10-16 13:15:53 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 13:15:53 - train.py[line:551] - INFO: load:1.60 valid_run:3610.19 task_valid:3479.79 collect_output:105.42

====================================================================================================
SGG eval:     R @ 50: 0.5457;     R @ 100: 0.5779;     R @ 500: 0.6022;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3714;    mR @ 100: 0.4007;    mR @ 500: 0.4258;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.7083) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8644) (says:0.0000) (sitting on:0.7018) (standing on:0.1283) (using:0.6000) (walking in:0.0000) (walking on:0.8649) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5457;     R @ 100: 0.5779;     R @ 500: 0.6022;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3714;    mR @ 100: 0.4007;    mR @ 500: 0.4258;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.7083) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8644) (says:0.0000) (sitting on:0.7018) (standing on:0.1283) (using:0.6000) (walking in:0.0000) (walking on:0.8649) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2022-10-16 13:18:25 - train.py[line:487] - INFO: 0.577881512605042
2022-10-16 13:18:25 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 13:18:25 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.323 | loss_v1 0 | loss_v2 0 | nll_loss 0.167 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.577882 | ppl 1.12 | vqa_score 0.5045 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 13000 | best_R@100 0.581461
2022-10-16 13:18:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 13000 updates
2022-10-16 13:18:25 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_13000.pt
2022-10-16 13:18:31 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_13000.pt
2022-10-16 13:18:34 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_13000.pt (epoch 1 @ 13000 updates, score 0.577881512605042) (writing took 8.83679784135893 seconds)
2022-10-16 13:18:45 - progress_bar.py[line:274] - INFO: epoch 001:  13026 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=0.3, ups=0, wpb=111, bsz=40, num_updates=13010, lr=3.17984e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63694
2022-10-16 13:18:56 - progress_bar.py[line:274] - INFO: epoch 001:  13036 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96, ups=0.88, wpb=109.6, bsz=40, num_updates=13020, lr=3.18228e-05, gnorm=0.952, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63705
2022-10-16 13:19:07 - progress_bar.py[line:274] - INFO: epoch 001:  13046 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102.1, ups=0.93, wpb=110.1, bsz=40, num_updates=13030, lr=3.18473e-05, gnorm=1.098, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63716
2022-10-16 13:19:18 - progress_bar.py[line:274] - INFO: epoch 001:  13056 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.8, ups=0.9, wpb=109.4, bsz=40, num_updates=13040, lr=3.18717e-05, gnorm=0.883, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=63727
2022-10-16 13:19:29 - progress_bar.py[line:274] - INFO: epoch 001:  13066 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=13050, lr=3.18962e-05, gnorm=1.062, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63738
2022-10-16 13:19:41 - progress_bar.py[line:274] - INFO: epoch 001:  13076 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=13060, lr=3.19206e-05, gnorm=0.886, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63750
2022-10-16 13:19:52 - progress_bar.py[line:274] - INFO: epoch 001:  13086 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=13070, lr=3.19451e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63761
2022-10-16 13:20:03 - progress_bar.py[line:274] - INFO: epoch 001:  13096 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.3, ups=0.89, wpb=109.3, bsz=40, num_updates=13080, lr=3.19695e-05, gnorm=1.018, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63772
2022-10-16 13:20:15 - progress_bar.py[line:274] - INFO: epoch 001:  13106 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=13090, lr=3.19939e-05, gnorm=0.95, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63784
2022-10-16 13:20:26 - progress_bar.py[line:274] - INFO: epoch 001:  13116 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.8, ups=0.89, wpb=111.1, bsz=40, num_updates=13100, lr=3.20184e-05, gnorm=1.011, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63795
2022-10-16 13:20:37 - progress_bar.py[line:274] - INFO: epoch 001:  13126 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.9, ups=0.89, wpb=109.4, bsz=40, num_updates=13110, lr=3.20428e-05, gnorm=0.898, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=63806
2022-10-16 13:20:48 - progress_bar.py[line:274] - INFO: epoch 001:  13136 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.6, ups=0.91, wpb=110, bsz=40, num_updates=13120, lr=3.20673e-05, gnorm=0.95, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=63817
2022-10-16 13:21:00 - progress_bar.py[line:274] - INFO: epoch 001:  13146 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.8, ups=0.88, wpb=111.3, bsz=40, num_updates=13130, lr=3.20917e-05, gnorm=0.994, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63828
2022-10-16 13:21:11 - progress_bar.py[line:274] - INFO: epoch 001:  13156 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=94.9, ups=0.87, wpb=109.3, bsz=40, num_updates=13140, lr=3.21161e-05, gnorm=0.968, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63840
2022-10-16 13:21:22 - progress_bar.py[line:274] - INFO: epoch 001:  13166 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=13150, lr=3.21406e-05, gnorm=0.981, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63851
2022-10-16 13:21:33 - progress_bar.py[line:274] - INFO: epoch 001:  13176 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=13160, lr=3.2165e-05, gnorm=1.038, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63862
2022-10-16 13:21:45 - progress_bar.py[line:274] - INFO: epoch 001:  13186 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.9, ups=0.87, wpb=110.1, bsz=40, num_updates=13170, lr=3.21895e-05, gnorm=0.861, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=63874
2022-10-16 13:22:00 - progress_bar.py[line:274] - INFO: epoch 001:  13196 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.6, ups=0.87, wpb=110.5, bsz=40, num_updates=13180, lr=3.22139e-05, gnorm=1.07, clip=50, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=63885
2022-10-16 13:22:11 - progress_bar.py[line:274] - INFO: epoch 001:  13206 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.6, ups=0.9, wpb=110.7, bsz=40, num_updates=13190, lr=3.22384e-05, gnorm=1.031, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63900
2022-10-16 13:22:22 - progress_bar.py[line:274] - INFO: epoch 001:  13216 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97, ups=0.89, wpb=108.8, bsz=40, num_updates=13200, lr=3.22628e-05, gnorm=1, clip=60, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=63911
2022-10-16 13:22:34 - progress_bar.py[line:274] - INFO: epoch 001:  13226 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.7, ups=0.89, wpb=108.2, bsz=40, num_updates=13210, lr=3.22872e-05, gnorm=1.112, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=63923
2022-10-16 13:22:44 - progress_bar.py[line:274] - INFO: epoch 001:  13236 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.6, ups=0.93, wpb=109.4, bsz=40, num_updates=13220, lr=3.23117e-05, gnorm=0.963, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=63933
2022-10-16 13:22:56 - progress_bar.py[line:274] - INFO: epoch 001:  13246 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=13230, lr=3.23361e-05, gnorm=1.173, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63944
2022-10-16 13:23:07 - progress_bar.py[line:274] - INFO: epoch 001:  13256 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.9, ups=0.88, wpb=110.4, bsz=40, num_updates=13240, lr=3.23606e-05, gnorm=0.95, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=63956
2022-10-16 13:23:18 - progress_bar.py[line:274] - INFO: epoch 001:  13266 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=13250, lr=3.2385e-05, gnorm=1.085, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63967
2022-10-16 13:23:30 - progress_bar.py[line:274] - INFO: epoch 001:  13276 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.4, ups=0.89, wpb=110.7, bsz=40, num_updates=13260, lr=3.24094e-05, gnorm=0.933, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=63978
2022-10-16 13:23:41 - progress_bar.py[line:274] - INFO: epoch 001:  13286 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.1, ups=0.88, wpb=110.5, bsz=40, num_updates=13270, lr=3.24339e-05, gnorm=1.019, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=63990
2022-10-16 13:23:52 - progress_bar.py[line:274] - INFO: epoch 001:  13296 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=13280, lr=3.24583e-05, gnorm=1.118, clip=60, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=64001
2022-10-16 13:24:03 - progress_bar.py[line:274] - INFO: epoch 001:  13306 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=13290, lr=3.24828e-05, gnorm=0.905, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64012
2022-10-16 13:24:15 - progress_bar.py[line:274] - INFO: epoch 001:  13316 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.2, ups=0.87, wpb=109.4, bsz=40, num_updates=13300, lr=3.25072e-05, gnorm=0.98, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64024
2022-10-16 13:24:26 - progress_bar.py[line:274] - INFO: epoch 001:  13326 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.1, ups=0.9, wpb=110, bsz=40, num_updates=13310, lr=3.25317e-05, gnorm=1.014, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64035
2022-10-16 13:24:37 - progress_bar.py[line:274] - INFO: epoch 001:  13336 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.5, ups=0.91, wpb=111.4, bsz=40, num_updates=13320, lr=3.25561e-05, gnorm=0.904, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64046
2022-10-16 13:24:48 - progress_bar.py[line:274] - INFO: epoch 001:  13346 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.9, ups=0.87, wpb=110.4, bsz=40, num_updates=13330, lr=3.25805e-05, gnorm=0.884, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64057
2022-10-16 13:25:00 - progress_bar.py[line:274] - INFO: epoch 001:  13356 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96, ups=0.88, wpb=108.6, bsz=40, num_updates=13340, lr=3.2605e-05, gnorm=1.041, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64069
2022-10-16 13:25:11 - progress_bar.py[line:274] - INFO: epoch 001:  13366 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=13350, lr=3.26294e-05, gnorm=1.194, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64080
2022-10-16 13:25:22 - progress_bar.py[line:274] - INFO: epoch 001:  13376 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.4, ups=0.91, wpb=109.5, bsz=40, num_updates=13360, lr=3.26539e-05, gnorm=1.371, clip=80, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64091
2022-10-16 13:25:33 - progress_bar.py[line:274] - INFO: epoch 001:  13386 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=103, ups=0.93, wpb=110.8, bsz=40, num_updates=13370, lr=3.26783e-05, gnorm=1.027, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64102
2022-10-16 13:25:44 - progress_bar.py[line:274] - INFO: epoch 001:  13396 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101, ups=0.91, wpb=110.4, bsz=40, num_updates=13380, lr=3.27027e-05, gnorm=0.93, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64113
2022-10-16 13:25:55 - progress_bar.py[line:274] - INFO: epoch 001:  13406 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=13390, lr=3.27272e-05, gnorm=1.059, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64124
2022-10-16 13:26:06 - progress_bar.py[line:274] - INFO: epoch 001:  13416 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.1, ups=0.88, wpb=110.8, bsz=40, num_updates=13400, lr=3.27516e-05, gnorm=0.913, clip=40, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=64135
2022-10-16 13:26:18 - progress_bar.py[line:274] - INFO: epoch 001:  13426 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=13410, lr=3.27761e-05, gnorm=1.122, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64147
2022-10-16 13:26:29 - progress_bar.py[line:274] - INFO: epoch 001:  13436 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.4, ups=0.87, wpb=111, bsz=40, num_updates=13420, lr=3.28005e-05, gnorm=1.029, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64158
2022-10-16 13:26:40 - progress_bar.py[line:274] - INFO: epoch 001:  13446 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.8, ups=0.9, wpb=109.2, bsz=40, num_updates=13430, lr=3.28249e-05, gnorm=1.044, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64169
2022-10-16 13:26:51 - progress_bar.py[line:274] - INFO: epoch 001:  13456 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=13440, lr=3.28494e-05, gnorm=0.966, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64180
2022-10-16 13:27:02 - progress_bar.py[line:274] - INFO: epoch 001:  13466 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=13450, lr=3.28738e-05, gnorm=1.039, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64191
2022-10-16 13:27:14 - progress_bar.py[line:274] - INFO: epoch 001:  13476 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.6, ups=0.86, wpb=109.4, bsz=40, num_updates=13460, lr=3.28983e-05, gnorm=0.948, clip=40, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=64203
2022-10-16 13:27:25 - progress_bar.py[line:274] - INFO: epoch 001:  13486 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.3, ups=0.9, wpb=111.4, bsz=40, num_updates=13470, lr=3.29227e-05, gnorm=1.051, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64214
2022-10-16 13:27:37 - progress_bar.py[line:274] - INFO: epoch 001:  13496 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.2, ups=0.89, wpb=111.9, bsz=40, num_updates=13480, lr=3.29472e-05, gnorm=0.975, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64225
2022-10-16 13:27:48 - progress_bar.py[line:274] - INFO: epoch 001:  13506 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.8, ups=0.9, wpb=111.7, bsz=40, num_updates=13490, lr=3.29716e-05, gnorm=0.997, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64237
2022-10-16 13:27:59 - progress_bar.py[line:274] - INFO: epoch 001:  13516 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=13500, lr=3.2996e-05, gnorm=0.942, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64248
2022-10-16 13:28:10 - progress_bar.py[line:274] - INFO: epoch 001:  13526 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.3, ups=0.88, wpb=108.8, bsz=40, num_updates=13510, lr=3.30205e-05, gnorm=1.018, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64259
2022-10-16 13:28:21 - progress_bar.py[line:274] - INFO: epoch 001:  13536 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.9, ups=0.91, wpb=110.5, bsz=40, num_updates=13520, lr=3.30449e-05, gnorm=0.954, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64270
2022-10-16 13:28:32 - progress_bar.py[line:274] - INFO: epoch 001:  13546 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=13530, lr=3.30694e-05, gnorm=1.084, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64281
2022-10-16 13:28:44 - progress_bar.py[line:274] - INFO: epoch 001:  13556 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.3, ups=0.88, wpb=111.5, bsz=40, num_updates=13540, lr=3.30938e-05, gnorm=0.869, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64292
2022-10-16 13:28:55 - progress_bar.py[line:274] - INFO: epoch 001:  13566 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.3, ups=0.9, wpb=110.6, bsz=40, num_updates=13550, lr=3.31182e-05, gnorm=1.031, clip=60, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=64304
2022-10-16 13:29:06 - progress_bar.py[line:274] - INFO: epoch 001:  13576 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.4, ups=0.88, wpb=110.2, bsz=40, num_updates=13560, lr=3.31427e-05, gnorm=0.894, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64315
2022-10-16 13:29:17 - progress_bar.py[line:274] - INFO: epoch 001:  13586 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.8, ups=0.9, wpb=111.4, bsz=40, num_updates=13570, lr=3.31671e-05, gnorm=0.929, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64326
2022-10-16 13:29:28 - progress_bar.py[line:274] - INFO: epoch 001:  13596 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=13580, lr=3.31916e-05, gnorm=0.883, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64337
2022-10-16 13:29:40 - progress_bar.py[line:274] - INFO: epoch 001:  13606 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.7, ups=0.9, wpb=110.1, bsz=40, num_updates=13590, lr=3.3216e-05, gnorm=0.977, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64349
2022-10-16 13:29:42 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-16 13:29:52 - progress_bar.py[line:274] - INFO: epoch 001:  13617 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.5, ups=0.82, wpb=110.3, bsz=40, num_updates=13600, lr=3.32405e-05, gnorm=1.022, clip=40, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=64361
2022-10-16 13:30:03 - progress_bar.py[line:274] - INFO: epoch 001:  13627 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.8, ups=0.92, wpb=111, bsz=40, num_updates=13610, lr=3.32649e-05, gnorm=0.985, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64372
2022-10-16 13:30:14 - progress_bar.py[line:274] - INFO: epoch 001:  13637 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=13620, lr=3.32893e-05, gnorm=1.009, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64383
2022-10-16 13:30:25 - progress_bar.py[line:274] - INFO: epoch 001:  13647 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=13630, lr=3.33138e-05, gnorm=0.919, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64394
2022-10-16 13:30:36 - progress_bar.py[line:274] - INFO: epoch 001:  13657 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=102.5, ups=0.92, wpb=111.8, bsz=40, num_updates=13640, lr=3.33382e-05, gnorm=0.948, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64405
2022-10-16 13:30:47 - progress_bar.py[line:274] - INFO: epoch 001:  13667 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.4, ups=0.92, wpb=111.9, bsz=40, num_updates=13650, lr=3.33627e-05, gnorm=0.934, clip=40, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=64416
2022-10-16 13:30:58 - progress_bar.py[line:274] - INFO: epoch 001:  13677 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=13660, lr=3.33871e-05, gnorm=0.917, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64427
2022-10-16 13:31:10 - progress_bar.py[line:274] - INFO: epoch 001:  13687 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=13670, lr=3.34115e-05, gnorm=0.933, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64439
2022-10-16 13:31:21 - progress_bar.py[line:274] - INFO: epoch 001:  13697 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.9, ups=0.88, wpb=108.9, bsz=40, num_updates=13680, lr=3.3436e-05, gnorm=0.894, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64450
2022-10-16 13:31:32 - progress_bar.py[line:274] - INFO: epoch 001:  13707 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=103.1, ups=0.93, wpb=110.8, bsz=40, num_updates=13690, lr=3.34604e-05, gnorm=0.925, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64461
2022-10-16 13:31:43 - progress_bar.py[line:274] - INFO: epoch 001:  13717 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.5, ups=0.88, wpb=111.9, bsz=40, num_updates=13700, lr=3.34849e-05, gnorm=1.184, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64472
2022-10-16 13:31:55 - progress_bar.py[line:274] - INFO: epoch 001:  13727 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.4, ups=0.89, wpb=111.5, bsz=40, num_updates=13710, lr=3.35093e-05, gnorm=1.094, clip=70, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64483
2022-10-16 13:32:05 - progress_bar.py[line:274] - INFO: epoch 001:  13737 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.5, ups=0.92, wpb=110.7, bsz=40, num_updates=13720, lr=3.35338e-05, gnorm=1.041, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64494
2022-10-16 13:32:16 - progress_bar.py[line:274] - INFO: epoch 001:  13747 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.1, ups=0.92, wpb=110.2, bsz=40, num_updates=13730, lr=3.35582e-05, gnorm=1.114, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64505
2022-10-16 13:32:28 - progress_bar.py[line:274] - INFO: epoch 001:  13757 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.3, ups=0.88, wpb=109.1, bsz=40, num_updates=13740, lr=3.35826e-05, gnorm=1.207, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64517
2022-10-16 13:32:39 - progress_bar.py[line:274] - INFO: epoch 001:  13767 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=13750, lr=3.36071e-05, gnorm=1.096, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64528
2022-10-16 13:32:50 - progress_bar.py[line:274] - INFO: epoch 001:  13777 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.8, ups=0.9, wpb=109.1, bsz=40, num_updates=13760, lr=3.36315e-05, gnorm=0.966, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64539
2022-10-16 13:33:01 - progress_bar.py[line:274] - INFO: epoch 001:  13787 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.7, ups=0.88, wpb=109.5, bsz=40, num_updates=13770, lr=3.3656e-05, gnorm=0.905, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64550
2022-10-16 13:33:13 - progress_bar.py[line:274] - INFO: epoch 001:  13797 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.9, ups=0.86, wpb=110.6, bsz=40, num_updates=13780, lr=3.36804e-05, gnorm=1.015, clip=50, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=64562
2022-10-16 13:33:24 - progress_bar.py[line:274] - INFO: epoch 001:  13807 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=13790, lr=3.37048e-05, gnorm=1.063, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64573
2022-10-16 13:33:36 - progress_bar.py[line:274] - INFO: epoch 001:  13817 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.4, ups=0.9, wpb=110.6, bsz=40, num_updates=13800, lr=3.37293e-05, gnorm=0.984, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64585
2022-10-16 13:33:47 - progress_bar.py[line:274] - INFO: epoch 001:  13827 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=13810, lr=3.37537e-05, gnorm=1.039, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64596
2022-10-16 13:33:58 - progress_bar.py[line:274] - INFO: epoch 001:  13837 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=103.4, ups=0.93, wpb=111.2, bsz=40, num_updates=13820, lr=3.37782e-05, gnorm=1.113, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64607
2022-10-16 13:34:09 - progress_bar.py[line:274] - INFO: epoch 001:  13847 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=13830, lr=3.38026e-05, gnorm=1.01, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64618
2022-10-16 13:34:20 - progress_bar.py[line:274] - INFO: epoch 001:  13857 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.2, ups=0.88, wpb=111.5, bsz=40, num_updates=13840, lr=3.38271e-05, gnorm=0.905, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64629
2022-10-16 13:34:31 - progress_bar.py[line:274] - INFO: epoch 001:  13867 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=103.4, ups=0.93, wpb=110.7, bsz=40, num_updates=13850, lr=3.38515e-05, gnorm=1, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64640
2022-10-16 13:34:42 - progress_bar.py[line:274] - INFO: epoch 001:  13877 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.3, ups=0.89, wpb=109.1, bsz=40, num_updates=13860, lr=3.38759e-05, gnorm=1.016, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64651
2022-10-16 13:34:53 - progress_bar.py[line:274] - INFO: epoch 001:  13887 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=13870, lr=3.39004e-05, gnorm=1, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64662
2022-10-16 13:35:05 - progress_bar.py[line:274] - INFO: epoch 001:  13897 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=13880, lr=3.39248e-05, gnorm=0.977, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64674
2022-10-16 13:35:16 - progress_bar.py[line:274] - INFO: epoch 001:  13907 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.5, ups=0.91, wpb=111.1, bsz=40, num_updates=13890, lr=3.39493e-05, gnorm=0.937, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64685
2022-10-16 13:35:27 - progress_bar.py[line:274] - INFO: epoch 001:  13917 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=13900, lr=3.39737e-05, gnorm=1.02, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64696
2022-10-16 13:35:38 - progress_bar.py[line:274] - INFO: epoch 001:  13927 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.7, ups=0.88, wpb=110.7, bsz=40, num_updates=13910, lr=3.39981e-05, gnorm=0.949, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64707
2022-10-16 13:35:50 - progress_bar.py[line:274] - INFO: epoch 001:  13937 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.9, wpb=110, bsz=40, num_updates=13920, lr=3.40226e-05, gnorm=1.148, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64719
2022-10-16 13:36:01 - progress_bar.py[line:274] - INFO: epoch 001:  13947 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.7, ups=0.92, wpb=111.8, bsz=40, num_updates=13930, lr=3.4047e-05, gnorm=0.906, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64730
2022-10-16 13:36:12 - progress_bar.py[line:274] - INFO: epoch 001:  13957 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.5, ups=0.88, wpb=108.2, bsz=40, num_updates=13940, lr=3.40715e-05, gnorm=1.002, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64741
2022-10-16 13:36:23 - progress_bar.py[line:274] - INFO: epoch 001:  13967 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.9, ups=0.88, wpb=111.9, bsz=40, num_updates=13950, lr=3.40959e-05, gnorm=0.974, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64752
2022-10-16 13:36:34 - progress_bar.py[line:274] - INFO: epoch 001:  13977 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.4, ups=0.9, wpb=112.1, bsz=40, num_updates=13960, lr=3.41204e-05, gnorm=0.956, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64763
2022-10-16 13:36:46 - progress_bar.py[line:274] - INFO: epoch 001:  13987 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.1, ups=0.87, wpb=110.5, bsz=40, num_updates=13970, lr=3.41448e-05, gnorm=0.95, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64775
2022-10-16 13:36:57 - progress_bar.py[line:274] - INFO: epoch 001:  13997 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.4, ups=0.9, wpb=109.9, bsz=40, num_updates=13980, lr=3.41692e-05, gnorm=0.91, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64786
2022-10-16 13:37:08 - progress_bar.py[line:274] - INFO: epoch 001:  14007 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=13990, lr=3.41937e-05, gnorm=0.956, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64797
2022-10-16 13:37:20 - progress_bar.py[line:274] - INFO: epoch 001:  14017 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100, ups=0.89, wpb=112, bsz=40, num_updates=14000, lr=3.42181e-05, gnorm=1.054, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64809
2022-10-16 13:37:20 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 13:37:21 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 13:37:21 - train.py[line:551] - INFO: load:1.00 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 13:39:53 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 13:39:53 - train.py[line:551] - INFO: load:1.02 valid_run:151.91 task_valid:148.38 collect_output:2.50
2022-10-16 13:42:21 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 13:42:21 - train.py[line:551] - INFO: load:1.05 valid_run:299.98 task_valid:291.63 collect_output:6.28
2022-10-16 13:44:53 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 13:44:53 - train.py[line:551] - INFO: load:1.08 valid_run:451.40 task_valid:434.59 collect_output:13.77
2022-10-16 13:47:21 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 13:47:21 - train.py[line:551] - INFO: load:1.10 valid_run:599.98 task_valid:579.42 collect_output:16.52
2022-10-16 13:49:53 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 13:49:53 - train.py[line:551] - INFO: load:1.13 valid_run:752.07 task_valid:726.77 collect_output:20.23
2022-10-16 13:52:25 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 13:52:25 - train.py[line:551] - INFO: load:1.15 valid_run:903.45 task_valid:872.41 collect_output:24.95
2022-10-16 13:54:57 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 13:54:57 - train.py[line:551] - INFO: load:1.18 valid_run:1055.86 task_valid:1018.25 collect_output:30.53
2022-10-16 13:57:28 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 13:57:28 - train.py[line:551] - INFO: load:1.20 valid_run:1206.37 task_valid:1159.27 collect_output:39.02
2022-10-16 13:59:57 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 13:59:57 - train.py[line:551] - INFO: load:1.23 valid_run:1355.65 task_valid:1303.89 collect_output:42.65
2022-10-16 14:02:25 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 14:02:25 - train.py[line:551] - INFO: load:1.26 valid_run:1503.80 task_valid:1446.95 collect_output:46.74
2022-10-16 14:04:55 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 14:04:55 - train.py[line:551] - INFO: load:1.28 valid_run:1653.22 task_valid:1591.92 collect_output:50.18
2022-10-16 14:07:24 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 14:07:24 - train.py[line:551] - INFO: load:1.31 valid_run:1802.68 task_valid:1736.76 collect_output:53.79
2022-10-16 14:09:54 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 14:09:54 - train.py[line:551] - INFO: load:1.33 valid_run:1952.30 task_valid:1878.74 collect_output:60.38
2022-10-16 14:12:24 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 14:12:24 - train.py[line:551] - INFO: load:1.36 valid_run:2102.51 task_valid:2024.32 collect_output:63.95
2022-10-16 14:14:55 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 14:14:55 - train.py[line:551] - INFO: load:1.39 valid_run:2252.99 task_valid:2171.34 collect_output:66.28
2022-10-16 14:17:25 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 14:17:25 - train.py[line:551] - INFO: load:1.41 valid_run:2403.13 task_valid:2316.20 collect_output:70.46
2022-10-16 14:19:57 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 14:19:57 - train.py[line:551] - INFO: load:1.44 valid_run:2554.90 task_valid:2462.14 collect_output:75.17
2022-10-16 14:22:28 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 14:22:28 - train.py[line:551] - INFO: load:1.47 valid_run:2705.73 task_valid:2609.62 collect_output:77.45
2022-10-16 14:24:57 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 14:24:57 - train.py[line:551] - INFO: load:1.49 valid_run:2854.57 task_valid:2752.05 collect_output:82.68
2022-10-16 14:27:28 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 14:27:28 - train.py[line:551] - INFO: load:1.52 valid_run:3005.40 task_valid:2897.77 collect_output:86.68
2022-10-16 14:30:01 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 14:30:01 - train.py[line:551] - INFO: load:1.55 valid_run:3158.45 task_valid:3042.83 collect_output:93.55
2022-10-16 14:32:31 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 14:32:31 - train.py[line:551] - INFO: load:1.57 valid_run:3308.55 task_valid:3187.75 collect_output:97.57
2022-10-16 14:35:03 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 14:35:03 - train.py[line:551] - INFO: load:1.60 valid_run:3460.29 task_valid:3334.34 collect_output:101.60
2022-10-16 14:37:35 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 14:37:35 - train.py[line:551] - INFO: load:1.63 valid_run:3612.65 task_valid:3481.69 collect_output:105.51

====================================================================================================
SGG eval:     R @ 50: 0.5392;     R @ 100: 0.5791;     R @ 500: 0.6030;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3656;    mR @ 100: 0.4051;    mR @ 500: 0.4278;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.8333) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4516) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8350) (says:0.0000) (sitting on:0.7120) (standing on:0.1350) (using:0.6000) (walking in:0.0000) (walking on:0.8288) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2022-10-16 14:40:07 - train.py[line:487] - INFO: 0.5790971988795518
2022-10-16 14:40:07 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.5392;     R @ 100: 0.5791;     R @ 500: 0.6030;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3656;    mR @ 100: 0.4051;    mR @ 500: 0.4278;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.8333) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4516) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8350) (says:0.0000) (sitting on:0.7120) (standing on:0.1350) (using:0.6000) (walking in:0.0000) (walking on:0.8288) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2022-10-16 14:40:07 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.337 | loss_v1 0 | loss_v2 0 | nll_loss 0.176 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.579097 | ppl 1.13 | vqa_score 0.5045 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 14000 | best_R@100 0.581461
2022-10-16 14:40:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 14000 updates
2022-10-16 14:40:07 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_14000.pt
2022-10-16 14:40:13 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_14000.pt
2022-10-16 14:40:16 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 0.5790971988795518) (writing took 8.477286831941456 seconds)
2022-10-16 14:40:27 - progress_bar.py[line:274] - INFO: epoch 001:  14027 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=14010, lr=3.42426e-05, gnorm=0.987, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68596
2022-10-16 14:40:38 - progress_bar.py[line:274] - INFO: epoch 001:  14037 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=14020, lr=3.4267e-05, gnorm=0.98, clip=50, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=68607
2022-10-16 14:40:49 - progress_bar.py[line:274] - INFO: epoch 001:  14047 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.8, ups=0.9, wpb=111.8, bsz=40, num_updates=14030, lr=3.42914e-05, gnorm=0.958, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68618
2022-10-16 14:41:01 - progress_bar.py[line:274] - INFO: epoch 001:  14057 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.2, ups=0.9, wpb=109, bsz=40, num_updates=14040, lr=3.43159e-05, gnorm=0.947, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68630
2022-10-16 14:41:12 - progress_bar.py[line:274] - INFO: epoch 001:  14067 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=14050, lr=3.43403e-05, gnorm=0.971, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68641
2022-10-16 14:41:23 - progress_bar.py[line:274] - INFO: epoch 001:  14077 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.1, ups=0.88, wpb=109.7, bsz=40, num_updates=14060, lr=3.43648e-05, gnorm=0.993, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=68652
2022-10-16 14:41:35 - progress_bar.py[line:274] - INFO: epoch 001:  14087 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.2, ups=0.87, wpb=110.1, bsz=40, num_updates=14070, lr=3.43892e-05, gnorm=0.952, clip=40, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=68664
2022-10-16 14:41:46 - progress_bar.py[line:274] - INFO: epoch 001:  14097 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.4, ups=0.91, wpb=110.5, bsz=40, num_updates=14080, lr=3.44136e-05, gnorm=1.081, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68675
2022-10-16 14:41:50 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 14:41:58 - progress_bar.py[line:274] - INFO: epoch 001:  14108 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=93.9, ups=0.84, wpb=111.3, bsz=40, num_updates=14090, lr=3.44381e-05, gnorm=1, clip=40, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=68687
2022-10-16 14:42:09 - progress_bar.py[line:274] - INFO: epoch 001:  14118 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=14100, lr=3.44625e-05, gnorm=0.96, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68698
2022-10-16 14:42:20 - progress_bar.py[line:274] - INFO: epoch 001:  14128 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=14110, lr=3.4487e-05, gnorm=1.006, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68709
2022-10-16 14:42:31 - progress_bar.py[line:274] - INFO: epoch 001:  14138 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=14120, lr=3.45114e-05, gnorm=1.284, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=68720
2022-10-16 14:42:43 - progress_bar.py[line:274] - INFO: epoch 001:  14148 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.88, wpb=111.5, bsz=40, num_updates=14130, lr=3.45359e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=68732
2022-10-16 14:42:54 - progress_bar.py[line:274] - INFO: epoch 001:  14158 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.9, ups=0.92, wpb=110.2, bsz=40, num_updates=14140, lr=3.45603e-05, gnorm=1.057, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68743
2022-10-16 14:43:05 - progress_bar.py[line:274] - INFO: epoch 001:  14168 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=14150, lr=3.45847e-05, gnorm=1.054, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68754
2022-10-16 14:43:16 - progress_bar.py[line:274] - INFO: epoch 001:  14178 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.2, ups=0.88, wpb=110.9, bsz=40, num_updates=14160, lr=3.46092e-05, gnorm=0.977, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68765
2022-10-16 14:43:28 - progress_bar.py[line:274] - INFO: epoch 001:  14188 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=14170, lr=3.46336e-05, gnorm=0.924, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=68776
2022-10-16 14:43:39 - progress_bar.py[line:274] - INFO: epoch 001:  14198 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=14180, lr=3.46581e-05, gnorm=0.84, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68788
2022-10-16 14:43:50 - progress_bar.py[line:274] - INFO: epoch 001:  14208 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.6, ups=0.9, wpb=109.2, bsz=40, num_updates=14190, lr=3.46825e-05, gnorm=0.9, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68799
2022-10-16 14:44:01 - progress_bar.py[line:274] - INFO: epoch 001:  14218 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.2, ups=0.91, wpb=109.6, bsz=40, num_updates=14200, lr=3.47069e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68810
2022-10-16 14:44:12 - progress_bar.py[line:274] - INFO: epoch 001:  14228 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=14210, lr=3.47314e-05, gnorm=1.178, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68821
2022-10-16 14:44:24 - progress_bar.py[line:274] - INFO: epoch 001:  14238 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.9, ups=0.89, wpb=108.7, bsz=40, num_updates=14220, lr=3.47558e-05, gnorm=0.941, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=68832
2022-10-16 14:44:35 - progress_bar.py[line:274] - INFO: epoch 001:  14248 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=14230, lr=3.47803e-05, gnorm=1.005, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68844
2022-10-16 14:44:46 - progress_bar.py[line:274] - INFO: epoch 001:  14258 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.8, ups=0.87, wpb=110.4, bsz=40, num_updates=14240, lr=3.48047e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68855
2022-10-16 14:44:57 - progress_bar.py[line:274] - INFO: epoch 001:  14268 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.2, ups=0.93, wpb=109, bsz=40, num_updates=14250, lr=3.48292e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68866
2022-10-16 14:45:08 - progress_bar.py[line:274] - INFO: epoch 001:  14278 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=14260, lr=3.48536e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68877
2022-10-16 14:45:20 - progress_bar.py[line:274] - INFO: epoch 001:  14288 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.3, ups=0.87, wpb=110.3, bsz=40, num_updates=14270, lr=3.4878e-05, gnorm=1.079, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68889
2022-10-16 14:45:31 - progress_bar.py[line:274] - INFO: epoch 001:  14298 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.7, ups=0.92, wpb=111.1, bsz=40, num_updates=14280, lr=3.49025e-05, gnorm=1.109, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68900
2022-10-16 14:45:42 - progress_bar.py[line:274] - INFO: epoch 001:  14308 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.8, ups=0.91, wpb=107.9, bsz=40, num_updates=14290, lr=3.49269e-05, gnorm=1.03, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68911
2022-10-16 14:45:53 - progress_bar.py[line:274] - INFO: epoch 001:  14318 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.7, ups=0.91, wpb=110.2, bsz=40, num_updates=14300, lr=3.49514e-05, gnorm=1.288, clip=50, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=68922
2022-10-16 14:46:04 - progress_bar.py[line:274] - INFO: epoch 001:  14328 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=14310, lr=3.49758e-05, gnorm=0.916, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68933
2022-10-16 14:46:15 - progress_bar.py[line:274] - INFO: epoch 001:  14338 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=14320, lr=3.50002e-05, gnorm=0.979, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68944
2022-10-16 14:46:27 - progress_bar.py[line:274] - INFO: epoch 001:  14348 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=14330, lr=3.50247e-05, gnorm=1.083, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=68955
2022-10-16 14:46:38 - progress_bar.py[line:274] - INFO: epoch 001:  14358 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=14340, lr=3.50491e-05, gnorm=1.032, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68967
2022-10-16 14:46:49 - progress_bar.py[line:274] - INFO: epoch 001:  14368 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=14350, lr=3.50736e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=68978
2022-10-16 14:47:00 - progress_bar.py[line:274] - INFO: epoch 001:  14378 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.8, ups=0.91, wpb=109.2, bsz=40, num_updates=14360, lr=3.5098e-05, gnorm=1.048, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68989
2022-10-16 14:47:10 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2022-10-16 14:47:12 - progress_bar.py[line:274] - INFO: epoch 001:  14389 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=90.1, ups=0.82, wpb=110, bsz=40, num_updates=14370, lr=3.51225e-05, gnorm=0.973, clip=40, loss_scale=256, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=69001
2022-10-16 14:47:24 - progress_bar.py[line:274] - INFO: epoch 001:  14399 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.5, ups=0.88, wpb=109.6, bsz=40, num_updates=14380, lr=3.51469e-05, gnorm=0.979, clip=60, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69013
2022-10-16 14:47:35 - progress_bar.py[line:274] - INFO: epoch 001:  14409 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=14390, lr=3.51713e-05, gnorm=0.922, clip=30, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=69024
2022-10-16 14:47:46 - progress_bar.py[line:274] - INFO: epoch 001:  14419 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.9, wpb=109.7, bsz=40, num_updates=14400, lr=3.51958e-05, gnorm=1.079, clip=70, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69035
2022-10-16 14:47:57 - progress_bar.py[line:274] - INFO: epoch 001:  14429 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99, ups=0.91, wpb=109.2, bsz=40, num_updates=14410, lr=3.52202e-05, gnorm=0.981, clip=40, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69046
2022-10-16 14:48:08 - progress_bar.py[line:274] - INFO: epoch 001:  14439 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=102.9, ups=0.93, wpb=110.7, bsz=40, num_updates=14420, lr=3.52447e-05, gnorm=1.009, clip=50, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69057
2022-10-16 14:48:19 - progress_bar.py[line:274] - INFO: epoch 001:  14449 / 102288 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=103.1, ups=0.93, wpb=110.7, bsz=40, num_updates=14430, lr=3.52691e-05, gnorm=1.036, clip=30, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=69068
2022-10-16 14:48:30 - progress_bar.py[line:274] - INFO: epoch 001:  14459 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.3, ups=0.9, wpb=109.7, bsz=40, num_updates=14440, lr=3.52935e-05, gnorm=1.248, clip=60, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69079
2022-10-16 14:48:41 - progress_bar.py[line:274] - INFO: epoch 001:  14469 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=14450, lr=3.5318e-05, gnorm=0.939, clip=30, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=69090
2022-10-16 14:48:52 - progress_bar.py[line:274] - INFO: epoch 001:  14479 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.4, ups=0.9, wpb=110.6, bsz=40, num_updates=14460, lr=3.53424e-05, gnorm=0.893, clip=20, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69101
2022-10-16 14:49:04 - progress_bar.py[line:274] - INFO: epoch 001:  14489 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.88, wpb=110.8, bsz=40, num_updates=14470, lr=3.53669e-05, gnorm=1.05, clip=50, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69113
2022-10-16 14:49:15 - progress_bar.py[line:274] - INFO: epoch 001:  14499 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=14480, lr=3.53913e-05, gnorm=0.899, clip=20, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69124
2022-10-16 14:49:26 - progress_bar.py[line:274] - INFO: epoch 001:  14509 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.2, ups=0.91, wpb=110.7, bsz=40, num_updates=14490, lr=3.54158e-05, gnorm=0.999, clip=50, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=69135
2022-10-16 14:49:37 - progress_bar.py[line:274] - INFO: epoch 001:  14519 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.5, ups=0.92, wpb=109.7, bsz=40, num_updates=14500, lr=3.54402e-05, gnorm=0.879, clip=10, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=69146
2022-10-16 14:49:48 - progress_bar.py[line:274] - INFO: epoch 001:  14529 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101, ups=0.92, wpb=110, bsz=40, num_updates=14510, lr=3.54646e-05, gnorm=0.862, clip=10, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69157
2022-10-16 14:49:59 - progress_bar.py[line:274] - INFO: epoch 001:  14539 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=14520, lr=3.54891e-05, gnorm=0.997, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69168
2022-10-16 14:50:10 - progress_bar.py[line:274] - INFO: epoch 001:  14549 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.5, ups=0.87, wpb=109.8, bsz=40, num_updates=14530, lr=3.55135e-05, gnorm=0.882, clip=20, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69179
2022-10-16 14:50:21 - progress_bar.py[line:274] - INFO: epoch 001:  14559 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=14540, lr=3.5538e-05, gnorm=1.079, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69190
2022-10-16 14:50:33 - progress_bar.py[line:274] - INFO: epoch 001:  14569 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=14550, lr=3.55624e-05, gnorm=1.003, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69202
2022-10-16 14:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  14579 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.7, ups=0.88, wpb=111.3, bsz=40, num_updates=14560, lr=3.55868e-05, gnorm=0.867, clip=30, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69213
2022-10-16 14:50:55 - progress_bar.py[line:274] - INFO: epoch 001:  14589 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102.1, ups=0.93, wpb=110, bsz=40, num_updates=14570, lr=3.56113e-05, gnorm=0.946, clip=20, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69224
2022-10-16 14:51:06 - progress_bar.py[line:274] - INFO: epoch 001:  14599 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.2, ups=0.9, wpb=110.8, bsz=40, num_updates=14580, lr=3.56357e-05, gnorm=0.996, clip=50, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69235
2022-10-16 14:51:17 - progress_bar.py[line:274] - INFO: epoch 001:  14609 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=14590, lr=3.56602e-05, gnorm=1.02, clip=60, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=69246
2022-10-16 14:51:29 - progress_bar.py[line:274] - INFO: epoch 001:  14619 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=14600, lr=3.56846e-05, gnorm=0.918, clip=10, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69258
2022-10-16 14:51:40 - progress_bar.py[line:274] - INFO: epoch 001:  14629 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.5, ups=0.88, wpb=110.2, bsz=40, num_updates=14610, lr=3.5709e-05, gnorm=0.978, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69269
2022-10-16 14:51:51 - progress_bar.py[line:274] - INFO: epoch 001:  14639 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=103.5, ups=0.93, wpb=111.2, bsz=40, num_updates=14620, lr=3.57335e-05, gnorm=0.94, clip=30, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=69280
2022-10-16 14:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  14649 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98, ups=0.9, wpb=109.2, bsz=40, num_updates=14630, lr=3.57579e-05, gnorm=1.115, clip=60, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69291
2022-10-16 14:52:13 - progress_bar.py[line:274] - INFO: epoch 001:  14659 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.4, ups=0.89, wpb=109.9, bsz=40, num_updates=14640, lr=3.57824e-05, gnorm=0.992, clip=50, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=69302
2022-10-16 14:52:24 - progress_bar.py[line:274] - INFO: epoch 001:  14669 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.9, ups=0.92, wpb=110.3, bsz=40, num_updates=14650, lr=3.58068e-05, gnorm=1.104, clip=70, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=69313
2022-10-16 14:52:35 - progress_bar.py[line:274] - INFO: epoch 001:  14679 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.1, ups=0.91, wpb=109.4, bsz=40, num_updates=14660, lr=3.58313e-05, gnorm=0.944, clip=30, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69324
2022-10-16 14:52:47 - progress_bar.py[line:274] - INFO: epoch 001:  14689 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98, ups=0.9, wpb=109.2, bsz=40, num_updates=14670, lr=3.58557e-05, gnorm=1.019, clip=40, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69336
2022-10-16 14:52:58 - progress_bar.py[line:274] - INFO: epoch 001:  14699 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.5, ups=0.88, wpb=109.2, bsz=40, num_updates=14680, lr=3.58801e-05, gnorm=1.059, clip=60, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69347
2022-10-16 14:53:09 - progress_bar.py[line:274] - INFO: epoch 001:  14709 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.5, ups=0.92, wpb=109.7, bsz=40, num_updates=14690, lr=3.59046e-05, gnorm=0.97, clip=20, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69358
2022-10-16 14:53:20 - progress_bar.py[line:274] - INFO: epoch 001:  14719 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100, ups=0.92, wpb=108.3, bsz=40, num_updates=14700, lr=3.5929e-05, gnorm=0.993, clip=40, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69369
2022-10-16 14:53:31 - progress_bar.py[line:274] - INFO: epoch 001:  14729 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102.9, ups=0.93, wpb=110.2, bsz=40, num_updates=14710, lr=3.59535e-05, gnorm=0.922, clip=20, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69379
2022-10-16 14:53:42 - progress_bar.py[line:274] - INFO: epoch 001:  14739 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.4, ups=0.91, wpb=108.6, bsz=40, num_updates=14720, lr=3.59779e-05, gnorm=0.947, clip=30, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69391
2022-10-16 14:53:53 - progress_bar.py[line:274] - INFO: epoch 001:  14749 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101, ups=0.91, wpb=111.2, bsz=40, num_updates=14730, lr=3.60023e-05, gnorm=0.926, clip=30, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=69402
2022-10-16 14:54:04 - progress_bar.py[line:274] - INFO: epoch 001:  14759 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.6, ups=0.91, wpb=108.9, bsz=40, num_updates=14740, lr=3.60268e-05, gnorm=0.953, clip=40, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69413
2022-10-16 14:54:15 - progress_bar.py[line:274] - INFO: epoch 001:  14769 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.6, ups=0.86, wpb=111.6, bsz=40, num_updates=14750, lr=3.60512e-05, gnorm=0.937, clip=30, loss_scale=256, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=69424
2022-10-16 14:54:26 - progress_bar.py[line:274] - INFO: epoch 001:  14779 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=14760, lr=3.60757e-05, gnorm=0.861, clip=20, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=69435
2022-10-16 14:54:38 - progress_bar.py[line:274] - INFO: epoch 001:  14789 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.6, ups=0.87, wpb=110.9, bsz=40, num_updates=14770, lr=3.61001e-05, gnorm=0.966, clip=40, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=69447
2022-10-16 14:54:49 - progress_bar.py[line:274] - INFO: epoch 001:  14799 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=14780, lr=3.61246e-05, gnorm=1.041, clip=70, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69458
2022-10-16 14:55:00 - progress_bar.py[line:274] - INFO: epoch 001:  14809 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=14790, lr=3.6149e-05, gnorm=0.945, clip=30, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69469
2022-10-16 14:55:11 - progress_bar.py[line:274] - INFO: epoch 001:  14819 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.8, ups=0.91, wpb=110.3, bsz=40, num_updates=14800, lr=3.61734e-05, gnorm=0.914, clip=30, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69480
2022-10-16 14:55:22 - progress_bar.py[line:274] - INFO: epoch 001:  14829 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.7, ups=0.91, wpb=109.9, bsz=40, num_updates=14810, lr=3.61979e-05, gnorm=1.004, clip=30, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69491
2022-10-16 14:55:33 - progress_bar.py[line:274] - INFO: epoch 001:  14839 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.7, ups=0.89, wpb=109.2, bsz=40, num_updates=14820, lr=3.62223e-05, gnorm=0.9, clip=40, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69502
2022-10-16 14:55:45 - progress_bar.py[line:274] - INFO: epoch 001:  14849 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.9, ups=0.9, wpb=109.2, bsz=40, num_updates=14830, lr=3.62468e-05, gnorm=1.004, clip=50, loss_scale=256, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=69514
2022-10-16 14:55:56 - progress_bar.py[line:274] - INFO: epoch 001:  14859 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=14840, lr=3.62712e-05, gnorm=1.055, clip=50, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69525
2022-10-16 14:56:07 - progress_bar.py[line:274] - INFO: epoch 001:  14869 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99, ups=0.9, wpb=109.6, bsz=40, num_updates=14850, lr=3.62956e-05, gnorm=1.365, clip=80, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69536
2022-10-16 14:56:18 - progress_bar.py[line:274] - INFO: epoch 001:  14879 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=14860, lr=3.63201e-05, gnorm=1.034, clip=40, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=69547
2022-10-16 14:56:29 - progress_bar.py[line:274] - INFO: epoch 001:  14889 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=14870, lr=3.63445e-05, gnorm=0.952, clip=50, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=69558
2022-10-16 14:56:41 - progress_bar.py[line:274] - INFO: epoch 001:  14899 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.3, ups=0.87, wpb=110.2, bsz=40, num_updates=14880, lr=3.6369e-05, gnorm=0.915, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69570
2022-10-16 14:56:52 - progress_bar.py[line:274] - INFO: epoch 001:  14909 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=14890, lr=3.63934e-05, gnorm=0.962, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69581
2022-10-16 14:57:04 - progress_bar.py[line:274] - INFO: epoch 001:  14919 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=94.7, ups=0.88, wpb=107.9, bsz=40, num_updates=14900, lr=3.64179e-05, gnorm=1, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69592
2022-10-16 14:57:15 - progress_bar.py[line:274] - INFO: epoch 001:  14929 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102, ups=0.9, wpb=112.8, bsz=40, num_updates=14910, lr=3.64423e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=69604
2022-10-16 14:57:26 - progress_bar.py[line:274] - INFO: epoch 001:  14939 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.6, ups=0.93, wpb=109.3, bsz=40, num_updates=14920, lr=3.64667e-05, gnorm=0.966, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69614
2022-10-16 14:57:37 - progress_bar.py[line:274] - INFO: epoch 001:  14949 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=14930, lr=3.64912e-05, gnorm=0.945, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69626
2022-10-16 14:57:48 - progress_bar.py[line:274] - INFO: epoch 001:  14959 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.9, ups=0.87, wpb=109, bsz=40, num_updates=14940, lr=3.65156e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69637
2022-10-16 14:57:59 - progress_bar.py[line:274] - INFO: epoch 001:  14969 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=14950, lr=3.65401e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69648
2022-10-16 14:58:11 - progress_bar.py[line:274] - INFO: epoch 001:  14979 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.7, ups=0.91, wpb=110.9, bsz=40, num_updates=14960, lr=3.65645e-05, gnorm=1.196, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69659
2022-10-16 14:58:22 - progress_bar.py[line:274] - INFO: epoch 001:  14989 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.5, ups=0.91, wpb=109.9, bsz=40, num_updates=14970, lr=3.65889e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=69671
2022-10-16 14:58:33 - progress_bar.py[line:274] - INFO: epoch 001:  14999 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.9, ups=0.92, wpb=110.1, bsz=40, num_updates=14980, lr=3.66134e-05, gnorm=1.003, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69682
2022-10-16 14:58:44 - progress_bar.py[line:274] - INFO: epoch 001:  15009 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.1, ups=0.9, wpb=108.5, bsz=40, num_updates=14990, lr=3.66378e-05, gnorm=0.89, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69693
2022-10-16 14:58:55 - progress_bar.py[line:274] - INFO: epoch 001:  15019 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.9, ups=0.88, wpb=112.1, bsz=40, num_updates=15000, lr=3.66623e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69704
2022-10-16 14:58:55 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 14:58:57 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 14:58:57 - train.py[line:551] - INFO: load:1.14 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 14:59:13 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.88 GiB already allocated; 5.66 GiB free; 31.44 GiB reserved in total by PyTorch)
2022-10-16 14:59:13 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 28        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9089 MB |   14319 MB |   10089 TB |   10089 TB |
|       from large pool |    8944 MB |   14174 MB |   10086 TB |   10086 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9089 MB |   14319 MB |   10089 TB |   10089 TB |
|       from large pool |    8944 MB |   14174 MB |   10086 TB |   10086 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32194 MB |   37842 MB |  284824 MB |  252630 MB |
|       from large pool |   32048 MB |   37694 MB |  284440 MB |  252392 MB |
|       from small pool |     146 MB |     152 MB |     384 MB |     238 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23104 MB |   27735 MB |    9999 TB |    9999 TB |
|       from large pool |   23103 MB |   27733 MB |    9996 TB |    9996 TB |
|       from small pool |       1 MB |       2 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  469925 K  |  469921 K  |
|       from large pool |     563    |     575    |  150655 K  |  150654 K  |
|       from small pool |    3106    |    3116    |  319270 K  |  319267 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  469925 K  |  469921 K  |
|       from large pool |     563    |     575    |  150655 K  |  150654 K  |
|       from small pool |    3106    |    3116    |  319270 K  |  319267 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     146    |     150    |     619    |     473    |
|       from large pool |      73    |      74    |     427    |     354    |
|       from small pool |      73    |      76    |     192    |     119    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      98    |     105    |  335116 K  |  335116 K  |
|       from large pool |      60    |      63    |   56414 K  |   56414 K  |
|       from small pool |      38    |      47    |  278701 K  |  278701 K  |
|===========================================================================|

2022-10-16 14:59:13 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-16 14:59:13 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-16 15:01:30 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 15:01:30 - train.py[line:551] - INFO: load:1.17 valid_run:152.67 task_valid:148.56 collect_output:2.00
2022-10-16 15:03:58 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 15:03:58 - train.py[line:551] - INFO: load:1.19 valid_run:300.66 task_valid:291.78 collect_output:5.75
2022-10-16 15:06:29 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 15:06:29 - train.py[line:551] - INFO: load:1.21 valid_run:452.20 task_valid:434.93 collect_output:13.16
2022-10-16 15:08:58 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 15:08:58 - train.py[line:551] - INFO: load:1.24 valid_run:600.94 task_valid:580.01 collect_output:15.81
2022-10-16 15:11:30 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 15:11:30 - train.py[line:551] - INFO: load:1.26 valid_run:752.74 task_valid:727.41 collect_output:19.22
2022-10-16 15:14:01 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 15:14:01 - train.py[line:551] - INFO: load:1.29 valid_run:904.13 task_valid:872.96 collect_output:24.07
2022-10-16 15:16:34 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 15:16:34 - train.py[line:551] - INFO: load:1.31 valid_run:1056.65 task_valid:1019.16 collect_output:29.37
2022-10-16 15:19:05 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 15:19:05 - train.py[line:551] - INFO: load:1.34 valid_run:1207.35 task_valid:1160.48 collect_output:37.76
2022-10-16 15:21:34 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 15:21:34 - train.py[line:551] - INFO: load:1.36 valid_run:1356.45 task_valid:1305.16 collect_output:41.21
2022-10-16 15:24:02 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 15:24:02 - train.py[line:551] - INFO: load:1.39 valid_run:1504.78 task_valid:1448.33 collect_output:45.40
2022-10-16 15:26:32 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 15:26:32 - train.py[line:551] - INFO: load:1.41 valid_run:1654.41 task_valid:1593.50 collect_output:48.82
2022-10-16 15:29:02 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 15:29:02 - train.py[line:551] - INFO: load:1.44 valid_run:1804.36 task_valid:1739.06 collect_output:52.19
2022-10-16 15:31:31 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 15:31:31 - train.py[line:551] - INFO: load:1.46 valid_run:1953.92 task_valid:1881.11 collect_output:58.66
2022-10-16 15:34:02 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 15:34:02 - train.py[line:551] - INFO: load:1.49 valid_run:2104.43 task_valid:2026.97 collect_output:62.24
2022-10-16 15:36:32 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 15:36:32 - train.py[line:551] - INFO: load:1.52 valid_run:2254.82 task_valid:2173.88 collect_output:64.65
2022-10-16 15:39:03 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 15:39:03 - train.py[line:551] - INFO: load:1.54 valid_run:2404.83 task_valid:2318.66 collect_output:68.77
2022-10-16 15:41:34 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 15:41:34 - train.py[line:551] - INFO: load:1.57 valid_run:2556.47 task_valid:2464.67 collect_output:73.37
2022-10-16 15:44:05 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 15:44:05 - train.py[line:551] - INFO: load:1.59 valid_run:2707.20 task_valid:2612.08 collect_output:75.65
2022-10-16 15:46:34 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 15:46:34 - train.py[line:551] - INFO: load:1.62 valid_run:2855.77 task_valid:2754.31 collect_output:80.90
2022-10-16 15:49:04 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 15:49:04 - train.py[line:551] - INFO: load:1.65 valid_run:3006.32 task_valid:2900.08 collect_output:84.64
2022-10-16 15:51:37 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 15:51:37 - train.py[line:551] - INFO: load:1.68 valid_run:3158.69 task_valid:3045.74 collect_output:90.27
2022-10-16 15:54:08 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 15:54:08 - train.py[line:551] - INFO: load:1.71 valid_run:3309.69 task_valid:3191.88 collect_output:93.85
2022-10-16 15:56:40 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 15:56:40 - train.py[line:551] - INFO: load:1.74 valid_run:3462.20 task_valid:3339.28 collect_output:97.69
2022-10-16 15:59:14 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 15:59:14 - train.py[line:551] - INFO: load:1.77 valid_run:3615.87 task_valid:3487.82 collect_output:101.21

====================================================================================================
SGG eval:     R @ 50: 0.5335;     R @ 100: 0.5769;     R @ 500: 0.5987;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3696;    mR @ 100: 0.4004;    mR @ 500: 0.4270;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.7083) (covering:0.3714) (eating:0.6765) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4516) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8497) (says:0.0000) (sitting on:0.6950) (standing on:0.1520) (using:0.6500) (walking in:0.0000) (walking on:0.8018) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================

2022-10-16 16:01:47 - train.py[line:487] - INFO: 0.5769481792717086
2022-10-16 16:01:47 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.5335;     R @ 100: 0.5769;     R @ 500: 0.5987;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3696;    mR @ 100: 0.4004;    mR @ 500: 0.4270;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.7083) (covering:0.3714) (eating:0.6765) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4516) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8497) (says:0.0000) (sitting on:0.6950) (standing on:0.1520) (using:0.6500) (walking in:0.0000) (walking on:0.8018) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================

2022-10-16 16:01:48 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.336 | loss_v1 0 | loss_v2 0 | nll_loss 0.176 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.576948 | ppl 1.13 | vqa_score 0.5079 | wps 119 | wpb 89.9 | bsz 30 | num_updates 15000 | best_R@100 0.581461
2022-10-16 16:01:48 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 15000 updates
2022-10-16 16:01:48 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_15000.pt
2022-10-16 16:01:53 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_15000.pt
2022-10-16 16:01:56 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_15000.pt (epoch 1 @ 15000 updates, score 0.5769481792717086) (writing took 8.269456489011645 seconds)
2022-10-16 16:02:08 - progress_bar.py[line:274] - INFO: epoch 001:  15029 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=15010, lr=3.66867e-05, gnorm=1.069, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73496
2022-10-16 16:02:19 - progress_bar.py[line:274] - INFO: epoch 001:  15039 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=15020, lr=3.67112e-05, gnorm=1.097, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73508
2022-10-16 16:02:30 - progress_bar.py[line:274] - INFO: epoch 001:  15049 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.3, ups=0.88, wpb=109.1, bsz=40, num_updates=15030, lr=3.67356e-05, gnorm=0.944, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73519
2022-10-16 16:02:42 - progress_bar.py[line:274] - INFO: epoch 001:  15059 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=15040, lr=3.676e-05, gnorm=0.968, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73531
2022-10-16 16:02:53 - progress_bar.py[line:274] - INFO: epoch 001:  15069 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96, ups=0.87, wpb=110.1, bsz=40, num_updates=15050, lr=3.67845e-05, gnorm=1.01, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=73542
2022-10-16 16:03:04 - progress_bar.py[line:274] - INFO: epoch 001:  15079 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.3, ups=0.9, wpb=109.7, bsz=40, num_updates=15060, lr=3.68089e-05, gnorm=1.006, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73553
2022-10-16 16:03:16 - progress_bar.py[line:274] - INFO: epoch 001:  15089 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96, ups=0.86, wpb=111.1, bsz=40, num_updates=15070, lr=3.68334e-05, gnorm=1.003, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73565
2022-10-16 16:03:27 - progress_bar.py[line:274] - INFO: epoch 001:  15099 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.5, ups=0.89, wpb=111.9, bsz=40, num_updates=15080, lr=3.68578e-05, gnorm=0.895, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73576
2022-10-16 16:03:38 - progress_bar.py[line:274] - INFO: epoch 001:  15109 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.2, ups=0.89, wpb=110.8, bsz=40, num_updates=15090, lr=3.68822e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73587
2022-10-16 16:03:50 - progress_bar.py[line:274] - INFO: epoch 001:  15119 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.6, ups=0.88, wpb=109.8, bsz=40, num_updates=15100, lr=3.69067e-05, gnorm=0.989, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73599
2022-10-16 16:04:01 - progress_bar.py[line:274] - INFO: epoch 001:  15129 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96, ups=0.88, wpb=109.4, bsz=40, num_updates=15110, lr=3.69311e-05, gnorm=1.102, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73610
2022-10-16 16:04:12 - progress_bar.py[line:274] - INFO: epoch 001:  15139 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.89, wpb=111.1, bsz=40, num_updates=15120, lr=3.69556e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73621
2022-10-16 16:04:24 - progress_bar.py[line:274] - INFO: epoch 001:  15149 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.4, ups=0.88, wpb=111.1, bsz=40, num_updates=15130, lr=3.698e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73633
2022-10-16 16:04:35 - progress_bar.py[line:274] - INFO: epoch 001:  15159 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96, ups=0.87, wpb=110.3, bsz=40, num_updates=15140, lr=3.70044e-05, gnorm=1.026, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73644
2022-10-16 16:04:47 - progress_bar.py[line:274] - INFO: epoch 001:  15169 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.7, ups=0.89, wpb=110.3, bsz=40, num_updates=15150, lr=3.70289e-05, gnorm=0.997, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73656
2022-10-16 16:04:58 - progress_bar.py[line:274] - INFO: epoch 001:  15179 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=15160, lr=3.70533e-05, gnorm=0.947, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73667
2022-10-16 16:05:09 - progress_bar.py[line:274] - INFO: epoch 001:  15189 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.8, ups=0.88, wpb=109.3, bsz=40, num_updates=15170, lr=3.70778e-05, gnorm=1.004, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73678
2022-10-16 16:05:21 - progress_bar.py[line:274] - INFO: epoch 001:  15199 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.4, ups=0.88, wpb=110.1, bsz=40, num_updates=15180, lr=3.71022e-05, gnorm=0.988, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73690
2022-10-16 16:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  15209 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.8, ups=0.89, wpb=110.2, bsz=40, num_updates=15190, lr=3.71267e-05, gnorm=0.852, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73701
2022-10-16 16:05:43 - progress_bar.py[line:274] - INFO: epoch 001:  15219 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.6, ups=0.91, wpb=110.6, bsz=40, num_updates=15200, lr=3.71511e-05, gnorm=0.945, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73712
2022-10-16 16:05:54 - progress_bar.py[line:274] - INFO: epoch 001:  15229 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.2, ups=0.91, wpb=109, bsz=40, num_updates=15210, lr=3.71755e-05, gnorm=0.989, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73723
2022-10-16 16:06:05 - progress_bar.py[line:274] - INFO: epoch 001:  15239 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.1, ups=0.87, wpb=110.2, bsz=40, num_updates=15220, lr=3.72e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73734
2022-10-16 16:06:17 - progress_bar.py[line:274] - INFO: epoch 001:  15249 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.9, wpb=108.9, bsz=40, num_updates=15230, lr=3.72244e-05, gnorm=1.08, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73745
2022-10-16 16:06:28 - progress_bar.py[line:274] - INFO: epoch 001:  15259 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.1, ups=0.89, wpb=109.7, bsz=40, num_updates=15240, lr=3.72489e-05, gnorm=0.983, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=73757
2022-10-16 16:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  15269 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.7, ups=0.91, wpb=109.8, bsz=40, num_updates=15250, lr=3.72733e-05, gnorm=1.054, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73768
2022-10-16 16:06:50 - progress_bar.py[line:274] - INFO: epoch 001:  15279 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.9, ups=0.92, wpb=110.5, bsz=40, num_updates=15260, lr=3.72977e-05, gnorm=0.97, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=73779
2022-10-16 16:07:01 - progress_bar.py[line:274] - INFO: epoch 001:  15289 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=15270, lr=3.73222e-05, gnorm=0.99, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73790
2022-10-16 16:07:12 - progress_bar.py[line:274] - INFO: epoch 001:  15299 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=15280, lr=3.73466e-05, gnorm=0.922, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73801
2022-10-16 16:07:23 - progress_bar.py[line:274] - INFO: epoch 001:  15309 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.4, ups=0.9, wpb=111.9, bsz=40, num_updates=15290, lr=3.73711e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73812
2022-10-16 16:07:35 - progress_bar.py[line:274] - INFO: epoch 001:  15319 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.1, ups=0.87, wpb=111.1, bsz=40, num_updates=15300, lr=3.73955e-05, gnorm=1.076, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73824
2022-10-16 16:07:46 - progress_bar.py[line:274] - INFO: epoch 001:  15329 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.6, ups=0.87, wpb=111.2, bsz=40, num_updates=15310, lr=3.742e-05, gnorm=0.983, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73835
2022-10-16 16:07:57 - progress_bar.py[line:274] - INFO: epoch 001:  15339 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.1, ups=0.89, wpb=108.1, bsz=40, num_updates=15320, lr=3.74444e-05, gnorm=1.029, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=73846
2022-10-16 16:08:09 - progress_bar.py[line:274] - INFO: epoch 001:  15349 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98, ups=0.89, wpb=110.4, bsz=40, num_updates=15330, lr=3.74688e-05, gnorm=0.854, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73858
2022-10-16 16:08:20 - progress_bar.py[line:274] - INFO: epoch 001:  15359 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.8, ups=0.89, wpb=110.1, bsz=40, num_updates=15340, lr=3.74933e-05, gnorm=1.015, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73869
2022-10-16 16:08:31 - progress_bar.py[line:274] - INFO: epoch 001:  15369 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=15350, lr=3.75177e-05, gnorm=0.964, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73880
2022-10-16 16:08:42 - progress_bar.py[line:274] - INFO: epoch 001:  15379 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.7, ups=0.87, wpb=110.5, bsz=40, num_updates=15360, lr=3.75422e-05, gnorm=1.018, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73891
2022-10-16 16:08:54 - progress_bar.py[line:274] - INFO: epoch 001:  15389 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.9, ups=0.87, wpb=109.8, bsz=40, num_updates=15370, lr=3.75666e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73903
2022-10-16 16:09:05 - progress_bar.py[line:274] - INFO: epoch 001:  15399 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=15380, lr=3.7591e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73914
2022-10-16 16:09:17 - progress_bar.py[line:274] - INFO: epoch 001:  15409 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99, ups=0.88, wpb=111.9, bsz=40, num_updates=15390, lr=3.76155e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73926
2022-10-16 16:09:28 - progress_bar.py[line:274] - INFO: epoch 001:  15419 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.6, ups=0.91, wpb=110.1, bsz=40, num_updates=15400, lr=3.76399e-05, gnorm=1.172, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73937
2022-10-16 16:09:38 - progress_bar.py[line:274] - INFO: epoch 001:  15429 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.8, ups=0.91, wpb=110.3, bsz=40, num_updates=15410, lr=3.76644e-05, gnorm=0.936, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73947
2022-10-16 16:09:50 - progress_bar.py[line:274] - INFO: epoch 001:  15439 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.4, ups=0.86, wpb=111, bsz=40, num_updates=15420, lr=3.76888e-05, gnorm=0.972, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=73959
2022-10-16 16:10:02 - progress_bar.py[line:274] - INFO: epoch 001:  15449 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.6, ups=0.87, wpb=110.4, bsz=40, num_updates=15430, lr=3.77133e-05, gnorm=0.954, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73971
2022-10-16 16:10:13 - progress_bar.py[line:274] - INFO: epoch 001:  15459 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.1, ups=0.89, wpb=109.6, bsz=40, num_updates=15440, lr=3.77377e-05, gnorm=1.109, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73982
2022-10-16 16:10:24 - progress_bar.py[line:274] - INFO: epoch 001:  15469 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.1, ups=0.87, wpb=109.4, bsz=40, num_updates=15450, lr=3.77621e-05, gnorm=0.956, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=73993
2022-10-16 16:10:36 - progress_bar.py[line:274] - INFO: epoch 001:  15479 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.6, ups=0.89, wpb=110.1, bsz=40, num_updates=15460, lr=3.77866e-05, gnorm=0.985, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74005
2022-10-16 16:10:47 - progress_bar.py[line:274] - INFO: epoch 001:  15489 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.4, ups=0.87, wpb=110.7, bsz=40, num_updates=15470, lr=3.7811e-05, gnorm=0.895, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74016
2022-10-16 16:10:58 - progress_bar.py[line:274] - INFO: epoch 001:  15499 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=103.2, ups=0.94, wpb=109.6, bsz=40, num_updates=15480, lr=3.78355e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74027
2022-10-16 16:11:09 - progress_bar.py[line:274] - INFO: epoch 001:  15509 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=15490, lr=3.78599e-05, gnorm=0.938, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74038
2022-10-16 16:11:20 - progress_bar.py[line:274] - INFO: epoch 001:  15519 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.6, ups=0.92, wpb=111, bsz=40, num_updates=15500, lr=3.78843e-05, gnorm=1.038, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74049
2022-10-16 16:11:31 - progress_bar.py[line:274] - INFO: epoch 001:  15529 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96, ups=0.88, wpb=108.9, bsz=40, num_updates=15510, lr=3.79088e-05, gnorm=0.924, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74060
2022-10-16 16:11:42 - progress_bar.py[line:274] - INFO: epoch 001:  15539 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=15520, lr=3.79332e-05, gnorm=0.934, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74071
2022-10-16 16:11:54 - progress_bar.py[line:274] - INFO: epoch 001:  15549 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.8, ups=0.87, wpb=109.1, bsz=40, num_updates=15530, lr=3.79577e-05, gnorm=0.854, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74083
2022-10-16 16:12:05 - progress_bar.py[line:274] - INFO: epoch 001:  15559 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.5, ups=0.9, wpb=108.9, bsz=40, num_updates=15540, lr=3.79821e-05, gnorm=0.832, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74094
2022-10-16 16:12:16 - progress_bar.py[line:274] - INFO: epoch 001:  15569 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=15550, lr=3.80066e-05, gnorm=0.993, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74105
2022-10-16 16:12:27 - progress_bar.py[line:274] - INFO: epoch 001:  15579 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=15560, lr=3.8031e-05, gnorm=1.034, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74116
2022-10-16 16:12:38 - progress_bar.py[line:274] - INFO: epoch 001:  15589 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.3, ups=0.9, wpb=108.8, bsz=40, num_updates=15570, lr=3.80554e-05, gnorm=1.014, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74127
2022-10-16 16:12:50 - progress_bar.py[line:274] - INFO: epoch 001:  15599 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.4, ups=0.88, wpb=109.2, bsz=40, num_updates=15580, lr=3.80799e-05, gnorm=0.849, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74139
2022-10-16 16:13:01 - progress_bar.py[line:274] - INFO: epoch 001:  15609 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=15590, lr=3.81043e-05, gnorm=0.871, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74150
2022-10-16 16:13:07 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 16:13:13 - progress_bar.py[line:274] - INFO: epoch 001:  15620 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.6, ups=0.83, wpb=109.5, bsz=40, num_updates=15600, lr=3.81288e-05, gnorm=0.944, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=74162
2022-10-16 16:13:25 - progress_bar.py[line:274] - INFO: epoch 001:  15630 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=93.6, ups=0.86, wpb=109, bsz=40, num_updates=15610, lr=3.81532e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=74174
2022-10-16 16:13:36 - progress_bar.py[line:274] - INFO: epoch 001:  15640 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.9, ups=0.89, wpb=112.1, bsz=40, num_updates=15620, lr=3.81776e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74185
2022-10-16 16:13:47 - progress_bar.py[line:274] - INFO: epoch 001:  15650 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.9, ups=0.91, wpb=111.2, bsz=40, num_updates=15630, lr=3.82021e-05, gnorm=0.92, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=74196
2022-10-16 16:13:58 - progress_bar.py[line:274] - INFO: epoch 001:  15660 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=15640, lr=3.82265e-05, gnorm=0.99, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74207
2022-10-16 16:14:09 - progress_bar.py[line:274] - INFO: epoch 001:  15670 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=15650, lr=3.8251e-05, gnorm=1.021, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74218
2022-10-16 16:14:20 - progress_bar.py[line:274] - INFO: epoch 001:  15680 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.2, ups=0.9, wpb=110.8, bsz=40, num_updates=15660, lr=3.82754e-05, gnorm=0.924, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74229
2022-10-16 16:14:31 - progress_bar.py[line:274] - INFO: epoch 001:  15690 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102.6, ups=0.93, wpb=110.7, bsz=40, num_updates=15670, lr=3.82998e-05, gnorm=1.051, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74240
2022-10-16 16:14:42 - progress_bar.py[line:274] - INFO: epoch 001:  15700 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=15680, lr=3.83243e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74251
2022-10-16 16:14:53 - progress_bar.py[line:274] - INFO: epoch 001:  15710 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.8, ups=0.92, wpb=109.7, bsz=40, num_updates=15690, lr=3.83487e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74262
2022-10-16 16:15:04 - progress_bar.py[line:274] - INFO: epoch 001:  15720 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=15700, lr=3.83732e-05, gnorm=0.96, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74273
2022-10-16 16:15:15 - progress_bar.py[line:274] - INFO: epoch 001:  15730 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.9, ups=0.9, wpb=108.7, bsz=40, num_updates=15710, lr=3.83976e-05, gnorm=1.013, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74284
2022-10-16 16:15:26 - progress_bar.py[line:274] - INFO: epoch 001:  15740 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.6, ups=0.88, wpb=111.1, bsz=40, num_updates=15720, lr=3.84221e-05, gnorm=0.967, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74295
2022-10-16 16:15:38 - progress_bar.py[line:274] - INFO: epoch 001:  15750 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=15730, lr=3.84465e-05, gnorm=1.155, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74307
2022-10-16 16:15:49 - progress_bar.py[line:274] - INFO: epoch 001:  15760 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=15740, lr=3.84709e-05, gnorm=0.977, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74318
2022-10-16 16:16:00 - progress_bar.py[line:274] - INFO: epoch 001:  15770 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=15750, lr=3.84954e-05, gnorm=0.984, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74329
2022-10-16 16:16:11 - progress_bar.py[line:274] - INFO: epoch 001:  15780 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=15760, lr=3.85198e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74340
2022-10-16 16:16:22 - progress_bar.py[line:274] - INFO: epoch 001:  15790 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=15770, lr=3.85443e-05, gnorm=1.042, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74351
2022-10-16 16:16:33 - progress_bar.py[line:274] - INFO: epoch 001:  15800 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.2, ups=0.92, wpb=110.2, bsz=40, num_updates=15780, lr=3.85687e-05, gnorm=0.868, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74362
2022-10-16 16:16:44 - progress_bar.py[line:274] - INFO: epoch 001:  15810 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=15790, lr=3.85931e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74373
2022-10-16 16:16:56 - progress_bar.py[line:274] - INFO: epoch 001:  15820 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=15800, lr=3.86176e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74385
2022-10-16 16:17:07 - progress_bar.py[line:274] - INFO: epoch 001:  15830 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98, ups=0.9, wpb=108.4, bsz=40, num_updates=15810, lr=3.8642e-05, gnorm=1.07, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74396
2022-10-16 16:17:18 - progress_bar.py[line:274] - INFO: epoch 001:  15840 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=15820, lr=3.86665e-05, gnorm=1.081, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=74407
2022-10-16 16:17:29 - progress_bar.py[line:274] - INFO: epoch 001:  15850 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.6, ups=0.89, wpb=110.2, bsz=40, num_updates=15830, lr=3.86909e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74418
2022-10-16 16:17:40 - progress_bar.py[line:274] - INFO: epoch 001:  15860 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=15840, lr=3.87154e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74429
2022-10-16 16:17:52 - progress_bar.py[line:274] - INFO: epoch 001:  15870 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=15850, lr=3.87398e-05, gnorm=0.991, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=74441
2022-10-16 16:18:03 - progress_bar.py[line:274] - INFO: epoch 001:  15880 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101, ups=0.91, wpb=111.2, bsz=40, num_updates=15860, lr=3.87642e-05, gnorm=0.842, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74452
2022-10-16 16:18:14 - progress_bar.py[line:274] - INFO: epoch 001:  15890 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=15870, lr=3.87887e-05, gnorm=0.881, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74463
2022-10-16 16:18:25 - progress_bar.py[line:274] - INFO: epoch 001:  15900 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.5, ups=0.87, wpb=110, bsz=40, num_updates=15880, lr=3.88131e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74474
2022-10-16 16:18:36 - progress_bar.py[line:274] - INFO: epoch 001:  15910 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.6, ups=0.92, wpb=110.9, bsz=40, num_updates=15890, lr=3.88376e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74485
2022-10-16 16:18:47 - progress_bar.py[line:274] - INFO: epoch 001:  15920 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.5, ups=0.88, wpb=108.5, bsz=40, num_updates=15900, lr=3.8862e-05, gnorm=0.901, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74496
2022-10-16 16:18:59 - progress_bar.py[line:274] - INFO: epoch 001:  15930 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.1, ups=0.88, wpb=109.1, bsz=40, num_updates=15910, lr=3.88864e-05, gnorm=0.931, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74508
2022-10-16 16:19:10 - progress_bar.py[line:274] - INFO: epoch 001:  15940 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.1, ups=0.9, wpb=109.5, bsz=40, num_updates=15920, lr=3.89109e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74519
2022-10-16 16:19:21 - progress_bar.py[line:274] - INFO: epoch 001:  15950 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=15930, lr=3.89353e-05, gnorm=0.956, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74530
2022-10-16 16:19:33 - progress_bar.py[line:274] - INFO: epoch 001:  15960 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96, ups=0.88, wpb=109.3, bsz=40, num_updates=15940, lr=3.89598e-05, gnorm=1.198, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=74542
2022-10-16 16:19:44 - progress_bar.py[line:274] - INFO: epoch 001:  15970 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.8, ups=0.87, wpb=111.1, bsz=40, num_updates=15950, lr=3.89842e-05, gnorm=0.913, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74553
2022-10-16 16:19:55 - progress_bar.py[line:274] - INFO: epoch 001:  15980 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=15960, lr=3.90087e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74564
2022-10-16 16:20:06 - progress_bar.py[line:274] - INFO: epoch 001:  15990 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=15970, lr=3.90331e-05, gnorm=0.882, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74575
2022-10-16 16:20:18 - progress_bar.py[line:274] - INFO: epoch 001:  16000 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.6, ups=0.87, wpb=111.2, bsz=40, num_updates=15980, lr=3.90575e-05, gnorm=0.901, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74587
2022-10-16 16:20:29 - progress_bar.py[line:274] - INFO: epoch 001:  16010 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.6, ups=0.87, wpb=109.9, bsz=40, num_updates=15990, lr=3.9082e-05, gnorm=0.861, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74598
2022-10-16 16:20:41 - progress_bar.py[line:274] - INFO: epoch 001:  16020 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.88, wpb=112, bsz=40, num_updates=16000, lr=3.91064e-05, gnorm=0.994, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74610
2022-10-16 16:20:41 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 16:20:42 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 16:20:42 - train.py[line:551] - INFO: load:1.35 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 16:20:43 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 39.59 GiB total capacity; 8.38 GiB already allocated; 4.42 GiB free; 32.68 GiB reserved in total by PyTorch)
2022-10-16 16:20:43 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 5            |        cudaMalloc retries: 29        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8585 MB |    9719 MB |   10795 TB |   10795 TB |
|       from large pool |    8440 MB |    9574 MB |   10792 TB |   10792 TB |
|       from small pool |     144 MB |     145 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8585 MB |    9719 MB |   10795 TB |   10795 TB |
|       from large pool |    8440 MB |    9574 MB |   10792 TB |   10792 TB |
|       from small pool |     144 MB |     145 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   33462 MB |   33462 MB |  291208 MB |  257746 MB |
|       from large pool |   33316 MB |   33316 MB |  290800 MB |  257484 MB |
|       from small pool |     146 MB |     146 MB |     408 MB |     262 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24876 MB |   28950 MB |   10681 TB |   10681 TB |
|       from large pool |   24875 MB |   28948 MB |   10678 TB |   10678 TB |
|       from small pool |       1 MB |       1 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  502992 K  |  502988 K  |
|       from large pool |     563    |     575    |  161189 K  |  161189 K  |
|       from small pool |    3095    |    3114    |  341802 K  |  341799 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  502992 K  |  502988 K  |
|       from large pool |     563    |     575    |  161189 K  |  161189 K  |
|       from small pool |    3095    |    3114    |  341802 K  |  341799 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     121    |     121    |     632    |     511    |
|       from large pool |      48    |      48    |     428    |     380    |
|       from small pool |      73    |      73    |     204    |     131    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     104    |     107    |  360180 K  |  360180 K  |
|       from large pool |      55    |      55    |   61633 K  |   61633 K  |
|       from small pool |      49    |      56    |  298546 K  |  298546 K  |
|===========================================================================|

2022-10-16 16:20:43 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-16 16:20:43 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-16 16:23:14 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 16:23:14 - train.py[line:551] - INFO: load:1.37 valid_run:151.72 task_valid:147.65 collect_output:2.20
2022-10-16 16:25:42 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 16:25:42 - train.py[line:551] - INFO: load:1.39 valid_run:299.60 task_valid:290.84 collect_output:5.88
2022-10-16 16:28:14 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 16:28:14 - train.py[line:551] - INFO: load:1.42 valid_run:451.66 task_valid:434.11 collect_output:13.57
2022-10-16 16:30:45 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 16:30:45 - train.py[line:551] - INFO: load:1.45 valid_run:603.03 task_valid:580.28 collect_output:17.24
2022-10-16 16:33:20 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 16:33:20 - train.py[line:551] - INFO: load:1.48 valid_run:757.54 task_valid:729.09 collect_output:21.25
2022-10-16 16:35:55 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 16:35:55 - train.py[line:551] - INFO: load:1.50 valid_run:912.32 task_valid:875.95 collect_output:27.55
2022-10-16 16:38:29 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 16:38:29 - train.py[line:551] - INFO: load:1.53 valid_run:1066.01 task_valid:1022.66 collect_output:33.27
2022-10-16 16:41:02 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 16:41:02 - train.py[line:551] - INFO: load:1.56 valid_run:1219.21 task_valid:1165.24 collect_output:42.34
2022-10-16 16:43:36 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 16:43:36 - train.py[line:551] - INFO: load:1.59 valid_run:1373.00 task_valid:1313.22 collect_output:46.44
2022-10-16 16:46:10 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 16:46:10 - train.py[line:551] - INFO: load:1.63 valid_run:1526.85 task_valid:1460.66 collect_output:51.00
2022-10-16 16:48:44 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 16:48:44 - train.py[line:551] - INFO: load:1.66 valid_run:1680.90 task_valid:1609.12 collect_output:54.90
2022-10-16 16:51:16 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 16:51:16 - train.py[line:551] - INFO: load:1.69 valid_run:1833.39 task_valid:1756.36 collect_output:58.62
2022-10-16 16:53:50 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 16:53:50 - train.py[line:551] - INFO: load:1.72 valid_run:1987.08 task_valid:1901.37 collect_output:65.52
2022-10-16 16:56:25 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 16:56:25 - train.py[line:551] - INFO: load:1.76 valid_run:2142.03 task_valid:2050.82 collect_output:69.40
2022-10-16 16:59:00 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 16:59:00 - train.py[line:551] - INFO: load:1.79 valid_run:2296.51 task_valid:2200.68 collect_output:72.23
2022-10-16 17:01:34 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 17:01:34 - train.py[line:551] - INFO: load:1.83 valid_run:2450.72 task_valid:2348.79 collect_output:76.53
2022-10-16 17:04:09 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 17:04:09 - train.py[line:551] - INFO: load:1.86 valid_run:2606.07 task_valid:2497.59 collect_output:81.28
2022-10-16 17:06:41 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 17:06:41 - train.py[line:551] - INFO: load:1.88 valid_run:2757.93 task_valid:2645.68 collect_output:83.81
2022-10-16 17:09:10 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 17:09:10 - train.py[line:551] - INFO: load:1.91 valid_run:2906.61 task_valid:2787.98 collect_output:89.06
2022-10-16 17:11:40 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 17:11:40 - train.py[line:551] - INFO: load:1.95 valid_run:3056.83 task_valid:2933.40 collect_output:92.77
2022-10-16 17:14:14 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 17:14:14 - train.py[line:551] - INFO: load:1.98 valid_run:3210.15 task_valid:3079.57 collect_output:98.17
2022-10-16 17:16:46 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 17:16:46 - train.py[line:551] - INFO: load:2.02 valid_run:3362.05 task_valid:3226.40 collect_output:101.30
2022-10-16 17:19:21 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 17:19:21 - train.py[line:551] - INFO: load:2.05 valid_run:3517.31 task_valid:3376.60 collect_output:104.46
2022-10-16 17:21:55 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 17:21:55 - train.py[line:551] - INFO: load:2.08 valid_run:3671.03 task_valid:3525.49 collect_output:107.52

====================================================================================================
SGG eval:     R @ 50: 0.5405;     R @ 100: 0.5764;     R @ 500: 0.5970;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3722;    mR @ 100: 0.4053;    mR @ 500: 0.4274;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.7083) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9062) (playing:0.0000) (riding:0.8448) (says:0.0000) (sitting on:0.6882) (standing on:0.1453) (using:0.7000) (walking in:0.0000) (walking on:0.8153) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5405;     R @ 100: 0.5764;     R @ 500: 0.5970;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3722;    mR @ 100: 0.4053;    mR @ 500: 0.4274;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.7083) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9062) (playing:0.0000) (riding:0.8448) (says:0.0000) (sitting on:0.6882) (standing on:0.1453) (using:0.7000) (walking in:0.0000) (walking on:0.8153) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================

2022-10-16 17:24:28 - train.py[line:487] - INFO: 0.5764481792717087
2022-10-16 17:24:28 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 17:24:29 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.346 | loss_v1 0 | loss_v2 0 | nll_loss 0.195 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.576448 | ppl 1.14 | vqa_score 0.5101 | wps 117.3 | wpb 89.9 | bsz 30 | num_updates 16000 | best_R@100 0.581461
2022-10-16 17:24:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 16000 updates
2022-10-16 17:24:29 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_16000.pt
2022-10-16 17:24:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_16000.pt
2022-10-16 17:24:37 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 0.5764481792717087) (writing took 8.433970524929464 seconds)
2022-10-16 17:24:48 - progress_bar.py[line:274] - INFO: epoch 001:  16030 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=0.3, ups=0, wpb=109.7, bsz=40, num_updates=16010, lr=3.91309e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78457
2022-10-16 17:24:59 - progress_bar.py[line:274] - INFO: epoch 001:  16040 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.9, ups=0.93, wpb=109.9, bsz=40, num_updates=16020, lr=3.91553e-05, gnorm=0.839, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=78468
2022-10-16 17:25:10 - progress_bar.py[line:274] - INFO: epoch 001:  16050 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=103.9, ups=0.94, wpb=110.4, bsz=40, num_updates=16030, lr=3.91797e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78479
2022-10-16 17:25:21 - progress_bar.py[line:274] - INFO: epoch 001:  16060 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=16040, lr=3.92042e-05, gnorm=0.963, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78490
2022-10-16 17:25:32 - progress_bar.py[line:274] - INFO: epoch 001:  16070 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.7, ups=0.9, wpb=109.9, bsz=40, num_updates=16050, lr=3.92286e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78501
2022-10-16 17:25:43 - progress_bar.py[line:274] - INFO: epoch 001:  16080 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.5, ups=0.92, wpb=108.6, bsz=40, num_updates=16060, lr=3.92531e-05, gnorm=0.885, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78512
2022-10-16 17:25:54 - progress_bar.py[line:274] - INFO: epoch 001:  16090 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=16070, lr=3.92775e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78523
2022-10-16 17:26:06 - progress_bar.py[line:274] - INFO: epoch 001:  16100 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.4, ups=0.87, wpb=111.9, bsz=40, num_updates=16080, lr=3.9302e-05, gnorm=0.847, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78535
2022-10-16 17:26:17 - progress_bar.py[line:274] - INFO: epoch 001:  16110 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.4, ups=0.91, wpb=110.4, bsz=40, num_updates=16090, lr=3.93264e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78546
2022-10-16 17:26:28 - progress_bar.py[line:274] - INFO: epoch 001:  16120 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=16100, lr=3.93508e-05, gnorm=0.873, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78557
2022-10-16 17:26:39 - progress_bar.py[line:274] - INFO: epoch 001:  16130 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.8, ups=0.9, wpb=109.4, bsz=40, num_updates=16110, lr=3.93753e-05, gnorm=0.914, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78568
2022-10-16 17:26:50 - progress_bar.py[line:274] - INFO: epoch 001:  16140 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.9, ups=0.91, wpb=111.2, bsz=40, num_updates=16120, lr=3.93997e-05, gnorm=0.973, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78579
2022-10-16 17:27:02 - progress_bar.py[line:274] - INFO: epoch 001:  16150 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=16130, lr=3.94242e-05, gnorm=0.91, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=78591
2022-10-16 17:27:13 - progress_bar.py[line:274] - INFO: epoch 001:  16160 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.1, ups=0.91, wpb=109.4, bsz=40, num_updates=16140, lr=3.94486e-05, gnorm=0.89, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78602
2022-10-16 17:27:24 - progress_bar.py[line:274] - INFO: epoch 001:  16170 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=16150, lr=3.9473e-05, gnorm=0.918, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78613
2022-10-16 17:27:35 - progress_bar.py[line:274] - INFO: epoch 001:  16180 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.1, ups=0.89, wpb=109.8, bsz=40, num_updates=16160, lr=3.94975e-05, gnorm=0.878, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78624
2022-10-16 17:27:46 - progress_bar.py[line:274] - INFO: epoch 001:  16190 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.5, ups=0.91, wpb=111.2, bsz=40, num_updates=16170, lr=3.95219e-05, gnorm=0.962, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78635
2022-10-16 17:27:57 - progress_bar.py[line:274] - INFO: epoch 001:  16200 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=16180, lr=3.95464e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78646
2022-10-16 17:28:14 - progress_bar.py[line:274] - INFO: epoch 001:  16210 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=16190, lr=3.95708e-05, gnorm=0.873, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78657
2022-10-16 17:28:25 - progress_bar.py[line:274] - INFO: epoch 001:  16220 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.1, ups=0.89, wpb=108.3, bsz=40, num_updates=16200, lr=3.95952e-05, gnorm=0.818, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78674
2022-10-16 17:28:36 - progress_bar.py[line:274] - INFO: epoch 001:  16230 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=16210, lr=3.96197e-05, gnorm=0.899, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78685
2022-10-16 17:28:48 - progress_bar.py[line:274] - INFO: epoch 001:  16240 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=16220, lr=3.96441e-05, gnorm=0.918, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=78696
2022-10-16 17:28:59 - progress_bar.py[line:274] - INFO: epoch 001:  16250 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=16230, lr=3.96686e-05, gnorm=0.93, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78708
2022-10-16 17:29:10 - progress_bar.py[line:274] - INFO: epoch 001:  16260 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=16240, lr=3.9693e-05, gnorm=0.914, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78719
2022-10-16 17:29:21 - progress_bar.py[line:274] - INFO: epoch 001:  16270 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=16250, lr=3.97175e-05, gnorm=1.028, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78730
2022-10-16 17:29:32 - progress_bar.py[line:274] - INFO: epoch 001:  16280 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=16260, lr=3.97419e-05, gnorm=0.914, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78741
2022-10-16 17:29:43 - progress_bar.py[line:274] - INFO: epoch 001:  16290 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=16270, lr=3.97663e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78752
2022-10-16 17:29:54 - progress_bar.py[line:274] - INFO: epoch 001:  16300 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=16280, lr=3.97908e-05, gnorm=1.038, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78763
2022-10-16 17:30:02 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 17:30:07 - progress_bar.py[line:274] - INFO: epoch 001:  16311 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=90.2, ups=0.82, wpb=110.3, bsz=40, num_updates=16290, lr=3.98152e-05, gnorm=1.104, clip=30, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=78776
2022-10-16 17:30:18 - progress_bar.py[line:274] - INFO: epoch 001:  16321 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=16300, lr=3.98397e-05, gnorm=0.899, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78787
2022-10-16 17:30:29 - progress_bar.py[line:274] - INFO: epoch 001:  16331 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.2, ups=0.9, wpb=107.8, bsz=40, num_updates=16310, lr=3.98641e-05, gnorm=0.964, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78798
2022-10-16 17:30:40 - progress_bar.py[line:274] - INFO: epoch 001:  16341 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=16320, lr=3.98885e-05, gnorm=1.092, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78809
2022-10-16 17:30:51 - progress_bar.py[line:274] - INFO: epoch 001:  16351 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101, ups=0.92, wpb=110.3, bsz=40, num_updates=16330, lr=3.9913e-05, gnorm=0.961, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78820
2022-10-16 17:31:03 - progress_bar.py[line:274] - INFO: epoch 001:  16361 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.6, ups=0.89, wpb=111.3, bsz=40, num_updates=16340, lr=3.99374e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78832
2022-10-16 17:31:14 - progress_bar.py[line:274] - INFO: epoch 001:  16371 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=16350, lr=3.99619e-05, gnorm=0.962, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78843
2022-10-16 17:31:25 - progress_bar.py[line:274] - INFO: epoch 001:  16381 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=16360, lr=3.99863e-05, gnorm=1.009, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78854
2022-10-16 17:31:36 - progress_bar.py[line:274] - INFO: epoch 001:  16391 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.3, ups=0.87, wpb=110.5, bsz=40, num_updates=16370, lr=4.00108e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78865
2022-10-16 17:31:47 - progress_bar.py[line:274] - INFO: epoch 001:  16401 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=16380, lr=4.00352e-05, gnorm=0.894, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78876
2022-10-16 17:31:59 - progress_bar.py[line:274] - INFO: epoch 001:  16411 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=16390, lr=4.00596e-05, gnorm=0.877, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78887
2022-10-16 17:32:10 - progress_bar.py[line:274] - INFO: epoch 001:  16421 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.7, ups=0.87, wpb=109.9, bsz=40, num_updates=16400, lr=4.00841e-05, gnorm=0.939, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78899
2022-10-16 17:32:21 - progress_bar.py[line:274] - INFO: epoch 001:  16431 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=16410, lr=4.01085e-05, gnorm=1.032, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78910
2022-10-16 17:32:33 - progress_bar.py[line:274] - INFO: epoch 001:  16441 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=16420, lr=4.0133e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78922
2022-10-16 17:32:45 - progress_bar.py[line:274] - INFO: epoch 001:  16451 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95, ups=0.87, wpb=109.5, bsz=40, num_updates=16430, lr=4.01574e-05, gnorm=1.134, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78933
2022-10-16 17:32:56 - progress_bar.py[line:274] - INFO: epoch 001:  16461 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.7, ups=0.89, wpb=111.1, bsz=40, num_updates=16440, lr=4.01818e-05, gnorm=0.901, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78945
2022-10-16 17:33:07 - progress_bar.py[line:274] - INFO: epoch 001:  16471 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=16450, lr=4.02063e-05, gnorm=1.052, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78956
2022-10-16 17:33:18 - progress_bar.py[line:274] - INFO: epoch 001:  16481 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.3, ups=0.89, wpb=108.3, bsz=40, num_updates=16460, lr=4.02307e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78967
2022-10-16 17:33:29 - progress_bar.py[line:274] - INFO: epoch 001:  16491 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=103.3, ups=0.93, wpb=111, bsz=40, num_updates=16470, lr=4.02552e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78978
2022-10-16 17:33:40 - progress_bar.py[line:274] - INFO: epoch 001:  16501 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=16480, lr=4.02796e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78989
2022-10-16 17:33:52 - progress_bar.py[line:274] - INFO: epoch 001:  16511 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=16490, lr=4.03041e-05, gnorm=0.873, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79001
2022-10-16 17:34:03 - progress_bar.py[line:274] - INFO: epoch 001:  16521 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=16500, lr=4.03285e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79012
2022-10-16 17:34:14 - progress_bar.py[line:274] - INFO: epoch 001:  16531 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.87, wpb=112, bsz=40, num_updates=16510, lr=4.03529e-05, gnorm=0.842, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79023
2022-10-16 17:34:25 - progress_bar.py[line:274] - INFO: epoch 001:  16541 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.6, ups=0.93, wpb=109.3, bsz=40, num_updates=16520, lr=4.03774e-05, gnorm=1.025, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79034
2022-10-16 17:34:36 - progress_bar.py[line:274] - INFO: epoch 001:  16551 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=16530, lr=4.04018e-05, gnorm=0.825, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79045
2022-10-16 17:34:48 - progress_bar.py[line:274] - INFO: epoch 001:  16561 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=16540, lr=4.04263e-05, gnorm=0.912, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79057
2022-10-16 17:34:59 - progress_bar.py[line:274] - INFO: epoch 001:  16571 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=16550, lr=4.04507e-05, gnorm=1.016, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79068
2022-10-16 17:35:10 - progress_bar.py[line:274] - INFO: epoch 001:  16581 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.7, ups=0.89, wpb=110.3, bsz=40, num_updates=16560, lr=4.04751e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79079
2022-10-16 17:35:21 - progress_bar.py[line:274] - INFO: epoch 001:  16591 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.3, ups=0.89, wpb=108.8, bsz=40, num_updates=16570, lr=4.04996e-05, gnorm=0.984, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79090
2022-10-16 17:35:33 - progress_bar.py[line:274] - INFO: epoch 001:  16601 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=16580, lr=4.0524e-05, gnorm=1.107, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79102
2022-10-16 17:35:44 - progress_bar.py[line:274] - INFO: epoch 001:  16611 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=16590, lr=4.05485e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79113
2022-10-16 17:35:55 - progress_bar.py[line:274] - INFO: epoch 001:  16621 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=16600, lr=4.05729e-05, gnorm=1.015, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79124
2022-10-16 17:36:06 - progress_bar.py[line:274] - INFO: epoch 001:  16631 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.3, ups=0.9, wpb=110.8, bsz=40, num_updates=16610, lr=4.05974e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79135
2022-10-16 17:36:17 - progress_bar.py[line:274] - INFO: epoch 001:  16641 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.2, ups=0.91, wpb=110.1, bsz=40, num_updates=16620, lr=4.06218e-05, gnorm=0.921, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79146
2022-10-16 17:36:29 - progress_bar.py[line:274] - INFO: epoch 001:  16651 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=16630, lr=4.06462e-05, gnorm=0.827, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79158
2022-10-16 17:36:40 - progress_bar.py[line:274] - INFO: epoch 001:  16661 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.6, ups=0.9, wpb=111.3, bsz=40, num_updates=16640, lr=4.06707e-05, gnorm=0.987, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79169
2022-10-16 17:36:51 - progress_bar.py[line:274] - INFO: epoch 001:  16671 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.8, ups=0.9, wpb=109.3, bsz=40, num_updates=16650, lr=4.06951e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79180
2022-10-16 17:37:02 - progress_bar.py[line:274] - INFO: epoch 001:  16681 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=16660, lr=4.07196e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79191
2022-10-16 17:37:13 - progress_bar.py[line:274] - INFO: epoch 001:  16691 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=16670, lr=4.0744e-05, gnorm=0.982, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79202
2022-10-16 17:37:24 - progress_bar.py[line:274] - INFO: epoch 001:  16701 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.6, ups=0.92, wpb=109.8, bsz=40, num_updates=16680, lr=4.07684e-05, gnorm=1.016, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79213
2022-10-16 17:37:35 - progress_bar.py[line:274] - INFO: epoch 001:  16711 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.1, ups=0.89, wpb=112.1, bsz=40, num_updates=16690, lr=4.07929e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79224
2022-10-16 17:37:47 - progress_bar.py[line:274] - INFO: epoch 001:  16721 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.6, ups=0.91, wpb=109.4, bsz=40, num_updates=16700, lr=4.08173e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79235
2022-10-16 17:37:58 - progress_bar.py[line:274] - INFO: epoch 001:  16731 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.7, ups=0.88, wpb=111.5, bsz=40, num_updates=16710, lr=4.08418e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79247
2022-10-16 17:38:09 - progress_bar.py[line:274] - INFO: epoch 001:  16741 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.9, ups=0.91, wpb=110.3, bsz=40, num_updates=16720, lr=4.08662e-05, gnorm=0.998, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79258
2022-10-16 17:38:20 - progress_bar.py[line:274] - INFO: epoch 001:  16751 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=16730, lr=4.08906e-05, gnorm=0.92, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79269
2022-10-16 17:38:31 - progress_bar.py[line:274] - INFO: epoch 001:  16761 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.6, ups=0.92, wpb=108, bsz=40, num_updates=16740, lr=4.09151e-05, gnorm=1.011, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79280
2022-10-16 17:38:42 - progress_bar.py[line:274] - INFO: epoch 001:  16771 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.9, ups=0.92, wpb=110.1, bsz=40, num_updates=16750, lr=4.09395e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=79291
2022-10-16 17:38:53 - progress_bar.py[line:274] - INFO: epoch 001:  16781 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.7, ups=0.92, wpb=109.8, bsz=40, num_updates=16760, lr=4.0964e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79302
2022-10-16 17:39:04 - progress_bar.py[line:274] - INFO: epoch 001:  16791 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=16770, lr=4.09884e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79313
2022-10-16 17:39:16 - progress_bar.py[line:274] - INFO: epoch 001:  16801 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.4, ups=0.88, wpb=109.3, bsz=40, num_updates=16780, lr=4.10129e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79324
2022-10-16 17:39:27 - progress_bar.py[line:274] - INFO: epoch 001:  16811 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.5, ups=0.91, wpb=109.9, bsz=40, num_updates=16790, lr=4.10373e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79336
2022-10-16 17:39:38 - progress_bar.py[line:274] - INFO: epoch 001:  16821 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=16800, lr=4.10617e-05, gnorm=0.946, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79347
2022-10-16 17:39:49 - progress_bar.py[line:274] - INFO: epoch 001:  16831 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.5, ups=0.9, wpb=111.5, bsz=40, num_updates=16810, lr=4.10862e-05, gnorm=0.902, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79358
2022-10-16 17:40:00 - progress_bar.py[line:274] - INFO: epoch 001:  16841 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.2, ups=0.91, wpb=110.4, bsz=40, num_updates=16820, lr=4.11106e-05, gnorm=0.909, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79369
2022-10-16 17:40:11 - progress_bar.py[line:274] - INFO: epoch 001:  16851 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=16830, lr=4.11351e-05, gnorm=0.889, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79380
2022-10-16 17:40:22 - progress_bar.py[line:274] - INFO: epoch 001:  16861 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=102.2, ups=0.92, wpb=111.1, bsz=40, num_updates=16840, lr=4.11595e-05, gnorm=0.877, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79391
2022-10-16 17:40:33 - progress_bar.py[line:274] - INFO: epoch 001:  16871 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=16850, lr=4.11839e-05, gnorm=0.971, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79402
2022-10-16 17:40:45 - progress_bar.py[line:274] - INFO: epoch 001:  16881 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=16860, lr=4.12084e-05, gnorm=0.946, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79414
2022-10-16 17:40:56 - progress_bar.py[line:274] - INFO: epoch 001:  16891 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.3, ups=0.88, wpb=109.6, bsz=40, num_updates=16870, lr=4.12328e-05, gnorm=0.92, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79425
2022-10-16 17:41:07 - progress_bar.py[line:274] - INFO: epoch 001:  16901 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.4, ups=0.92, wpb=110.3, bsz=40, num_updates=16880, lr=4.12573e-05, gnorm=1.044, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79436
2022-10-16 17:41:18 - progress_bar.py[line:274] - INFO: epoch 001:  16911 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.2, ups=0.88, wpb=111.9, bsz=40, num_updates=16890, lr=4.12817e-05, gnorm=0.905, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79447
2022-10-16 17:41:30 - progress_bar.py[line:274] - INFO: epoch 001:  16921 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=16900, lr=4.13062e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79459
2022-10-16 17:41:41 - progress_bar.py[line:274] - INFO: epoch 001:  16931 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.5, ups=0.91, wpb=109.9, bsz=40, num_updates=16910, lr=4.13306e-05, gnorm=0.869, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79470
2022-10-16 17:41:52 - progress_bar.py[line:274] - INFO: epoch 001:  16941 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100, ups=0.91, wpb=110.1, bsz=40, num_updates=16920, lr=4.1355e-05, gnorm=0.997, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79481
2022-10-16 17:42:02 - progress_bar.py[line:274] - INFO: epoch 001:  16951 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=104.8, ups=0.95, wpb=109.9, bsz=40, num_updates=16930, lr=4.13795e-05, gnorm=0.86, clip=20, loss_scale=1024, train_wall=10, gb_free=10.4, ema_decay=0.9999, wall=79491
2022-10-16 17:42:13 - progress_bar.py[line:274] - INFO: epoch 001:  16961 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=16940, lr=4.14039e-05, gnorm=0.767, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79502
2022-10-16 17:42:25 - progress_bar.py[line:274] - INFO: epoch 001:  16971 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=16950, lr=4.14284e-05, gnorm=0.876, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=79514
2022-10-16 17:42:36 - progress_bar.py[line:274] - INFO: epoch 001:  16981 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=16960, lr=4.14528e-05, gnorm=0.888, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79525
2022-10-16 17:42:47 - progress_bar.py[line:274] - INFO: epoch 001:  16991 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.9, ups=0.88, wpb=108.9, bsz=40, num_updates=16970, lr=4.14772e-05, gnorm=0.889, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=79536
2022-10-16 17:42:58 - progress_bar.py[line:274] - INFO: epoch 001:  17001 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.9, wpb=109.2, bsz=40, num_updates=16980, lr=4.15017e-05, gnorm=0.926, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79547
2022-10-16 17:43:10 - progress_bar.py[line:274] - INFO: epoch 001:  17011 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.3, ups=0.88, wpb=110.1, bsz=40, num_updates=16990, lr=4.15261e-05, gnorm=0.898, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79559
2022-10-16 17:43:21 - progress_bar.py[line:274] - INFO: epoch 001:  17021 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.9, ups=0.89, wpb=107.6, bsz=40, num_updates=17000, lr=4.15506e-05, gnorm=1.007, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79570
2022-10-16 17:43:21 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 17:43:23 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 17:43:23 - train.py[line:551] - INFO: load:1.46 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 17:43:23 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 39.59 GiB total capacity; 8.38 GiB already allocated; 5.16 GiB free; 31.94 GiB reserved in total by PyTorch)
2022-10-16 17:43:23 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 6            |        cudaMalloc retries: 30        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8581 MB |    9714 MB |   11503 TB |   11503 TB |
|       from large pool |    8436 MB |    9569 MB |   11500 TB |   11500 TB |
|       from small pool |     144 MB |     145 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8581 MB |    9714 MB |   11503 TB |   11503 TB |
|       from large pool |    8436 MB |    9569 MB |   11500 TB |   11500 TB |
|       from small pool |     144 MB |     145 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32704 MB |   32704 MB |  291232 MB |  258528 MB |
|       from large pool |   32558 MB |   32558 MB |  290800 MB |  258242 MB |
|       from small pool |     146 MB |     146 MB |     432 MB |     286 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24122 MB |   28196 MB |   11728 TB |   11728 TB |
|       from large pool |   24121 MB |   28194 MB |   11724 TB |   11724 TB |
|       from small pool |       1 MB |       1 MB |       3 TB |       3 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  536170 K  |  536167 K  |
|       from large pool |     563    |     575    |  171755 K  |  171755 K  |
|       from small pool |    3095    |    3114    |  364414 K  |  364411 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  536170 K  |  536167 K  |
|       from large pool |     563    |     575    |  171755 K  |  171755 K  |
|       from small pool |    3095    |    3114    |  364414 K  |  364411 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     118    |     118    |     644    |     526    |
|       from large pool |      45    |      45    |     428    |     383    |
|       from small pool |      73    |      73    |     216    |     143    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      86    |      92    |  385246 K  |  385246 K  |
|       from large pool |      41    |      44    |   66766 K  |   66766 K  |
|       from small pool |      45    |      53    |  318479 K  |  318479 K  |
|===========================================================================|

2022-10-16 17:43:23 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-16 17:43:23 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-16 17:45:55 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 17:45:55 - train.py[line:551] - INFO: load:1.48 valid_run:151.93 task_valid:147.92 collect_output:2.04
2022-10-16 17:48:23 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 17:48:23 - train.py[line:551] - INFO: load:1.51 valid_run:299.96 task_valid:291.07 collect_output:5.91
2022-10-16 17:50:54 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 17:50:54 - train.py[line:551] - INFO: load:1.53 valid_run:451.45 task_valid:434.07 collect_output:13.36
2022-10-16 17:53:23 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 17:53:23 - train.py[line:551] - INFO: load:1.56 valid_run:600.00 task_valid:578.86 collect_output:16.13
2022-10-16 17:55:55 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 17:55:55 - train.py[line:551] - INFO: load:1.58 valid_run:751.88 task_valid:726.34 collect_output:19.52
2022-10-16 17:58:27 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 17:58:27 - train.py[line:551] - INFO: load:1.61 valid_run:903.54 task_valid:872.42 collect_output:23.92
2022-10-16 18:00:59 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 18:00:59 - train.py[line:551] - INFO: load:1.64 valid_run:1056.38 task_valid:1019.02 collect_output:29.03
2022-10-16 18:03:30 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 18:03:30 - train.py[line:551] - INFO: load:1.66 valid_run:1207.21 task_valid:1160.57 collect_output:37.23
2022-10-16 18:06:00 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 18:06:00 - train.py[line:551] - INFO: load:1.69 valid_run:1356.76 task_valid:1305.76 collect_output:40.43
2022-10-16 18:08:29 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 18:08:29 - train.py[line:551] - INFO: load:1.72 valid_run:1505.55 task_valid:1449.65 collect_output:44.22
2022-10-16 18:10:59 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 18:10:59 - train.py[line:551] - INFO: load:1.74 valid_run:1655.69 task_valid:1595.07 collect_output:47.84
2022-10-16 18:13:29 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 18:13:29 - train.py[line:551] - INFO: load:1.77 valid_run:1805.70 task_valid:1740.48 collect_output:51.33
2022-10-16 18:15:59 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 18:15:59 - train.py[line:551] - INFO: load:1.79 valid_run:1955.48 task_valid:1882.75 collect_output:57.75
2022-10-16 18:18:30 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 18:18:30 - train.py[line:551] - INFO: load:1.82 valid_run:2106.17 task_valid:2028.96 collect_output:61.09
2022-10-16 18:21:00 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 18:21:00 - train.py[line:551] - INFO: load:1.85 valid_run:2256.54 task_valid:2175.90 collect_output:63.41
2022-10-16 18:23:30 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 18:23:30 - train.py[line:551] - INFO: load:1.87 valid_run:2406.50 task_valid:2320.54 collect_output:67.60
2022-10-16 18:26:02 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 18:26:02 - train.py[line:551] - INFO: load:1.90 valid_run:2557.94 task_valid:2466.23 collect_output:72.21
2022-10-16 18:28:32 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 18:28:32 - train.py[line:551] - INFO: load:1.93 valid_run:2708.31 task_valid:2613.26 collect_output:74.53
2022-10-16 18:31:00 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 18:31:00 - train.py[line:551] - INFO: load:1.95 valid_run:2856.45 task_valid:2754.90 collect_output:79.98
2022-10-16 18:33:30 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 18:33:30 - train.py[line:551] - INFO: load:1.98 valid_run:3006.37 task_valid:2899.87 collect_output:83.93
2022-10-16 18:36:02 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 18:36:02 - train.py[line:551] - INFO: load:2.00 valid_run:3158.07 task_valid:3044.45 collect_output:90.04
2022-10-16 18:38:31 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 18:38:31 - train.py[line:551] - INFO: load:2.03 valid_run:3307.32 task_valid:3189.12 collect_output:93.60
2022-10-16 18:41:03 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 18:41:03 - train.py[line:551] - INFO: load:2.06 valid_run:3458.65 task_valid:3335.44 collect_output:97.57
2022-10-16 18:43:34 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 18:43:34 - train.py[line:551] - INFO: load:2.08 valid_run:3609.69 task_valid:3481.79 collect_output:101.27

====================================================================================================
SGG eval:     R @ 50: 0.5325;     R @ 100: 0.5686;     R @ 500: 0.5915;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3704;    mR @ 100: 0.4005;    mR @ 500: 0.4267;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.7083) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4645) (lying on:0.3500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9062) (playing:0.0000) (riding:0.8252) (says:0.0000) (sitting on:0.6950) (standing on:0.1553) (using:0.7000) (walking in:0.0000) (walking on:0.8153) (watching:0.2431) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5325;     R @ 100: 0.5686;     R @ 500: 0.5915;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3704;    mR @ 100: 0.4005;    mR @ 500: 0.4267;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.7083) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4645) (lying on:0.3500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9062) (playing:0.0000) (riding:0.8252) (says:0.0000) (sitting on:0.6950) (standing on:0.1553) (using:0.7000) (walking in:0.0000) (walking on:0.8153) (watching:0.2431) 
--------------------------------------------------------
====================================================================================================

2022-10-16 18:46:05 - train.py[line:487] - INFO: 0.568581512605042
2022-10-16 18:46:05 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 18:46:05 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.364 | loss_v1 0 | loss_v2 0 | nll_loss 0.213 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.568582 | ppl 1.16 | vqa_score 0.5 | wps 119.3 | wpb 89.9 | bsz 30 | num_updates 17000 | best_R@100 0.581461
2022-10-16 18:46:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 17000 updates
2022-10-16 18:46:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_17000.pt
2022-10-16 18:46:11 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_17000.pt
2022-10-16 18:46:14 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_17000.pt (epoch 1 @ 17000 updates, score 0.568581512605042) (writing took 8.466277406085283 seconds)
2022-10-16 18:46:25 - progress_bar.py[line:274] - INFO: epoch 001:  17031 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=0.3, ups=0, wpb=109, bsz=40, num_updates=17010, lr=4.1575e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83354
2022-10-16 18:46:37 - progress_bar.py[line:274] - INFO: epoch 001:  17041 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.88, wpb=111.7, bsz=40, num_updates=17020, lr=4.15995e-05, gnorm=0.872, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83366
2022-10-16 18:46:48 - progress_bar.py[line:274] - INFO: epoch 001:  17051 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=17030, lr=4.16239e-05, gnorm=0.842, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83377
2022-10-16 18:46:59 - progress_bar.py[line:274] - INFO: epoch 001:  17061 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102, ups=0.91, wpb=111.5, bsz=40, num_updates=17040, lr=4.16483e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83387
2022-10-16 18:47:10 - progress_bar.py[line:274] - INFO: epoch 001:  17071 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=17050, lr=4.16728e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83399
2022-10-16 18:47:21 - progress_bar.py[line:274] - INFO: epoch 001:  17081 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=17060, lr=4.16972e-05, gnorm=0.988, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83410
2022-10-16 18:47:32 - progress_bar.py[line:274] - INFO: epoch 001:  17091 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=17070, lr=4.17217e-05, gnorm=0.956, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83421
2022-10-16 18:47:44 - progress_bar.py[line:274] - INFO: epoch 001:  17101 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=17080, lr=4.17461e-05, gnorm=1.025, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83432
2022-10-16 18:47:55 - progress_bar.py[line:274] - INFO: epoch 001:  17111 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.9, ups=0.89, wpb=110.6, bsz=40, num_updates=17090, lr=4.17705e-05, gnorm=1.086, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83444
2022-10-16 18:48:06 - progress_bar.py[line:274] - INFO: epoch 001:  17121 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=17100, lr=4.1795e-05, gnorm=0.993, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83455
2022-10-16 18:48:17 - progress_bar.py[line:274] - INFO: epoch 001:  17131 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=17110, lr=4.18194e-05, gnorm=0.884, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83466
2022-10-16 18:48:28 - progress_bar.py[line:274] - INFO: epoch 001:  17141 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.2, ups=0.92, wpb=108.3, bsz=40, num_updates=17120, lr=4.18439e-05, gnorm=0.839, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83477
2022-10-16 18:48:40 - progress_bar.py[line:274] - INFO: epoch 001:  17151 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=17130, lr=4.18683e-05, gnorm=0.856, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83488
2022-10-16 18:48:50 - progress_bar.py[line:274] - INFO: epoch 001:  17161 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.2, ups=0.92, wpb=109.9, bsz=40, num_updates=17140, lr=4.18928e-05, gnorm=0.815, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83499
2022-10-16 18:49:02 - progress_bar.py[line:274] - INFO: epoch 001:  17171 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=17150, lr=4.19172e-05, gnorm=0.91, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83511
2022-10-16 18:49:13 - progress_bar.py[line:274] - INFO: epoch 001:  17181 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.3, ups=0.89, wpb=109.1, bsz=40, num_updates=17160, lr=4.19416e-05, gnorm=1.032, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83522
2022-10-16 18:49:25 - progress_bar.py[line:274] - INFO: epoch 001:  17191 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.8, ups=0.88, wpb=109.6, bsz=40, num_updates=17170, lr=4.19661e-05, gnorm=0.889, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83534
2022-10-16 18:49:36 - progress_bar.py[line:274] - INFO: epoch 001:  17201 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.6, ups=0.88, wpb=109.6, bsz=40, num_updates=17180, lr=4.19905e-05, gnorm=0.928, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83545
2022-10-16 18:49:48 - progress_bar.py[line:274] - INFO: epoch 001:  17211 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=17190, lr=4.2015e-05, gnorm=0.951, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83556
2022-10-16 18:49:59 - progress_bar.py[line:274] - INFO: epoch 001:  17221 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=17200, lr=4.20394e-05, gnorm=0.984, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83568
2022-10-16 18:50:11 - progress_bar.py[line:274] - INFO: epoch 001:  17231 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.8, ups=0.87, wpb=110.3, bsz=40, num_updates=17210, lr=4.20638e-05, gnorm=0.982, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83580
2022-10-16 18:50:22 - progress_bar.py[line:274] - INFO: epoch 001:  17241 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=17220, lr=4.20883e-05, gnorm=0.897, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83591
2022-10-16 18:50:33 - progress_bar.py[line:274] - INFO: epoch 001:  17251 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=17230, lr=4.21127e-05, gnorm=0.835, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83602
2022-10-16 18:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  17261 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.8, ups=0.93, wpb=110.9, bsz=40, num_updates=17240, lr=4.21372e-05, gnorm=0.814, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83613
2022-10-16 18:50:55 - progress_bar.py[line:274] - INFO: epoch 001:  17271 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=17250, lr=4.21616e-05, gnorm=0.902, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83624
2022-10-16 18:51:06 - progress_bar.py[line:274] - INFO: epoch 001:  17281 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=17260, lr=4.2186e-05, gnorm=1.03, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83635
2022-10-16 18:51:17 - progress_bar.py[line:274] - INFO: epoch 001:  17291 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=17270, lr=4.22105e-05, gnorm=1.041, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=83646
2022-10-16 18:51:28 - progress_bar.py[line:274] - INFO: epoch 001:  17301 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=17280, lr=4.22349e-05, gnorm=1.123, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83657
2022-10-16 18:51:39 - progress_bar.py[line:274] - INFO: epoch 001:  17311 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=17290, lr=4.22594e-05, gnorm=1.01, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83668
2022-10-16 18:51:49 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 18:51:52 - progress_bar.py[line:274] - INFO: epoch 001:  17322 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=90.5, ups=0.82, wpb=110.6, bsz=40, num_updates=17300, lr=4.22838e-05, gnorm=0.935, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=83681
2022-10-16 18:52:03 - progress_bar.py[line:274] - INFO: epoch 001:  17332 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=17310, lr=4.23083e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83692
2022-10-16 18:52:14 - progress_bar.py[line:274] - INFO: epoch 001:  17342 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.3, ups=0.92, wpb=110.4, bsz=40, num_updates=17320, lr=4.23327e-05, gnorm=1.054, clip=50, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=83703
2022-10-16 18:52:25 - progress_bar.py[line:274] - INFO: epoch 001:  17352 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.9, ups=0.87, wpb=109.4, bsz=40, num_updates=17330, lr=4.23571e-05, gnorm=0.903, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83714
2022-10-16 18:52:37 - progress_bar.py[line:274] - INFO: epoch 001:  17362 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.4, ups=0.87, wpb=109.5, bsz=40, num_updates=17340, lr=4.23816e-05, gnorm=0.968, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83726
2022-10-16 18:52:48 - progress_bar.py[line:274] - INFO: epoch 001:  17372 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=17350, lr=4.2406e-05, gnorm=0.887, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83737
2022-10-16 18:52:59 - progress_bar.py[line:274] - INFO: epoch 001:  17382 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=103.1, ups=0.92, wpb=112.4, bsz=40, num_updates=17360, lr=4.24305e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83748
2022-10-16 18:53:10 - progress_bar.py[line:274] - INFO: epoch 001:  17392 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=103.5, ups=0.93, wpb=111.2, bsz=40, num_updates=17370, lr=4.24549e-05, gnorm=1.099, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83759
2022-10-16 18:53:21 - progress_bar.py[line:274] - INFO: epoch 001:  17402 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.1, ups=0.88, wpb=109.7, bsz=40, num_updates=17380, lr=4.24793e-05, gnorm=0.975, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83770
2022-10-16 18:53:32 - progress_bar.py[line:274] - INFO: epoch 001:  17412 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=17390, lr=4.25038e-05, gnorm=0.868, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83781
2022-10-16 18:53:44 - progress_bar.py[line:274] - INFO: epoch 001:  17422 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=17400, lr=4.25282e-05, gnorm=0.873, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83792
2022-10-16 18:53:55 - progress_bar.py[line:274] - INFO: epoch 001:  17432 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.9, wpb=109.3, bsz=40, num_updates=17410, lr=4.25527e-05, gnorm=0.878, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83804
2022-10-16 18:54:06 - progress_bar.py[line:274] - INFO: epoch 001:  17442 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=17420, lr=4.25771e-05, gnorm=1.047, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83815
2022-10-16 18:54:17 - progress_bar.py[line:274] - INFO: epoch 001:  17452 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.4, ups=0.88, wpb=109.5, bsz=40, num_updates=17430, lr=4.26016e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83826
2022-10-16 18:54:29 - progress_bar.py[line:274] - INFO: epoch 001:  17462 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.6, ups=0.88, wpb=108.1, bsz=40, num_updates=17440, lr=4.2626e-05, gnorm=0.912, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83837
2022-10-16 18:54:40 - progress_bar.py[line:274] - INFO: epoch 001:  17472 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.4, ups=0.9, wpb=109.7, bsz=40, num_updates=17450, lr=4.26504e-05, gnorm=0.908, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83849
2022-10-16 18:54:51 - progress_bar.py[line:274] - INFO: epoch 001:  17482 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98, ups=0.9, wpb=108.8, bsz=40, num_updates=17460, lr=4.26749e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83860
2022-10-16 18:55:02 - progress_bar.py[line:274] - INFO: epoch 001:  17492 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=105.8, ups=0.94, wpb=112.4, bsz=40, num_updates=17470, lr=4.26993e-05, gnorm=0.943, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=83871
2022-10-16 18:55:13 - progress_bar.py[line:274] - INFO: epoch 001:  17502 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=17480, lr=4.27238e-05, gnorm=0.946, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83882
2022-10-16 18:55:24 - progress_bar.py[line:274] - INFO: epoch 001:  17512 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=17490, lr=4.27482e-05, gnorm=0.881, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83893
2022-10-16 18:55:35 - progress_bar.py[line:274] - INFO: epoch 001:  17522 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=17500, lr=4.27726e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83904
2022-10-16 18:55:47 - progress_bar.py[line:274] - INFO: epoch 001:  17532 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=17510, lr=4.27971e-05, gnorm=1.02, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83916
2022-10-16 18:55:58 - progress_bar.py[line:274] - INFO: epoch 001:  17542 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99, ups=0.91, wpb=108.7, bsz=40, num_updates=17520, lr=4.28215e-05, gnorm=0.918, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83927
2022-10-16 18:56:08 - progress_bar.py[line:274] - INFO: epoch 001:  17552 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102.3, ups=0.94, wpb=109.2, bsz=40, num_updates=17530, lr=4.2846e-05, gnorm=1.013, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83937
2022-10-16 18:56:20 - progress_bar.py[line:274] - INFO: epoch 001:  17562 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.6, ups=0.88, wpb=109.6, bsz=40, num_updates=17540, lr=4.28704e-05, gnorm=0.919, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83949
2022-10-16 18:56:31 - progress_bar.py[line:274] - INFO: epoch 001:  17572 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.7, ups=0.91, wpb=110, bsz=40, num_updates=17550, lr=4.28949e-05, gnorm=0.845, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83960
2022-10-16 18:56:42 - progress_bar.py[line:274] - INFO: epoch 001:  17582 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.8, ups=0.91, wpb=111.4, bsz=40, num_updates=17560, lr=4.29193e-05, gnorm=0.797, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83971
2022-10-16 18:56:53 - progress_bar.py[line:274] - INFO: epoch 001:  17592 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.6, ups=0.92, wpb=109.8, bsz=40, num_updates=17570, lr=4.29437e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83982
2022-10-16 18:57:04 - progress_bar.py[line:274] - INFO: epoch 001:  17602 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97, ups=0.89, wpb=109.5, bsz=40, num_updates=17580, lr=4.29682e-05, gnorm=0.924, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83993
2022-10-16 18:57:16 - progress_bar.py[line:274] - INFO: epoch 001:  17612 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=17590, lr=4.29926e-05, gnorm=0.931, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84004
2022-10-16 18:57:27 - progress_bar.py[line:274] - INFO: epoch 001:  17622 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=17600, lr=4.30171e-05, gnorm=0.894, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84016
2022-10-16 18:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  17632 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.3, ups=0.89, wpb=109, bsz=40, num_updates=17610, lr=4.30415e-05, gnorm=0.975, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84027
2022-10-16 18:57:49 - progress_bar.py[line:274] - INFO: epoch 001:  17642 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.1, ups=0.92, wpb=109.2, bsz=40, num_updates=17620, lr=4.30659e-05, gnorm=1.011, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84038
2022-10-16 18:58:00 - progress_bar.py[line:274] - INFO: epoch 001:  17652 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=17630, lr=4.30904e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84049
2022-10-16 18:58:11 - progress_bar.py[line:274] - INFO: epoch 001:  17662 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=17640, lr=4.31148e-05, gnorm=1.008, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84060
2022-10-16 18:58:22 - progress_bar.py[line:274] - INFO: epoch 001:  17672 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.7, ups=0.9, wpb=110.2, bsz=40, num_updates=17650, lr=4.31393e-05, gnorm=1.05, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84071
2022-10-16 18:58:33 - progress_bar.py[line:274] - INFO: epoch 001:  17682 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=104.7, ups=0.95, wpb=110.7, bsz=40, num_updates=17660, lr=4.31637e-05, gnorm=0.928, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84082
2022-10-16 18:58:44 - progress_bar.py[line:274] - INFO: epoch 001:  17692 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.2, ups=0.91, wpb=109.8, bsz=40, num_updates=17670, lr=4.31882e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84093
2022-10-16 18:58:56 - progress_bar.py[line:274] - INFO: epoch 001:  17702 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=17680, lr=4.32126e-05, gnorm=1.127, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84105
2022-10-16 18:59:07 - progress_bar.py[line:274] - INFO: epoch 001:  17712 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=17690, lr=4.3237e-05, gnorm=1.06, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84116
2022-10-16 18:59:18 - progress_bar.py[line:274] - INFO: epoch 001:  17722 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=17700, lr=4.32615e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84127
2022-10-16 18:59:30 - progress_bar.py[line:274] - INFO: epoch 001:  17732 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.8, ups=0.87, wpb=109.5, bsz=40, num_updates=17710, lr=4.32859e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84139
2022-10-16 18:59:41 - progress_bar.py[line:274] - INFO: epoch 001:  17742 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=17720, lr=4.33104e-05, gnorm=1.003, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84150
2022-10-16 18:59:52 - progress_bar.py[line:274] - INFO: epoch 001:  17752 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.8, ups=0.93, wpb=108.5, bsz=40, num_updates=17730, lr=4.33348e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84161
2022-10-16 19:00:03 - progress_bar.py[line:274] - INFO: epoch 001:  17762 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.6, ups=0.93, wpb=109.4, bsz=40, num_updates=17740, lr=4.33592e-05, gnorm=1, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84171
2022-10-16 19:00:14 - progress_bar.py[line:274] - INFO: epoch 001:  17772 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=17750, lr=4.33837e-05, gnorm=0.809, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84183
2022-10-16 19:00:25 - progress_bar.py[line:274] - INFO: epoch 001:  17782 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.3, ups=0.88, wpb=111.2, bsz=40, num_updates=17760, lr=4.34081e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84194
2022-10-16 19:00:36 - progress_bar.py[line:274] - INFO: epoch 001:  17792 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.3, ups=0.93, wpb=109.6, bsz=40, num_updates=17770, lr=4.34326e-05, gnorm=1.196, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84205
2022-10-16 19:00:47 - progress_bar.py[line:274] - INFO: epoch 001:  17802 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.5, ups=0.91, wpb=111.1, bsz=40, num_updates=17780, lr=4.3457e-05, gnorm=0.931, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84216
2022-10-16 19:00:58 - progress_bar.py[line:274] - INFO: epoch 001:  17812 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96, ups=0.88, wpb=109.2, bsz=40, num_updates=17790, lr=4.34814e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84227
2022-10-16 19:01:10 - progress_bar.py[line:274] - INFO: epoch 001:  17822 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.2, ups=0.88, wpb=112.2, bsz=40, num_updates=17800, lr=4.35059e-05, gnorm=0.962, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84239
2022-10-16 19:01:21 - progress_bar.py[line:274] - INFO: epoch 001:  17832 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=17810, lr=4.35303e-05, gnorm=0.891, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84250
2022-10-16 19:01:32 - progress_bar.py[line:274] - INFO: epoch 001:  17842 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=17820, lr=4.35548e-05, gnorm=0.92, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84261
2022-10-16 19:01:43 - progress_bar.py[line:274] - INFO: epoch 001:  17852 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.8, ups=0.9, wpb=110.4, bsz=40, num_updates=17830, lr=4.35792e-05, gnorm=1.073, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84272
2022-10-16 19:01:54 - progress_bar.py[line:274] - INFO: epoch 001:  17862 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=104.2, ups=0.94, wpb=110.6, bsz=40, num_updates=17840, lr=4.36037e-05, gnorm=0.951, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84283
2022-10-16 19:02:05 - progress_bar.py[line:274] - INFO: epoch 001:  17872 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.8, ups=0.9, wpb=110.2, bsz=40, num_updates=17850, lr=4.36281e-05, gnorm=0.991, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84294
2022-10-16 19:02:17 - progress_bar.py[line:274] - INFO: epoch 001:  17882 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=17860, lr=4.36525e-05, gnorm=0.966, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84305
2022-10-16 19:02:28 - progress_bar.py[line:274] - INFO: epoch 001:  17892 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.2, ups=0.88, wpb=108.9, bsz=40, num_updates=17870, lr=4.3677e-05, gnorm=0.921, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84317
2022-10-16 19:02:39 - progress_bar.py[line:274] - INFO: epoch 001:  17902 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.7, ups=0.89, wpb=108.1, bsz=40, num_updates=17880, lr=4.37014e-05, gnorm=0.994, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84328
2022-10-16 19:02:50 - progress_bar.py[line:274] - INFO: epoch 001:  17912 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.3, ups=0.9, wpb=111.1, bsz=40, num_updates=17890, lr=4.37259e-05, gnorm=0.892, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84339
2022-10-16 19:03:01 - progress_bar.py[line:274] - INFO: epoch 001:  17922 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.5, ups=0.91, wpb=110.7, bsz=40, num_updates=17900, lr=4.37503e-05, gnorm=0.861, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84350
2022-10-16 19:03:13 - progress_bar.py[line:274] - INFO: epoch 001:  17932 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=17910, lr=4.37747e-05, gnorm=0.851, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84361
2022-10-16 19:03:24 - progress_bar.py[line:274] - INFO: epoch 001:  17942 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.4, ups=0.88, wpb=109.5, bsz=40, num_updates=17920, lr=4.37992e-05, gnorm=0.965, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84373
2022-10-16 19:03:35 - progress_bar.py[line:274] - INFO: epoch 001:  17952 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100, ups=0.92, wpb=109, bsz=40, num_updates=17930, lr=4.38236e-05, gnorm=1.048, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84384
2022-10-16 19:03:46 - progress_bar.py[line:274] - INFO: epoch 001:  17962 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=17940, lr=4.38481e-05, gnorm=1.001, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84395
2022-10-16 19:03:58 - progress_bar.py[line:274] - INFO: epoch 001:  17972 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.1, ups=0.88, wpb=109.2, bsz=40, num_updates=17950, lr=4.38725e-05, gnorm=0.973, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84407
2022-10-16 19:04:09 - progress_bar.py[line:274] - INFO: epoch 001:  17982 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.8, ups=0.87, wpb=110.9, bsz=40, num_updates=17960, lr=4.3897e-05, gnorm=0.788, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84418
2022-10-16 19:04:20 - progress_bar.py[line:274] - INFO: epoch 001:  17992 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=17970, lr=4.39214e-05, gnorm=0.829, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84429
2022-10-16 19:04:31 - progress_bar.py[line:274] - INFO: epoch 001:  18002 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.4, ups=0.91, wpb=109.4, bsz=40, num_updates=17980, lr=4.39458e-05, gnorm=0.833, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84440
2022-10-16 19:04:43 - progress_bar.py[line:274] - INFO: epoch 001:  18012 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=17990, lr=4.39703e-05, gnorm=0.788, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84451
2022-10-16 19:04:54 - progress_bar.py[line:274] - INFO: epoch 001:  18022 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=94.3, ups=0.87, wpb=108.5, bsz=40, num_updates=18000, lr=4.39947e-05, gnorm=0.873, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84463
2022-10-16 19:04:54 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 19:04:55 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 19:04:55 - train.py[line:551] - INFO: load:1.10 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 19:07:28 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 19:07:28 - train.py[line:551] - INFO: load:1.12 valid_run:152.30 task_valid:148.82 collect_output:2.47
2022-10-16 19:09:56 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 19:09:56 - train.py[line:551] - INFO: load:1.15 valid_run:300.39 task_valid:292.21 collect_output:6.16
2022-10-16 19:12:28 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 19:12:28 - train.py[line:551] - INFO: load:1.17 valid_run:452.33 task_valid:435.77 collect_output:13.31
2022-10-16 19:14:57 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 19:14:57 - train.py[line:551] - INFO: load:1.20 valid_run:601.51 task_valid:581.18 collect_output:15.97
2022-10-16 19:17:30 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 19:17:30 - train.py[line:551] - INFO: load:1.23 valid_run:753.77 task_valid:729.06 collect_output:19.22
2022-10-16 19:20:01 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 19:20:01 - train.py[line:551] - INFO: load:1.25 valid_run:905.61 task_valid:875.26 collect_output:23.76
2022-10-16 19:22:35 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 19:22:35 - train.py[line:551] - INFO: load:1.28 valid_run:1058.79 task_valid:1021.91 collect_output:29.12
2022-10-16 19:25:06 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 19:25:06 - train.py[line:551] - INFO: load:1.31 valid_run:1209.74 task_valid:1163.45 collect_output:37.44
2022-10-16 19:27:35 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 19:27:35 - train.py[line:551] - INFO: load:1.33 valid_run:1359.15 task_valid:1308.42 collect_output:40.76
2022-10-16 19:30:04 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 19:30:04 - train.py[line:551] - INFO: load:1.36 valid_run:1507.63 task_valid:1451.99 collect_output:44.52
2022-10-16 19:32:34 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 19:32:34 - train.py[line:551] - INFO: load:1.39 valid_run:1657.93 task_valid:1597.51 collect_output:48.19
2022-10-16 19:35:04 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 19:35:04 - train.py[line:551] - INFO: load:1.42 valid_run:1807.93 task_valid:1743.01 collect_output:51.56
2022-10-16 19:37:34 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 19:37:34 - train.py[line:551] - INFO: load:1.44 valid_run:1957.83 task_valid:1885.11 collect_output:58.24
2022-10-16 19:40:05 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 19:40:05 - train.py[line:551] - INFO: load:1.47 valid_run:2108.48 task_valid:2030.97 collect_output:61.89
2022-10-16 19:42:35 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 19:42:35 - train.py[line:551] - INFO: load:1.50 valid_run:2258.51 task_valid:2177.60 collect_output:64.26
2022-10-16 19:45:05 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 19:45:05 - train.py[line:551] - INFO: load:1.52 valid_run:2408.44 task_valid:2321.80 collect_output:68.97
2022-10-16 19:47:37 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 19:47:37 - train.py[line:551] - INFO: load:1.55 valid_run:2560.03 task_valid:2467.26 collect_output:74.12
2022-10-16 19:50:07 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 19:50:07 - train.py[line:551] - INFO: load:1.57 valid_run:2710.35 task_valid:2614.12 collect_output:76.58
2022-10-16 19:52:35 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 19:52:35 - train.py[line:551] - INFO: load:1.60 valid_run:2858.76 task_valid:2756.21 collect_output:81.88
2022-10-16 19:55:06 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 19:55:06 - train.py[line:551] - INFO: load:1.62 valid_run:3008.94 task_valid:2901.19 collect_output:86.09
2022-10-16 19:57:38 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 19:57:38 - train.py[line:551] - INFO: load:1.65 valid_run:3160.73 task_valid:3045.61 collect_output:92.45
2022-10-16 20:00:07 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 20:00:07 - train.py[line:551] - INFO: load:1.67 valid_run:3309.82 task_valid:3189.98 collect_output:96.17
2022-10-16 20:02:38 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 20:02:38 - train.py[line:551] - INFO: load:1.70 valid_run:3460.89 task_valid:3336.12 collect_output:100.10
2022-10-16 20:05:09 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 20:05:09 - train.py[line:551] - INFO: load:1.73 valid_run:3612.38 task_valid:3482.73 collect_output:103.98

====================================================================================================
SGG eval:     R @ 50: 0.5305;     R @ 100: 0.5622;     R @ 500: 0.5862;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3554;    mR @ 100: 0.3877;    mR @ 500: 0.4137;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6171) (covered in:0.7083) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4581) (lying on:0.1500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8854) (playing:0.0000) (riding:0.8268) (says:0.0000) (sitting on:0.6950) (standing on:0.1603) (using:0.7000) (walking in:0.0000) (walking on:0.7748) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2022-10-16 20:07:40 - train.py[line:487] - INFO: 0.5621815126050419

====================================================================================================
SGG eval:     R @ 50: 0.5305;     R @ 100: 0.5622;     R @ 500: 0.5862;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3554;    mR @ 100: 0.3877;    mR @ 500: 0.4137;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6171) (covered in:0.7083) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4581) (lying on:0.1500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8854) (playing:0.0000) (riding:0.8268) (says:0.0000) (sitting on:0.6950) (standing on:0.1603) (using:0.7000) (walking in:0.0000) (walking on:0.7748) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2022-10-16 20:07:40 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 20:07:41 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.349 | loss_v1 0 | loss_v2 0 | nll_loss 0.191 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.562182 | ppl 1.14 | vqa_score 0.4989 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 18000 | best_R@100 0.581461
2022-10-16 20:07:41 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 18000 updates
2022-10-16 20:07:41 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_18000.pt
2022-10-16 20:07:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_18000.pt
2022-10-16 20:07:49 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 0.5621815126050419) (writing took 8.589871169999242 seconds)
2022-10-16 20:08:00 - progress_bar.py[line:274] - INFO: epoch 001:  18032 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=0.3, ups=0, wpb=108.9, bsz=40, num_updates=18010, lr=4.40192e-05, gnorm=1.165, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88249
2022-10-16 20:08:12 - progress_bar.py[line:274] - INFO: epoch 001:  18042 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.7, ups=0.88, wpb=109.8, bsz=40, num_updates=18020, lr=4.40436e-05, gnorm=0.904, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88261
2022-10-16 20:08:23 - progress_bar.py[line:274] - INFO: epoch 001:  18052 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=18030, lr=4.4068e-05, gnorm=0.981, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88272
2022-10-16 20:08:34 - progress_bar.py[line:274] - INFO: epoch 001:  18062 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=18040, lr=4.40925e-05, gnorm=1.014, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88283
2022-10-16 20:08:45 - progress_bar.py[line:274] - INFO: epoch 001:  18072 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=18050, lr=4.41169e-05, gnorm=0.881, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88294
2022-10-16 20:08:56 - progress_bar.py[line:274] - INFO: epoch 001:  18082 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.91, wpb=109.5, bsz=40, num_updates=18060, lr=4.41414e-05, gnorm=0.909, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88305
2022-10-16 20:09:08 - progress_bar.py[line:274] - INFO: epoch 001:  18092 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.1, ups=0.89, wpb=108.9, bsz=40, num_updates=18070, lr=4.41658e-05, gnorm=0.929, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88317
2022-10-16 20:09:19 - progress_bar.py[line:274] - INFO: epoch 001:  18102 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.7, ups=0.88, wpb=109.8, bsz=40, num_updates=18080, lr=4.41903e-05, gnorm=0.82, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88328
2022-10-16 20:09:30 - progress_bar.py[line:274] - INFO: epoch 001:  18112 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.4, ups=0.9, wpb=111.3, bsz=40, num_updates=18090, lr=4.42147e-05, gnorm=0.832, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88339
2022-10-16 20:09:41 - progress_bar.py[line:274] - INFO: epoch 001:  18122 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100, ups=0.91, wpb=109.9, bsz=40, num_updates=18100, lr=4.42391e-05, gnorm=0.878, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88350
2022-10-16 20:09:53 - progress_bar.py[line:274] - INFO: epoch 001:  18132 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.6, ups=0.87, wpb=109, bsz=40, num_updates=18110, lr=4.42636e-05, gnorm=0.919, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88362
2022-10-16 20:10:04 - progress_bar.py[line:274] - INFO: epoch 001:  18142 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.2, ups=0.9, wpb=109.3, bsz=40, num_updates=18120, lr=4.4288e-05, gnorm=0.98, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88373
2022-10-16 20:10:15 - progress_bar.py[line:274] - INFO: epoch 001:  18152 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=18130, lr=4.43125e-05, gnorm=0.935, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=88384
2022-10-16 20:10:27 - progress_bar.py[line:274] - INFO: epoch 001:  18162 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=18140, lr=4.43369e-05, gnorm=0.871, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88395
2022-10-16 20:10:38 - progress_bar.py[line:274] - INFO: epoch 001:  18172 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=18150, lr=4.43613e-05, gnorm=0.931, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88407
2022-10-16 20:10:49 - progress_bar.py[line:274] - INFO: epoch 001:  18182 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=18160, lr=4.43858e-05, gnorm=1.023, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88418
2022-10-16 20:11:00 - progress_bar.py[line:274] - INFO: epoch 001:  18192 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=18170, lr=4.44102e-05, gnorm=0.965, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=88429
2022-10-16 20:11:12 - progress_bar.py[line:274] - INFO: epoch 001:  18202 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.3, ups=0.88, wpb=109.4, bsz=40, num_updates=18180, lr=4.44347e-05, gnorm=0.898, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88441
2022-10-16 20:11:23 - progress_bar.py[line:274] - INFO: epoch 001:  18212 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=18190, lr=4.44591e-05, gnorm=0.862, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=88452
2022-10-16 20:11:34 - progress_bar.py[line:274] - INFO: epoch 001:  18222 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.9, ups=0.89, wpb=109.5, bsz=40, num_updates=18200, lr=4.44836e-05, gnorm=0.891, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=88463
2022-10-16 20:11:45 - progress_bar.py[line:274] - INFO: epoch 001:  18232 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.2, ups=0.91, wpb=110.5, bsz=40, num_updates=18210, lr=4.4508e-05, gnorm=0.87, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=88474
2022-10-16 20:11:56 - progress_bar.py[line:274] - INFO: epoch 001:  18242 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.9, ups=0.9, wpb=109.3, bsz=40, num_updates=18220, lr=4.45324e-05, gnorm=0.876, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88485
2022-10-16 20:12:10 - progress_bar.py[line:274] - INFO: epoch 001:  18252 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.5, ups=0.87, wpb=108.5, bsz=40, num_updates=18230, lr=4.45569e-05, gnorm=0.942, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88497
2022-10-16 20:12:21 - progress_bar.py[line:274] - INFO: epoch 001:  18262 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.8, ups=0.88, wpb=109.3, bsz=40, num_updates=18240, lr=4.45813e-05, gnorm=1.042, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=88510
2022-10-16 20:12:32 - progress_bar.py[line:274] - INFO: epoch 001:  18272 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.9, ups=0.9, wpb=110.5, bsz=40, num_updates=18250, lr=4.46058e-05, gnorm=0.917, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=88521
2022-10-16 20:12:43 - progress_bar.py[line:274] - INFO: epoch 001:  18282 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102.4, ups=0.93, wpb=110.3, bsz=40, num_updates=18260, lr=4.46302e-05, gnorm=0.854, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88532
2022-10-16 20:12:54 - progress_bar.py[line:274] - INFO: epoch 001:  18292 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=18270, lr=4.46546e-05, gnorm=0.998, clip=30, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=88543
2022-10-16 20:13:06 - progress_bar.py[line:274] - INFO: epoch 001:  18302 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=18280, lr=4.46791e-05, gnorm=0.887, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88554
2022-10-16 20:13:17 - progress_bar.py[line:274] - INFO: epoch 001:  18312 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.2, ups=0.87, wpb=110.4, bsz=40, num_updates=18290, lr=4.47035e-05, gnorm=0.879, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88566
2022-10-16 20:13:28 - progress_bar.py[line:274] - INFO: epoch 001:  18322 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.4, ups=0.9, wpb=110.7, bsz=40, num_updates=18300, lr=4.4728e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88577
2022-10-16 20:13:39 - progress_bar.py[line:274] - INFO: epoch 001:  18332 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.6, ups=0.9, wpb=110.1, bsz=40, num_updates=18310, lr=4.47524e-05, gnorm=0.906, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=88588
2022-10-16 20:13:50 - progress_bar.py[line:274] - INFO: epoch 001:  18342 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.3, ups=0.91, wpb=111, bsz=40, num_updates=18320, lr=4.47768e-05, gnorm=0.987, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88599
2022-10-16 20:14:02 - progress_bar.py[line:274] - INFO: epoch 001:  18352 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.6, ups=0.88, wpb=108.4, bsz=40, num_updates=18330, lr=4.48013e-05, gnorm=1.011, clip=40, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88611
2022-10-16 20:14:13 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-16 20:14:14 - progress_bar.py[line:274] - INFO: epoch 001:  18363 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=88.3, ups=0.8, wpb=110.5, bsz=40, num_updates=18340, lr=4.48257e-05, gnorm=0.89, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=88623
2022-10-16 20:14:26 - progress_bar.py[line:274] - INFO: epoch 001:  18373 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98, ups=0.89, wpb=109.5, bsz=40, num_updates=18350, lr=4.48502e-05, gnorm=0.964, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88635
2022-10-16 20:14:37 - progress_bar.py[line:274] - INFO: epoch 001:  18383 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=18360, lr=4.48746e-05, gnorm=0.913, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=88646
2022-10-16 20:14:48 - progress_bar.py[line:274] - INFO: epoch 001:  18393 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.4, ups=0.91, wpb=112, bsz=40, num_updates=18370, lr=4.48991e-05, gnorm=0.89, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88657
2022-10-16 20:14:59 - progress_bar.py[line:274] - INFO: epoch 001:  18403 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=18380, lr=4.49235e-05, gnorm=1.111, clip=40, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=88668
2022-10-16 20:15:10 - progress_bar.py[line:274] - INFO: epoch 001:  18413 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=18390, lr=4.49479e-05, gnorm=0.894, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88679
2022-10-16 20:15:21 - progress_bar.py[line:274] - INFO: epoch 001:  18423 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=18400, lr=4.49724e-05, gnorm=0.961, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88690
2022-10-16 20:15:33 - progress_bar.py[line:274] - INFO: epoch 001:  18433 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=18410, lr=4.49968e-05, gnorm=0.895, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88702
2022-10-16 20:15:44 - progress_bar.py[line:274] - INFO: epoch 001:  18443 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=18420, lr=4.50213e-05, gnorm=0.842, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88713
2022-10-16 20:15:55 - progress_bar.py[line:274] - INFO: epoch 001:  18453 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.6, ups=0.91, wpb=111.3, bsz=40, num_updates=18430, lr=4.50457e-05, gnorm=0.843, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88724
2022-10-16 20:16:06 - progress_bar.py[line:274] - INFO: epoch 001:  18463 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=18440, lr=4.50701e-05, gnorm=0.885, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88735
2022-10-16 20:16:17 - progress_bar.py[line:274] - INFO: epoch 001:  18473 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=18450, lr=4.50946e-05, gnorm=0.825, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88746
2022-10-16 20:16:29 - progress_bar.py[line:274] - INFO: epoch 001:  18483 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.2, ups=0.88, wpb=109.2, bsz=40, num_updates=18460, lr=4.5119e-05, gnorm=0.965, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=88758
2022-10-16 20:16:40 - progress_bar.py[line:274] - INFO: epoch 001:  18493 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=18470, lr=4.51435e-05, gnorm=0.847, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88769
2022-10-16 20:16:51 - progress_bar.py[line:274] - INFO: epoch 001:  18503 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=18480, lr=4.51679e-05, gnorm=0.851, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88780
2022-10-16 20:17:02 - progress_bar.py[line:274] - INFO: epoch 001:  18513 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=18490, lr=4.51924e-05, gnorm=0.806, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=88791
2022-10-16 20:17:14 - progress_bar.py[line:274] - INFO: epoch 001:  18523 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.91, wpb=109.7, bsz=40, num_updates=18500, lr=4.52168e-05, gnorm=0.941, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88802
2022-10-16 20:17:15 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 20:17:26 - progress_bar.py[line:274] - INFO: epoch 001:  18534 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=88.1, ups=0.81, wpb=108.9, bsz=40, num_updates=18510, lr=4.52412e-05, gnorm=0.918, clip=60, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=88815
2022-10-16 20:17:37 - progress_bar.py[line:274] - INFO: epoch 001:  18544 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=18520, lr=4.52657e-05, gnorm=0.916, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88826
2022-10-16 20:17:49 - progress_bar.py[line:274] - INFO: epoch 001:  18554 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=18530, lr=4.52901e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=88837
2022-10-16 20:18:00 - progress_bar.py[line:274] - INFO: epoch 001:  18564 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=18540, lr=4.53146e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88849
2022-10-16 20:18:11 - progress_bar.py[line:274] - INFO: epoch 001:  18574 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=18550, lr=4.5339e-05, gnorm=0.888, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88860
2022-10-16 20:18:22 - progress_bar.py[line:274] - INFO: epoch 001:  18584 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=18560, lr=4.53634e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88871
2022-10-16 20:18:33 - progress_bar.py[line:274] - INFO: epoch 001:  18594 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.1, ups=0.91, wpb=109.3, bsz=40, num_updates=18570, lr=4.53879e-05, gnorm=0.999, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88882
2022-10-16 20:18:44 - progress_bar.py[line:274] - INFO: epoch 001:  18604 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99, ups=0.89, wpb=111.1, bsz=40, num_updates=18580, lr=4.54123e-05, gnorm=0.87, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88893
2022-10-16 20:18:55 - progress_bar.py[line:274] - INFO: epoch 001:  18614 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.2, ups=0.93, wpb=110.1, bsz=40, num_updates=18590, lr=4.54368e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88904
2022-10-16 20:19:06 - progress_bar.py[line:274] - INFO: epoch 001:  18624 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=18600, lr=4.54612e-05, gnorm=0.894, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88915
2022-10-16 20:19:17 - progress_bar.py[line:274] - INFO: epoch 001:  18634 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.4, ups=0.91, wpb=110.5, bsz=40, num_updates=18610, lr=4.54857e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=88926
2022-10-16 20:19:29 - progress_bar.py[line:274] - INFO: epoch 001:  18644 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=18620, lr=4.55101e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88938
2022-10-16 20:19:40 - progress_bar.py[line:274] - INFO: epoch 001:  18654 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=18630, lr=4.55345e-05, gnorm=1.024, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=88949
2022-10-16 20:19:51 - progress_bar.py[line:274] - INFO: epoch 001:  18664 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=18640, lr=4.5559e-05, gnorm=0.891, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88960
2022-10-16 20:20:02 - progress_bar.py[line:274] - INFO: epoch 001:  18674 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.5, ups=0.91, wpb=109.6, bsz=40, num_updates=18650, lr=4.55834e-05, gnorm=0.985, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88971
2022-10-16 20:20:14 - progress_bar.py[line:274] - INFO: epoch 001:  18684 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.8, ups=0.88, wpb=111, bsz=40, num_updates=18660, lr=4.56079e-05, gnorm=0.767, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88983
2022-10-16 20:20:25 - progress_bar.py[line:274] - INFO: epoch 001:  18694 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.89, wpb=109.8, bsz=40, num_updates=18670, lr=4.56323e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88994
2022-10-16 20:20:36 - progress_bar.py[line:274] - INFO: epoch 001:  18704 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.8, ups=0.92, wpb=110.2, bsz=40, num_updates=18680, lr=4.56567e-05, gnorm=0.984, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89005
2022-10-16 20:20:47 - progress_bar.py[line:274] - INFO: epoch 001:  18714 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.1, ups=0.9, wpb=109.6, bsz=40, num_updates=18690, lr=4.56812e-05, gnorm=0.858, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89016
2022-10-16 20:20:59 - progress_bar.py[line:274] - INFO: epoch 001:  18724 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=18700, lr=4.57056e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89027
2022-10-16 20:21:10 - progress_bar.py[line:274] - INFO: epoch 001:  18734 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=18710, lr=4.57301e-05, gnorm=0.913, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89039
2022-10-16 20:21:21 - progress_bar.py[line:274] - INFO: epoch 001:  18744 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.8, ups=0.91, wpb=111, bsz=40, num_updates=18720, lr=4.57545e-05, gnorm=1.003, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89050
2022-10-16 20:21:32 - progress_bar.py[line:274] - INFO: epoch 001:  18754 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.1, ups=0.88, wpb=110.4, bsz=40, num_updates=18730, lr=4.5779e-05, gnorm=1.089, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89061
2022-10-16 20:21:43 - progress_bar.py[line:274] - INFO: epoch 001:  18764 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=18740, lr=4.58034e-05, gnorm=0.967, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89072
2022-10-16 20:21:54 - progress_bar.py[line:274] - INFO: epoch 001:  18774 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=18750, lr=4.58278e-05, gnorm=1.079, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89083
2022-10-16 20:22:05 - progress_bar.py[line:274] - INFO: epoch 001:  18784 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.2, ups=0.92, wpb=108.3, bsz=40, num_updates=18760, lr=4.58523e-05, gnorm=0.963, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89094
2022-10-16 20:22:17 - progress_bar.py[line:274] - INFO: epoch 001:  18794 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=18770, lr=4.58767e-05, gnorm=0.924, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89105
2022-10-16 20:22:28 - progress_bar.py[line:274] - INFO: epoch 001:  18804 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.3, ups=0.89, wpb=109, bsz=40, num_updates=18780, lr=4.59012e-05, gnorm=0.979, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89117
2022-10-16 20:22:39 - progress_bar.py[line:274] - INFO: epoch 001:  18814 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.1, ups=0.87, wpb=112.2, bsz=40, num_updates=18790, lr=4.59256e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=89128
2022-10-16 20:22:50 - progress_bar.py[line:274] - INFO: epoch 001:  18824 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100, ups=0.92, wpb=109.1, bsz=40, num_updates=18800, lr=4.595e-05, gnorm=1.011, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89139
2022-10-16 20:23:02 - progress_bar.py[line:274] - INFO: epoch 001:  18834 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.6, ups=0.87, wpb=109.6, bsz=40, num_updates=18810, lr=4.59745e-05, gnorm=0.976, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=89151
2022-10-16 20:23:13 - progress_bar.py[line:274] - INFO: epoch 001:  18844 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=18820, lr=4.59989e-05, gnorm=0.907, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89162
2022-10-16 20:23:24 - progress_bar.py[line:274] - INFO: epoch 001:  18854 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.8, ups=0.88, wpb=110.9, bsz=40, num_updates=18830, lr=4.60234e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89173
2022-10-16 20:23:35 - progress_bar.py[line:274] - INFO: epoch 001:  18864 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=18840, lr=4.60478e-05, gnorm=0.916, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89184
2022-10-16 20:23:47 - progress_bar.py[line:274] - INFO: epoch 001:  18874 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=18850, lr=4.60722e-05, gnorm=0.862, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=89196
2022-10-16 20:23:58 - progress_bar.py[line:274] - INFO: epoch 001:  18884 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.3, ups=0.9, wpb=109.5, bsz=40, num_updates=18860, lr=4.60967e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=89207
2022-10-16 20:24:09 - progress_bar.py[line:274] - INFO: epoch 001:  18894 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.2, ups=0.92, wpb=109.5, bsz=40, num_updates=18870, lr=4.61211e-05, gnorm=1.056, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=89218
2022-10-16 20:24:20 - progress_bar.py[line:274] - INFO: epoch 001:  18904 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.7, ups=0.88, wpb=111.2, bsz=40, num_updates=18880, lr=4.61456e-05, gnorm=0.937, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89229
2022-10-16 20:24:31 - progress_bar.py[line:274] - INFO: epoch 001:  18914 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.5, ups=0.92, wpb=108.7, bsz=40, num_updates=18890, lr=4.617e-05, gnorm=0.948, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89240
2022-10-16 20:24:42 - progress_bar.py[line:274] - INFO: epoch 001:  18924 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=103.9, ups=0.94, wpb=110.1, bsz=40, num_updates=18900, lr=4.61945e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89251
2022-10-16 20:24:53 - progress_bar.py[line:274] - INFO: epoch 001:  18934 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=18910, lr=4.62189e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=89262
2022-10-16 20:25:04 - progress_bar.py[line:274] - INFO: epoch 001:  18944 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.9, ups=0.92, wpb=110.1, bsz=40, num_updates=18920, lr=4.62433e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89273
2022-10-16 20:25:15 - progress_bar.py[line:274] - INFO: epoch 001:  18954 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=18930, lr=4.62678e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89284
2022-10-16 20:25:26 - progress_bar.py[line:274] - INFO: epoch 001:  18964 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=18940, lr=4.62922e-05, gnorm=0.862, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89295
2022-10-16 20:25:37 - progress_bar.py[line:274] - INFO: epoch 001:  18974 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=18950, lr=4.63167e-05, gnorm=0.862, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89306
2022-10-16 20:25:49 - progress_bar.py[line:274] - INFO: epoch 001:  18984 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=18960, lr=4.63411e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89318
2022-10-16 20:26:00 - progress_bar.py[line:274] - INFO: epoch 001:  18994 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=18970, lr=4.63655e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=89329
2022-10-16 20:26:11 - progress_bar.py[line:274] - INFO: epoch 001:  19004 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.2, ups=0.89, wpb=110.6, bsz=40, num_updates=18980, lr=4.639e-05, gnorm=0.875, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89340
2022-10-16 20:26:23 - progress_bar.py[line:274] - INFO: epoch 001:  19014 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=18990, lr=4.64144e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=89352
2022-10-16 20:26:34 - progress_bar.py[line:274] - INFO: epoch 001:  19024 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.4, ups=0.93, wpb=110.4, bsz=40, num_updates=19000, lr=4.64389e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89362
2022-10-16 20:26:34 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 20:26:35 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 20:26:35 - train.py[line:551] - INFO: load:1.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 20:29:07 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 20:29:07 - train.py[line:551] - INFO: load:1.08 valid_run:152.19 task_valid:148.62 collect_output:2.32
2022-10-16 20:31:35 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 20:31:35 - train.py[line:551] - INFO: load:1.11 valid_run:300.44 task_valid:292.23 collect_output:5.80
2022-10-16 20:34:07 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 20:34:07 - train.py[line:551] - INFO: load:1.13 valid_run:452.24 task_valid:435.63 collect_output:13.11
2022-10-16 20:36:37 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 20:36:37 - train.py[line:551] - INFO: load:1.16 valid_run:601.50 task_valid:581.26 collect_output:15.68
2022-10-16 20:39:09 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 20:39:09 - train.py[line:551] - INFO: load:1.19 valid_run:754.19 task_valid:729.39 collect_output:19.16
2022-10-16 20:41:41 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 20:41:41 - train.py[line:551] - INFO: load:1.21 valid_run:906.05 task_valid:875.48 collect_output:23.85
2022-10-16 20:44:14 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 20:44:14 - train.py[line:551] - INFO: load:1.24 valid_run:1059.15 task_valid:1022.12 collect_output:29.15
2022-10-16 20:46:45 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 20:46:45 - train.py[line:551] - INFO: load:1.26 valid_run:1210.04 task_valid:1164.14 collect_output:36.89
2022-10-16 20:49:15 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 20:49:15 - train.py[line:551] - INFO: load:1.29 valid_run:1359.51 task_valid:1309.22 collect_output:40.18
2022-10-16 20:51:44 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 20:51:44 - train.py[line:551] - INFO: load:1.31 valid_run:1508.72 task_valid:1453.36 collect_output:44.17
2022-10-16 20:54:14 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 20:54:14 - train.py[line:551] - INFO: load:1.34 valid_run:1658.39 task_valid:1598.53 collect_output:47.60
2022-10-16 20:56:44 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 20:56:44 - train.py[line:551] - INFO: load:1.36 valid_run:1808.05 task_valid:1743.49 collect_output:51.32
2022-10-16 20:59:13 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 20:59:13 - train.py[line:551] - INFO: load:1.39 valid_run:1957.63 task_valid:1885.21 collect_output:58.16
2022-10-16 21:01:44 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 21:01:44 - train.py[line:551] - INFO: load:1.41 valid_run:2108.00 task_valid:2030.66 collect_output:62.07
2022-10-16 21:04:14 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 21:04:14 - train.py[line:551] - INFO: load:1.44 valid_run:2257.83 task_valid:2177.06 collect_output:64.48
2022-10-16 21:06:43 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 21:06:43 - train.py[line:551] - INFO: load:1.46 valid_run:2407.54 task_valid:2321.33 collect_output:68.88
2022-10-16 21:09:15 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 21:09:15 - train.py[line:551] - INFO: load:1.49 valid_run:2558.87 task_valid:2466.91 collect_output:73.62
2022-10-16 21:11:45 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 21:11:45 - train.py[line:551] - INFO: load:1.51 valid_run:2709.46 task_valid:2614.03 collect_output:76.07
2022-10-16 21:14:13 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 21:14:13 - train.py[line:551] - INFO: load:1.54 valid_run:2857.38 task_valid:2755.49 collect_output:81.52
2022-10-16 21:16:43 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 21:16:43 - train.py[line:551] - INFO: load:1.56 valid_run:3007.37 task_valid:2900.56 collect_output:85.43
2022-10-16 21:19:15 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 21:19:15 - train.py[line:551] - INFO: load:1.59 valid_run:3158.98 task_valid:3045.21 collect_output:91.41
2022-10-16 21:21:44 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 21:21:44 - train.py[line:551] - INFO: load:1.61 valid_run:3308.12 task_valid:3189.60 collect_output:95.17
2022-10-16 21:24:15 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 21:24:15 - train.py[line:551] - INFO: load:1.64 valid_run:3459.05 task_valid:3335.89 collect_output:98.79
2022-10-16 21:26:46 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 21:26:46 - train.py[line:551] - INFO: load:1.66 valid_run:3610.12 task_valid:3482.33 collect_output:102.44

====================================================================================================
SGG eval:     R @ 50: 0.5282;     R @ 100: 0.5566;     R @ 500: 0.5837;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3530;    mR @ 100: 0.3821;    mR @ 500: 0.4106;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6171) (covered in:0.7083) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.1500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8854) (playing:0.0000) (riding:0.8317) (says:0.0000) (sitting on:0.6865) (standing on:0.1603) (using:0.7000) (walking in:0.0000) (walking on:0.7477) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2022-10-16 21:29:17 - train.py[line:487] - INFO: 0.5566148459383753

====================================================================================================
SGG eval:     R @ 50: 0.5282;     R @ 100: 0.5566;     R @ 500: 0.5837;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3530;    mR @ 100: 0.3821;    mR @ 500: 0.4106;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6171) (covered in:0.7083) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.1500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8854) (playing:0.0000) (riding:0.8317) (says:0.0000) (sitting on:0.6865) (standing on:0.1603) (using:0.7000) (walking in:0.0000) (walking on:0.7477) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2022-10-16 21:29:17 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 21:29:17 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.341 | loss_v1 0 | loss_v2 0 | nll_loss 0.182 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.556615 | ppl 1.13 | vqa_score 0.491 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 19000 | best_R@100 0.581461
2022-10-16 21:29:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 19000 updates
2022-10-16 21:29:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_19000.pt
2022-10-16 21:29:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_19000.pt
2022-10-16 21:29:26 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_19000.pt (epoch 1 @ 19000 updates, score 0.5566148459383753) (writing took 8.690435785800219 seconds)
2022-10-16 21:29:38 - progress_bar.py[line:274] - INFO: epoch 001:  19034 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=19010, lr=4.64633e-05, gnorm=0.965, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93147
2022-10-16 21:29:49 - progress_bar.py[line:274] - INFO: epoch 001:  19044 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=19020, lr=4.64878e-05, gnorm=0.968, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93158
2022-10-16 21:30:00 - progress_bar.py[line:274] - INFO: epoch 001:  19054 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.7, ups=0.9, wpb=110.9, bsz=40, num_updates=19030, lr=4.65122e-05, gnorm=0.825, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93169
2022-10-16 21:30:11 - progress_bar.py[line:274] - INFO: epoch 001:  19064 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=19040, lr=4.65366e-05, gnorm=0.864, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=93180
2022-10-16 21:30:23 - progress_bar.py[line:274] - INFO: epoch 001:  19074 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=19050, lr=4.65611e-05, gnorm=0.872, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93191
2022-10-16 21:30:34 - progress_bar.py[line:274] - INFO: epoch 001:  19084 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99, ups=0.9, wpb=109.6, bsz=40, num_updates=19060, lr=4.65855e-05, gnorm=0.874, clip=20, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=93203
2022-10-16 21:30:45 - progress_bar.py[line:274] - INFO: epoch 001:  19094 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=19070, lr=4.661e-05, gnorm=0.864, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93214
2022-10-16 21:30:56 - progress_bar.py[line:274] - INFO: epoch 001:  19104 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=19080, lr=4.66344e-05, gnorm=0.931, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93225
2022-10-16 21:31:07 - progress_bar.py[line:274] - INFO: epoch 001:  19114 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=19090, lr=4.66588e-05, gnorm=0.909, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=93236
2022-10-16 21:31:18 - progress_bar.py[line:274] - INFO: epoch 001:  19124 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.1, ups=0.93, wpb=108.7, bsz=40, num_updates=19100, lr=4.66833e-05, gnorm=0.924, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93247
2022-10-16 21:31:29 - progress_bar.py[line:274] - INFO: epoch 001:  19134 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=19110, lr=4.67077e-05, gnorm=0.945, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93258
2022-10-16 21:31:40 - progress_bar.py[line:274] - INFO: epoch 001:  19144 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.6, ups=0.91, wpb=110.7, bsz=40, num_updates=19120, lr=4.67322e-05, gnorm=1.032, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93269
2022-10-16 21:31:52 - progress_bar.py[line:274] - INFO: epoch 001:  19154 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=19130, lr=4.67566e-05, gnorm=1.03, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93281
2022-10-16 21:32:03 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 21:32:04 - progress_bar.py[line:274] - INFO: epoch 001:  19165 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=87.9, ups=0.8, wpb=109.8, bsz=40, num_updates=19140, lr=4.67811e-05, gnorm=0.938, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=93293
2022-10-16 21:32:15 - progress_bar.py[line:274] - INFO: epoch 001:  19175 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.2, ups=0.92, wpb=110.5, bsz=40, num_updates=19150, lr=4.68055e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=93304
2022-10-16 21:32:27 - progress_bar.py[line:274] - INFO: epoch 001:  19185 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.4, ups=0.88, wpb=111.7, bsz=40, num_updates=19160, lr=4.68299e-05, gnorm=0.868, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93315
2022-10-16 21:32:38 - progress_bar.py[line:274] - INFO: epoch 001:  19195 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=19170, lr=4.68544e-05, gnorm=0.775, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93327
2022-10-16 21:32:49 - progress_bar.py[line:274] - INFO: epoch 001:  19205 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.3, ups=0.9, wpb=109.7, bsz=40, num_updates=19180, lr=4.68788e-05, gnorm=0.936, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=93338
2022-10-16 21:33:00 - progress_bar.py[line:274] - INFO: epoch 001:  19215 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=19190, lr=4.69033e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93349
2022-10-16 21:33:12 - progress_bar.py[line:274] - INFO: epoch 001:  19225 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96, ups=0.88, wpb=108.9, bsz=40, num_updates=19200, lr=4.69277e-05, gnorm=0.828, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93361
2022-10-16 21:33:25 - progress_bar.py[line:274] - INFO: epoch 001:  19235 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.1, ups=0.9, wpb=111.7, bsz=40, num_updates=19210, lr=4.69521e-05, gnorm=0.962, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93372
2022-10-16 21:33:37 - progress_bar.py[line:274] - INFO: epoch 001:  19245 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96, ups=0.88, wpb=109.2, bsz=40, num_updates=19220, lr=4.69766e-05, gnorm=0.971, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93386
2022-10-16 21:33:48 - progress_bar.py[line:274] - INFO: epoch 001:  19255 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.1, ups=0.91, wpb=110.6, bsz=40, num_updates=19230, lr=4.7001e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93397
2022-10-16 21:33:59 - progress_bar.py[line:274] - INFO: epoch 001:  19265 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=19240, lr=4.70255e-05, gnorm=1.066, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=93408
2022-10-16 21:34:10 - progress_bar.py[line:274] - INFO: epoch 001:  19275 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=19250, lr=4.70499e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93419
2022-10-16 21:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  19285 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=19260, lr=4.70744e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93430
2022-10-16 21:34:33 - progress_bar.py[line:274] - INFO: epoch 001:  19295 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=19270, lr=4.70988e-05, gnorm=0.897, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93442
2022-10-16 21:34:44 - progress_bar.py[line:274] - INFO: epoch 001:  19305 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=19280, lr=4.71232e-05, gnorm=0.942, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93453
2022-10-16 21:34:55 - progress_bar.py[line:274] - INFO: epoch 001:  19315 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.8, ups=0.89, wpb=109.5, bsz=40, num_updates=19290, lr=4.71477e-05, gnorm=1.04, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93464
2022-10-16 21:35:06 - progress_bar.py[line:274] - INFO: epoch 001:  19325 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.5, ups=0.88, wpb=108.7, bsz=40, num_updates=19300, lr=4.71721e-05, gnorm=1.16, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93475
2022-10-16 21:35:18 - progress_bar.py[line:274] - INFO: epoch 001:  19335 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=19310, lr=4.71966e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=93487
2022-10-16 21:35:29 - progress_bar.py[line:274] - INFO: epoch 001:  19345 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=19320, lr=4.7221e-05, gnorm=0.996, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93498
2022-10-16 21:35:40 - progress_bar.py[line:274] - INFO: epoch 001:  19355 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100, ups=0.89, wpb=112.1, bsz=40, num_updates=19330, lr=4.72454e-05, gnorm=0.886, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93509
2022-10-16 21:35:51 - progress_bar.py[line:274] - INFO: epoch 001:  19365 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=19340, lr=4.72699e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=93520
2022-10-16 21:36:03 - progress_bar.py[line:274] - INFO: epoch 001:  19375 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.6, ups=0.87, wpb=109.9, bsz=40, num_updates=19350, lr=4.72943e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=93532
2022-10-16 21:36:13 - progress_bar.py[line:274] - INFO: epoch 001:  19385 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.8, ups=0.93, wpb=109.5, bsz=40, num_updates=19360, lr=4.73188e-05, gnorm=0.817, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93542
2022-10-16 21:36:25 - progress_bar.py[line:274] - INFO: epoch 001:  19395 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=19370, lr=4.73432e-05, gnorm=0.909, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93554
2022-10-16 21:36:36 - progress_bar.py[line:274] - INFO: epoch 001:  19405 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.2, ups=0.88, wpb=109.3, bsz=40, num_updates=19380, lr=4.73676e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93565
2022-10-16 21:36:47 - progress_bar.py[line:274] - INFO: epoch 001:  19415 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.7, ups=0.93, wpb=109.3, bsz=40, num_updates=19390, lr=4.73921e-05, gnorm=0.921, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93576
2022-10-16 21:36:58 - progress_bar.py[line:274] - INFO: epoch 001:  19425 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=19400, lr=4.74165e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93587
2022-10-16 21:37:10 - progress_bar.py[line:274] - INFO: epoch 001:  19435 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=19410, lr=4.7441e-05, gnorm=1.017, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93599
2022-10-16 21:37:21 - progress_bar.py[line:274] - INFO: epoch 001:  19445 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.6, ups=0.88, wpb=108.8, bsz=40, num_updates=19420, lr=4.74654e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=93610
2022-10-16 21:37:32 - progress_bar.py[line:274] - INFO: epoch 001:  19455 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.8, ups=0.93, wpb=111, bsz=40, num_updates=19430, lr=4.74899e-05, gnorm=0.924, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93621
2022-10-16 21:37:43 - progress_bar.py[line:274] - INFO: epoch 001:  19465 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.8, ups=0.9, wpb=109.4, bsz=40, num_updates=19440, lr=4.75143e-05, gnorm=0.873, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93632
2022-10-16 21:37:55 - progress_bar.py[line:274] - INFO: epoch 001:  19475 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.8, ups=0.87, wpb=111.4, bsz=40, num_updates=19450, lr=4.75387e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93644
2022-10-16 21:38:06 - progress_bar.py[line:274] - INFO: epoch 001:  19485 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=19460, lr=4.75632e-05, gnorm=0.99, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93655
2022-10-16 21:38:17 - progress_bar.py[line:274] - INFO: epoch 001:  19495 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.1, ups=0.88, wpb=109.1, bsz=40, num_updates=19470, lr=4.75876e-05, gnorm=1.169, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93666
2022-10-16 21:38:28 - progress_bar.py[line:274] - INFO: epoch 001:  19505 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.1, ups=0.9, wpb=110.2, bsz=40, num_updates=19480, lr=4.76121e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93677
2022-10-16 21:38:40 - progress_bar.py[line:274] - INFO: epoch 001:  19515 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.5, ups=0.88, wpb=108.4, bsz=40, num_updates=19490, lr=4.76365e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93689
2022-10-16 21:38:51 - progress_bar.py[line:274] - INFO: epoch 001:  19525 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.9, ups=0.89, wpb=112.6, bsz=40, num_updates=19500, lr=4.76609e-05, gnorm=0.893, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93700
2022-10-16 21:39:02 - progress_bar.py[line:274] - INFO: epoch 001:  19535 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=19510, lr=4.76854e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93711
2022-10-16 21:39:14 - progress_bar.py[line:274] - INFO: epoch 001:  19545 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.2, ups=0.87, wpb=108.2, bsz=40, num_updates=19520, lr=4.77098e-05, gnorm=1.008, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93723
2022-10-16 21:39:25 - progress_bar.py[line:274] - INFO: epoch 001:  19555 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97, ups=0.89, wpb=109, bsz=40, num_updates=19530, lr=4.77343e-05, gnorm=0.957, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=93734
2022-10-16 21:39:36 - progress_bar.py[line:274] - INFO: epoch 001:  19565 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102.2, ups=0.93, wpb=110.1, bsz=40, num_updates=19540, lr=4.77587e-05, gnorm=0.968, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93745
2022-10-16 21:39:47 - progress_bar.py[line:274] - INFO: epoch 001:  19575 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.5, ups=0.87, wpb=109.7, bsz=40, num_updates=19550, lr=4.77832e-05, gnorm=0.91, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93756
2022-10-16 21:39:58 - progress_bar.py[line:274] - INFO: epoch 001:  19585 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.9, ups=0.93, wpb=110.8, bsz=40, num_updates=19560, lr=4.78076e-05, gnorm=0.891, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93767
2022-10-16 21:40:10 - progress_bar.py[line:274] - INFO: epoch 001:  19595 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=19570, lr=4.7832e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93778
2022-10-16 21:40:20 - progress_bar.py[line:274] - INFO: epoch 001:  19605 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=104.8, ups=0.95, wpb=109.9, bsz=40, num_updates=19580, lr=4.78565e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=93789
2022-10-16 21:40:31 - progress_bar.py[line:274] - INFO: epoch 001:  19615 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.5, ups=0.92, wpb=108.7, bsz=40, num_updates=19590, lr=4.78809e-05, gnorm=0.922, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93800
2022-10-16 21:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  19625 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.5, ups=0.87, wpb=109.8, bsz=40, num_updates=19600, lr=4.79054e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=93812
2022-10-16 21:40:54 - progress_bar.py[line:274] - INFO: epoch 001:  19635 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.7, ups=0.91, wpb=109, bsz=40, num_updates=19610, lr=4.79298e-05, gnorm=0.936, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93822
2022-10-16 21:41:05 - progress_bar.py[line:274] - INFO: epoch 001:  19645 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.8, ups=0.88, wpb=109.3, bsz=40, num_updates=19620, lr=4.79542e-05, gnorm=1.065, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93834
2022-10-16 21:41:16 - progress_bar.py[line:274] - INFO: epoch 001:  19655 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98, ups=0.9, wpb=109.5, bsz=40, num_updates=19630, lr=4.79787e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93845
2022-10-16 21:41:27 - progress_bar.py[line:274] - INFO: epoch 001:  19665 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100, ups=0.89, wpb=112.2, bsz=40, num_updates=19640, lr=4.80031e-05, gnorm=0.985, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93856
2022-10-16 21:41:39 - progress_bar.py[line:274] - INFO: epoch 001:  19675 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.5, ups=0.9, wpb=110.6, bsz=40, num_updates=19650, lr=4.80276e-05, gnorm=0.97, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=93868
2022-10-16 21:41:50 - progress_bar.py[line:274] - INFO: epoch 001:  19685 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.5, ups=0.87, wpb=110.8, bsz=40, num_updates=19660, lr=4.8052e-05, gnorm=0.807, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93879
2022-10-16 21:42:01 - progress_bar.py[line:274] - INFO: epoch 001:  19695 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.1, ups=0.92, wpb=111.4, bsz=40, num_updates=19670, lr=4.80765e-05, gnorm=0.927, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93890
2022-10-16 21:42:12 - progress_bar.py[line:274] - INFO: epoch 001:  19705 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.1, ups=0.87, wpb=110.5, bsz=40, num_updates=19680, lr=4.81009e-05, gnorm=0.769, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93901
2022-10-16 21:42:24 - progress_bar.py[line:274] - INFO: epoch 001:  19715 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=19690, lr=4.81253e-05, gnorm=0.819, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93913
2022-10-16 21:42:34 - progress_bar.py[line:274] - INFO: epoch 001:  19725 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.7, ups=0.93, wpb=110.5, bsz=40, num_updates=19700, lr=4.81498e-05, gnorm=0.846, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=93923
2022-10-16 21:42:43 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 21:42:47 - progress_bar.py[line:274] - INFO: epoch 001:  19736 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=87.9, ups=0.81, wpb=109.1, bsz=40, num_updates=19710, lr=4.81742e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=93936
2022-10-16 21:42:58 - progress_bar.py[line:274] - INFO: epoch 001:  19746 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=19720, lr=4.81987e-05, gnorm=0.878, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93947
2022-10-16 21:43:09 - progress_bar.py[line:274] - INFO: epoch 001:  19756 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=19730, lr=4.82231e-05, gnorm=1.153, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=93958
2022-10-16 21:43:21 - progress_bar.py[line:274] - INFO: epoch 001:  19766 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=19740, lr=4.82475e-05, gnorm=1.116, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93970
2022-10-16 21:43:32 - progress_bar.py[line:274] - INFO: epoch 001:  19776 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.4, ups=0.88, wpb=110.9, bsz=40, num_updates=19750, lr=4.8272e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93981
2022-10-16 21:43:44 - progress_bar.py[line:274] - INFO: epoch 001:  19786 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=19760, lr=4.82964e-05, gnorm=0.844, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93993
2022-10-16 21:43:55 - progress_bar.py[line:274] - INFO: epoch 001:  19796 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.2, ups=0.92, wpb=110.3, bsz=40, num_updates=19770, lr=4.83209e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94003
2022-10-16 21:44:06 - progress_bar.py[line:274] - INFO: epoch 001:  19806 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.8, ups=0.88, wpb=110.9, bsz=40, num_updates=19780, lr=4.83453e-05, gnorm=0.95, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94015
2022-10-16 21:44:17 - progress_bar.py[line:274] - INFO: epoch 001:  19816 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=19790, lr=4.83698e-05, gnorm=0.838, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94026
2022-10-16 21:44:28 - progress_bar.py[line:274] - INFO: epoch 001:  19826 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.1, ups=0.91, wpb=110.6, bsz=40, num_updates=19800, lr=4.83942e-05, gnorm=0.936, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94037
2022-10-16 21:44:39 - progress_bar.py[line:274] - INFO: epoch 001:  19836 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.8, ups=0.87, wpb=112.2, bsz=40, num_updates=19810, lr=4.84186e-05, gnorm=1.052, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94048
2022-10-16 21:44:51 - progress_bar.py[line:274] - INFO: epoch 001:  19846 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.6, ups=0.88, wpb=109, bsz=40, num_updates=19820, lr=4.84431e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94060
2022-10-16 21:45:02 - progress_bar.py[line:274] - INFO: epoch 001:  19856 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=19830, lr=4.84675e-05, gnorm=0.889, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94071
2022-10-16 21:45:13 - progress_bar.py[line:274] - INFO: epoch 001:  19866 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.1, ups=0.9, wpb=108.8, bsz=40, num_updates=19840, lr=4.8492e-05, gnorm=0.863, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94082
2022-10-16 21:45:24 - progress_bar.py[line:274] - INFO: epoch 001:  19876 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=19850, lr=4.85164e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94093
2022-10-16 21:45:35 - progress_bar.py[line:274] - INFO: epoch 001:  19886 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.8, ups=0.91, wpb=110.4, bsz=40, num_updates=19860, lr=4.85408e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=94104
2022-10-16 21:45:46 - progress_bar.py[line:274] - INFO: epoch 001:  19896 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.6, ups=0.9, wpb=111.5, bsz=40, num_updates=19870, lr=4.85653e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94115
2022-10-16 21:45:57 - progress_bar.py[line:274] - INFO: epoch 001:  19906 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101, ups=0.93, wpb=109, bsz=40, num_updates=19880, lr=4.85897e-05, gnorm=0.955, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=94126
2022-10-16 21:46:08 - progress_bar.py[line:274] - INFO: epoch 001:  19916 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=104.4, ups=0.94, wpb=111, bsz=40, num_updates=19890, lr=4.86142e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94137
2022-10-16 21:46:19 - progress_bar.py[line:274] - INFO: epoch 001:  19926 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.4, ups=0.87, wpb=110, bsz=40, num_updates=19900, lr=4.86386e-05, gnorm=0.927, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94148
2022-10-16 21:46:30 - progress_bar.py[line:274] - INFO: epoch 001:  19936 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=19910, lr=4.8663e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94159
2022-10-16 21:46:41 - progress_bar.py[line:274] - INFO: epoch 001:  19946 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=102.6, ups=0.92, wpb=111.7, bsz=40, num_updates=19920, lr=4.86875e-05, gnorm=0.869, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94170
2022-10-16 21:46:53 - progress_bar.py[line:274] - INFO: epoch 001:  19956 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.7, ups=0.88, wpb=109.5, bsz=40, num_updates=19930, lr=4.87119e-05, gnorm=0.936, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=94182
2022-10-16 21:47:04 - progress_bar.py[line:274] - INFO: epoch 001:  19966 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=19940, lr=4.87364e-05, gnorm=0.859, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94193
2022-10-16 21:47:15 - progress_bar.py[line:274] - INFO: epoch 001:  19976 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99, ups=0.9, wpb=110, bsz=40, num_updates=19950, lr=4.87608e-05, gnorm=1.136, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94204
2022-10-16 21:47:26 - progress_bar.py[line:274] - INFO: epoch 001:  19986 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=19960, lr=4.87853e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94215
2022-10-16 21:47:37 - progress_bar.py[line:274] - INFO: epoch 001:  19996 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=19970, lr=4.88097e-05, gnorm=0.867, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94226
2022-10-16 21:47:49 - progress_bar.py[line:274] - INFO: epoch 001:  20006 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.4, ups=0.87, wpb=109.2, bsz=40, num_updates=19980, lr=4.88341e-05, gnorm=0.873, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94238
2022-10-16 21:48:00 - progress_bar.py[line:274] - INFO: epoch 001:  20016 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=19990, lr=4.88586e-05, gnorm=0.934, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94249
2022-10-16 21:48:12 - progress_bar.py[line:274] - INFO: epoch 001:  20026 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=20000, lr=4.8883e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94260
2022-10-16 21:48:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 21:48:13 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 21:48:13 - train.py[line:551] - INFO: load:1.22 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 21:50:45 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 21:50:45 - train.py[line:551] - INFO: load:1.24 valid_run:151.74 task_valid:148.71 collect_output:1.92
2022-10-16 21:53:13 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 21:53:13 - train.py[line:551] - INFO: load:1.27 valid_run:300.20 task_valid:292.53 collect_output:5.45
2022-10-16 21:55:46 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 21:55:46 - train.py[line:551] - INFO: load:1.29 valid_run:452.36 task_valid:436.00 collect_output:13.04
2022-10-16 21:58:15 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 21:58:15 - train.py[line:551] - INFO: load:1.32 valid_run:601.76 task_valid:581.50 collect_output:15.81
2022-10-16 22:00:48 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 22:00:48 - train.py[line:551] - INFO: load:1.35 valid_run:754.18 task_valid:729.59 collect_output:19.02
2022-10-16 22:03:19 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 22:03:19 - train.py[line:551] - INFO: load:1.37 valid_run:906.02 task_valid:876.05 collect_output:23.24
2022-10-16 22:05:53 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 22:05:53 - train.py[line:551] - INFO: load:1.41 valid_run:1058.99 task_valid:1022.43 collect_output:28.68
2022-10-16 22:08:23 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 22:08:23 - train.py[line:551] - INFO: load:1.44 valid_run:1209.66 task_valid:1163.67 collect_output:37.06
2022-10-16 22:10:52 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 22:10:52 - train.py[line:551] - INFO: load:1.46 valid_run:1358.62 task_valid:1308.20 collect_output:40.49
2022-10-16 22:13:21 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 22:13:21 - train.py[line:551] - INFO: load:1.49 valid_run:1506.93 task_valid:1451.48 collect_output:44.55
2022-10-16 22:15:50 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 22:15:50 - train.py[line:551] - INFO: load:1.51 valid_run:1656.64 task_valid:1596.55 collect_output:48.17
2022-10-16 22:18:20 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 22:18:20 - train.py[line:551] - INFO: load:1.54 valid_run:1806.18 task_valid:1741.48 collect_output:51.76
2022-10-16 22:20:49 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 22:20:49 - train.py[line:551] - INFO: load:1.56 valid_run:1955.58 task_valid:1883.23 collect_output:58.44
2022-10-16 22:23:20 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 22:23:20 - train.py[line:551] - INFO: load:1.59 valid_run:2105.84 task_valid:2028.79 collect_output:62.14
2022-10-16 22:25:50 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 22:25:50 - train.py[line:551] - INFO: load:1.61 valid_run:2255.54 task_valid:2175.18 collect_output:64.46
2022-10-16 22:28:19 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 22:28:19 - train.py[line:551] - INFO: load:1.64 valid_run:2405.34 task_valid:2319.27 collect_output:69.15
2022-10-16 22:30:51 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 22:30:51 - train.py[line:551] - INFO: load:1.66 valid_run:2556.53 task_valid:2464.61 collect_output:74.00
2022-10-16 22:33:21 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 22:33:21 - train.py[line:551] - INFO: load:1.69 valid_run:2706.86 task_valid:2611.62 collect_output:76.32
2022-10-16 22:35:49 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 22:35:49 - train.py[line:551] - INFO: load:1.71 valid_run:2854.91 task_valid:2753.46 collect_output:81.53
2022-10-16 22:38:19 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 22:38:19 - train.py[line:551] - INFO: load:1.74 valid_run:3005.19 task_valid:2898.57 collect_output:85.68
2022-10-16 22:40:51 - train.py[line:549] - INFO: 4200 / 4988
2022-10-16 22:40:51 - train.py[line:551] - INFO: load:1.77 valid_run:3156.81 task_valid:3043.14 collect_output:91.69
2022-10-16 22:43:20 - train.py[line:549] - INFO: 4400 / 4988
2022-10-16 22:43:20 - train.py[line:551] - INFO: load:1.79 valid_run:3305.95 task_valid:3187.69 collect_output:95.28
2022-10-16 22:45:51 - train.py[line:549] - INFO: 4600 / 4988
2022-10-16 22:45:51 - train.py[line:551] - INFO: load:1.81 valid_run:3456.98 task_valid:3333.97 collect_output:99.03
2022-10-16 22:48:23 - train.py[line:549] - INFO: 4800 / 4988
2022-10-16 22:48:23 - train.py[line:551] - INFO: load:1.84 valid_run:3608.31 task_valid:3480.54 collect_output:102.79

====================================================================================================
SGG eval:     R @ 50: 0.5170;     R @ 100: 0.5559;     R @ 500: 0.5835;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3408;    mR @ 100: 0.3780;    mR @ 500: 0.4075;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6171) (covered in:0.7083) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4516) (lying on:0.0667) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8438) (playing:0.0000) (riding:0.8072) (says:0.0000) (sitting on:0.6825) (standing on:0.1853) (using:0.7000) (walking in:0.0000) (walking on:0.7207) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5170;     R @ 100: 0.5559;     R @ 500: 0.5835;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3408;    mR @ 100: 0.3780;    mR @ 500: 0.4075;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6171) (covered in:0.7083) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4516) (lying on:0.0667) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8438) (playing:0.0000) (riding:0.8072) (says:0.0000) (sitting on:0.6825) (standing on:0.1853) (using:0.7000) (walking in:0.0000) (walking on:0.7207) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2022-10-16 22:50:54 - train.py[line:487] - INFO: 0.5559481792717087
2022-10-16 22:50:54 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-16 22:50:54 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.365 | loss_v1 0 | loss_v2 0 | nll_loss 0.209 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.555948 | ppl 1.16 | vqa_score 0.4865 | wps 119.3 | wpb 89.9 | bsz 30 | num_updates 20000 | best_R@100 0.581461
2022-10-16 22:50:54 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 20000 updates
2022-10-16 22:50:54 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_20000.pt
2022-10-16 22:51:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_20000.pt
2022-10-16 22:51:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score 0.5559481792717087) (writing took 8.334615025203675 seconds)
2022-10-16 22:51:14 - progress_bar.py[line:274] - INFO: epoch 001:  20036 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=0.3, ups=0, wpb=109.4, bsz=40, num_updates=20010, lr=4.89075e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98043
2022-10-16 22:51:25 - progress_bar.py[line:274] - INFO: epoch 001:  20046 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=20020, lr=4.89319e-05, gnorm=0.955, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98054
2022-10-16 22:51:37 - progress_bar.py[line:274] - INFO: epoch 001:  20056 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.3, ups=0.89, wpb=110.7, bsz=40, num_updates=20030, lr=4.89563e-05, gnorm=0.905, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=98066
2022-10-16 22:51:48 - progress_bar.py[line:274] - INFO: epoch 001:  20066 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=20040, lr=4.89808e-05, gnorm=1.037, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=98077
2022-10-16 22:51:59 - progress_bar.py[line:274] - INFO: epoch 001:  20076 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=20050, lr=4.90052e-05, gnorm=0.92, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98088
2022-10-16 22:52:10 - progress_bar.py[line:274] - INFO: epoch 001:  20086 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.8, ups=0.92, wpb=112.1, bsz=40, num_updates=20060, lr=4.90297e-05, gnorm=0.837, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98099
2022-10-16 22:52:21 - progress_bar.py[line:274] - INFO: epoch 001:  20096 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=20070, lr=4.90541e-05, gnorm=1.024, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98110
2022-10-16 22:52:32 - progress_bar.py[line:274] - INFO: epoch 001:  20106 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.8, ups=0.92, wpb=111.2, bsz=40, num_updates=20080, lr=4.90786e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98121
2022-10-16 22:52:43 - progress_bar.py[line:274] - INFO: epoch 001:  20116 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=20090, lr=4.9103e-05, gnorm=0.98, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=98132
2022-10-16 22:52:54 - progress_bar.py[line:274] - INFO: epoch 001:  20126 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.4, ups=0.9, wpb=110.5, bsz=40, num_updates=20100, lr=4.91274e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98143
2022-10-16 22:53:06 - progress_bar.py[line:274] - INFO: epoch 001:  20136 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.3, ups=0.88, wpb=109.7, bsz=40, num_updates=20110, lr=4.91519e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98155
2022-10-16 22:53:16 - progress_bar.py[line:274] - INFO: epoch 001:  20146 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.7, ups=0.91, wpb=110.1, bsz=40, num_updates=20120, lr=4.91763e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98165
2022-10-16 22:53:28 - progress_bar.py[line:274] - INFO: epoch 001:  20156 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=20130, lr=4.92008e-05, gnorm=0.996, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98176
2022-10-16 22:53:39 - progress_bar.py[line:274] - INFO: epoch 001:  20166 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.6, ups=0.88, wpb=110.3, bsz=40, num_updates=20140, lr=4.92252e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98188
2022-10-16 22:53:50 - progress_bar.py[line:274] - INFO: epoch 001:  20176 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.3, ups=0.87, wpb=111.3, bsz=40, num_updates=20150, lr=4.92496e-05, gnorm=0.991, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98199
2022-10-16 22:54:02 - progress_bar.py[line:274] - INFO: epoch 001:  20186 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=20160, lr=4.92741e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98211
2022-10-16 22:54:13 - progress_bar.py[line:274] - INFO: epoch 001:  20196 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.7, ups=0.92, wpb=111.2, bsz=40, num_updates=20170, lr=4.92985e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98222
2022-10-16 22:54:24 - progress_bar.py[line:274] - INFO: epoch 001:  20206 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=20180, lr=4.9323e-05, gnorm=1.029, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98233
2022-10-16 22:54:35 - progress_bar.py[line:274] - INFO: epoch 001:  20216 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=20190, lr=4.93474e-05, gnorm=1.03, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98244
2022-10-16 22:54:47 - progress_bar.py[line:274] - INFO: epoch 001:  20226 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=20200, lr=4.93719e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98256
2022-10-16 22:54:58 - progress_bar.py[line:274] - INFO: epoch 001:  20236 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=20210, lr=4.93963e-05, gnorm=0.815, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98267
2022-10-16 22:55:09 - progress_bar.py[line:274] - INFO: epoch 001:  20246 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=94.3, ups=0.86, wpb=109.3, bsz=40, num_updates=20220, lr=4.94207e-05, gnorm=0.935, clip=40, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=98278
2022-10-16 22:55:20 - progress_bar.py[line:274] - INFO: epoch 001:  20256 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.5, ups=0.91, wpb=110.2, bsz=40, num_updates=20230, lr=4.94452e-05, gnorm=0.896, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98289
2022-10-16 22:55:31 - progress_bar.py[line:274] - INFO: epoch 001:  20266 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.1, ups=0.91, wpb=110.6, bsz=40, num_updates=20240, lr=4.94696e-05, gnorm=0.866, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98300
2022-10-16 22:55:42 - progress_bar.py[line:274] - INFO: epoch 001:  20276 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.5, ups=0.91, wpb=109.5, bsz=40, num_updates=20250, lr=4.94941e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98311
2022-10-16 22:55:54 - progress_bar.py[line:274] - INFO: epoch 001:  20286 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.6, ups=0.88, wpb=108, bsz=40, num_updates=20260, lr=4.95185e-05, gnorm=1.018, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98323
2022-10-16 22:56:05 - progress_bar.py[line:274] - INFO: epoch 001:  20296 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=20270, lr=4.95429e-05, gnorm=0.813, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98334
2022-10-16 22:56:16 - progress_bar.py[line:274] - INFO: epoch 001:  20306 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=20280, lr=4.95674e-05, gnorm=0.965, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98345
2022-10-16 22:56:27 - progress_bar.py[line:274] - INFO: epoch 001:  20316 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=20290, lr=4.95918e-05, gnorm=0.867, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98356
2022-10-16 22:56:39 - progress_bar.py[line:274] - INFO: epoch 001:  20326 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.7, ups=0.89, wpb=110.1, bsz=40, num_updates=20300, lr=4.96163e-05, gnorm=0.838, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98368
2022-10-16 22:56:50 - progress_bar.py[line:274] - INFO: epoch 001:  20336 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.2, ups=0.9, wpb=110, bsz=40, num_updates=20310, lr=4.96407e-05, gnorm=0.926, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98379
2022-10-16 22:57:01 - progress_bar.py[line:274] - INFO: epoch 001:  20346 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.9, ups=0.89, wpb=107.8, bsz=40, num_updates=20320, lr=4.96652e-05, gnorm=1.148, clip=60, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=98390
2022-10-16 22:57:12 - progress_bar.py[line:274] - INFO: epoch 001:  20356 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.4, ups=0.91, wpb=109.8, bsz=40, num_updates=20330, lr=4.96896e-05, gnorm=0.87, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98401
2022-10-16 22:57:23 - progress_bar.py[line:274] - INFO: epoch 001:  20366 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.91, wpb=109.1, bsz=40, num_updates=20340, lr=4.9714e-05, gnorm=1.033, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98412
2022-10-16 22:57:34 - progress_bar.py[line:274] - INFO: epoch 001:  20376 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=20350, lr=4.97385e-05, gnorm=1.012, clip=50, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=98423
2022-10-16 22:57:45 - progress_bar.py[line:274] - INFO: epoch 001:  20386 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.89, wpb=111.2, bsz=40, num_updates=20360, lr=4.97629e-05, gnorm=0.765, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98434
2022-10-16 22:57:56 - progress_bar.py[line:274] - INFO: epoch 001:  20396 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.8, ups=0.9, wpb=109.7, bsz=40, num_updates=20370, lr=4.97874e-05, gnorm=0.902, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98445
2022-10-16 22:58:08 - progress_bar.py[line:274] - INFO: epoch 001:  20406 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.7, ups=0.88, wpb=111.9, bsz=40, num_updates=20380, lr=4.98118e-05, gnorm=0.899, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98457
2022-10-16 22:58:19 - progress_bar.py[line:274] - INFO: epoch 001:  20416 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=20390, lr=4.98362e-05, gnorm=0.943, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98468
2022-10-16 22:58:30 - progress_bar.py[line:274] - INFO: epoch 001:  20426 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.8, ups=0.9, wpb=110.3, bsz=40, num_updates=20400, lr=4.98607e-05, gnorm=0.988, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98479
2022-10-16 22:58:41 - progress_bar.py[line:274] - INFO: epoch 001:  20436 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.8, ups=0.88, wpb=110.5, bsz=40, num_updates=20410, lr=4.98851e-05, gnorm=0.852, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98490
2022-10-16 22:58:53 - progress_bar.py[line:274] - INFO: epoch 001:  20446 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.3, ups=0.9, wpb=108.9, bsz=40, num_updates=20420, lr=4.99096e-05, gnorm=1.039, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=98502
2022-10-16 22:59:04 - progress_bar.py[line:274] - INFO: epoch 001:  20456 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=20430, lr=4.9934e-05, gnorm=0.957, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98513
2022-10-16 22:59:15 - progress_bar.py[line:274] - INFO: epoch 001:  20466 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=20440, lr=4.99584e-05, gnorm=0.928, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98524
2022-10-16 22:59:26 - progress_bar.py[line:274] - INFO: epoch 001:  20476 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.3, ups=0.9, wpb=108.9, bsz=40, num_updates=20450, lr=4.99829e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98535
2022-10-16 22:59:37 - progress_bar.py[line:274] - INFO: epoch 001:  20486 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.89, wpb=111.3, bsz=40, num_updates=20460, lr=4.99997e-05, gnorm=0.922, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98546
2022-10-16 22:59:49 - progress_bar.py[line:274] - INFO: epoch 001:  20496 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=20470, lr=4.99987e-05, gnorm=0.887, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98558
2022-10-16 23:00:00 - progress_bar.py[line:274] - INFO: epoch 001:  20506 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.89, wpb=108.9, bsz=40, num_updates=20480, lr=4.99977e-05, gnorm=0.854, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98569
2022-10-16 23:00:11 - progress_bar.py[line:274] - INFO: epoch 001:  20516 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.5, ups=0.92, wpb=110.7, bsz=40, num_updates=20490, lr=4.99966e-05, gnorm=0.758, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98580
2022-10-16 23:00:22 - progress_bar.py[line:274] - INFO: epoch 001:  20526 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=20500, lr=4.99956e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=98591
2022-10-16 23:00:33 - progress_bar.py[line:274] - INFO: epoch 001:  20536 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=20510, lr=4.99946e-05, gnorm=0.93, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98602
2022-10-16 23:00:44 - progress_bar.py[line:274] - INFO: epoch 001:  20546 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=20520, lr=4.99936e-05, gnorm=0.867, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98613
2022-10-16 23:00:55 - progress_bar.py[line:274] - INFO: epoch 001:  20556 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=20530, lr=4.99926e-05, gnorm=0.92, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98624
2022-10-16 23:01:07 - progress_bar.py[line:274] - INFO: epoch 001:  20566 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.8, ups=0.88, wpb=111, bsz=40, num_updates=20540, lr=4.99915e-05, gnorm=0.922, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98636
2022-10-16 23:01:18 - progress_bar.py[line:274] - INFO: epoch 001:  20576 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.9, ups=0.91, wpb=110.3, bsz=40, num_updates=20550, lr=4.99905e-05, gnorm=0.909, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98647
2022-10-16 23:01:29 - progress_bar.py[line:274] - INFO: epoch 001:  20586 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.2, ups=0.89, wpb=109.6, bsz=40, num_updates=20560, lr=4.99895e-05, gnorm=0.92, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98658
2022-10-16 23:01:40 - progress_bar.py[line:274] - INFO: epoch 001:  20596 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.7, ups=0.9, wpb=109.2, bsz=40, num_updates=20570, lr=4.99885e-05, gnorm=0.905, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98669
2022-10-16 23:01:51 - progress_bar.py[line:274] - INFO: epoch 001:  20606 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.5, ups=0.87, wpb=108.7, bsz=40, num_updates=20580, lr=4.99875e-05, gnorm=1.023, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98680
2022-10-16 23:02:03 - progress_bar.py[line:274] - INFO: epoch 001:  20616 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=20590, lr=4.99865e-05, gnorm=1.085, clip=70, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=98692
2022-10-16 23:02:14 - progress_bar.py[line:274] - INFO: epoch 001:  20626 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.1, ups=0.91, wpb=110.6, bsz=40, num_updates=20600, lr=4.99854e-05, gnorm=0.901, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98703
2022-10-16 23:02:25 - progress_bar.py[line:274] - INFO: epoch 001:  20636 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=20610, lr=4.99844e-05, gnorm=0.882, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98714
2022-10-16 23:02:28 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-16 23:02:37 - progress_bar.py[line:274] - INFO: epoch 001:  20647 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=90.2, ups=0.82, wpb=110.5, bsz=40, num_updates=20620, lr=4.99834e-05, gnorm=1.014, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=98726
2022-10-16 23:02:49 - progress_bar.py[line:274] - INFO: epoch 001:  20657 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.4, ups=0.89, wpb=110.8, bsz=40, num_updates=20630, lr=4.99824e-05, gnorm=0.947, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98737
2022-10-16 23:03:00 - progress_bar.py[line:274] - INFO: epoch 001:  20667 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.6, ups=0.87, wpb=109.8, bsz=40, num_updates=20640, lr=4.99814e-05, gnorm=0.97, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98749
2022-10-16 23:03:11 - progress_bar.py[line:274] - INFO: epoch 001:  20677 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.4, ups=0.91, wpb=109.3, bsz=40, num_updates=20650, lr=4.99803e-05, gnorm=1.056, clip=70, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=98760
2022-10-16 23:03:22 - progress_bar.py[line:274] - INFO: epoch 001:  20687 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.9, ups=0.92, wpb=110.2, bsz=40, num_updates=20660, lr=4.99793e-05, gnorm=0.95, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98771
2022-10-16 23:03:33 - progress_bar.py[line:274] - INFO: epoch 001:  20697 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.3, ups=0.88, wpb=111.8, bsz=40, num_updates=20670, lr=4.99783e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98782
2022-10-16 23:03:44 - progress_bar.py[line:274] - INFO: epoch 001:  20707 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.5, ups=0.92, wpb=109.8, bsz=40, num_updates=20680, lr=4.99773e-05, gnorm=0.901, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=98793
2022-10-16 23:03:55 - progress_bar.py[line:274] - INFO: epoch 001:  20717 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.5, ups=0.89, wpb=109.3, bsz=40, num_updates=20690, lr=4.99763e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98804
2022-10-16 23:04:07 - progress_bar.py[line:274] - INFO: epoch 001:  20727 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96, ups=0.87, wpb=110.3, bsz=40, num_updates=20700, lr=4.99753e-05, gnorm=0.887, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98816
2022-10-16 23:04:18 - progress_bar.py[line:274] - INFO: epoch 001:  20737 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.1, ups=0.88, wpb=109.7, bsz=40, num_updates=20710, lr=4.99742e-05, gnorm=0.929, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98827
2022-10-16 23:04:29 - progress_bar.py[line:274] - INFO: epoch 001:  20747 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.4, ups=0.91, wpb=109.9, bsz=40, num_updates=20720, lr=4.99732e-05, gnorm=0.882, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98838
2022-10-16 23:04:40 - progress_bar.py[line:274] - INFO: epoch 001:  20757 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=20730, lr=4.99722e-05, gnorm=1.029, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98849
2022-10-16 23:04:51 - progress_bar.py[line:274] - INFO: epoch 001:  20767 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.7, ups=0.92, wpb=108.9, bsz=40, num_updates=20740, lr=4.99712e-05, gnorm=1.15, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98860
2022-10-16 23:05:03 - progress_bar.py[line:274] - INFO: epoch 001:  20777 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.9, ups=0.89, wpb=110.7, bsz=40, num_updates=20750, lr=4.99702e-05, gnorm=0.993, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98872
2022-10-16 23:05:14 - progress_bar.py[line:274] - INFO: epoch 001:  20787 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.7, ups=0.9, wpb=111.3, bsz=40, num_updates=20760, lr=4.99691e-05, gnorm=0.937, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98883
2022-10-16 23:05:24 - progress_bar.py[line:274] - INFO: epoch 001:  20797 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102, ups=0.93, wpb=109.9, bsz=40, num_updates=20770, lr=4.99681e-05, gnorm=1.055, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=98893
2022-10-16 23:05:35 - progress_bar.py[line:274] - INFO: epoch 001:  20807 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=20780, lr=4.99671e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=98904
2022-10-16 23:05:47 - progress_bar.py[line:274] - INFO: epoch 001:  20817 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.89, wpb=110.2, bsz=40, num_updates=20790, lr=4.99661e-05, gnorm=0.878, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98916
2022-10-16 23:05:58 - progress_bar.py[line:274] - INFO: epoch 001:  20827 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=20800, lr=4.99651e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98927
2022-10-16 23:06:09 - progress_bar.py[line:274] - INFO: epoch 001:  20837 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.3, ups=0.9, wpb=109.3, bsz=40, num_updates=20810, lr=4.99641e-05, gnorm=1.018, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98938
2022-10-16 23:06:20 - progress_bar.py[line:274] - INFO: epoch 001:  20847 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.3, ups=0.9, wpb=109.6, bsz=40, num_updates=20820, lr=4.9963e-05, gnorm=0.879, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98949
2022-10-16 23:06:31 - progress_bar.py[line:274] - INFO: epoch 001:  20857 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.9, wpb=109.9, bsz=40, num_updates=20830, lr=4.9962e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=98960
2022-10-16 23:06:43 - progress_bar.py[line:274] - INFO: epoch 001:  20867 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.4, ups=0.9, wpb=110.6, bsz=40, num_updates=20840, lr=4.9961e-05, gnorm=0.807, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98972
2022-10-16 23:06:54 - progress_bar.py[line:274] - INFO: epoch 001:  20877 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=20850, lr=4.996e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98983
2022-10-16 23:07:05 - progress_bar.py[line:274] - INFO: epoch 001:  20887 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.5, ups=0.88, wpb=111.3, bsz=40, num_updates=20860, lr=4.9959e-05, gnorm=0.912, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98994
2022-10-16 23:07:16 - progress_bar.py[line:274] - INFO: epoch 001:  20897 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100, ups=0.9, wpb=110.5, bsz=40, num_updates=20870, lr=4.99579e-05, gnorm=0.766, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99005
2022-10-16 23:07:27 - progress_bar.py[line:274] - INFO: epoch 001:  20907 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.9, ups=0.9, wpb=108.9, bsz=40, num_updates=20880, lr=4.99569e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99016
2022-10-16 23:07:38 - progress_bar.py[line:274] - INFO: epoch 001:  20917 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.4, ups=0.91, wpb=110.1, bsz=40, num_updates=20890, lr=4.99559e-05, gnorm=1.101, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99027
2022-10-16 23:07:50 - progress_bar.py[line:274] - INFO: epoch 001:  20927 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=20900, lr=4.99549e-05, gnorm=0.9, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=99039
2022-10-16 23:08:01 - progress_bar.py[line:274] - INFO: epoch 001:  20937 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.7, ups=0.9, wpb=109.4, bsz=40, num_updates=20910, lr=4.99539e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99050
2022-10-16 23:08:12 - progress_bar.py[line:274] - INFO: epoch 001:  20947 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=20920, lr=4.99528e-05, gnorm=0.887, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=99061
2022-10-16 23:08:23 - progress_bar.py[line:274] - INFO: epoch 001:  20957 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.5, ups=0.88, wpb=109.4, bsz=40, num_updates=20930, lr=4.99518e-05, gnorm=0.95, clip=20, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=99072
2022-10-16 23:08:35 - progress_bar.py[line:274] - INFO: epoch 001:  20967 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=20940, lr=4.99508e-05, gnorm=0.946, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99084
2022-10-16 23:08:46 - progress_bar.py[line:274] - INFO: epoch 001:  20977 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=20950, lr=4.99498e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99095
2022-10-16 23:08:57 - progress_bar.py[line:274] - INFO: epoch 001:  20987 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=20960, lr=4.99488e-05, gnorm=1.01, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=99106
2022-10-16 23:09:08 - progress_bar.py[line:274] - INFO: epoch 001:  20997 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=20970, lr=4.99478e-05, gnorm=0.873, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99117
2022-10-16 23:09:20 - progress_bar.py[line:274] - INFO: epoch 001:  21007 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.9, ups=0.87, wpb=109.5, bsz=40, num_updates=20980, lr=4.99467e-05, gnorm=0.964, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99129
2022-10-16 23:09:31 - progress_bar.py[line:274] - INFO: epoch 001:  21017 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.3, ups=0.91, wpb=110.3, bsz=40, num_updates=20990, lr=4.99457e-05, gnorm=0.916, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99140
2022-10-16 23:09:42 - progress_bar.py[line:274] - INFO: epoch 001:  21027 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=21000, lr=4.99447e-05, gnorm=1.028, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99151
2022-10-16 23:09:42 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-16 23:09:43 - train.py[line:549] - INFO: 0 / 4988
2022-10-16 23:09:43 - train.py[line:551] - INFO: load:1.05 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-16 23:12:15 - train.py[line:549] - INFO: 200 / 4988
2022-10-16 23:12:15 - train.py[line:551] - INFO: load:1.08 valid_run:152.00 task_valid:148.84 collect_output:2.05
2022-10-16 23:14:44 - train.py[line:549] - INFO: 400 / 4988
2022-10-16 23:14:44 - train.py[line:551] - INFO: load:1.10 valid_run:300.37 task_valid:292.55 collect_output:5.53
2022-10-16 23:17:16 - train.py[line:549] - INFO: 600 / 4988
2022-10-16 23:17:16 - train.py[line:551] - INFO: load:1.13 valid_run:452.54 task_valid:436.57 collect_output:12.56
2022-10-16 23:19:46 - train.py[line:549] - INFO: 800 / 4988
2022-10-16 23:19:46 - train.py[line:551] - INFO: load:1.16 valid_run:602.43 task_valid:582.82 collect_output:14.96
2022-10-16 23:22:19 - train.py[line:549] - INFO: 1000 / 4988
2022-10-16 23:22:19 - train.py[line:551] - INFO: load:1.18 valid_run:755.06 task_valid:730.72 collect_output:18.65
2022-10-16 23:24:50 - train.py[line:549] - INFO: 1200 / 4988
2022-10-16 23:24:50 - train.py[line:551] - INFO: load:1.21 valid_run:906.53 task_valid:876.61 collect_output:23.18
2022-10-16 23:27:23 - train.py[line:549] - INFO: 1400 / 4988
2022-10-16 23:27:23 - train.py[line:551] - INFO: load:1.24 valid_run:1059.13 task_valid:1022.69 collect_output:28.67
2022-10-16 23:29:54 - train.py[line:549] - INFO: 1600 / 4988
2022-10-16 23:29:54 - train.py[line:551] - INFO: load:1.26 valid_run:1209.91 task_valid:1164.20 collect_output:36.90
2022-10-16 23:32:23 - train.py[line:549] - INFO: 1800 / 4988
2022-10-16 23:32:23 - train.py[line:551] - INFO: load:1.29 valid_run:1359.44 task_valid:1309.11 collect_output:40.50
2022-10-16 23:34:51 - train.py[line:549] - INFO: 2000 / 4988
2022-10-16 23:34:51 - train.py[line:551] - INFO: load:1.32 valid_run:1507.56 task_valid:1452.44 collect_output:44.29
2022-10-16 23:37:21 - train.py[line:549] - INFO: 2200 / 4988
2022-10-16 23:37:21 - train.py[line:551] - INFO: load:1.35 valid_run:1657.03 task_valid:1597.46 collect_output:47.70
2022-10-16 23:39:51 - train.py[line:549] - INFO: 2400 / 4988
2022-10-16 23:39:51 - train.py[line:551] - INFO: load:1.37 valid_run:1806.78 task_valid:1742.72 collect_output:51.16
2022-10-16 23:42:20 - train.py[line:549] - INFO: 2600 / 4988
2022-10-16 23:42:20 - train.py[line:551] - INFO: load:1.40 valid_run:1956.35 task_valid:1884.61 collect_output:57.81
2022-10-16 23:44:51 - train.py[line:549] - INFO: 2800 / 4988
2022-10-16 23:44:51 - train.py[line:551] - INFO: load:1.42 valid_run:2106.60 task_valid:2030.07 collect_output:61.59
2022-10-16 23:47:20 - train.py[line:549] - INFO: 3000 / 4988
2022-10-16 23:47:20 - train.py[line:551] - INFO: load:1.45 valid_run:2256.37 task_valid:2176.45 collect_output:63.97
2022-10-16 23:49:51 - train.py[line:549] - INFO: 3200 / 4988
2022-10-16 23:49:51 - train.py[line:551] - INFO: load:1.48 valid_run:2406.42 task_valid:2320.91 collect_output:68.51
2022-10-16 23:52:22 - train.py[line:549] - INFO: 3400 / 4988
2022-10-16 23:52:22 - train.py[line:551] - INFO: load:1.50 valid_run:2558.15 task_valid:2466.55 collect_output:73.57
2022-10-16 23:54:53 - train.py[line:549] - INFO: 3600 / 4988
2022-10-16 23:54:53 - train.py[line:551] - INFO: load:1.53 valid_run:2708.66 task_valid:2613.71 collect_output:75.89
2022-10-16 23:57:21 - train.py[line:549] - INFO: 3800 / 4988
2022-10-16 23:57:21 - train.py[line:551] - INFO: load:1.56 valid_run:2856.82 task_valid:2755.49 collect_output:81.25
2022-10-16 23:59:51 - train.py[line:549] - INFO: 4000 / 4988
2022-10-16 23:59:51 - train.py[line:551] - INFO: load:1.59 valid_run:3006.96 task_valid:2900.52 collect_output:85.35
2022-10-17 00:02:23 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 00:02:23 - train.py[line:551] - INFO: load:1.61 valid_run:3158.97 task_valid:3045.41 collect_output:91.44
2022-10-17 00:04:53 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 00:04:53 - train.py[line:551] - INFO: load:1.64 valid_run:3308.30 task_valid:3190.03 collect_output:95.16
2022-10-17 00:07:24 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 00:07:24 - train.py[line:551] - INFO: load:1.67 valid_run:3459.76 task_valid:3336.77 collect_output:98.78
2022-10-17 00:09:57 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 00:09:57 - train.py[line:551] - INFO: load:1.69 valid_run:3611.96 task_valid:3484.27 collect_output:102.29

====================================================================================================
SGG eval:     R @ 50: 0.5065;     R @ 100: 0.5519;     R @ 500: 0.5815;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3227;    mR @ 100: 0.3908;    mR @ 500: 0.4241;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.7083) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0667) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8438) (playing:0.0000) (riding:0.7925) (says:0.0000) (sitting on:0.6769) (standing on:0.2003) (using:0.7000) (walking in:0.3333) (walking on:0.6396) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2022-10-17 00:12:28 - train.py[line:487] - INFO: 0.5519481792717087
2022-10-17 00:12:29 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.5065;     R @ 100: 0.5519;     R @ 500: 0.5815;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3227;    mR @ 100: 0.3908;    mR @ 500: 0.4241;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.7083) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0667) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8438) (playing:0.0000) (riding:0.7925) (says:0.0000) (sitting on:0.6769) (standing on:0.2003) (using:0.7000) (walking in:0.3333) (walking on:0.6396) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2022-10-17 00:12:29 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.331 | loss_v1 0 | loss_v2 0 | nll_loss 0.169 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.551948 | ppl 1.12 | vqa_score 0.482 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 21000 | best_R@100 0.581461
2022-10-17 00:12:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 21000 updates
2022-10-17 00:12:29 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_21000.pt
2022-10-17 00:12:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_21000.pt
2022-10-17 00:12:37 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_21000.pt (epoch 1 @ 21000 updates, score 0.5519481792717087) (writing took 8.712558622006327 seconds)
2022-10-17 00:12:48 - progress_bar.py[line:274] - INFO: epoch 001:  21037 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=0.3, ups=0, wpb=109.2, bsz=40, num_updates=21010, lr=4.99437e-05, gnorm=0.941, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=102937
2022-10-17 00:13:00 - progress_bar.py[line:274] - INFO: epoch 001:  21047 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.8, ups=0.9, wpb=109.2, bsz=40, num_updates=21020, lr=4.99427e-05, gnorm=0.883, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102949
2022-10-17 00:13:11 - progress_bar.py[line:274] - INFO: epoch 001:  21057 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.5, ups=0.87, wpb=110.1, bsz=40, num_updates=21030, lr=4.99416e-05, gnorm=0.978, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=102960
2022-10-17 00:13:22 - progress_bar.py[line:274] - INFO: epoch 001:  21067 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.7, ups=0.91, wpb=110.3, bsz=40, num_updates=21040, lr=4.99406e-05, gnorm=0.929, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=102971
2022-10-17 00:13:33 - progress_bar.py[line:274] - INFO: epoch 001:  21077 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.7, ups=0.89, wpb=111.9, bsz=40, num_updates=21050, lr=4.99396e-05, gnorm=0.836, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=102982
2022-10-17 00:13:44 - progress_bar.py[line:274] - INFO: epoch 001:  21087 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.1, ups=0.9, wpb=110.4, bsz=40, num_updates=21060, lr=4.99386e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=102993
2022-10-17 00:13:56 - progress_bar.py[line:274] - INFO: epoch 001:  21097 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=21070, lr=4.99376e-05, gnorm=0.98, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103005
2022-10-17 00:14:07 - progress_bar.py[line:274] - INFO: epoch 001:  21107 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.2, ups=0.87, wpb=110.8, bsz=40, num_updates=21080, lr=4.99366e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103016
2022-10-17 00:14:19 - progress_bar.py[line:274] - INFO: epoch 001:  21117 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.88, wpb=111.2, bsz=40, num_updates=21090, lr=4.99355e-05, gnorm=0.979, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=103028
2022-10-17 00:14:29 - progress_bar.py[line:274] - INFO: epoch 001:  21127 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=103.5, ups=0.93, wpb=111.1, bsz=40, num_updates=21100, lr=4.99345e-05, gnorm=1.069, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103038
2022-10-17 00:14:40 - progress_bar.py[line:274] - INFO: epoch 001:  21137 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.4, ups=0.9, wpb=110.3, bsz=40, num_updates=21110, lr=4.99335e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103049
2022-10-17 00:14:52 - progress_bar.py[line:274] - INFO: epoch 001:  21147 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=21120, lr=4.99325e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103061
2022-10-17 00:15:03 - progress_bar.py[line:274] - INFO: epoch 001:  21157 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.5, ups=0.89, wpb=110, bsz=40, num_updates=21130, lr=4.99315e-05, gnorm=0.923, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103072
2022-10-17 00:15:14 - progress_bar.py[line:274] - INFO: epoch 001:  21167 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99, ups=0.89, wpb=111.5, bsz=40, num_updates=21140, lr=4.99304e-05, gnorm=0.865, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103083
2022-10-17 00:15:25 - progress_bar.py[line:274] - INFO: epoch 001:  21177 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.5, ups=0.93, wpb=109.7, bsz=40, num_updates=21150, lr=4.99294e-05, gnorm=0.805, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103094
2022-10-17 00:15:37 - progress_bar.py[line:274] - INFO: epoch 001:  21187 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.84, wpb=109.3, bsz=40, num_updates=21160, lr=4.99284e-05, gnorm=0.954, clip=30, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=103106
2022-10-17 00:15:48 - progress_bar.py[line:274] - INFO: epoch 001:  21197 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.4, ups=0.9, wpb=111, bsz=40, num_updates=21170, lr=4.99274e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103117
2022-10-17 00:15:59 - progress_bar.py[line:274] - INFO: epoch 001:  21207 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.1, ups=0.93, wpb=109.8, bsz=40, num_updates=21180, lr=4.99264e-05, gnorm=0.798, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=103128
2022-10-17 00:16:10 - progress_bar.py[line:274] - INFO: epoch 001:  21217 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.9, ups=0.89, wpb=111.9, bsz=40, num_updates=21190, lr=4.99254e-05, gnorm=0.834, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103139
2022-10-17 00:16:21 - progress_bar.py[line:274] - INFO: epoch 001:  21227 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=21200, lr=4.99243e-05, gnorm=0.906, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103150
2022-10-17 00:16:32 - progress_bar.py[line:274] - INFO: epoch 001:  21237 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=21210, lr=4.99233e-05, gnorm=1.028, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103161
2022-10-17 00:16:43 - progress_bar.py[line:274] - INFO: epoch 001:  21247 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=21220, lr=4.99223e-05, gnorm=0.991, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103172
2022-10-17 00:16:55 - progress_bar.py[line:274] - INFO: epoch 001:  21257 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=21230, lr=4.99213e-05, gnorm=1.022, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103184
2022-10-17 00:17:06 - progress_bar.py[line:274] - INFO: epoch 001:  21267 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.6, ups=0.87, wpb=111.2, bsz=40, num_updates=21240, lr=4.99203e-05, gnorm=0.843, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103195
2022-10-17 00:17:17 - progress_bar.py[line:274] - INFO: epoch 001:  21277 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=21250, lr=4.99192e-05, gnorm=1.067, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103206
2022-10-17 00:17:29 - progress_bar.py[line:274] - INFO: epoch 001:  21287 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.3, ups=0.89, wpb=111.5, bsz=40, num_updates=21260, lr=4.99182e-05, gnorm=0.906, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103217
2022-10-17 00:17:40 - progress_bar.py[line:274] - INFO: epoch 001:  21297 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99, ups=0.9, wpb=109.7, bsz=40, num_updates=21270, lr=4.99172e-05, gnorm=0.93, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103229
2022-10-17 00:17:51 - progress_bar.py[line:274] - INFO: epoch 001:  21307 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.2, ups=0.9, wpb=108.8, bsz=40, num_updates=21280, lr=4.99162e-05, gnorm=0.872, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=103240
2022-10-17 00:18:02 - progress_bar.py[line:274] - INFO: epoch 001:  21317 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.1, ups=0.87, wpb=107.4, bsz=40, num_updates=21290, lr=4.99152e-05, gnorm=0.955, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103251
2022-10-17 00:18:13 - progress_bar.py[line:274] - INFO: epoch 001:  21327 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.8, ups=0.9, wpb=110.9, bsz=40, num_updates=21300, lr=4.99142e-05, gnorm=0.816, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=103262
2022-10-17 00:18:25 - progress_bar.py[line:274] - INFO: epoch 001:  21337 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.5, ups=0.88, wpb=110.1, bsz=40, num_updates=21310, lr=4.99131e-05, gnorm=0.818, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103274
2022-10-17 00:18:36 - progress_bar.py[line:274] - INFO: epoch 001:  21347 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=21320, lr=4.99121e-05, gnorm=0.866, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103285
2022-10-17 00:18:47 - progress_bar.py[line:274] - INFO: epoch 001:  21357 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.8, ups=0.89, wpb=109.9, bsz=40, num_updates=21330, lr=4.99111e-05, gnorm=0.841, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103296
2022-10-17 00:18:59 - progress_bar.py[line:274] - INFO: epoch 001:  21367 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.3, ups=0.88, wpb=110.9, bsz=40, num_updates=21340, lr=4.99101e-05, gnorm=0.898, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=103308
2022-10-17 00:19:10 - progress_bar.py[line:274] - INFO: epoch 001:  21377 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=21350, lr=4.99091e-05, gnorm=0.979, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103319
2022-10-17 00:19:21 - progress_bar.py[line:274] - INFO: epoch 001:  21387 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.7, ups=0.88, wpb=110.8, bsz=40, num_updates=21360, lr=4.9908e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103330
2022-10-17 00:19:32 - progress_bar.py[line:274] - INFO: epoch 001:  21397 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=21370, lr=4.9907e-05, gnorm=0.901, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103341
2022-10-17 00:19:44 - progress_bar.py[line:274] - INFO: epoch 001:  21407 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.2, ups=0.89, wpb=108.9, bsz=40, num_updates=21380, lr=4.9906e-05, gnorm=0.937, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=103353
2022-10-17 00:19:55 - progress_bar.py[line:274] - INFO: epoch 001:  21417 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=21390, lr=4.9905e-05, gnorm=0.862, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103364
2022-10-17 00:20:06 - progress_bar.py[line:274] - INFO: epoch 001:  21427 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=21400, lr=4.9904e-05, gnorm=0.842, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103375
2022-10-17 00:20:17 - progress_bar.py[line:274] - INFO: epoch 001:  21437 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=21410, lr=4.99029e-05, gnorm=0.912, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103386
2022-10-17 00:20:28 - progress_bar.py[line:274] - INFO: epoch 001:  21447 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=21420, lr=4.99019e-05, gnorm=0.98, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103397
2022-10-17 00:20:40 - progress_bar.py[line:274] - INFO: epoch 001:  21457 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=21430, lr=4.99009e-05, gnorm=1.056, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103409
2022-10-17 00:20:50 - progress_bar.py[line:274] - INFO: epoch 001:  21467 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101, ups=0.92, wpb=110.3, bsz=40, num_updates=21440, lr=4.98999e-05, gnorm=0.918, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103419
2022-10-17 00:21:02 - progress_bar.py[line:274] - INFO: epoch 001:  21477 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=21450, lr=4.98989e-05, gnorm=1.08, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103431
2022-10-17 00:21:13 - progress_bar.py[line:274] - INFO: epoch 001:  21487 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.1, ups=0.86, wpb=111.1, bsz=40, num_updates=21460, lr=4.98979e-05, gnorm=0.975, clip=40, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=103442
2022-10-17 00:21:25 - progress_bar.py[line:274] - INFO: epoch 001:  21497 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.9, ups=0.9, wpb=111.3, bsz=40, num_updates=21470, lr=4.98968e-05, gnorm=0.928, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103454
2022-10-17 00:21:36 - progress_bar.py[line:274] - INFO: epoch 001:  21507 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=21480, lr=4.98958e-05, gnorm=0.988, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103465
2022-10-17 00:21:47 - progress_bar.py[line:274] - INFO: epoch 001:  21517 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=21490, lr=4.98948e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103476
2022-10-17 00:21:58 - progress_bar.py[line:274] - INFO: epoch 001:  21527 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=103, ups=0.93, wpb=110.8, bsz=40, num_updates=21500, lr=4.98938e-05, gnorm=0.816, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103487
2022-10-17 00:22:09 - progress_bar.py[line:274] - INFO: epoch 001:  21537 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.2, ups=0.89, wpb=108.1, bsz=40, num_updates=21510, lr=4.98928e-05, gnorm=0.915, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103498
2022-10-17 00:22:20 - progress_bar.py[line:274] - INFO: epoch 001:  21547 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.5, ups=0.89, wpb=111, bsz=40, num_updates=21520, lr=4.98917e-05, gnorm=0.885, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103509
2022-10-17 00:22:31 - progress_bar.py[line:274] - INFO: epoch 001:  21557 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.8, ups=0.92, wpb=108.8, bsz=40, num_updates=21530, lr=4.98907e-05, gnorm=1.07, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103520
2022-10-17 00:22:43 - progress_bar.py[line:274] - INFO: epoch 001:  21567 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.8, ups=0.88, wpb=108.3, bsz=40, num_updates=21540, lr=4.98897e-05, gnorm=1.064, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103532
2022-10-17 00:22:54 - progress_bar.py[line:274] - INFO: epoch 001:  21577 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=21550, lr=4.98887e-05, gnorm=1.026, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103543
2022-10-17 00:23:05 - progress_bar.py[line:274] - INFO: epoch 001:  21587 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.6, ups=0.88, wpb=109.9, bsz=40, num_updates=21560, lr=4.98877e-05, gnorm=0.911, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103554
2022-10-17 00:23:16 - progress_bar.py[line:274] - INFO: epoch 001:  21597 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.3, ups=0.89, wpb=111.8, bsz=40, num_updates=21570, lr=4.98867e-05, gnorm=0.838, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103565
2022-10-17 00:23:28 - progress_bar.py[line:274] - INFO: epoch 001:  21607 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.6, ups=0.88, wpb=110, bsz=40, num_updates=21580, lr=4.98856e-05, gnorm=0.867, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103577
2022-10-17 00:23:39 - progress_bar.py[line:274] - INFO: epoch 001:  21617 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.1, ups=0.87, wpb=111.8, bsz=40, num_updates=21590, lr=4.98846e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103588
2022-10-17 00:23:50 - progress_bar.py[line:274] - INFO: epoch 001:  21627 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.7, ups=0.88, wpb=110.8, bsz=40, num_updates=21600, lr=4.98836e-05, gnorm=0.828, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103599
2022-10-17 00:24:02 - progress_bar.py[line:274] - INFO: epoch 001:  21637 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.4, ups=0.85, wpb=111.1, bsz=40, num_updates=21610, lr=4.98826e-05, gnorm=0.877, clip=30, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=103611
2022-10-17 00:24:14 - progress_bar.py[line:274] - INFO: epoch 001:  21647 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=21620, lr=4.98816e-05, gnorm=0.998, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103623
2022-10-17 00:24:25 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 00:24:26 - progress_bar.py[line:274] - INFO: epoch 001:  21658 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=90.9, ups=0.82, wpb=111.3, bsz=40, num_updates=21630, lr=4.98805e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=103635
2022-10-17 00:24:37 - progress_bar.py[line:274] - INFO: epoch 001:  21668 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=21640, lr=4.98795e-05, gnorm=1.14, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103646
2022-10-17 00:24:48 - progress_bar.py[line:274] - INFO: epoch 001:  21678 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=21650, lr=4.98785e-05, gnorm=1.313, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103657
2022-10-17 00:24:59 - progress_bar.py[line:274] - INFO: epoch 001:  21688 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.2, ups=0.91, wpb=109.6, bsz=40, num_updates=21660, lr=4.98775e-05, gnorm=0.906, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103668
2022-10-17 00:25:10 - progress_bar.py[line:274] - INFO: epoch 001:  21698 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=21670, lr=4.98765e-05, gnorm=0.871, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103679
2022-10-17 00:25:22 - progress_bar.py[line:274] - INFO: epoch 001:  21708 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=21680, lr=4.98755e-05, gnorm=0.921, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103691
2022-10-17 00:25:33 - progress_bar.py[line:274] - INFO: epoch 001:  21718 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98, ups=0.89, wpb=109.6, bsz=40, num_updates=21690, lr=4.98744e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=103702
2022-10-17 00:25:44 - progress_bar.py[line:274] - INFO: epoch 001:  21728 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.2, ups=0.88, wpb=110.7, bsz=40, num_updates=21700, lr=4.98734e-05, gnorm=0.844, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103713
2022-10-17 00:25:55 - progress_bar.py[line:274] - INFO: epoch 001:  21738 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.9, ups=0.9, wpb=110.4, bsz=40, num_updates=21710, lr=4.98724e-05, gnorm=0.831, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103724
2022-10-17 00:26:06 - progress_bar.py[line:274] - INFO: epoch 001:  21748 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.4, ups=0.91, wpb=110, bsz=40, num_updates=21720, lr=4.98714e-05, gnorm=0.974, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103735
2022-10-17 00:26:17 - progress_bar.py[line:274] - INFO: epoch 001:  21758 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.2, ups=0.9, wpb=112, bsz=40, num_updates=21730, lr=4.98704e-05, gnorm=0.81, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103746
2022-10-17 00:26:28 - progress_bar.py[line:274] - INFO: epoch 001:  21768 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98, ups=0.9, wpb=109.2, bsz=40, num_updates=21740, lr=4.98693e-05, gnorm=0.824, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103757
2022-10-17 00:26:40 - progress_bar.py[line:274] - INFO: epoch 001:  21778 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.8, ups=0.89, wpb=111.1, bsz=40, num_updates=21750, lr=4.98683e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103769
2022-10-17 00:26:51 - progress_bar.py[line:274] - INFO: epoch 001:  21788 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=21760, lr=4.98673e-05, gnorm=1.079, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103780
2022-10-17 00:27:02 - progress_bar.py[line:274] - INFO: epoch 001:  21798 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=103.8, ups=0.94, wpb=110.1, bsz=40, num_updates=21770, lr=4.98663e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=103791
2022-10-17 00:27:13 - progress_bar.py[line:274] - INFO: epoch 001:  21808 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.4, ups=0.9, wpb=111, bsz=40, num_updates=21780, lr=4.98653e-05, gnorm=0.854, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103802
2022-10-17 00:27:24 - progress_bar.py[line:274] - INFO: epoch 001:  21818 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.5, ups=0.89, wpb=108.7, bsz=40, num_updates=21790, lr=4.98643e-05, gnorm=0.919, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103813
2022-10-17 00:27:35 - progress_bar.py[line:274] - INFO: epoch 001:  21828 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=21800, lr=4.98632e-05, gnorm=0.807, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103824
2022-10-17 00:27:46 - progress_bar.py[line:274] - INFO: epoch 001:  21838 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.8, ups=0.92, wpb=111.2, bsz=40, num_updates=21810, lr=4.98622e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103835
2022-10-17 00:27:57 - progress_bar.py[line:274] - INFO: epoch 001:  21848 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=21820, lr=4.98612e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=103846
2022-10-17 00:28:08 - progress_bar.py[line:274] - INFO: epoch 001:  21858 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.7, ups=0.92, wpb=109.2, bsz=40, num_updates=21830, lr=4.98602e-05, gnorm=1.008, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103857
2022-10-17 00:28:19 - progress_bar.py[line:274] - INFO: epoch 001:  21868 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.6, ups=0.89, wpb=109.9, bsz=40, num_updates=21840, lr=4.98592e-05, gnorm=1.04, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=103868
2022-10-17 00:28:30 - progress_bar.py[line:274] - INFO: epoch 001:  21878 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.9, wpb=109.7, bsz=40, num_updates=21850, lr=4.98581e-05, gnorm=0.975, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103879
2022-10-17 00:28:41 - progress_bar.py[line:274] - INFO: epoch 001:  21888 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=21860, lr=4.98571e-05, gnorm=0.854, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103890
2022-10-17 00:28:53 - progress_bar.py[line:274] - INFO: epoch 001:  21898 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=21870, lr=4.98561e-05, gnorm=1.013, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103902
2022-10-17 00:29:04 - progress_bar.py[line:274] - INFO: epoch 001:  21908 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.8, ups=0.92, wpb=110.1, bsz=40, num_updates=21880, lr=4.98551e-05, gnorm=0.92, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103913
2022-10-17 00:29:15 - progress_bar.py[line:274] - INFO: epoch 001:  21918 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=21890, lr=4.98541e-05, gnorm=0.883, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103924
2022-10-17 00:29:26 - progress_bar.py[line:274] - INFO: epoch 001:  21928 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.6, ups=0.88, wpb=110, bsz=40, num_updates=21900, lr=4.9853e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=103935
2022-10-17 00:29:37 - progress_bar.py[line:274] - INFO: epoch 001:  21938 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.4, ups=0.92, wpb=111.5, bsz=40, num_updates=21910, lr=4.9852e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=103946
2022-10-17 00:29:48 - progress_bar.py[line:274] - INFO: epoch 001:  21948 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=21920, lr=4.9851e-05, gnorm=0.922, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103957
2022-10-17 00:30:00 - progress_bar.py[line:274] - INFO: epoch 001:  21958 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.1, ups=0.88, wpb=109.4, bsz=40, num_updates=21930, lr=4.985e-05, gnorm=1.013, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=103969
2022-10-17 00:30:11 - progress_bar.py[line:274] - INFO: epoch 001:  21968 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97, ups=0.88, wpb=109.8, bsz=40, num_updates=21940, lr=4.9849e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103980
2022-10-17 00:30:22 - progress_bar.py[line:274] - INFO: epoch 001:  21978 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=21950, lr=4.9848e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=103991
2022-10-17 00:30:33 - progress_bar.py[line:274] - INFO: epoch 001:  21988 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96, ups=0.88, wpb=109.3, bsz=40, num_updates=21960, lr=4.98469e-05, gnorm=0.943, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=104002
2022-10-17 00:30:44 - progress_bar.py[line:274] - INFO: epoch 001:  21998 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=21970, lr=4.98459e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=104013
2022-10-17 00:30:56 - progress_bar.py[line:274] - INFO: epoch 001:  22008 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=21980, lr=4.98449e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=104025
2022-10-17 00:31:07 - progress_bar.py[line:274] - INFO: epoch 001:  22018 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.4, ups=0.91, wpb=109.3, bsz=40, num_updates=21990, lr=4.98439e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=104036
2022-10-17 00:31:18 - progress_bar.py[line:274] - INFO: epoch 001:  22028 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.7, ups=0.9, wpb=111.5, bsz=40, num_updates=22000, lr=4.98429e-05, gnorm=0.823, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=104047
2022-10-17 00:31:18 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 00:31:19 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 00:31:19 - train.py[line:551] - INFO: load:1.38 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 00:33:51 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 00:33:51 - train.py[line:551] - INFO: load:1.40 valid_run:151.80 task_valid:148.47 collect_output:2.23
2022-10-17 00:36:20 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 00:36:20 - train.py[line:551] - INFO: load:1.43 valid_run:300.41 task_valid:292.33 collect_output:5.92
2022-10-17 00:38:52 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 00:38:52 - train.py[line:551] - INFO: load:1.46 valid_run:452.00 task_valid:435.44 collect_output:13.39
2022-10-17 00:41:20 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 00:41:20 - train.py[line:551] - INFO: load:1.48 valid_run:600.74 task_valid:580.48 collect_output:16.05
2022-10-17 00:43:52 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 00:43:52 - train.py[line:551] - INFO: load:1.51 valid_run:752.66 task_valid:727.87 collect_output:19.54
2022-10-17 00:46:24 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 00:46:24 - train.py[line:551] - INFO: load:1.54 valid_run:904.17 task_valid:873.49 collect_output:24.42
2022-10-17 00:48:57 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 00:48:57 - train.py[line:551] - INFO: load:1.56 valid_run:1056.71 task_valid:1019.47 collect_output:29.99
2022-10-17 00:51:27 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 00:51:27 - train.py[line:551] - INFO: load:1.59 valid_run:1207.32 task_valid:1160.60 collect_output:38.46
2022-10-17 00:53:56 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 00:53:56 - train.py[line:551] - INFO: load:1.61 valid_run:1356.52 task_valid:1305.19 collect_output:42.06
2022-10-17 00:56:25 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 00:56:25 - train.py[line:551] - INFO: load:1.64 valid_run:1504.92 task_valid:1448.43 collect_output:46.20
2022-10-17 00:58:54 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 00:58:54 - train.py[line:551] - INFO: load:1.66 valid_run:1654.21 task_valid:1593.31 collect_output:49.59
2022-10-17 01:01:24 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 01:01:24 - train.py[line:551] - INFO: load:1.69 valid_run:1803.74 task_valid:1738.27 collect_output:53.13
2022-10-17 01:03:53 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 01:03:53 - train.py[line:551] - INFO: load:1.72 valid_run:1953.27 task_valid:1880.28 collect_output:59.61
2022-10-17 01:06:24 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 01:06:24 - train.py[line:551] - INFO: load:1.74 valid_run:2103.75 task_valid:2025.88 collect_output:63.49
2022-10-17 01:08:54 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 01:08:54 - train.py[line:551] - INFO: load:1.77 valid_run:2253.47 task_valid:2172.22 collect_output:65.86
2022-10-17 01:11:23 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 01:11:23 - train.py[line:551] - INFO: load:1.79 valid_run:2403.11 task_valid:2316.34 collect_output:70.37
2022-10-17 01:13:55 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 01:13:55 - train.py[line:551] - INFO: load:1.82 valid_run:2554.47 task_valid:2461.74 collect_output:75.34
2022-10-17 01:16:25 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 01:16:25 - train.py[line:551] - INFO: load:1.85 valid_run:2704.85 task_valid:2608.70 collect_output:77.74
2022-10-17 01:18:53 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 01:18:53 - train.py[line:551] - INFO: load:1.87 valid_run:2852.83 task_valid:2750.38 collect_output:83.03
2022-10-17 01:21:24 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 01:21:24 - train.py[line:551] - INFO: load:1.90 valid_run:3003.25 task_valid:2896.00 collect_output:86.77
2022-10-17 01:23:56 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 01:23:56 - train.py[line:551] - INFO: load:1.93 valid_run:3155.30 task_valid:3041.13 collect_output:92.52
2022-10-17 01:26:26 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 01:26:26 - train.py[line:551] - INFO: load:1.95 valid_run:3304.86 task_valid:3186.20 collect_output:95.85
2022-10-17 01:28:58 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 01:28:58 - train.py[line:551] - INFO: load:1.98 valid_run:3456.78 task_valid:3333.19 collect_output:99.63
2022-10-17 01:31:29 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 01:31:29 - train.py[line:551] - INFO: load:2.01 valid_run:3608.55 task_valid:3480.38 collect_output:103.11

====================================================================================================
SGG eval:     R @ 50: 0.4910;     R @ 100: 0.5416;     R @ 500: 0.5732;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3105;    mR @ 100: 0.3869;    mR @ 500: 0.4232;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6171) (covered in:0.7083) (covering:0.3714) (eating:0.5000) (flying in:0.5000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.0333) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8438) (playing:0.0000) (riding:0.7974) (says:0.0000) (sitting on:0.6633) (standing on:0.1920) (using:0.7000) (walking in:0.3333) (walking on:0.5450) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4910;     R @ 100: 0.5416;     R @ 500: 0.5732;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3105;    mR @ 100: 0.3869;    mR @ 500: 0.4232;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6171) (covered in:0.7083) (covering:0.3714) (eating:0.5000) (flying in:0.5000) (growing on:0.2500) (hanging from:0.4194) (lying on:0.0333) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8438) (playing:0.0000) (riding:0.7974) (says:0.0000) (sitting on:0.6633) (standing on:0.1920) (using:0.7000) (walking in:0.3333) (walking on:0.5450) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2022-10-17 01:34:01 - train.py[line:487] - INFO: 0.5416148459383753
2022-10-17 01:34:01 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 01:34:01 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.335 | loss_v1 0 | loss_v2 0 | nll_loss 0.172 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.541615 | ppl 1.13 | vqa_score 0.4764 | wps 119.3 | wpb 89.9 | bsz 30 | num_updates 22000 | best_R@100 0.581461
2022-10-17 01:34:01 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 22000 updates
2022-10-17 01:34:01 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_22000.pt
2022-10-17 01:34:07 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_22000.pt
2022-10-17 01:34:10 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_22000.pt (epoch 1 @ 22000 updates, score 0.5416148459383753) (writing took 8.663623979780823 seconds)
2022-10-17 01:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  22038 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=22010, lr=4.98418e-05, gnorm=0.904, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107830
2022-10-17 01:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  22048 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.1, ups=0.89, wpb=109.6, bsz=40, num_updates=22020, lr=4.98408e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=107841
2022-10-17 01:34:43 - progress_bar.py[line:274] - INFO: epoch 001:  22058 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=22030, lr=4.98398e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=107852
2022-10-17 01:34:54 - progress_bar.py[line:274] - INFO: epoch 001:  22068 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102, ups=0.94, wpb=109, bsz=40, num_updates=22040, lr=4.98388e-05, gnorm=0.957, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=107863
2022-10-17 01:35:05 - progress_bar.py[line:274] - INFO: epoch 001:  22078 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=22050, lr=4.98378e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107874
2022-10-17 01:35:16 - progress_bar.py[line:274] - INFO: epoch 001:  22088 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101, ups=0.91, wpb=110.4, bsz=40, num_updates=22060, lr=4.98368e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=107885
2022-10-17 01:35:27 - progress_bar.py[line:274] - INFO: epoch 001:  22098 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.6, ups=0.9, wpb=111.4, bsz=40, num_updates=22070, lr=4.98357e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=107896
2022-10-17 01:35:38 - progress_bar.py[line:274] - INFO: epoch 001:  22108 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.5, ups=0.9, wpb=111.4, bsz=40, num_updates=22080, lr=4.98347e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=107907
2022-10-17 01:35:50 - progress_bar.py[line:274] - INFO: epoch 001:  22118 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.4, ups=0.88, wpb=109.3, bsz=40, num_updates=22090, lr=4.98337e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=107919
2022-10-17 01:36:01 - progress_bar.py[line:274] - INFO: epoch 001:  22128 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.2, ups=0.91, wpb=109.9, bsz=40, num_updates=22100, lr=4.98327e-05, gnorm=0.928, clip=20, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=107930
2022-10-17 01:36:12 - progress_bar.py[line:274] - INFO: epoch 001:  22138 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=22110, lr=4.98317e-05, gnorm=0.751, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107941
2022-10-17 01:36:23 - progress_bar.py[line:274] - INFO: epoch 001:  22148 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=22120, lr=4.98306e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=107952
2022-10-17 01:36:34 - progress_bar.py[line:274] - INFO: epoch 001:  22158 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=22130, lr=4.98296e-05, gnorm=0.779, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107963
2022-10-17 01:36:45 - progress_bar.py[line:274] - INFO: epoch 001:  22168 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=22140, lr=4.98286e-05, gnorm=0.92, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107974
2022-10-17 01:36:56 - progress_bar.py[line:274] - INFO: epoch 001:  22178 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.5, ups=0.89, wpb=110.9, bsz=40, num_updates=22150, lr=4.98276e-05, gnorm=1.031, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=107985
2022-10-17 01:37:08 - progress_bar.py[line:274] - INFO: epoch 001:  22188 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.1, ups=0.89, wpb=111.3, bsz=40, num_updates=22160, lr=4.98266e-05, gnorm=0.909, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=107997
2022-10-17 01:37:19 - progress_bar.py[line:274] - INFO: epoch 001:  22198 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.5, ups=0.91, wpb=110.1, bsz=40, num_updates=22170, lr=4.98256e-05, gnorm=0.814, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108008
2022-10-17 01:37:30 - progress_bar.py[line:274] - INFO: epoch 001:  22208 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=22180, lr=4.98245e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108019
2022-10-17 01:37:41 - progress_bar.py[line:274] - INFO: epoch 001:  22218 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=22190, lr=4.98235e-05, gnorm=0.777, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108030
2022-10-17 01:37:53 - progress_bar.py[line:274] - INFO: epoch 001:  22228 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=22200, lr=4.98225e-05, gnorm=0.892, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108042
2022-10-17 01:38:04 - progress_bar.py[line:274] - INFO: epoch 001:  22238 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=22210, lr=4.98215e-05, gnorm=0.941, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108053
2022-10-17 01:38:15 - progress_bar.py[line:274] - INFO: epoch 001:  22248 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.6, ups=0.91, wpb=110.3, bsz=40, num_updates=22220, lr=4.98205e-05, gnorm=0.79, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108064
2022-10-17 01:38:26 - progress_bar.py[line:274] - INFO: epoch 001:  22258 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.5, ups=0.87, wpb=112.2, bsz=40, num_updates=22230, lr=4.98194e-05, gnorm=0.875, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108075
2022-10-17 01:38:38 - progress_bar.py[line:274] - INFO: epoch 001:  22268 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97, ups=0.88, wpb=110.7, bsz=40, num_updates=22240, lr=4.98184e-05, gnorm=0.861, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108087
2022-10-17 01:38:49 - progress_bar.py[line:274] - INFO: epoch 001:  22278 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=22250, lr=4.98174e-05, gnorm=1.083, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=108098
2022-10-17 01:39:00 - progress_bar.py[line:274] - INFO: epoch 001:  22288 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=22260, lr=4.98164e-05, gnorm=0.9, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108109
2022-10-17 01:39:11 - progress_bar.py[line:274] - INFO: epoch 001:  22298 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.9, ups=0.91, wpb=110.5, bsz=40, num_updates=22270, lr=4.98154e-05, gnorm=0.934, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108120
2022-10-17 01:39:22 - progress_bar.py[line:274] - INFO: epoch 001:  22308 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.3, ups=0.9, wpb=111.3, bsz=40, num_updates=22280, lr=4.98144e-05, gnorm=1.062, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108131
2022-10-17 01:39:34 - progress_bar.py[line:274] - INFO: epoch 001:  22318 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.5, ups=0.89, wpb=109.3, bsz=40, num_updates=22290, lr=4.98133e-05, gnorm=0.865, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=108143
2022-10-17 01:39:45 - progress_bar.py[line:274] - INFO: epoch 001:  22328 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=22300, lr=4.98123e-05, gnorm=1.057, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=108154
2022-10-17 01:39:56 - progress_bar.py[line:274] - INFO: epoch 001:  22338 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=22310, lr=4.98113e-05, gnorm=0.978, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108165
2022-10-17 01:40:07 - progress_bar.py[line:274] - INFO: epoch 001:  22348 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=22320, lr=4.98103e-05, gnorm=0.897, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108176
2022-10-17 01:40:19 - progress_bar.py[line:274] - INFO: epoch 001:  22358 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.9, ups=0.88, wpb=111.5, bsz=40, num_updates=22330, lr=4.98093e-05, gnorm=0.794, clip=20, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=108187
2022-10-17 01:40:30 - progress_bar.py[line:274] - INFO: epoch 001:  22368 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=22340, lr=4.98082e-05, gnorm=0.847, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108199
2022-10-17 01:40:41 - progress_bar.py[line:274] - INFO: epoch 001:  22378 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.1, ups=0.91, wpb=110.9, bsz=40, num_updates=22350, lr=4.98072e-05, gnorm=0.803, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108210
2022-10-17 01:40:52 - progress_bar.py[line:274] - INFO: epoch 001:  22388 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.8, ups=0.88, wpb=110.3, bsz=40, num_updates=22360, lr=4.98062e-05, gnorm=0.937, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=108221
2022-10-17 01:41:03 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 01:41:04 - progress_bar.py[line:274] - INFO: epoch 001:  22399 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.6, ups=0.82, wpb=111.2, bsz=40, num_updates=22370, lr=4.98052e-05, gnorm=1.021, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=108233
2022-10-17 01:41:16 - progress_bar.py[line:274] - INFO: epoch 001:  22409 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.8, ups=0.89, wpb=107.7, bsz=40, num_updates=22380, lr=4.98042e-05, gnorm=1.02, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108245
2022-10-17 01:41:27 - progress_bar.py[line:274] - INFO: epoch 001:  22419 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.9, ups=0.92, wpb=111.4, bsz=40, num_updates=22390, lr=4.98032e-05, gnorm=0.858, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108256
2022-10-17 01:41:38 - progress_bar.py[line:274] - INFO: epoch 001:  22429 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.8, ups=0.89, wpb=109.3, bsz=40, num_updates=22400, lr=4.98021e-05, gnorm=0.95, clip=40, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=108267
2022-10-17 01:41:49 - progress_bar.py[line:274] - INFO: epoch 001:  22439 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.1, ups=0.87, wpb=110.5, bsz=40, num_updates=22410, lr=4.98011e-05, gnorm=0.875, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108278
2022-10-17 01:42:00 - progress_bar.py[line:274] - INFO: epoch 001:  22449 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=22420, lr=4.98001e-05, gnorm=1.056, clip=80, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=108289
2022-10-17 01:42:12 - progress_bar.py[line:274] - INFO: epoch 001:  22459 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.89, wpb=109.4, bsz=40, num_updates=22430, lr=4.97991e-05, gnorm=0.976, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108301
2022-10-17 01:42:23 - progress_bar.py[line:274] - INFO: epoch 001:  22469 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.9, ups=0.9, wpb=109.9, bsz=40, num_updates=22440, lr=4.97981e-05, gnorm=0.931, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=108312
2022-10-17 01:42:34 - progress_bar.py[line:274] - INFO: epoch 001:  22479 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101, ups=0.92, wpb=110.3, bsz=40, num_updates=22450, lr=4.9797e-05, gnorm=0.772, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108323
2022-10-17 01:42:45 - progress_bar.py[line:274] - INFO: epoch 001:  22489 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.6, ups=0.9, wpb=109, bsz=40, num_updates=22460, lr=4.9796e-05, gnorm=0.869, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=108334
2022-10-17 01:42:56 - progress_bar.py[line:274] - INFO: epoch 001:  22499 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=22470, lr=4.9795e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108345
2022-10-17 01:43:07 - progress_bar.py[line:274] - INFO: epoch 001:  22509 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.1, ups=0.9, wpb=108.7, bsz=40, num_updates=22480, lr=4.9794e-05, gnorm=1.001, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108356
2022-10-17 01:43:18 - progress_bar.py[line:274] - INFO: epoch 001:  22519 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.9, ups=0.9, wpb=111.3, bsz=40, num_updates=22490, lr=4.9793e-05, gnorm=0.849, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108367
2022-10-17 01:43:29 - progress_bar.py[line:274] - INFO: epoch 001:  22529 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101, ups=0.92, wpb=109.8, bsz=40, num_updates=22500, lr=4.97919e-05, gnorm=0.962, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108378
2022-10-17 01:43:40 - progress_bar.py[line:274] - INFO: epoch 001:  22539 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.1, ups=0.88, wpb=109.3, bsz=40, num_updates=22510, lr=4.97909e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108389
2022-10-17 01:43:51 - progress_bar.py[line:274] - INFO: epoch 001:  22549 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.6, ups=0.91, wpb=108.9, bsz=40, num_updates=22520, lr=4.97899e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108400
2022-10-17 01:44:03 - progress_bar.py[line:274] - INFO: epoch 001:  22559 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.6, ups=0.87, wpb=110.9, bsz=40, num_updates=22530, lr=4.97889e-05, gnorm=0.816, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108412
2022-10-17 01:44:14 - progress_bar.py[line:274] - INFO: epoch 001:  22569 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=22540, lr=4.97879e-05, gnorm=1.035, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108423
2022-10-17 01:44:25 - progress_bar.py[line:274] - INFO: epoch 001:  22579 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=22550, lr=4.97869e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108434
2022-10-17 01:44:36 - progress_bar.py[line:274] - INFO: epoch 001:  22589 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.7, ups=0.93, wpb=110.8, bsz=40, num_updates=22560, lr=4.97858e-05, gnorm=0.926, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108445
2022-10-17 01:44:47 - progress_bar.py[line:274] - INFO: epoch 001:  22599 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=22570, lr=4.97848e-05, gnorm=0.825, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108456
2022-10-17 01:44:59 - progress_bar.py[line:274] - INFO: epoch 001:  22609 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.1, ups=0.88, wpb=110.9, bsz=40, num_updates=22580, lr=4.97838e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108468
2022-10-17 01:45:10 - progress_bar.py[line:274] - INFO: epoch 001:  22619 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.2, ups=0.9, wpb=108.7, bsz=40, num_updates=22590, lr=4.97828e-05, gnorm=0.988, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108479
2022-10-17 01:45:21 - progress_bar.py[line:274] - INFO: epoch 001:  22629 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=22600, lr=4.97818e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108490
2022-10-17 01:45:33 - progress_bar.py[line:274] - INFO: epoch 001:  22639 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96, ups=0.88, wpb=109.6, bsz=40, num_updates=22610, lr=4.97807e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108502
2022-10-17 01:45:44 - progress_bar.py[line:274] - INFO: epoch 001:  22649 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.1, ups=0.93, wpb=110.3, bsz=40, num_updates=22620, lr=4.97797e-05, gnorm=0.842, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=108512
2022-10-17 01:45:55 - progress_bar.py[line:274] - INFO: epoch 001:  22659 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.6, ups=0.88, wpb=111.1, bsz=40, num_updates=22630, lr=4.97787e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108524
2022-10-17 01:46:06 - progress_bar.py[line:274] - INFO: epoch 001:  22669 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.1, ups=0.89, wpb=111.5, bsz=40, num_updates=22640, lr=4.97777e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108535
2022-10-17 01:46:18 - progress_bar.py[line:274] - INFO: epoch 001:  22679 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=22650, lr=4.97767e-05, gnorm=0.813, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=108546
2022-10-17 01:46:29 - progress_bar.py[line:274] - INFO: epoch 001:  22689 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98, ups=0.88, wpb=111.5, bsz=40, num_updates=22660, lr=4.97757e-05, gnorm=0.906, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=108558
2022-10-17 01:46:40 - progress_bar.py[line:274] - INFO: epoch 001:  22699 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.5, ups=0.9, wpb=109.2, bsz=40, num_updates=22670, lr=4.97746e-05, gnorm=0.849, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108569
2022-10-17 01:46:51 - progress_bar.py[line:274] - INFO: epoch 001:  22709 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.8, ups=0.91, wpb=111.5, bsz=40, num_updates=22680, lr=4.97736e-05, gnorm=1.02, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108580
2022-10-17 01:47:02 - progress_bar.py[line:274] - INFO: epoch 001:  22719 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102, ups=0.92, wpb=110.3, bsz=40, num_updates=22690, lr=4.97726e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108591
2022-10-17 01:47:13 - progress_bar.py[line:274] - INFO: epoch 001:  22729 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.4, ups=0.89, wpb=109.2, bsz=40, num_updates=22700, lr=4.97716e-05, gnorm=0.861, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108602
2022-10-17 01:47:24 - progress_bar.py[line:274] - INFO: epoch 001:  22739 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=22710, lr=4.97706e-05, gnorm=0.857, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108613
2022-10-17 01:47:35 - progress_bar.py[line:274] - INFO: epoch 001:  22749 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=22720, lr=4.97695e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108624
2022-10-17 01:47:46 - progress_bar.py[line:274] - INFO: epoch 001:  22759 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.3, ups=0.93, wpb=109.2, bsz=40, num_updates=22730, lr=4.97685e-05, gnorm=0.956, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108635
2022-10-17 01:47:57 - progress_bar.py[line:274] - INFO: epoch 001:  22769 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.4, ups=0.89, wpb=109, bsz=40, num_updates=22740, lr=4.97675e-05, gnorm=1.074, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108646
2022-10-17 01:48:09 - progress_bar.py[line:274] - INFO: epoch 001:  22779 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.5, ups=0.89, wpb=109.7, bsz=40, num_updates=22750, lr=4.97665e-05, gnorm=1.055, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108658
2022-10-17 01:48:20 - progress_bar.py[line:274] - INFO: epoch 001:  22789 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.8, ups=0.9, wpb=109.4, bsz=40, num_updates=22760, lr=4.97655e-05, gnorm=0.995, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108669
2022-10-17 01:48:31 - progress_bar.py[line:274] - INFO: epoch 001:  22799 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.1, ups=0.88, wpb=109.4, bsz=40, num_updates=22770, lr=4.97645e-05, gnorm=0.963, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108680
2022-10-17 01:48:43 - progress_bar.py[line:274] - INFO: epoch 001:  22809 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.5, ups=0.86, wpb=110.5, bsz=40, num_updates=22780, lr=4.97634e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=108692
2022-10-17 01:48:54 - progress_bar.py[line:274] - INFO: epoch 001:  22819 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.8, ups=0.89, wpb=110.2, bsz=40, num_updates=22790, lr=4.97624e-05, gnorm=0.871, clip=10, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=108703
2022-10-17 01:49:05 - progress_bar.py[line:274] - INFO: epoch 001:  22829 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=22800, lr=4.97614e-05, gnorm=0.852, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108714
2022-10-17 01:49:16 - progress_bar.py[line:274] - INFO: epoch 001:  22839 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.8, ups=0.9, wpb=109.8, bsz=40, num_updates=22810, lr=4.97604e-05, gnorm=0.888, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108725
2022-10-17 01:49:28 - progress_bar.py[line:274] - INFO: epoch 001:  22849 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.4, ups=0.89, wpb=112.1, bsz=40, num_updates=22820, lr=4.97594e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=108737
2022-10-17 01:49:39 - progress_bar.py[line:274] - INFO: epoch 001:  22859 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.4, ups=0.88, wpb=111.1, bsz=40, num_updates=22830, lr=4.97583e-05, gnorm=0.812, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108748
2022-10-17 01:49:50 - progress_bar.py[line:274] - INFO: epoch 001:  22869 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.6, ups=0.9, wpb=109.3, bsz=40, num_updates=22840, lr=4.97573e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108759
2022-10-17 01:50:01 - progress_bar.py[line:274] - INFO: epoch 001:  22879 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=22850, lr=4.97563e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108770
2022-10-17 01:50:12 - progress_bar.py[line:274] - INFO: epoch 001:  22889 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.6, ups=0.92, wpb=111, bsz=40, num_updates=22860, lr=4.97553e-05, gnorm=0.92, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108781
2022-10-17 01:50:23 - progress_bar.py[line:274] - INFO: epoch 001:  22899 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=103.7, ups=0.93, wpb=111.8, bsz=40, num_updates=22870, lr=4.97543e-05, gnorm=0.891, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108792
2022-10-17 01:50:34 - progress_bar.py[line:274] - INFO: epoch 001:  22909 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.8, ups=0.88, wpb=109.7, bsz=40, num_updates=22880, lr=4.97533e-05, gnorm=0.857, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108803
2022-10-17 01:50:46 - progress_bar.py[line:274] - INFO: epoch 001:  22919 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.6, ups=0.88, wpb=108.9, bsz=40, num_updates=22890, lr=4.97522e-05, gnorm=1.011, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108815
2022-10-17 01:50:57 - progress_bar.py[line:274] - INFO: epoch 001:  22929 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.4, ups=0.89, wpb=111.5, bsz=40, num_updates=22900, lr=4.97512e-05, gnorm=0.784, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=108826
2022-10-17 01:51:08 - progress_bar.py[line:274] - INFO: epoch 001:  22939 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.3, ups=0.93, wpb=110.2, bsz=40, num_updates=22910, lr=4.97502e-05, gnorm=0.983, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108837
2022-10-17 01:51:19 - progress_bar.py[line:274] - INFO: epoch 001:  22949 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=22920, lr=4.97492e-05, gnorm=0.824, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108848
2022-10-17 01:51:30 - progress_bar.py[line:274] - INFO: epoch 001:  22959 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.5, ups=0.88, wpb=109.6, bsz=40, num_updates=22930, lr=4.97482e-05, gnorm=0.838, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108859
2022-10-17 01:51:41 - progress_bar.py[line:274] - INFO: epoch 001:  22969 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.7, ups=0.93, wpb=109.7, bsz=40, num_updates=22940, lr=4.97471e-05, gnorm=0.931, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108870
2022-10-17 01:51:52 - progress_bar.py[line:274] - INFO: epoch 001:  22979 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=22950, lr=4.97461e-05, gnorm=0.976, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108881
2022-10-17 01:52:04 - progress_bar.py[line:274] - INFO: epoch 001:  22989 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=22960, lr=4.97451e-05, gnorm=0.94, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108893
2022-10-17 01:52:15 - progress_bar.py[line:274] - INFO: epoch 001:  22999 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=102, ups=0.91, wpb=112.5, bsz=40, num_updates=22970, lr=4.97441e-05, gnorm=0.875, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=108904
2022-10-17 01:52:26 - progress_bar.py[line:274] - INFO: epoch 001:  23009 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.5, ups=0.87, wpb=111.1, bsz=40, num_updates=22980, lr=4.97431e-05, gnorm=0.885, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=108915
2022-10-17 01:52:38 - progress_bar.py[line:274] - INFO: epoch 001:  23019 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.2, ups=0.87, wpb=109.3, bsz=40, num_updates=22990, lr=4.9742e-05, gnorm=0.959, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=108927
2022-10-17 01:52:49 - progress_bar.py[line:274] - INFO: epoch 001:  23029 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=23000, lr=4.9741e-05, gnorm=0.942, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=108938
2022-10-17 01:52:49 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 01:52:50 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 01:52:50 - train.py[line:551] - INFO: load:0.94 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 01:55:22 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 01:55:22 - train.py[line:551] - INFO: load:0.97 valid_run:151.73 task_valid:147.99 collect_output:2.68
2022-10-17 01:57:50 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 01:57:50 - train.py[line:551] - INFO: load:0.99 valid_run:299.65 task_valid:291.07 collect_output:6.51
2022-10-17 02:00:22 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 02:00:22 - train.py[line:551] - INFO: load:1.02 valid_run:451.29 task_valid:434.22 collect_output:14.01
2022-10-17 02:02:51 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 02:02:51 - train.py[line:551] - INFO: load:1.04 valid_run:600.06 task_valid:579.03 collect_output:16.99
2022-10-17 02:05:23 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 02:05:23 - train.py[line:551] - INFO: load:1.07 valid_run:751.86 task_valid:726.33 collect_output:20.51
2022-10-17 02:07:54 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 02:07:54 - train.py[line:551] - INFO: load:1.09 valid_run:902.92 task_valid:871.70 collect_output:25.21
2022-10-17 02:10:26 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 02:10:26 - train.py[line:551] - INFO: load:1.12 valid_run:1055.60 task_valid:1017.69 collect_output:30.91
2022-10-17 02:12:57 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 02:12:57 - train.py[line:551] - INFO: load:1.14 valid_run:1206.28 task_valid:1158.59 collect_output:39.72
2022-10-17 02:15:26 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 02:15:26 - train.py[line:551] - INFO: load:1.17 valid_run:1355.37 task_valid:1303.10 collect_output:43.32
2022-10-17 02:17:54 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 02:17:54 - train.py[line:551] - INFO: load:1.19 valid_run:1503.43 task_valid:1445.99 collect_output:47.51
2022-10-17 02:20:24 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 02:20:24 - train.py[line:551] - INFO: load:1.22 valid_run:1652.75 task_valid:1590.67 collect_output:51.15
2022-10-17 02:22:54 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 02:22:54 - train.py[line:551] - INFO: load:1.25 valid_run:1802.50 task_valid:1735.57 collect_output:55.03
2022-10-17 02:25:23 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 02:25:23 - train.py[line:551] - INFO: load:1.27 valid_run:1951.88 task_valid:1877.16 collect_output:61.81
2022-10-17 02:27:53 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 02:27:53 - train.py[line:551] - INFO: load:1.30 valid_run:2101.88 task_valid:2022.46 collect_output:65.51
2022-10-17 02:30:23 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 02:30:23 - train.py[line:551] - INFO: load:1.32 valid_run:2251.42 task_valid:2168.65 collect_output:67.87
2022-10-17 02:32:53 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 02:32:53 - train.py[line:551] - INFO: load:1.35 valid_run:2401.10 task_valid:2312.74 collect_output:72.48
2022-10-17 02:35:24 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 02:35:24 - train.py[line:551] - INFO: load:1.38 valid_run:2552.77 task_valid:2458.60 collect_output:77.26
2022-10-17 02:37:56 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 02:37:56 - train.py[line:551] - INFO: load:1.40 valid_run:2703.99 task_valid:2606.33 collect_output:79.61
2022-10-17 02:40:24 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 02:40:24 - train.py[line:551] - INFO: load:1.43 valid_run:2852.37 task_valid:2748.33 collect_output:84.94
2022-10-17 02:42:55 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 02:42:55 - train.py[line:551] - INFO: load:1.45 valid_run:3003.09 task_valid:2894.15 collect_output:88.77
2022-10-17 02:45:27 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 02:45:27 - train.py[line:551] - INFO: load:1.48 valid_run:3155.31 task_valid:3039.04 collect_output:95.02
2022-10-17 02:47:57 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 02:47:57 - train.py[line:551] - INFO: load:1.53 valid_run:3304.82 task_valid:3184.01 collect_output:98.49
2022-10-17 02:50:28 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 02:50:28 - train.py[line:551] - INFO: load:1.56 valid_run:3456.26 task_valid:3330.75 collect_output:102.16
2022-10-17 02:53:00 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 02:53:00 - train.py[line:551] - INFO: load:1.59 valid_run:3608.07 task_valid:3477.97 collect_output:105.68

====================================================================================================
SGG eval:     R @ 50: 0.4888;     R @ 100: 0.5452;     R @ 500: 0.5755;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3067;    mR @ 100: 0.3862;    mR @ 500: 0.4211;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6171) (covered in:0.7500) (covering:0.3714) (eating:0.5000) (flying in:0.5000) (growing on:0.2500) (hanging from:0.4323) (lying on:0.0333) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8378) (playing:0.0000) (riding:0.7990) (says:0.0000) (sitting on:0.6599) (standing on:0.2070) (using:0.6500) (walking in:0.3333) (walking on:0.5180) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2022-10-17 02:55:31 - train.py[line:487] - INFO: 0.5452271708683475

====================================================================================================
SGG eval:     R @ 50: 0.4888;     R @ 100: 0.5452;     R @ 500: 0.5755;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3067;    mR @ 100: 0.3862;    mR @ 500: 0.4211;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6171) (covered in:0.7500) (covering:0.3714) (eating:0.5000) (flying in:0.5000) (growing on:0.2500) (hanging from:0.4323) (lying on:0.0333) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8378) (playing:0.0000) (riding:0.7990) (says:0.0000) (sitting on:0.6599) (standing on:0.2070) (using:0.6500) (walking in:0.3333) (walking on:0.5180) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2022-10-17 02:55:32 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 02:55:32 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.359 | loss_v1 0 | loss_v2 0 | nll_loss 0.208 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.545227 | ppl 1.15 | vqa_score 0.473 | wps 119.3 | wpb 89.9 | bsz 30 | num_updates 23000 | best_R@100 0.581461
2022-10-17 02:55:32 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 23000 updates
2022-10-17 02:55:32 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_23000.pt
2022-10-17 02:55:37 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_23000.pt
2022-10-17 02:55:40 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_23000.pt (epoch 1 @ 23000 updates, score 0.5452271708683475) (writing took 8.723133059218526 seconds)
2022-10-17 02:55:51 - progress_bar.py[line:274] - INFO: epoch 001:  23039 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=0.3, ups=0, wpb=110, bsz=40, num_updates=23010, lr=4.974e-05, gnorm=1.089, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=112720
2022-10-17 02:56:02 - progress_bar.py[line:274] - INFO: epoch 001:  23049 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=23020, lr=4.9739e-05, gnorm=1.032, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=112731
2022-10-17 02:56:14 - progress_bar.py[line:274] - INFO: epoch 001:  23059 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.8, ups=0.9, wpb=111.8, bsz=40, num_updates=23030, lr=4.9738e-05, gnorm=0.869, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=112743
2022-10-17 02:56:24 - progress_bar.py[line:274] - INFO: epoch 001:  23069 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.4, ups=0.91, wpb=108.6, bsz=40, num_updates=23040, lr=4.9737e-05, gnorm=0.993, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=112753
2022-10-17 02:56:36 - progress_bar.py[line:274] - INFO: epoch 001:  23079 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=23050, lr=4.97359e-05, gnorm=0.962, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=112765
2022-10-17 02:56:46 - progress_bar.py[line:274] - INFO: epoch 001:  23089 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.6, ups=0.93, wpb=110.8, bsz=40, num_updates=23060, lr=4.97349e-05, gnorm=1.178, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=112775
2022-10-17 02:56:58 - progress_bar.py[line:274] - INFO: epoch 001:  23099 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=23070, lr=4.97339e-05, gnorm=0.973, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=112787
2022-10-17 02:57:09 - progress_bar.py[line:274] - INFO: epoch 001:  23109 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.2, ups=0.9, wpb=110.3, bsz=40, num_updates=23080, lr=4.97329e-05, gnorm=0.824, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=112798
2022-10-17 02:57:20 - progress_bar.py[line:274] - INFO: epoch 001:  23119 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=23090, lr=4.97319e-05, gnorm=0.848, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=112809
2022-10-17 02:57:31 - progress_bar.py[line:274] - INFO: epoch 001:  23129 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=23100, lr=4.97308e-05, gnorm=0.769, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=112820
2022-10-17 02:57:42 - progress_bar.py[line:274] - INFO: epoch 001:  23139 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.8, ups=0.91, wpb=109.2, bsz=40, num_updates=23110, lr=4.97298e-05, gnorm=0.899, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=112831
2022-10-17 02:57:53 - progress_bar.py[line:274] - INFO: epoch 001:  23149 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=23120, lr=4.97288e-05, gnorm=0.864, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=112842
2022-10-17 02:58:04 - progress_bar.py[line:274] - INFO: epoch 001:  23159 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97, ups=0.89, wpb=108.5, bsz=40, num_updates=23130, lr=4.97278e-05, gnorm=0.916, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=112853
2022-10-17 02:58:16 - progress_bar.py[line:274] - INFO: epoch 001:  23169 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=23140, lr=4.97268e-05, gnorm=0.858, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=112865
2022-10-17 02:58:27 - progress_bar.py[line:274] - INFO: epoch 001:  23179 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=23150, lr=4.97258e-05, gnorm=0.968, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=112876
2022-10-17 02:58:38 - progress_bar.py[line:274] - INFO: epoch 001:  23189 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=23160, lr=4.97247e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=112887
2022-10-17 02:58:49 - progress_bar.py[line:274] - INFO: epoch 001:  23199 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=23170, lr=4.97237e-05, gnorm=0.842, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=112898
2022-10-17 02:59:00 - progress_bar.py[line:274] - INFO: epoch 001:  23209 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.3, ups=0.92, wpb=111.5, bsz=40, num_updates=23180, lr=4.97227e-05, gnorm=0.875, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=112909
2022-10-17 02:59:11 - progress_bar.py[line:274] - INFO: epoch 001:  23219 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.6, ups=0.93, wpb=109.7, bsz=40, num_updates=23190, lr=4.97217e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=112920
2022-10-17 02:59:22 - progress_bar.py[line:274] - INFO: epoch 001:  23229 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.92, wpb=107.5, bsz=40, num_updates=23200, lr=4.97207e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=112931
2022-10-17 02:59:33 - progress_bar.py[line:274] - INFO: epoch 001:  23239 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=23210, lr=4.97196e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=112942
2022-10-17 02:59:44 - progress_bar.py[line:274] - INFO: epoch 001:  23249 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=23220, lr=4.97186e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=112953
2022-10-17 02:59:56 - progress_bar.py[line:274] - INFO: epoch 001:  23259 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.4, ups=0.89, wpb=108.9, bsz=40, num_updates=23230, lr=4.97176e-05, gnorm=0.868, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=112965
2022-10-17 03:00:11 - progress_bar.py[line:274] - INFO: epoch 001:  23269 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=23240, lr=4.97166e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=112976
2022-10-17 03:00:23 - progress_bar.py[line:274] - INFO: epoch 001:  23279 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.6, ups=0.87, wpb=110.6, bsz=40, num_updates=23250, lr=4.97156e-05, gnorm=0.795, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=112992
2022-10-17 03:00:34 - progress_bar.py[line:274] - INFO: epoch 001:  23289 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.4, ups=0.88, wpb=110.8, bsz=40, num_updates=23260, lr=4.97146e-05, gnorm=1.045, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113003
2022-10-17 03:00:45 - progress_bar.py[line:274] - INFO: epoch 001:  23299 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.2, ups=0.9, wpb=111.2, bsz=40, num_updates=23270, lr=4.97135e-05, gnorm=0.854, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113014
2022-10-17 03:00:57 - progress_bar.py[line:274] - INFO: epoch 001:  23309 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.3, ups=0.87, wpb=111.8, bsz=40, num_updates=23280, lr=4.97125e-05, gnorm=0.927, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113026
2022-10-17 03:01:08 - progress_bar.py[line:274] - INFO: epoch 001:  23319 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.3, ups=0.88, wpb=109.5, bsz=40, num_updates=23290, lr=4.97115e-05, gnorm=0.873, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113037
2022-10-17 03:01:19 - progress_bar.py[line:274] - INFO: epoch 001:  23329 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=23300, lr=4.97105e-05, gnorm=0.741, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113048
2022-10-17 03:01:30 - progress_bar.py[line:274] - INFO: epoch 001:  23339 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=23310, lr=4.97095e-05, gnorm=0.827, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113059
2022-10-17 03:01:42 - progress_bar.py[line:274] - INFO: epoch 001:  23349 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.7, ups=0.88, wpb=111, bsz=40, num_updates=23320, lr=4.97084e-05, gnorm=0.849, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113071
2022-10-17 03:01:53 - progress_bar.py[line:274] - INFO: epoch 001:  23359 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.4, ups=0.93, wpb=109.4, bsz=40, num_updates=23330, lr=4.97074e-05, gnorm=0.942, clip=30, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=113082
2022-10-17 03:02:04 - progress_bar.py[line:274] - INFO: epoch 001:  23369 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.8, ups=0.87, wpb=110.2, bsz=40, num_updates=23340, lr=4.97064e-05, gnorm=0.779, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113093
2022-10-17 03:02:15 - progress_bar.py[line:274] - INFO: epoch 001:  23379 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.9, ups=0.93, wpb=110.4, bsz=40, num_updates=23350, lr=4.97054e-05, gnorm=0.894, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=113104
2022-10-17 03:02:26 - progress_bar.py[line:274] - INFO: epoch 001:  23389 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=23360, lr=4.97044e-05, gnorm=0.908, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113115
2022-10-17 03:02:37 - progress_bar.py[line:274] - INFO: epoch 001:  23399 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=23370, lr=4.97034e-05, gnorm=0.929, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113126
2022-10-17 03:02:48 - progress_bar.py[line:274] - INFO: epoch 001:  23409 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102, ups=0.91, wpb=111.7, bsz=40, num_updates=23380, lr=4.97023e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113137
2022-10-17 03:02:59 - progress_bar.py[line:274] - INFO: epoch 001:  23419 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=102.1, ups=0.92, wpb=111.4, bsz=40, num_updates=23390, lr=4.97013e-05, gnorm=0.758, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=113148
2022-10-17 03:03:10 - progress_bar.py[line:274] - INFO: epoch 001:  23429 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=23400, lr=4.97003e-05, gnorm=0.941, clip=30, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113159
2022-10-17 03:03:22 - progress_bar.py[line:274] - INFO: epoch 001:  23439 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=23410, lr=4.96993e-05, gnorm=0.944, clip=50, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113171
2022-10-17 03:03:25 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-17 03:03:34 - progress_bar.py[line:274] - INFO: epoch 001:  23450 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=88.4, ups=0.8, wpb=110.7, bsz=40, num_updates=23420, lr=4.96983e-05, gnorm=0.961, clip=40, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=113183
2022-10-17 03:03:45 - progress_bar.py[line:274] - INFO: epoch 001:  23460 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=23430, lr=4.96972e-05, gnorm=0.968, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113194
2022-10-17 03:03:57 - progress_bar.py[line:274] - INFO: epoch 001:  23470 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.7, ups=0.87, wpb=110.2, bsz=40, num_updates=23440, lr=4.96962e-05, gnorm=1, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113206
2022-10-17 03:04:08 - progress_bar.py[line:274] - INFO: epoch 001:  23480 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=23450, lr=4.96952e-05, gnorm=0.962, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113217
2022-10-17 03:04:19 - progress_bar.py[line:274] - INFO: epoch 001:  23490 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.4, ups=0.9, wpb=110.7, bsz=40, num_updates=23460, lr=4.96942e-05, gnorm=1.017, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113228
2022-10-17 03:04:31 - progress_bar.py[line:274] - INFO: epoch 001:  23500 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=23470, lr=4.96932e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=113240
2022-10-17 03:04:42 - progress_bar.py[line:274] - INFO: epoch 001:  23510 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=23480, lr=4.96921e-05, gnorm=0.987, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113251
2022-10-17 03:04:53 - progress_bar.py[line:274] - INFO: epoch 001:  23520 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.5, ups=0.89, wpb=109, bsz=40, num_updates=23490, lr=4.96911e-05, gnorm=0.88, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113262
2022-10-17 03:05:04 - progress_bar.py[line:274] - INFO: epoch 001:  23530 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=23500, lr=4.96901e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113273
2022-10-17 03:05:15 - progress_bar.py[line:274] - INFO: epoch 001:  23540 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.8, ups=0.92, wpb=110.2, bsz=40, num_updates=23510, lr=4.96891e-05, gnorm=0.934, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113284
2022-10-17 03:05:26 - progress_bar.py[line:274] - INFO: epoch 001:  23550 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.4, ups=0.92, wpb=109.3, bsz=40, num_updates=23520, lr=4.96881e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113295
2022-10-17 03:05:38 - progress_bar.py[line:274] - INFO: epoch 001:  23560 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.9, ups=0.89, wpb=110.1, bsz=40, num_updates=23530, lr=4.96871e-05, gnorm=0.843, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113307
2022-10-17 03:05:49 - progress_bar.py[line:274] - INFO: epoch 001:  23570 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.5, ups=0.87, wpb=112, bsz=40, num_updates=23540, lr=4.9686e-05, gnorm=0.932, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=113318
2022-10-17 03:06:00 - progress_bar.py[line:274] - INFO: epoch 001:  23580 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.89, wpb=110.7, bsz=40, num_updates=23550, lr=4.9685e-05, gnorm=0.766, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=113329
2022-10-17 03:06:11 - progress_bar.py[line:274] - INFO: epoch 001:  23590 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.6, ups=0.9, wpb=109.3, bsz=40, num_updates=23560, lr=4.9684e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=113340
2022-10-17 03:06:23 - progress_bar.py[line:274] - INFO: epoch 001:  23600 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=23570, lr=4.9683e-05, gnorm=1.035, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113352
2022-10-17 03:06:34 - progress_bar.py[line:274] - INFO: epoch 001:  23610 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=23580, lr=4.9682e-05, gnorm=0.763, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113363
2022-10-17 03:06:45 - progress_bar.py[line:274] - INFO: epoch 001:  23620 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=23590, lr=4.96809e-05, gnorm=0.792, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=113374
2022-10-17 03:06:56 - progress_bar.py[line:274] - INFO: epoch 001:  23630 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.8, ups=0.88, wpb=110.9, bsz=40, num_updates=23600, lr=4.96799e-05, gnorm=1.084, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113385
2022-10-17 03:07:08 - progress_bar.py[line:274] - INFO: epoch 001:  23640 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=23610, lr=4.96789e-05, gnorm=0.965, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=113397
2022-10-17 03:07:19 - progress_bar.py[line:274] - INFO: epoch 001:  23650 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=23620, lr=4.96779e-05, gnorm=0.949, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113408
2022-10-17 03:07:25 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 03:07:31 - progress_bar.py[line:274] - INFO: epoch 001:  23661 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.4, ups=0.81, wpb=110.6, bsz=40, num_updates=23630, lr=4.96769e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=113420
2022-10-17 03:07:42 - progress_bar.py[line:274] - INFO: epoch 001:  23671 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.7, ups=0.89, wpb=109.2, bsz=40, num_updates=23640, lr=4.96759e-05, gnorm=1.032, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113431
2022-10-17 03:07:54 - progress_bar.py[line:274] - INFO: epoch 001:  23681 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=23650, lr=4.96748e-05, gnorm=0.973, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113443
2022-10-17 03:08:05 - progress_bar.py[line:274] - INFO: epoch 001:  23691 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.2, ups=0.88, wpb=110.8, bsz=40, num_updates=23660, lr=4.96738e-05, gnorm=0.947, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=113454
2022-10-17 03:08:16 - progress_bar.py[line:274] - INFO: epoch 001:  23701 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=23670, lr=4.96728e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113465
2022-10-17 03:08:27 - progress_bar.py[line:274] - INFO: epoch 001:  23711 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97, ups=0.89, wpb=108.7, bsz=40, num_updates=23680, lr=4.96718e-05, gnorm=1.06, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113476
2022-10-17 03:08:38 - progress_bar.py[line:274] - INFO: epoch 001:  23721 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.3, ups=0.91, wpb=110.3, bsz=40, num_updates=23690, lr=4.96708e-05, gnorm=0.95, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113487
2022-10-17 03:08:49 - progress_bar.py[line:274] - INFO: epoch 001:  23731 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.9, ups=0.9, wpb=111.7, bsz=40, num_updates=23700, lr=4.96697e-05, gnorm=0.952, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113498
2022-10-17 03:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  23741 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101, ups=0.92, wpb=110.4, bsz=40, num_updates=23710, lr=4.96687e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=113509
2022-10-17 03:09:12 - progress_bar.py[line:274] - INFO: epoch 001:  23751 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=23720, lr=4.96677e-05, gnorm=0.855, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113521
2022-10-17 03:09:23 - progress_bar.py[line:274] - INFO: epoch 001:  23761 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=23730, lr=4.96667e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113532
2022-10-17 03:09:34 - progress_bar.py[line:274] - INFO: epoch 001:  23771 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=23740, lr=4.96657e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=113543
2022-10-17 03:09:45 - progress_bar.py[line:274] - INFO: epoch 001:  23781 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=103.4, ups=0.93, wpb=111.4, bsz=40, num_updates=23750, lr=4.96647e-05, gnorm=0.744, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113554
2022-10-17 03:09:56 - progress_bar.py[line:274] - INFO: epoch 001:  23791 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=23760, lr=4.96636e-05, gnorm=0.873, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113565
2022-10-17 03:10:07 - progress_bar.py[line:274] - INFO: epoch 001:  23801 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=23770, lr=4.96626e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113576
2022-10-17 03:10:18 - progress_bar.py[line:274] - INFO: epoch 001:  23811 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.9, ups=0.92, wpb=108.9, bsz=40, num_updates=23780, lr=4.96616e-05, gnorm=0.917, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113587
2022-10-17 03:10:29 - progress_bar.py[line:274] - INFO: epoch 001:  23821 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=23790, lr=4.96606e-05, gnorm=0.772, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113598
2022-10-17 03:10:41 - progress_bar.py[line:274] - INFO: epoch 001:  23831 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.6, ups=0.87, wpb=111, bsz=40, num_updates=23800, lr=4.96596e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113610
2022-10-17 03:10:52 - progress_bar.py[line:274] - INFO: epoch 001:  23841 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.9, ups=0.91, wpb=109, bsz=40, num_updates=23810, lr=4.96585e-05, gnorm=1.015, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=113621
2022-10-17 03:11:03 - progress_bar.py[line:274] - INFO: epoch 001:  23851 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.91, wpb=108.6, bsz=40, num_updates=23820, lr=4.96575e-05, gnorm=0.978, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113632
2022-10-17 03:11:14 - progress_bar.py[line:274] - INFO: epoch 001:  23861 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.89, wpb=109, bsz=40, num_updates=23830, lr=4.96565e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113643
2022-10-17 03:11:26 - progress_bar.py[line:274] - INFO: epoch 001:  23871 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=23840, lr=4.96555e-05, gnorm=0.77, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113655
2022-10-17 03:11:37 - progress_bar.py[line:274] - INFO: epoch 001:  23881 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98, ups=0.91, wpb=108.3, bsz=40, num_updates=23850, lr=4.96545e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113666
2022-10-17 03:11:48 - progress_bar.py[line:274] - INFO: epoch 001:  23891 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=23860, lr=4.96535e-05, gnorm=1.11, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113677
2022-10-17 03:11:59 - progress_bar.py[line:274] - INFO: epoch 001:  23901 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.4, ups=0.93, wpb=110.2, bsz=40, num_updates=23870, lr=4.96524e-05, gnorm=1.123, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113688
2022-10-17 03:12:10 - progress_bar.py[line:274] - INFO: epoch 001:  23911 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.1, ups=0.92, wpb=110.4, bsz=40, num_updates=23880, lr=4.96514e-05, gnorm=0.936, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=113699
2022-10-17 03:12:21 - progress_bar.py[line:274] - INFO: epoch 001:  23921 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=23890, lr=4.96504e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113710
2022-10-17 03:12:32 - progress_bar.py[line:274] - INFO: epoch 001:  23931 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.5, ups=0.89, wpb=109.2, bsz=40, num_updates=23900, lr=4.96494e-05, gnorm=0.996, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113721
2022-10-17 03:12:43 - progress_bar.py[line:274] - INFO: epoch 001:  23941 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=23910, lr=4.96484e-05, gnorm=0.929, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113732
2022-10-17 03:12:54 - progress_bar.py[line:274] - INFO: epoch 001:  23951 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=23920, lr=4.96473e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=113743
2022-10-17 03:13:06 - progress_bar.py[line:274] - INFO: epoch 001:  23961 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=23930, lr=4.96463e-05, gnorm=0.864, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=113755
2022-10-17 03:13:17 - progress_bar.py[line:274] - INFO: epoch 001:  23971 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=23940, lr=4.96453e-05, gnorm=0.88, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113766
2022-10-17 03:13:28 - progress_bar.py[line:274] - INFO: epoch 001:  23981 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.5, ups=0.93, wpb=110.5, bsz=40, num_updates=23950, lr=4.96443e-05, gnorm=0.888, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113777
2022-10-17 03:13:39 - progress_bar.py[line:274] - INFO: epoch 001:  23991 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=23960, lr=4.96433e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=113788
2022-10-17 03:13:50 - progress_bar.py[line:274] - INFO: epoch 001:  24001 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=23970, lr=4.96422e-05, gnorm=0.855, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113799
2022-10-17 03:14:01 - progress_bar.py[line:274] - INFO: epoch 001:  24011 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99, ups=0.9, wpb=109.6, bsz=40, num_updates=23980, lr=4.96412e-05, gnorm=0.97, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113810
2022-10-17 03:14:12 - progress_bar.py[line:274] - INFO: epoch 001:  24021 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=23990, lr=4.96402e-05, gnorm=1.113, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=113821
2022-10-17 03:14:24 - progress_bar.py[line:274] - INFO: epoch 001:  24031 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=24000, lr=4.96392e-05, gnorm=0.999, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=113833
2022-10-17 03:14:24 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 03:14:25 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 03:14:25 - train.py[line:551] - INFO: load:1.12 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 03:16:57 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 03:16:57 - train.py[line:551] - INFO: load:1.14 valid_run:151.44 task_valid:148.03 collect_output:2.39
2022-10-17 03:19:25 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 03:19:25 - train.py[line:551] - INFO: load:1.17 valid_run:299.29 task_valid:291.05 collect_output:6.23
2022-10-17 03:21:56 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 03:21:56 - train.py[line:551] - INFO: load:1.19 valid_run:450.93 task_valid:434.05 collect_output:13.86
2022-10-17 03:24:25 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 03:24:25 - train.py[line:551] - INFO: load:1.22 valid_run:599.58 task_valid:578.98 collect_output:16.57
2022-10-17 03:26:57 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 03:26:57 - train.py[line:551] - INFO: load:1.24 valid_run:751.69 task_valid:726.59 collect_output:20.08
2022-10-17 03:29:29 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 03:29:29 - train.py[line:551] - INFO: load:1.27 valid_run:903.05 task_valid:872.11 collect_output:24.90
2022-10-17 03:32:02 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 03:32:02 - train.py[line:551] - INFO: load:1.29 valid_run:1056.02 task_valid:1018.10 collect_output:30.90
2022-10-17 03:34:32 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 03:34:32 - train.py[line:551] - INFO: load:1.32 valid_run:1206.64 task_valid:1159.18 collect_output:39.44
2022-10-17 03:37:02 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 03:37:02 - train.py[line:551] - INFO: load:1.34 valid_run:1355.87 task_valid:1303.82 collect_output:43.02
2022-10-17 03:39:30 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 03:39:30 - train.py[line:551] - INFO: load:1.37 valid_run:1504.24 task_valid:1447.13 collect_output:47.08
2022-10-17 03:41:59 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 03:41:59 - train.py[line:551] - INFO: load:1.40 valid_run:1653.62 task_valid:1592.04 collect_output:50.56
2022-10-17 03:44:29 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 03:44:29 - train.py[line:551] - INFO: load:1.42 valid_run:1803.38 task_valid:1736.95 collect_output:54.43
2022-10-17 03:46:59 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 03:46:59 - train.py[line:551] - INFO: load:1.45 valid_run:1952.96 task_valid:1878.74 collect_output:61.18
2022-10-17 03:49:30 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 03:49:30 - train.py[line:551] - INFO: load:1.47 valid_run:2103.67 task_valid:2024.75 collect_output:64.81
2022-10-17 03:52:00 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 03:52:00 - train.py[line:551] - INFO: load:1.50 valid_run:2254.03 task_valid:2171.83 collect_output:67.03
2022-10-17 03:54:31 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 03:54:31 - train.py[line:551] - INFO: load:1.53 valid_run:2404.37 task_valid:2316.58 collect_output:71.53
2022-10-17 03:57:03 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 03:57:03 - train.py[line:551] - INFO: load:1.55 valid_run:2556.28 task_valid:2462.62 collect_output:76.24
2022-10-17 03:59:34 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 03:59:34 - train.py[line:551] - INFO: load:1.58 valid_run:2707.36 task_valid:2610.27 collect_output:78.59
2022-10-17 04:02:02 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 04:02:02 - train.py[line:551] - INFO: load:1.61 valid_run:2855.86 task_valid:2752.38 collect_output:83.90
2022-10-17 04:04:33 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 04:04:33 - train.py[line:551] - INFO: load:1.63 valid_run:3006.67 task_valid:2898.13 collect_output:87.86
2022-10-17 04:07:05 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 04:07:05 - train.py[line:551] - INFO: load:1.66 valid_run:3158.57 task_valid:3043.10 collect_output:93.68
2022-10-17 04:09:35 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 04:09:35 - train.py[line:551] - INFO: load:1.70 valid_run:3308.31 task_valid:3188.32 collect_output:97.12
2022-10-17 04:12:06 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 04:12:06 - train.py[line:551] - INFO: load:1.72 valid_run:3459.62 task_valid:3335.05 collect_output:100.62
2022-10-17 04:14:38 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 04:14:38 - train.py[line:551] - INFO: load:1.75 valid_run:3611.38 task_valid:3481.84 collect_output:104.50

====================================================================================================
SGG eval:     R @ 50: 0.4807;     R @ 100: 0.5426;     R @ 500: 0.5732;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2994;    mR @ 100: 0.3866;    mR @ 500: 0.4240;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6122) (covered in:0.7500) (covering:0.3714) (eating:0.5000) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8318) (playing:0.0000) (riding:0.7431) (says:0.0000) (sitting on:0.6692) (standing on:0.2270) (using:0.6500) (walking in:0.3333) (walking on:0.5045) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4807;     R @ 100: 0.5426;     R @ 500: 0.5732;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2994;    mR @ 100: 0.3866;    mR @ 500: 0.4240;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6122) (covered in:0.7500) (covering:0.3714) (eating:0.5000) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8318) (playing:0.0000) (riding:0.7431) (says:0.0000) (sitting on:0.6692) (standing on:0.2270) (using:0.6500) (walking in:0.3333) (walking on:0.5045) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2022-10-17 04:17:09 - train.py[line:487] - INFO: 0.5426414565826331
2022-10-17 04:17:09 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 04:17:09 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.337 | loss_v1 0 | loss_v2 0 | nll_loss 0.181 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.542641 | ppl 1.13 | vqa_score 0.4662 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 24000 | best_R@100 0.581461
2022-10-17 04:17:09 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 24000 updates
2022-10-17 04:17:09 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_24000.pt
2022-10-17 04:17:15 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_24000.pt
2022-10-17 04:17:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_24000.pt (epoch 1 @ 24000 updates, score 0.5426414565826331) (writing took 8.313061114866287 seconds)
2022-10-17 04:17:29 - progress_bar.py[line:274] - INFO: epoch 001:  24041 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=0.3, ups=0, wpb=111.2, bsz=40, num_updates=24010, lr=4.96382e-05, gnorm=0.903, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117618
2022-10-17 04:17:40 - progress_bar.py[line:274] - INFO: epoch 001:  24051 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=24020, lr=4.96372e-05, gnorm=1.003, clip=40, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=117629
2022-10-17 04:17:51 - progress_bar.py[line:274] - INFO: epoch 001:  24061 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=24030, lr=4.96361e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=117640
2022-10-17 04:18:02 - progress_bar.py[line:274] - INFO: epoch 001:  24071 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.5, ups=0.9, wpb=109, bsz=40, num_updates=24040, lr=4.96351e-05, gnorm=0.875, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117651
2022-10-17 04:18:13 - progress_bar.py[line:274] - INFO: epoch 001:  24081 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=24050, lr=4.96341e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117662
2022-10-17 04:18:24 - progress_bar.py[line:274] - INFO: epoch 001:  24091 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.3, ups=0.88, wpb=111.7, bsz=40, num_updates=24060, lr=4.96331e-05, gnorm=0.963, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=117673
2022-10-17 04:18:36 - progress_bar.py[line:274] - INFO: epoch 001:  24101 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.3, ups=0.88, wpb=109.4, bsz=40, num_updates=24070, lr=4.96321e-05, gnorm=0.981, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=117685
2022-10-17 04:18:47 - progress_bar.py[line:274] - INFO: epoch 001:  24111 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=24080, lr=4.9631e-05, gnorm=0.883, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=117696
2022-10-17 04:18:58 - progress_bar.py[line:274] - INFO: epoch 001:  24121 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=103, ups=0.93, wpb=110.8, bsz=40, num_updates=24090, lr=4.963e-05, gnorm=0.931, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=117707
2022-10-17 04:19:09 - progress_bar.py[line:274] - INFO: epoch 001:  24131 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.6, ups=0.92, wpb=110.9, bsz=40, num_updates=24100, lr=4.9629e-05, gnorm=0.863, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=117717
2022-10-17 04:19:20 - progress_bar.py[line:274] - INFO: epoch 001:  24141 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=24110, lr=4.9628e-05, gnorm=1.02, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=117729
2022-10-17 04:19:30 - progress_bar.py[line:274] - INFO: epoch 001:  24151 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.4, ups=0.93, wpb=108.6, bsz=40, num_updates=24120, lr=4.9627e-05, gnorm=1.12, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117739
2022-10-17 04:19:42 - progress_bar.py[line:274] - INFO: epoch 001:  24161 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98, ups=0.88, wpb=111.1, bsz=40, num_updates=24130, lr=4.9626e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=117751
2022-10-17 04:19:53 - progress_bar.py[line:274] - INFO: epoch 001:  24171 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=24140, lr=4.96249e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=117762
2022-10-17 04:20:04 - progress_bar.py[line:274] - INFO: epoch 001:  24181 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.9, ups=0.92, wpb=111.3, bsz=40, num_updates=24150, lr=4.96239e-05, gnorm=0.962, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117773
2022-10-17 04:20:15 - progress_bar.py[line:274] - INFO: epoch 001:  24191 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.3, ups=0.88, wpb=111.7, bsz=40, num_updates=24160, lr=4.96229e-05, gnorm=0.863, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117784
2022-10-17 04:20:26 - progress_bar.py[line:274] - INFO: epoch 001:  24201 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.1, ups=0.92, wpb=109.3, bsz=40, num_updates=24170, lr=4.96219e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117795
2022-10-17 04:20:38 - progress_bar.py[line:274] - INFO: epoch 001:  24211 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=93.3, ups=0.85, wpb=110.2, bsz=40, num_updates=24180, lr=4.96209e-05, gnorm=0.908, clip=30, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=117807
2022-10-17 04:20:49 - progress_bar.py[line:274] - INFO: epoch 001:  24221 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=24190, lr=4.96198e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117818
2022-10-17 04:21:00 - progress_bar.py[line:274] - INFO: epoch 001:  24231 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=102.4, ups=0.92, wpb=111, bsz=40, num_updates=24200, lr=4.96188e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=117829
2022-10-17 04:21:11 - progress_bar.py[line:274] - INFO: epoch 001:  24241 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.4, ups=0.88, wpb=110.3, bsz=40, num_updates=24210, lr=4.96178e-05, gnorm=0.964, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=117840
2022-10-17 04:21:23 - progress_bar.py[line:274] - INFO: epoch 001:  24251 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=24220, lr=4.96168e-05, gnorm=0.918, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117852
2022-10-17 04:21:34 - progress_bar.py[line:274] - INFO: epoch 001:  24261 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=24230, lr=4.96158e-05, gnorm=1.064, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=117863
2022-10-17 04:21:45 - progress_bar.py[line:274] - INFO: epoch 001:  24271 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.6, ups=0.87, wpb=109.7, bsz=40, num_updates=24240, lr=4.96148e-05, gnorm=0.867, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=117874
2022-10-17 04:21:57 - progress_bar.py[line:274] - INFO: epoch 001:  24281 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101, ups=0.92, wpb=110, bsz=40, num_updates=24250, lr=4.96137e-05, gnorm=1.029, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=117885
2022-10-17 04:22:08 - progress_bar.py[line:274] - INFO: epoch 001:  24291 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96, ups=0.87, wpb=110.4, bsz=40, num_updates=24260, lr=4.96127e-05, gnorm=1.041, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117897
2022-10-17 04:22:19 - progress_bar.py[line:274] - INFO: epoch 001:  24301 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=24270, lr=4.96117e-05, gnorm=0.873, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=117908
2022-10-17 04:22:31 - progress_bar.py[line:274] - INFO: epoch 001:  24311 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.2, ups=0.88, wpb=109.3, bsz=40, num_updates=24280, lr=4.96107e-05, gnorm=0.864, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117920
2022-10-17 04:22:42 - progress_bar.py[line:274] - INFO: epoch 001:  24321 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.5, ups=0.87, wpb=109.8, bsz=40, num_updates=24290, lr=4.96097e-05, gnorm=0.86, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=117931
2022-10-17 04:22:54 - progress_bar.py[line:274] - INFO: epoch 001:  24331 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.9, ups=0.89, wpb=108.7, bsz=40, num_updates=24300, lr=4.96086e-05, gnorm=0.859, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117942
2022-10-17 04:23:05 - progress_bar.py[line:274] - INFO: epoch 001:  24341 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=24310, lr=4.96076e-05, gnorm=0.836, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=117954
2022-10-17 04:23:16 - progress_bar.py[line:274] - INFO: epoch 001:  24351 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.4, ups=0.89, wpb=110, bsz=40, num_updates=24320, lr=4.96066e-05, gnorm=0.961, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=117965
2022-10-17 04:23:28 - progress_bar.py[line:274] - INFO: epoch 001:  24361 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=24330, lr=4.96056e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117976
2022-10-17 04:23:39 - progress_bar.py[line:274] - INFO: epoch 001:  24371 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=24340, lr=4.96046e-05, gnorm=0.801, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=117988
2022-10-17 04:23:50 - progress_bar.py[line:274] - INFO: epoch 001:  24381 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.7, ups=0.87, wpb=109.9, bsz=40, num_updates=24350, lr=4.96036e-05, gnorm=0.919, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=117999
2022-10-17 04:24:02 - progress_bar.py[line:274] - INFO: epoch 001:  24391 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.9, wpb=109.5, bsz=40, num_updates=24360, lr=4.96025e-05, gnorm=0.948, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=118011
2022-10-17 04:24:13 - progress_bar.py[line:274] - INFO: epoch 001:  24401 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=24370, lr=4.96015e-05, gnorm=1.015, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=118022
2022-10-17 04:24:24 - progress_bar.py[line:274] - INFO: epoch 001:  24411 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.1, ups=0.89, wpb=111.2, bsz=40, num_updates=24380, lr=4.96005e-05, gnorm=0.929, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118033
2022-10-17 04:24:35 - progress_bar.py[line:274] - INFO: epoch 001:  24421 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.4, ups=0.88, wpb=109.5, bsz=40, num_updates=24390, lr=4.95995e-05, gnorm=0.848, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=118044
2022-10-17 04:24:46 - progress_bar.py[line:274] - INFO: epoch 001:  24431 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.9, ups=0.91, wpb=110.1, bsz=40, num_updates=24400, lr=4.95985e-05, gnorm=0.91, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118055
2022-10-17 04:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  24441 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.8, ups=0.89, wpb=108.2, bsz=40, num_updates=24410, lr=4.95974e-05, gnorm=0.713, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118067
2022-10-17 04:25:09 - progress_bar.py[line:274] - INFO: epoch 001:  24451 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=103.1, ups=0.93, wpb=110.9, bsz=40, num_updates=24420, lr=4.95964e-05, gnorm=0.887, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118078
2022-10-17 04:25:20 - progress_bar.py[line:274] - INFO: epoch 001:  24461 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=24430, lr=4.95954e-05, gnorm=0.921, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=118089
2022-10-17 04:25:31 - progress_bar.py[line:274] - INFO: epoch 001:  24471 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=24440, lr=4.95944e-05, gnorm=0.928, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118100
2022-10-17 04:25:42 - progress_bar.py[line:274] - INFO: epoch 001:  24481 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.3, ups=0.93, wpb=110.1, bsz=40, num_updates=24450, lr=4.95934e-05, gnorm=0.875, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118111
2022-10-17 04:25:53 - progress_bar.py[line:274] - INFO: epoch 001:  24491 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=103.8, ups=0.93, wpb=111.6, bsz=40, num_updates=24460, lr=4.95923e-05, gnorm=0.844, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=118122
2022-10-17 04:26:04 - progress_bar.py[line:274] - INFO: epoch 001:  24501 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.4, ups=0.87, wpb=111, bsz=40, num_updates=24470, lr=4.95913e-05, gnorm=0.819, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=118133
2022-10-17 04:26:16 - progress_bar.py[line:274] - INFO: epoch 001:  24511 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.9, ups=0.88, wpb=110.4, bsz=40, num_updates=24480, lr=4.95903e-05, gnorm=0.78, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118145
2022-10-17 04:26:27 - progress_bar.py[line:274] - INFO: epoch 001:  24521 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=24490, lr=4.95893e-05, gnorm=0.951, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=118156
2022-10-17 04:26:38 - progress_bar.py[line:274] - INFO: epoch 001:  24531 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=24500, lr=4.95883e-05, gnorm=0.871, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118167
2022-10-17 04:26:49 - progress_bar.py[line:274] - INFO: epoch 001:  24541 / 102288 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=103.2, ups=0.93, wpb=111.5, bsz=40, num_updates=24510, lr=4.95873e-05, gnorm=0.89, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=118178
2022-10-17 04:27:00 - progress_bar.py[line:274] - INFO: epoch 001:  24551 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100, ups=0.91, wpb=110.1, bsz=40, num_updates=24520, lr=4.95862e-05, gnorm=0.822, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118189
2022-10-17 04:27:11 - progress_bar.py[line:274] - INFO: epoch 001:  24561 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=24530, lr=4.95852e-05, gnorm=1.071, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118200
2022-10-17 04:27:22 - progress_bar.py[line:274] - INFO: epoch 001:  24571 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.8, ups=0.92, wpb=109.7, bsz=40, num_updates=24540, lr=4.95842e-05, gnorm=0.955, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118211
2022-10-17 04:27:34 - progress_bar.py[line:274] - INFO: epoch 001:  24581 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.2, ups=0.89, wpb=108.9, bsz=40, num_updates=24550, lr=4.95832e-05, gnorm=0.923, clip=40, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=118222
2022-10-17 04:27:45 - progress_bar.py[line:274] - INFO: epoch 001:  24591 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.1, ups=0.9, wpb=110.2, bsz=40, num_updates=24560, lr=4.95822e-05, gnorm=1.068, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118234
2022-10-17 04:27:56 - progress_bar.py[line:274] - INFO: epoch 001:  24601 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.7, ups=0.88, wpb=109.8, bsz=40, num_updates=24570, lr=4.95811e-05, gnorm=1.062, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=118245
2022-10-17 04:28:07 - progress_bar.py[line:274] - INFO: epoch 001:  24611 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=102.2, ups=0.93, wpb=109.6, bsz=40, num_updates=24580, lr=4.95801e-05, gnorm=0.904, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=118256
2022-10-17 04:28:18 - progress_bar.py[line:274] - INFO: epoch 001:  24621 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.9, ups=0.92, wpb=110.3, bsz=40, num_updates=24590, lr=4.95791e-05, gnorm=1.019, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=118267
2022-10-17 04:28:29 - progress_bar.py[line:274] - INFO: epoch 001:  24631 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102, ups=0.92, wpb=111.3, bsz=40, num_updates=24600, lr=4.95781e-05, gnorm=0.871, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118278
2022-10-17 04:28:40 - progress_bar.py[line:274] - INFO: epoch 001:  24641 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.5, ups=0.89, wpb=109, bsz=40, num_updates=24610, lr=4.95771e-05, gnorm=1.08, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=118289
2022-10-17 04:28:51 - progress_bar.py[line:274] - INFO: epoch 001:  24651 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=24620, lr=4.95761e-05, gnorm=1.01, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=118300
2022-10-17 04:29:03 - progress_bar.py[line:274] - INFO: epoch 001:  24661 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.9, ups=0.88, wpb=111.9, bsz=40, num_updates=24630, lr=4.9575e-05, gnorm=0.96, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118312
2022-10-17 04:29:13 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 04:29:15 - progress_bar.py[line:274] - INFO: epoch 001:  24672 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=89.4, ups=0.81, wpb=110.6, bsz=40, num_updates=24640, lr=4.9574e-05, gnorm=0.954, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=118324
2022-10-17 04:29:26 - progress_bar.py[line:274] - INFO: epoch 001:  24682 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.3, ups=0.92, wpb=109.4, bsz=40, num_updates=24650, lr=4.9573e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=118335
2022-10-17 04:29:37 - progress_bar.py[line:274] - INFO: epoch 001:  24692 / 102288 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=106.2, ups=0.95, wpb=111.4, bsz=40, num_updates=24660, lr=4.9572e-05, gnorm=0.788, clip=0, loss_scale=512, train_wall=10, gb_free=10.5, ema_decay=0.9999, wall=118346
2022-10-17 04:29:48 - progress_bar.py[line:274] - INFO: epoch 001:  24702 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.1, ups=0.92, wpb=110.4, bsz=40, num_updates=24670, lr=4.9571e-05, gnorm=0.947, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=118357
2022-10-17 04:29:59 - progress_bar.py[line:274] - INFO: epoch 001:  24712 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98, ups=0.88, wpb=111.1, bsz=40, num_updates=24680, lr=4.95699e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118368
2022-10-17 04:30:10 - progress_bar.py[line:274] - INFO: epoch 001:  24722 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.7, ups=0.9, wpb=109.2, bsz=40, num_updates=24690, lr=4.95689e-05, gnorm=1.162, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=118379
2022-10-17 04:30:22 - progress_bar.py[line:274] - INFO: epoch 001:  24732 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=24700, lr=4.95679e-05, gnorm=0.936, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118390
2022-10-17 04:30:33 - progress_bar.py[line:274] - INFO: epoch 001:  24742 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=24710, lr=4.95669e-05, gnorm=0.923, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118402
2022-10-17 04:30:44 - progress_bar.py[line:274] - INFO: epoch 001:  24752 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.3, ups=0.9, wpb=109.7, bsz=40, num_updates=24720, lr=4.95659e-05, gnorm=1.109, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=118413
2022-10-17 04:30:55 - progress_bar.py[line:274] - INFO: epoch 001:  24762 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.7, ups=0.93, wpb=110.1, bsz=40, num_updates=24730, lr=4.95649e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118424
2022-10-17 04:31:06 - progress_bar.py[line:274] - INFO: epoch 001:  24772 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.6, ups=0.88, wpb=109.3, bsz=40, num_updates=24740, lr=4.95638e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118435
2022-10-17 04:31:17 - progress_bar.py[line:274] - INFO: epoch 001:  24782 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=24750, lr=4.95628e-05, gnorm=0.94, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118446
2022-10-17 04:31:29 - progress_bar.py[line:274] - INFO: epoch 001:  24792 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=24760, lr=4.95618e-05, gnorm=1.004, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118458
2022-10-17 04:31:40 - progress_bar.py[line:274] - INFO: epoch 001:  24802 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=24770, lr=4.95608e-05, gnorm=0.821, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118469
2022-10-17 04:31:51 - progress_bar.py[line:274] - INFO: epoch 001:  24812 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=24780, lr=4.95598e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=118480
2022-10-17 04:32:03 - progress_bar.py[line:274] - INFO: epoch 001:  24822 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=24790, lr=4.95587e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=118492
2022-10-17 04:32:14 - progress_bar.py[line:274] - INFO: epoch 001:  24832 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.2, ups=0.87, wpb=109.4, bsz=40, num_updates=24800, lr=4.95577e-05, gnorm=0.917, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118503
2022-10-17 04:32:26 - progress_bar.py[line:274] - INFO: epoch 001:  24842 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=24810, lr=4.95567e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=118515
2022-10-17 04:32:36 - progress_bar.py[line:274] - INFO: epoch 001:  24852 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.6, ups=0.93, wpb=110, bsz=40, num_updates=24820, lr=4.95557e-05, gnorm=0.932, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=118525
2022-10-17 04:32:48 - progress_bar.py[line:274] - INFO: epoch 001:  24862 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.6, ups=0.87, wpb=109.8, bsz=40, num_updates=24830, lr=4.95547e-05, gnorm=1.182, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118537
2022-10-17 04:32:59 - progress_bar.py[line:274] - INFO: epoch 001:  24872 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.3, ups=0.91, wpb=111.8, bsz=40, num_updates=24840, lr=4.95537e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=118548
2022-10-17 04:33:10 - progress_bar.py[line:274] - INFO: epoch 001:  24882 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.8, ups=0.92, wpb=111, bsz=40, num_updates=24850, lr=4.95526e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118559
2022-10-17 04:33:21 - progress_bar.py[line:274] - INFO: epoch 001:  24892 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.6, ups=0.88, wpb=109.3, bsz=40, num_updates=24860, lr=4.95516e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118570
2022-10-17 04:33:32 - progress_bar.py[line:274] - INFO: epoch 001:  24902 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=24870, lr=4.95506e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118581
2022-10-17 04:33:43 - progress_bar.py[line:274] - INFO: epoch 001:  24912 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.5, ups=0.91, wpb=110.3, bsz=40, num_updates=24880, lr=4.95496e-05, gnorm=1.019, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118592
2022-10-17 04:33:54 - progress_bar.py[line:274] - INFO: epoch 001:  24922 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=24890, lr=4.95486e-05, gnorm=1.115, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=118603
2022-10-17 04:34:05 - progress_bar.py[line:274] - INFO: epoch 001:  24932 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.5, ups=0.92, wpb=109.7, bsz=40, num_updates=24900, lr=4.95475e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=118614
2022-10-17 04:34:17 - progress_bar.py[line:274] - INFO: epoch 001:  24942 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=24910, lr=4.95465e-05, gnorm=0.822, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=118625
2022-10-17 04:34:28 - progress_bar.py[line:274] - INFO: epoch 001:  24952 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.6, ups=0.88, wpb=111, bsz=40, num_updates=24920, lr=4.95455e-05, gnorm=0.903, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=118637
2022-10-17 04:34:39 - progress_bar.py[line:274] - INFO: epoch 001:  24962 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=24930, lr=4.95445e-05, gnorm=1.059, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=118648
2022-10-17 04:34:50 - progress_bar.py[line:274] - INFO: epoch 001:  24972 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=103.2, ups=0.93, wpb=110.9, bsz=40, num_updates=24940, lr=4.95435e-05, gnorm=0.906, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118659
2022-10-17 04:35:01 - progress_bar.py[line:274] - INFO: epoch 001:  24982 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.1, ups=0.92, wpb=110.1, bsz=40, num_updates=24950, lr=4.95424e-05, gnorm=1.037, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118670
2022-10-17 04:35:12 - progress_bar.py[line:274] - INFO: epoch 001:  24992 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.7, ups=0.91, wpb=111.3, bsz=40, num_updates=24960, lr=4.95414e-05, gnorm=0.793, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118681
2022-10-17 04:35:23 - progress_bar.py[line:274] - INFO: epoch 001:  25002 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=24970, lr=4.95404e-05, gnorm=0.967, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=118692
2022-10-17 04:35:34 - progress_bar.py[line:274] - INFO: epoch 001:  25012 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=24980, lr=4.95394e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=118703
2022-10-17 04:35:45 - progress_bar.py[line:274] - INFO: epoch 001:  25022 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99, ups=0.91, wpb=109.3, bsz=40, num_updates=24990, lr=4.95384e-05, gnorm=0.886, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118714
2022-10-17 04:35:56 - progress_bar.py[line:274] - INFO: epoch 001:  25032 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.1, ups=0.88, wpb=109.8, bsz=40, num_updates=25000, lr=4.95374e-05, gnorm=0.924, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=118725
2022-10-17 04:35:56 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 04:35:58 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 04:35:58 - train.py[line:551] - INFO: load:1.04 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 04:38:29 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 04:38:29 - train.py[line:551] - INFO: load:1.06 valid_run:151.39 task_valid:147.98 collect_output:2.38
2022-10-17 04:40:57 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 04:40:57 - train.py[line:551] - INFO: load:1.09 valid_run:299.73 task_valid:291.31 collect_output:6.41
2022-10-17 04:43:29 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 04:43:29 - train.py[line:551] - INFO: load:1.11 valid_run:451.23 task_valid:434.34 collect_output:13.88
2022-10-17 04:45:58 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 04:45:58 - train.py[line:551] - INFO: load:1.14 valid_run:599.84 task_valid:579.29 collect_output:16.53
2022-10-17 04:48:30 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 04:48:30 - train.py[line:551] - INFO: load:1.16 valid_run:751.88 task_valid:726.84 collect_output:19.99
2022-10-17 04:51:01 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 04:51:01 - train.py[line:551] - INFO: load:1.19 valid_run:903.37 task_valid:872.45 collect_output:24.88
2022-10-17 04:53:34 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 04:53:34 - train.py[line:551] - INFO: load:1.21 valid_run:1055.92 task_valid:1018.54 collect_output:30.32
2022-10-17 04:56:04 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 04:56:04 - train.py[line:551] - INFO: load:1.24 valid_run:1206.34 task_valid:1159.62 collect_output:38.67
2022-10-17 04:58:34 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 04:58:34 - train.py[line:551] - INFO: load:1.26 valid_run:1355.45 task_valid:1304.29 collect_output:42.11
2022-10-17 05:01:02 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 05:01:02 - train.py[line:551] - INFO: load:1.29 valid_run:1503.58 task_valid:1447.47 collect_output:46.03
2022-10-17 05:03:32 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 05:03:32 - train.py[line:551] - INFO: load:1.32 valid_run:1653.78 task_valid:1592.87 collect_output:49.76
2022-10-17 05:06:02 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 05:06:02 - train.py[line:551] - INFO: load:1.34 valid_run:1803.84 task_valid:1738.29 collect_output:53.30
2022-10-17 05:08:32 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 05:08:32 - train.py[line:551] - INFO: load:1.37 valid_run:1953.66 task_valid:1880.55 collect_output:59.74
2022-10-17 05:11:03 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 05:11:03 - train.py[line:551] - INFO: load:1.40 valid_run:2104.30 task_valid:2026.46 collect_output:63.35
2022-10-17 05:13:33 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 05:13:33 - train.py[line:551] - INFO: load:1.42 valid_run:2254.81 task_valid:2173.56 collect_output:65.72
2022-10-17 05:16:03 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 05:16:03 - train.py[line:551] - INFO: load:1.45 valid_run:2404.92 task_valid:2318.22 collect_output:70.07
2022-10-17 05:18:35 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 05:18:35 - train.py[line:551] - INFO: load:1.47 valid_run:2556.56 task_valid:2464.18 collect_output:74.65
2022-10-17 05:21:06 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 05:21:06 - train.py[line:551] - INFO: load:1.50 valid_run:2707.46 task_valid:2611.71 collect_output:76.92
2022-10-17 05:23:35 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 05:23:35 - train.py[line:551] - INFO: load:1.52 valid_run:2856.23 task_valid:2754.01 collect_output:82.24
2022-10-17 05:26:06 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 05:26:06 - train.py[line:551] - INFO: load:1.55 valid_run:3006.89 task_valid:2899.63 collect_output:86.15
2022-10-17 05:28:38 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 05:28:38 - train.py[line:551] - INFO: load:1.57 valid_run:3159.21 task_valid:3044.70 collect_output:92.25
2022-10-17 05:31:07 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 05:31:07 - train.py[line:551] - INFO: load:1.60 valid_run:3308.57 task_valid:3189.47 collect_output:95.76
2022-10-17 05:33:39 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 05:33:39 - train.py[line:551] - INFO: load:1.62 valid_run:3459.59 task_valid:3335.71 collect_output:99.53
2022-10-17 05:36:10 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 05:36:10 - train.py[line:551] - INFO: load:1.65 valid_run:3611.02 task_valid:3482.34 collect_output:103.34

====================================================================================================
SGG eval:     R @ 50: 0.4646;     R @ 100: 0.5305;     R @ 500: 0.5596;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3071;    mR @ 100: 0.3969;    mR @ 500: 0.4325;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6122) (covered in:0.7500) (covering:0.3714) (eating:0.5000) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8318) (playing:0.0000) (riding:0.6879) (says:0.0000) (sitting on:0.6684) (standing on:0.2320) (using:0.6500) (walking in:0.6667) (walking on:0.4414) (watching:0.2500) 
--------------------------------------------------------
====================================================================================================

2022-10-17 05:38:41 - train.py[line:487] - INFO: 0.5305081232492997

====================================================================================================
SGG eval:     R @ 50: 0.4646;     R @ 100: 0.5305;     R @ 500: 0.5596;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3071;    mR @ 100: 0.3969;    mR @ 500: 0.4325;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6122) (covered in:0.7500) (covering:0.3714) (eating:0.5000) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8318) (playing:0.0000) (riding:0.6879) (says:0.0000) (sitting on:0.6684) (standing on:0.2320) (using:0.6500) (walking in:0.6667) (walking on:0.4414) (watching:0.2500) 
--------------------------------------------------------
====================================================================================================

2022-10-17 05:38:41 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 05:38:41 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.384 | loss_v1 0 | loss_v2 0 | nll_loss 0.23 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.530508 | ppl 1.17 | vqa_score 0.4482 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 25000 | best_R@100 0.581461
2022-10-17 05:38:41 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 25000 updates
2022-10-17 05:38:41 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_25000.pt
2022-10-17 05:38:47 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_25000.pt
2022-10-17 05:38:49 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_25000.pt (epoch 1 @ 25000 updates, score 0.5305081232492997) (writing took 8.200352061074227 seconds)
2022-10-17 05:39:00 - progress_bar.py[line:274] - INFO: epoch 001:  25042 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=0.3, ups=0, wpb=110.7, bsz=40, num_updates=25010, lr=4.95363e-05, gnorm=1.069, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122509
2022-10-17 05:39:11 - progress_bar.py[line:274] - INFO: epoch 001:  25052 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.7, ups=0.91, wpb=108.8, bsz=40, num_updates=25020, lr=4.95353e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122520
2022-10-17 05:39:23 - progress_bar.py[line:274] - INFO: epoch 001:  25062 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=25030, lr=4.95343e-05, gnorm=0.933, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122532
2022-10-17 05:39:34 - progress_bar.py[line:274] - INFO: epoch 001:  25072 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=25040, lr=4.95333e-05, gnorm=1.028, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122543
2022-10-17 05:39:45 - progress_bar.py[line:274] - INFO: epoch 001:  25082 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=25050, lr=4.95323e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122554
2022-10-17 05:39:56 - progress_bar.py[line:274] - INFO: epoch 001:  25092 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=25060, lr=4.95312e-05, gnorm=0.972, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122565
2022-10-17 05:40:08 - progress_bar.py[line:274] - INFO: epoch 001:  25102 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.3, ups=0.88, wpb=110.7, bsz=40, num_updates=25070, lr=4.95302e-05, gnorm=0.939, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=122577
2022-10-17 05:40:19 - progress_bar.py[line:274] - INFO: epoch 001:  25112 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.9, ups=0.89, wpb=109.5, bsz=40, num_updates=25080, lr=4.95292e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=122588
2022-10-17 05:40:30 - progress_bar.py[line:274] - INFO: epoch 001:  25122 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.7, ups=0.88, wpb=111.1, bsz=40, num_updates=25090, lr=4.95282e-05, gnorm=0.999, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122599
2022-10-17 05:40:42 - progress_bar.py[line:274] - INFO: epoch 001:  25132 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.7, ups=0.89, wpb=110, bsz=40, num_updates=25100, lr=4.95272e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122610
2022-10-17 05:40:53 - progress_bar.py[line:274] - INFO: epoch 001:  25142 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.4, ups=0.89, wpb=111.8, bsz=40, num_updates=25110, lr=4.95262e-05, gnorm=0.944, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=122622
2022-10-17 05:41:04 - progress_bar.py[line:274] - INFO: epoch 001:  25152 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.8, ups=0.93, wpb=108.8, bsz=40, num_updates=25120, lr=4.95251e-05, gnorm=1.235, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122633
2022-10-17 05:41:15 - progress_bar.py[line:274] - INFO: epoch 001:  25162 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.3, ups=0.92, wpb=108.5, bsz=40, num_updates=25130, lr=4.95241e-05, gnorm=0.999, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122643
2022-10-17 05:41:25 - progress_bar.py[line:274] - INFO: epoch 001:  25172 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=103.7, ups=0.94, wpb=109.9, bsz=40, num_updates=25140, lr=4.95231e-05, gnorm=1.049, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122654
2022-10-17 05:41:36 - progress_bar.py[line:274] - INFO: epoch 001:  25182 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=25150, lr=4.95221e-05, gnorm=1.038, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122665
2022-10-17 05:41:47 - progress_bar.py[line:274] - INFO: epoch 001:  25192 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=25160, lr=4.95211e-05, gnorm=0.874, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122676
2022-10-17 05:41:59 - progress_bar.py[line:274] - INFO: epoch 001:  25202 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=25170, lr=4.952e-05, gnorm=0.862, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122688
2022-10-17 05:42:10 - progress_bar.py[line:274] - INFO: epoch 001:  25212 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.1, ups=0.87, wpb=109.5, bsz=40, num_updates=25180, lr=4.9519e-05, gnorm=0.922, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122699
2022-10-17 05:42:21 - progress_bar.py[line:274] - INFO: epoch 001:  25222 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=103.2, ups=0.93, wpb=111.2, bsz=40, num_updates=25190, lr=4.9518e-05, gnorm=0.922, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122710
2022-10-17 05:42:32 - progress_bar.py[line:274] - INFO: epoch 001:  25232 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=25200, lr=4.9517e-05, gnorm=0.891, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122721
2022-10-17 05:42:43 - progress_bar.py[line:274] - INFO: epoch 001:  25242 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.2, ups=0.92, wpb=110.1, bsz=40, num_updates=25210, lr=4.9516e-05, gnorm=0.917, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122732
2022-10-17 05:42:54 - progress_bar.py[line:274] - INFO: epoch 001:  25252 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=25220, lr=4.9515e-05, gnorm=0.753, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122743
2022-10-17 05:43:05 - progress_bar.py[line:274] - INFO: epoch 001:  25262 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=25230, lr=4.95139e-05, gnorm=0.922, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122754
2022-10-17 05:43:17 - progress_bar.py[line:274] - INFO: epoch 001:  25272 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=25240, lr=4.95129e-05, gnorm=0.944, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122766
2022-10-17 05:43:28 - progress_bar.py[line:274] - INFO: epoch 001:  25282 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.2, ups=0.91, wpb=110.5, bsz=40, num_updates=25250, lr=4.95119e-05, gnorm=0.811, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122777
2022-10-17 05:43:39 - progress_bar.py[line:274] - INFO: epoch 001:  25292 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.1, ups=0.89, wpb=110.8, bsz=40, num_updates=25260, lr=4.95109e-05, gnorm=0.936, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122788
2022-10-17 05:43:50 - progress_bar.py[line:274] - INFO: epoch 001:  25302 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.6, ups=0.91, wpb=111.1, bsz=40, num_updates=25270, lr=4.95099e-05, gnorm=1.023, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122799
2022-10-17 05:44:01 - progress_bar.py[line:274] - INFO: epoch 001:  25312 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.9, ups=0.91, wpb=111.5, bsz=40, num_updates=25280, lr=4.95088e-05, gnorm=0.882, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122810
2022-10-17 05:44:12 - progress_bar.py[line:274] - INFO: epoch 001:  25322 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=25290, lr=4.95078e-05, gnorm=0.876, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122821
2022-10-17 05:44:23 - progress_bar.py[line:274] - INFO: epoch 001:  25332 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=103, ups=0.93, wpb=111.2, bsz=40, num_updates=25300, lr=4.95068e-05, gnorm=0.812, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122832
2022-10-17 05:44:35 - progress_bar.py[line:274] - INFO: epoch 001:  25342 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=25310, lr=4.95058e-05, gnorm=1.073, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122843
2022-10-17 05:44:45 - progress_bar.py[line:274] - INFO: epoch 001:  25352 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.9, ups=0.93, wpb=109.7, bsz=40, num_updates=25320, lr=4.95048e-05, gnorm=1.049, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122854
2022-10-17 05:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  25362 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.7, ups=0.92, wpb=109.8, bsz=40, num_updates=25330, lr=4.95038e-05, gnorm=0.945, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122865
2022-10-17 05:45:08 - progress_bar.py[line:274] - INFO: epoch 001:  25372 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=25340, lr=4.95027e-05, gnorm=0.891, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122876
2022-10-17 05:45:19 - progress_bar.py[line:274] - INFO: epoch 001:  25382 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.9, ups=0.91, wpb=109.2, bsz=40, num_updates=25350, lr=4.95017e-05, gnorm=0.907, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122888
2022-10-17 05:45:30 - progress_bar.py[line:274] - INFO: epoch 001:  25392 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.89, wpb=108.9, bsz=40, num_updates=25360, lr=4.95007e-05, gnorm=0.987, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122899
2022-10-17 05:45:41 - progress_bar.py[line:274] - INFO: epoch 001:  25402 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.8, ups=0.87, wpb=110.1, bsz=40, num_updates=25370, lr=4.94997e-05, gnorm=1.085, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=122910
2022-10-17 05:45:53 - progress_bar.py[line:274] - INFO: epoch 001:  25412 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=25380, lr=4.94987e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122922
2022-10-17 05:46:04 - progress_bar.py[line:274] - INFO: epoch 001:  25422 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.2, ups=0.9, wpb=110.8, bsz=40, num_updates=25390, lr=4.94976e-05, gnorm=0.87, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122933
2022-10-17 05:46:15 - progress_bar.py[line:274] - INFO: epoch 001:  25432 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=25400, lr=4.94966e-05, gnorm=0.904, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122944
2022-10-17 05:46:27 - progress_bar.py[line:274] - INFO: epoch 001:  25442 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=25410, lr=4.94956e-05, gnorm=0.971, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=122955
2022-10-17 05:46:38 - progress_bar.py[line:274] - INFO: epoch 001:  25452 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.89, wpb=110.7, bsz=40, num_updates=25420, lr=4.94946e-05, gnorm=1.023, clip=60, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=122967
2022-10-17 05:46:49 - progress_bar.py[line:274] - INFO: epoch 001:  25462 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.4, ups=0.9, wpb=110.4, bsz=40, num_updates=25430, lr=4.94936e-05, gnorm=1.135, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=122978
2022-10-17 05:47:00 - progress_bar.py[line:274] - INFO: epoch 001:  25472 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=25440, lr=4.94925e-05, gnorm=1.056, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=122989
2022-10-17 05:47:11 - progress_bar.py[line:274] - INFO: epoch 001:  25482 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.4, ups=0.93, wpb=109.4, bsz=40, num_updates=25450, lr=4.94915e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123000
2022-10-17 05:47:21 - progress_bar.py[line:274] - INFO: epoch 001:  25492 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=104, ups=0.94, wpb=110.6, bsz=40, num_updates=25460, lr=4.94905e-05, gnorm=1.114, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123010
2022-10-17 05:47:29 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 05:47:34 - progress_bar.py[line:274] - INFO: epoch 001:  25503 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.83, wpb=109.6, bsz=40, num_updates=25470, lr=4.94895e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=123023
2022-10-17 05:47:45 - progress_bar.py[line:274] - INFO: epoch 001:  25513 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=25480, lr=4.94885e-05, gnorm=1.059, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=123034
2022-10-17 05:47:56 - progress_bar.py[line:274] - INFO: epoch 001:  25523 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.9, wpb=109.7, bsz=40, num_updates=25490, lr=4.94875e-05, gnorm=0.998, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123045
2022-10-17 05:48:07 - progress_bar.py[line:274] - INFO: epoch 001:  25533 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.9, wpb=109, bsz=40, num_updates=25500, lr=4.94864e-05, gnorm=0.975, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123056
2022-10-17 05:48:18 - progress_bar.py[line:274] - INFO: epoch 001:  25543 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=25510, lr=4.94854e-05, gnorm=0.958, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123067
2022-10-17 05:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  25553 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=25520, lr=4.94844e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123078
2022-10-17 05:48:41 - progress_bar.py[line:274] - INFO: epoch 001:  25563 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=25530, lr=4.94834e-05, gnorm=0.875, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123090
2022-10-17 05:48:52 - progress_bar.py[line:274] - INFO: epoch 001:  25573 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.9, wpb=110.2, bsz=40, num_updates=25540, lr=4.94824e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123101
2022-10-17 05:49:03 - progress_bar.py[line:274] - INFO: epoch 001:  25583 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101, ups=0.91, wpb=111, bsz=40, num_updates=25550, lr=4.94813e-05, gnorm=0.962, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123112
2022-10-17 05:49:14 - progress_bar.py[line:274] - INFO: epoch 001:  25593 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.3, ups=0.88, wpb=109.2, bsz=40, num_updates=25560, lr=4.94803e-05, gnorm=0.861, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123123
2022-10-17 05:49:26 - progress_bar.py[line:274] - INFO: epoch 001:  25603 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.1, ups=0.89, wpb=108.6, bsz=40, num_updates=25570, lr=4.94793e-05, gnorm=0.976, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123135
2022-10-17 05:49:37 - progress_bar.py[line:274] - INFO: epoch 001:  25613 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.1, ups=0.9, wpb=109.5, bsz=40, num_updates=25580, lr=4.94783e-05, gnorm=0.9, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123146
2022-10-17 05:49:49 - progress_bar.py[line:274] - INFO: epoch 001:  25623 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.8, ups=0.87, wpb=110, bsz=40, num_updates=25590, lr=4.94773e-05, gnorm=0.826, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123157
2022-10-17 05:50:00 - progress_bar.py[line:274] - INFO: epoch 001:  25633 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.4, ups=0.89, wpb=109.2, bsz=40, num_updates=25600, lr=4.94763e-05, gnorm=0.893, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123169
2022-10-17 05:50:11 - progress_bar.py[line:274] - INFO: epoch 001:  25643 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=25610, lr=4.94752e-05, gnorm=0.803, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=123180
2022-10-17 05:50:22 - progress_bar.py[line:274] - INFO: epoch 001:  25653 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.3, ups=0.9, wpb=108.7, bsz=40, num_updates=25620, lr=4.94742e-05, gnorm=0.933, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123191
2022-10-17 05:50:34 - progress_bar.py[line:274] - INFO: epoch 001:  25663 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.6, ups=0.87, wpb=109.8, bsz=40, num_updates=25630, lr=4.94732e-05, gnorm=0.899, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123203
2022-10-17 05:50:45 - progress_bar.py[line:274] - INFO: epoch 001:  25673 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.1, ups=0.87, wpb=110.4, bsz=40, num_updates=25640, lr=4.94722e-05, gnorm=0.922, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123214
2022-10-17 05:50:57 - progress_bar.py[line:274] - INFO: epoch 001:  25683 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=25650, lr=4.94712e-05, gnorm=0.976, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123225
2022-10-17 05:51:08 - progress_bar.py[line:274] - INFO: epoch 001:  25693 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.4, ups=0.88, wpb=109.3, bsz=40, num_updates=25660, lr=4.94701e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123237
2022-10-17 05:51:19 - progress_bar.py[line:274] - INFO: epoch 001:  25703 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=25670, lr=4.94691e-05, gnorm=0.86, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123248
2022-10-17 05:51:30 - progress_bar.py[line:274] - INFO: epoch 001:  25713 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=25680, lr=4.94681e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123259
2022-10-17 05:51:42 - progress_bar.py[line:274] - INFO: epoch 001:  25723 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97, ups=0.87, wpb=111.4, bsz=40, num_updates=25690, lr=4.94671e-05, gnorm=0.966, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123271
2022-10-17 05:51:53 - progress_bar.py[line:274] - INFO: epoch 001:  25733 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=25700, lr=4.94661e-05, gnorm=0.873, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=123282
2022-10-17 05:52:05 - progress_bar.py[line:274] - INFO: epoch 001:  25743 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.7, ups=0.87, wpb=109.7, bsz=40, num_updates=25710, lr=4.94651e-05, gnorm=0.952, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123294
2022-10-17 05:52:16 - progress_bar.py[line:274] - INFO: epoch 001:  25753 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=25720, lr=4.9464e-05, gnorm=0.948, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123305
2022-10-17 05:52:28 - progress_bar.py[line:274] - INFO: epoch 001:  25763 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.7, ups=0.87, wpb=110.2, bsz=40, num_updates=25730, lr=4.9463e-05, gnorm=0.795, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123317
2022-10-17 05:52:39 - progress_bar.py[line:274] - INFO: epoch 001:  25773 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.6, ups=0.87, wpb=108.5, bsz=40, num_updates=25740, lr=4.9462e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123328
2022-10-17 05:52:50 - progress_bar.py[line:274] - INFO: epoch 001:  25783 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.7, ups=0.92, wpb=108.9, bsz=40, num_updates=25750, lr=4.9461e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123339
2022-10-17 05:53:01 - progress_bar.py[line:274] - INFO: epoch 001:  25793 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.4, ups=0.9, wpb=112.3, bsz=40, num_updates=25760, lr=4.946e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123350
2022-10-17 05:53:12 - progress_bar.py[line:274] - INFO: epoch 001:  25803 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=25770, lr=4.94589e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123361
2022-10-17 05:53:23 - progress_bar.py[line:274] - INFO: epoch 001:  25813 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=25780, lr=4.94579e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123372
2022-10-17 05:53:35 - progress_bar.py[line:274] - INFO: epoch 001:  25823 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.5, ups=0.9, wpb=109.1, bsz=40, num_updates=25790, lr=4.94569e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123384
2022-10-17 05:53:46 - progress_bar.py[line:274] - INFO: epoch 001:  25833 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=25800, lr=4.94559e-05, gnorm=0.779, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123395
2022-10-17 05:53:57 - progress_bar.py[line:274] - INFO: epoch 001:  25843 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.4, ups=0.89, wpb=111.8, bsz=40, num_updates=25810, lr=4.94549e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123406
2022-10-17 05:54:08 - progress_bar.py[line:274] - INFO: epoch 001:  25853 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=25820, lr=4.94539e-05, gnorm=0.888, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123417
2022-10-17 05:54:19 - progress_bar.py[line:274] - INFO: epoch 001:  25863 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=103, ups=0.93, wpb=110.7, bsz=40, num_updates=25830, lr=4.94528e-05, gnorm=0.734, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123428
2022-10-17 05:54:30 - progress_bar.py[line:274] - INFO: epoch 001:  25873 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.6, ups=0.89, wpb=108.6, bsz=40, num_updates=25840, lr=4.94518e-05, gnorm=0.962, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123439
2022-10-17 05:54:41 - progress_bar.py[line:274] - INFO: epoch 001:  25883 / 102288 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=25850, lr=4.94508e-05, gnorm=0.881, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=123450
2022-10-17 05:54:52 - progress_bar.py[line:274] - INFO: epoch 001:  25893 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=25860, lr=4.94498e-05, gnorm=1.012, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123461
2022-10-17 05:55:03 - progress_bar.py[line:274] - INFO: epoch 001:  25903 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=25870, lr=4.94488e-05, gnorm=0.998, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123472
2022-10-17 05:55:14 - progress_bar.py[line:274] - INFO: epoch 001:  25913 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=25880, lr=4.94477e-05, gnorm=0.833, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123483
2022-10-17 05:55:26 - progress_bar.py[line:274] - INFO: epoch 001:  25923 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=25890, lr=4.94467e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123495
2022-10-17 05:55:37 - progress_bar.py[line:274] - INFO: epoch 001:  25933 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=25900, lr=4.94457e-05, gnorm=0.876, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123506
2022-10-17 05:55:48 - progress_bar.py[line:274] - INFO: epoch 001:  25943 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.5, ups=0.92, wpb=111.7, bsz=40, num_updates=25910, lr=4.94447e-05, gnorm=0.807, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=123517
2022-10-17 05:55:59 - progress_bar.py[line:274] - INFO: epoch 001:  25953 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=25920, lr=4.94437e-05, gnorm=0.962, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123528
2022-10-17 05:56:11 - progress_bar.py[line:274] - INFO: epoch 001:  25963 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=25930, lr=4.94426e-05, gnorm=0.948, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123540
2022-10-17 05:56:22 - progress_bar.py[line:274] - INFO: epoch 001:  25973 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.3, ups=0.89, wpb=109.1, bsz=40, num_updates=25940, lr=4.94416e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123551
2022-10-17 05:56:33 - progress_bar.py[line:274] - INFO: epoch 001:  25983 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99, ups=0.9, wpb=109.5, bsz=40, num_updates=25950, lr=4.94406e-05, gnorm=0.841, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123562
2022-10-17 05:56:44 - progress_bar.py[line:274] - INFO: epoch 001:  25993 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=25960, lr=4.94396e-05, gnorm=0.955, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=123573
2022-10-17 05:56:55 - progress_bar.py[line:274] - INFO: epoch 001:  26003 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=25970, lr=4.94386e-05, gnorm=0.969, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=123584
2022-10-17 05:57:06 - progress_bar.py[line:274] - INFO: epoch 001:  26013 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.8, ups=0.91, wpb=111, bsz=40, num_updates=25980, lr=4.94376e-05, gnorm=0.805, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=123595
2022-10-17 05:57:17 - progress_bar.py[line:274] - INFO: epoch 001:  26023 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.6, ups=0.91, wpb=110.1, bsz=40, num_updates=25990, lr=4.94365e-05, gnorm=0.888, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123606
2022-10-17 05:57:28 - progress_bar.py[line:274] - INFO: epoch 001:  26033 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=26000, lr=4.94355e-05, gnorm=0.798, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=123617
2022-10-17 05:57:28 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 05:57:30 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 05:57:30 - train.py[line:551] - INFO: load:1.00 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 05:57:46 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.88 GiB already allocated; 914.19 MiB free; 36.21 GiB reserved in total by PyTorch)
2022-10-17 05:57:46 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 7            |        cudaMalloc retries: 35        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9088 MB |   14318 MB |   17879 TB |   17879 TB |
|       from large pool |    8943 MB |   14173 MB |   17874 TB |   17874 TB |
|       from small pool |     144 MB |     145 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9088 MB |   14318 MB |   17879 TB |   17879 TB |
|       from large pool |    8943 MB |   14173 MB |   17874 TB |   17874 TB |
|       from small pool |     144 MB |     145 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   37078 MB |   37136 MB |  328378 MB |  291300 MB |
|       from large pool |   36932 MB |   36984 MB |  327910 MB |  290978 MB |
|       from small pool |     146 MB |     152 MB |     468 MB |     322 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   27989 MB |   27989 MB |   18676 TB |   18676 TB |
|       from large pool |   27988 MB |   27988 MB |   18670 TB |   18670 TB |
|       from small pool |       1 MB |       2 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |     834 M  |     834 M  |
|       from large pool |     563    |     575    |     266 M  |     266 M  |
|       from small pool |    3106    |    3116    |     567 M  |     567 M  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |     834 M  |     834 M  |
|       from large pool |     563    |     575    |     266 M  |     266 M  |
|       from small pool |    3106    |    3116    |     567 M  |     567 M  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     141    |     146    |     698    |     557    |
|       from large pool |      68    |      70    |     464    |     396    |
|       from small pool |      73    |      76    |     234    |     161    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      98    |     101    |  595052 K  |  595052 K  |
|       from large pool |      59    |      61    |   98941 K  |   98941 K  |
|       from small pool |      39    |      47    |  496111 K  |  496111 K  |
|===========================================================================|

2022-10-17 05:57:46 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-17 05:57:46 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-17 06:00:02 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 06:00:02 - train.py[line:551] - INFO: load:1.02 valid_run:152.66 task_valid:147.81 collect_output:2.88
2022-10-17 06:02:31 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 06:02:31 - train.py[line:551] - INFO: load:1.05 valid_run:300.64 task_valid:290.83 collect_output:6.84
2022-10-17 06:05:02 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 06:05:02 - train.py[line:551] - INFO: load:1.07 valid_run:452.30 task_valid:433.85 collect_output:14.47
2022-10-17 06:07:31 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 06:07:31 - train.py[line:551] - INFO: load:1.10 valid_run:601.32 task_valid:579.09 collect_output:17.25
2022-10-17 06:10:03 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 06:10:03 - train.py[line:551] - INFO: load:1.12 valid_run:753.36 task_valid:726.54 collect_output:20.85
2022-10-17 06:12:35 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 06:12:35 - train.py[line:551] - INFO: load:1.15 valid_run:904.56 task_valid:872.07 collect_output:25.53
2022-10-17 06:15:08 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 06:15:08 - train.py[line:551] - INFO: load:1.17 valid_run:1057.31 task_valid:1018.30 collect_output:30.99
2022-10-17 06:17:39 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 06:17:39 - train.py[line:551] - INFO: load:1.20 valid_run:1208.54 task_valid:1160.03 collect_output:39.45
2022-10-17 06:20:09 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 06:20:09 - train.py[line:551] - INFO: load:1.22 valid_run:1358.34 task_valid:1305.13 collect_output:43.01
2022-10-17 06:22:37 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 06:22:37 - train.py[line:551] - INFO: load:1.25 valid_run:1506.99 task_valid:1448.79 collect_output:46.92
2022-10-17 06:25:07 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 06:25:07 - train.py[line:551] - INFO: load:1.27 valid_run:1656.89 task_valid:1594.07 collect_output:50.42
2022-10-17 06:27:38 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 06:27:38 - train.py[line:551] - INFO: load:1.30 valid_run:1807.27 task_valid:1739.54 collect_output:54.21
2022-10-17 06:30:08 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 06:30:08 - train.py[line:551] - INFO: load:1.33 valid_run:1957.33 task_valid:1881.76 collect_output:60.94
2022-10-17 06:32:39 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 06:32:39 - train.py[line:551] - INFO: load:1.35 valid_run:2108.35 task_valid:2027.94 collect_output:64.68
2022-10-17 06:35:09 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 06:35:09 - train.py[line:551] - INFO: load:1.39 valid_run:2258.77 task_valid:2174.88 collect_output:67.05
2022-10-17 06:37:40 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 06:37:40 - train.py[line:551] - INFO: load:1.41 valid_run:2408.98 task_valid:2319.32 collect_output:71.76
2022-10-17 06:40:12 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 06:40:12 - train.py[line:551] - INFO: load:1.44 valid_run:2561.07 task_valid:2465.35 collect_output:76.80
2022-10-17 06:42:43 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 06:42:43 - train.py[line:551] - INFO: load:1.48 valid_run:2712.15 task_valid:2612.84 collect_output:79.26
2022-10-17 06:45:11 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 06:45:11 - train.py[line:551] - INFO: load:1.50 valid_run:2860.43 task_valid:2754.72 collect_output:84.64
2022-10-17 06:47:42 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 06:47:42 - train.py[line:551] - INFO: load:1.53 valid_run:3010.62 task_valid:2899.76 collect_output:88.79
2022-10-17 06:50:14 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 06:50:14 - train.py[line:551] - INFO: load:1.55 valid_run:3162.81 task_valid:3044.39 collect_output:95.37
2022-10-17 06:52:43 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 06:52:43 - train.py[line:551] - INFO: load:1.58 valid_run:3312.18 task_valid:3188.95 collect_output:99.19
2022-10-17 06:55:15 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 06:55:15 - train.py[line:551] - INFO: load:1.60 valid_run:3463.46 task_valid:3335.17 collect_output:103.24
2022-10-17 06:57:46 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 06:57:46 - train.py[line:551] - INFO: load:1.63 valid_run:3614.79 task_valid:3481.72 collect_output:107.02

====================================================================================================
SGG eval:     R @ 50: 0.4494;     R @ 100: 0.5088;     R @ 500: 0.5392;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2950;    mR @ 100: 0.3811;    mR @ 500: 0.4176;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5878) (covered in:0.7500) (covering:0.3714) (eating:0.5000) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8229) (playing:0.0000) (riding:0.6732) (says:0.0000) (sitting on:0.6531) (standing on:0.2200) (using:0.6000) (walking in:0.6667) (walking on:0.2523) (watching:0.2500) 
--------------------------------------------------------
====================================================================================================

2022-10-17 07:00:17 - train.py[line:487] - INFO: 0.5088285714285714
2022-10-17 07:00:17 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.4494;     R @ 100: 0.5088;     R @ 500: 0.5392;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2950;    mR @ 100: 0.3811;    mR @ 500: 0.4176;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5878) (covered in:0.7500) (covering:0.3714) (eating:0.5000) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8229) (playing:0.0000) (riding:0.6732) (says:0.0000) (sitting on:0.6531) (standing on:0.2200) (using:0.6000) (walking in:0.6667) (walking on:0.2523) (watching:0.2500) 
--------------------------------------------------------
====================================================================================================

2022-10-17 07:00:17 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.334 | loss_v1 0 | loss_v2 0 | nll_loss 0.172 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.508829 | ppl 1.13 | vqa_score 0.4347 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 26000 | best_R@100 0.581461
2022-10-17 07:00:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 26000 updates
2022-10-17 07:00:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_26000.pt
2022-10-17 07:00:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_26000.pt
2022-10-17 07:00:26 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_26000.pt (epoch 1 @ 26000 updates, score 0.5088285714285714) (writing took 8.372678447980434 seconds)
2022-10-17 07:00:34 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 07:00:38 - progress_bar.py[line:274] - INFO: epoch 001:  26044 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=0.3, ups=0, wpb=111.2, bsz=40, num_updates=26010, lr=4.94345e-05, gnorm=0.976, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=127407
2022-10-17 07:00:49 - progress_bar.py[line:274] - INFO: epoch 001:  26054 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.1, ups=0.91, wpb=111.4, bsz=40, num_updates=26020, lr=4.94335e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127418
2022-10-17 07:01:00 - progress_bar.py[line:274] - INFO: epoch 001:  26064 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.5, ups=0.89, wpb=109.4, bsz=40, num_updates=26030, lr=4.94325e-05, gnorm=0.862, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127429
2022-10-17 07:01:12 - progress_bar.py[line:274] - INFO: epoch 001:  26074 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=26040, lr=4.94314e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=127441
2022-10-17 07:01:23 - progress_bar.py[line:274] - INFO: epoch 001:  26084 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.3, ups=0.89, wpb=109.3, bsz=40, num_updates=26050, lr=4.94304e-05, gnorm=0.984, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127452
2022-10-17 07:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  26094 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.6, ups=0.89, wpb=109.2, bsz=40, num_updates=26060, lr=4.94294e-05, gnorm=1.156, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127463
2022-10-17 07:01:45 - progress_bar.py[line:274] - INFO: epoch 001:  26104 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=26070, lr=4.94284e-05, gnorm=1.103, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127474
2022-10-17 07:01:56 - progress_bar.py[line:274] - INFO: epoch 001:  26114 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=26080, lr=4.94274e-05, gnorm=1.01, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127485
2022-10-17 07:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  26124 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.6, ups=0.92, wpb=110.5, bsz=40, num_updates=26090, lr=4.94264e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127496
2022-10-17 07:02:18 - progress_bar.py[line:274] - INFO: epoch 001:  26134 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=26100, lr=4.94253e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127507
2022-10-17 07:02:30 - progress_bar.py[line:274] - INFO: epoch 001:  26144 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.4, ups=0.89, wpb=109.2, bsz=40, num_updates=26110, lr=4.94243e-05, gnorm=0.933, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=127518
2022-10-17 07:02:41 - progress_bar.py[line:274] - INFO: epoch 001:  26154 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.1, ups=0.88, wpb=109, bsz=40, num_updates=26120, lr=4.94233e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127530
2022-10-17 07:02:52 - progress_bar.py[line:274] - INFO: epoch 001:  26164 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.4, ups=0.89, wpb=109.1, bsz=40, num_updates=26130, lr=4.94223e-05, gnorm=0.98, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127541
2022-10-17 07:03:03 - progress_bar.py[line:274] - INFO: epoch 001:  26174 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.9, ups=0.91, wpb=110.4, bsz=40, num_updates=26140, lr=4.94213e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127552
2022-10-17 07:03:14 - progress_bar.py[line:274] - INFO: epoch 001:  26184 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.3, ups=0.93, wpb=109.1, bsz=40, num_updates=26150, lr=4.94202e-05, gnorm=1, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=127563
2022-10-17 07:03:25 - progress_bar.py[line:274] - INFO: epoch 001:  26194 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.4, ups=0.9, wpb=111.2, bsz=40, num_updates=26160, lr=4.94192e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127574
2022-10-17 07:03:36 - progress_bar.py[line:274] - INFO: epoch 001:  26204 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=26170, lr=4.94182e-05, gnorm=0.944, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127585
2022-10-17 07:03:48 - progress_bar.py[line:274] - INFO: epoch 001:  26214 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=26180, lr=4.94172e-05, gnorm=0.913, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127597
2022-10-17 07:03:59 - progress_bar.py[line:274] - INFO: epoch 001:  26224 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.4, ups=0.91, wpb=109.8, bsz=40, num_updates=26190, lr=4.94162e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127608
2022-10-17 07:04:10 - progress_bar.py[line:274] - INFO: epoch 001:  26234 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.4, ups=0.87, wpb=110.6, bsz=40, num_updates=26200, lr=4.94152e-05, gnorm=0.907, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127619
2022-10-17 07:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  26244 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=26210, lr=4.94141e-05, gnorm=1.003, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127630
2022-10-17 07:04:33 - progress_bar.py[line:274] - INFO: epoch 001:  26254 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=26220, lr=4.94131e-05, gnorm=1.075, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127642
2022-10-17 07:04:44 - progress_bar.py[line:274] - INFO: epoch 001:  26264 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.7, ups=0.9, wpb=109.3, bsz=40, num_updates=26230, lr=4.94121e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127653
2022-10-17 07:04:55 - progress_bar.py[line:274] - INFO: epoch 001:  26274 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.2, ups=0.89, wpb=110.8, bsz=40, num_updates=26240, lr=4.94111e-05, gnorm=0.853, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127664
2022-10-17 07:05:06 - progress_bar.py[line:274] - INFO: epoch 001:  26284 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=26250, lr=4.94101e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127675
2022-10-17 07:05:21 - progress_bar.py[line:274] - INFO: epoch 001:  26294 / 102288 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=26260, lr=4.9409e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127687
2022-10-17 07:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  26304 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101, ups=0.91, wpb=110.7, bsz=40, num_updates=26270, lr=4.9408e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127701
2022-10-17 07:05:43 - progress_bar.py[line:274] - INFO: epoch 001:  26314 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101, ups=0.92, wpb=110.2, bsz=40, num_updates=26280, lr=4.9407e-05, gnorm=1.012, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127712
2022-10-17 07:05:54 - progress_bar.py[line:274] - INFO: epoch 001:  26324 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=26290, lr=4.9406e-05, gnorm=1.103, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127723
2022-10-17 07:06:05 - progress_bar.py[line:274] - INFO: epoch 001:  26334 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.6, ups=0.9, wpb=110.2, bsz=40, num_updates=26300, lr=4.9405e-05, gnorm=1.061, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=127734
2022-10-17 07:06:16 - progress_bar.py[line:274] - INFO: epoch 001:  26344 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=26310, lr=4.9404e-05, gnorm=0.987, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127745
2022-10-17 07:06:28 - progress_bar.py[line:274] - INFO: epoch 001:  26354 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=26320, lr=4.94029e-05, gnorm=0.917, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127756
2022-10-17 07:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  26364 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.3, ups=0.88, wpb=111.6, bsz=40, num_updates=26330, lr=4.94019e-05, gnorm=0.838, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=127768
2022-10-17 07:06:50 - progress_bar.py[line:274] - INFO: epoch 001:  26374 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.9, ups=0.92, wpb=109, bsz=40, num_updates=26340, lr=4.94009e-05, gnorm=0.926, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127779
2022-10-17 07:07:01 - progress_bar.py[line:274] - INFO: epoch 001:  26384 / 102288 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97, ups=0.87, wpb=111.1, bsz=40, num_updates=26350, lr=4.93999e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=127790
2022-10-17 07:07:13 - progress_bar.py[line:274] - INFO: epoch 001:  26394 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=26360, lr=4.93989e-05, gnorm=0.86, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127802
2022-10-17 07:07:24 - progress_bar.py[line:274] - INFO: epoch 001:  26404 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.8, ups=0.91, wpb=109.4, bsz=40, num_updates=26370, lr=4.93978e-05, gnorm=0.936, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127813
2022-10-17 07:07:35 - progress_bar.py[line:274] - INFO: epoch 001:  26414 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.2, ups=0.91, wpb=109.6, bsz=40, num_updates=26380, lr=4.93968e-05, gnorm=1.054, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127824
2022-10-17 07:07:46 - progress_bar.py[line:274] - INFO: epoch 001:  26424 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.4, ups=0.89, wpb=108.3, bsz=40, num_updates=26390, lr=4.93958e-05, gnorm=1.13, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=127835
2022-10-17 07:07:57 - progress_bar.py[line:274] - INFO: epoch 001:  26434 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=26400, lr=4.93948e-05, gnorm=1.111, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=127846
2022-10-17 07:08:08 - progress_bar.py[line:274] - INFO: epoch 001:  26444 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=104, ups=0.94, wpb=110.5, bsz=40, num_updates=26410, lr=4.93938e-05, gnorm=0.825, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127857
2022-10-17 07:08:19 - progress_bar.py[line:274] - INFO: epoch 001:  26454 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96, ups=0.87, wpb=110.3, bsz=40, num_updates=26420, lr=4.93927e-05, gnorm=0.991, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127868
2022-10-17 07:08:31 - progress_bar.py[line:274] - INFO: epoch 001:  26464 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=26430, lr=4.93917e-05, gnorm=0.943, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127880
2022-10-17 07:08:42 - progress_bar.py[line:274] - INFO: epoch 001:  26474 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.4, ups=0.91, wpb=108.8, bsz=40, num_updates=26440, lr=4.93907e-05, gnorm=0.979, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=127890
2022-10-17 07:08:52 - progress_bar.py[line:274] - INFO: epoch 001:  26484 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=103.1, ups=0.93, wpb=111.4, bsz=40, num_updates=26450, lr=4.93897e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127901
2022-10-17 07:09:04 - progress_bar.py[line:274] - INFO: epoch 001:  26494 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.6, ups=0.89, wpb=111.6, bsz=40, num_updates=26460, lr=4.93887e-05, gnorm=1.112, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127913
2022-10-17 07:09:14 - progress_bar.py[line:274] - INFO: epoch 001:  26504 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.4, ups=0.93, wpb=110.2, bsz=40, num_updates=26470, lr=4.93877e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127923
2022-10-17 07:09:25 - progress_bar.py[line:274] - INFO: epoch 001:  26514 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100, ups=0.91, wpb=110.1, bsz=40, num_updates=26480, lr=4.93866e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127934
2022-10-17 07:09:36 - progress_bar.py[line:274] - INFO: epoch 001:  26524 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.5, ups=0.91, wpb=109.9, bsz=40, num_updates=26490, lr=4.93856e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127945
2022-10-17 07:09:47 - progress_bar.py[line:274] - INFO: epoch 001:  26534 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=104.1, ups=0.93, wpb=112, bsz=40, num_updates=26500, lr=4.93846e-05, gnorm=0.947, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127956
2022-10-17 07:09:58 - progress_bar.py[line:274] - INFO: epoch 001:  26544 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.3, ups=0.93, wpb=109.1, bsz=40, num_updates=26510, lr=4.93836e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=127967
2022-10-17 07:10:09 - progress_bar.py[line:274] - INFO: epoch 001:  26554 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.2, ups=0.88, wpb=109, bsz=40, num_updates=26520, lr=4.93826e-05, gnorm=0.808, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=127978
2022-10-17 07:10:21 - progress_bar.py[line:274] - INFO: epoch 001:  26564 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=26530, lr=4.93815e-05, gnorm=0.936, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=127990
2022-10-17 07:10:32 - progress_bar.py[line:274] - INFO: epoch 001:  26574 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=26540, lr=4.93805e-05, gnorm=0.759, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128001
2022-10-17 07:10:44 - progress_bar.py[line:274] - INFO: epoch 001:  26584 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96, ups=0.87, wpb=110.1, bsz=40, num_updates=26550, lr=4.93795e-05, gnorm=0.9, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128012
2022-10-17 07:10:55 - progress_bar.py[line:274] - INFO: epoch 001:  26594 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=26560, lr=4.93785e-05, gnorm=1, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128024
2022-10-17 07:11:06 - progress_bar.py[line:274] - INFO: epoch 001:  26604 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.7, ups=0.91, wpb=110, bsz=40, num_updates=26570, lr=4.93775e-05, gnorm=0.958, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128035
2022-10-17 07:11:17 - progress_bar.py[line:274] - INFO: epoch 001:  26614 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=26580, lr=4.93765e-05, gnorm=1.065, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128046
2022-10-17 07:11:28 - progress_bar.py[line:274] - INFO: epoch 001:  26624 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=26590, lr=4.93754e-05, gnorm=0.925, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128057
2022-10-17 07:11:39 - progress_bar.py[line:274] - INFO: epoch 001:  26634 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.4, ups=0.92, wpb=110.7, bsz=40, num_updates=26600, lr=4.93744e-05, gnorm=1.064, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128068
2022-10-17 07:11:50 - progress_bar.py[line:274] - INFO: epoch 001:  26644 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.2, ups=0.92, wpb=110.5, bsz=40, num_updates=26610, lr=4.93734e-05, gnorm=1.025, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128079
2022-10-17 07:12:02 - progress_bar.py[line:274] - INFO: epoch 001:  26654 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=26620, lr=4.93724e-05, gnorm=0.974, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128090
2022-10-17 07:12:13 - progress_bar.py[line:274] - INFO: epoch 001:  26664 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.9, wpb=110.5, bsz=40, num_updates=26630, lr=4.93714e-05, gnorm=0.85, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128102
2022-10-17 07:12:24 - progress_bar.py[line:274] - INFO: epoch 001:  26674 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98, ups=0.9, wpb=108.7, bsz=40, num_updates=26640, lr=4.93703e-05, gnorm=1.031, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128113
2022-10-17 07:12:35 - progress_bar.py[line:274] - INFO: epoch 001:  26684 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=26650, lr=4.93693e-05, gnorm=1.046, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=128124
2022-10-17 07:12:46 - progress_bar.py[line:274] - INFO: epoch 001:  26694 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=26660, lr=4.93683e-05, gnorm=0.893, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128135
2022-10-17 07:12:58 - progress_bar.py[line:274] - INFO: epoch 001:  26704 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.2, ups=0.88, wpb=108.3, bsz=40, num_updates=26670, lr=4.93673e-05, gnorm=1.04, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=128147
2022-10-17 07:13:09 - progress_bar.py[line:274] - INFO: epoch 001:  26714 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.6, ups=0.87, wpb=111.2, bsz=40, num_updates=26680, lr=4.93663e-05, gnorm=0.985, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128158
2022-10-17 07:13:20 - progress_bar.py[line:274] - INFO: epoch 001:  26724 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.2, ups=0.93, wpb=110.3, bsz=40, num_updates=26690, lr=4.93653e-05, gnorm=0.955, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=128169
2022-10-17 07:13:31 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 07:13:32 - progress_bar.py[line:274] - INFO: epoch 001:  26735 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.2, ups=0.82, wpb=110.4, bsz=40, num_updates=26700, lr=4.93642e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=128181
2022-10-17 07:13:44 - progress_bar.py[line:274] - INFO: epoch 001:  26745 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96, ups=0.87, wpb=110.2, bsz=40, num_updates=26710, lr=4.93632e-05, gnorm=1.018, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=128193
2022-10-17 07:13:55 - progress_bar.py[line:274] - INFO: epoch 001:  26755 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=26720, lr=4.93622e-05, gnorm=0.913, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128204
2022-10-17 07:14:06 - progress_bar.py[line:274] - INFO: epoch 001:  26765 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=26730, lr=4.93612e-05, gnorm=1.073, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128215
2022-10-17 07:14:17 - progress_bar.py[line:274] - INFO: epoch 001:  26775 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=26740, lr=4.93602e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128226
2022-10-17 07:14:29 - progress_bar.py[line:274] - INFO: epoch 001:  26785 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97, ups=0.88, wpb=109.9, bsz=40, num_updates=26750, lr=4.93591e-05, gnorm=0.97, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128238
2022-10-17 07:14:40 - progress_bar.py[line:274] - INFO: epoch 001:  26795 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=26760, lr=4.93581e-05, gnorm=0.955, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=128249
2022-10-17 07:14:51 - progress_bar.py[line:274] - INFO: epoch 001:  26805 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=26770, lr=4.93571e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128260
2022-10-17 07:15:02 - progress_bar.py[line:274] - INFO: epoch 001:  26815 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=26780, lr=4.93561e-05, gnorm=0.89, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128271
2022-10-17 07:15:13 - progress_bar.py[line:274] - INFO: epoch 001:  26825 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=26790, lr=4.93551e-05, gnorm=0.894, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128282
2022-10-17 07:15:25 - progress_bar.py[line:274] - INFO: epoch 001:  26835 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=26800, lr=4.93541e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128293
2022-10-17 07:15:36 - progress_bar.py[line:274] - INFO: epoch 001:  26845 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=26810, lr=4.9353e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128305
2022-10-17 07:15:47 - progress_bar.py[line:274] - INFO: epoch 001:  26855 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=26820, lr=4.9352e-05, gnorm=0.845, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=128316
2022-10-17 07:15:58 - progress_bar.py[line:274] - INFO: epoch 001:  26865 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.4, ups=0.91, wpb=112.7, bsz=40, num_updates=26830, lr=4.9351e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128327
2022-10-17 07:16:09 - progress_bar.py[line:274] - INFO: epoch 001:  26875 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.91, wpb=109.1, bsz=40, num_updates=26840, lr=4.935e-05, gnorm=0.96, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128338
2022-10-17 07:16:20 - progress_bar.py[line:274] - INFO: epoch 001:  26885 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.2, ups=0.91, wpb=110.4, bsz=40, num_updates=26850, lr=4.9349e-05, gnorm=1.101, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128349
2022-10-17 07:16:31 - progress_bar.py[line:274] - INFO: epoch 001:  26895 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=26860, lr=4.93479e-05, gnorm=1.012, clip=40, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=128360
2022-10-17 07:16:42 - progress_bar.py[line:274] - INFO: epoch 001:  26905 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.7, ups=0.91, wpb=108.9, bsz=40, num_updates=26870, lr=4.93469e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128371
2022-10-17 07:16:54 - progress_bar.py[line:274] - INFO: epoch 001:  26915 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.2, ups=0.87, wpb=110.2, bsz=40, num_updates=26880, lr=4.93459e-05, gnorm=0.919, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128383
2022-10-17 07:17:05 - progress_bar.py[line:274] - INFO: epoch 001:  26925 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=26890, lr=4.93449e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=128394
2022-10-17 07:17:17 - progress_bar.py[line:274] - INFO: epoch 001:  26935 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.3, ups=0.87, wpb=109.8, bsz=40, num_updates=26900, lr=4.93439e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=128406
2022-10-17 07:17:28 - progress_bar.py[line:274] - INFO: epoch 001:  26945 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=26910, lr=4.93428e-05, gnorm=0.93, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=128417
2022-10-17 07:17:38 - progress_bar.py[line:274] - INFO: epoch 001:  26955 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=103.3, ups=0.94, wpb=109.9, bsz=40, num_updates=26920, lr=4.93418e-05, gnorm=1.1, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=128427
2022-10-17 07:17:50 - progress_bar.py[line:274] - INFO: epoch 001:  26965 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.1, ups=0.89, wpb=108.8, bsz=40, num_updates=26930, lr=4.93408e-05, gnorm=0.876, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128439
2022-10-17 07:18:01 - progress_bar.py[line:274] - INFO: epoch 001:  26975 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.2, ups=0.9, wpb=109.6, bsz=40, num_updates=26940, lr=4.93398e-05, gnorm=0.944, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128450
2022-10-17 07:18:12 - progress_bar.py[line:274] - INFO: epoch 001:  26985 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.5, ups=0.93, wpb=109.5, bsz=40, num_updates=26950, lr=4.93388e-05, gnorm=0.936, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=128461
2022-10-17 07:18:23 - progress_bar.py[line:274] - INFO: epoch 001:  26995 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=26960, lr=4.93378e-05, gnorm=0.97, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128472
2022-10-17 07:18:34 - progress_bar.py[line:274] - INFO: epoch 001:  27005 / 102288 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.6, ups=0.9, wpb=111.2, bsz=40, num_updates=26970, lr=4.93367e-05, gnorm=0.859, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128483
2022-10-17 07:18:45 - progress_bar.py[line:274] - INFO: epoch 001:  27015 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=26980, lr=4.93357e-05, gnorm=0.954, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128494
2022-10-17 07:18:56 - progress_bar.py[line:274] - INFO: epoch 001:  27025 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.3, ups=0.9, wpb=110.7, bsz=40, num_updates=26990, lr=4.93347e-05, gnorm=0.917, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128505
2022-10-17 07:19:08 - progress_bar.py[line:274] - INFO: epoch 001:  27035 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.6, ups=0.87, wpb=109.8, bsz=40, num_updates=27000, lr=4.93337e-05, gnorm=0.895, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=128517
2022-10-17 07:19:08 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 07:19:09 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 07:19:09 - train.py[line:551] - INFO: load:1.00 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 07:21:42 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 07:21:42 - train.py[line:551] - INFO: load:1.02 valid_run:152.36 task_valid:148.82 collect_output:2.55
2022-10-17 07:24:10 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 07:24:10 - train.py[line:551] - INFO: load:1.05 valid_run:300.38 task_valid:292.22 collect_output:6.17
2022-10-17 07:26:42 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 07:26:42 - train.py[line:551] - INFO: load:1.07 valid_run:452.17 task_valid:435.40 collect_output:13.80
2022-10-17 07:29:11 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 07:29:11 - train.py[line:551] - INFO: load:1.11 valid_run:601.13 task_valid:580.60 collect_output:16.47
2022-10-17 07:31:43 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 07:31:43 - train.py[line:551] - INFO: load:1.14 valid_run:753.60 task_valid:728.65 collect_output:19.83
2022-10-17 07:34:15 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 07:34:15 - train.py[line:551] - INFO: load:1.16 valid_run:905.42 task_valid:874.79 collect_output:24.35
2022-10-17 07:36:48 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 07:36:48 - train.py[line:551] - INFO: load:1.19 valid_run:1058.74 task_valid:1021.94 collect_output:29.36
2022-10-17 07:39:19 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 07:39:19 - train.py[line:551] - INFO: load:1.22 valid_run:1209.75 task_valid:1164.08 collect_output:37.07
2022-10-17 07:41:49 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 07:41:49 - train.py[line:551] - INFO: load:1.25 valid_run:1359.69 task_valid:1309.69 collect_output:40.30
2022-10-17 07:44:18 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 07:44:18 - train.py[line:551] - INFO: load:1.28 valid_run:1508.45 task_valid:1453.57 collect_output:44.11
2022-10-17 07:46:49 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 07:46:49 - train.py[line:551] - INFO: load:1.30 valid_run:1658.74 task_valid:1599.32 collect_output:47.58
2022-10-17 07:49:19 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 07:49:19 - train.py[line:551] - INFO: load:1.33 valid_run:1809.09 task_valid:1745.19 collect_output:50.97
2022-10-17 07:51:49 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 07:51:49 - train.py[line:551] - INFO: load:1.35 valid_run:1959.03 task_valid:1887.76 collect_output:57.23
2022-10-17 07:54:20 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 07:54:20 - train.py[line:551] - INFO: load:1.38 valid_run:2109.88 task_valid:2033.88 collect_output:60.76
2022-10-17 07:56:51 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 07:56:51 - train.py[line:551] - INFO: load:1.41 valid_run:2260.46 task_valid:2181.12 collect_output:62.92
2022-10-17 07:59:21 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 07:59:21 - train.py[line:551] - INFO: load:1.43 valid_run:2410.49 task_valid:2325.67 collect_output:67.29
2022-10-17 08:01:52 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 08:01:52 - train.py[line:551] - INFO: load:1.46 valid_run:2561.70 task_valid:2471.10 collect_output:72.10
2022-10-17 08:04:22 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 08:04:22 - train.py[line:551] - INFO: load:1.49 valid_run:2712.20 task_valid:2618.22 collect_output:74.48
2022-10-17 08:06:51 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 08:06:51 - train.py[line:551] - INFO: load:1.51 valid_run:2860.29 task_valid:2760.10 collect_output:79.70
2022-10-17 08:09:21 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 08:09:21 - train.py[line:551] - INFO: load:1.54 valid_run:3010.59 task_valid:2905.54 collect_output:83.54
2022-10-17 08:11:53 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 08:11:53 - train.py[line:551] - INFO: load:1.56 valid_run:3162.14 task_valid:3050.09 collect_output:89.55
2022-10-17 08:14:22 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 08:14:22 - train.py[line:551] - INFO: load:1.59 valid_run:3311.22 task_valid:3194.56 collect_output:93.16
2022-10-17 08:16:53 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 08:16:53 - train.py[line:551] - INFO: load:1.61 valid_run:3462.16 task_valid:3340.75 collect_output:96.94
2022-10-17 08:19:24 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 08:19:24 - train.py[line:551] - INFO: load:1.64 valid_run:3613.56 task_valid:3487.46 collect_output:100.64

====================================================================================================
SGG eval:     R @ 50: 0.4607;     R @ 100: 0.5187;     R @ 500: 0.5489;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3030;    mR @ 100: 0.3918;    mR @ 500: 0.4203;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5829) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8438) (playing:0.0000) (riding:0.7026) (says:0.0000) (sitting on:0.6590) (standing on:0.2300) (using:0.6500) (walking in:0.6667) (walking on:0.2117) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4607;     R @ 100: 0.5187;     R @ 500: 0.5489;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3030;    mR @ 100: 0.3918;    mR @ 500: 0.4203;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5829) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8438) (playing:0.0000) (riding:0.7026) (says:0.0000) (sitting on:0.6590) (standing on:0.2300) (using:0.6500) (walking in:0.6667) (walking on:0.2117) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2022-10-17 08:21:55 - train.py[line:487] - INFO: 0.5187285714285714
2022-10-17 08:21:55 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 08:21:55 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.358 | loss_v1 0 | loss_v2 0 | nll_loss 0.203 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.518729 | ppl 1.15 | vqa_score 0.4336 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 27000 | best_R@100 0.581461
2022-10-17 08:21:55 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 27000 updates
2022-10-17 08:21:55 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_27000.pt
2022-10-17 08:22:01 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_27000.pt
2022-10-17 08:22:04 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_27000.pt (epoch 1 @ 27000 updates, score 0.5187285714285714) (writing took 8.444373229052871 seconds)
2022-10-17 08:22:15 - progress_bar.py[line:274] - INFO: epoch 001:  27045 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=0.3, ups=0, wpb=109.6, bsz=40, num_updates=27010, lr=4.93327e-05, gnorm=0.869, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132304
2022-10-17 08:22:26 - progress_bar.py[line:274] - INFO: epoch 001:  27055 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.7, ups=0.91, wpb=111.3, bsz=40, num_updates=27020, lr=4.93316e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=132315
2022-10-17 08:22:37 - progress_bar.py[line:274] - INFO: epoch 001:  27065 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=27030, lr=4.93306e-05, gnorm=0.829, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132326
2022-10-17 08:22:49 - progress_bar.py[line:274] - INFO: epoch 001:  27075 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.4, ups=0.88, wpb=109.2, bsz=40, num_updates=27040, lr=4.93296e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132337
2022-10-17 08:23:00 - progress_bar.py[line:274] - INFO: epoch 001:  27085 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=27050, lr=4.93286e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132349
2022-10-17 08:23:11 - progress_bar.py[line:274] - INFO: epoch 001:  27095 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=27060, lr=4.93276e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=132360
2022-10-17 08:23:22 - progress_bar.py[line:274] - INFO: epoch 001:  27105 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.88, wpb=111.1, bsz=40, num_updates=27070, lr=4.93266e-05, gnorm=0.918, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132371
2022-10-17 08:23:33 - progress_bar.py[line:274] - INFO: epoch 001:  27115 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.9, wpb=110.2, bsz=40, num_updates=27080, lr=4.93255e-05, gnorm=0.85, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=132382
2022-10-17 08:23:44 - progress_bar.py[line:274] - INFO: epoch 001:  27125 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.1, ups=0.92, wpb=109.3, bsz=40, num_updates=27090, lr=4.93245e-05, gnorm=0.956, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132393
2022-10-17 08:23:56 - progress_bar.py[line:274] - INFO: epoch 001:  27135 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=27100, lr=4.93235e-05, gnorm=0.913, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132405
2022-10-17 08:24:07 - progress_bar.py[line:274] - INFO: epoch 001:  27145 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=103, ups=0.93, wpb=110.9, bsz=40, num_updates=27110, lr=4.93225e-05, gnorm=0.932, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132416
2022-10-17 08:24:17 - progress_bar.py[line:274] - INFO: epoch 001:  27155 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.5, ups=0.92, wpb=110.6, bsz=40, num_updates=27120, lr=4.93215e-05, gnorm=0.876, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132426
2022-10-17 08:24:29 - progress_bar.py[line:274] - INFO: epoch 001:  27165 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.4, ups=0.9, wpb=108.8, bsz=40, num_updates=27130, lr=4.93204e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=132438
2022-10-17 08:24:40 - progress_bar.py[line:274] - INFO: epoch 001:  27175 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.4, ups=0.87, wpb=110, bsz=40, num_updates=27140, lr=4.93194e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132449
2022-10-17 08:24:51 - progress_bar.py[line:274] - INFO: epoch 001:  27185 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=27150, lr=4.93184e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132460
2022-10-17 08:25:03 - progress_bar.py[line:274] - INFO: epoch 001:  27195 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.2, ups=0.88, wpb=109.5, bsz=40, num_updates=27160, lr=4.93174e-05, gnorm=1.033, clip=70, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=132472
2022-10-17 08:25:14 - progress_bar.py[line:274] - INFO: epoch 001:  27205 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=27170, lr=4.93164e-05, gnorm=0.893, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=132483
2022-10-17 08:25:25 - progress_bar.py[line:274] - INFO: epoch 001:  27215 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.3, ups=0.92, wpb=110.6, bsz=40, num_updates=27180, lr=4.93154e-05, gnorm=0.935, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132494
2022-10-17 08:25:36 - progress_bar.py[line:274] - INFO: epoch 001:  27225 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=27190, lr=4.93143e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132505
2022-10-17 08:25:48 - progress_bar.py[line:274] - INFO: epoch 001:  27235 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=27200, lr=4.93133e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132517
2022-10-17 08:25:59 - progress_bar.py[line:274] - INFO: epoch 001:  27245 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.88, wpb=111.6, bsz=40, num_updates=27210, lr=4.93123e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132528
2022-10-17 08:26:11 - progress_bar.py[line:274] - INFO: epoch 001:  27255 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.7, ups=0.9, wpb=108.3, bsz=40, num_updates=27220, lr=4.93113e-05, gnorm=0.905, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=132540
2022-10-17 08:26:22 - progress_bar.py[line:274] - INFO: epoch 001:  27265 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=27230, lr=4.93103e-05, gnorm=0.817, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=132551
2022-10-17 08:26:33 - progress_bar.py[line:274] - INFO: epoch 001:  27275 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=27240, lr=4.93092e-05, gnorm=0.877, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132562
2022-10-17 08:26:44 - progress_bar.py[line:274] - INFO: epoch 001:  27285 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99, ups=0.9, wpb=109.6, bsz=40, num_updates=27250, lr=4.93082e-05, gnorm=0.902, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=132573
2022-10-17 08:26:56 - progress_bar.py[line:274] - INFO: epoch 001:  27295 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.4, ups=0.89, wpb=108, bsz=40, num_updates=27260, lr=4.93072e-05, gnorm=0.907, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132584
2022-10-17 08:27:07 - progress_bar.py[line:274] - INFO: epoch 001:  27305 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.89, wpb=108.9, bsz=40, num_updates=27270, lr=4.93062e-05, gnorm=1.074, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132596
2022-10-17 08:27:18 - progress_bar.py[line:274] - INFO: epoch 001:  27315 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=27280, lr=4.93052e-05, gnorm=0.936, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132607
2022-10-17 08:27:29 - progress_bar.py[line:274] - INFO: epoch 001:  27325 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.6, ups=0.92, wpb=110.7, bsz=40, num_updates=27290, lr=4.93042e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132618
2022-10-17 08:27:31 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 08:27:41 - progress_bar.py[line:274] - INFO: epoch 001:  27336 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=90.8, ups=0.83, wpb=109.8, bsz=40, num_updates=27300, lr=4.93031e-05, gnorm=0.943, clip=50, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=132630
2022-10-17 08:27:52 - progress_bar.py[line:274] - INFO: epoch 001:  27346 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.3, ups=0.89, wpb=109.1, bsz=40, num_updates=27310, lr=4.93021e-05, gnorm=1.001, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=132641
2022-10-17 08:28:04 - progress_bar.py[line:274] - INFO: epoch 001:  27356 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.2, ups=0.89, wpb=111.2, bsz=40, num_updates=27320, lr=4.93011e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132652
2022-10-17 08:28:14 - progress_bar.py[line:274] - INFO: epoch 001:  27366 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=102.8, ups=0.93, wpb=110.9, bsz=40, num_updates=27330, lr=4.93001e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132663
2022-10-17 08:28:25 - progress_bar.py[line:274] - INFO: epoch 001:  27376 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=27340, lr=4.92991e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132674
2022-10-17 08:28:37 - progress_bar.py[line:274] - INFO: epoch 001:  27386 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.9, ups=0.91, wpb=110.8, bsz=40, num_updates=27350, lr=4.9298e-05, gnorm=0.929, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132685
2022-10-17 08:28:48 - progress_bar.py[line:274] - INFO: epoch 001:  27396 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.4, ups=0.87, wpb=108.5, bsz=40, num_updates=27360, lr=4.9297e-05, gnorm=1.025, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132697
2022-10-17 08:28:59 - progress_bar.py[line:274] - INFO: epoch 001:  27406 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.3, ups=0.93, wpb=110.4, bsz=40, num_updates=27370, lr=4.9296e-05, gnorm=1.065, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132708
2022-10-17 08:29:10 - progress_bar.py[line:274] - INFO: epoch 001:  27416 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.6, ups=0.9, wpb=109.1, bsz=40, num_updates=27380, lr=4.9295e-05, gnorm=1.052, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132719
2022-10-17 08:29:21 - progress_bar.py[line:274] - INFO: epoch 001:  27426 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.8, ups=0.91, wpb=109.9, bsz=40, num_updates=27390, lr=4.9294e-05, gnorm=1.091, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132730
2022-10-17 08:29:32 - progress_bar.py[line:274] - INFO: epoch 001:  27436 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.9, ups=0.9, wpb=111.5, bsz=40, num_updates=27400, lr=4.92929e-05, gnorm=0.998, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132741
2022-10-17 08:29:43 - progress_bar.py[line:274] - INFO: epoch 001:  27446 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=27410, lr=4.92919e-05, gnorm=0.986, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132752
2022-10-17 08:29:55 - progress_bar.py[line:274] - INFO: epoch 001:  27456 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=27420, lr=4.92909e-05, gnorm=1.041, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132764
2022-10-17 08:30:06 - progress_bar.py[line:274] - INFO: epoch 001:  27466 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94.8, ups=0.86, wpb=110.1, bsz=40, num_updates=27430, lr=4.92899e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=132775
2022-10-17 08:30:17 - progress_bar.py[line:274] - INFO: epoch 001:  27476 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.1, ups=0.9, wpb=110.1, bsz=40, num_updates=27440, lr=4.92889e-05, gnorm=0.989, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132786
2022-10-17 08:30:29 - progress_bar.py[line:274] - INFO: epoch 001:  27486 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=27450, lr=4.92879e-05, gnorm=0.979, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132798
2022-10-17 08:30:40 - progress_bar.py[line:274] - INFO: epoch 001:  27496 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=27460, lr=4.92868e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132809
2022-10-17 08:30:51 - progress_bar.py[line:274] - INFO: epoch 001:  27506 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=27470, lr=4.92858e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132820
2022-10-17 08:31:03 - progress_bar.py[line:274] - INFO: epoch 001:  27516 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=27480, lr=4.92848e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=132831
2022-10-17 08:31:14 - progress_bar.py[line:274] - INFO: epoch 001:  27526 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.7, ups=0.91, wpb=109.1, bsz=40, num_updates=27490, lr=4.92838e-05, gnorm=0.93, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132843
2022-10-17 08:31:25 - progress_bar.py[line:274] - INFO: epoch 001:  27536 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.3, ups=0.87, wpb=110.9, bsz=40, num_updates=27500, lr=4.92828e-05, gnorm=0.998, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132854
2022-10-17 08:31:36 - progress_bar.py[line:274] - INFO: epoch 001:  27546 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.4, ups=0.89, wpb=109.1, bsz=40, num_updates=27510, lr=4.92817e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132865
2022-10-17 08:31:47 - progress_bar.py[line:274] - INFO: epoch 001:  27556 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.5, ups=0.91, wpb=109.6, bsz=40, num_updates=27520, lr=4.92807e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=132876
2022-10-17 08:31:59 - progress_bar.py[line:274] - INFO: epoch 001:  27566 / 102288 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.5, ups=0.89, wpb=109.4, bsz=40, num_updates=27530, lr=4.92797e-05, gnorm=0.718, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=132888
2022-10-17 08:32:10 - progress_bar.py[line:274] - INFO: epoch 001:  27576 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.6, ups=0.93, wpb=109.5, bsz=40, num_updates=27540, lr=4.92787e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132898
2022-10-17 08:32:21 - progress_bar.py[line:274] - INFO: epoch 001:  27586 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.3, ups=0.89, wpb=109.9, bsz=40, num_updates=27550, lr=4.92777e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132910
2022-10-17 08:32:32 - progress_bar.py[line:274] - INFO: epoch 001:  27596 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.5, ups=0.89, wpb=109.3, bsz=40, num_updates=27560, lr=4.92767e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132921
2022-10-17 08:32:44 - progress_bar.py[line:274] - INFO: epoch 001:  27606 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.6, ups=0.88, wpb=108.5, bsz=40, num_updates=27570, lr=4.92756e-05, gnorm=0.957, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132933
2022-10-17 08:32:54 - progress_bar.py[line:274] - INFO: epoch 001:  27616 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=102.1, ups=0.91, wpb=111.6, bsz=40, num_updates=27580, lr=4.92746e-05, gnorm=0.931, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132943
2022-10-17 08:33:06 - progress_bar.py[line:274] - INFO: epoch 001:  27626 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.3, ups=0.89, wpb=109.2, bsz=40, num_updates=27590, lr=4.92736e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132955
2022-10-17 08:33:17 - progress_bar.py[line:274] - INFO: epoch 001:  27636 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.9, ups=0.93, wpb=109.5, bsz=40, num_updates=27600, lr=4.92726e-05, gnorm=0.941, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=132966
2022-10-17 08:33:28 - progress_bar.py[line:274] - INFO: epoch 001:  27646 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=27610, lr=4.92716e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=132977
2022-10-17 08:33:39 - progress_bar.py[line:274] - INFO: epoch 001:  27656 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=27620, lr=4.92705e-05, gnorm=0.991, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=132988
2022-10-17 08:33:51 - progress_bar.py[line:274] - INFO: epoch 001:  27666 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.8, ups=0.88, wpb=110.9, bsz=40, num_updates=27630, lr=4.92695e-05, gnorm=1.04, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=133000
2022-10-17 08:34:02 - progress_bar.py[line:274] - INFO: epoch 001:  27676 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.5, ups=0.89, wpb=109.7, bsz=40, num_updates=27640, lr=4.92685e-05, gnorm=1.005, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133011
2022-10-17 08:34:13 - progress_bar.py[line:274] - INFO: epoch 001:  27686 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.9, ups=0.88, wpb=109.8, bsz=40, num_updates=27650, lr=4.92675e-05, gnorm=0.788, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=133022
2022-10-17 08:34:25 - progress_bar.py[line:274] - INFO: epoch 001:  27696 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.8, ups=0.89, wpb=112, bsz=40, num_updates=27660, lr=4.92665e-05, gnorm=0.888, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=133033
2022-10-17 08:34:35 - progress_bar.py[line:274] - INFO: epoch 001:  27706 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=103.5, ups=0.93, wpb=111.5, bsz=40, num_updates=27670, lr=4.92655e-05, gnorm=0.943, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=133044
2022-10-17 08:34:47 - progress_bar.py[line:274] - INFO: epoch 001:  27716 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.9, wpb=109.5, bsz=40, num_updates=27680, lr=4.92644e-05, gnorm=0.923, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=133055
2022-10-17 08:34:58 - progress_bar.py[line:274] - INFO: epoch 001:  27726 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=27690, lr=4.92634e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=133067
2022-10-17 08:35:09 - progress_bar.py[line:274] - INFO: epoch 001:  27736 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=27700, lr=4.92624e-05, gnorm=0.916, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=133078
2022-10-17 08:35:20 - progress_bar.py[line:274] - INFO: epoch 001:  27746 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=27710, lr=4.92614e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133089
2022-10-17 08:35:32 - progress_bar.py[line:274] - INFO: epoch 001:  27756 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.3, ups=0.87, wpb=109.3, bsz=40, num_updates=27720, lr=4.92604e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=133101
2022-10-17 08:35:43 - progress_bar.py[line:274] - INFO: epoch 001:  27766 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.6, ups=0.88, wpb=108.7, bsz=40, num_updates=27730, lr=4.92593e-05, gnorm=1.047, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=133112
2022-10-17 08:35:55 - progress_bar.py[line:274] - INFO: epoch 001:  27776 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.6, ups=0.88, wpb=109.5, bsz=40, num_updates=27740, lr=4.92583e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=133124
2022-10-17 08:36:06 - progress_bar.py[line:274] - INFO: epoch 001:  27786 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.9, wpb=109.1, bsz=40, num_updates=27750, lr=4.92573e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=133135
2022-10-17 08:36:17 - progress_bar.py[line:274] - INFO: epoch 001:  27796 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.9, ups=0.92, wpb=109, bsz=40, num_updates=27760, lr=4.92563e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=133146
2022-10-17 08:36:28 - progress_bar.py[line:274] - INFO: epoch 001:  27806 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.4, ups=0.92, wpb=109.5, bsz=40, num_updates=27770, lr=4.92553e-05, gnorm=1.04, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=133157
2022-10-17 08:36:39 - progress_bar.py[line:274] - INFO: epoch 001:  27816 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.9, ups=0.88, wpb=109, bsz=40, num_updates=27780, lr=4.92543e-05, gnorm=0.886, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133168
2022-10-17 08:36:51 - progress_bar.py[line:274] - INFO: epoch 001:  27826 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.1, ups=0.88, wpb=112, bsz=40, num_updates=27790, lr=4.92532e-05, gnorm=1.024, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=133180
2022-10-17 08:37:02 - progress_bar.py[line:274] - INFO: epoch 001:  27836 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.9, ups=0.9, wpb=108.5, bsz=40, num_updates=27800, lr=4.92522e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133191
2022-10-17 08:37:13 - progress_bar.py[line:274] - INFO: epoch 001:  27846 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=27810, lr=4.92512e-05, gnorm=0.907, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=133202
2022-10-17 08:37:24 - progress_bar.py[line:274] - INFO: epoch 001:  27856 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=27820, lr=4.92502e-05, gnorm=0.927, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133213
2022-10-17 08:37:36 - progress_bar.py[line:274] - INFO: epoch 001:  27866 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98, ups=0.89, wpb=110.2, bsz=40, num_updates=27830, lr=4.92492e-05, gnorm=1.027, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133225
2022-10-17 08:37:47 - progress_bar.py[line:274] - INFO: epoch 001:  27876 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.2, ups=0.88, wpb=109.4, bsz=40, num_updates=27840, lr=4.92481e-05, gnorm=0.927, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133236
2022-10-17 08:37:58 - progress_bar.py[line:274] - INFO: epoch 001:  27886 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.1, ups=0.92, wpb=110.5, bsz=40, num_updates=27850, lr=4.92471e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=133247
2022-10-17 08:38:09 - progress_bar.py[line:274] - INFO: epoch 001:  27896 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=27860, lr=4.92461e-05, gnorm=0.88, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133258
2022-10-17 08:38:21 - progress_bar.py[line:274] - INFO: epoch 001:  27906 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.1, ups=0.88, wpb=111, bsz=40, num_updates=27870, lr=4.92451e-05, gnorm=0.932, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=133270
2022-10-17 08:38:32 - progress_bar.py[line:274] - INFO: epoch 001:  27916 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.5, ups=0.9, wpb=111.7, bsz=40, num_updates=27880, lr=4.92441e-05, gnorm=0.816, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=133281
2022-10-17 08:38:43 - progress_bar.py[line:274] - INFO: epoch 001:  27926 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=27890, lr=4.9243e-05, gnorm=0.933, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=133292
2022-10-17 08:38:54 - progress_bar.py[line:274] - INFO: epoch 001:  27936 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.9, wpb=110.7, bsz=40, num_updates=27900, lr=4.9242e-05, gnorm=0.945, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=133303
2022-10-17 08:39:05 - progress_bar.py[line:274] - INFO: epoch 001:  27946 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.3, ups=0.9, wpb=111.2, bsz=40, num_updates=27910, lr=4.9241e-05, gnorm=0.812, clip=0, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=133314
2022-10-17 08:39:17 - progress_bar.py[line:274] - INFO: epoch 001:  27956 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.4, ups=0.89, wpb=109.2, bsz=40, num_updates=27920, lr=4.924e-05, gnorm=1.166, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=133325
2022-10-17 08:39:28 - progress_bar.py[line:274] - INFO: epoch 001:  27966 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=27930, lr=4.9239e-05, gnorm=0.834, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=133337
2022-10-17 08:39:39 - progress_bar.py[line:274] - INFO: epoch 001:  27976 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.1, ups=0.88, wpb=108.9, bsz=40, num_updates=27940, lr=4.9238e-05, gnorm=1.056, clip=60, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=133348
2022-10-17 08:39:51 - progress_bar.py[line:274] - INFO: epoch 001:  27986 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=27950, lr=4.92369e-05, gnorm=1.097, clip=70, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=133360
2022-10-17 08:40:02 - progress_bar.py[line:274] - INFO: epoch 001:  27996 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.8, ups=0.91, wpb=111, bsz=40, num_updates=27960, lr=4.92359e-05, gnorm=0.885, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133371
2022-10-17 08:40:13 - progress_bar.py[line:274] - INFO: epoch 001:  28006 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.3, ups=0.88, wpb=111.5, bsz=40, num_updates=27970, lr=4.92349e-05, gnorm=0.796, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=133382
2022-10-17 08:40:24 - progress_bar.py[line:274] - INFO: epoch 001:  28016 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=27980, lr=4.92339e-05, gnorm=0.88, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=133393
2022-10-17 08:40:36 - progress_bar.py[line:274] - INFO: epoch 001:  28026 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=27990, lr=4.92329e-05, gnorm=0.977, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=133405
2022-10-17 08:40:47 - progress_bar.py[line:274] - INFO: epoch 001:  28036 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=28000, lr=4.92318e-05, gnorm=0.949, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=133416
2022-10-17 08:40:47 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 08:40:49 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 08:40:49 - train.py[line:551] - INFO: load:1.16 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 08:43:21 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 08:43:21 - train.py[line:551] - INFO: load:1.18 valid_run:151.98 task_valid:148.46 collect_output:2.42
2022-10-17 08:45:49 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 08:45:49 - train.py[line:551] - INFO: load:1.21 valid_run:300.42 task_valid:292.20 collect_output:5.95
2022-10-17 08:48:21 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 08:48:21 - train.py[line:551] - INFO: load:1.23 valid_run:452.46 task_valid:435.73 collect_output:13.30
2022-10-17 08:50:51 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 08:50:51 - train.py[line:551] - INFO: load:1.26 valid_run:601.75 task_valid:581.31 collect_output:15.92
2022-10-17 08:53:23 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 08:53:23 - train.py[line:551] - INFO: load:1.29 valid_run:754.49 task_valid:729.52 collect_output:19.36
2022-10-17 08:55:55 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 08:55:55 - train.py[line:551] - INFO: load:1.32 valid_run:906.18 task_valid:875.69 collect_output:23.70
2022-10-17 08:58:28 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 08:58:28 - train.py[line:551] - INFO: load:1.35 valid_run:1059.29 task_valid:1022.29 collect_output:29.07
2022-10-17 09:01:00 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 09:01:00 - train.py[line:551] - INFO: load:1.38 valid_run:1210.41 task_valid:1164.26 collect_output:37.12
2022-10-17 09:03:29 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 09:03:29 - train.py[line:551] - INFO: load:1.41 valid_run:1360.21 task_valid:1309.57 collect_output:40.50
2022-10-17 09:05:59 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 09:05:59 - train.py[line:551] - INFO: load:1.43 valid_run:1509.30 task_valid:1453.62 collect_output:44.33
2022-10-17 09:08:29 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 09:08:29 - train.py[line:551] - INFO: load:1.46 valid_run:1659.46 task_valid:1599.27 collect_output:47.72
2022-10-17 09:10:59 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 09:10:59 - train.py[line:551] - INFO: load:1.49 valid_run:1809.56 task_valid:1744.82 collect_output:51.19
2022-10-17 09:13:29 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 09:13:29 - train.py[line:551] - INFO: load:1.51 valid_run:1959.47 task_valid:1886.97 collect_output:57.90
2022-10-17 09:15:59 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 09:15:59 - train.py[line:551] - INFO: load:1.54 valid_run:2109.93 task_valid:2032.44 collect_output:61.85
2022-10-17 09:18:29 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 09:18:29 - train.py[line:551] - INFO: load:1.57 valid_run:2259.86 task_valid:2179.02 collect_output:64.17
2022-10-17 09:20:59 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 09:20:59 - train.py[line:551] - INFO: load:1.59 valid_run:2409.60 task_valid:2323.18 collect_output:68.76
2022-10-17 09:23:31 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 09:23:31 - train.py[line:551] - INFO: load:1.62 valid_run:2561.36 task_valid:2468.93 collect_output:73.76
2022-10-17 09:26:02 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 09:26:02 - train.py[line:551] - INFO: load:1.64 valid_run:2711.91 task_valid:2615.88 collect_output:76.34
2022-10-17 09:28:30 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 09:28:30 - train.py[line:551] - INFO: load:1.67 valid_run:2860.13 task_valid:2757.57 collect_output:81.84
2022-10-17 09:31:00 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 09:31:00 - train.py[line:551] - INFO: load:1.69 valid_run:3010.41 task_valid:2902.83 collect_output:85.84
2022-10-17 09:33:33 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 09:33:33 - train.py[line:551] - INFO: load:1.72 valid_run:3162.83 task_valid:3047.91 collect_output:92.15
2022-10-17 09:36:02 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 09:36:02 - train.py[line:551] - INFO: load:1.75 valid_run:3312.08 task_valid:3192.36 collect_output:95.92
2022-10-17 09:38:33 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 09:38:33 - train.py[line:551] - INFO: load:1.77 valid_run:3463.36 task_valid:3338.46 collect_output:100.12
2022-10-17 09:41:05 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 09:41:05 - train.py[line:551] - INFO: load:1.80 valid_run:3614.51 task_valid:3484.82 collect_output:103.91

====================================================================================================
SGG eval:     R @ 50: 0.4525;     R @ 100: 0.5096;     R @ 500: 0.5391;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2990;    mR @ 100: 0.3829;    mR @ 500: 0.4103;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5585) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5032) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8438) (playing:0.0000) (riding:0.6732) (says:0.0000) (sitting on:0.6658) (standing on:0.2350) (using:0.6000) (walking in:0.6667) (walking on:0.1892) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4525;     R @ 100: 0.5096;     R @ 500: 0.5391;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2990;    mR @ 100: 0.3829;    mR @ 500: 0.4103;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5585) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5032) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8438) (playing:0.0000) (riding:0.6732) (says:0.0000) (sitting on:0.6658) (standing on:0.2350) (using:0.6000) (walking in:0.6667) (walking on:0.1892) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2022-10-17 09:43:36 - train.py[line:487] - INFO: 0.5096285714285714
2022-10-17 09:43:36 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 09:43:36 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.357 | loss_v1 0 | loss_v2 0 | nll_loss 0.198 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.509629 | ppl 1.15 | vqa_score 0.4291 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 28000 | best_R@100 0.581461
2022-10-17 09:43:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 28000 updates
2022-10-17 09:43:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_28000.pt
2022-10-17 09:43:42 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_28000.pt
2022-10-17 09:43:44 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_28000.pt (epoch 1 @ 28000 updates, score 0.5096285714285714) (writing took 8.369854446034878 seconds)
2022-10-17 09:43:55 - progress_bar.py[line:274] - INFO: epoch 001:  28046 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=0.3, ups=0, wpb=110.3, bsz=40, num_updates=28010, lr=4.92308e-05, gnorm=1.048, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137204
2022-10-17 09:44:00 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 09:44:08 - progress_bar.py[line:274] - INFO: epoch 001:  28057 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=86.8, ups=0.8, wpb=109, bsz=40, num_updates=28020, lr=4.92298e-05, gnorm=0.919, clip=50, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=137217
2022-10-17 09:44:19 - progress_bar.py[line:274] - INFO: epoch 001:  28067 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.5, ups=0.88, wpb=108.6, bsz=40, num_updates=28030, lr=4.92288e-05, gnorm=1.09, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137228
2022-10-17 09:44:31 - progress_bar.py[line:274] - INFO: epoch 001:  28077 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.8, ups=0.88, wpb=110, bsz=40, num_updates=28040, lr=4.92278e-05, gnorm=1.072, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137240
2022-10-17 09:44:42 - progress_bar.py[line:274] - INFO: epoch 001:  28087 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=28050, lr=4.92268e-05, gnorm=1.126, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137251
2022-10-17 09:44:53 - progress_bar.py[line:274] - INFO: epoch 001:  28097 / 102288 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.9, ups=0.88, wpb=111.2, bsz=40, num_updates=28060, lr=4.92257e-05, gnorm=0.772, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137262
2022-10-17 09:45:05 - progress_bar.py[line:274] - INFO: epoch 001:  28107 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.9, ups=0.88, wpb=111.2, bsz=40, num_updates=28070, lr=4.92247e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137274
2022-10-17 09:45:16 - progress_bar.py[line:274] - INFO: epoch 001:  28117 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=28080, lr=4.92237e-05, gnorm=0.986, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=137285
2022-10-17 09:45:28 - progress_bar.py[line:274] - INFO: epoch 001:  28127 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.6, ups=0.88, wpb=111.5, bsz=40, num_updates=28090, lr=4.92227e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137296
2022-10-17 09:45:38 - progress_bar.py[line:274] - INFO: epoch 001:  28137 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.3, ups=0.92, wpb=109.5, bsz=40, num_updates=28100, lr=4.92217e-05, gnorm=1.038, clip=40, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=137307
2022-10-17 09:45:50 - progress_bar.py[line:274] - INFO: epoch 001:  28147 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=28110, lr=4.92206e-05, gnorm=1.009, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137319
2022-10-17 09:46:01 - progress_bar.py[line:274] - INFO: epoch 001:  28157 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=28120, lr=4.92196e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137330
2022-10-17 09:46:12 - progress_bar.py[line:274] - INFO: epoch 001:  28167 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.6, ups=0.89, wpb=108.1, bsz=40, num_updates=28130, lr=4.92186e-05, gnorm=0.917, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=137341
2022-10-17 09:46:24 - progress_bar.py[line:274] - INFO: epoch 001:  28177 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=28140, lr=4.92176e-05, gnorm=1.144, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=137352
2022-10-17 09:46:35 - progress_bar.py[line:274] - INFO: epoch 001:  28187 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.9, ups=0.88, wpb=110.7, bsz=40, num_updates=28150, lr=4.92166e-05, gnorm=1.191, clip=50, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=137364
2022-10-17 09:46:46 - progress_bar.py[line:274] - INFO: epoch 001:  28197 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97, ups=0.89, wpb=108.8, bsz=40, num_updates=28160, lr=4.92156e-05, gnorm=0.975, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137375
2022-10-17 09:46:57 - progress_bar.py[line:274] - INFO: epoch 001:  28207 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=28170, lr=4.92145e-05, gnorm=0.889, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=137386
2022-10-17 09:47:09 - progress_bar.py[line:274] - INFO: epoch 001:  28217 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.5, ups=0.89, wpb=111.6, bsz=40, num_updates=28180, lr=4.92135e-05, gnorm=0.898, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137398
2022-10-17 09:47:20 - progress_bar.py[line:274] - INFO: epoch 001:  28227 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=28190, lr=4.92125e-05, gnorm=0.932, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137409
2022-10-17 09:47:32 - progress_bar.py[line:274] - INFO: epoch 001:  28237 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.1, ups=0.88, wpb=109.4, bsz=40, num_updates=28200, lr=4.92115e-05, gnorm=1.075, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=137420
2022-10-17 09:47:43 - progress_bar.py[line:274] - INFO: epoch 001:  28247 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=28210, lr=4.92105e-05, gnorm=1.026, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137431
2022-10-17 09:47:54 - progress_bar.py[line:274] - INFO: epoch 001:  28257 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=28220, lr=4.92094e-05, gnorm=0.899, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137443
2022-10-17 09:48:05 - progress_bar.py[line:274] - INFO: epoch 001:  28267 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=28230, lr=4.92084e-05, gnorm=0.927, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137454
2022-10-17 09:48:16 - progress_bar.py[line:274] - INFO: epoch 001:  28277 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=28240, lr=4.92074e-05, gnorm=0.848, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137465
2022-10-17 09:48:27 - progress_bar.py[line:274] - INFO: epoch 001:  28287 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102, ups=0.92, wpb=110.8, bsz=40, num_updates=28250, lr=4.92064e-05, gnorm=1.764, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=137476
2022-10-17 09:48:38 - progress_bar.py[line:274] - INFO: epoch 001:  28297 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.4, ups=0.89, wpb=109.8, bsz=40, num_updates=28260, lr=4.92054e-05, gnorm=1.012, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137487
2022-10-17 09:48:53 - progress_bar.py[line:274] - INFO: epoch 001:  28307 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.2, ups=0.92, wpb=110.2, bsz=40, num_updates=28270, lr=4.92044e-05, gnorm=0.862, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=137498
2022-10-17 09:49:04 - progress_bar.py[line:274] - INFO: epoch 001:  28317 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.1, ups=0.89, wpb=110.8, bsz=40, num_updates=28280, lr=4.92033e-05, gnorm=0.908, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=137513
2022-10-17 09:49:15 - progress_bar.py[line:274] - INFO: epoch 001:  28327 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.8, ups=0.9, wpb=111, bsz=40, num_updates=28290, lr=4.92023e-05, gnorm=0.811, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137524
2022-10-17 09:49:26 - progress_bar.py[line:274] - INFO: epoch 001:  28337 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.7, ups=0.93, wpb=110.6, bsz=40, num_updates=28300, lr=4.92013e-05, gnorm=0.84, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=137535
2022-10-17 09:49:37 - progress_bar.py[line:274] - INFO: epoch 001:  28347 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102, ups=0.92, wpb=111.3, bsz=40, num_updates=28310, lr=4.92003e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137546
2022-10-17 09:49:48 - progress_bar.py[line:274] - INFO: epoch 001:  28357 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96, ups=0.87, wpb=110.2, bsz=40, num_updates=28320, lr=4.91993e-05, gnorm=1.037, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=137557
2022-10-17 09:50:00 - progress_bar.py[line:274] - INFO: epoch 001:  28367 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=28330, lr=4.91982e-05, gnorm=0.934, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137569
2022-10-17 09:50:11 - progress_bar.py[line:274] - INFO: epoch 001:  28377 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.9, ups=0.92, wpb=111.3, bsz=40, num_updates=28340, lr=4.91972e-05, gnorm=0.97, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137580
2022-10-17 09:50:22 - progress_bar.py[line:274] - INFO: epoch 001:  28387 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=28350, lr=4.91962e-05, gnorm=0.916, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137591
2022-10-17 09:50:33 - progress_bar.py[line:274] - INFO: epoch 001:  28397 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=28360, lr=4.91952e-05, gnorm=0.893, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137602
2022-10-17 09:50:44 - progress_bar.py[line:274] - INFO: epoch 001:  28407 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.1, ups=0.92, wpb=110.3, bsz=40, num_updates=28370, lr=4.91942e-05, gnorm=1.015, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137613
2022-10-17 09:50:55 - progress_bar.py[line:274] - INFO: epoch 001:  28417 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=105, ups=0.95, wpb=110.5, bsz=40, num_updates=28380, lr=4.91931e-05, gnorm=0.947, clip=40, loss_scale=512, train_wall=10, gb_free=10.5, ema_decay=0.9999, wall=137623
2022-10-17 09:51:06 - progress_bar.py[line:274] - INFO: epoch 001:  28427 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=28390, lr=4.91921e-05, gnorm=0.995, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137635
2022-10-17 09:51:17 - progress_bar.py[line:274] - INFO: epoch 001:  28437 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=28400, lr=4.91911e-05, gnorm=1.063, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137646
2022-10-17 09:51:28 - progress_bar.py[line:274] - INFO: epoch 001:  28447 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.7, ups=0.9, wpb=109.1, bsz=40, num_updates=28410, lr=4.91901e-05, gnorm=0.95, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137657
2022-10-17 09:51:40 - progress_bar.py[line:274] - INFO: epoch 001:  28457 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=28420, lr=4.91891e-05, gnorm=1.051, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137668
2022-10-17 09:51:51 - progress_bar.py[line:274] - INFO: epoch 001:  28467 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=28430, lr=4.91881e-05, gnorm=0.858, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137680
2022-10-17 09:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  28477 / 102288 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=28440, lr=4.9187e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137691
2022-10-17 09:52:13 - progress_bar.py[line:274] - INFO: epoch 001:  28487 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=28450, lr=4.9186e-05, gnorm=0.998, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=137702
2022-10-17 09:52:24 - progress_bar.py[line:274] - INFO: epoch 001:  28497 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.4, ups=0.9, wpb=111, bsz=40, num_updates=28460, lr=4.9185e-05, gnorm=1.02, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137713
2022-10-17 09:52:35 - progress_bar.py[line:274] - INFO: epoch 001:  28507 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.8, ups=0.93, wpb=109.6, bsz=40, num_updates=28470, lr=4.9184e-05, gnorm=0.843, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137724
2022-10-17 09:52:46 - progress_bar.py[line:274] - INFO: epoch 001:  28517 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=28480, lr=4.9183e-05, gnorm=0.844, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137735
2022-10-17 09:52:57 - progress_bar.py[line:274] - INFO: epoch 001:  28527 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.1, ups=0.92, wpb=110.3, bsz=40, num_updates=28490, lr=4.91819e-05, gnorm=0.961, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137746
2022-10-17 09:53:08 - progress_bar.py[line:274] - INFO: epoch 001:  28537 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.4, ups=0.87, wpb=110.7, bsz=40, num_updates=28500, lr=4.91809e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137757
2022-10-17 09:53:19 - progress_bar.py[line:274] - INFO: epoch 001:  28547 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.6, ups=0.92, wpb=110.9, bsz=40, num_updates=28510, lr=4.91799e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=137768
2022-10-17 09:53:31 - progress_bar.py[line:274] - INFO: epoch 001:  28557 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=28520, lr=4.91789e-05, gnorm=1.156, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=137780
2022-10-17 09:53:42 - progress_bar.py[line:274] - INFO: epoch 001:  28567 / 102288 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=28530, lr=4.91779e-05, gnorm=0.867, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137791
2022-10-17 09:53:53 - progress_bar.py[line:274] - INFO: epoch 001:  28577 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.89, wpb=111.6, bsz=40, num_updates=28540, lr=4.91769e-05, gnorm=0.882, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137802
2022-10-17 09:54:05 - progress_bar.py[line:274] - INFO: epoch 001:  28587 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.3, ups=0.87, wpb=111.5, bsz=40, num_updates=28550, lr=4.91758e-05, gnorm=0.917, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=137813
2022-10-17 09:54:16 - progress_bar.py[line:274] - INFO: epoch 001:  28597 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=28560, lr=4.91748e-05, gnorm=1.009, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137825
2022-10-17 09:54:26 - progress_bar.py[line:274] - INFO: epoch 001:  28607 / 102288 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=104, ups=0.94, wpb=110.6, bsz=40, num_updates=28570, lr=4.91738e-05, gnorm=1.021, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137835
2022-10-17 09:54:38 - progress_bar.py[line:274] - INFO: epoch 001:  28617 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=28580, lr=4.91728e-05, gnorm=1.013, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=137847
2022-10-17 09:54:49 - progress_bar.py[line:274] - INFO: epoch 001:  28627 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.4, ups=0.92, wpb=109.7, bsz=40, num_updates=28590, lr=4.91718e-05, gnorm=1.058, clip=60, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=137858
2022-10-17 09:55:00 - progress_bar.py[line:274] - INFO: epoch 001:  28637 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.1, ups=0.87, wpb=110.6, bsz=40, num_updates=28600, lr=4.91707e-05, gnorm=1.318, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137869
2022-10-17 09:55:12 - progress_bar.py[line:274] - INFO: epoch 001:  28647 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.1, ups=0.88, wpb=110.8, bsz=40, num_updates=28610, lr=4.91697e-05, gnorm=0.976, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=137881
2022-10-17 09:55:23 - progress_bar.py[line:274] - INFO: epoch 001:  28657 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=28620, lr=4.91687e-05, gnorm=0.994, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137892
2022-10-17 09:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  28667 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.7, ups=0.87, wpb=109.4, bsz=40, num_updates=28630, lr=4.91677e-05, gnorm=0.95, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137903
2022-10-17 09:55:45 - progress_bar.py[line:274] - INFO: epoch 001:  28677 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=28640, lr=4.91667e-05, gnorm=0.907, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137914
2022-10-17 09:55:57 - progress_bar.py[line:274] - INFO: epoch 001:  28687 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=28650, lr=4.91657e-05, gnorm=0.861, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137926
2022-10-17 09:56:08 - progress_bar.py[line:274] - INFO: epoch 001:  28697 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.4, ups=0.88, wpb=111, bsz=40, num_updates=28660, lr=4.91646e-05, gnorm=1.011, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137937
2022-10-17 09:56:20 - progress_bar.py[line:274] - INFO: epoch 001:  28707 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.8, ups=0.88, wpb=110.5, bsz=40, num_updates=28670, lr=4.91636e-05, gnorm=0.852, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=137949
2022-10-17 09:56:31 - progress_bar.py[line:274] - INFO: epoch 001:  28717 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.3, ups=0.9, wpb=109.7, bsz=40, num_updates=28680, lr=4.91626e-05, gnorm=0.899, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137960
2022-10-17 09:56:42 - progress_bar.py[line:274] - INFO: epoch 001:  28727 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=28690, lr=4.91616e-05, gnorm=1.01, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=137971
2022-10-17 09:56:53 - progress_bar.py[line:274] - INFO: epoch 001:  28737 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=28700, lr=4.91606e-05, gnorm=0.949, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=137982
2022-10-17 09:57:05 - progress_bar.py[line:274] - INFO: epoch 001:  28747 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.6, ups=0.88, wpb=111.5, bsz=40, num_updates=28710, lr=4.91595e-05, gnorm=0.893, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=137994
2022-10-17 09:57:16 - progress_bar.py[line:274] - INFO: epoch 001:  28757 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=28720, lr=4.91585e-05, gnorm=1.007, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=138005
2022-10-17 09:57:27 - progress_bar.py[line:274] - INFO: epoch 001:  28767 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98, ups=0.9, wpb=108.6, bsz=40, num_updates=28730, lr=4.91575e-05, gnorm=0.993, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=138016
2022-10-17 09:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  28777 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95, ups=0.88, wpb=108.1, bsz=40, num_updates=28740, lr=4.91565e-05, gnorm=0.858, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=138027
2022-10-17 09:57:50 - progress_bar.py[line:274] - INFO: epoch 001:  28787 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=28750, lr=4.91555e-05, gnorm=0.894, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=138038
2022-10-17 09:58:01 - progress_bar.py[line:274] - INFO: epoch 001:  28797 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.4, ups=0.89, wpb=110, bsz=40, num_updates=28760, lr=4.91545e-05, gnorm=0.865, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=138050
2022-10-17 09:58:12 - progress_bar.py[line:274] - INFO: epoch 001:  28807 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.9, ups=0.88, wpb=110.4, bsz=40, num_updates=28770, lr=4.91534e-05, gnorm=1.194, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=138061
2022-10-17 09:58:24 - progress_bar.py[line:274] - INFO: epoch 001:  28817 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.6, ups=0.88, wpb=108.5, bsz=40, num_updates=28780, lr=4.91524e-05, gnorm=0.966, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=138073
2022-10-17 09:58:35 - progress_bar.py[line:274] - INFO: epoch 001:  28827 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.6, ups=0.88, wpb=111, bsz=40, num_updates=28790, lr=4.91514e-05, gnorm=0.862, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=138084
2022-10-17 09:58:47 - progress_bar.py[line:274] - INFO: epoch 001:  28837 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.5, ups=0.87, wpb=109.4, bsz=40, num_updates=28800, lr=4.91504e-05, gnorm=0.988, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=138096
2022-10-17 09:58:57 - progress_bar.py[line:274] - INFO: epoch 001:  28847 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.2, ups=0.93, wpb=110.3, bsz=40, num_updates=28810, lr=4.91494e-05, gnorm=0.872, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=138106
2022-10-17 09:59:09 - progress_bar.py[line:274] - INFO: epoch 001:  28857 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.8, ups=0.9, wpb=111.4, bsz=40, num_updates=28820, lr=4.91483e-05, gnorm=1.031, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=138117
2022-10-17 09:59:20 - progress_bar.py[line:274] - INFO: epoch 001:  28867 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=28830, lr=4.91473e-05, gnorm=0.89, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=138129
2022-10-17 09:59:31 - progress_bar.py[line:274] - INFO: epoch 001:  28877 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.8, ups=0.93, wpb=110.8, bsz=40, num_updates=28840, lr=4.91463e-05, gnorm=0.893, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=138140
2022-10-17 09:59:42 - progress_bar.py[line:274] - INFO: epoch 001:  28887 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=28850, lr=4.91453e-05, gnorm=0.926, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=138151
2022-10-17 09:59:54 - progress_bar.py[line:274] - INFO: epoch 001:  28897 / 102288 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96, ups=0.87, wpb=110.7, bsz=40, num_updates=28860, lr=4.91443e-05, gnorm=0.945, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=138163
2022-10-17 10:00:05 - progress_bar.py[line:274] - INFO: epoch 001:  28907 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96, ups=0.88, wpb=109.3, bsz=40, num_updates=28870, lr=4.91432e-05, gnorm=0.871, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=138174
2022-10-17 10:00:17 - progress_bar.py[line:274] - INFO: epoch 001:  28917 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=28880, lr=4.91422e-05, gnorm=0.836, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=138185
2022-10-17 10:00:27 - progress_bar.py[line:274] - INFO: epoch 001:  28927 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.6, ups=0.92, wpb=111, bsz=40, num_updates=28890, lr=4.91412e-05, gnorm=0.916, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=138196
2022-10-17 10:00:38 - progress_bar.py[line:274] - INFO: epoch 001:  28937 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=103.6, ups=0.94, wpb=110.5, bsz=40, num_updates=28900, lr=4.91402e-05, gnorm=0.828, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=138207
2022-10-17 10:00:49 - progress_bar.py[line:274] - INFO: epoch 001:  28947 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.4, ups=0.93, wpb=109.5, bsz=40, num_updates=28910, lr=4.91392e-05, gnorm=0.977, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=138218
2022-10-17 10:01:00 - progress_bar.py[line:274] - INFO: epoch 001:  28957 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.4, ups=0.91, wpb=110.1, bsz=40, num_updates=28920, lr=4.91382e-05, gnorm=0.88, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=138229
2022-10-17 10:01:11 - progress_bar.py[line:274] - INFO: epoch 001:  28967 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=28930, lr=4.91371e-05, gnorm=0.871, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=138240
2022-10-17 10:01:22 - progress_bar.py[line:274] - INFO: epoch 001:  28977 / 102288 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=113.8, nsentences=40, sample_size=113.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=105, ups=0.92, wpb=113.8, bsz=40, num_updates=28940, lr=4.91361e-05, gnorm=0.896, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=138251
2022-10-17 10:01:33 - progress_bar.py[line:274] - INFO: epoch 001:  28987 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.8, ups=0.9, wpb=110.8, bsz=40, num_updates=28950, lr=4.91351e-05, gnorm=0.823, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=138262
2022-10-17 10:01:45 - progress_bar.py[line:274] - INFO: epoch 001:  28997 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.7, ups=0.88, wpb=108.8, bsz=40, num_updates=28960, lr=4.91341e-05, gnorm=0.881, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=138274
2022-10-17 10:01:56 - progress_bar.py[line:274] - INFO: epoch 001:  29007 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=28970, lr=4.91331e-05, gnorm=0.81, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=138285
2022-10-17 10:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  29017 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.5, ups=0.89, wpb=111, bsz=40, num_updates=28980, lr=4.9132e-05, gnorm=0.858, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=138296
2022-10-17 10:02:18 - progress_bar.py[line:274] - INFO: epoch 001:  29027 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.1, ups=0.89, wpb=109.1, bsz=40, num_updates=28990, lr=4.9131e-05, gnorm=0.979, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=138307
2022-10-17 10:02:29 - progress_bar.py[line:274] - INFO: epoch 001:  29037 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.6, ups=0.91, wpb=109.6, bsz=40, num_updates=29000, lr=4.913e-05, gnorm=1.248, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=138318
2022-10-17 10:02:29 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 10:02:31 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 10:02:31 - train.py[line:551] - INFO: load:1.28 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 10:05:03 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 10:05:03 - train.py[line:551] - INFO: load:1.31 valid_run:151.77 task_valid:148.60 collect_output:2.04
2022-10-17 10:07:31 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 10:07:31 - train.py[line:551] - INFO: load:1.33 valid_run:300.35 task_valid:292.44 collect_output:5.68
2022-10-17 10:10:04 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 10:10:04 - train.py[line:551] - INFO: load:1.36 valid_run:452.59 task_valid:436.04 collect_output:13.25
2022-10-17 10:12:33 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 10:12:33 - train.py[line:551] - INFO: load:1.38 valid_run:602.13 task_valid:581.69 collect_output:16.01
2022-10-17 10:15:06 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 10:15:06 - train.py[line:551] - INFO: load:1.41 valid_run:755.10 task_valid:729.78 collect_output:19.74
2022-10-17 10:17:38 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 10:17:38 - train.py[line:551] - INFO: load:1.43 valid_run:906.99 task_valid:875.72 collect_output:24.52
2022-10-17 10:20:12 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 10:20:12 - train.py[line:551] - INFO: load:1.46 valid_run:1060.26 task_valid:1022.66 collect_output:29.73
2022-10-17 10:22:43 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 10:22:43 - train.py[line:551] - INFO: load:1.49 valid_run:1211.28 task_valid:1164.40 collect_output:37.83
2022-10-17 10:25:13 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 10:25:13 - train.py[line:551] - INFO: load:1.51 valid_run:1361.24 task_valid:1309.83 collect_output:41.23
2022-10-17 10:27:41 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 10:27:41 - train.py[line:551] - INFO: load:1.54 valid_run:1509.67 task_valid:1453.12 collect_output:45.37
2022-10-17 10:30:11 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 10:30:11 - train.py[line:551] - INFO: load:1.57 valid_run:1659.62 task_valid:1598.27 collect_output:49.16
2022-10-17 10:32:41 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 10:32:41 - train.py[line:551] - INFO: load:1.59 valid_run:1809.31 task_valid:1743.27 collect_output:52.81
2022-10-17 10:35:11 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 10:35:11 - train.py[line:551] - INFO: load:1.62 valid_run:1959.03 task_valid:1885.08 collect_output:59.71
2022-10-17 10:37:41 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 10:37:41 - train.py[line:551] - INFO: load:1.64 valid_run:2109.40 task_valid:2030.60 collect_output:63.52
2022-10-17 10:40:11 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 10:40:11 - train.py[line:551] - INFO: load:1.67 valid_run:2259.35 task_valid:2177.24 collect_output:65.83
2022-10-17 10:42:41 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 10:42:41 - train.py[line:551] - INFO: load:1.69 valid_run:2409.36 task_valid:2321.41 collect_output:70.66
2022-10-17 10:45:13 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 10:45:13 - train.py[line:551] - INFO: load:1.72 valid_run:2560.92 task_valid:2466.84 collect_output:75.79
2022-10-17 10:47:44 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 10:47:44 - train.py[line:551] - INFO: load:1.74 valid_run:2711.55 task_valid:2613.97 collect_output:78.26
2022-10-17 10:50:12 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 10:50:12 - train.py[line:551] - INFO: load:1.77 valid_run:2859.87 task_valid:2755.69 collect_output:83.85
2022-10-17 10:52:43 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 10:52:43 - train.py[line:551] - INFO: load:1.79 valid_run:3010.44 task_valid:2900.95 collect_output:88.16
2022-10-17 10:55:15 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 10:55:15 - train.py[line:551] - INFO: load:1.82 valid_run:3162.47 task_valid:3045.50 collect_output:94.63
2022-10-17 10:57:44 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 10:57:44 - train.py[line:551] - INFO: load:1.84 valid_run:3311.72 task_valid:3189.98 collect_output:98.40
2022-10-17 11:00:15 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 11:00:15 - train.py[line:551] - INFO: load:1.87 valid_run:3463.06 task_valid:3336.34 collect_output:102.36
2022-10-17 11:02:47 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 11:02:47 - train.py[line:551] - INFO: load:1.89 valid_run:3614.89 task_valid:3483.03 collect_output:106.49

====================================================================================================
SGG eval:     R @ 50: 0.4548;     R @ 100: 0.5064;     R @ 500: 0.5361;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2809;    mR @ 100: 0.3650;    mR @ 500: 0.3947;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5537) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4903) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8229) (playing:0.0000) (riding:0.6993) (says:0.0000) (sitting on:0.6352) (standing on:0.2550) (using:0.6000) (walking in:0.3333) (walking on:0.1892) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2022-10-17 11:05:18 - train.py[line:487] - INFO: 0.5063619047619048

====================================================================================================
SGG eval:     R @ 50: 0.4548;     R @ 100: 0.5064;     R @ 500: 0.5361;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2809;    mR @ 100: 0.3650;    mR @ 500: 0.3947;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5537) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4903) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8229) (playing:0.0000) (riding:0.6993) (says:0.0000) (sitting on:0.6352) (standing on:0.2550) (using:0.6000) (walking in:0.3333) (walking on:0.1892) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2022-10-17 11:05:18 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 11:05:19 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.376 | loss_v1 0 | loss_v2 0 | nll_loss 0.22 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.506362 | ppl 1.16 | vqa_score 0.4245 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 29000 | best_R@100 0.581461
2022-10-17 11:05:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 29000 updates
2022-10-17 11:05:19 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_29000.pt
2022-10-17 11:05:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_29000.pt
2022-10-17 11:05:28 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_29000.pt (epoch 1 @ 29000 updates, score 0.5063619047619048) (writing took 9.084435493219644 seconds)
2022-10-17 11:05:39 - progress_bar.py[line:274] - INFO: epoch 001:  29047 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=0.3, ups=0, wpb=110, bsz=40, num_updates=29010, lr=4.9129e-05, gnorm=0.941, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=142108
2022-10-17 11:05:50 - progress_bar.py[line:274] - INFO: epoch 001:  29057 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.5, ups=0.92, wpb=110.9, bsz=40, num_updates=29020, lr=4.9128e-05, gnorm=1.102, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142119
2022-10-17 11:06:01 - progress_bar.py[line:274] - INFO: epoch 001:  29067 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=29030, lr=4.9127e-05, gnorm=0.862, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142130
2022-10-17 11:06:12 - progress_bar.py[line:274] - INFO: epoch 001:  29077 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=29040, lr=4.91259e-05, gnorm=0.897, clip=10, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=142141
2022-10-17 11:06:23 - progress_bar.py[line:274] - INFO: epoch 001:  29087 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=29050, lr=4.91249e-05, gnorm=0.839, clip=30, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142152
2022-10-17 11:06:35 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-17 11:06:36 - progress_bar.py[line:274] - INFO: epoch 001:  29098 / 102288 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.3, ups=0.81, wpb=110.7, bsz=40, num_updates=29060, lr=4.91239e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=142165
2022-10-17 11:06:47 - progress_bar.py[line:274] - INFO: epoch 001:  29108 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=29070, lr=4.91229e-05, gnorm=0.985, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142176
2022-10-17 11:06:58 - progress_bar.py[line:274] - INFO: epoch 001:  29118 / 102288 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=106.2, ups=0.96, wpb=111.2, bsz=40, num_updates=29080, lr=4.91219e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=142186
2022-10-17 11:07:09 - progress_bar.py[line:274] - INFO: epoch 001:  29128 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.1, ups=0.87, wpb=109.9, bsz=40, num_updates=29090, lr=4.91208e-05, gnorm=1.073, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142198
2022-10-17 11:07:20 - progress_bar.py[line:274] - INFO: epoch 001:  29138 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=29100, lr=4.91198e-05, gnorm=1.024, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142209
2022-10-17 11:07:31 - progress_bar.py[line:274] - INFO: epoch 001:  29148 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100, ups=0.91, wpb=110.4, bsz=40, num_updates=29110, lr=4.91188e-05, gnorm=0.835, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142220
2022-10-17 11:07:42 - progress_bar.py[line:274] - INFO: epoch 001:  29158 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.2, ups=0.92, wpb=110.2, bsz=40, num_updates=29120, lr=4.91178e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142231
2022-10-17 11:07:54 - progress_bar.py[line:274] - INFO: epoch 001:  29168 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=29130, lr=4.91168e-05, gnorm=0.891, clip=20, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=142242
2022-10-17 11:08:04 - progress_bar.py[line:274] - INFO: epoch 001:  29178 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.4, ups=0.93, wpb=110.3, bsz=40, num_updates=29140, lr=4.91158e-05, gnorm=0.926, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142253
2022-10-17 11:08:15 - progress_bar.py[line:274] - INFO: epoch 001:  29188 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.2, ups=0.93, wpb=109.1, bsz=40, num_updates=29150, lr=4.91147e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=142264
2022-10-17 11:08:26 - progress_bar.py[line:274] - INFO: epoch 001:  29198 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=29160, lr=4.91137e-05, gnorm=0.827, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142275
2022-10-17 11:08:37 - progress_bar.py[line:274] - INFO: epoch 001:  29208 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.9, ups=0.92, wpb=110, bsz=40, num_updates=29170, lr=4.91127e-05, gnorm=0.762, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142286
2022-10-17 11:08:49 - progress_bar.py[line:274] - INFO: epoch 001:  29218 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=29180, lr=4.91117e-05, gnorm=1.347, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142298
2022-10-17 11:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  29228 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.6, ups=0.87, wpb=109.6, bsz=40, num_updates=29190, lr=4.91107e-05, gnorm=0.834, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142309
2022-10-17 11:09:12 - progress_bar.py[line:274] - INFO: epoch 001:  29238 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.88, wpb=110.8, bsz=40, num_updates=29200, lr=4.91096e-05, gnorm=0.946, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142321
2022-10-17 11:09:23 - progress_bar.py[line:274] - INFO: epoch 001:  29248 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=29210, lr=4.91086e-05, gnorm=0.957, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=142332
2022-10-17 11:09:34 - progress_bar.py[line:274] - INFO: epoch 001:  29258 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=29220, lr=4.91076e-05, gnorm=1.066, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=142343
2022-10-17 11:09:45 - progress_bar.py[line:274] - INFO: epoch 001:  29268 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.5, ups=0.89, wpb=108.8, bsz=40, num_updates=29230, lr=4.91066e-05, gnorm=0.94, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=142354
2022-10-17 11:09:56 - progress_bar.py[line:274] - INFO: epoch 001:  29278 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=29240, lr=4.91056e-05, gnorm=0.982, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142365
2022-10-17 11:10:08 - progress_bar.py[line:274] - INFO: epoch 001:  29288 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.1, ups=0.88, wpb=111.7, bsz=40, num_updates=29250, lr=4.91046e-05, gnorm=0.93, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142377
2022-10-17 11:10:19 - progress_bar.py[line:274] - INFO: epoch 001:  29298 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.5, ups=0.9, wpb=111.1, bsz=40, num_updates=29260, lr=4.91035e-05, gnorm=1.06, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142388
2022-10-17 11:10:30 - progress_bar.py[line:274] - INFO: epoch 001:  29308 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98, ups=0.89, wpb=110.4, bsz=40, num_updates=29270, lr=4.91025e-05, gnorm=0.865, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=142399
2022-10-17 11:10:41 - progress_bar.py[line:274] - INFO: epoch 001:  29318 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.1, ups=0.91, wpb=109.2, bsz=40, num_updates=29280, lr=4.91015e-05, gnorm=1.035, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142410
2022-10-17 11:10:52 - progress_bar.py[line:274] - INFO: epoch 001:  29328 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=29290, lr=4.91005e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142421
2022-10-17 11:11:04 - progress_bar.py[line:274] - INFO: epoch 001:  29338 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.1, ups=0.88, wpb=111.6, bsz=40, num_updates=29300, lr=4.90995e-05, gnorm=0.838, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142433
2022-10-17 11:11:15 - progress_bar.py[line:274] - INFO: epoch 001:  29348 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=29310, lr=4.90984e-05, gnorm=1.038, clip=50, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=142444
2022-10-17 11:11:26 - progress_bar.py[line:274] - INFO: epoch 001:  29358 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=102.8, ups=0.94, wpb=109.4, bsz=40, num_updates=29320, lr=4.90974e-05, gnorm=0.951, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142455
2022-10-17 11:11:37 - progress_bar.py[line:274] - INFO: epoch 001:  29368 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.4, ups=0.91, wpb=112, bsz=40, num_updates=29330, lr=4.90964e-05, gnorm=0.8, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142466
2022-10-17 11:11:48 - progress_bar.py[line:274] - INFO: epoch 001:  29378 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=29340, lr=4.90954e-05, gnorm=0.91, clip=30, loss_scale=1024, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=142477
2022-10-17 11:11:59 - progress_bar.py[line:274] - INFO: epoch 001:  29388 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.8, ups=0.89, wpb=108.6, bsz=40, num_updates=29350, lr=4.90944e-05, gnorm=0.902, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142488
2022-10-17 11:12:10 - progress_bar.py[line:274] - INFO: epoch 001:  29398 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.3, ups=0.91, wpb=109.6, bsz=40, num_updates=29360, lr=4.90933e-05, gnorm=0.918, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142499
2022-10-17 11:12:22 - progress_bar.py[line:274] - INFO: epoch 001:  29408 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.6, ups=0.86, wpb=110.6, bsz=40, num_updates=29370, lr=4.90923e-05, gnorm=0.825, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=142511
2022-10-17 11:12:33 - progress_bar.py[line:274] - INFO: epoch 001:  29418 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=29380, lr=4.90913e-05, gnorm=0.907, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142522
2022-10-17 11:12:44 - progress_bar.py[line:274] - INFO: epoch 001:  29428 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=29390, lr=4.90903e-05, gnorm=0.866, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=142533
2022-10-17 11:12:55 - progress_bar.py[line:274] - INFO: epoch 001:  29438 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98, ups=0.89, wpb=110.5, bsz=40, num_updates=29400, lr=4.90893e-05, gnorm=0.989, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142544
2022-10-17 11:13:07 - progress_bar.py[line:274] - INFO: epoch 001:  29448 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=29410, lr=4.90883e-05, gnorm=0.872, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142555
2022-10-17 11:13:18 - progress_bar.py[line:274] - INFO: epoch 001:  29458 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=29420, lr=4.90872e-05, gnorm=0.98, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142567
2022-10-17 11:13:29 - progress_bar.py[line:274] - INFO: epoch 001:  29468 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.7, ups=0.89, wpb=110, bsz=40, num_updates=29430, lr=4.90862e-05, gnorm=0.997, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=142578
2022-10-17 11:13:40 - progress_bar.py[line:274] - INFO: epoch 001:  29478 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.2, ups=0.9, wpb=109.7, bsz=40, num_updates=29440, lr=4.90852e-05, gnorm=0.766, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142589
2022-10-17 11:13:52 - progress_bar.py[line:274] - INFO: epoch 001:  29488 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97, ups=0.87, wpb=111.4, bsz=40, num_updates=29450, lr=4.90842e-05, gnorm=0.841, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142601
2022-10-17 11:14:03 - progress_bar.py[line:274] - INFO: epoch 001:  29498 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.5, ups=0.91, wpb=111, bsz=40, num_updates=29460, lr=4.90832e-05, gnorm=1.012, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142612
2022-10-17 11:14:14 - progress_bar.py[line:274] - INFO: epoch 001:  29508 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.2, ups=0.88, wpb=109.3, bsz=40, num_updates=29470, lr=4.90821e-05, gnorm=0.865, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142623
2022-10-17 11:14:26 - progress_bar.py[line:274] - INFO: epoch 001:  29518 / 102288 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.4, ups=0.87, wpb=111.3, bsz=40, num_updates=29480, lr=4.90811e-05, gnorm=0.86, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142635
2022-10-17 11:14:37 - progress_bar.py[line:274] - INFO: epoch 001:  29528 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=29490, lr=4.90801e-05, gnorm=0.854, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=142646
2022-10-17 11:14:48 - progress_bar.py[line:274] - INFO: epoch 001:  29538 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=29500, lr=4.90791e-05, gnorm=1.039, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142657
2022-10-17 11:14:59 - progress_bar.py[line:274] - INFO: epoch 001:  29548 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=29510, lr=4.90781e-05, gnorm=1.018, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142668
2022-10-17 11:15:10 - progress_bar.py[line:274] - INFO: epoch 001:  29558 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.2, ups=0.9, wpb=110.2, bsz=40, num_updates=29520, lr=4.90771e-05, gnorm=1.035, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142679
2022-10-17 11:15:21 - progress_bar.py[line:274] - INFO: epoch 001:  29568 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=102.3, ups=0.93, wpb=110, bsz=40, num_updates=29530, lr=4.9076e-05, gnorm=1.069, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142690
2022-10-17 11:15:32 - progress_bar.py[line:274] - INFO: epoch 001:  29578 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.7, ups=0.89, wpb=109.9, bsz=40, num_updates=29540, lr=4.9075e-05, gnorm=0.813, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142701
2022-10-17 11:15:43 - progress_bar.py[line:274] - INFO: epoch 001:  29588 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.91, wpb=109.5, bsz=40, num_updates=29550, lr=4.9074e-05, gnorm=0.981, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142712
2022-10-17 11:15:55 - progress_bar.py[line:274] - INFO: epoch 001:  29598 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.6, ups=0.88, wpb=110, bsz=40, num_updates=29560, lr=4.9073e-05, gnorm=0.943, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142724
2022-10-17 11:16:06 - progress_bar.py[line:274] - INFO: epoch 001:  29608 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=29570, lr=4.9072e-05, gnorm=0.837, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142735
2022-10-17 11:16:17 - progress_bar.py[line:274] - INFO: epoch 001:  29618 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.9, ups=0.9, wpb=110, bsz=40, num_updates=29580, lr=4.90709e-05, gnorm=0.76, clip=10, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142746
2022-10-17 11:16:25 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-17 11:16:29 - progress_bar.py[line:274] - INFO: epoch 001:  29629 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=93.4, ups=0.85, wpb=110.5, bsz=40, num_updates=29590, lr=4.90699e-05, gnorm=0.973, clip=40, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=142758
2022-10-17 11:16:40 - progress_bar.py[line:274] - INFO: epoch 001:  29639 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=29600, lr=4.90689e-05, gnorm=1.071, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142769
2022-10-17 11:16:52 - progress_bar.py[line:274] - INFO: epoch 001:  29649 / 102288 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=29610, lr=4.90679e-05, gnorm=0.815, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=142780
2022-10-17 11:17:02 - progress_bar.py[line:274] - INFO: epoch 001:  29659 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.5, ups=0.92, wpb=110.9, bsz=40, num_updates=29620, lr=4.90669e-05, gnorm=0.911, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142791
2022-10-17 11:17:14 - progress_bar.py[line:274] - INFO: epoch 001:  29669 / 102288 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.2, ups=0.9, wpb=112.3, bsz=40, num_updates=29630, lr=4.90659e-05, gnorm=0.789, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=142803
2022-10-17 11:17:24 - progress_bar.py[line:274] - INFO: epoch 001:  29679 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.6, ups=0.93, wpb=109.6, bsz=40, num_updates=29640, lr=4.90648e-05, gnorm=0.954, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=142813
2022-10-17 11:17:36 - progress_bar.py[line:274] - INFO: epoch 001:  29689 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=29650, lr=4.90638e-05, gnorm=0.911, clip=20, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=142825
2022-10-17 11:17:47 - progress_bar.py[line:274] - INFO: epoch 001:  29699 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.1, ups=0.92, wpb=110.3, bsz=40, num_updates=29660, lr=4.90628e-05, gnorm=0.834, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142836
2022-10-17 11:17:58 - progress_bar.py[line:274] - INFO: epoch 001:  29709 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.7, ups=0.87, wpb=110.5, bsz=40, num_updates=29670, lr=4.90618e-05, gnorm=0.821, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142847
2022-10-17 11:18:09 - progress_bar.py[line:274] - INFO: epoch 001:  29719 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.8, ups=0.9, wpb=109.4, bsz=40, num_updates=29680, lr=4.90608e-05, gnorm=0.875, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142858
2022-10-17 11:18:21 - progress_bar.py[line:274] - INFO: epoch 001:  29729 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=29690, lr=4.90597e-05, gnorm=0.914, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=142870
2022-10-17 11:18:32 - progress_bar.py[line:274] - INFO: epoch 001:  29739 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.5, ups=0.88, wpb=109.4, bsz=40, num_updates=29700, lr=4.90587e-05, gnorm=1.032, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142881
2022-10-17 11:18:43 - progress_bar.py[line:274] - INFO: epoch 001:  29749 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.9, ups=0.91, wpb=112.1, bsz=40, num_updates=29710, lr=4.90577e-05, gnorm=0.851, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=142892
2022-10-17 11:18:54 - progress_bar.py[line:274] - INFO: epoch 001:  29759 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=29720, lr=4.90567e-05, gnorm=0.891, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142903
2022-10-17 11:19:05 - progress_bar.py[line:274] - INFO: epoch 001:  29769 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=29730, lr=4.90557e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142914
2022-10-17 11:19:16 - progress_bar.py[line:274] - INFO: epoch 001:  29779 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.89, wpb=109.3, bsz=40, num_updates=29740, lr=4.90547e-05, gnorm=0.815, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=142925
2022-10-17 11:19:28 - progress_bar.py[line:274] - INFO: epoch 001:  29789 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=29750, lr=4.90536e-05, gnorm=0.762, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142937
2022-10-17 11:19:39 - progress_bar.py[line:274] - INFO: epoch 001:  29799 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=29760, lr=4.90526e-05, gnorm=0.873, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=142948
2022-10-17 11:19:50 - progress_bar.py[line:274] - INFO: epoch 001:  29809 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=29770, lr=4.90516e-05, gnorm=0.78, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142959
2022-10-17 11:20:02 - progress_bar.py[line:274] - INFO: epoch 001:  29819 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=29780, lr=4.90506e-05, gnorm=0.714, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142970
2022-10-17 11:20:13 - progress_bar.py[line:274] - INFO: epoch 001:  29829 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.1, ups=0.89, wpb=110.5, bsz=40, num_updates=29790, lr=4.90496e-05, gnorm=0.901, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=142982
2022-10-17 11:20:19 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 11:20:25 - progress_bar.py[line:274] - INFO: epoch 001:  29840 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.4, ups=0.82, wpb=109.8, bsz=40, num_updates=29800, lr=4.90485e-05, gnorm=0.974, clip=50, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=142994
2022-10-17 11:20:36 - progress_bar.py[line:274] - INFO: epoch 001:  29850 / 102288 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=102.6, ups=0.91, wpb=112.2, bsz=40, num_updates=29810, lr=4.90475e-05, gnorm=0.969, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=143005
2022-10-17 11:20:47 - progress_bar.py[line:274] - INFO: epoch 001:  29860 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=29820, lr=4.90465e-05, gnorm=0.971, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=143016
2022-10-17 11:20:58 - progress_bar.py[line:274] - INFO: epoch 001:  29870 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99, ups=0.9, wpb=109.7, bsz=40, num_updates=29830, lr=4.90455e-05, gnorm=0.879, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=143027
2022-10-17 11:21:10 - progress_bar.py[line:274] - INFO: epoch 001:  29880 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=29840, lr=4.90445e-05, gnorm=0.883, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=143039
2022-10-17 11:21:21 - progress_bar.py[line:274] - INFO: epoch 001:  29890 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=29850, lr=4.90434e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=143050
2022-10-17 11:21:32 - progress_bar.py[line:274] - INFO: epoch 001:  29900 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.4, ups=0.89, wpb=109, bsz=40, num_updates=29860, lr=4.90424e-05, gnorm=1.074, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=143061
2022-10-17 11:21:43 - progress_bar.py[line:274] - INFO: epoch 001:  29910 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.9, ups=0.89, wpb=108.8, bsz=40, num_updates=29870, lr=4.90414e-05, gnorm=0.979, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=143072
2022-10-17 11:21:54 - progress_bar.py[line:274] - INFO: epoch 001:  29920 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.8, ups=0.92, wpb=109.9, bsz=40, num_updates=29880, lr=4.90404e-05, gnorm=0.994, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=143083
2022-10-17 11:22:06 - progress_bar.py[line:274] - INFO: epoch 001:  29930 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=29890, lr=4.90394e-05, gnorm=0.859, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=143095
2022-10-17 11:22:17 - progress_bar.py[line:274] - INFO: epoch 001:  29940 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=29900, lr=4.90384e-05, gnorm=1.03, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=143106
2022-10-17 11:22:28 - progress_bar.py[line:274] - INFO: epoch 001:  29950 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=29910, lr=4.90373e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=143117
2022-10-17 11:22:39 - progress_bar.py[line:274] - INFO: epoch 001:  29960 / 102288 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.5, ups=0.89, wpb=111.6, bsz=40, num_updates=29920, lr=4.90363e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=143128
2022-10-17 11:22:50 - progress_bar.py[line:274] - INFO: epoch 001:  29970 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=29930, lr=4.90353e-05, gnorm=0.955, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=143139
2022-10-17 11:23:02 - progress_bar.py[line:274] - INFO: epoch 001:  29980 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=29940, lr=4.90343e-05, gnorm=1.036, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=143151
2022-10-17 11:23:13 - progress_bar.py[line:274] - INFO: epoch 001:  29990 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.8, ups=0.9, wpb=109.4, bsz=40, num_updates=29950, lr=4.90333e-05, gnorm=1.09, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=143162
2022-10-17 11:23:24 - progress_bar.py[line:274] - INFO: epoch 001:  30000 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.9, ups=0.91, wpb=109.3, bsz=40, num_updates=29960, lr=4.90322e-05, gnorm=1.005, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=143173
2022-10-17 11:23:35 - progress_bar.py[line:274] - INFO: epoch 001:  30010 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.8, ups=0.87, wpb=110.3, bsz=40, num_updates=29970, lr=4.90312e-05, gnorm=1.1, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=143184
2022-10-17 11:23:47 - progress_bar.py[line:274] - INFO: epoch 001:  30020 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.1, ups=0.89, wpb=110.6, bsz=40, num_updates=29980, lr=4.90302e-05, gnorm=1.034, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=143195
2022-10-17 11:23:57 - progress_bar.py[line:274] - INFO: epoch 001:  30030 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.8, ups=0.93, wpb=108.9, bsz=40, num_updates=29990, lr=4.90292e-05, gnorm=1.016, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=143206
2022-10-17 11:24:09 - progress_bar.py[line:274] - INFO: epoch 001:  30040 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=30000, lr=4.90282e-05, gnorm=1.033, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=143218
2022-10-17 11:24:09 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 11:24:10 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 11:24:10 - train.py[line:551] - INFO: load:1.28 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 11:26:42 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 11:26:42 - train.py[line:551] - INFO: load:1.30 valid_run:151.82 task_valid:148.54 collect_output:2.21
2022-10-17 11:29:10 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 11:29:10 - train.py[line:551] - INFO: load:1.33 valid_run:300.07 task_valid:292.08 collect_output:5.86
2022-10-17 11:31:43 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 11:31:43 - train.py[line:551] - INFO: load:1.36 valid_run:452.19 task_valid:436.12 collect_output:12.81
2022-10-17 11:34:12 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 11:34:12 - train.py[line:551] - INFO: load:1.39 valid_run:601.24 task_valid:581.46 collect_output:15.41
2022-10-17 11:36:44 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 11:36:44 - train.py[line:551] - INFO: load:1.41 valid_run:753.77 task_valid:729.50 collect_output:18.81
2022-10-17 11:39:16 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 11:39:16 - train.py[line:551] - INFO: load:1.44 valid_run:905.34 task_valid:875.46 collect_output:23.36
2022-10-17 11:41:49 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 11:41:49 - train.py[line:551] - INFO: load:1.47 valid_run:1057.91 task_valid:1021.45 collect_output:28.93
2022-10-17 11:44:19 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 11:44:19 - train.py[line:551] - INFO: load:1.49 valid_run:1208.46 task_valid:1162.60 collect_output:37.33
2022-10-17 11:46:49 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 11:46:49 - train.py[line:551] - INFO: load:1.51 valid_run:1357.79 task_valid:1307.36 collect_output:40.89
2022-10-17 11:49:17 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 11:49:17 - train.py[line:551] - INFO: load:1.54 valid_run:1505.98 task_valid:1450.59 collect_output:44.85
2022-10-17 11:51:46 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 11:51:46 - train.py[line:551] - INFO: load:1.56 valid_run:1655.35 task_valid:1595.56 collect_output:48.24
2022-10-17 11:54:16 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 11:54:16 - train.py[line:551] - INFO: load:1.59 valid_run:1805.04 task_valid:1740.64 collect_output:51.84
2022-10-17 11:56:46 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 11:56:46 - train.py[line:551] - INFO: load:1.61 valid_run:1954.62 task_valid:1882.49 collect_output:58.56
2022-10-17 11:59:16 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 11:59:16 - train.py[line:551] - INFO: load:1.64 valid_run:2104.71 task_valid:2027.95 collect_output:62.19
2022-10-17 12:01:46 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 12:01:46 - train.py[line:551] - INFO: load:1.66 valid_run:2254.42 task_valid:2174.37 collect_output:64.49
2022-10-17 12:04:15 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 12:04:15 - train.py[line:551] - INFO: load:1.68 valid_run:2404.08 task_valid:2318.57 collect_output:68.96
2022-10-17 12:06:46 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 12:06:46 - train.py[line:551] - INFO: load:1.71 valid_run:2555.30 task_valid:2463.86 collect_output:73.91
2022-10-17 12:09:17 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 12:09:17 - train.py[line:551] - INFO: load:1.73 valid_run:2705.66 task_valid:2610.74 collect_output:76.40
2022-10-17 12:11:45 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 12:11:45 - train.py[line:551] - INFO: load:1.76 valid_run:2853.62 task_valid:2752.30 collect_output:81.80
2022-10-17 12:14:15 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 12:14:15 - train.py[line:551] - INFO: load:1.78 valid_run:3003.88 task_valid:2897.62 collect_output:85.74
2022-10-17 12:16:47 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 12:16:47 - train.py[line:551] - INFO: load:1.81 valid_run:3155.53 task_valid:3042.19 collect_output:91.81
2022-10-17 12:19:16 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 12:19:16 - train.py[line:551] - INFO: load:1.83 valid_run:3304.96 task_valid:3186.73 collect_output:95.70
2022-10-17 12:21:48 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 12:21:48 - train.py[line:551] - INFO: load:1.86 valid_run:3455.96 task_valid:3332.92 collect_output:99.52
2022-10-17 12:24:19 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 12:24:19 - train.py[line:551] - INFO: load:1.88 valid_run:3607.49 task_valid:3479.71 collect_output:103.19

====================================================================================================
SGG eval:     R @ 50: 0.4504;     R @ 100: 0.4982;     R @ 500: 0.5293;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2790;    mR @ 100: 0.3546;    mR @ 500: 0.3886;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5244) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.0000) (hanging from:0.5161) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8170) (playing:0.0000) (riding:0.7023) (says:0.0000) (sitting on:0.6284) (standing on:0.2350) (using:0.5500) (walking in:0.3333) (walking on:0.1892) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2022-10-17 12:26:51 - train.py[line:487] - INFO: 0.4982095238095238

====================================================================================================
SGG eval:     R @ 50: 0.4504;     R @ 100: 0.4982;     R @ 500: 0.5293;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2790;    mR @ 100: 0.3546;    mR @ 500: 0.3886;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5244) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.0000) (hanging from:0.5161) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.8170) (playing:0.0000) (riding:0.7023) (says:0.0000) (sitting on:0.6284) (standing on:0.2350) (using:0.5500) (walking in:0.3333) (walking on:0.1892) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2022-10-17 12:26:51 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 12:26:51 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.333 | loss_v1 0 | loss_v2 0 | nll_loss 0.176 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.49821 | ppl 1.13 | vqa_score 0.4144 | wps 119.3 | wpb 89.9 | bsz 30 | num_updates 30000 | best_R@100 0.581461
2022-10-17 12:26:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 30000 updates
2022-10-17 12:26:51 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_30000.pt
2022-10-17 12:26:58 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_30000.pt
2022-10-17 12:27:00 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_30000.pt (epoch 1 @ 30000 updates, score 0.4982095238095238) (writing took 8.813396114856005 seconds)
2022-10-17 12:27:13 - progress_bar.py[line:274] - INFO: epoch 001:  30050 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=0.3, ups=0, wpb=110.3, bsz=40, num_updates=30010, lr=4.90272e-05, gnorm=0.952, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147000
2022-10-17 12:27:24 - progress_bar.py[line:274] - INFO: epoch 001:  30060 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=30020, lr=4.90261e-05, gnorm=1.045, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147013
2022-10-17 12:27:36 - progress_bar.py[line:274] - INFO: epoch 001:  30070 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=30030, lr=4.90251e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147025
2022-10-17 12:27:47 - progress_bar.py[line:274] - INFO: epoch 001:  30080 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=30040, lr=4.90241e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147036
2022-10-17 12:27:58 - progress_bar.py[line:274] - INFO: epoch 001:  30090 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.1, ups=0.89, wpb=108.2, bsz=40, num_updates=30050, lr=4.90231e-05, gnorm=1.02, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=147047
2022-10-17 12:28:09 - progress_bar.py[line:274] - INFO: epoch 001:  30100 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.5, ups=0.9, wpb=109, bsz=40, num_updates=30060, lr=4.90221e-05, gnorm=1.191, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147058
2022-10-17 12:28:20 - progress_bar.py[line:274] - INFO: epoch 001:  30110 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.2, ups=0.91, wpb=108.7, bsz=40, num_updates=30070, lr=4.9021e-05, gnorm=1.06, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=147069
2022-10-17 12:28:31 - progress_bar.py[line:274] - INFO: epoch 001:  30120 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=30080, lr=4.902e-05, gnorm=1.067, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147080
2022-10-17 12:28:42 - progress_bar.py[line:274] - INFO: epoch 001:  30130 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=30090, lr=4.9019e-05, gnorm=0.922, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147091
2022-10-17 12:28:54 - progress_bar.py[line:274] - INFO: epoch 001:  30140 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.8, ups=0.9, wpb=110.8, bsz=40, num_updates=30100, lr=4.9018e-05, gnorm=1.053, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147103
2022-10-17 12:29:05 - progress_bar.py[line:274] - INFO: epoch 001:  30150 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96, ups=0.88, wpb=109.2, bsz=40, num_updates=30110, lr=4.9017e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147114
2022-10-17 12:29:16 - progress_bar.py[line:274] - INFO: epoch 001:  30160 / 102288 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.8, ups=0.89, wpb=112, bsz=40, num_updates=30120, lr=4.9016e-05, gnorm=1.101, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147125
2022-10-17 12:29:27 - progress_bar.py[line:274] - INFO: epoch 001:  30170 / 102288 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=30130, lr=4.90149e-05, gnorm=1.053, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147136
2022-10-17 12:29:39 - progress_bar.py[line:274] - INFO: epoch 001:  30180 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.1, ups=0.89, wpb=112.4, bsz=40, num_updates=30140, lr=4.90139e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147148
2022-10-17 12:29:49 - progress_bar.py[line:274] - INFO: epoch 001:  30190 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=103.6, ups=0.94, wpb=110.1, bsz=40, num_updates=30150, lr=4.90129e-05, gnorm=1.006, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147158
2022-10-17 12:30:01 - progress_bar.py[line:274] - INFO: epoch 001:  30200 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.6, ups=0.88, wpb=111.3, bsz=40, num_updates=30160, lr=4.90119e-05, gnorm=1.048, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=147170
2022-10-17 12:30:12 - progress_bar.py[line:274] - INFO: epoch 001:  30210 / 102288 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.2, ups=0.88, wpb=111.5, bsz=40, num_updates=30170, lr=4.90109e-05, gnorm=0.931, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147181
2022-10-17 12:30:24 - progress_bar.py[line:274] - INFO: epoch 001:  30220 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.1, ups=0.87, wpb=109.3, bsz=40, num_updates=30180, lr=4.90098e-05, gnorm=1.195, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147193
2022-10-17 12:30:34 - progress_bar.py[line:274] - INFO: epoch 001:  30230 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102, ups=0.92, wpb=110.4, bsz=40, num_updates=30190, lr=4.90088e-05, gnorm=1.017, clip=40, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=147203
2022-10-17 12:30:46 - progress_bar.py[line:274] - INFO: epoch 001:  30240 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.9, ups=0.9, wpb=109.6, bsz=40, num_updates=30200, lr=4.90078e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147215
2022-10-17 12:30:56 - progress_bar.py[line:274] - INFO: epoch 001:  30250 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=102.3, ups=0.93, wpb=110.1, bsz=40, num_updates=30210, lr=4.90068e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=147225
2022-10-17 12:31:08 - progress_bar.py[line:274] - INFO: epoch 001:  30260 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.9, ups=0.9, wpb=110.8, bsz=40, num_updates=30220, lr=4.90058e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147237
2022-10-17 12:31:19 - progress_bar.py[line:274] - INFO: epoch 001:  30270 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.3, ups=0.88, wpb=109.4, bsz=40, num_updates=30230, lr=4.90048e-05, gnorm=0.903, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147248
2022-10-17 12:31:30 - progress_bar.py[line:274] - INFO: epoch 001:  30280 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.6, ups=0.89, wpb=111.6, bsz=40, num_updates=30240, lr=4.90037e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147259
2022-10-17 12:31:41 - progress_bar.py[line:274] - INFO: epoch 001:  30290 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=30250, lr=4.90027e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147270
2022-10-17 12:31:53 - progress_bar.py[line:274] - INFO: epoch 001:  30300 / 102288 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.3, ups=0.9, wpb=111.7, bsz=40, num_updates=30260, lr=4.90017e-05, gnorm=0.971, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147282
2022-10-17 12:32:04 - progress_bar.py[line:274] - INFO: epoch 001:  30310 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=30270, lr=4.90007e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=147293
2022-10-17 12:32:16 - progress_bar.py[line:274] - INFO: epoch 001:  30320 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.2, ups=0.92, wpb=109.5, bsz=40, num_updates=30280, lr=4.89997e-05, gnorm=0.903, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147304
2022-10-17 12:32:27 - progress_bar.py[line:274] - INFO: epoch 001:  30330 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.2, ups=0.87, wpb=109.8, bsz=40, num_updates=30290, lr=4.89986e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147316
2022-10-17 12:32:38 - progress_bar.py[line:274] - INFO: epoch 001:  30340 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101, ups=0.91, wpb=110.7, bsz=40, num_updates=30300, lr=4.89976e-05, gnorm=0.841, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147327
2022-10-17 12:32:50 - progress_bar.py[line:274] - INFO: epoch 001:  30350 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.2, ups=0.9, wpb=110.3, bsz=40, num_updates=30310, lr=4.89966e-05, gnorm=0.825, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147338
2022-10-17 12:33:02 - progress_bar.py[line:274] - INFO: epoch 001:  30360 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.1, ups=0.9, wpb=111.2, bsz=40, num_updates=30320, lr=4.89956e-05, gnorm=1, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147351
2022-10-17 12:33:12 - progress_bar.py[line:274] - INFO: epoch 001:  30370 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.3, ups=0.92, wpb=109.2, bsz=40, num_updates=30330, lr=4.89946e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147361
2022-10-17 12:33:24 - progress_bar.py[line:274] - INFO: epoch 001:  30380 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.8, ups=0.88, wpb=111.4, bsz=40, num_updates=30340, lr=4.89935e-05, gnorm=0.952, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=147373
2022-10-17 12:33:35 - progress_bar.py[line:274] - INFO: epoch 001:  30390 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.7, ups=0.93, wpb=110.9, bsz=40, num_updates=30350, lr=4.89925e-05, gnorm=1.062, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=147384
2022-10-17 12:33:46 - progress_bar.py[line:274] - INFO: epoch 001:  30400 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=30360, lr=4.89915e-05, gnorm=0.993, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147395
2022-10-17 12:33:57 - progress_bar.py[line:274] - INFO: epoch 001:  30410 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=30370, lr=4.89905e-05, gnorm=0.898, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=147406
2022-10-17 12:34:08 - progress_bar.py[line:274] - INFO: epoch 001:  30420 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=30380, lr=4.89895e-05, gnorm=1.062, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147417
2022-10-17 12:34:19 - progress_bar.py[line:274] - INFO: epoch 001:  30430 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=30390, lr=4.89885e-05, gnorm=1.038, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147428
2022-10-17 12:34:24 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 12:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  30441 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.6, ups=0.81, wpb=111, bsz=40, num_updates=30400, lr=4.89874e-05, gnorm=1.143, clip=60, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=147441
2022-10-17 12:34:43 - progress_bar.py[line:274] - INFO: epoch 001:  30451 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.2, ups=0.87, wpb=110.5, bsz=40, num_updates=30410, lr=4.89864e-05, gnorm=1.128, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147452
2022-10-17 12:34:55 - progress_bar.py[line:274] - INFO: epoch 001:  30461 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.3, ups=0.89, wpb=110.6, bsz=40, num_updates=30420, lr=4.89854e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147464
2022-10-17 12:35:06 - progress_bar.py[line:274] - INFO: epoch 001:  30471 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=30430, lr=4.89844e-05, gnorm=1.013, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=147475
2022-10-17 12:35:17 - progress_bar.py[line:274] - INFO: epoch 001:  30481 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=30440, lr=4.89834e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=147486
2022-10-17 12:35:29 - progress_bar.py[line:274] - INFO: epoch 001:  30491 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.6, ups=0.87, wpb=107.8, bsz=40, num_updates=30450, lr=4.89823e-05, gnorm=0.976, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147498
2022-10-17 12:35:40 - progress_bar.py[line:274] - INFO: epoch 001:  30501 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=30460, lr=4.89813e-05, gnorm=1.019, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=147509
2022-10-17 12:35:51 - progress_bar.py[line:274] - INFO: epoch 001:  30511 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.7, ups=0.89, wpb=109.5, bsz=40, num_updates=30470, lr=4.89803e-05, gnorm=1.013, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147520
2022-10-17 12:36:03 - progress_bar.py[line:274] - INFO: epoch 001:  30521 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=30480, lr=4.89793e-05, gnorm=1.071, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=147532
2022-10-17 12:36:14 - progress_bar.py[line:274] - INFO: epoch 001:  30531 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=30490, lr=4.89783e-05, gnorm=1.239, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147543
2022-10-17 12:36:25 - progress_bar.py[line:274] - INFO: epoch 001:  30541 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.5, ups=0.89, wpb=108.9, bsz=40, num_updates=30500, lr=4.89773e-05, gnorm=0.985, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147554
2022-10-17 12:36:37 - progress_bar.py[line:274] - INFO: epoch 001:  30551 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=30510, lr=4.89762e-05, gnorm=1.117, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147566
2022-10-17 12:36:48 - progress_bar.py[line:274] - INFO: epoch 001:  30561 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.1, ups=0.89, wpb=112.2, bsz=40, num_updates=30520, lr=4.89752e-05, gnorm=0.954, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147577
2022-10-17 12:36:59 - progress_bar.py[line:274] - INFO: epoch 001:  30571 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=30530, lr=4.89742e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147588
2022-10-17 12:37:10 - progress_bar.py[line:274] - INFO: epoch 001:  30581 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=30540, lr=4.89732e-05, gnorm=1.004, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=147599
2022-10-17 12:37:22 - progress_bar.py[line:274] - INFO: epoch 001:  30591 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=30550, lr=4.89722e-05, gnorm=0.888, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147611
2022-10-17 12:37:33 - progress_bar.py[line:274] - INFO: epoch 001:  30601 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.3, ups=0.9, wpb=110.2, bsz=40, num_updates=30560, lr=4.89711e-05, gnorm=0.976, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147622
2022-10-17 12:37:44 - progress_bar.py[line:274] - INFO: epoch 001:  30611 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.6, ups=0.88, wpb=110.3, bsz=40, num_updates=30570, lr=4.89701e-05, gnorm=1, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147633
2022-10-17 12:37:55 - progress_bar.py[line:274] - INFO: epoch 001:  30621 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=30580, lr=4.89691e-05, gnorm=0.967, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147644
2022-10-17 12:38:06 - progress_bar.py[line:274] - INFO: epoch 001:  30631 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.1, ups=0.89, wpb=109.1, bsz=40, num_updates=30590, lr=4.89681e-05, gnorm=0.959, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147655
2022-10-17 12:38:18 - progress_bar.py[line:274] - INFO: epoch 001:  30641 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=30600, lr=4.89671e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147667
2022-10-17 12:38:29 - progress_bar.py[line:274] - INFO: epoch 001:  30651 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=30610, lr=4.89661e-05, gnorm=0.849, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147678
2022-10-17 12:38:40 - progress_bar.py[line:274] - INFO: epoch 001:  30661 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=30620, lr=4.8965e-05, gnorm=1.263, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=147689
2022-10-17 12:38:52 - progress_bar.py[line:274] - INFO: epoch 001:  30671 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.5, ups=0.88, wpb=109.9, bsz=40, num_updates=30630, lr=4.8964e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147701
2022-10-17 12:39:03 - progress_bar.py[line:274] - INFO: epoch 001:  30681 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=30640, lr=4.8963e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=147712
2022-10-17 12:39:14 - progress_bar.py[line:274] - INFO: epoch 001:  30691 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=30650, lr=4.8962e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147723
2022-10-17 12:39:25 - progress_bar.py[line:274] - INFO: epoch 001:  30701 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=30660, lr=4.8961e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147734
2022-10-17 12:39:36 - progress_bar.py[line:274] - INFO: epoch 001:  30711 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.9, ups=0.91, wpb=109.6, bsz=40, num_updates=30670, lr=4.89599e-05, gnorm=0.867, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147745
2022-10-17 12:39:47 - progress_bar.py[line:274] - INFO: epoch 001:  30721 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=30680, lr=4.89589e-05, gnorm=0.855, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147756
2022-10-17 12:39:59 - progress_bar.py[line:274] - INFO: epoch 001:  30731 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.1, ups=0.88, wpb=110.4, bsz=40, num_updates=30690, lr=4.89579e-05, gnorm=0.972, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147768
2022-10-17 12:40:09 - progress_bar.py[line:274] - INFO: epoch 001:  30741 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=104, ups=0.94, wpb=110.7, bsz=40, num_updates=30700, lr=4.89569e-05, gnorm=0.918, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147778
2022-10-17 12:40:21 - progress_bar.py[line:274] - INFO: epoch 001:  30751 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.9, ups=0.87, wpb=109.7, bsz=40, num_updates=30710, lr=4.89559e-05, gnorm=0.87, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147790
2022-10-17 12:40:32 - progress_bar.py[line:274] - INFO: epoch 001:  30761 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=30720, lr=4.89549e-05, gnorm=0.879, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=147801
2022-10-17 12:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  30771 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=30730, lr=4.89538e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147812
2022-10-17 12:40:54 - progress_bar.py[line:274] - INFO: epoch 001:  30781 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.2, ups=0.91, wpb=109.7, bsz=40, num_updates=30740, lr=4.89528e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147823
2022-10-17 12:41:06 - progress_bar.py[line:274] - INFO: epoch 001:  30791 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.9, ups=0.87, wpb=110.8, bsz=40, num_updates=30750, lr=4.89518e-05, gnorm=0.88, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=147835
2022-10-17 12:41:17 - progress_bar.py[line:274] - INFO: epoch 001:  30801 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=30760, lr=4.89508e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147846
2022-10-17 12:41:28 - progress_bar.py[line:274] - INFO: epoch 001:  30811 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=30770, lr=4.89498e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147857
2022-10-17 12:41:39 - progress_bar.py[line:274] - INFO: epoch 001:  30821 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=30780, lr=4.89487e-05, gnorm=0.852, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147868
2022-10-17 12:41:50 - progress_bar.py[line:274] - INFO: epoch 001:  30831 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98, ups=0.88, wpb=111.5, bsz=40, num_updates=30790, lr=4.89477e-05, gnorm=0.815, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=147879
2022-10-17 12:42:01 - progress_bar.py[line:274] - INFO: epoch 001:  30841 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.4, ups=0.92, wpb=109.7, bsz=40, num_updates=30800, lr=4.89467e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147890
2022-10-17 12:42:12 - progress_bar.py[line:274] - INFO: epoch 001:  30851 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.9, ups=0.91, wpb=110.6, bsz=40, num_updates=30810, lr=4.89457e-05, gnorm=1.075, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147901
2022-10-17 12:42:24 - progress_bar.py[line:274] - INFO: epoch 001:  30861 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96, ups=0.87, wpb=110.3, bsz=40, num_updates=30820, lr=4.89447e-05, gnorm=0.822, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147913
2022-10-17 12:42:35 - progress_bar.py[line:274] - INFO: epoch 001:  30871 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.9, ups=0.89, wpb=108.8, bsz=40, num_updates=30830, lr=4.89436e-05, gnorm=1.036, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=147924
2022-10-17 12:42:46 - progress_bar.py[line:274] - INFO: epoch 001:  30881 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.5, ups=0.88, wpb=110.1, bsz=40, num_updates=30840, lr=4.89426e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147935
2022-10-17 12:42:58 - progress_bar.py[line:274] - INFO: epoch 001:  30891 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=30850, lr=4.89416e-05, gnorm=1.078, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147947
2022-10-17 12:43:09 - progress_bar.py[line:274] - INFO: epoch 001:  30901 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.4, ups=0.91, wpb=111.1, bsz=40, num_updates=30860, lr=4.89406e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147957
2022-10-17 12:43:19 - progress_bar.py[line:274] - INFO: epoch 001:  30911 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.7, ups=0.92, wpb=110.9, bsz=40, num_updates=30870, lr=4.89396e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=147968
2022-10-17 12:43:31 - progress_bar.py[line:274] - INFO: epoch 001:  30921 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.7, ups=0.89, wpb=109.5, bsz=40, num_updates=30880, lr=4.89386e-05, gnorm=0.943, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147980
2022-10-17 12:43:42 - progress_bar.py[line:274] - INFO: epoch 001:  30931 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=30890, lr=4.89375e-05, gnorm=0.894, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=147991
2022-10-17 12:43:53 - progress_bar.py[line:274] - INFO: epoch 001:  30941 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.1, ups=0.9, wpb=109.1, bsz=40, num_updates=30900, lr=4.89365e-05, gnorm=1.116, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=148002
2022-10-17 12:44:04 - progress_bar.py[line:274] - INFO: epoch 001:  30951 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.9, ups=0.87, wpb=109.8, bsz=40, num_updates=30910, lr=4.89355e-05, gnorm=1.006, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=148013
2022-10-17 12:44:15 - progress_bar.py[line:274] - INFO: epoch 001:  30961 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.1, ups=0.91, wpb=110.5, bsz=40, num_updates=30920, lr=4.89345e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=148024
2022-10-17 12:44:26 - progress_bar.py[line:274] - INFO: epoch 001:  30971 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.3, ups=0.91, wpb=111.4, bsz=40, num_updates=30930, lr=4.89335e-05, gnorm=0.866, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=148035
2022-10-17 12:44:38 - progress_bar.py[line:274] - INFO: epoch 001:  30981 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.6, ups=0.89, wpb=109.8, bsz=40, num_updates=30940, lr=4.89324e-05, gnorm=0.941, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=148047
2022-10-17 12:44:49 - progress_bar.py[line:274] - INFO: epoch 001:  30991 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.1, ups=0.89, wpb=109.8, bsz=40, num_updates=30950, lr=4.89314e-05, gnorm=0.992, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=148058
2022-10-17 12:45:00 - progress_bar.py[line:274] - INFO: epoch 001:  31001 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.1, ups=0.89, wpb=109.7, bsz=40, num_updates=30960, lr=4.89304e-05, gnorm=0.986, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=148069
2022-10-17 12:45:11 - progress_bar.py[line:274] - INFO: epoch 001:  31011 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.8, ups=0.88, wpb=108, bsz=40, num_updates=30970, lr=4.89294e-05, gnorm=0.926, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=148080
2022-10-17 12:45:23 - progress_bar.py[line:274] - INFO: epoch 001:  31021 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=30980, lr=4.89284e-05, gnorm=1.01, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=148092
2022-10-17 12:45:33 - progress_bar.py[line:274] - INFO: epoch 001:  31031 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.3, ups=0.91, wpb=109.7, bsz=40, num_updates=30990, lr=4.89274e-05, gnorm=0.967, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=148102
2022-10-17 12:45:45 - progress_bar.py[line:274] - INFO: epoch 001:  31041 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=31000, lr=4.89263e-05, gnorm=1.231, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=148114
2022-10-17 12:45:45 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 12:45:46 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 12:45:46 - train.py[line:551] - INFO: load:1.23 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 12:46:02 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.87 GiB already allocated; 428.19 MiB free; 36.68 GiB reserved in total by PyTorch)
2022-10-17 12:46:02 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 8            |        cudaMalloc retries: 39        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9086 MB |   14316 MB |   21421 TB |   21421 TB |
|       from large pool |    8941 MB |   14171 MB |   21415 TB |   21415 TB |
|       from small pool |     144 MB |     145 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9086 MB |   14316 MB |   21421 TB |   21421 TB |
|       from large pool |    8941 MB |   14171 MB |   21415 TB |   21415 TB |
|       from small pool |     144 MB |     145 MB |       5 TB |       5 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   37564 MB |   37680 MB |  376544 MB |  338980 MB |
|       from large pool |   37418 MB |   37528 MB |  376042 MB |  338624 MB |
|       from small pool |     146 MB |     152 MB |     502 MB |     356 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   28477 MB |   28477 MB |   22174 TB |   22174 TB |
|       from large pool |   28476 MB |   28476 MB |   22168 TB |   22168 TB |
|       from small pool |       1 MB |       2 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |    1000 M  |    1000 M  |
|       from large pool |     563    |     575    |     319 M  |     319 M  |
|       from small pool |    3106    |    3116    |     681 M  |     681 M  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |    1000 M  |    1000 M  |
|       from large pool |     563    |     575    |     319 M  |     319 M  |
|       from small pool |    3106    |    3116    |     681 M  |     681 M  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     145    |     150    |     756    |     611    |
|       from large pool |      72    |      74    |     505    |     433    |
|       from small pool |      73    |      76    |     251    |     178    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     107    |     112    |  714301 K  |  714300 K  |
|       from large pool |      70    |      71    |  119079 K  |  119079 K  |
|       from small pool |      37    |      48    |  595221 K  |  595221 K  |
|===========================================================================|

2022-10-17 12:46:02 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-17 12:46:02 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-17 12:48:19 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 12:48:19 - train.py[line:551] - INFO: load:1.25 valid_run:152.89 task_valid:148.45 collect_output:2.27
2022-10-17 12:50:48 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 12:50:48 - train.py[line:551] - INFO: load:1.28 valid_run:301.82 task_valid:292.46 collect_output:6.08
2022-10-17 12:53:20 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 12:53:20 - train.py[line:551] - INFO: load:1.30 valid_run:453.61 task_valid:435.64 collect_output:13.61
2022-10-17 12:55:49 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 12:55:49 - train.py[line:551] - INFO: load:1.33 valid_run:602.24 task_valid:580.53 collect_output:16.36
2022-10-17 12:58:21 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 12:58:21 - train.py[line:551] - INFO: load:1.35 valid_run:754.18 task_valid:727.96 collect_output:19.88
2022-10-17 13:00:52 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 13:00:52 - train.py[line:551] - INFO: load:1.37 valid_run:905.64 task_valid:873.59 collect_output:24.71
2022-10-17 13:03:25 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 13:03:25 - train.py[line:551] - INFO: load:1.40 valid_run:1058.13 task_valid:1019.61 collect_output:30.20
2022-10-17 13:05:55 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 13:05:55 - train.py[line:551] - INFO: load:1.42 valid_run:1208.67 task_valid:1160.72 collect_output:38.64
2022-10-17 13:08:25 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 13:08:25 - train.py[line:551] - INFO: load:1.45 valid_run:1357.94 task_valid:1305.39 collect_output:42.24
2022-10-17 13:10:53 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 13:10:53 - train.py[line:551] - INFO: load:1.47 valid_run:1506.36 task_valid:1448.62 collect_output:46.44
2022-10-17 13:13:23 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 13:13:23 - train.py[line:551] - INFO: load:1.50 valid_run:1655.87 task_valid:1593.65 collect_output:49.89
2022-10-17 13:15:52 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 13:15:52 - train.py[line:551] - INFO: load:1.52 valid_run:1805.32 task_valid:1738.54 collect_output:53.45
2022-10-17 13:18:22 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 13:18:22 - train.py[line:551] - INFO: load:1.54 valid_run:1954.78 task_valid:1880.24 collect_output:60.24
2022-10-17 13:20:52 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 13:20:52 - train.py[line:551] - INFO: load:1.57 valid_run:2105.18 task_valid:2025.73 collect_output:64.16
2022-10-17 13:23:22 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 13:23:22 - train.py[line:551] - INFO: load:1.59 valid_run:2254.99 task_valid:2172.06 collect_output:66.63
2022-10-17 13:25:52 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 13:25:52 - train.py[line:551] - INFO: load:1.62 valid_run:2404.69 task_valid:2316.06 collect_output:71.35
2022-10-17 13:28:24 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 13:28:24 - train.py[line:551] - INFO: load:1.64 valid_run:2556.32 task_valid:2461.50 collect_output:76.54
2022-10-17 13:30:54 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 13:30:54 - train.py[line:551] - INFO: load:1.67 valid_run:2706.60 task_valid:2608.27 collect_output:79.06
2022-10-17 13:33:23 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 13:33:23 - train.py[line:551] - INFO: load:1.69 valid_run:2855.14 task_valid:2749.96 collect_output:84.92
2022-10-17 13:35:53 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 13:35:53 - train.py[line:551] - INFO: load:1.71 valid_run:3005.48 task_valid:2895.01 collect_output:89.19
2022-10-17 13:38:25 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 13:38:25 - train.py[line:551] - INFO: load:1.74 valid_run:3157.94 task_valid:3040.04 collect_output:95.53
2022-10-17 13:40:55 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 13:40:55 - train.py[line:551] - INFO: load:1.77 valid_run:3307.49 task_valid:3185.02 collect_output:99.04
2022-10-17 13:43:27 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 13:43:27 - train.py[line:551] - INFO: load:1.79 valid_run:3459.43 task_valid:3331.80 collect_output:103.12
2022-10-17 13:45:59 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 13:45:59 - train.py[line:551] - INFO: load:1.82 valid_run:3611.52 task_valid:3479.18 collect_output:106.78

====================================================================================================
SGG eval:     R @ 50: 0.4477;     R @ 100: 0.4910;     R @ 500: 0.5198;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2769;    mR @ 100: 0.3500;    mR @ 500: 0.3818;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5244) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7336) (playing:0.0000) (riding:0.6837) (says:0.0000) (sitting on:0.6259) (standing on:0.2283) (using:0.6000) (walking in:0.3333) (walking on:0.1892) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2022-10-17 13:48:31 - train.py[line:487] - INFO: 0.49097619047619045

====================================================================================================
SGG eval:     R @ 50: 0.4477;     R @ 100: 0.4910;     R @ 500: 0.5198;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2769;    mR @ 100: 0.3500;    mR @ 500: 0.3818;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5244) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7336) (playing:0.0000) (riding:0.6837) (says:0.0000) (sitting on:0.6259) (standing on:0.2283) (using:0.6000) (walking in:0.3333) (walking on:0.1892) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2022-10-17 13:48:31 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 13:48:31 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.355 | loss_v1 0 | loss_v2 0 | nll_loss 0.202 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.490976 | ppl 1.15 | vqa_score 0.4088 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 31000 | best_R@100 0.581461
2022-10-17 13:48:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 31000 updates
2022-10-17 13:48:31 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_31000.pt
2022-10-17 13:48:38 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_31000.pt
2022-10-17 13:48:40 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_31000.pt (epoch 1 @ 31000 updates, score 0.49097619047619045) (writing took 9.344350015278906 seconds)
2022-10-17 13:48:52 - progress_bar.py[line:274] - INFO: epoch 001:  31051 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=0.3, ups=0, wpb=110.3, bsz=40, num_updates=31010, lr=4.89253e-05, gnorm=1.018, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=151900
2022-10-17 13:49:03 - progress_bar.py[line:274] - INFO: epoch 001:  31061 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.9, wpb=110.3, bsz=40, num_updates=31020, lr=4.89243e-05, gnorm=0.966, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=151912
2022-10-17 13:49:14 - progress_bar.py[line:274] - INFO: epoch 001:  31071 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=31030, lr=4.89233e-05, gnorm=1.125, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=151923
2022-10-17 13:49:25 - progress_bar.py[line:274] - INFO: epoch 001:  31081 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=31040, lr=4.89223e-05, gnorm=0.937, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=151934
2022-10-17 13:49:36 - progress_bar.py[line:274] - INFO: epoch 001:  31091 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=31050, lr=4.89212e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=151945
2022-10-17 13:49:48 - progress_bar.py[line:274] - INFO: epoch 001:  31101 / 102288 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.8, ups=0.89, wpb=112.4, bsz=40, num_updates=31060, lr=4.89202e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=151957
2022-10-17 13:49:59 - progress_bar.py[line:274] - INFO: epoch 001:  31111 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.6, ups=0.89, wpb=109.7, bsz=40, num_updates=31070, lr=4.89192e-05, gnorm=1.098, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=151968
2022-10-17 13:50:10 - progress_bar.py[line:274] - INFO: epoch 001:  31121 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.7, ups=0.9, wpb=108.5, bsz=40, num_updates=31080, lr=4.89182e-05, gnorm=0.94, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=151979
2022-10-17 13:50:21 - progress_bar.py[line:274] - INFO: epoch 001:  31131 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=31090, lr=4.89172e-05, gnorm=0.965, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=151990
2022-10-17 13:50:32 - progress_bar.py[line:274] - INFO: epoch 001:  31141 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=31100, lr=4.89162e-05, gnorm=0.914, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152001
2022-10-17 13:50:43 - progress_bar.py[line:274] - INFO: epoch 001:  31151 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.5, ups=0.91, wpb=110, bsz=40, num_updates=31110, lr=4.89151e-05, gnorm=0.915, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152012
2022-10-17 13:50:55 - progress_bar.py[line:274] - INFO: epoch 001:  31161 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=31120, lr=4.89141e-05, gnorm=0.973, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152023
2022-10-17 13:51:06 - progress_bar.py[line:274] - INFO: epoch 001:  31171 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.6, ups=0.89, wpb=111.2, bsz=40, num_updates=31130, lr=4.89131e-05, gnorm=0.998, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152035
2022-10-17 13:51:17 - progress_bar.py[line:274] - INFO: epoch 001:  31181 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.1, ups=0.9, wpb=108.9, bsz=40, num_updates=31140, lr=4.89121e-05, gnorm=0.781, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152046
2022-10-17 13:51:28 - progress_bar.py[line:274] - INFO: epoch 001:  31191 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.8, ups=0.9, wpb=110.8, bsz=40, num_updates=31150, lr=4.89111e-05, gnorm=0.976, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152057
2022-10-17 13:51:39 - progress_bar.py[line:274] - INFO: epoch 001:  31201 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=31160, lr=4.891e-05, gnorm=1.015, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152068
2022-10-17 13:51:50 - progress_bar.py[line:274] - INFO: epoch 001:  31211 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100, ups=0.92, wpb=109.2, bsz=40, num_updates=31170, lr=4.8909e-05, gnorm=0.892, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152079
2022-10-17 13:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  31221 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.9, ups=0.89, wpb=109, bsz=40, num_updates=31180, lr=4.8908e-05, gnorm=0.832, clip=10, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=152090
2022-10-17 13:52:13 - progress_bar.py[line:274] - INFO: epoch 001:  31231 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=31190, lr=4.8907e-05, gnorm=0.905, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=152102
2022-10-17 13:52:24 - progress_bar.py[line:274] - INFO: epoch 001:  31241 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.7, ups=0.91, wpb=109.5, bsz=40, num_updates=31200, lr=4.8906e-05, gnorm=1.08, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152113
2022-10-17 13:52:35 - progress_bar.py[line:274] - INFO: epoch 001:  31251 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=31210, lr=4.8905e-05, gnorm=0.874, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152124
2022-10-17 13:52:46 - progress_bar.py[line:274] - INFO: epoch 001:  31261 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97, ups=0.89, wpb=109.1, bsz=40, num_updates=31220, lr=4.89039e-05, gnorm=0.908, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152135
2022-10-17 13:52:58 - progress_bar.py[line:274] - INFO: epoch 001:  31271 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=31230, lr=4.89029e-05, gnorm=0.802, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=152146
2022-10-17 13:53:09 - progress_bar.py[line:274] - INFO: epoch 001:  31281 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=31240, lr=4.89019e-05, gnorm=1.01, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=152158
2022-10-17 13:53:20 - progress_bar.py[line:274] - INFO: epoch 001:  31291 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.4, ups=0.91, wpb=110.8, bsz=40, num_updates=31250, lr=4.89009e-05, gnorm=0.898, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=152169
2022-10-17 13:53:31 - progress_bar.py[line:274] - INFO: epoch 001:  31301 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=31260, lr=4.88999e-05, gnorm=0.916, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152180
2022-10-17 13:53:42 - progress_bar.py[line:274] - INFO: epoch 001:  31311 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.3, ups=0.9, wpb=111.4, bsz=40, num_updates=31270, lr=4.88988e-05, gnorm=1.105, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152191
2022-10-17 13:53:53 - progress_bar.py[line:274] - INFO: epoch 001:  31321 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.9, ups=0.89, wpb=109.1, bsz=40, num_updates=31280, lr=4.88978e-05, gnorm=0.96, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152202
2022-10-17 13:54:05 - progress_bar.py[line:274] - INFO: epoch 001:  31331 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99, ups=0.89, wpb=111.2, bsz=40, num_updates=31290, lr=4.88968e-05, gnorm=0.998, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152214
2022-10-17 13:54:15 - progress_bar.py[line:274] - INFO: epoch 001:  31341 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100, ups=0.91, wpb=109.3, bsz=40, num_updates=31300, lr=4.88958e-05, gnorm=0.961, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152224
2022-10-17 13:54:27 - progress_bar.py[line:274] - INFO: epoch 001:  31351 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=31310, lr=4.88948e-05, gnorm=1.01, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=152236
2022-10-17 13:54:38 - progress_bar.py[line:274] - INFO: epoch 001:  31361 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.3, ups=0.9, wpb=110.3, bsz=40, num_updates=31320, lr=4.88937e-05, gnorm=0.865, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152247
2022-10-17 13:54:50 - progress_bar.py[line:274] - INFO: epoch 001:  31371 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95, ups=0.85, wpb=111.3, bsz=40, num_updates=31330, lr=4.88927e-05, gnorm=0.874, clip=30, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=152259
2022-10-17 13:55:00 - progress_bar.py[line:274] - INFO: epoch 001:  31381 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=103.8, ups=0.93, wpb=112, bsz=40, num_updates=31340, lr=4.88917e-05, gnorm=0.895, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152269
2022-10-17 13:55:12 - progress_bar.py[line:274] - INFO: epoch 001:  31391 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=31350, lr=4.88907e-05, gnorm=0.832, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152280
2022-10-17 13:55:23 - progress_bar.py[line:274] - INFO: epoch 001:  31401 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.5, ups=0.88, wpb=109.8, bsz=40, num_updates=31360, lr=4.88897e-05, gnorm=0.836, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=152292
2022-10-17 13:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  31411 / 102288 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=31370, lr=4.88887e-05, gnorm=0.947, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152303
2022-10-17 13:55:45 - progress_bar.py[line:274] - INFO: epoch 001:  31421 / 102288 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.2, ups=0.89, wpb=112.1, bsz=40, num_updates=31380, lr=4.88876e-05, gnorm=0.978, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152314
2022-10-17 13:55:56 - progress_bar.py[line:274] - INFO: epoch 001:  31431 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.9, ups=0.92, wpb=110.1, bsz=40, num_updates=31390, lr=4.88866e-05, gnorm=0.89, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=152325
2022-10-17 13:56:07 - progress_bar.py[line:274] - INFO: epoch 001:  31441 / 102288 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.8, ups=0.9, wpb=111.7, bsz=40, num_updates=31400, lr=4.88856e-05, gnorm=0.743, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152336
2022-10-17 13:56:19 - progress_bar.py[line:274] - INFO: epoch 001:  31451 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=31410, lr=4.88846e-05, gnorm=0.942, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152348
2022-10-17 13:56:30 - progress_bar.py[line:274] - INFO: epoch 001:  31461 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.4, ups=0.91, wpb=111.2, bsz=40, num_updates=31420, lr=4.88836e-05, gnorm=0.904, clip=20, loss_scale=2048, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=152359
2022-10-17 13:56:35 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-17 13:56:42 - progress_bar.py[line:274] - INFO: epoch 001:  31472 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=89.3, ups=0.81, wpb=109.8, bsz=40, num_updates=31430, lr=4.88825e-05, gnorm=0.9, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=152371
2022-10-17 13:56:53 - progress_bar.py[line:274] - INFO: epoch 001:  31482 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=31440, lr=4.88815e-05, gnorm=0.999, clip=60, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=152382
2022-10-17 13:57:04 - progress_bar.py[line:274] - INFO: epoch 001:  31492 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.3, ups=0.89, wpb=109.2, bsz=40, num_updates=31450, lr=4.88805e-05, gnorm=0.906, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152393
2022-10-17 13:57:16 - progress_bar.py[line:274] - INFO: epoch 001:  31502 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=31460, lr=4.88795e-05, gnorm=0.938, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=152405
2022-10-17 13:57:27 - progress_bar.py[line:274] - INFO: epoch 001:  31512 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.9, wpb=109.9, bsz=40, num_updates=31470, lr=4.88785e-05, gnorm=0.87, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152416
2022-10-17 13:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  31522 / 102288 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.7, ups=0.88, wpb=111.5, bsz=40, num_updates=31480, lr=4.88775e-05, gnorm=0.846, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152427
2022-10-17 13:57:49 - progress_bar.py[line:274] - INFO: epoch 001:  31532 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=31490, lr=4.88764e-05, gnorm=0.935, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152438
2022-10-17 13:58:00 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 13:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  31543 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.8, wpb=110.9, bsz=40, num_updates=31500, lr=4.88754e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=152451
2022-10-17 13:58:13 - progress_bar.py[line:274] - INFO: epoch 001:  31553 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=31510, lr=4.88744e-05, gnorm=0.867, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152462
2022-10-17 13:58:25 - progress_bar.py[line:274] - INFO: epoch 001:  31563 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.9, ups=0.88, wpb=110.6, bsz=40, num_updates=31520, lr=4.88734e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=152474
2022-10-17 13:58:36 - progress_bar.py[line:274] - INFO: epoch 001:  31573 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=31530, lr=4.88724e-05, gnorm=0.988, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=152485
2022-10-17 13:58:47 - progress_bar.py[line:274] - INFO: epoch 001:  31583 / 102288 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=31540, lr=4.88713e-05, gnorm=1.218, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152496
2022-10-17 13:58:58 - progress_bar.py[line:274] - INFO: epoch 001:  31593 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.5, ups=0.9, wpb=111.4, bsz=40, num_updates=31550, lr=4.88703e-05, gnorm=1.102, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152507
2022-10-17 13:59:09 - progress_bar.py[line:274] - INFO: epoch 001:  31603 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=102.7, ups=0.93, wpb=110.8, bsz=40, num_updates=31560, lr=4.88693e-05, gnorm=0.822, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152518
2022-10-17 13:59:20 - progress_bar.py[line:274] - INFO: epoch 001:  31613 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.2, ups=0.91, wpb=109.3, bsz=40, num_updates=31570, lr=4.88683e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152529
2022-10-17 13:59:31 - progress_bar.py[line:274] - INFO: epoch 001:  31623 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=31580, lr=4.88673e-05, gnorm=1.137, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152540
2022-10-17 13:59:43 - progress_bar.py[line:274] - INFO: epoch 001:  31633 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.9, ups=0.88, wpb=110.3, bsz=40, num_updates=31590, lr=4.88663e-05, gnorm=1.027, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152552
2022-10-17 13:59:54 - progress_bar.py[line:274] - INFO: epoch 001:  31643 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.4, ups=0.89, wpb=109.9, bsz=40, num_updates=31600, lr=4.88652e-05, gnorm=1.005, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152563
2022-10-17 14:00:06 - progress_bar.py[line:274] - INFO: epoch 001:  31653 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.6, ups=0.87, wpb=111.5, bsz=40, num_updates=31610, lr=4.88642e-05, gnorm=0.822, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152575
2022-10-17 14:00:17 - progress_bar.py[line:274] - INFO: epoch 001:  31663 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.7, ups=0.92, wpb=111.1, bsz=40, num_updates=31620, lr=4.88632e-05, gnorm=0.781, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152586
2022-10-17 14:00:28 - progress_bar.py[line:274] - INFO: epoch 001:  31673 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.7, ups=0.91, wpb=110, bsz=40, num_updates=31630, lr=4.88622e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152597
2022-10-17 14:00:39 - progress_bar.py[line:274] - INFO: epoch 001:  31683 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=31640, lr=4.88612e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152608
2022-10-17 14:00:50 - progress_bar.py[line:274] - INFO: epoch 001:  31693 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=31650, lr=4.88601e-05, gnorm=0.984, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152619
2022-10-17 14:01:02 - progress_bar.py[line:274] - INFO: epoch 001:  31703 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=31660, lr=4.88591e-05, gnorm=0.946, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152631
2022-10-17 14:01:13 - progress_bar.py[line:274] - INFO: epoch 001:  31713 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.4, ups=0.89, wpb=108.4, bsz=40, num_updates=31670, lr=4.88581e-05, gnorm=0.87, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152642
2022-10-17 14:01:24 - progress_bar.py[line:274] - INFO: epoch 001:  31723 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.8, ups=0.9, wpb=109.2, bsz=40, num_updates=31680, lr=4.88571e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152653
2022-10-17 14:01:36 - progress_bar.py[line:274] - INFO: epoch 001:  31733 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=31690, lr=4.88561e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=152665
2022-10-17 14:01:47 - progress_bar.py[line:274] - INFO: epoch 001:  31743 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.8, ups=0.9, wpb=109.8, bsz=40, num_updates=31700, lr=4.88551e-05, gnorm=1.139, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152676
2022-10-17 14:01:58 - progress_bar.py[line:274] - INFO: epoch 001:  31753 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=104, ups=0.94, wpb=110.6, bsz=40, num_updates=31710, lr=4.8854e-05, gnorm=0.894, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152686
2022-10-17 14:02:09 - progress_bar.py[line:274] - INFO: epoch 001:  31763 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.8, ups=0.9, wpb=109.8, bsz=40, num_updates=31720, lr=4.8853e-05, gnorm=0.995, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152698
2022-10-17 14:02:20 - progress_bar.py[line:274] - INFO: epoch 001:  31773 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.6, ups=0.88, wpb=109.9, bsz=40, num_updates=31730, lr=4.8852e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152709
2022-10-17 14:02:31 - progress_bar.py[line:274] - INFO: epoch 001:  31783 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.5, ups=0.91, wpb=110.4, bsz=40, num_updates=31740, lr=4.8851e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152720
2022-10-17 14:02:43 - progress_bar.py[line:274] - INFO: epoch 001:  31793 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.2, ups=0.88, wpb=110.7, bsz=40, num_updates=31750, lr=4.885e-05, gnorm=0.999, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=152731
2022-10-17 14:02:54 - progress_bar.py[line:274] - INFO: epoch 001:  31803 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.1, ups=0.88, wpb=111.4, bsz=40, num_updates=31760, lr=4.88489e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152743
2022-10-17 14:03:05 - progress_bar.py[line:274] - INFO: epoch 001:  31813 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98, ups=0.89, wpb=110.3, bsz=40, num_updates=31770, lr=4.88479e-05, gnorm=0.967, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152754
2022-10-17 14:03:17 - progress_bar.py[line:274] - INFO: epoch 001:  31823 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=31780, lr=4.88469e-05, gnorm=0.855, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=152766
2022-10-17 14:03:28 - progress_bar.py[line:274] - INFO: epoch 001:  31833 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=31790, lr=4.88459e-05, gnorm=0.948, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152777
2022-10-17 14:03:39 - progress_bar.py[line:274] - INFO: epoch 001:  31843 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.4, ups=0.9, wpb=110.9, bsz=40, num_updates=31800, lr=4.88449e-05, gnorm=1.05, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=152788
2022-10-17 14:03:50 - progress_bar.py[line:274] - INFO: epoch 001:  31853 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=31810, lr=4.88438e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=152799
2022-10-17 14:04:02 - progress_bar.py[line:274] - INFO: epoch 001:  31863 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=31820, lr=4.88428e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152811
2022-10-17 14:04:13 - progress_bar.py[line:274] - INFO: epoch 001:  31873 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=31830, lr=4.88418e-05, gnorm=0.99, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152822
2022-10-17 14:04:25 - progress_bar.py[line:274] - INFO: epoch 001:  31883 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.2, ups=0.88, wpb=108.3, bsz=40, num_updates=31840, lr=4.88408e-05, gnorm=1.048, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152834
2022-10-17 14:04:36 - progress_bar.py[line:274] - INFO: epoch 001:  31893 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.4, ups=0.91, wpb=110, bsz=40, num_updates=31850, lr=4.88398e-05, gnorm=0.923, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=152845
2022-10-17 14:04:47 - progress_bar.py[line:274] - INFO: epoch 001:  31903 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.6, ups=0.88, wpb=108.3, bsz=40, num_updates=31860, lr=4.88388e-05, gnorm=0.78, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=152856
2022-10-17 14:04:59 - progress_bar.py[line:274] - INFO: epoch 001:  31913 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=31870, lr=4.88377e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152867
2022-10-17 14:05:10 - progress_bar.py[line:274] - INFO: epoch 001:  31923 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=31880, lr=4.88367e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152879
2022-10-17 14:05:21 - progress_bar.py[line:274] - INFO: epoch 001:  31933 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=31890, lr=4.88357e-05, gnorm=0.914, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152890
2022-10-17 14:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  31943 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.3, ups=0.87, wpb=109.6, bsz=40, num_updates=31900, lr=4.88347e-05, gnorm=0.966, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152901
2022-10-17 14:05:43 - progress_bar.py[line:274] - INFO: epoch 001:  31953 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.3, ups=0.93, wpb=108.1, bsz=40, num_updates=31910, lr=4.88337e-05, gnorm=0.875, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152912
2022-10-17 14:05:54 - progress_bar.py[line:274] - INFO: epoch 001:  31963 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=31920, lr=4.88326e-05, gnorm=0.958, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152923
2022-10-17 14:06:05 - progress_bar.py[line:274] - INFO: epoch 001:  31973 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.9, ups=0.9, wpb=110.4, bsz=40, num_updates=31930, lr=4.88316e-05, gnorm=1.106, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152934
2022-10-17 14:06:17 - progress_bar.py[line:274] - INFO: epoch 001:  31983 / 102288 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=31940, lr=4.88306e-05, gnorm=0.781, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152946
2022-10-17 14:06:28 - progress_bar.py[line:274] - INFO: epoch 001:  31993 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=31950, lr=4.88296e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=152957
2022-10-17 14:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  32003 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=102.7, ups=0.92, wpb=111.4, bsz=40, num_updates=31960, lr=4.88286e-05, gnorm=0.833, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152968
2022-10-17 14:06:50 - progress_bar.py[line:274] - INFO: epoch 001:  32013 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=31970, lr=4.88276e-05, gnorm=0.883, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=152979
2022-10-17 14:07:01 - progress_bar.py[line:274] - INFO: epoch 001:  32023 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=103.3, ups=0.93, wpb=111.2, bsz=40, num_updates=31980, lr=4.88265e-05, gnorm=1.135, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=152989
2022-10-17 14:07:12 - progress_bar.py[line:274] - INFO: epoch 001:  32033 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=31990, lr=4.88255e-05, gnorm=0.937, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=153001
2022-10-17 14:07:23 - progress_bar.py[line:274] - INFO: epoch 001:  32043 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=32000, lr=4.88245e-05, gnorm=1.076, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=153012
2022-10-17 14:07:23 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 14:07:25 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 14:07:25 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 14:07:42 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.28 GiB (GPU 0; 39.59 GiB total capacity; 8.91 GiB already allocated; 5.95 GiB free; 31.15 GiB reserved in total by PyTorch)
2022-10-17 14:07:42 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 9            |        cudaMalloc retries: 40        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9127 MB |   15444 MB |   22129 TB |   22129 TB |
|       from large pool |    8982 MB |   15299 MB |   22123 TB |   22123 TB |
|       from small pool |     144 MB |     145 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9127 MB |   15444 MB |   22129 TB |   22129 TB |
|       from large pool |    8982 MB |   15299 MB |   22123 TB |   22123 TB |
|       from small pool |     144 MB |     145 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31896 MB |   32150 MB |  388492 MB |  356596 MB |
|       from large pool |   31750 MB |   32002 MB |  387964 MB |  356214 MB |
|       from small pool |     146 MB |     148 MB |     528 MB |     382 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22768 MB |   27329 MB |   23158 TB |   23158 TB |
|       from large pool |   22767 MB |   27327 MB |   23152 TB |   23152 TB |
|       from small pool |       1 MB |       2 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |    1033 M  |    1033 M  |
|       from large pool |     563    |     575    |     330 M  |     330 M  |
|       from small pool |    3106    |    3116    |     703 M  |     703 M  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |    1033 M  |    1033 M  |
|       from large pool |     563    |     575    |     330 M  |     330 M  |
|       from small pool |    3106    |    3116    |     703 M  |     703 M  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     144    |     152    |     801    |     657    |
|       from large pool |      71    |      78    |     537    |     466    |
|       from small pool |      73    |      74    |     264    |     191    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      98    |     109    |  740051 K  |  740051 K  |
|       from large pool |      56    |      63    |  125027 K  |  125027 K  |
|       from small pool |      42    |      55    |  615023 K  |  615023 K  |
|===========================================================================|

2022-10-17 14:07:42 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-17 14:07:42 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-17 14:09:57 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 14:09:57 - train.py[line:551] - INFO: load:1.01 valid_run:152.45 task_valid:147.89 collect_output:2.49
2022-10-17 14:12:25 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 14:12:25 - train.py[line:551] - INFO: load:1.03 valid_run:300.56 task_valid:290.99 collect_output:6.50
2022-10-17 14:14:57 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 14:14:57 - train.py[line:551] - INFO: load:1.06 valid_run:452.26 task_valid:434.26 collect_output:13.91
2022-10-17 14:17:26 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 14:17:26 - train.py[line:551] - INFO: load:1.08 valid_run:600.99 task_valid:579.22 collect_output:16.69
2022-10-17 14:19:58 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 14:19:58 - train.py[line:551] - INFO: load:1.11 valid_run:753.05 task_valid:726.71 collect_output:20.26
2022-10-17 14:22:29 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 14:22:29 - train.py[line:551] - INFO: load:1.13 valid_run:904.47 task_valid:872.23 collect_output:25.14
2022-10-17 14:25:02 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 14:25:02 - train.py[line:551] - INFO: load:1.15 valid_run:1057.45 task_valid:1018.48 collect_output:30.86
2022-10-17 14:27:33 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 14:27:33 - train.py[line:551] - INFO: load:1.18 valid_run:1208.12 task_valid:1159.56 collect_output:39.47
2022-10-17 14:30:03 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 14:30:03 - train.py[line:551] - INFO: load:1.20 valid_run:1357.43 task_valid:1304.25 collect_output:43.11
2022-10-17 14:32:31 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 14:32:31 - train.py[line:551] - INFO: load:1.23 valid_run:1505.74 task_valid:1447.29 collect_output:47.41
2022-10-17 14:35:01 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 14:35:01 - train.py[line:551] - INFO: load:1.25 valid_run:1655.39 task_valid:1592.22 collect_output:51.13
2022-10-17 14:37:31 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 14:37:31 - train.py[line:551] - INFO: load:1.27 valid_run:1805.33 task_valid:1737.40 collect_output:54.90
2022-10-17 14:40:00 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 14:40:00 - train.py[line:551] - INFO: load:1.30 valid_run:1954.85 task_valid:1879.21 collect_output:61.62
2022-10-17 14:42:30 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 14:42:30 - train.py[line:551] - INFO: load:1.32 valid_run:2104.96 task_valid:2024.53 collect_output:65.41
2022-10-17 14:45:00 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 14:45:00 - train.py[line:551] - INFO: load:1.35 valid_run:2254.74 task_valid:2170.82 collect_output:67.91
2022-10-17 14:47:30 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 14:47:30 - train.py[line:551] - INFO: load:1.37 valid_run:2404.48 task_valid:2315.01 collect_output:72.46
2022-10-17 14:50:02 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 14:50:02 - train.py[line:551] - INFO: load:1.41 valid_run:2556.35 task_valid:2460.72 collect_output:77.50
2022-10-17 14:52:33 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 14:52:33 - train.py[line:551] - INFO: load:1.43 valid_run:2707.24 task_valid:2608.08 collect_output:79.95
2022-10-17 14:55:02 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 14:55:02 - train.py[line:551] - INFO: load:1.46 valid_run:2856.12 task_valid:2750.10 collect_output:85.66
2022-10-17 14:57:33 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 14:57:33 - train.py[line:551] - INFO: load:1.48 valid_run:3007.06 task_valid:2895.94 collect_output:89.62
2022-10-17 15:00:05 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 15:00:05 - train.py[line:551] - INFO: load:1.51 valid_run:3159.52 task_valid:3041.05 collect_output:95.83
2022-10-17 15:02:35 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 15:02:35 - train.py[line:551] - INFO: load:1.53 valid_run:3309.26 task_valid:3186.12 collect_output:99.32
2022-10-17 15:05:08 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 15:05:08 - train.py[line:551] - INFO: load:1.56 valid_run:3462.46 task_valid:3334.16 collect_output:103.31
2022-10-17 15:07:41 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 15:07:41 - train.py[line:551] - INFO: load:1.59 valid_run:3614.70 task_valid:3481.47 collect_output:107.09

====================================================================================================
SGG eval:     R @ 50: 0.4497;     R @ 100: 0.4932;     R @ 500: 0.5245;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2764;    mR @ 100: 0.3500;    mR @ 500: 0.3896;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5244) (covered in:0.8750) (covering:0.3714) (eating:0.5294) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6920) (playing:0.0000) (riding:0.6895) (says:0.0000) (sitting on:0.6190) (standing on:0.2333) (using:0.6000) (walking in:0.3333) (walking on:0.2162) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4497;     R @ 100: 0.4932;     R @ 500: 0.5245;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2764;    mR @ 100: 0.3500;    mR @ 500: 0.3896;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5244) (covered in:0.8750) (covering:0.3714) (eating:0.5294) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4839) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6920) (playing:0.0000) (riding:0.6895) (says:0.0000) (sitting on:0.6190) (standing on:0.2333) (using:0.6000) (walking in:0.3333) (walking on:0.2162) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================

2022-10-17 15:10:13 - train.py[line:487] - INFO: 0.49317619047619055
2022-10-17 15:10:13 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 15:10:13 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.349 | loss_v1 0 | loss_v2 0 | nll_loss 0.197 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.493176 | ppl 1.15 | vqa_score 0.4077 | wps 119 | wpb 89.9 | bsz 30 | num_updates 32000 | best_R@100 0.581461
2022-10-17 15:10:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 32000 updates
2022-10-17 15:10:13 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_32000.pt
2022-10-17 15:10:20 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_32000.pt
2022-10-17 15:10:23 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_32000.pt (epoch 1 @ 32000 updates, score 0.49317619047619055) (writing took 9.29536485299468 seconds)
2022-10-17 15:10:34 - progress_bar.py[line:274] - INFO: epoch 001:  32053 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=0.3, ups=0, wpb=109.4, bsz=40, num_updates=32010, lr=4.88235e-05, gnorm=0.861, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=156803
2022-10-17 15:10:45 - progress_bar.py[line:274] - INFO: epoch 001:  32063 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.6, ups=0.9, wpb=109.2, bsz=40, num_updates=32020, lr=4.88225e-05, gnorm=1.044, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=156814
2022-10-17 15:10:56 - progress_bar.py[line:274] - INFO: epoch 001:  32073 / 102288 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.5, ups=0.89, wpb=113, bsz=40, num_updates=32030, lr=4.88214e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=156825
2022-10-17 15:11:08 - progress_bar.py[line:274] - INFO: epoch 001:  32083 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=32040, lr=4.88204e-05, gnorm=0.946, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=156837
2022-10-17 15:11:19 - progress_bar.py[line:274] - INFO: epoch 001:  32093 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=32050, lr=4.88194e-05, gnorm=0.942, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=156848
2022-10-17 15:11:30 - progress_bar.py[line:274] - INFO: epoch 001:  32103 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.6, ups=0.87, wpb=109, bsz=40, num_updates=32060, lr=4.88184e-05, gnorm=0.924, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=156859
2022-10-17 15:11:41 - progress_bar.py[line:274] - INFO: epoch 001:  32113 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=32070, lr=4.88174e-05, gnorm=0.814, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=156870
2022-10-17 15:11:52 - progress_bar.py[line:274] - INFO: epoch 001:  32123 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=103.6, ups=0.93, wpb=111.5, bsz=40, num_updates=32080, lr=4.88164e-05, gnorm=0.724, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=156881
2022-10-17 15:12:03 - progress_bar.py[line:274] - INFO: epoch 001:  32133 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.8, ups=0.89, wpb=111.1, bsz=40, num_updates=32090, lr=4.88153e-05, gnorm=0.895, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=156892
2022-10-17 15:12:15 - progress_bar.py[line:274] - INFO: epoch 001:  32143 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=32100, lr=4.88143e-05, gnorm=0.915, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=156904
2022-10-17 15:12:26 - progress_bar.py[line:274] - INFO: epoch 001:  32153 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.6, ups=0.88, wpb=111.7, bsz=40, num_updates=32110, lr=4.88133e-05, gnorm=0.834, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=156915
2022-10-17 15:12:37 - progress_bar.py[line:274] - INFO: epoch 001:  32163 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.8, ups=0.88, wpb=110.3, bsz=40, num_updates=32120, lr=4.88123e-05, gnorm=0.836, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=156926
2022-10-17 15:12:48 - progress_bar.py[line:274] - INFO: epoch 001:  32173 / 102288 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.4, ups=0.9, wpb=111, bsz=40, num_updates=32130, lr=4.88113e-05, gnorm=0.837, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=156937
2022-10-17 15:13:00 - progress_bar.py[line:274] - INFO: epoch 001:  32183 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.9, ups=0.87, wpb=110.3, bsz=40, num_updates=32140, lr=4.88102e-05, gnorm=1.066, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=156949
2022-10-17 15:13:11 - progress_bar.py[line:274] - INFO: epoch 001:  32193 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.1, ups=0.9, wpb=112.1, bsz=40, num_updates=32150, lr=4.88092e-05, gnorm=0.771, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=156960
2022-10-17 15:13:22 - progress_bar.py[line:274] - INFO: epoch 001:  32203 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=32160, lr=4.88082e-05, gnorm=0.945, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=156971
2022-10-17 15:13:33 - progress_bar.py[line:274] - INFO: epoch 001:  32213 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=32170, lr=4.88072e-05, gnorm=0.811, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=156982
2022-10-17 15:13:44 - progress_bar.py[line:274] - INFO: epoch 001:  32223 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98, ups=0.89, wpb=110.2, bsz=40, num_updates=32180, lr=4.88062e-05, gnorm=0.894, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=156993
2022-10-17 15:13:55 - progress_bar.py[line:274] - INFO: epoch 001:  32233 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=103.5, ups=0.94, wpb=110.1, bsz=40, num_updates=32190, lr=4.88052e-05, gnorm=0.992, clip=50, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=157004
2022-10-17 15:14:06 - progress_bar.py[line:274] - INFO: epoch 001:  32243 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.6, ups=0.89, wpb=110, bsz=40, num_updates=32200, lr=4.88041e-05, gnorm=0.799, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157015
2022-10-17 15:14:18 - progress_bar.py[line:274] - INFO: epoch 001:  32253 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=32210, lr=4.88031e-05, gnorm=0.931, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=157027
2022-10-17 15:14:29 - progress_bar.py[line:274] - INFO: epoch 001:  32263 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.4, ups=0.91, wpb=110, bsz=40, num_updates=32220, lr=4.88021e-05, gnorm=0.869, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157038
2022-10-17 15:14:35 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 15:14:41 - progress_bar.py[line:274] - INFO: epoch 001:  32274 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.81, wpb=110.7, bsz=40, num_updates=32230, lr=4.88011e-05, gnorm=1.001, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=157050
2022-10-17 15:14:52 - progress_bar.py[line:274] - INFO: epoch 001:  32284 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100, ups=0.92, wpb=108.6, bsz=40, num_updates=32240, lr=4.88001e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=157061
2022-10-17 15:15:03 - progress_bar.py[line:274] - INFO: epoch 001:  32294 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.4, ups=0.9, wpb=109.2, bsz=40, num_updates=32250, lr=4.8799e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=157072
2022-10-17 15:15:14 - progress_bar.py[line:274] - INFO: epoch 001:  32304 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=32260, lr=4.8798e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157083
2022-10-17 15:15:25 - progress_bar.py[line:274] - INFO: epoch 001:  32314 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.3, ups=0.87, wpb=109.9, bsz=40, num_updates=32270, lr=4.8797e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157094
2022-10-17 15:15:37 - progress_bar.py[line:274] - INFO: epoch 001:  32324 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.9, ups=0.87, wpb=110.7, bsz=40, num_updates=32280, lr=4.8796e-05, gnorm=0.916, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=157106
2022-10-17 15:15:51 - progress_bar.py[line:274] - INFO: epoch 001:  32334 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=32290, lr=4.8795e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157117
2022-10-17 15:16:02 - progress_bar.py[line:274] - INFO: epoch 001:  32344 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.3, ups=0.9, wpb=110.8, bsz=40, num_updates=32300, lr=4.8794e-05, gnorm=0.99, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=157131
2022-10-17 15:16:13 - progress_bar.py[line:274] - INFO: epoch 001:  32354 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.1, ups=0.92, wpb=110.5, bsz=40, num_updates=32310, lr=4.87929e-05, gnorm=0.996, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157142
2022-10-17 15:16:24 - progress_bar.py[line:274] - INFO: epoch 001:  32364 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=32320, lr=4.87919e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=157153
2022-10-17 15:16:35 - progress_bar.py[line:274] - INFO: epoch 001:  32374 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.7, ups=0.92, wpb=109, bsz=40, num_updates=32330, lr=4.87909e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157164
2022-10-17 15:16:46 - progress_bar.py[line:274] - INFO: epoch 001:  32384 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.8, ups=0.91, wpb=109.2, bsz=40, num_updates=32340, lr=4.87899e-05, gnorm=0.827, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157175
2022-10-17 15:16:57 - progress_bar.py[line:274] - INFO: epoch 001:  32394 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.3, ups=0.88, wpb=109.6, bsz=40, num_updates=32350, lr=4.87889e-05, gnorm=0.792, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=157186
2022-10-17 15:17:09 - progress_bar.py[line:274] - INFO: epoch 001:  32404 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=32360, lr=4.87878e-05, gnorm=1.184, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157197
2022-10-17 15:17:20 - progress_bar.py[line:274] - INFO: epoch 001:  32414 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=32370, lr=4.87868e-05, gnorm=1.002, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157209
2022-10-17 15:17:30 - progress_bar.py[line:274] - INFO: epoch 001:  32424 / 102288 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=105.8, ups=0.95, wpb=111.6, bsz=40, num_updates=32380, lr=4.87858e-05, gnorm=0.822, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157219
2022-10-17 15:17:41 - progress_bar.py[line:274] - INFO: epoch 001:  32434 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.91, wpb=110.3, bsz=40, num_updates=32390, lr=4.87848e-05, gnorm=0.848, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157230
2022-10-17 15:17:52 - progress_bar.py[line:274] - INFO: epoch 001:  32444 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.1, ups=0.92, wpb=109, bsz=40, num_updates=32400, lr=4.87838e-05, gnorm=0.951, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=157241
2022-10-17 15:18:04 - progress_bar.py[line:274] - INFO: epoch 001:  32454 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.5, ups=0.89, wpb=108.9, bsz=40, num_updates=32410, lr=4.87827e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=157253
2022-10-17 15:18:15 - progress_bar.py[line:274] - INFO: epoch 001:  32464 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.7, ups=0.91, wpb=109, bsz=40, num_updates=32420, lr=4.87817e-05, gnorm=0.924, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157264
2022-10-17 15:18:26 - progress_bar.py[line:274] - INFO: epoch 001:  32474 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.6, ups=0.88, wpb=111, bsz=40, num_updates=32430, lr=4.87807e-05, gnorm=1.01, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157275
2022-10-17 15:18:37 - progress_bar.py[line:274] - INFO: epoch 001:  32484 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=32440, lr=4.87797e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157286
2022-10-17 15:18:49 - progress_bar.py[line:274] - INFO: epoch 001:  32494 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.1, ups=0.89, wpb=109.7, bsz=40, num_updates=32450, lr=4.87787e-05, gnorm=0.848, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=157297
2022-10-17 15:18:59 - progress_bar.py[line:274] - INFO: epoch 001:  32504 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.3, ups=0.92, wpb=108.7, bsz=40, num_updates=32460, lr=4.87777e-05, gnorm=1.143, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157308
2022-10-17 15:19:11 - progress_bar.py[line:274] - INFO: epoch 001:  32514 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.7, ups=0.89, wpb=109.5, bsz=40, num_updates=32470, lr=4.87766e-05, gnorm=0.887, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=157320
2022-10-17 15:19:22 - progress_bar.py[line:274] - INFO: epoch 001:  32524 / 102288 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.5, ups=0.92, wpb=109.5, bsz=40, num_updates=32480, lr=4.87756e-05, gnorm=0.753, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157331
2022-10-17 15:19:33 - progress_bar.py[line:274] - INFO: epoch 001:  32534 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=32490, lr=4.87746e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157342
2022-10-17 15:19:44 - progress_bar.py[line:274] - INFO: epoch 001:  32544 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=102.3, ups=0.93, wpb=110.1, bsz=40, num_updates=32500, lr=4.87736e-05, gnorm=1.031, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157353
2022-10-17 15:19:55 - progress_bar.py[line:274] - INFO: epoch 001:  32554 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.1, ups=0.92, wpb=111.4, bsz=40, num_updates=32510, lr=4.87726e-05, gnorm=1.155, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157364
2022-10-17 15:20:06 - progress_bar.py[line:274] - INFO: epoch 001:  32564 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.6, ups=0.89, wpb=109.2, bsz=40, num_updates=32520, lr=4.87715e-05, gnorm=0.954, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157375
2022-10-17 15:20:17 - progress_bar.py[line:274] - INFO: epoch 001:  32574 / 102288 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=102.5, ups=0.92, wpb=111.9, bsz=40, num_updates=32530, lr=4.87705e-05, gnorm=0.883, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157386
2022-10-17 15:20:28 - progress_bar.py[line:274] - INFO: epoch 001:  32584 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.2, ups=0.92, wpb=109.1, bsz=40, num_updates=32540, lr=4.87695e-05, gnorm=1.01, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=157397
2022-10-17 15:20:39 - progress_bar.py[line:274] - INFO: epoch 001:  32594 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.2, ups=0.88, wpb=109.8, bsz=40, num_updates=32550, lr=4.87685e-05, gnorm=1.001, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157408
2022-10-17 15:20:51 - progress_bar.py[line:274] - INFO: epoch 001:  32604 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.3, ups=0.88, wpb=109.1, bsz=40, num_updates=32560, lr=4.87675e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157420
2022-10-17 15:21:02 - progress_bar.py[line:274] - INFO: epoch 001:  32614 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=32570, lr=4.87665e-05, gnorm=0.863, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157431
2022-10-17 15:21:13 - progress_bar.py[line:274] - INFO: epoch 001:  32624 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.89, wpb=110.8, bsz=40, num_updates=32580, lr=4.87654e-05, gnorm=1.121, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=157442
2022-10-17 15:21:24 - progress_bar.py[line:274] - INFO: epoch 001:  32634 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.2, ups=0.88, wpb=109, bsz=40, num_updates=32590, lr=4.87644e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157453
2022-10-17 15:21:36 - progress_bar.py[line:274] - INFO: epoch 001:  32644 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=32600, lr=4.87634e-05, gnorm=1.179, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157465
2022-10-17 15:21:47 - progress_bar.py[line:274] - INFO: epoch 001:  32654 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.4, ups=0.9, wpb=110.4, bsz=40, num_updates=32610, lr=4.87624e-05, gnorm=1.045, clip=50, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=157476
2022-10-17 15:21:58 - progress_bar.py[line:274] - INFO: epoch 001:  32664 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101, ups=0.92, wpb=110.1, bsz=40, num_updates=32620, lr=4.87614e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157487
2022-10-17 15:22:09 - progress_bar.py[line:274] - INFO: epoch 001:  32674 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.4, ups=0.89, wpb=109.1, bsz=40, num_updates=32630, lr=4.87603e-05, gnorm=0.892, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=157498
2022-10-17 15:22:20 - progress_bar.py[line:274] - INFO: epoch 001:  32684 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=32640, lr=4.87593e-05, gnorm=1.013, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157509
2022-10-17 15:22:32 - progress_bar.py[line:274] - INFO: epoch 001:  32694 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.1, ups=0.88, wpb=109.8, bsz=40, num_updates=32650, lr=4.87583e-05, gnorm=0.963, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157520
2022-10-17 15:22:43 - progress_bar.py[line:274] - INFO: epoch 001:  32704 / 102288 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=32660, lr=4.87573e-05, gnorm=0.87, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157532
2022-10-17 15:22:54 - progress_bar.py[line:274] - INFO: epoch 001:  32714 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.8, ups=0.91, wpb=109.1, bsz=40, num_updates=32670, lr=4.87563e-05, gnorm=1.015, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157543
2022-10-17 15:23:05 - progress_bar.py[line:274] - INFO: epoch 001:  32724 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=32680, lr=4.87553e-05, gnorm=0.837, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=157554
2022-10-17 15:23:16 - progress_bar.py[line:274] - INFO: epoch 001:  32734 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=32690, lr=4.87542e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157565
2022-10-17 15:23:28 - progress_bar.py[line:274] - INFO: epoch 001:  32744 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=32700, lr=4.87532e-05, gnorm=1.113, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157577
2022-10-17 15:23:39 - progress_bar.py[line:274] - INFO: epoch 001:  32754 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=32710, lr=4.87522e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157588
2022-10-17 15:23:50 - progress_bar.py[line:274] - INFO: epoch 001:  32764 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=32720, lr=4.87512e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157599
2022-10-17 15:24:02 - progress_bar.py[line:274] - INFO: epoch 001:  32774 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96, ups=0.87, wpb=110.8, bsz=40, num_updates=32730, lr=4.87502e-05, gnorm=0.952, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=157610
2022-10-17 15:24:13 - progress_bar.py[line:274] - INFO: epoch 001:  32784 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.2, ups=0.92, wpb=108.2, bsz=40, num_updates=32740, lr=4.87491e-05, gnorm=0.89, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157622
2022-10-17 15:24:25 - progress_bar.py[line:274] - INFO: epoch 001:  32794 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=32750, lr=4.87481e-05, gnorm=0.885, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157633
2022-10-17 15:24:36 - progress_bar.py[line:274] - INFO: epoch 001:  32804 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.9, ups=0.88, wpb=108.6, bsz=40, num_updates=32760, lr=4.87471e-05, gnorm=0.959, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157645
2022-10-17 15:24:47 - progress_bar.py[line:274] - INFO: epoch 001:  32814 / 102288 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.4, ups=0.9, wpb=111.3, bsz=40, num_updates=32770, lr=4.87461e-05, gnorm=0.822, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157656
2022-10-17 15:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  32824 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.8, ups=0.89, wpb=109.5, bsz=40, num_updates=32780, lr=4.87451e-05, gnorm=0.948, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=157667
2022-10-17 15:25:09 - progress_bar.py[line:274] - INFO: epoch 001:  32834 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=32790, lr=4.87441e-05, gnorm=0.842, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=157678
2022-10-17 15:25:20 - progress_bar.py[line:274] - INFO: epoch 001:  32844 / 102288 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.7, ups=0.92, wpb=110.7, bsz=40, num_updates=32800, lr=4.8743e-05, gnorm=1.018, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157689
2022-10-17 15:25:32 - progress_bar.py[line:274] - INFO: epoch 001:  32854 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.2, ups=0.87, wpb=109.4, bsz=40, num_updates=32810, lr=4.8742e-05, gnorm=1.126, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157701
2022-10-17 15:25:43 - progress_bar.py[line:274] - INFO: epoch 001:  32864 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=32820, lr=4.8741e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=157712
2022-10-17 15:25:54 - progress_bar.py[line:274] - INFO: epoch 001:  32874 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.9, ups=0.88, wpb=108.8, bsz=40, num_updates=32830, lr=4.874e-05, gnorm=0.925, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157723
2022-10-17 15:26:06 - progress_bar.py[line:274] - INFO: epoch 001:  32884 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=32840, lr=4.8739e-05, gnorm=0.992, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157735
2022-10-17 15:26:17 - progress_bar.py[line:274] - INFO: epoch 001:  32894 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.7, ups=0.91, wpb=110.2, bsz=40, num_updates=32850, lr=4.87379e-05, gnorm=0.899, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157746
2022-10-17 15:26:28 - progress_bar.py[line:274] - INFO: epoch 001:  32904 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=32860, lr=4.87369e-05, gnorm=0.944, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157757
2022-10-17 15:26:39 - progress_bar.py[line:274] - INFO: epoch 001:  32914 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=32870, lr=4.87359e-05, gnorm=1.106, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157768
2022-10-17 15:26:50 - progress_bar.py[line:274] - INFO: epoch 001:  32924 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=32880, lr=4.87349e-05, gnorm=0.962, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=157779
2022-10-17 15:27:01 - progress_bar.py[line:274] - INFO: epoch 001:  32934 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.5, ups=0.92, wpb=109.8, bsz=40, num_updates=32890, lr=4.87339e-05, gnorm=0.931, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157790
2022-10-17 15:27:13 - progress_bar.py[line:274] - INFO: epoch 001:  32944 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=94.7, ups=0.87, wpb=108.8, bsz=40, num_updates=32900, lr=4.87328e-05, gnorm=1.064, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157802
2022-10-17 15:27:24 - progress_bar.py[line:274] - INFO: epoch 001:  32954 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.1, ups=0.9, wpb=108.5, bsz=40, num_updates=32910, lr=4.87318e-05, gnorm=1.128, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157813
2022-10-17 15:27:36 - progress_bar.py[line:274] - INFO: epoch 001:  32964 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.8, ups=0.88, wpb=109.7, bsz=40, num_updates=32920, lr=4.87308e-05, gnorm=0.996, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157824
2022-10-17 15:27:47 - progress_bar.py[line:274] - INFO: epoch 001:  32974 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=32930, lr=4.87298e-05, gnorm=0.926, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157836
2022-10-17 15:27:58 - progress_bar.py[line:274] - INFO: epoch 001:  32984 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=32940, lr=4.87288e-05, gnorm=0.942, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=157847
2022-10-17 15:28:10 - progress_bar.py[line:274] - INFO: epoch 001:  32994 / 102288 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=32950, lr=4.87278e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157859
2022-10-17 15:28:21 - progress_bar.py[line:274] - INFO: epoch 001:  33004 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98, ups=0.89, wpb=110.7, bsz=40, num_updates=32960, lr=4.87267e-05, gnorm=0.99, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157870
2022-10-17 15:28:32 - progress_bar.py[line:274] - INFO: epoch 001:  33014 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=32970, lr=4.87257e-05, gnorm=0.992, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157881
2022-10-17 15:28:43 - progress_bar.py[line:274] - INFO: epoch 001:  33024 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.6, ups=0.93, wpb=110.7, bsz=40, num_updates=32980, lr=4.87247e-05, gnorm=0.773, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157892
2022-10-17 15:28:54 - progress_bar.py[line:274] - INFO: epoch 001:  33034 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.4, ups=0.89, wpb=109.9, bsz=40, num_updates=32990, lr=4.87237e-05, gnorm=1.011, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157903
2022-10-17 15:29:05 - progress_bar.py[line:274] - INFO: epoch 001:  33044 / 102288 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.7, ups=0.91, wpb=110.9, bsz=40, num_updates=33000, lr=4.87227e-05, gnorm=1.037, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=157914
2022-10-17 15:29:05 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 15:29:07 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 15:29:07 - train.py[line:551] - INFO: load:1.30 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 15:31:39 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 15:31:39 - train.py[line:551] - INFO: load:1.33 valid_run:152.46 task_valid:149.28 collect_output:2.18
2022-10-17 15:34:07 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 15:34:07 - train.py[line:551] - INFO: load:1.35 valid_run:300.43 task_valid:292.26 collect_output:6.18
2022-10-17 15:36:39 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 15:36:39 - train.py[line:551] - INFO: load:1.38 valid_run:451.92 task_valid:435.41 collect_output:13.50
2022-10-17 15:39:08 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 15:39:08 - train.py[line:551] - INFO: load:1.40 valid_run:600.60 task_valid:580.39 collect_output:16.21
2022-10-17 15:41:40 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 15:41:40 - train.py[line:551] - INFO: load:1.43 valid_run:752.89 task_valid:728.11 collect_output:19.76
2022-10-17 15:44:11 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 15:44:11 - train.py[line:551] - INFO: load:1.45 valid_run:904.08 task_valid:873.69 collect_output:24.35
2022-10-17 15:46:44 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 15:46:44 - train.py[line:551] - INFO: load:1.48 valid_run:1056.56 task_valid:1019.75 collect_output:29.72
2022-10-17 15:49:14 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 15:49:14 - train.py[line:551] - INFO: load:1.50 valid_run:1207.11 task_valid:1160.99 collect_output:38.04
2022-10-17 15:51:44 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 15:51:44 - train.py[line:551] - INFO: load:1.53 valid_run:1356.65 task_valid:1305.97 collect_output:41.57
2022-10-17 15:54:12 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 15:54:12 - train.py[line:551] - INFO: load:1.55 valid_run:1504.83 task_valid:1449.14 collect_output:45.57
2022-10-17 15:56:42 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 15:56:42 - train.py[line:551] - INFO: load:1.58 valid_run:1654.28 task_valid:1594.09 collect_output:49.05
2022-10-17 15:59:11 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 15:59:11 - train.py[line:551] - INFO: load:1.61 valid_run:1803.87 task_valid:1739.06 collect_output:52.67
2022-10-17 16:01:41 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 16:01:41 - train.py[line:551] - INFO: load:1.63 valid_run:1953.45 task_valid:1881.03 collect_output:59.19
2022-10-17 16:04:12 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 16:04:12 - train.py[line:551] - INFO: load:1.66 valid_run:2104.67 task_valid:2027.35 collect_output:62.92
2022-10-17 16:06:43 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 16:06:43 - train.py[line:551] - INFO: load:1.69 valid_run:2255.06 task_valid:2174.30 collect_output:65.20
2022-10-17 16:09:13 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 16:09:13 - train.py[line:551] - INFO: load:1.71 valid_run:2405.22 task_valid:2318.97 collect_output:69.55
2022-10-17 16:11:45 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 16:11:45 - train.py[line:551] - INFO: load:1.74 valid_run:2556.84 task_valid:2464.91 collect_output:74.10
2022-10-17 16:14:16 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 16:14:16 - train.py[line:551] - INFO: load:1.76 valid_run:2707.94 task_valid:2612.43 collect_output:76.52
2022-10-17 16:16:45 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 16:16:45 - train.py[line:551] - INFO: load:1.79 valid_run:2857.07 task_valid:2754.53 collect_output:82.44
2022-10-17 16:19:16 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 16:19:16 - train.py[line:551] - INFO: load:1.82 valid_run:3008.44 task_valid:2900.04 collect_output:87.09
2022-10-17 16:21:50 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 16:21:50 - train.py[line:551] - INFO: load:1.84 valid_run:3161.65 task_valid:3045.17 collect_output:94.06
2022-10-17 16:24:20 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 16:24:20 - train.py[line:551] - INFO: load:1.87 valid_run:3312.28 task_valid:3190.69 collect_output:98.02
2022-10-17 16:26:52 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 16:26:52 - train.py[line:551] - INFO: load:1.90 valid_run:3463.98 task_valid:3337.90 collect_output:101.34
2022-10-17 16:29:24 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 16:29:24 - train.py[line:551] - INFO: load:1.92 valid_run:3615.72 task_valid:3485.17 collect_output:104.65

====================================================================================================
SGG eval:     R @ 50: 0.4520;     R @ 100: 0.4948;     R @ 500: 0.5233;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2805;    mR @ 100: 0.3514;    mR @ 500: 0.3884;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5488) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4516) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6771) (playing:0.0000) (riding:0.7042) (says:0.0000) (sitting on:0.6176) (standing on:0.2233) (using:0.6500) (walking in:0.3333) (walking on:0.2252) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2022-10-17 16:31:55 - train.py[line:487] - INFO: 0.4948285714285714
2022-10-17 16:31:55 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.4520;     R @ 100: 0.4948;     R @ 500: 0.5233;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2805;    mR @ 100: 0.3514;    mR @ 500: 0.3884;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5488) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4516) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6771) (playing:0.0000) (riding:0.7042) (says:0.0000) (sitting on:0.6176) (standing on:0.2233) (using:0.6500) (walking in:0.3333) (walking on:0.2252) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2022-10-17 16:31:55 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.351 | loss_v1 0 | loss_v2 0 | nll_loss 0.197 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.494829 | ppl 1.15 | vqa_score 0.4043 | wps 119 | wpb 89.9 | bsz 30 | num_updates 33000 | best_R@100 0.581461
2022-10-17 16:31:55 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 33000 updates
2022-10-17 16:31:55 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_33000.pt
2022-10-17 16:32:01 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_33000.pt
2022-10-17 16:32:04 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_33000.pt (epoch 1 @ 33000 updates, score 0.4948285714285714) (writing took 8.63131888024509 seconds)
2022-10-17 16:32:15 - progress_bar.py[line:274] - INFO: epoch 001:  33054 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=0.3, ups=0, wpb=111.9, bsz=40, num_updates=33010, lr=4.87216e-05, gnorm=1.055, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=161704
2022-10-17 16:32:27 - progress_bar.py[line:274] - INFO: epoch 001:  33064 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.8, ups=0.88, wpb=109.5, bsz=40, num_updates=33020, lr=4.87206e-05, gnorm=0.906, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=161716
2022-10-17 16:32:38 - progress_bar.py[line:274] - INFO: epoch 001:  33074 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=33030, lr=4.87196e-05, gnorm=0.787, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=161727
2022-10-17 16:32:49 - progress_bar.py[line:274] - INFO: epoch 001:  33084 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.9, ups=0.87, wpb=110.3, bsz=40, num_updates=33040, lr=4.87186e-05, gnorm=0.962, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=161738
2022-10-17 16:33:00 - progress_bar.py[line:274] - INFO: epoch 001:  33094 / 102288 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=33050, lr=4.87176e-05, gnorm=0.944, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=161749
2022-10-17 16:33:12 - progress_bar.py[line:274] - INFO: epoch 001:  33104 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.5, ups=0.9, wpb=112.5, bsz=40, num_updates=33060, lr=4.87166e-05, gnorm=0.875, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=161760
2022-10-17 16:33:23 - progress_bar.py[line:274] - INFO: epoch 001:  33114 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.2, ups=0.87, wpb=109.4, bsz=40, num_updates=33070, lr=4.87155e-05, gnorm=0.985, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=161772
2022-10-17 16:33:34 - progress_bar.py[line:274] - INFO: epoch 001:  33124 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101, ups=0.92, wpb=110.2, bsz=40, num_updates=33080, lr=4.87145e-05, gnorm=0.843, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=161783
2022-10-17 16:33:45 - progress_bar.py[line:274] - INFO: epoch 001:  33134 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.7, ups=0.93, wpb=109.8, bsz=40, num_updates=33090, lr=4.87135e-05, gnorm=1.028, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=161794
2022-10-17 16:33:56 - progress_bar.py[line:274] - INFO: epoch 001:  33144 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=33100, lr=4.87125e-05, gnorm=0.864, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=161805
2022-10-17 16:34:07 - progress_bar.py[line:274] - INFO: epoch 001:  33154 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=33110, lr=4.87115e-05, gnorm=0.929, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=161816
2022-10-17 16:34:18 - progress_bar.py[line:274] - INFO: epoch 001:  33164 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.3, ups=0.9, wpb=108.8, bsz=40, num_updates=33120, lr=4.87104e-05, gnorm=0.733, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=161827
2022-10-17 16:34:29 - progress_bar.py[line:274] - INFO: epoch 001:  33174 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=33130, lr=4.87094e-05, gnorm=0.953, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=161838
2022-10-17 16:34:40 - progress_bar.py[line:274] - INFO: epoch 001:  33184 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=33140, lr=4.87084e-05, gnorm=0.97, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=161849
2022-10-17 16:34:52 - progress_bar.py[line:274] - INFO: epoch 001:  33194 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.4, ups=0.89, wpb=109.2, bsz=40, num_updates=33150, lr=4.87074e-05, gnorm=0.882, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=161861
2022-10-17 16:35:03 - progress_bar.py[line:274] - INFO: epoch 001:  33204 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=33160, lr=4.87064e-05, gnorm=0.851, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=161872
2022-10-17 16:35:14 - progress_bar.py[line:274] - INFO: epoch 001:  33214 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=102.6, ups=0.93, wpb=110.6, bsz=40, num_updates=33170, lr=4.87054e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=161883
2022-10-17 16:35:25 - progress_bar.py[line:274] - INFO: epoch 001:  33224 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.4, ups=0.87, wpb=108.9, bsz=40, num_updates=33180, lr=4.87043e-05, gnorm=1.013, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=161894
2022-10-17 16:35:36 - progress_bar.py[line:274] - INFO: epoch 001:  33234 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.7, ups=0.92, wpb=109.8, bsz=40, num_updates=33190, lr=4.87033e-05, gnorm=0.92, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=161905
2022-10-17 16:35:48 - progress_bar.py[line:274] - INFO: epoch 001:  33244 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.3, ups=0.86, wpb=109.9, bsz=40, num_updates=33200, lr=4.87023e-05, gnorm=0.926, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=161917
2022-10-17 16:35:59 - progress_bar.py[line:274] - INFO: epoch 001:  33254 / 102288 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.9, ups=0.87, wpb=110.1, bsz=40, num_updates=33210, lr=4.87013e-05, gnorm=0.829, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=161928
2022-10-17 16:36:11 - progress_bar.py[line:274] - INFO: epoch 001:  33264 / 102288 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.7, ups=0.89, wpb=112, bsz=40, num_updates=33220, lr=4.87003e-05, gnorm=0.926, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=161939
2022-10-17 16:36:22 - progress_bar.py[line:274] - INFO: epoch 001:  33274 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.9, ups=0.89, wpb=109.2, bsz=40, num_updates=33230, lr=4.86992e-05, gnorm=0.944, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=161951
2022-10-17 16:36:33 - progress_bar.py[line:274] - INFO: epoch 001:  33284 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=33240, lr=4.86982e-05, gnorm=0.96, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=161962
2022-10-17 16:36:44 - progress_bar.py[line:274] - INFO: epoch 001:  33294 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=33250, lr=4.86972e-05, gnorm=0.931, clip=30, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=161973
2022-10-17 16:36:56 - progress_bar.py[line:274] - INFO: epoch 001:  33304 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.1, ups=0.87, wpb=110.4, bsz=40, num_updates=33260, lr=4.86962e-05, gnorm=1.178, clip=60, loss_scale=2048, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=161985
2022-10-17 16:37:01 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-17 16:37:08 - progress_bar.py[line:274] - INFO: epoch 001:  33315 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=90.5, ups=0.83, wpb=109.6, bsz=40, num_updates=33270, lr=4.86952e-05, gnorm=0.989, clip=50, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=161997
2022-10-17 16:37:19 - progress_bar.py[line:274] - INFO: epoch 001:  33325 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=33280, lr=4.86942e-05, gnorm=1.108, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162008
2022-10-17 16:37:30 - progress_bar.py[line:274] - INFO: epoch 001:  33335 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=33290, lr=4.86931e-05, gnorm=0.803, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162019
2022-10-17 16:37:41 - progress_bar.py[line:274] - INFO: epoch 001:  33345 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.4, ups=0.91, wpb=111.7, bsz=40, num_updates=33300, lr=4.86921e-05, gnorm=1.029, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162030
2022-10-17 16:37:53 - progress_bar.py[line:274] - INFO: epoch 001:  33355 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=33310, lr=4.86911e-05, gnorm=0.841, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162042
2022-10-17 16:38:04 - progress_bar.py[line:274] - INFO: epoch 001:  33365 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=33320, lr=4.86901e-05, gnorm=0.829, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162053
2022-10-17 16:38:15 - progress_bar.py[line:274] - INFO: epoch 001:  33375 / 102288 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=33330, lr=4.86891e-05, gnorm=0.796, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162064
2022-10-17 16:38:26 - progress_bar.py[line:274] - INFO: epoch 001:  33385 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.4, ups=0.88, wpb=112, bsz=40, num_updates=33340, lr=4.8688e-05, gnorm=0.943, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162075
2022-10-17 16:38:38 - progress_bar.py[line:274] - INFO: epoch 001:  33395 / 102288 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=33350, lr=4.8687e-05, gnorm=0.969, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=162087
2022-10-17 16:38:49 - progress_bar.py[line:274] - INFO: epoch 001:  33405 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=33360, lr=4.8686e-05, gnorm=0.958, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162098
2022-10-17 16:39:00 - progress_bar.py[line:274] - INFO: epoch 001:  33415 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=103.6, ups=0.93, wpb=111, bsz=40, num_updates=33370, lr=4.8685e-05, gnorm=0.924, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162109
2022-10-17 16:39:11 - progress_bar.py[line:274] - INFO: epoch 001:  33425 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=33380, lr=4.8684e-05, gnorm=0.889, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162120
2022-10-17 16:39:22 - progress_bar.py[line:274] - INFO: epoch 001:  33435 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.7, ups=0.88, wpb=109.5, bsz=40, num_updates=33390, lr=4.86829e-05, gnorm=1.123, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162131
2022-10-17 16:39:34 - progress_bar.py[line:274] - INFO: epoch 001:  33445 / 102288 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=33400, lr=4.86819e-05, gnorm=0.844, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=162142
2022-10-17 16:39:45 - progress_bar.py[line:274] - INFO: epoch 001:  33455 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=33410, lr=4.86809e-05, gnorm=0.872, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162154
2022-10-17 16:39:56 - progress_bar.py[line:274] - INFO: epoch 001:  33465 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101, ups=0.93, wpb=109.1, bsz=40, num_updates=33420, lr=4.86799e-05, gnorm=0.834, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162165
2022-10-17 16:40:07 - progress_bar.py[line:274] - INFO: epoch 001:  33475 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=33430, lr=4.86789e-05, gnorm=1.088, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162176
2022-10-17 16:40:18 - progress_bar.py[line:274] - INFO: epoch 001:  33485 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.6, ups=0.88, wpb=109.8, bsz=40, num_updates=33440, lr=4.86779e-05, gnorm=0.842, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162187
2022-10-17 16:40:30 - progress_bar.py[line:274] - INFO: epoch 001:  33495 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.8, ups=0.87, wpb=110.3, bsz=40, num_updates=33450, lr=4.86768e-05, gnorm=0.968, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=162199
2022-10-17 16:40:41 - progress_bar.py[line:274] - INFO: epoch 001:  33505 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.3, ups=0.9, wpb=111.1, bsz=40, num_updates=33460, lr=4.86758e-05, gnorm=0.821, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162210
2022-10-17 16:40:52 - progress_bar.py[line:274] - INFO: epoch 001:  33515 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.9, wpb=109.6, bsz=40, num_updates=33470, lr=4.86748e-05, gnorm=0.921, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=162221
2022-10-17 16:41:03 - progress_bar.py[line:274] - INFO: epoch 001:  33525 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=33480, lr=4.86738e-05, gnorm=0.904, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162232
2022-10-17 16:41:14 - progress_bar.py[line:274] - INFO: epoch 001:  33535 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.7, ups=0.89, wpb=109.5, bsz=40, num_updates=33490, lr=4.86728e-05, gnorm=0.838, clip=30, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=162243
2022-10-17 16:41:26 - progress_bar.py[line:274] - INFO: epoch 001:  33545 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=33500, lr=4.86717e-05, gnorm=0.848, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=162255
2022-10-17 16:41:37 - progress_bar.py[line:274] - INFO: epoch 001:  33555 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.9, ups=0.9, wpb=109.4, bsz=40, num_updates=33510, lr=4.86707e-05, gnorm=0.943, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=162266
2022-10-17 16:41:48 - progress_bar.py[line:274] - INFO: epoch 001:  33565 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.3, ups=0.88, wpb=110.8, bsz=40, num_updates=33520, lr=4.86697e-05, gnorm=0.969, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162277
2022-10-17 16:42:00 - progress_bar.py[line:274] - INFO: epoch 001:  33575 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=33530, lr=4.86687e-05, gnorm=1.052, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162289
2022-10-17 16:42:11 - progress_bar.py[line:274] - INFO: epoch 001:  33585 / 102288 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.8, ups=0.88, wpb=110.9, bsz=40, num_updates=33540, lr=4.86677e-05, gnorm=0.908, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162300
2022-10-17 16:42:22 - progress_bar.py[line:274] - INFO: epoch 001:  33595 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=33550, lr=4.86667e-05, gnorm=0.817, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162311
2022-10-17 16:42:33 - progress_bar.py[line:274] - INFO: epoch 001:  33605 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101, ups=0.9, wpb=111.8, bsz=40, num_updates=33560, lr=4.86656e-05, gnorm=0.874, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162322
2022-10-17 16:42:44 - progress_bar.py[line:274] - INFO: epoch 001:  33615 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.9, wpb=109.9, bsz=40, num_updates=33570, lr=4.86646e-05, gnorm=0.996, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162333
2022-10-17 16:42:55 - progress_bar.py[line:274] - INFO: epoch 001:  33625 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=104, ups=0.93, wpb=111.7, bsz=40, num_updates=33580, lr=4.86636e-05, gnorm=0.784, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=162344
2022-10-17 16:43:06 - progress_bar.py[line:274] - INFO: epoch 001:  33635 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=33590, lr=4.86626e-05, gnorm=0.909, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162355
2022-10-17 16:43:17 - progress_bar.py[line:274] - INFO: epoch 001:  33645 / 102288 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=106.5, ups=0.95, wpb=111.6, bsz=40, num_updates=33600, lr=4.86616e-05, gnorm=0.982, clip=40, loss_scale=1024, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=162366
2022-10-17 16:43:28 - progress_bar.py[line:274] - INFO: epoch 001:  33655 / 102288 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=33610, lr=4.86605e-05, gnorm=0.802, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=162377
2022-10-17 16:43:39 - progress_bar.py[line:274] - INFO: epoch 001:  33665 / 102288 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=33620, lr=4.86595e-05, gnorm=0.916, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162388
2022-10-17 16:43:51 - progress_bar.py[line:274] - INFO: epoch 001:  33675 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.2, ups=0.88, wpb=109.3, bsz=40, num_updates=33630, lr=4.86585e-05, gnorm=0.861, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162400
2022-10-17 16:44:02 - progress_bar.py[line:274] - INFO: epoch 001:  33685 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.2, ups=0.89, wpb=111.5, bsz=40, num_updates=33640, lr=4.86575e-05, gnorm=0.911, clip=30, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=162411
2022-10-17 16:44:13 - progress_bar.py[line:274] - INFO: epoch 001:  33695 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.4, ups=0.91, wpb=109.8, bsz=40, num_updates=33650, lr=4.86565e-05, gnorm=0.823, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162422
2022-10-17 16:44:24 - progress_bar.py[line:274] - INFO: epoch 001:  33705 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.9, ups=0.91, wpb=110.3, bsz=40, num_updates=33660, lr=4.86555e-05, gnorm=0.978, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=162433
2022-10-17 16:44:35 - progress_bar.py[line:274] - INFO: epoch 001:  33715 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.1, ups=0.91, wpb=110.6, bsz=40, num_updates=33670, lr=4.86544e-05, gnorm=0.991, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162444
2022-10-17 16:44:46 - progress_bar.py[line:274] - INFO: epoch 001:  33725 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=33680, lr=4.86534e-05, gnorm=0.898, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162455
2022-10-17 16:44:58 - progress_bar.py[line:274] - INFO: epoch 001:  33735 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=33690, lr=4.86524e-05, gnorm=0.85, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162466
2022-10-17 16:45:09 - progress_bar.py[line:274] - INFO: epoch 001:  33745 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.4, ups=0.89, wpb=108.9, bsz=40, num_updates=33700, lr=4.86514e-05, gnorm=1.027, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162478
2022-10-17 16:45:20 - progress_bar.py[line:274] - INFO: epoch 001:  33755 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=33710, lr=4.86504e-05, gnorm=0.964, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162489
2022-10-17 16:45:32 - progress_bar.py[line:274] - INFO: epoch 001:  33765 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=33720, lr=4.86493e-05, gnorm=0.997, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162501
2022-10-17 16:45:43 - progress_bar.py[line:274] - INFO: epoch 001:  33775 / 102288 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.5, ups=0.87, wpb=111, bsz=40, num_updates=33730, lr=4.86483e-05, gnorm=0.859, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162512
2022-10-17 16:45:54 - progress_bar.py[line:274] - INFO: epoch 001:  33785 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=102.8, ups=0.92, wpb=112, bsz=40, num_updates=33740, lr=4.86473e-05, gnorm=0.905, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162523
2022-10-17 16:46:05 - progress_bar.py[line:274] - INFO: epoch 001:  33795 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=102, ups=0.92, wpb=111.1, bsz=40, num_updates=33750, lr=4.86463e-05, gnorm=1.022, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162534
2022-10-17 16:46:16 - progress_bar.py[line:274] - INFO: epoch 001:  33805 / 102288 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=103, ups=0.93, wpb=110.6, bsz=40, num_updates=33760, lr=4.86453e-05, gnorm=0.899, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162545
2022-10-17 16:46:27 - progress_bar.py[line:274] - INFO: epoch 001:  33815 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.2, ups=0.91, wpb=111.7, bsz=40, num_updates=33770, lr=4.86443e-05, gnorm=1.03, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162556
2022-10-17 16:46:38 - progress_bar.py[line:274] - INFO: epoch 001:  33825 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.3, ups=0.93, wpb=109.5, bsz=40, num_updates=33780, lr=4.86432e-05, gnorm=0.896, clip=20, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162567
2022-10-17 16:46:39 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-17 16:46:50 - progress_bar.py[line:274] - INFO: epoch 001:  33836 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=88.5, ups=0.81, wpb=109.7, bsz=40, num_updates=33790, lr=4.86422e-05, gnorm=1.039, clip=50, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=162579
2022-10-17 16:47:01 - progress_bar.py[line:274] - INFO: epoch 001:  33846 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=33800, lr=4.86412e-05, gnorm=0.919, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162590
2022-10-17 16:47:12 - progress_bar.py[line:274] - INFO: epoch 001:  33856 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=33810, lr=4.86402e-05, gnorm=0.906, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162601
2022-10-17 16:47:23 - progress_bar.py[line:274] - INFO: epoch 001:  33866 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.9, ups=0.89, wpb=110.5, bsz=40, num_updates=33820, lr=4.86392e-05, gnorm=0.945, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162612
2022-10-17 16:47:35 - progress_bar.py[line:274] - INFO: epoch 001:  33876 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.6, ups=0.9, wpb=110.2, bsz=40, num_updates=33830, lr=4.86381e-05, gnorm=0.892, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162624
2022-10-17 16:47:46 - progress_bar.py[line:274] - INFO: epoch 001:  33886 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=33840, lr=4.86371e-05, gnorm=0.881, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162635
2022-10-17 16:47:57 - progress_bar.py[line:274] - INFO: epoch 001:  33896 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=33850, lr=4.86361e-05, gnorm=0.894, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162646
2022-10-17 16:48:08 - progress_bar.py[line:274] - INFO: epoch 001:  33906 / 102288 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=33860, lr=4.86351e-05, gnorm=1.006, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=162657
2022-10-17 16:48:20 - progress_bar.py[line:274] - INFO: epoch 001:  33916 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=33870, lr=4.86341e-05, gnorm=0.887, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162669
2022-10-17 16:48:31 - progress_bar.py[line:274] - INFO: epoch 001:  33926 / 102288 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97, ups=0.87, wpb=111.8, bsz=40, num_updates=33880, lr=4.8633e-05, gnorm=0.962, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=162680
2022-10-17 16:48:42 - progress_bar.py[line:274] - INFO: epoch 001:  33936 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=33890, lr=4.8632e-05, gnorm=1.017, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=162691
2022-10-17 16:48:54 - progress_bar.py[line:274] - INFO: epoch 001:  33946 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.2, ups=0.87, wpb=109.6, bsz=40, num_updates=33900, lr=4.8631e-05, gnorm=0.938, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162703
2022-10-17 16:49:05 - progress_bar.py[line:274] - INFO: epoch 001:  33956 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=33910, lr=4.863e-05, gnorm=1.014, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162714
2022-10-17 16:49:16 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 16:49:17 - progress_bar.py[line:274] - INFO: epoch 001:  33967 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=93, ups=0.84, wpb=111, bsz=40, num_updates=33920, lr=4.8629e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=162726
2022-10-17 16:49:28 - progress_bar.py[line:274] - INFO: epoch 001:  33977 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=33930, lr=4.8628e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162737
2022-10-17 16:49:40 - progress_bar.py[line:274] - INFO: epoch 001:  33987 / 102288 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.3, ups=0.87, wpb=111.5, bsz=40, num_updates=33940, lr=4.86269e-05, gnorm=1.031, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162749
2022-10-17 16:49:51 - progress_bar.py[line:274] - INFO: epoch 001:  33997 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.2, ups=0.9, wpb=110.8, bsz=40, num_updates=33950, lr=4.86259e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=162760
2022-10-17 16:50:02 - progress_bar.py[line:274] - INFO: epoch 001:  34007 / 102288 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=33960, lr=4.86249e-05, gnorm=1.04, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162771
2022-10-17 16:50:13 - progress_bar.py[line:274] - INFO: epoch 001:  34017 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99, ups=0.9, wpb=109.4, bsz=40, num_updates=33970, lr=4.86239e-05, gnorm=0.952, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162782
2022-10-17 16:50:24 - progress_bar.py[line:274] - INFO: epoch 001:  34027 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.3, ups=0.87, wpb=110.7, bsz=40, num_updates=33980, lr=4.86229e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=162793
2022-10-17 16:50:36 - progress_bar.py[line:274] - INFO: epoch 001:  34037 / 102288 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=33990, lr=4.86218e-05, gnorm=1.053, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=162805
2022-10-17 16:50:47 - progress_bar.py[line:274] - INFO: epoch 001:  34047 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.5, ups=0.9, wpb=109.3, bsz=40, num_updates=34000, lr=4.86208e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=162816
2022-10-17 16:50:47 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 16:50:48 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 16:50:48 - train.py[line:551] - INFO: load:0.98 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 16:53:20 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 16:53:20 - train.py[line:551] - INFO: load:1.00 valid_run:151.70 task_valid:147.99 collect_output:2.68
2022-10-17 16:55:48 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 16:55:48 - train.py[line:551] - INFO: load:1.03 valid_run:300.10 task_valid:291.40 collect_output:6.58
2022-10-17 16:58:20 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 16:58:20 - train.py[line:551] - INFO: load:1.05 valid_run:452.00 task_valid:434.93 collect_output:13.87
2022-10-17 17:00:49 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 17:00:49 - train.py[line:551] - INFO: load:1.08 valid_run:600.89 task_valid:580.11 collect_output:16.53
2022-10-17 17:03:21 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 17:03:21 - train.py[line:551] - INFO: load:1.10 valid_run:752.68 task_valid:727.49 collect_output:19.94
2022-10-17 17:05:53 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 17:05:53 - train.py[line:551] - INFO: load:1.13 valid_run:904.34 task_valid:873.35 collect_output:24.72
2022-10-17 17:08:26 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 17:08:26 - train.py[line:551] - INFO: load:1.15 valid_run:1057.10 task_valid:1019.74 collect_output:30.03
2022-10-17 17:10:56 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 17:10:56 - train.py[line:551] - INFO: load:1.18 valid_run:1207.80 task_valid:1160.96 collect_output:38.51
2022-10-17 17:13:26 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 17:13:26 - train.py[line:551] - INFO: load:1.20 valid_run:1357.51 task_valid:1306.10 collect_output:41.99
2022-10-17 17:15:55 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 17:15:55 - train.py[line:551] - INFO: load:1.23 valid_run:1506.32 task_valid:1449.91 collect_output:45.89
2022-10-17 17:18:26 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 17:18:26 - train.py[line:551] - INFO: load:1.26 valid_run:1657.03 task_valid:1595.93 collect_output:49.45
2022-10-17 17:20:56 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 17:20:56 - train.py[line:551] - INFO: load:1.29 valid_run:1807.45 task_valid:1741.65 collect_output:52.99
2022-10-17 17:23:26 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 17:23:26 - train.py[line:551] - INFO: load:1.32 valid_run:1957.34 task_valid:1884.06 collect_output:59.35
2022-10-17 17:25:57 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 17:25:57 - train.py[line:551] - INFO: load:1.34 valid_run:2108.46 task_valid:2030.44 collect_output:62.92
2022-10-17 17:28:28 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 17:28:28 - train.py[line:551] - INFO: load:1.37 valid_run:2259.20 task_valid:2177.61 collect_output:65.35
2022-10-17 17:30:59 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 17:30:59 - train.py[line:551] - INFO: load:1.39 valid_run:2409.60 task_valid:2322.67 collect_output:69.53
2022-10-17 17:33:30 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 17:33:30 - train.py[line:551] - INFO: load:1.42 valid_run:2561.20 task_valid:2468.57 collect_output:74.12
2022-10-17 17:36:01 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 17:36:01 - train.py[line:551] - INFO: load:1.45 valid_run:2712.00 task_valid:2615.96 collect_output:76.38
2022-10-17 17:38:30 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 17:38:30 - train.py[line:551] - INFO: load:1.49 valid_run:2860.64 task_valid:2758.38 collect_output:81.43
2022-10-17 17:41:01 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 17:41:01 - train.py[line:551] - INFO: load:1.51 valid_run:3011.42 task_valid:2904.37 collect_output:85.08
2022-10-17 17:43:33 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 17:43:33 - train.py[line:551] - INFO: load:1.54 valid_run:3163.88 task_valid:3049.87 collect_output:90.86
2022-10-17 17:46:02 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 17:46:02 - train.py[line:551] - INFO: load:1.56 valid_run:3312.87 task_valid:3194.51 collect_output:94.21
2022-10-17 17:48:33 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 17:48:33 - train.py[line:551] - INFO: load:1.59 valid_run:3463.77 task_valid:3340.72 collect_output:97.90
2022-10-17 17:51:05 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 17:51:05 - train.py[line:551] - INFO: load:1.61 valid_run:3615.31 task_valid:3487.55 collect_output:101.59

====================================================================================================
SGG eval:     R @ 50: 0.4440;     R @ 100: 0.4928;     R @ 500: 0.5191;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2927;    mR @ 100: 0.3653;    mR @ 500: 0.3942;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5488) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4194) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6771) (playing:0.0000) (riding:0.6748) (says:0.0000) (sitting on:0.6329) (standing on:0.2233) (using:0.6000) (walking in:0.6667) (walking on:0.2252) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4440;     R @ 100: 0.4928;     R @ 500: 0.5191;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2927;    mR @ 100: 0.3653;    mR @ 500: 0.3942;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5488) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4194) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6771) (playing:0.0000) (riding:0.6748) (says:0.0000) (sitting on:0.6329) (standing on:0.2233) (using:0.6000) (walking in:0.6667) (walking on:0.2252) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================

2022-10-17 17:53:36 - train.py[line:487] - INFO: 0.49282857142857145
2022-10-17 17:53:36 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 17:53:36 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.351 | loss_v1 0 | loss_v2 0 | nll_loss 0.196 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.492829 | ppl 1.15 | vqa_score 0.3998 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 34000 | best_R@100 0.581461
2022-10-17 17:53:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 34000 updates
2022-10-17 17:53:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_34000.pt
2022-10-17 17:53:42 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_34000.pt
2022-10-17 17:53:44 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_34000.pt (epoch 1 @ 34000 updates, score 0.49282857142857145) (writing took 8.210988116916269 seconds)
2022-10-17 17:53:56 - progress_bar.py[line:274] - INFO: epoch 001:  34057 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=0.3, ups=0, wpb=111.9, bsz=40, num_updates=34010, lr=4.86198e-05, gnorm=0.95, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=166605
2022-10-17 17:54:08 - progress_bar.py[line:274] - INFO: epoch 001:  34067 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.4, ups=0.87, wpb=110, bsz=40, num_updates=34020, lr=4.86188e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=166617
2022-10-17 17:54:19 - progress_bar.py[line:274] - INFO: epoch 001:  34077 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=34030, lr=4.86178e-05, gnorm=0.962, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166628
2022-10-17 17:54:30 - progress_bar.py[line:274] - INFO: epoch 001:  34087 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.1, ups=0.88, wpb=109.3, bsz=40, num_updates=34040, lr=4.86168e-05, gnorm=0.944, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=166639
2022-10-17 17:54:42 - progress_bar.py[line:274] - INFO: epoch 001:  34097 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=34050, lr=4.86157e-05, gnorm=1.046, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=166651
2022-10-17 17:54:53 - progress_bar.py[line:274] - INFO: epoch 001:  34107 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=34060, lr=4.86147e-05, gnorm=1.035, clip=60, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=166662
2022-10-17 17:55:04 - progress_bar.py[line:274] - INFO: epoch 001:  34117 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=34070, lr=4.86137e-05, gnorm=0.951, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166673
2022-10-17 17:55:15 - progress_bar.py[line:274] - INFO: epoch 001:  34127 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.2, ups=0.91, wpb=109.5, bsz=40, num_updates=34080, lr=4.86127e-05, gnorm=1.015, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=166684
2022-10-17 17:55:27 - progress_bar.py[line:274] - INFO: epoch 001:  34137 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96, ups=0.87, wpb=110.1, bsz=40, num_updates=34090, lr=4.86117e-05, gnorm=0.997, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166696
2022-10-17 17:55:38 - progress_bar.py[line:274] - INFO: epoch 001:  34147 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.92, wpb=109.2, bsz=40, num_updates=34100, lr=4.86106e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=166707
2022-10-17 17:55:48 - progress_bar.py[line:274] - INFO: epoch 001:  34157 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=103.4, ups=0.93, wpb=111.4, bsz=40, num_updates=34110, lr=4.86096e-05, gnorm=0.979, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=166717
2022-10-17 17:56:00 - progress_bar.py[line:274] - INFO: epoch 001:  34167 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=34120, lr=4.86086e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166729
2022-10-17 17:56:11 - progress_bar.py[line:274] - INFO: epoch 001:  34177 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=34130, lr=4.86076e-05, gnorm=0.845, clip=20, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=166740
2022-10-17 17:56:22 - progress_bar.py[line:274] - INFO: epoch 001:  34187 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=34140, lr=4.86066e-05, gnorm=1.097, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166751
2022-10-17 17:56:33 - progress_bar.py[line:274] - INFO: epoch 001:  34197 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=34150, lr=4.86056e-05, gnorm=1.003, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=166762
2022-10-17 17:56:44 - progress_bar.py[line:274] - INFO: epoch 001:  34207 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=34160, lr=4.86045e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166773
2022-10-17 17:56:55 - progress_bar.py[line:274] - INFO: epoch 001:  34217 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.1, ups=0.91, wpb=109.4, bsz=40, num_updates=34170, lr=4.86035e-05, gnorm=0.896, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=166784
2022-10-17 17:57:06 - progress_bar.py[line:274] - INFO: epoch 001:  34227 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.6, ups=0.93, wpb=109.5, bsz=40, num_updates=34180, lr=4.86025e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=166795
2022-10-17 17:57:17 - progress_bar.py[line:274] - INFO: epoch 001:  34237 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=34190, lr=4.86015e-05, gnorm=1.012, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166806
2022-10-17 17:57:28 - progress_bar.py[line:274] - INFO: epoch 001:  34247 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.8, ups=0.9, wpb=110, bsz=40, num_updates=34200, lr=4.86005e-05, gnorm=0.753, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166817
2022-10-17 17:57:40 - progress_bar.py[line:274] - INFO: epoch 001:  34257 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=34210, lr=4.85994e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=166829
2022-10-17 17:57:51 - progress_bar.py[line:274] - INFO: epoch 001:  34267 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=34220, lr=4.85984e-05, gnorm=0.992, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166840
2022-10-17 17:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  34277 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97, ups=0.89, wpb=108.7, bsz=40, num_updates=34230, lr=4.85974e-05, gnorm=0.962, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=166851
2022-10-17 17:58:13 - progress_bar.py[line:274] - INFO: epoch 001:  34287 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.91, wpb=108.6, bsz=40, num_updates=34240, lr=4.85964e-05, gnorm=0.912, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=166862
2022-10-17 17:58:24 - progress_bar.py[line:274] - INFO: epoch 001:  34297 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=34250, lr=4.85954e-05, gnorm=0.893, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166873
2022-10-17 17:58:36 - progress_bar.py[line:274] - INFO: epoch 001:  34307 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.7, ups=0.9, wpb=111.5, bsz=40, num_updates=34260, lr=4.85944e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=166885
2022-10-17 17:58:47 - progress_bar.py[line:274] - INFO: epoch 001:  34317 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=34270, lr=4.85933e-05, gnorm=0.978, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=166896
2022-10-17 17:58:58 - progress_bar.py[line:274] - INFO: epoch 001:  34327 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.3, ups=0.87, wpb=109.4, bsz=40, num_updates=34280, lr=4.85923e-05, gnorm=1.02, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=166907
2022-10-17 17:59:09 - progress_bar.py[line:274] - INFO: epoch 001:  34337 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.7, ups=0.89, wpb=108.5, bsz=40, num_updates=34290, lr=4.85913e-05, gnorm=1.011, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=166918
2022-10-17 17:59:20 - progress_bar.py[line:274] - INFO: epoch 001:  34347 / 102288 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=34300, lr=4.85903e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166929
2022-10-17 17:59:32 - progress_bar.py[line:274] - INFO: epoch 001:  34357 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=34310, lr=4.85893e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=166941
2022-10-17 17:59:43 - progress_bar.py[line:274] - INFO: epoch 001:  34367 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=34320, lr=4.85882e-05, gnorm=1.032, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=166952
2022-10-17 17:59:54 - progress_bar.py[line:274] - INFO: epoch 001:  34377 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=34330, lr=4.85872e-05, gnorm=0.841, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=166963
2022-10-17 18:00:05 - progress_bar.py[line:274] - INFO: epoch 001:  34387 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=34340, lr=4.85862e-05, gnorm=0.858, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=166974
2022-10-17 18:00:16 - progress_bar.py[line:274] - INFO: epoch 001:  34397 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=34350, lr=4.85852e-05, gnorm=0.965, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=166985
2022-10-17 18:00:28 - progress_bar.py[line:274] - INFO: epoch 001:  34407 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.6, ups=0.9, wpb=109.4, bsz=40, num_updates=34360, lr=4.85842e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=166997
2022-10-17 18:00:39 - progress_bar.py[line:274] - INFO: epoch 001:  34417 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=34370, lr=4.85831e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167007
2022-10-17 18:00:50 - progress_bar.py[line:274] - INFO: epoch 001:  34427 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.8, ups=0.87, wpb=111.3, bsz=40, num_updates=34380, lr=4.85821e-05, gnorm=0.888, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167019
2022-10-17 18:01:01 - progress_bar.py[line:274] - INFO: epoch 001:  34437 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=34390, lr=4.85811e-05, gnorm=0.986, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167030
2022-10-17 18:01:13 - progress_bar.py[line:274] - INFO: epoch 001:  34447 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=34400, lr=4.85801e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167042
2022-10-17 18:01:24 - progress_bar.py[line:274] - INFO: epoch 001:  34457 / 102288 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=101.5, ups=0.9, wpb=112.4, bsz=40, num_updates=34410, lr=4.85791e-05, gnorm=0.924, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167053
2022-10-17 18:01:35 - progress_bar.py[line:274] - INFO: epoch 001:  34467 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97, ups=0.87, wpb=111.7, bsz=40, num_updates=34420, lr=4.85781e-05, gnorm=0.886, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167064
2022-10-17 18:01:47 - progress_bar.py[line:274] - INFO: epoch 001:  34477 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.1, ups=0.88, wpb=111.6, bsz=40, num_updates=34430, lr=4.8577e-05, gnorm=0.898, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167076
2022-10-17 18:01:58 - progress_bar.py[line:274] - INFO: epoch 001:  34487 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101, ups=0.91, wpb=111.4, bsz=40, num_updates=34440, lr=4.8576e-05, gnorm=0.772, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167087
2022-10-17 18:02:09 - progress_bar.py[line:274] - INFO: epoch 001:  34497 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.3, ups=0.9, wpb=109.7, bsz=40, num_updates=34450, lr=4.8575e-05, gnorm=0.901, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=167098
2022-10-17 18:02:20 - progress_bar.py[line:274] - INFO: epoch 001:  34507 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=102.4, ups=0.92, wpb=111.6, bsz=40, num_updates=34460, lr=4.8574e-05, gnorm=0.964, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167109
2022-10-17 18:02:31 - progress_bar.py[line:274] - INFO: epoch 001:  34517 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=34470, lr=4.8573e-05, gnorm=0.969, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167120
2022-10-17 18:02:42 - progress_bar.py[line:274] - INFO: epoch 001:  34527 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=103, ups=0.94, wpb=109.5, bsz=40, num_updates=34480, lr=4.85719e-05, gnorm=1.084, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167131
2022-10-17 18:02:53 - progress_bar.py[line:274] - INFO: epoch 001:  34537 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.1, ups=0.89, wpb=109.8, bsz=40, num_updates=34490, lr=4.85709e-05, gnorm=0.899, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167142
2022-10-17 18:03:04 - progress_bar.py[line:274] - INFO: epoch 001:  34547 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=34500, lr=4.85699e-05, gnorm=0.84, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167153
2022-10-17 18:03:15 - progress_bar.py[line:274] - INFO: epoch 001:  34557 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.1, ups=0.92, wpb=108.1, bsz=40, num_updates=34510, lr=4.85689e-05, gnorm=1.081, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167164
2022-10-17 18:03:26 - progress_bar.py[line:274] - INFO: epoch 001:  34567 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.4, ups=0.89, wpb=108.3, bsz=40, num_updates=34520, lr=4.85679e-05, gnorm=1.109, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167175
2022-10-17 18:03:37 - progress_bar.py[line:274] - INFO: epoch 001:  34577 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=34530, lr=4.85669e-05, gnorm=1.061, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167186
2022-10-17 18:03:48 - progress_bar.py[line:274] - INFO: epoch 001:  34587 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=34540, lr=4.85658e-05, gnorm=1.01, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167197
2022-10-17 18:03:59 - progress_bar.py[line:274] - INFO: epoch 001:  34597 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.3, ups=0.93, wpb=110.2, bsz=40, num_updates=34550, lr=4.85648e-05, gnorm=0.962, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167208
2022-10-17 18:04:10 - progress_bar.py[line:274] - INFO: epoch 001:  34607 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=34560, lr=4.85638e-05, gnorm=1.031, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=167219
2022-10-17 18:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  34617 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=34570, lr=4.85628e-05, gnorm=1.114, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167230
2022-10-17 18:04:33 - progress_bar.py[line:274] - INFO: epoch 001:  34627 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=34580, lr=4.85618e-05, gnorm=0.869, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167242
2022-10-17 18:04:44 - progress_bar.py[line:274] - INFO: epoch 001:  34637 / 102288 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=34590, lr=4.85607e-05, gnorm=0.894, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167253
2022-10-17 18:04:55 - progress_bar.py[line:274] - INFO: epoch 001:  34647 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=102.2, ups=0.93, wpb=110.2, bsz=40, num_updates=34600, lr=4.85597e-05, gnorm=0.861, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=167264
2022-10-17 18:05:06 - progress_bar.py[line:274] - INFO: epoch 001:  34657 / 102288 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=34610, lr=4.85587e-05, gnorm=0.843, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=167275
2022-10-17 18:05:17 - progress_bar.py[line:274] - INFO: epoch 001:  34667 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=34620, lr=4.85577e-05, gnorm=0.983, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167286
2022-10-17 18:05:28 - progress_bar.py[line:274] - INFO: epoch 001:  34677 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99, ups=0.91, wpb=108.3, bsz=40, num_updates=34630, lr=4.85567e-05, gnorm=0.78, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167297
2022-10-17 18:05:39 - progress_bar.py[line:274] - INFO: epoch 001:  34687 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=34640, lr=4.85557e-05, gnorm=0.859, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167308
2022-10-17 18:05:51 - progress_bar.py[line:274] - INFO: epoch 001:  34697 / 102288 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=34650, lr=4.85546e-05, gnorm=0.92, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167320
2022-10-17 18:06:02 - progress_bar.py[line:274] - INFO: epoch 001:  34707 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=34660, lr=4.85536e-05, gnorm=1.021, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167331
2022-10-17 18:06:13 - progress_bar.py[line:274] - INFO: epoch 001:  34717 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=34670, lr=4.85526e-05, gnorm=0.896, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167342
2022-10-17 18:06:24 - progress_bar.py[line:274] - INFO: epoch 001:  34727 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=34680, lr=4.85516e-05, gnorm=1.061, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167353
2022-10-17 18:06:35 - progress_bar.py[line:274] - INFO: epoch 001:  34737 / 102288 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.4, ups=0.89, wpb=112.4, bsz=40, num_updates=34690, lr=4.85506e-05, gnorm=0.9, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167364
2022-10-17 18:06:46 - progress_bar.py[line:274] - INFO: epoch 001:  34747 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.4, ups=0.92, wpb=111.8, bsz=40, num_updates=34700, lr=4.85495e-05, gnorm=0.903, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167375
2022-10-17 18:06:57 - progress_bar.py[line:274] - INFO: epoch 001:  34757 / 102288 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=34710, lr=4.85485e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=167386
2022-10-17 18:07:09 - progress_bar.py[line:274] - INFO: epoch 001:  34767 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=34720, lr=4.85475e-05, gnorm=0.932, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=167398
2022-10-17 18:07:20 - progress_bar.py[line:274] - INFO: epoch 001:  34777 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.7, ups=0.87, wpb=110.2, bsz=40, num_updates=34730, lr=4.85465e-05, gnorm=0.918, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167409
2022-10-17 18:07:31 - progress_bar.py[line:274] - INFO: epoch 001:  34787 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.2, ups=0.92, wpb=109.4, bsz=40, num_updates=34740, lr=4.85455e-05, gnorm=0.965, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=167420
2022-10-17 18:07:42 - progress_bar.py[line:274] - INFO: epoch 001:  34797 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.1, ups=0.89, wpb=109.8, bsz=40, num_updates=34750, lr=4.85445e-05, gnorm=0.83, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167431
2022-10-17 18:07:53 - progress_bar.py[line:274] - INFO: epoch 001:  34807 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=34760, lr=4.85434e-05, gnorm=0.835, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167442
2022-10-17 18:08:05 - progress_bar.py[line:274] - INFO: epoch 001:  34817 / 102288 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=34770, lr=4.85424e-05, gnorm=0.715, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=167454
2022-10-17 18:08:16 - progress_bar.py[line:274] - INFO: epoch 001:  34827 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.6, ups=0.9, wpb=111.3, bsz=40, num_updates=34780, lr=4.85414e-05, gnorm=1.027, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167465
2022-10-17 18:08:27 - progress_bar.py[line:274] - INFO: epoch 001:  34837 / 102288 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=34790, lr=4.85404e-05, gnorm=0.776, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=167476
2022-10-17 18:08:38 - progress_bar.py[line:274] - INFO: epoch 001:  34847 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=34800, lr=4.85394e-05, gnorm=0.861, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=167487
2022-10-17 18:08:49 - progress_bar.py[line:274] - INFO: epoch 001:  34857 / 102288 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=102, ups=0.92, wpb=111.3, bsz=40, num_updates=34810, lr=4.85383e-05, gnorm=0.901, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167498
2022-10-17 18:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  34867 / 102288 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.5, ups=0.92, wpb=110.3, bsz=40, num_updates=34820, lr=4.85373e-05, gnorm=0.924, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167509
2022-10-17 18:09:11 - progress_bar.py[line:274] - INFO: epoch 001:  34877 / 102288 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=34830, lr=4.85363e-05, gnorm=0.929, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167520
2022-10-17 18:09:22 - progress_bar.py[line:274] - INFO: epoch 001:  34887 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.5, ups=0.9, wpb=110.1, bsz=40, num_updates=34840, lr=4.85353e-05, gnorm=0.889, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167531
2022-10-17 18:09:34 - progress_bar.py[line:274] - INFO: epoch 001:  34897 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.9, ups=0.87, wpb=110.3, bsz=40, num_updates=34850, lr=4.85343e-05, gnorm=1.042, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167543
2022-10-17 18:09:45 - progress_bar.py[line:274] - INFO: epoch 001:  34907 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.6, ups=0.87, wpb=110.2, bsz=40, num_updates=34860, lr=4.85332e-05, gnorm=1.092, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167554
2022-10-17 18:09:57 - progress_bar.py[line:274] - INFO: epoch 001:  34917 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=34870, lr=4.85322e-05, gnorm=1.067, clip=60, loss_scale=1024, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=167566
2022-10-17 18:10:08 - progress_bar.py[line:274] - INFO: epoch 001:  34927 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=34880, lr=4.85312e-05, gnorm=0.849, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=167577
2022-10-17 18:10:19 - progress_bar.py[line:274] - INFO: epoch 001:  34937 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=34890, lr=4.85302e-05, gnorm=0.978, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167588
2022-10-17 18:10:30 - progress_bar.py[line:274] - INFO: epoch 001:  34947 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=34900, lr=4.85292e-05, gnorm=0.913, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167599
2022-10-17 18:10:41 - progress_bar.py[line:274] - INFO: epoch 001:  34957 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.3, ups=0.88, wpb=109, bsz=40, num_updates=34910, lr=4.85282e-05, gnorm=0.962, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=167610
2022-10-17 18:10:52 - progress_bar.py[line:274] - INFO: epoch 001:  34967 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=34920, lr=4.85271e-05, gnorm=0.952, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167621
2022-10-17 18:11:04 - progress_bar.py[line:274] - INFO: epoch 001:  34977 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=34930, lr=4.85261e-05, gnorm=1.21, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=167633
2022-10-17 18:11:15 - progress_bar.py[line:274] - INFO: epoch 001:  34987 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.1, ups=0.91, wpb=110.3, bsz=40, num_updates=34940, lr=4.85251e-05, gnorm=1.211, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167644
2022-10-17 18:11:26 - progress_bar.py[line:274] - INFO: epoch 001:  34997 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.3, ups=0.9, wpb=111.1, bsz=40, num_updates=34950, lr=4.85241e-05, gnorm=0.979, clip=40, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167655
2022-10-17 18:11:30 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-17 18:11:38 - progress_bar.py[line:274] - INFO: epoch 001:  35008 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.1, ups=0.81, wpb=110.3, bsz=40, num_updates=34960, lr=4.85231e-05, gnorm=0.765, clip=20, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=167667
2022-10-17 18:11:50 - progress_bar.py[line:274] - INFO: epoch 001:  35018 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.3, ups=0.89, wpb=109, bsz=40, num_updates=34970, lr=4.8522e-05, gnorm=0.91, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=167679
2022-10-17 18:12:00 - progress_bar.py[line:274] - INFO: epoch 001:  35028 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.9, ups=0.92, wpb=107.9, bsz=40, num_updates=34980, lr=4.8521e-05, gnorm=1.016, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=167689
2022-10-17 18:12:12 - progress_bar.py[line:274] - INFO: epoch 001:  35038 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=34990, lr=4.852e-05, gnorm=0.857, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167701
2022-10-17 18:12:23 - progress_bar.py[line:274] - INFO: epoch 001:  35048 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=35000, lr=4.8519e-05, gnorm=0.984, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=167712
2022-10-17 18:12:23 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 18:12:24 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 18:12:24 - train.py[line:551] - INFO: load:1.00 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 18:12:25 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 39.59 GiB total capacity; 8.39 GiB already allocated; 2.05 GiB free; 35.05 GiB reserved in total by PyTorch)
2022-10-17 18:12:25 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 10           |        cudaMalloc retries: 45        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8590 MB |    9723 MB |   24252 TB |   24252 TB |
|       from large pool |    8446 MB |    9578 MB |   24245 TB |   24245 TB |
|       from small pool |     144 MB |     145 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8590 MB |    9723 MB |   24252 TB |   24252 TB |
|       from large pool |    8446 MB |    9578 MB |   24245 TB |   24245 TB |
|       from small pool |     144 MB |     145 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   35892 MB |   36130 MB |  430150 MB |  394258 MB |
|       from large pool |   35746 MB |   35978 MB |  429586 MB |  393840 MB |
|       from small pool |     146 MB |     152 MB |     564 MB |     418 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   27301 MB |   27301 MB |   25628 TB |   25628 TB |
|       from large pool |   27299 MB |   27299 MB |   25621 TB |   25621 TB |
|       from small pool |       1 MB |       1 MB |       7 TB |       7 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |    1133 M  |    1133 M  |
|       from large pool |     563    |     575    |     361 M  |     361 M  |
|       from small pool |    3095    |    3114    |     771 M  |     771 M  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |    1133 M  |    1133 M  |
|       from large pool |     563    |     575    |     361 M  |     361 M  |
|       from small pool |    3095    |    3114    |     771 M  |     771 M  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     141    |     145    |     857    |     716    |
|       from large pool |      68    |      69    |     575    |     507    |
|       from small pool |      73    |      76    |     282    |     209    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     110    |     113    |     810 M  |     810 M  |
|       from large pool |      70    |      71    |     136 M  |     136 M  |
|       from small pool |      40    |      47    |     674 M  |     674 M  |
|===========================================================================|

2022-10-17 18:12:25 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-17 18:12:25 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-17 18:14:56 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 18:14:56 - train.py[line:551] - INFO: load:1.02 valid_run:152.29 task_valid:148.02 collect_output:2.27
2022-10-17 18:17:24 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 18:17:24 - train.py[line:551] - INFO: load:1.05 valid_run:300.17 task_valid:291.15 collect_output:6.00
2022-10-17 18:19:56 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 18:19:56 - train.py[line:551] - INFO: load:1.07 valid_run:452.25 task_valid:434.54 collect_output:13.66
2022-10-17 18:22:25 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 18:22:25 - train.py[line:551] - INFO: load:1.10 valid_run:601.03 task_valid:579.57 collect_output:16.38
2022-10-17 18:24:58 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 18:24:58 - train.py[line:551] - INFO: load:1.12 valid_run:753.19 task_valid:727.12 collect_output:19.95
2022-10-17 18:27:29 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 18:27:29 - train.py[line:551] - INFO: load:1.15 valid_run:904.54 task_valid:872.73 collect_output:24.65
2022-10-17 18:30:02 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 18:30:02 - train.py[line:551] - INFO: load:1.18 valid_run:1057.38 task_valid:1019.21 collect_output:29.94
2022-10-17 18:32:33 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 18:32:33 - train.py[line:551] - INFO: load:1.20 valid_run:1208.45 task_valid:1160.98 collect_output:38.12
2022-10-17 18:35:03 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 18:35:03 - train.py[line:551] - INFO: load:1.23 valid_run:1358.73 task_valid:1306.64 collect_output:41.54
2022-10-17 18:37:32 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 18:37:32 - train.py[line:551] - INFO: load:1.25 valid_run:1507.28 task_valid:1450.15 collect_output:45.45
2022-10-17 18:40:02 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 18:40:02 - train.py[line:551] - INFO: load:1.28 valid_run:1657.30 task_valid:1595.72 collect_output:48.80
2022-10-17 18:42:32 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 18:42:32 - train.py[line:551] - INFO: load:1.31 valid_run:1807.48 task_valid:1741.33 collect_output:52.18
2022-10-17 18:45:02 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 18:45:02 - train.py[line:551] - INFO: load:1.33 valid_run:1957.56 task_valid:1883.84 collect_output:58.64
2022-10-17 18:47:33 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 18:47:33 - train.py[line:551] - INFO: load:1.37 valid_run:2108.35 task_valid:2029.92 collect_output:62.21
2022-10-17 18:50:04 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 18:50:04 - train.py[line:551] - INFO: load:1.40 valid_run:2258.89 task_valid:2177.11 collect_output:64.41
2022-10-17 18:52:34 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 18:52:34 - train.py[line:551] - INFO: load:1.42 valid_run:2409.23 task_valid:2322.22 collect_output:68.58
2022-10-17 18:55:06 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 18:55:06 - train.py[line:551] - INFO: load:1.45 valid_run:2561.09 task_valid:2468.35 collect_output:73.19
2022-10-17 18:57:37 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 18:57:37 - train.py[line:551] - INFO: load:1.47 valid_run:2712.11 task_valid:2615.92 collect_output:75.58
2022-10-17 19:00:05 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 19:00:05 - train.py[line:551] - INFO: load:1.50 valid_run:2860.26 task_valid:2757.66 collect_output:80.99
2022-10-17 19:02:36 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 19:02:36 - train.py[line:551] - INFO: load:1.53 valid_run:3010.36 task_valid:2902.83 collect_output:84.87
2022-10-17 19:05:07 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 19:05:07 - train.py[line:551] - INFO: load:1.55 valid_run:3162.10 task_valid:3047.54 collect_output:90.89
2022-10-17 19:07:37 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 19:07:37 - train.py[line:551] - INFO: load:1.58 valid_run:3311.49 task_valid:3192.31 collect_output:94.49
2022-10-17 19:10:08 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 19:10:08 - train.py[line:551] - INFO: load:1.60 valid_run:3462.42 task_valid:3338.53 collect_output:98.19
2022-10-17 19:12:39 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 19:12:39 - train.py[line:551] - INFO: load:1.63 valid_run:3613.59 task_valid:3485.10 collect_output:101.75

====================================================================================================
SGG eval:     R @ 50: 0.4430;     R @ 100: 0.4871;     R @ 500: 0.5153;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2924;    mR @ 100: 0.3603;    mR @ 500: 0.3916;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5488) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4032) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6443) (playing:0.0000) (riding:0.6748) (says:0.0000) (sitting on:0.6304) (standing on:0.2233) (using:0.5500) (walking in:0.6667) (walking on:0.2252) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================

2022-10-17 19:15:10 - train.py[line:487] - INFO: 0.4870571428571428

====================================================================================================
SGG eval:     R @ 50: 0.4430;     R @ 100: 0.4871;     R @ 500: 0.5153;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2924;    mR @ 100: 0.3603;    mR @ 500: 0.3916;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5488) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4032) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6443) (playing:0.0000) (riding:0.6748) (says:0.0000) (sitting on:0.6304) (standing on:0.2233) (using:0.5500) (walking in:0.6667) (walking on:0.2252) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================

2022-10-17 19:15:10 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 19:15:10 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.349 | loss_v1 0 | loss_v2 0 | nll_loss 0.192 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.487057 | ppl 1.14 | vqa_score 0.3941 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 35000 | best_R@100 0.581461
2022-10-17 19:15:10 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 35000 updates
2022-10-17 19:15:10 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_35000.pt
2022-10-17 19:15:16 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_35000.pt
2022-10-17 19:15:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_35000.pt (epoch 1 @ 35000 updates, score 0.4870571428571428) (writing took 8.246284761000425 seconds)
2022-10-17 19:15:30 - progress_bar.py[line:274] - INFO: epoch 001:  35058 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=0.3, ups=0, wpb=108.4, bsz=40, num_updates=35010, lr=4.8518e-05, gnorm=1.159, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171498
2022-10-17 19:15:41 - progress_bar.py[line:274] - INFO: epoch 001:  35068 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.5, ups=0.89, wpb=109.2, bsz=40, num_updates=35020, lr=4.8517e-05, gnorm=1.071, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=171510
2022-10-17 19:15:52 - progress_bar.py[line:274] - INFO: epoch 001:  35078 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=35030, lr=4.85159e-05, gnorm=1.159, clip=90, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=171521
2022-10-17 19:16:03 - progress_bar.py[line:274] - INFO: epoch 001:  35088 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.4, ups=0.89, wpb=109.2, bsz=40, num_updates=35040, lr=4.85149e-05, gnorm=1.21, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=171532
2022-10-17 19:16:14 - progress_bar.py[line:274] - INFO: epoch 001:  35098 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.3, ups=0.92, wpb=110.5, bsz=40, num_updates=35050, lr=4.85139e-05, gnorm=0.969, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171543
2022-10-17 19:16:25 - progress_bar.py[line:274] - INFO: epoch 001:  35108 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.8, ups=0.92, wpb=109.1, bsz=40, num_updates=35060, lr=4.85129e-05, gnorm=0.918, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=171554
2022-10-17 19:16:36 - progress_bar.py[line:274] - INFO: epoch 001:  35118 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.3, ups=0.88, wpb=109.2, bsz=40, num_updates=35070, lr=4.85119e-05, gnorm=0.925, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=171565
2022-10-17 19:16:47 - progress_bar.py[line:274] - INFO: epoch 001:  35128 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.3, ups=0.91, wpb=109.7, bsz=40, num_updates=35080, lr=4.85108e-05, gnorm=0.917, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171576
2022-10-17 19:16:58 - progress_bar.py[line:274] - INFO: epoch 001:  35138 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=35090, lr=4.85098e-05, gnorm=0.998, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171587
2022-10-17 19:17:10 - progress_bar.py[line:274] - INFO: epoch 001:  35148 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=35100, lr=4.85088e-05, gnorm=0.863, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=171599
2022-10-17 19:17:21 - progress_bar.py[line:274] - INFO: epoch 001:  35158 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.3, ups=0.9, wpb=109.7, bsz=40, num_updates=35110, lr=4.85078e-05, gnorm=0.943, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=171610
2022-10-17 19:17:31 - progress_bar.py[line:274] - INFO: epoch 001:  35168 / 102288 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=102.1, ups=0.93, wpb=110.2, bsz=40, num_updates=35120, lr=4.85068e-05, gnorm=0.857, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171620
2022-10-17 19:17:43 - progress_bar.py[line:274] - INFO: epoch 001:  35178 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.5, ups=0.9, wpb=110.6, bsz=40, num_updates=35130, lr=4.85058e-05, gnorm=0.965, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=171632
2022-10-17 19:17:54 - progress_bar.py[line:274] - INFO: epoch 001:  35188 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=35140, lr=4.85047e-05, gnorm=1.223, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171643
2022-10-17 19:18:05 - progress_bar.py[line:274] - INFO: epoch 001:  35198 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=102.3, ups=0.92, wpb=111.8, bsz=40, num_updates=35150, lr=4.85037e-05, gnorm=0.979, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171654
2022-10-17 19:18:16 - progress_bar.py[line:274] - INFO: epoch 001:  35208 / 102288 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=101.8, ups=0.92, wpb=111.2, bsz=40, num_updates=35160, lr=4.85027e-05, gnorm=1.01, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=171665
2022-10-17 19:18:27 - progress_bar.py[line:274] - INFO: epoch 001:  35218 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.9, ups=0.92, wpb=109, bsz=40, num_updates=35170, lr=4.85017e-05, gnorm=1.139, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=171675
2022-10-17 19:18:38 - progress_bar.py[line:274] - INFO: epoch 001:  35228 / 102288 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=35180, lr=4.85007e-05, gnorm=1.109, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171687
2022-10-17 19:18:49 - progress_bar.py[line:274] - INFO: epoch 001:  35238 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.2, ups=0.88, wpb=109.2, bsz=40, num_updates=35190, lr=4.84996e-05, gnorm=1.042, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171698
2022-10-17 19:19:01 - progress_bar.py[line:274] - INFO: epoch 001:  35248 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.6, ups=0.88, wpb=109, bsz=40, num_updates=35200, lr=4.84986e-05, gnorm=0.891, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=171709
2022-10-17 19:19:12 - progress_bar.py[line:274] - INFO: epoch 001:  35258 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.1, ups=0.89, wpb=109.6, bsz=40, num_updates=35210, lr=4.84976e-05, gnorm=0.979, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171721
2022-10-17 19:19:23 - progress_bar.py[line:274] - INFO: epoch 001:  35268 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.1, ups=0.89, wpb=109.2, bsz=40, num_updates=35220, lr=4.84966e-05, gnorm=1.026, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=171732
2022-10-17 19:19:34 - progress_bar.py[line:274] - INFO: epoch 001:  35278 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.2, ups=0.91, wpb=111.8, bsz=40, num_updates=35230, lr=4.84956e-05, gnorm=0.998, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171743
2022-10-17 19:19:45 - progress_bar.py[line:274] - INFO: epoch 001:  35288 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=35240, lr=4.84946e-05, gnorm=0.903, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=171754
2022-10-17 19:19:56 - progress_bar.py[line:274] - INFO: epoch 001:  35298 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.7, ups=0.92, wpb=109.8, bsz=40, num_updates=35250, lr=4.84935e-05, gnorm=1.272, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171765
2022-10-17 19:20:08 - progress_bar.py[line:274] - INFO: epoch 001:  35308 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=35260, lr=4.84925e-05, gnorm=0.943, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=171777
2022-10-17 19:20:19 - progress_bar.py[line:274] - INFO: epoch 001:  35318 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=35270, lr=4.84915e-05, gnorm=0.929, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171788
2022-10-17 19:20:30 - progress_bar.py[line:274] - INFO: epoch 001:  35328 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.6, ups=0.91, wpb=111, bsz=40, num_updates=35280, lr=4.84905e-05, gnorm=1.083, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=171799
2022-10-17 19:20:41 - progress_bar.py[line:274] - INFO: epoch 001:  35338 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.7, ups=0.89, wpb=109.3, bsz=40, num_updates=35290, lr=4.84895e-05, gnorm=0.905, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=171810
2022-10-17 19:20:52 - progress_bar.py[line:274] - INFO: epoch 001:  35348 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.1, ups=0.9, wpb=111.1, bsz=40, num_updates=35300, lr=4.84884e-05, gnorm=0.945, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=171821
2022-10-17 19:21:41 - progress_bar.py[line:274] - INFO: epoch 001:  35358 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.7, ups=0.9, wpb=108.3, bsz=40, num_updates=35310, lr=4.84874e-05, gnorm=0.991, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=171870
2022-10-17 19:21:52 - progress_bar.py[line:274] - INFO: epoch 001:  35368 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=35320, lr=4.84864e-05, gnorm=0.988, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=171881
2022-10-17 19:22:03 - progress_bar.py[line:274] - INFO: epoch 001:  35378 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=35330, lr=4.84854e-05, gnorm=1.086, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171892
2022-10-17 19:22:15 - progress_bar.py[line:274] - INFO: epoch 001:  35388 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.6, ups=0.9, wpb=111.4, bsz=40, num_updates=35340, lr=4.84844e-05, gnorm=0.983, clip=50, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=171904
2022-10-17 19:22:26 - progress_bar.py[line:274] - INFO: epoch 001:  35398 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.3, ups=0.88, wpb=110.8, bsz=40, num_updates=35350, lr=4.84833e-05, gnorm=1.003, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=171915
2022-10-17 19:22:37 - progress_bar.py[line:274] - INFO: epoch 001:  35408 / 102288 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=35360, lr=4.84823e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171926
2022-10-17 19:22:48 - progress_bar.py[line:274] - INFO: epoch 001:  35418 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.1, ups=0.91, wpb=110.5, bsz=40, num_updates=35370, lr=4.84813e-05, gnorm=1.02, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171937
2022-10-17 19:22:59 - progress_bar.py[line:274] - INFO: epoch 001:  35428 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.2, ups=0.91, wpb=110.6, bsz=40, num_updates=35380, lr=4.84803e-05, gnorm=1.005, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=171948
2022-10-17 19:23:10 - progress_bar.py[line:274] - INFO: epoch 001:  35438 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=35390, lr=4.84793e-05, gnorm=1.136, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=171959
2022-10-17 19:23:21 - progress_bar.py[line:274] - INFO: epoch 001:  35448 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=35400, lr=4.84783e-05, gnorm=0.986, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171970
2022-10-17 19:23:32 - progress_bar.py[line:274] - INFO: epoch 001:  35458 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=35410, lr=4.84772e-05, gnorm=0.952, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=171981
2022-10-17 19:23:44 - progress_bar.py[line:274] - INFO: epoch 001:  35468 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.9, ups=0.88, wpb=109.8, bsz=40, num_updates=35420, lr=4.84762e-05, gnorm=1.013, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=171993
2022-10-17 19:23:55 - progress_bar.py[line:274] - INFO: epoch 001:  35478 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=35430, lr=4.84752e-05, gnorm=1.075, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172004
2022-10-17 19:24:06 - progress_bar.py[line:274] - INFO: epoch 001:  35488 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.2, ups=0.92, wpb=110.6, bsz=40, num_updates=35440, lr=4.84742e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172015
2022-10-17 19:24:17 - progress_bar.py[line:274] - INFO: epoch 001:  35498 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=35450, lr=4.84732e-05, gnorm=0.917, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172026
2022-10-17 19:24:28 - progress_bar.py[line:274] - INFO: epoch 001:  35508 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=102.3, ups=0.93, wpb=110, bsz=40, num_updates=35460, lr=4.84721e-05, gnorm=0.901, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=172037
2022-10-17 19:24:39 - progress_bar.py[line:274] - INFO: epoch 001:  35518 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.7, ups=0.92, wpb=109.7, bsz=40, num_updates=35470, lr=4.84711e-05, gnorm=1.005, clip=30, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172048
2022-10-17 19:24:46 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-17 19:24:51 - progress_bar.py[line:274] - INFO: epoch 001:  35529 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=91.9, ups=0.84, wpb=110, bsz=40, num_updates=35480, lr=4.84701e-05, gnorm=1.131, clip=70, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=172060
2022-10-17 19:25:02 - progress_bar.py[line:274] - INFO: epoch 001:  35539 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.2, ups=0.9, wpb=110, bsz=40, num_updates=35490, lr=4.84691e-05, gnorm=1.155, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=172071
2022-10-17 19:25:13 - progress_bar.py[line:274] - INFO: epoch 001:  35549 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.7, ups=0.88, wpb=109, bsz=40, num_updates=35500, lr=4.84681e-05, gnorm=1.064, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172082
2022-10-17 19:25:24 - progress_bar.py[line:274] - INFO: epoch 001:  35559 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.9, wpb=109.3, bsz=40, num_updates=35510, lr=4.84671e-05, gnorm=1.014, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172093
2022-10-17 19:25:35 - progress_bar.py[line:274] - INFO: epoch 001:  35569 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.1, ups=0.92, wpb=110.2, bsz=40, num_updates=35520, lr=4.8466e-05, gnorm=0.922, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172104
2022-10-17 19:25:47 - progress_bar.py[line:274] - INFO: epoch 001:  35579 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=35530, lr=4.8465e-05, gnorm=0.928, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172116
2022-10-17 19:25:58 - progress_bar.py[line:274] - INFO: epoch 001:  35589 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=35540, lr=4.8464e-05, gnorm=0.884, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=172127
2022-10-17 19:26:09 - progress_bar.py[line:274] - INFO: epoch 001:  35599 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=35550, lr=4.8463e-05, gnorm=0.911, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172138
2022-10-17 19:26:20 - progress_bar.py[line:274] - INFO: epoch 001:  35609 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.3, ups=0.92, wpb=110.6, bsz=40, num_updates=35560, lr=4.8462e-05, gnorm=0.795, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=172149
2022-10-17 19:26:31 - progress_bar.py[line:274] - INFO: epoch 001:  35619 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.4, ups=0.91, wpb=108.7, bsz=40, num_updates=35570, lr=4.84609e-05, gnorm=0.925, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172160
2022-10-17 19:26:42 - progress_bar.py[line:274] - INFO: epoch 001:  35629 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=35580, lr=4.84599e-05, gnorm=0.989, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172171
2022-10-17 19:26:53 - progress_bar.py[line:274] - INFO: epoch 001:  35639 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=35590, lr=4.84589e-05, gnorm=0.89, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172182
2022-10-17 19:27:04 - progress_bar.py[line:274] - INFO: epoch 001:  35649 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=35600, lr=4.84579e-05, gnorm=1.061, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172193
2022-10-17 19:27:15 - progress_bar.py[line:274] - INFO: epoch 001:  35659 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=35610, lr=4.84569e-05, gnorm=0.879, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172204
2022-10-17 19:27:26 - progress_bar.py[line:274] - INFO: epoch 001:  35669 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=35620, lr=4.84559e-05, gnorm=0.994, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=172215
2022-10-17 19:27:38 - progress_bar.py[line:274] - INFO: epoch 001:  35679 / 102288 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.3, ups=0.9, wpb=111.1, bsz=40, num_updates=35630, lr=4.84548e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=172226
2022-10-17 19:27:49 - progress_bar.py[line:274] - INFO: epoch 001:  35689 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.2, ups=0.89, wpb=111.5, bsz=40, num_updates=35640, lr=4.84538e-05, gnorm=1.1, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172238
2022-10-17 19:28:00 - progress_bar.py[line:274] - INFO: epoch 001:  35699 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.3, ups=0.89, wpb=109.3, bsz=40, num_updates=35650, lr=4.84528e-05, gnorm=0.838, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=172249
2022-10-17 19:28:11 - progress_bar.py[line:274] - INFO: epoch 001:  35709 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.9, ups=0.92, wpb=109.1, bsz=40, num_updates=35660, lr=4.84518e-05, gnorm=0.961, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172260
2022-10-17 19:28:22 - progress_bar.py[line:274] - INFO: epoch 001:  35719 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.9, ups=0.9, wpb=109.6, bsz=40, num_updates=35670, lr=4.84508e-05, gnorm=0.876, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172271
2022-10-17 19:28:33 - progress_bar.py[line:274] - INFO: epoch 001:  35729 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97, ups=0.87, wpb=111.6, bsz=40, num_updates=35680, lr=4.84497e-05, gnorm=0.925, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172282
2022-10-17 19:28:45 - progress_bar.py[line:274] - INFO: epoch 001:  35739 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=35690, lr=4.84487e-05, gnorm=0.916, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=172294
2022-10-17 19:28:56 - progress_bar.py[line:274] - INFO: epoch 001:  35749 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.6, ups=0.88, wpb=109.9, bsz=40, num_updates=35700, lr=4.84477e-05, gnorm=0.795, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172305
2022-10-17 19:29:08 - progress_bar.py[line:274] - INFO: epoch 001:  35759 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.3, ups=0.87, wpb=109.7, bsz=40, num_updates=35710, lr=4.84467e-05, gnorm=0.824, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=172317
2022-10-17 19:29:19 - progress_bar.py[line:274] - INFO: epoch 001:  35769 / 102288 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.3, ups=0.9, wpb=111.1, bsz=40, num_updates=35720, lr=4.84457e-05, gnorm=0.791, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172328
2022-10-17 19:29:30 - progress_bar.py[line:274] - INFO: epoch 001:  35779 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.2, ups=0.87, wpb=110.7, bsz=40, num_updates=35730, lr=4.84447e-05, gnorm=0.92, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172339
2022-10-17 19:29:41 - progress_bar.py[line:274] - INFO: epoch 001:  35789 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=102.2, ups=0.93, wpb=110.2, bsz=40, num_updates=35740, lr=4.84436e-05, gnorm=1.052, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172350
2022-10-17 19:29:52 - progress_bar.py[line:274] - INFO: epoch 001:  35799 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=35750, lr=4.84426e-05, gnorm=0.988, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=172361
2022-10-17 19:30:03 - progress_bar.py[line:274] - INFO: epoch 001:  35809 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=35760, lr=4.84416e-05, gnorm=0.894, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=172372
2022-10-17 19:30:15 - progress_bar.py[line:274] - INFO: epoch 001:  35819 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=35770, lr=4.84406e-05, gnorm=0.99, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172384
2022-10-17 19:30:26 - progress_bar.py[line:274] - INFO: epoch 001:  35829 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=35780, lr=4.84396e-05, gnorm=0.897, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172395
2022-10-17 19:30:37 - progress_bar.py[line:274] - INFO: epoch 001:  35839 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=35790, lr=4.84385e-05, gnorm=0.983, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172406
2022-10-17 19:30:49 - progress_bar.py[line:274] - INFO: epoch 001:  35849 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.2, ups=0.87, wpb=110.7, bsz=40, num_updates=35800, lr=4.84375e-05, gnorm=0.917, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172418
2022-10-17 19:31:00 - progress_bar.py[line:274] - INFO: epoch 001:  35859 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=35810, lr=4.84365e-05, gnorm=0.876, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=172429
2022-10-17 19:31:11 - progress_bar.py[line:274] - INFO: epoch 001:  35869 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.6, ups=0.88, wpb=109.6, bsz=40, num_updates=35820, lr=4.84355e-05, gnorm=0.807, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172440
2022-10-17 19:31:23 - progress_bar.py[line:274] - INFO: epoch 001:  35879 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.2, ups=0.87, wpb=109.6, bsz=40, num_updates=35830, lr=4.84345e-05, gnorm=0.873, clip=30, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=172452
2022-10-17 19:31:34 - progress_bar.py[line:274] - INFO: epoch 001:  35889 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.4, ups=0.88, wpb=109.3, bsz=40, num_updates=35840, lr=4.84334e-05, gnorm=0.78, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=172463
2022-10-17 19:31:45 - progress_bar.py[line:274] - INFO: epoch 001:  35899 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=35850, lr=4.84324e-05, gnorm=0.977, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172474
2022-10-17 19:31:56 - progress_bar.py[line:274] - INFO: epoch 001:  35909 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=35860, lr=4.84314e-05, gnorm=1.099, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172485
2022-10-17 19:32:08 - progress_bar.py[line:274] - INFO: epoch 001:  35919 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=35870, lr=4.84304e-05, gnorm=1.003, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=172497
2022-10-17 19:32:19 - progress_bar.py[line:274] - INFO: epoch 001:  35929 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=35880, lr=4.84294e-05, gnorm=0.997, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172508
2022-10-17 19:32:30 - progress_bar.py[line:274] - INFO: epoch 001:  35939 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=35890, lr=4.84284e-05, gnorm=1.04, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=172519
2022-10-17 19:32:42 - progress_bar.py[line:274] - INFO: epoch 001:  35949 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96, ups=0.87, wpb=110.4, bsz=40, num_updates=35900, lr=4.84273e-05, gnorm=1.046, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=172531
2022-10-17 19:32:53 - progress_bar.py[line:274] - INFO: epoch 001:  35959 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.6, ups=0.91, wpb=110.1, bsz=40, num_updates=35910, lr=4.84263e-05, gnorm=0.922, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=172542
2022-10-17 19:33:04 - progress_bar.py[line:274] - INFO: epoch 001:  35969 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.9, ups=0.9, wpb=109.3, bsz=40, num_updates=35920, lr=4.84253e-05, gnorm=0.913, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172553
2022-10-17 19:33:15 - progress_bar.py[line:274] - INFO: epoch 001:  35979 / 102288 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.7, ups=0.9, wpb=110.3, bsz=40, num_updates=35930, lr=4.84243e-05, gnorm=0.921, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172564
2022-10-17 19:33:26 - progress_bar.py[line:274] - INFO: epoch 001:  35989 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.6, ups=0.9, wpb=111, bsz=40, num_updates=35940, lr=4.84233e-05, gnorm=0.993, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=172575
2022-10-17 19:33:37 - progress_bar.py[line:274] - INFO: epoch 001:  35999 / 102288 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101.5, ups=0.91, wpb=111, bsz=40, num_updates=35950, lr=4.84222e-05, gnorm=1.182, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172586
2022-10-17 19:33:48 - progress_bar.py[line:274] - INFO: epoch 001:  36009 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=35960, lr=4.84212e-05, gnorm=1.34, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=172597
2022-10-17 19:33:59 - progress_bar.py[line:274] - INFO: epoch 001:  36019 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.3, ups=0.92, wpb=110.6, bsz=40, num_updates=35970, lr=4.84202e-05, gnorm=1.271, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=172608
2022-10-17 19:34:10 - progress_bar.py[line:274] - INFO: epoch 001:  36029 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=35980, lr=4.84192e-05, gnorm=1.022, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=172619
2022-10-17 19:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  36039 / 102288 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101, ups=0.9, wpb=111.8, bsz=40, num_updates=35990, lr=4.84182e-05, gnorm=0.859, clip=20, loss_scale=2048, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=172630
2022-10-17 19:34:25 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-17 19:34:34 - progress_bar.py[line:274] - INFO: epoch 001:  36050 / 102288 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=90.2, ups=0.82, wpb=109.7, bsz=40, num_updates=36000, lr=4.84172e-05, gnorm=0.829, clip=30, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=172643
2022-10-17 19:34:34 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 19:34:35 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 19:34:35 - train.py[line:551] - INFO: load:1.13 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 19:37:07 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 19:37:07 - train.py[line:551] - INFO: load:1.15 valid_run:151.60 task_valid:148.27 collect_output:2.26
2022-10-17 19:39:35 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 19:39:35 - train.py[line:551] - INFO: load:1.18 valid_run:299.75 task_valid:291.69 collect_output:5.95
2022-10-17 19:42:08 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 19:42:08 - train.py[line:551] - INFO: load:1.21 valid_run:452.27 task_valid:435.43 collect_output:13.59
2022-10-17 19:44:37 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 19:44:37 - train.py[line:551] - INFO: load:1.23 valid_run:601.63 task_valid:580.92 collect_output:16.25
2022-10-17 19:47:10 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 19:47:10 - train.py[line:551] - INFO: load:1.26 valid_run:754.34 task_valid:729.30 collect_output:19.44
2022-10-17 19:49:42 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 19:49:42 - train.py[line:551] - INFO: load:1.28 valid_run:906.58 task_valid:875.88 collect_output:23.93
2022-10-17 19:52:16 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 19:52:16 - train.py[line:551] - INFO: load:1.31 valid_run:1060.23 task_valid:1022.80 collect_output:29.51
2022-10-17 19:54:47 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 19:54:47 - train.py[line:551] - INFO: load:1.34 valid_run:1211.64 task_valid:1164.75 collect_output:37.85
2022-10-17 19:57:17 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 19:57:17 - train.py[line:551] - INFO: load:1.37 valid_run:1361.47 task_valid:1310.22 collect_output:41.11
2022-10-17 19:59:46 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 19:59:46 - train.py[line:551] - INFO: load:1.39 valid_run:1510.34 task_valid:1454.24 collect_output:44.84
2022-10-17 20:02:16 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 20:02:16 - train.py[line:551] - INFO: load:1.42 valid_run:1660.69 task_valid:1599.80 collect_output:48.55
2022-10-17 20:04:47 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 20:04:47 - train.py[line:551] - INFO: load:1.45 valid_run:1810.88 task_valid:1745.39 collect_output:52.03
2022-10-17 20:07:17 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 20:07:17 - train.py[line:551] - INFO: load:1.47 valid_run:1960.87 task_valid:1887.71 collect_output:58.61
2022-10-17 20:09:48 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 20:09:48 - train.py[line:551] - INFO: load:1.50 valid_run:2111.84 task_valid:2033.83 collect_output:62.35
2022-10-17 20:12:18 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 20:12:18 - train.py[line:551] - INFO: load:1.53 valid_run:2261.67 task_valid:2180.24 collect_output:64.74
2022-10-17 20:14:48 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 20:14:48 - train.py[line:551] - INFO: load:1.55 valid_run:2411.47 task_valid:2324.45 collect_output:69.31
2022-10-17 20:17:19 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 20:17:19 - train.py[line:551] - INFO: load:1.57 valid_run:2562.92 task_valid:2469.93 collect_output:74.23
2022-10-17 20:19:50 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 20:19:50 - train.py[line:551] - INFO: load:1.60 valid_run:2713.58 task_valid:2617.14 collect_output:76.65
2022-10-17 20:22:18 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 20:22:18 - train.py[line:551] - INFO: load:1.63 valid_run:2861.69 task_valid:2758.85 collect_output:82.01
2022-10-17 20:24:49 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 20:24:49 - train.py[line:551] - INFO: load:1.65 valid_run:3012.55 task_valid:2904.47 collect_output:86.21
2022-10-17 20:27:21 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 20:27:21 - train.py[line:551] - INFO: load:1.68 valid_run:3164.57 task_valid:3049.31 collect_output:92.35
2022-10-17 20:29:50 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 20:29:50 - train.py[line:551] - INFO: load:1.70 valid_run:3314.05 task_valid:3194.18 collect_output:95.95
2022-10-17 20:32:22 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 20:32:22 - train.py[line:551] - INFO: load:1.73 valid_run:3465.53 task_valid:3340.64 collect_output:99.93
2022-10-17 20:34:54 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 20:34:54 - train.py[line:551] - INFO: load:1.75 valid_run:3617.07 task_valid:3487.29 collect_output:103.79

====================================================================================================
SGG eval:     R @ 50: 0.4435;     R @ 100: 0.4820;     R @ 500: 0.5120;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2861;    mR @ 100: 0.3476;    mR @ 500: 0.3843;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5732) (covered in:0.7500) (covering:0.3714) (eating:0.5294) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6205) (playing:0.0000) (riding:0.6650) (says:0.0000) (sitting on:0.6230) (standing on:0.2233) (using:0.5500) (walking in:0.6667) (walking on:0.2252) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4435;     R @ 100: 0.4820;     R @ 500: 0.5120;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2861;    mR @ 100: 0.3476;    mR @ 500: 0.3843;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5732) (covered in:0.7500) (covering:0.3714) (eating:0.5294) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6205) (playing:0.0000) (riding:0.6650) (says:0.0000) (sitting on:0.6230) (standing on:0.2233) (using:0.5500) (walking in:0.6667) (walking on:0.2252) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================

2022-10-17 20:37:25 - train.py[line:487] - INFO: 0.48196190476190476
2022-10-17 20:37:25 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 20:37:25 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.37 | loss_v1 0 | loss_v2 0 | nll_loss 0.217 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.481962 | ppl 1.16 | vqa_score 0.3941 | wps 119 | wpb 89.9 | bsz 30 | num_updates 36000 | best_R@100 0.581461
2022-10-17 20:37:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 36000 updates
2022-10-17 20:37:25 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_36000.pt
2022-10-17 20:37:30 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_36000.pt
2022-10-17 20:37:33 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_36000.pt (epoch 1 @ 36000 updates, score 0.48196190476190476) (writing took 8.664376749191433 seconds)
2022-10-17 20:37:45 - progress_bar.py[line:274] - INFO: epoch 001:  36060 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=0.3, ups=0, wpb=111.1, bsz=40, num_updates=36010, lr=4.84161e-05, gnorm=1.164, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=176434
2022-10-17 20:37:56 - progress_bar.py[line:274] - INFO: epoch 001:  36070 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=36020, lr=4.84151e-05, gnorm=1.058, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176445
2022-10-17 20:38:07 - progress_bar.py[line:274] - INFO: epoch 001:  36080 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=36030, lr=4.84141e-05, gnorm=0.728, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176456
2022-10-17 20:38:18 - progress_bar.py[line:274] - INFO: epoch 001:  36090 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.3, ups=0.9, wpb=109.2, bsz=40, num_updates=36040, lr=4.84131e-05, gnorm=0.839, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176467
2022-10-17 20:38:30 - progress_bar.py[line:274] - INFO: epoch 001:  36100 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.3, ups=0.88, wpb=111.6, bsz=40, num_updates=36050, lr=4.84121e-05, gnorm=0.983, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176479
2022-10-17 20:38:41 - progress_bar.py[line:274] - INFO: epoch 001:  36110 / 102288 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=36060, lr=4.8411e-05, gnorm=0.945, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176490
2022-10-17 20:38:52 - progress_bar.py[line:274] - INFO: epoch 001:  36120 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.5, ups=0.9, wpb=109.2, bsz=40, num_updates=36070, lr=4.841e-05, gnorm=0.888, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=176501
2022-10-17 20:39:03 - progress_bar.py[line:274] - INFO: epoch 001:  36130 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=102, ups=0.93, wpb=110.1, bsz=40, num_updates=36080, lr=4.8409e-05, gnorm=0.962, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=176512
2022-10-17 20:39:14 - progress_bar.py[line:274] - INFO: epoch 001:  36140 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.5, ups=0.9, wpb=110, bsz=40, num_updates=36090, lr=4.8408e-05, gnorm=0.861, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=176523
2022-10-17 20:39:25 - progress_bar.py[line:274] - INFO: epoch 001:  36150 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.1, ups=0.92, wpb=109.2, bsz=40, num_updates=36100, lr=4.8407e-05, gnorm=1.014, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176534
2022-10-17 20:39:36 - progress_bar.py[line:274] - INFO: epoch 001:  36160 / 102288 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=36110, lr=4.8406e-05, gnorm=0.857, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=176545
2022-10-17 20:39:47 - progress_bar.py[line:274] - INFO: epoch 001:  36170 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.3, ups=0.88, wpb=109, bsz=40, num_updates=36120, lr=4.84049e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=176556
2022-10-17 20:39:59 - progress_bar.py[line:274] - INFO: epoch 001:  36180 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=36130, lr=4.84039e-05, gnorm=0.784, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176568
2022-10-17 20:40:10 - progress_bar.py[line:274] - INFO: epoch 001:  36190 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=36140, lr=4.84029e-05, gnorm=0.778, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176579
2022-10-17 20:40:21 - progress_bar.py[line:274] - INFO: epoch 001:  36200 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=36150, lr=4.84019e-05, gnorm=0.83, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176590
2022-10-17 20:40:32 - progress_bar.py[line:274] - INFO: epoch 001:  36210 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.4, ups=0.92, wpb=110.7, bsz=40, num_updates=36160, lr=4.84009e-05, gnorm=0.952, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176601
2022-10-17 20:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  36220 / 102288 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=36170, lr=4.83998e-05, gnorm=0.879, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176612
2022-10-17 20:40:54 - progress_bar.py[line:274] - INFO: epoch 001:  36230 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=36180, lr=4.83988e-05, gnorm=1.096, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176623
2022-10-17 20:41:05 - progress_bar.py[line:274] - INFO: epoch 001:  36240 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102, ups=0.91, wpb=111.5, bsz=40, num_updates=36190, lr=4.83978e-05, gnorm=1.095, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176634
2022-10-17 20:41:16 - progress_bar.py[line:274] - INFO: epoch 001:  36250 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.7, ups=0.93, wpb=110.6, bsz=40, num_updates=36200, lr=4.83968e-05, gnorm=0.894, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176645
2022-10-17 20:41:27 - progress_bar.py[line:274] - INFO: epoch 001:  36260 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.5, ups=0.87, wpb=110.8, bsz=40, num_updates=36210, lr=4.83958e-05, gnorm=1.023, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176656
2022-10-17 20:41:38 - progress_bar.py[line:274] - INFO: epoch 001:  36270 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.5, ups=0.9, wpb=109.2, bsz=40, num_updates=36220, lr=4.83948e-05, gnorm=0.97, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176667
2022-10-17 20:41:50 - progress_bar.py[line:274] - INFO: epoch 001:  36280 / 102288 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=36230, lr=4.83937e-05, gnorm=0.783, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=176679
2022-10-17 20:42:01 - progress_bar.py[line:274] - INFO: epoch 001:  36290 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.2, ups=0.9, wpb=110.8, bsz=40, num_updates=36240, lr=4.83927e-05, gnorm=0.948, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=176690
2022-10-17 20:42:12 - progress_bar.py[line:274] - INFO: epoch 001:  36300 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=36250, lr=4.83917e-05, gnorm=1.101, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176701
2022-10-17 20:42:23 - progress_bar.py[line:274] - INFO: epoch 001:  36310 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=36260, lr=4.83907e-05, gnorm=0.79, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=176712
2022-10-17 20:42:34 - progress_bar.py[line:274] - INFO: epoch 001:  36320 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.6, ups=0.92, wpb=108.8, bsz=40, num_updates=36270, lr=4.83897e-05, gnorm=0.87, clip=30, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=176723
2022-10-17 20:42:46 - progress_bar.py[line:274] - INFO: epoch 001:  36330 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.7, ups=0.88, wpb=108.6, bsz=40, num_updates=36280, lr=4.83886e-05, gnorm=0.865, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176735
2022-10-17 20:42:57 - progress_bar.py[line:274] - INFO: epoch 001:  36340 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.8, ups=0.88, wpb=108.8, bsz=40, num_updates=36290, lr=4.83876e-05, gnorm=1.01, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176746
2022-10-17 20:43:08 - progress_bar.py[line:274] - INFO: epoch 001:  36350 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=36300, lr=4.83866e-05, gnorm=0.93, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=176757
2022-10-17 20:43:20 - progress_bar.py[line:274] - INFO: epoch 001:  36360 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=36310, lr=4.83856e-05, gnorm=0.715, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=176769
2022-10-17 20:43:31 - progress_bar.py[line:274] - INFO: epoch 001:  36370 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.6, ups=0.87, wpb=110.1, bsz=40, num_updates=36320, lr=4.83846e-05, gnorm=0.919, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=176780
2022-10-17 20:43:43 - progress_bar.py[line:274] - INFO: epoch 001:  36380 / 102288 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.6, ups=0.86, wpb=111.8, bsz=40, num_updates=36330, lr=4.83835e-05, gnorm=0.926, clip=30, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=176792
2022-10-17 20:43:54 - progress_bar.py[line:274] - INFO: epoch 001:  36390 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=36340, lr=4.83825e-05, gnorm=0.89, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=176803
2022-10-17 20:44:06 - progress_bar.py[line:274] - INFO: epoch 001:  36400 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=36350, lr=4.83815e-05, gnorm=0.978, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176815
2022-10-17 20:44:14 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-17 20:44:18 - progress_bar.py[line:274] - INFO: epoch 001:  36411 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=89.6, ups=0.8, wpb=111.5, bsz=40, num_updates=36360, lr=4.83805e-05, gnorm=0.817, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=176827
2022-10-17 20:44:30 - progress_bar.py[line:274] - INFO: epoch 001:  36421 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=36370, lr=4.83795e-05, gnorm=1.001, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176838
2022-10-17 20:44:41 - progress_bar.py[line:274] - INFO: epoch 001:  36431 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=36380, lr=4.83785e-05, gnorm=0.89, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176850
2022-10-17 20:44:52 - progress_bar.py[line:274] - INFO: epoch 001:  36441 / 102288 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=36390, lr=4.83774e-05, gnorm=1.14, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=176861
2022-10-17 20:45:03 - progress_bar.py[line:274] - INFO: epoch 001:  36451 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.7, ups=0.9, wpb=111.7, bsz=40, num_updates=36400, lr=4.83764e-05, gnorm=0.966, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=176872
2022-10-17 20:45:14 - progress_bar.py[line:274] - INFO: epoch 001:  36461 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.7, ups=0.89, wpb=110.1, bsz=40, num_updates=36410, lr=4.83754e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=176883
2022-10-17 20:45:25 - progress_bar.py[line:274] - INFO: epoch 001:  36471 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.2, ups=0.91, wpb=110.4, bsz=40, num_updates=36420, lr=4.83744e-05, gnorm=1.013, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=176894
2022-10-17 20:45:37 - progress_bar.py[line:274] - INFO: epoch 001:  36481 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=36430, lr=4.83734e-05, gnorm=0.942, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176906
2022-10-17 20:45:48 - progress_bar.py[line:274] - INFO: epoch 001:  36491 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.4, ups=0.89, wpb=109.9, bsz=40, num_updates=36440, lr=4.83723e-05, gnorm=0.891, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176917
2022-10-17 20:45:59 - progress_bar.py[line:274] - INFO: epoch 001:  36501 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=36450, lr=4.83713e-05, gnorm=0.957, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=176928
2022-10-17 20:46:11 - progress_bar.py[line:274] - INFO: epoch 001:  36511 / 102288 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=93.8, ups=0.86, wpb=109, bsz=40, num_updates=36460, lr=4.83703e-05, gnorm=1.009, clip=40, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=176940
2022-10-17 20:46:22 - progress_bar.py[line:274] - INFO: epoch 001:  36521 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.1, ups=0.87, wpb=109.5, bsz=40, num_updates=36470, lr=4.83693e-05, gnorm=0.942, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176951
2022-10-17 20:46:33 - progress_bar.py[line:274] - INFO: epoch 001:  36531 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=36480, lr=4.83683e-05, gnorm=0.933, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=176962
2022-10-17 20:46:45 - progress_bar.py[line:274] - INFO: epoch 001:  36541 / 102288 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101.7, ups=0.91, wpb=112.2, bsz=40, num_updates=36490, lr=4.83673e-05, gnorm=0.83, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=176973
2022-10-17 20:46:56 - progress_bar.py[line:274] - INFO: epoch 001:  36551 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=36500, lr=4.83662e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=176985
2022-10-17 20:47:07 - progress_bar.py[line:274] - INFO: epoch 001:  36561 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.8, ups=0.9, wpb=109.2, bsz=40, num_updates=36510, lr=4.83652e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=176996
2022-10-17 20:47:17 - progress_bar.py[line:274] - INFO: epoch 001:  36571 / 102288 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=104.4, ups=0.94, wpb=111, bsz=40, num_updates=36520, lr=4.83642e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=177006
2022-10-17 20:47:29 - progress_bar.py[line:274] - INFO: epoch 001:  36581 / 102288 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=36530, lr=4.83632e-05, gnorm=1.074, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177017
2022-10-17 20:47:40 - progress_bar.py[line:274] - INFO: epoch 001:  36591 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=36540, lr=4.83622e-05, gnorm=0.807, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177029
2022-10-17 20:47:51 - progress_bar.py[line:274] - INFO: epoch 001:  36601 / 102288 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=36550, lr=4.83611e-05, gnorm=0.838, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177040
2022-10-17 20:48:02 - progress_bar.py[line:274] - INFO: epoch 001:  36611 / 102288 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.1, ups=0.88, wpb=110.8, bsz=40, num_updates=36560, lr=4.83601e-05, gnorm=0.693, clip=0, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=177051
2022-10-17 20:48:13 - progress_bar.py[line:274] - INFO: epoch 001:  36621 / 102288 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=36570, lr=4.83591e-05, gnorm=0.802, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177062
2022-10-17 20:48:25 - progress_bar.py[line:274] - INFO: epoch 001:  36631 / 102288 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.8, ups=0.88, wpb=110.9, bsz=40, num_updates=36580, lr=4.83581e-05, gnorm=0.85, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177074
2022-10-17 20:48:36 - progress_bar.py[line:274] - INFO: epoch 001:  36641 / 102288 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.2, ups=0.91, wpb=110.6, bsz=40, num_updates=36590, lr=4.83571e-05, gnorm=0.956, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177085
2022-10-17 20:48:47 - progress_bar.py[line:274] - INFO: epoch 001:  36651 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.6, ups=0.89, wpb=111.3, bsz=40, num_updates=36600, lr=4.83561e-05, gnorm=0.908, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177096
2022-10-17 20:48:58 - progress_bar.py[line:274] - INFO: epoch 001:  36661 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.5, ups=0.87, wpb=109.1, bsz=40, num_updates=36610, lr=4.8355e-05, gnorm=0.85, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177107
2022-10-17 20:49:10 - progress_bar.py[line:274] - INFO: epoch 001:  36671 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=36620, lr=4.8354e-05, gnorm=0.94, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177119
2022-10-17 20:49:21 - progress_bar.py[line:274] - INFO: epoch 001:  36681 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=36630, lr=4.8353e-05, gnorm=0.872, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177130
2022-10-17 20:49:32 - progress_bar.py[line:274] - INFO: epoch 001:  36691 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.92, wpb=107.6, bsz=40, num_updates=36640, lr=4.8352e-05, gnorm=0.907, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177141
2022-10-17 20:49:43 - progress_bar.py[line:274] - INFO: epoch 001:  36701 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.4, ups=0.93, wpb=110.5, bsz=40, num_updates=36650, lr=4.8351e-05, gnorm=0.927, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=177152
2022-10-17 20:49:54 - progress_bar.py[line:274] - INFO: epoch 001:  36711 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=36660, lr=4.83499e-05, gnorm=0.837, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177163
2022-10-17 20:50:05 - progress_bar.py[line:274] - INFO: epoch 001:  36721 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=36670, lr=4.83489e-05, gnorm=1.037, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=177174
2022-10-17 20:50:16 - progress_bar.py[line:274] - INFO: epoch 001:  36731 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=36680, lr=4.83479e-05, gnorm=0.899, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177185
2022-10-17 20:50:28 - progress_bar.py[line:274] - INFO: epoch 001:  36741 / 102288 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=36690, lr=4.83469e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177197
2022-10-17 20:50:39 - progress_bar.py[line:274] - INFO: epoch 001:  36751 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=36700, lr=4.83459e-05, gnorm=0.833, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=177208
2022-10-17 20:50:51 - progress_bar.py[line:274] - INFO: epoch 001:  36761 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.2, ups=0.87, wpb=109.7, bsz=40, num_updates=36710, lr=4.83449e-05, gnorm=0.998, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177220
2022-10-17 20:51:01 - progress_bar.py[line:274] - INFO: epoch 001:  36771 / 102288 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=103, ups=0.93, wpb=110.6, bsz=40, num_updates=36720, lr=4.83438e-05, gnorm=0.831, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177230
2022-10-17 20:51:12 - progress_bar.py[line:274] - INFO: epoch 001:  36781 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.6, ups=0.91, wpb=109.8, bsz=40, num_updates=36730, lr=4.83428e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=177241
2022-10-17 20:51:24 - progress_bar.py[line:274] - INFO: epoch 001:  36791 / 102288 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=36740, lr=4.83418e-05, gnorm=0.86, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177253
2022-10-17 20:51:35 - progress_bar.py[line:274] - INFO: epoch 001:  36801 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.1, ups=0.91, wpb=109.7, bsz=40, num_updates=36750, lr=4.83408e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177264
2022-10-17 20:51:46 - progress_bar.py[line:274] - INFO: epoch 001:  36811 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.3, ups=0.87, wpb=109.7, bsz=40, num_updates=36760, lr=4.83398e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177275
2022-10-17 20:51:57 - progress_bar.py[line:274] - INFO: epoch 001:  36821 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.8, ups=0.92, wpb=112, bsz=40, num_updates=36770, lr=4.83387e-05, gnorm=0.954, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177286
2022-10-17 20:52:09 - progress_bar.py[line:274] - INFO: epoch 001:  36831 / 102288 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.4, ups=0.89, wpb=108.5, bsz=40, num_updates=36780, lr=4.83377e-05, gnorm=0.944, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177298
2022-10-17 20:52:20 - progress_bar.py[line:274] - INFO: epoch 001:  36841 / 102288 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=36790, lr=4.83367e-05, gnorm=0.957, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=177309
2022-10-17 20:52:31 - progress_bar.py[line:274] - INFO: epoch 001:  36851 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=36800, lr=4.83357e-05, gnorm=0.863, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=177320
2022-10-17 20:52:42 - progress_bar.py[line:274] - INFO: epoch 001:  36861 / 102288 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=36810, lr=4.83347e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=177331
2022-10-17 20:52:53 - progress_bar.py[line:274] - INFO: epoch 001:  36871 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=36820, lr=4.83336e-05, gnorm=0.899, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177342
2022-10-17 20:53:05 - progress_bar.py[line:274] - INFO: epoch 001:  36881 / 102288 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.3, ups=0.87, wpb=110.4, bsz=40, num_updates=36830, lr=4.83326e-05, gnorm=1.031, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177354
2022-10-17 20:53:16 - progress_bar.py[line:274] - INFO: epoch 001:  36891 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=36840, lr=4.83316e-05, gnorm=1.112, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177365
2022-10-17 20:53:27 - progress_bar.py[line:274] - INFO: epoch 001:  36901 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=36850, lr=4.83306e-05, gnorm=0.997, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177376
2022-10-17 20:53:38 - progress_bar.py[line:274] - INFO: epoch 001:  36911 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=36860, lr=4.83296e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177387
2022-10-17 20:53:50 - progress_bar.py[line:274] - INFO: epoch 001:  36921 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.1, ups=0.9, wpb=110.2, bsz=40, num_updates=36870, lr=4.83286e-05, gnorm=1.002, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177399
2022-10-17 20:54:01 - progress_bar.py[line:274] - INFO: epoch 001:  36931 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.4, ups=0.88, wpb=110.8, bsz=40, num_updates=36880, lr=4.83275e-05, gnorm=0.805, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177410
2022-10-17 20:54:12 - progress_bar.py[line:274] - INFO: epoch 001:  36941 / 102288 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=36890, lr=4.83265e-05, gnorm=1.035, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177421
2022-10-17 20:54:23 - progress_bar.py[line:274] - INFO: epoch 001:  36951 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=36900, lr=4.83255e-05, gnorm=1.136, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177432
2022-10-17 20:54:35 - progress_bar.py[line:274] - INFO: epoch 001:  36961 / 102288 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99, ups=0.89, wpb=111.8, bsz=40, num_updates=36910, lr=4.83245e-05, gnorm=0.899, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=177444
2022-10-17 20:54:46 - progress_bar.py[line:274] - INFO: epoch 001:  36971 / 102288 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.89, wpb=109, bsz=40, num_updates=36920, lr=4.83235e-05, gnorm=0.935, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=177455
2022-10-17 20:54:57 - progress_bar.py[line:274] - INFO: epoch 001:  36981 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.7, ups=0.89, wpb=108.7, bsz=40, num_updates=36930, lr=4.83224e-05, gnorm=0.984, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177466
2022-10-17 20:55:09 - progress_bar.py[line:274] - INFO: epoch 001:  36991 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=36940, lr=4.83214e-05, gnorm=0.831, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177478
2022-10-17 20:55:20 - progress_bar.py[line:274] - INFO: epoch 001:  37001 / 102288 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.9, ups=0.91, wpb=111.2, bsz=40, num_updates=36950, lr=4.83204e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=177489
2022-10-17 20:55:31 - progress_bar.py[line:274] - INFO: epoch 001:  37011 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.4, ups=0.91, wpb=108.6, bsz=40, num_updates=36960, lr=4.83194e-05, gnorm=1.044, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177500
2022-10-17 20:55:42 - progress_bar.py[line:274] - INFO: epoch 001:  37021 / 102288 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.1, ups=0.9, wpb=110.1, bsz=40, num_updates=36970, lr=4.83184e-05, gnorm=1.03, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177511
2022-10-17 20:55:53 - progress_bar.py[line:274] - INFO: epoch 001:  37031 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.9, ups=0.9, wpb=109.6, bsz=40, num_updates=36980, lr=4.83174e-05, gnorm=0.867, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=177522
2022-10-17 20:56:04 - progress_bar.py[line:274] - INFO: epoch 001:  37041 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=36990, lr=4.83163e-05, gnorm=0.77, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=177533
2022-10-17 20:56:15 - progress_bar.py[line:274] - INFO: epoch 001:  37051 / 102288 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=37000, lr=4.83153e-05, gnorm=0.955, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=177544
2022-10-17 20:56:15 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-17 20:56:17 - train.py[line:549] - INFO: 0 / 4988
2022-10-17 20:56:17 - train.py[line:551] - INFO: load:1.28 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-17 20:58:49 - train.py[line:549] - INFO: 200 / 4988
2022-10-17 20:58:49 - train.py[line:551] - INFO: load:1.30 valid_run:151.95 task_valid:148.90 collect_output:1.94
2022-10-17 21:01:17 - train.py[line:549] - INFO: 400 / 4988
2022-10-17 21:01:17 - train.py[line:551] - INFO: load:1.33 valid_run:300.52 task_valid:292.91 collect_output:5.42
2022-10-17 21:03:50 - train.py[line:549] - INFO: 600 / 4988
2022-10-17 21:03:50 - train.py[line:551] - INFO: load:1.36 valid_run:452.60 task_valid:436.60 collect_output:12.69
2022-10-17 21:06:19 - train.py[line:549] - INFO: 800 / 4988
2022-10-17 21:06:19 - train.py[line:551] - INFO: load:1.38 valid_run:602.02 task_valid:582.07 collect_output:15.49
2022-10-17 21:08:52 - train.py[line:549] - INFO: 1000 / 4988
2022-10-17 21:08:52 - train.py[line:551] - INFO: load:1.42 valid_run:754.71 task_valid:730.43 collect_output:18.64
2022-10-17 21:11:24 - train.py[line:549] - INFO: 1200 / 4988
2022-10-17 21:11:24 - train.py[line:551] - INFO: load:1.45 valid_run:906.64 task_valid:876.73 collect_output:23.07
2022-10-17 21:13:57 - train.py[line:549] - INFO: 1400 / 4988
2022-10-17 21:13:57 - train.py[line:551] - INFO: load:1.47 valid_run:1059.74 task_valid:1023.59 collect_output:28.18
2022-10-17 21:16:28 - train.py[line:549] - INFO: 1600 / 4988
2022-10-17 21:16:28 - train.py[line:551] - INFO: load:1.50 valid_run:1210.66 task_valid:1165.27 collect_output:36.28
2022-10-17 21:18:58 - train.py[line:549] - INFO: 1800 / 4988
2022-10-17 21:18:58 - train.py[line:551] - INFO: load:1.52 valid_run:1360.48 task_valid:1310.62 collect_output:39.57
2022-10-17 21:21:27 - train.py[line:549] - INFO: 2000 / 4988
2022-10-17 21:21:27 - train.py[line:551] - INFO: load:1.55 valid_run:1509.38 task_valid:1454.72 collect_output:43.22
2022-10-17 21:23:57 - train.py[line:549] - INFO: 2200 / 4988
2022-10-17 21:23:57 - train.py[line:551] - INFO: load:1.57 valid_run:1659.31 task_valid:1600.12 collect_output:46.63
2022-10-17 21:26:27 - train.py[line:549] - INFO: 2400 / 4988
2022-10-17 21:26:27 - train.py[line:551] - INFO: load:1.60 valid_run:1809.01 task_valid:1745.20 collect_output:50.24
2022-10-17 21:28:56 - train.py[line:549] - INFO: 2600 / 4988
2022-10-17 21:28:56 - train.py[line:551] - INFO: load:1.62 valid_run:1958.52 task_valid:1886.99 collect_output:56.93
2022-10-17 21:31:26 - train.py[line:549] - INFO: 2800 / 4988
2022-10-17 21:31:26 - train.py[line:551] - INFO: load:1.65 valid_run:2108.74 task_valid:2032.54 collect_output:60.54
2022-10-17 21:33:57 - train.py[line:549] - INFO: 3000 / 4988
2022-10-17 21:33:57 - train.py[line:551] - INFO: load:1.68 valid_run:2259.19 task_valid:2179.69 collect_output:62.78
2022-10-17 21:36:27 - train.py[line:549] - INFO: 3200 / 4988
2022-10-17 21:36:27 - train.py[line:551] - INFO: load:1.70 valid_run:2408.89 task_valid:2323.94 collect_output:67.18
2022-10-17 21:38:58 - train.py[line:549] - INFO: 3400 / 4988
2022-10-17 21:38:58 - train.py[line:551] - INFO: load:1.73 valid_run:2560.17 task_valid:2469.54 collect_output:71.82
2022-10-17 21:41:29 - train.py[line:549] - INFO: 3600 / 4988
2022-10-17 21:41:29 - train.py[line:551] - INFO: load:1.75 valid_run:2710.62 task_valid:2616.60 collect_output:74.17
2022-10-17 21:43:56 - train.py[line:549] - INFO: 3800 / 4988
2022-10-17 21:43:56 - train.py[line:551] - INFO: load:1.78 valid_run:2858.47 task_valid:2758.48 collect_output:79.10
2022-10-17 21:46:26 - train.py[line:549] - INFO: 4000 / 4988
2022-10-17 21:46:26 - train.py[line:551] - INFO: load:1.81 valid_run:3008.40 task_valid:2903.56 collect_output:82.93
2022-10-17 21:48:58 - train.py[line:549] - INFO: 4200 / 4988
2022-10-17 21:48:58 - train.py[line:551] - INFO: load:1.83 valid_run:3159.73 task_valid:3048.13 collect_output:88.66
2022-10-17 21:51:27 - train.py[line:549] - INFO: 4400 / 4988
2022-10-17 21:51:27 - train.py[line:551] - INFO: load:1.86 valid_run:3308.99 task_valid:3192.69 collect_output:92.36
2022-10-17 21:53:58 - train.py[line:549] - INFO: 4600 / 4988
2022-10-17 21:53:58 - train.py[line:551] - INFO: load:1.88 valid_run:3460.16 task_valid:3339.11 collect_output:96.08
2022-10-17 21:56:30 - train.py[line:549] - INFO: 4800 / 4988
2022-10-17 21:56:30 - train.py[line:551] - INFO: load:1.91 valid_run:3611.34 task_valid:3485.65 collect_output:99.71

====================================================================================================
SGG eval:     R @ 50: 0.4383;     R @ 100: 0.4769;     R @ 500: 0.5110;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2707;    mR @ 100: 0.3323;    mR @ 500: 0.3705;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5780) (covered in:0.7500) (covering:0.3714) (eating:0.5294) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4032) (lying on:0.0333) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6146) (playing:0.0000) (riding:0.6454) (says:0.0000) (sitting on:0.6188) (standing on:0.2333) (using:0.5500) (walking in:0.3333) (walking on:0.2342) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================

2022-10-17 21:59:01 - train.py[line:487] - INFO: 0.47694285714285717

====================================================================================================
SGG eval:     R @ 50: 0.4383;     R @ 100: 0.4769;     R @ 500: 0.5110;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2707;    mR @ 100: 0.3323;    mR @ 500: 0.3705;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5780) (covered in:0.7500) (covering:0.3714) (eating:0.5294) (flying in:0.5000) (growing on:0.0000) (hanging from:0.4032) (lying on:0.0333) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6146) (playing:0.0000) (riding:0.6454) (says:0.0000) (sitting on:0.6188) (standing on:0.2333) (using:0.5500) (walking in:0.3333) (walking on:0.2342) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================

2022-10-17 21:59:01 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-17 21:59:01 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.375 | loss_v1 0 | loss_v2 0 | nll_loss 0.221 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.476943 | ppl 1.17 | vqa_score 0.3919 | wps 119.2 | wpb 89.9 | bsz 30 | num_updates 37000 | best_R@100 0.581461
2022-10-17 21:59:01 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 37000 updates
2022-10-17 21:59:01 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_37000.pt
2022-10-17 21:59:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_37000.pt
2022-10-17 21:59:09 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_37000.pt (epoch 1 @ 37000 updates, score 0.47694285714285717) (writing took 8.240840611979365 seconds)
2022-10-17 21:59:21 - progress_bar.py[line:274] - INFO: epoch 001:  37061 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=0.3, ups=0, wpb=110.6, bsz=40, num_updates=37010, lr=4.83143e-05, gnorm=0.949, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=181330
2022-10-17 21:59:32 - progress_bar.py[line:274] - INFO: epoch 001:  37071 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=37020, lr=4.83133e-05, gnorm=0.944, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=181341
2022-10-17 21:59:43 - progress_bar.py[line:274] - INFO: epoch 001:  37081 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.1, ups=0.89, wpb=108.9, bsz=40, num_updates=37030, lr=4.83123e-05, gnorm=0.765, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=181352
2022-10-17 21:59:54 - progress_bar.py[line:274] - INFO: epoch 001:  37091 / 102288 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=37040, lr=4.83112e-05, gnorm=0.934, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=181363
2022-10-17 22:00:06 - progress_bar.py[line:274] - INFO: epoch 001:  37101 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.1, ups=0.88, wpb=109.1, bsz=40, num_updates=37050, lr=4.83102e-05, gnorm=0.912, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=181375
2022-10-17 22:00:17 - progress_bar.py[line:274] - INFO: epoch 001:  37111 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.4, ups=0.9, wpb=108.9, bsz=40, num_updates=37060, lr=4.83092e-05, gnorm=0.767, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=181386
2022-10-17 22:00:28 - progress_bar.py[line:274] - INFO: epoch 001:  37121 / 102288 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.5, ups=0.87, wpb=112, bsz=40, num_updates=37070, lr=4.83082e-05, gnorm=0.87, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=181397
2022-10-17 22:00:39 - progress_bar.py[line:274] - INFO: epoch 001:  37131 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.8, ups=0.9, wpb=109.3, bsz=40, num_updates=37080, lr=4.83072e-05, gnorm=1.158, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181408
2022-10-17 22:00:50 - progress_bar.py[line:274] - INFO: epoch 001:  37141 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.6, ups=0.9, wpb=109.8, bsz=40, num_updates=37090, lr=4.83062e-05, gnorm=1.076, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181419
2022-10-17 22:01:02 - progress_bar.py[line:274] - INFO: epoch 001:  37151 / 102288 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.6, ups=0.89, wpb=111.5, bsz=40, num_updates=37100, lr=4.83051e-05, gnorm=0.935, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=181431
2022-10-17 22:01:13 - progress_bar.py[line:274] - INFO: epoch 001:  37161 / 102288 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=37110, lr=4.83041e-05, gnorm=0.94, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181442
2022-10-17 22:01:25 - progress_bar.py[line:274] - INFO: epoch 001:  37171 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.3, ups=0.87, wpb=109.7, bsz=40, num_updates=37120, lr=4.83031e-05, gnorm=1.108, clip=70, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=181453
2022-10-17 22:01:36 - progress_bar.py[line:274] - INFO: epoch 001:  37181 / 102288 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.4, ups=0.87, wpb=110.9, bsz=40, num_updates=37130, lr=4.83021e-05, gnorm=0.763, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181465
2022-10-17 22:01:47 - progress_bar.py[line:274] - INFO: epoch 001:  37191 / 102288 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=102.7, ups=0.93, wpb=110.3, bsz=40, num_updates=37140, lr=4.83011e-05, gnorm=0.751, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181476
2022-10-17 22:01:58 - progress_bar.py[line:274] - INFO: epoch 001:  37201 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=37150, lr=4.83e-05, gnorm=1.052, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=181487
2022-10-17 22:02:10 - progress_bar.py[line:274] - INFO: epoch 001:  37211 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.7, ups=0.89, wpb=110, bsz=40, num_updates=37160, lr=4.8299e-05, gnorm=1.023, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181499
2022-10-17 22:02:21 - progress_bar.py[line:274] - INFO: epoch 001:  37221 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=37170, lr=4.8298e-05, gnorm=0.875, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=181510
2022-10-17 22:02:32 - progress_bar.py[line:274] - INFO: epoch 001:  37231 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=37180, lr=4.8297e-05, gnorm=0.818, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=181521
2022-10-17 22:02:43 - progress_bar.py[line:274] - INFO: epoch 001:  37241 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.4, ups=0.93, wpb=109.9, bsz=40, num_updates=37190, lr=4.8296e-05, gnorm=0.815, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181532
2022-10-17 22:02:54 - progress_bar.py[line:274] - INFO: epoch 001:  37251 / 102288 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=37200, lr=4.8295e-05, gnorm=0.979, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=181543
2022-10-17 22:03:05 - progress_bar.py[line:274] - INFO: epoch 001:  37261 / 102288 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=37210, lr=4.82939e-05, gnorm=0.88, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181554
2022-10-17 22:03:16 - progress_bar.py[line:274] - INFO: epoch 001:  37271 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.6, ups=0.91, wpb=108.8, bsz=40, num_updates=37220, lr=4.82929e-05, gnorm=1.081, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181565
2022-10-17 22:03:28 - progress_bar.py[line:274] - INFO: epoch 001:  37281 / 102288 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=37230, lr=4.82919e-05, gnorm=1.057, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=181576
2022-10-17 22:03:39 - progress_bar.py[line:274] - INFO: epoch 001:  37291 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.9, wpb=110.4, bsz=40, num_updates=37240, lr=4.82909e-05, gnorm=1.079, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=181588
2022-10-17 22:03:50 - progress_bar.py[line:274] - INFO: epoch 001:  37301 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.6, ups=0.92, wpb=111, bsz=40, num_updates=37250, lr=4.82899e-05, gnorm=1.006, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=181599
2022-10-17 22:04:01 - progress_bar.py[line:274] - INFO: epoch 001:  37311 / 102288 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.9, ups=0.9, wpb=111.8, bsz=40, num_updates=37260, lr=4.82888e-05, gnorm=0.871, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=181610
2022-10-17 22:04:12 - progress_bar.py[line:274] - INFO: epoch 001:  37321 / 102288 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=37270, lr=4.82878e-05, gnorm=0.984, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181621
2022-10-17 22:04:24 - progress_bar.py[line:274] - INFO: epoch 001:  37331 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.7, ups=0.88, wpb=108.6, bsz=40, num_updates=37280, lr=4.82868e-05, gnorm=0.802, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=181632
2022-10-17 22:04:35 - progress_bar.py[line:274] - INFO: epoch 001:  37341 / 102288 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.4, ups=0.87, wpb=109.9, bsz=40, num_updates=37290, lr=4.82858e-05, gnorm=0.922, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=181644
2022-10-17 22:04:47 - progress_bar.py[line:274] - INFO: epoch 001:  37351 / 102288 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=37300, lr=4.82848e-05, gnorm=1.056, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=181655
2022-10-17 22:04:58 - progress_bar.py[line:274] - INFO: epoch 001:  37361 / 102288 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.1, ups=0.87, wpb=110.4, bsz=40, num_updates=37310, lr=4.82837e-05, gnorm=0.961, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181667
2022-10-17 22:05:09 - progress_bar.py[line:274] - INFO: epoch 001:  37371 / 102288 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.3, ups=0.9, wpb=110.2, bsz=40, num_updates=37320, lr=4.82827e-05, gnorm=0.983, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=181678
2022-10-17 22:05:20 - progress_bar.py[line:274] - INFO: epoch 001:  37381 / 102288 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.2, ups=0.91, wpb=110.9, bsz=40, num_updates=37330, lr=4.82817e-05, gnorm=1.139, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=181689
2022-10-17 22:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  37391 / 102288 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=37340, lr=4.82807e-05, gnorm=0.885, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=181700
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2572823
Killing subprocess 2572824
Main process received SIGINT, exiting
2022-10-18 19:25:22 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-18 19:25:22 - utils.py[line:261] - INFO: Start init
2022-10-18 19:25:23 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-18 19:25:23 - utils.py[line:261] - INFO: Start init
2022-10-18 19:25:23 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-18 19:25:23 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-18 19:25:23 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-18 19:25:23 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-18 19:25:34 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_BERT_v1_data', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_BERT_v1_data', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-18 19:25:34 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-18 19:25:34 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-10-18 19:25:38 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-18 19:25:38 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-18 19:25:38 - train.py[line:119] - INFO: model: OFAModel
2022-10-18 19:25:38 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-18 19:25:38 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-18 19:25:38 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-18 19:25:39 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-18 19:25:39 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-18 19:25:40 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-18 19:25:40 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-18 19:25:40 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-18 19:25:40 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-18 19:25:40 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-18 19:25:40 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-10-18 19:25:40 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-10-18 19:25:50 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-10-18 19:25:50 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-10-18 19:25:51 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-18 19:25:51 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-10-18 19:25:51 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-10-18 19:25:51 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E0.tsv slice_id 1 row count 2045757 total row count 4091514
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_BERT_v1train_NA1_E0.tsv slice_id 0 row count 2045757 total row count 4091514
2022-10-18 19:25:59 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 511440, warmup steps 20457, warmup_factor 4.8883022926137754e-05
Total steps 511440, warmup steps 20457, warmup_factor 4.8883022926137754e-05
2022-10-18 19:26:00 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-18 19:26:00 - train.py[line:312] - INFO: Start iterating over samples
2022-10-18 19:26:25 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 102288 loss=1.296, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=85.2, ups=0.77, wpb=111, bsz=40, num_updates=10, lr=2.44415e-08, gnorm=13.271, clip=100, loss_scale=128, train_wall=20, gb_free=10.6, ema_decay=0.9999, wall=44
2022-10-18 19:26:36 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 102288 loss=1.335, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=94.1, ups=0.85, wpb=110.6, bsz=40, num_updates=20, lr=4.8883e-08, gnorm=13.418, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=56
2022-10-18 19:26:48 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 102288 loss=1.348, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=94.5, ups=0.85, wpb=111.4, bsz=40, num_updates=30, lr=7.33245e-08, gnorm=14.695, clip=100, loss_scale=128, train_wall=12, gb_free=11, ema_decay=0.9999, wall=68
2022-10-18 19:26:59 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 102288 loss=1.497, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=97, ups=0.89, wpb=108.4, bsz=40, num_updates=40, lr=9.7766e-08, gnorm=17.402, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79
2022-10-18 19:27:10 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 102288 loss=1.318, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=100, ups=0.91, wpb=109.9, bsz=40, num_updates=50, lr=1.22208e-07, gnorm=13.271, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=90
2022-10-18 19:27:22 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 102288 loss=1.344, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=96.5, ups=0.86, wpb=111.8, bsz=40, num_updates=60, lr=1.46649e-07, gnorm=13.472, clip=100, loss_scale=128, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=102
2022-10-18 19:27:33 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 102288 loss=1.397, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=99.2, ups=0.91, wpb=109, bsz=40, num_updates=70, lr=1.71091e-07, gnorm=14.194, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=113
2022-10-18 19:27:44 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 102288 loss=1.324, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=100.7, ups=0.9, wpb=111.6, bsz=40, num_updates=80, lr=1.95532e-07, gnorm=13.166, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=124
2022-10-18 19:27:56 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 102288 loss=1.446, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=90.9, ups=0.83, wpb=109.5, bsz=40, num_updates=90, lr=2.19974e-07, gnorm=14.231, clip=100, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=136
2022-10-18 19:28:07 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 102288 loss=1.307, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=100, lr=2.44415e-07, gnorm=13.236, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=147
2022-10-18 19:28:19 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 102288 loss=1.342, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=96.1, ups=0.88, wpb=109.6, bsz=40, num_updates=110, lr=2.68857e-07, gnorm=13.809, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=159
2022-10-18 19:28:30 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 102288 loss=1.174, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=99.3, ups=0.89, wpb=112.2, bsz=40, num_updates=120, lr=2.93298e-07, gnorm=11.51, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=170
2022-10-18 19:28:42 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 102288 loss=1.236, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=97.5, ups=0.89, wpb=109.7, bsz=40, num_updates=130, lr=3.1774e-07, gnorm=12.6, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=181
2022-10-18 19:28:53 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 102288 loss=1.244, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=98.1, ups=0.9, wpb=108.8, bsz=40, num_updates=140, lr=3.42181e-07, gnorm=10.233, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=192
2022-10-18 19:29:04 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 102288 loss=1.22, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=150, lr=3.66623e-07, gnorm=10.396, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=204
2022-10-18 19:29:15 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 102288 loss=1.215, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=98.1, ups=0.89, wpb=110.4, bsz=40, num_updates=160, lr=3.91064e-07, gnorm=9.449, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=215
2022-10-18 19:29:26 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 102288 loss=1.134, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=170, lr=4.15506e-07, gnorm=8.701, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=226
2022-10-18 19:29:38 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 102288 loss=1.168, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=97.1, ups=0.89, wpb=109.5, bsz=40, num_updates=180, lr=4.39947e-07, gnorm=9.049, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=237
2022-10-18 19:29:49 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 102288 loss=0.992, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=98.5, ups=0.89, wpb=110.8, bsz=40, num_updates=190, lr=4.64389e-07, gnorm=7.619, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=249
2022-10-18 19:30:00 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 102288 loss=1.024, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=98.3, ups=0.9, wpb=109.8, bsz=40, num_updates=200, lr=4.8883e-07, gnorm=7.533, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=260
2022-10-18 19:30:11 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 102288 loss=1.025, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=97.5, ups=0.89, wpb=109.9, bsz=40, num_updates=210, lr=5.13272e-07, gnorm=6.971, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=271
2022-10-18 19:30:23 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 102288 loss=1.065, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=95.8, ups=0.86, wpb=110.8, bsz=40, num_updates=220, lr=5.37713e-07, gnorm=7.111, clip=100, loss_scale=128, train_wall=12, gb_free=11, ema_decay=0.9999, wall=283
2022-10-18 19:30:34 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 102288 loss=0.978, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=94.6, ups=0.87, wpb=109.1, bsz=40, num_updates=230, lr=5.62155e-07, gnorm=6.352, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=294
2022-10-18 19:30:46 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 102288 loss=0.986, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=95.3, ups=0.87, wpb=110.1, bsz=40, num_updates=240, lr=5.86596e-07, gnorm=5.822, clip=100, loss_scale=128, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=306
2022-10-18 19:30:57 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 102288 loss=0.927, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=99.5, ups=0.9, wpb=110.7, bsz=40, num_updates=250, lr=6.11038e-07, gnorm=5.688, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=317
2022-10-18 19:31:08 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 102288 loss=0.904, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=98.8, ups=0.89, wpb=111.1, bsz=40, num_updates=260, lr=6.35479e-07, gnorm=5.538, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=328
2022-10-18 19:31:20 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 102288 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=95.7, ups=0.87, wpb=110.2, bsz=40, num_updates=270, lr=6.59921e-07, gnorm=5.461, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=340
2022-10-18 19:31:31 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 102288 loss=1.003, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=97.3, ups=0.89, wpb=109.3, bsz=40, num_updates=280, lr=6.84362e-07, gnorm=5.831, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=351
2022-10-18 19:31:42 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 102288 loss=0.923, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=97.3, ups=0.89, wpb=109.6, bsz=40, num_updates=290, lr=7.08804e-07, gnorm=5.291, clip=100, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=362
2022-10-18 19:31:53 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 102288 loss=0.925, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=300, lr=7.33245e-07, gnorm=4.933, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=373
2022-10-18 19:32:05 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 102288 loss=0.858, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=97.9, ups=0.89, wpb=110.2, bsz=40, num_updates=310, lr=7.57687e-07, gnorm=4.299, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=385
2022-10-18 19:32:16 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 102288 loss=0.902, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=99.2, ups=0.9, wpb=110.3, bsz=40, num_updates=320, lr=7.82128e-07, gnorm=4.503, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=396
2022-10-18 19:32:27 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 102288 loss=0.918, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=99.8, ups=0.91, wpb=109.3, bsz=40, num_updates=330, lr=8.0657e-07, gnorm=4.493, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=407
2022-10-18 19:32:38 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 102288 loss=0.875, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=98.1, ups=0.89, wpb=110.5, bsz=40, num_updates=340, lr=8.31011e-07, gnorm=4.228, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=418
2022-10-18 19:32:49 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 102288 loss=0.913, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=97.7, ups=0.89, wpb=110.3, bsz=40, num_updates=350, lr=8.55453e-07, gnorm=4.127, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=429
2022-10-18 19:33:01 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 102288 loss=0.903, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=99.4, ups=0.9, wpb=110.4, bsz=40, num_updates=360, lr=8.79894e-07, gnorm=3.995, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=440
2022-10-18 19:33:12 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 102288 loss=0.845, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=370, lr=9.04336e-07, gnorm=3.775, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=451
2022-10-18 19:33:23 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 102288 loss=0.852, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=97.8, ups=0.89, wpb=110.3, bsz=40, num_updates=380, lr=9.28777e-07, gnorm=3.613, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=463
2022-10-18 19:33:34 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 102288 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=96.9, ups=0.87, wpb=111.4, bsz=40, num_updates=390, lr=9.53219e-07, gnorm=3.686, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=474
2022-10-18 19:33:46 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 102288 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=98.6, ups=0.9, wpb=109.6, bsz=40, num_updates=400, lr=9.7766e-07, gnorm=3.829, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=485
2022-10-18 19:33:57 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 102288 loss=0.874, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=410, lr=1.0021e-06, gnorm=3.539, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=497
2022-10-18 19:34:08 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 102288 loss=0.861, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=420, lr=1.02654e-06, gnorm=3.824, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=508
2022-10-18 19:34:19 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 102288 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=100.1, ups=0.9, wpb=111.3, bsz=40, num_updates=430, lr=1.05098e-06, gnorm=3.377, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=519
2022-10-18 19:34:30 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 102288 loss=0.837, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=440, lr=1.07543e-06, gnorm=3.035, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=530
2022-10-18 19:34:42 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 102288 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=450, lr=1.09987e-06, gnorm=3.35, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=541
2022-10-18 19:34:52 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 102288 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=101.6, ups=0.92, wpb=109.9, bsz=40, num_updates=460, lr=1.12431e-06, gnorm=3.146, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=552
2022-10-18 19:35:04 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 102288 loss=0.873, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=96.9, ups=0.89, wpb=108.9, bsz=40, num_updates=470, lr=1.14875e-06, gnorm=3.117, clip=100, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=563
2022-10-18 19:35:15 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 102288 loss=0.816, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=480, lr=1.17319e-06, gnorm=3.093, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=575
2022-10-18 19:35:26 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 102288 loss=0.817, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=490, lr=1.19763e-06, gnorm=2.817, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=586
2022-10-18 19:35:37 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 102288 loss=0.834, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=104.4, ups=0.95, wpb=110.2, bsz=40, num_updates=500, lr=1.22208e-06, gnorm=2.881, clip=100, loss_scale=128, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=597
2022-10-18 19:35:48 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 102288 loss=0.815, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=99, ups=0.89, wpb=111.4, bsz=40, num_updates=510, lr=1.24652e-06, gnorm=2.549, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=608
2022-10-18 19:35:59 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 102288 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=99.6, ups=0.9, wpb=110.8, bsz=40, num_updates=520, lr=1.27096e-06, gnorm=2.626, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=619
2022-10-18 19:36:11 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 102288 loss=0.842, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=97.2, ups=0.89, wpb=109.5, bsz=40, num_updates=530, lr=1.2954e-06, gnorm=2.93, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=630
2022-10-18 19:36:22 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 102288 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=540, lr=1.31984e-06, gnorm=2.682, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=642
2022-10-18 19:36:33 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 102288 loss=0.821, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=100, ups=0.91, wpb=109.6, bsz=40, num_updates=550, lr=1.34428e-06, gnorm=2.559, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=653
2022-10-18 19:36:44 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 102288 loss=0.827, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=560, lr=1.36872e-06, gnorm=2.449, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=664
2022-10-18 19:36:55 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 102288 loss=0.813, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=98.3, ups=0.89, wpb=110.7, bsz=40, num_updates=570, lr=1.39317e-06, gnorm=2.376, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=675
2022-10-18 19:37:06 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 102288 loss=0.846, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=580, lr=1.41761e-06, gnorm=2.491, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=686
2022-10-18 19:37:18 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 102288 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=590, lr=1.44205e-06, gnorm=2.368, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=697
2022-10-18 19:37:29 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 102288 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=101.6, ups=0.91, wpb=111.2, bsz=40, num_updates=600, lr=1.46649e-06, gnorm=2.424, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=708
2022-10-18 19:37:40 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 102288 loss=0.819, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=610, lr=1.49093e-06, gnorm=2.478, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=720
2022-10-18 19:37:51 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 102288 loss=0.821, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=96, ups=0.88, wpb=109.3, bsz=40, num_updates=620, lr=1.51537e-06, gnorm=2.252, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=731
2022-10-18 19:38:02 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=102.7, ups=0.92, wpb=111.4, bsz=40, num_updates=630, lr=1.53982e-06, gnorm=2.175, clip=100, loss_scale=256, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=742
2022-10-18 19:38:13 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 102288 loss=0.827, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=101.1, ups=0.91, wpb=110.6, bsz=40, num_updates=640, lr=1.56426e-06, gnorm=2.329, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=753
2022-10-18 19:38:24 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 102288 loss=0.799, loss_v1=0, loss_v2=0, nll_loss=0.731, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=650, lr=1.5887e-06, gnorm=2.264, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=764
2022-10-18 19:38:35 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 102288 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.68, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=660, lr=1.61314e-06, gnorm=2.086, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=775
2022-10-18 19:38:46 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 102288 loss=0.839, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=99.7, ups=0.91, wpb=109.2, bsz=40, num_updates=670, lr=1.63758e-06, gnorm=2.443, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=786
2022-10-18 19:38:58 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 102288 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=99.1, ups=0.89, wpb=111.2, bsz=40, num_updates=680, lr=1.66202e-06, gnorm=2.266, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=797
2022-10-18 19:39:09 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 102288 loss=0.84, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=98.4, ups=0.9, wpb=109.7, bsz=40, num_updates=690, lr=1.68646e-06, gnorm=2.195, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=809
2022-10-18 19:39:20 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.7, ups=0.89, wpb=111.2, bsz=40, num_updates=700, lr=1.71091e-06, gnorm=2.33, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=820
2022-10-18 19:39:31 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 102288 loss=0.813, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=97, ups=0.88, wpb=110.6, bsz=40, num_updates=710, lr=1.73535e-06, gnorm=2.007, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=831
2022-10-18 19:39:43 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 102288 loss=0.85, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=97.3, ups=0.88, wpb=110.8, bsz=40, num_updates=720, lr=1.75979e-06, gnorm=2.12, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=843
2022-10-18 19:39:54 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 102288 loss=0.842, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=730, lr=1.78423e-06, gnorm=2.18, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=854
2022-10-18 19:40:06 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 102288 loss=0.857, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=96, ups=0.88, wpb=109.1, bsz=40, num_updates=740, lr=1.80867e-06, gnorm=2.207, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=865
2022-10-18 19:40:17 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 102288 loss=0.802, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=96.7, ups=0.88, wpb=110.2, bsz=40, num_updates=750, lr=1.83311e-06, gnorm=2.056, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=877
2022-10-18 19:40:28 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 102288 loss=0.818, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=103, ups=0.92, wpb=111.4, bsz=40, num_updates=760, lr=1.85755e-06, gnorm=2.039, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=888
2022-10-18 19:40:39 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 102288 loss=0.851, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=98, ups=0.9, wpb=108.5, bsz=40, num_updates=770, lr=1.882e-06, gnorm=2.124, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=899
2022-10-18 19:40:50 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 102288 loss=0.843, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=98, ups=0.9, wpb=108.6, bsz=40, num_updates=780, lr=1.90644e-06, gnorm=1.976, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=910
2022-10-18 19:41:01 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=97.7, ups=0.88, wpb=111.1, bsz=40, num_updates=790, lr=1.93088e-06, gnorm=2.075, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=921
2022-10-18 19:41:13 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 102288 loss=0.784, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=97.3, ups=0.88, wpb=110.7, bsz=40, num_updates=800, lr=1.95532e-06, gnorm=1.916, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=933
2022-10-18 19:41:24 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 102288 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=98.5, ups=0.88, wpb=111.9, bsz=40, num_updates=810, lr=1.97976e-06, gnorm=1.759, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=944
2022-10-18 19:41:35 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 102288 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=100.7, ups=0.91, wpb=110.6, bsz=40, num_updates=820, lr=2.0042e-06, gnorm=1.879, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=955
2022-10-18 19:41:46 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 102288 loss=0.835, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=830, lr=2.02865e-06, gnorm=1.883, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=966
2022-10-18 19:41:57 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 102288 loss=0.818, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=98.8, ups=0.9, wpb=110.1, bsz=40, num_updates=840, lr=2.05309e-06, gnorm=1.929, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=977
2022-10-18 19:42:08 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=105.4, ups=0.95, wpb=111, bsz=40, num_updates=850, lr=2.07753e-06, gnorm=1.767, clip=100, loss_scale=256, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=988
2022-10-18 19:42:19 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 102288 loss=0.797, loss_v1=0, loss_v2=0, nll_loss=0.726, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=100.8, ups=0.92, wpb=110.1, bsz=40, num_updates=860, lr=2.10197e-06, gnorm=1.881, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=999
2022-10-18 19:42:30 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 102288 loss=0.823, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=100, ups=0.91, wpb=109.4, bsz=40, num_updates=870, lr=2.12641e-06, gnorm=1.888, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1010
2022-10-18 19:42:41 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 102288 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=880, lr=2.15085e-06, gnorm=1.878, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1021
2022-10-18 19:42:52 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 102288 loss=0.79, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=98.5, ups=0.89, wpb=111, bsz=40, num_updates=890, lr=2.17529e-06, gnorm=1.808, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1032
2022-10-18 19:43:03 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 102288 loss=0.794, loss_v1=0, loss_v2=0, nll_loss=0.725, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=98.4, ups=0.89, wpb=110.7, bsz=40, num_updates=900, lr=2.19974e-06, gnorm=1.852, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1043
2022-10-18 19:43:15 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 102288 loss=0.833, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=910, lr=2.22418e-06, gnorm=2.088, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1054
2022-10-18 19:43:26 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 102288 loss=0.794, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=100, ups=0.91, wpb=109.6, bsz=40, num_updates=920, lr=2.24862e-06, gnorm=1.816, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1065
2022-10-18 19:43:37 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 102288 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=96.6, ups=0.88, wpb=109.6, bsz=40, num_updates=930, lr=2.27306e-06, gnorm=1.953, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1077
2022-10-18 19:43:48 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 102288 loss=0.844, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=98.1, ups=0.89, wpb=110.6, bsz=40, num_updates=940, lr=2.2975e-06, gnorm=2.015, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1088
2022-10-18 19:44:00 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 102288 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.726, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=96.1, ups=0.87, wpb=110.8, bsz=40, num_updates=950, lr=2.32194e-06, gnorm=1.844, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1100
2022-10-18 19:44:11 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=960, lr=2.34639e-06, gnorm=1.723, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1111
2022-10-18 19:44:23 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 102288 loss=0.824, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=96.9, ups=0.88, wpb=110.5, bsz=40, num_updates=970, lr=2.37083e-06, gnorm=1.871, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1122
2022-10-18 19:44:34 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.679, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.6, ups=0.89, wpb=112.1, bsz=40, num_updates=980, lr=2.39527e-06, gnorm=1.702, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1134
2022-10-18 19:44:45 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 102288 loss=0.836, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=95.4, ups=0.88, wpb=108.7, bsz=40, num_updates=990, lr=2.41971e-06, gnorm=1.818, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1145
2022-10-18 19:44:56 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=100.5, ups=0.9, wpb=111.7, bsz=40, num_updates=1000, lr=2.44415e-06, gnorm=1.701, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=1156
2022-10-18 19:44:56 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-18 19:44:56 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-18 19:44:58 - train.py[line:549] - INFO: 0 / 4988
2022-10-18 19:44:58 - train.py[line:551] - INFO: load:1.10 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-18 19:47:33 - train.py[line:549] - INFO: 200 / 4988
2022-10-18 19:47:33 - train.py[line:551] - INFO: load:1.13 valid_run:155.21 task_valid:151.42 collect_output:2.73
2022-10-18 19:50:02 - train.py[line:549] - INFO: 400 / 4988
2022-10-18 19:50:02 - train.py[line:551] - INFO: load:1.15 valid_run:304.46 task_valid:294.85 collect_output:7.52
2022-10-18 19:52:36 - train.py[line:549] - INFO: 600 / 4988
2022-10-18 19:52:36 - train.py[line:551] - INFO: load:1.18 valid_run:457.88 task_valid:438.08 collect_output:16.69
2022-10-18 19:55:06 - train.py[line:549] - INFO: 800 / 4988
2022-10-18 19:55:06 - train.py[line:551] - INFO: load:1.20 valid_run:607.56 task_valid:583.18 collect_output:20.26
2022-10-18 19:57:38 - train.py[line:549] - INFO: 1000 / 4988
2022-10-18 19:57:38 - train.py[line:551] - INFO: load:1.23 valid_run:759.95 task_valid:730.42 collect_output:24.43
2022-10-18 20:00:10 - train.py[line:549] - INFO: 1200 / 4988
2022-10-18 20:00:10 - train.py[line:551] - INFO: load:1.25 valid_run:912.01 task_valid:876.16 collect_output:29.73
2022-10-18 20:02:44 - train.py[line:549] - INFO: 1400 / 4988
2022-10-18 20:02:44 - train.py[line:551] - INFO: load:1.28 valid_run:1065.90 task_valid:1022.20 collect_output:36.60
2022-10-18 20:05:17 - train.py[line:549] - INFO: 1600 / 4988
2022-10-18 20:05:17 - train.py[line:551] - INFO: load:1.30 valid_run:1218.17 task_valid:1163.59 collect_output:46.46
2022-10-18 20:07:47 - train.py[line:549] - INFO: 1800 / 4988
2022-10-18 20:07:47 - train.py[line:551] - INFO: load:1.33 valid_run:1368.39 task_valid:1308.42 collect_output:50.85
2022-10-18 20:10:16 - train.py[line:549] - INFO: 2000 / 4988
2022-10-18 20:10:16 - train.py[line:551] - INFO: load:1.35 valid_run:1517.22 task_valid:1451.46 collect_output:55.64
2022-10-18 20:12:46 - train.py[line:549] - INFO: 2200 / 4988
2022-10-18 20:12:46 - train.py[line:551] - INFO: load:1.38 valid_run:1667.30 task_valid:1596.43 collect_output:59.72
2022-10-18 20:15:16 - train.py[line:549] - INFO: 2400 / 4988
2022-10-18 20:15:16 - train.py[line:551] - INFO: load:1.40 valid_run:1817.79 task_valid:1741.60 collect_output:64.04
2022-10-18 20:17:49 - train.py[line:549] - INFO: 2600 / 4988
2022-10-18 20:17:49 - train.py[line:551] - INFO: load:1.44 valid_run:1970.17 task_valid:1885.21 collect_output:71.60
2022-10-18 20:20:23 - train.py[line:549] - INFO: 2800 / 4988
2022-10-18 20:20:23 - train.py[line:551] - INFO: load:1.46 valid_run:2123.79 task_valid:2032.96 collect_output:76.22
2022-10-18 20:22:55 - train.py[line:549] - INFO: 3000 / 4988
2022-10-18 20:22:55 - train.py[line:551] - INFO: load:1.49 valid_run:2276.59 task_valid:2181.80 collect_output:78.92
2022-10-18 20:25:29 - train.py[line:549] - INFO: 3200 / 4988
2022-10-18 20:25:29 - train.py[line:551] - INFO: load:1.53 valid_run:2430.42 task_valid:2328.79 collect_output:84.34
2022-10-18 20:28:06 - train.py[line:549] - INFO: 3400 / 4988
2022-10-18 20:28:06 - train.py[line:551] - INFO: load:1.57 valid_run:2586.89 task_valid:2477.38 collect_output:90.88
2022-10-18 20:30:41 - train.py[line:549] - INFO: 3600 / 4988
2022-10-18 20:30:41 - train.py[line:551] - INFO: load:1.60 valid_run:2741.79 task_valid:2627.49 collect_output:94.30
2022-10-18 20:33:14 - train.py[line:549] - INFO: 3800 / 4988
2022-10-18 20:33:14 - train.py[line:551] - INFO: load:1.63 valid_run:2895.17 task_valid:2772.23 collect_output:101.55
2022-10-18 20:35:50 - train.py[line:549] - INFO: 4000 / 4988
2022-10-18 20:35:50 - train.py[line:551] - INFO: load:1.67 valid_run:3051.01 task_valid:2920.69 collect_output:107.55
2022-10-18 20:38:29 - train.py[line:549] - INFO: 4200 / 4988
2022-10-18 20:38:29 - train.py[line:551] - INFO: load:1.69 valid_run:3209.83 task_valid:3069.59 collect_output:116.03
2022-10-18 20:41:03 - train.py[line:549] - INFO: 4400 / 4988
2022-10-18 20:41:03 - train.py[line:551] - INFO: load:1.72 valid_run:3363.47 task_valid:3217.33 collect_output:120.61
2022-10-18 20:43:35 - train.py[line:549] - INFO: 4600 / 4988
2022-10-18 20:43:35 - train.py[line:551] - INFO: load:1.75 valid_run:3515.31 task_valid:3363.60 collect_output:125.18
2022-10-18 20:46:07 - train.py[line:549] - INFO: 4800 / 4988
2022-10-18 20:46:07 - train.py[line:551] - INFO: load:1.78 valid_run:3667.11 task_valid:3510.28 collect_output:129.29

====================================================================================================
SGG eval:     R @ 50: 0.1418;     R @ 100: 0.2180;     R @ 500: 0.3078;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0676;    mR @ 100: 0.1143;    mR @ 500: 0.1690;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3677) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1814) (says:0.0000) (sitting on:0.2426) (standing on:0.4550) (using:0.0500) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1418;     R @ 100: 0.2180;     R @ 500: 0.3078;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0676;    mR @ 100: 0.1143;    mR @ 500: 0.1690;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3677) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1814) (says:0.0000) (sitting on:0.2426) (standing on:0.4550) (using:0.0500) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2022-10-18 20:48:37 - train.py[line:487] - INFO: 0.21803333333333333
2022-10-18 20:48:38 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-18 20:48:38 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.416 | loss_v1 0 | loss_v2 0 | nll_loss 0.322 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.218033 | ppl 1.25 | vqa_score 0.1577 | wps 117.5 | wpb 89.9 | bsz 30 | num_updates 1000
2022-10-18 20:48:38 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2022-10-18 20:48:38 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-18 20:48:43 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-18 20:48:49 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 0.21803333333333333) (writing took 11.048998016864061 seconds)
2022-10-18 20:49:00 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 102288 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=0.3, ups=0, wpb=110.6, bsz=40, num_updates=1010, lr=2.46859e-06, gnorm=1.719, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5000
2022-10-18 20:49:11 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=101.1, ups=0.91, wpb=111.1, bsz=40, num_updates=1020, lr=2.49303e-06, gnorm=1.714, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5011
2022-10-18 20:49:22 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=103.1, ups=0.93, wpb=111.4, bsz=40, num_updates=1030, lr=2.51748e-06, gnorm=1.479, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=5022
2022-10-18 20:49:33 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 102288 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99.2, ups=0.9, wpb=110.4, bsz=40, num_updates=1040, lr=2.54192e-06, gnorm=1.662, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5033
2022-10-18 20:49:45 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 102288 loss=0.803, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=95.5, ups=0.87, wpb=109.4, bsz=40, num_updates=1050, lr=2.56636e-06, gnorm=1.744, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5045
2022-10-18 20:49:56 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 102288 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=99, ups=0.9, wpb=110.2, bsz=40, num_updates=1060, lr=2.5908e-06, gnorm=1.637, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5056
2022-10-18 20:50:07 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 102288 loss=0.841, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=98.6, ups=0.91, wpb=108.1, bsz=40, num_updates=1070, lr=2.61524e-06, gnorm=1.828, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5067
2022-10-18 20:50:18 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 102288 loss=0.805, loss_v1=0, loss_v2=0, nll_loss=0.74, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=99.1, ups=0.9, wpb=110.1, bsz=40, num_updates=1080, lr=2.63968e-06, gnorm=1.739, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5078
2022-10-18 20:50:29 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 102288 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=96.8, ups=0.89, wpb=108.8, bsz=40, num_updates=1090, lr=2.66412e-06, gnorm=1.804, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5089
2022-10-18 20:50:40 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=101, ups=0.92, wpb=110.2, bsz=40, num_updates=1100, lr=2.68857e-06, gnorm=1.849, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5100
2022-10-18 20:50:52 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 102288 loss=0.82, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=95.4, ups=0.87, wpb=110, bsz=40, num_updates=1110, lr=2.71301e-06, gnorm=1.756, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5111
2022-10-18 20:51:03 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 102288 loss=0.76, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=102.1, ups=0.91, wpb=111.6, bsz=40, num_updates=1120, lr=2.73745e-06, gnorm=1.6, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5122
2022-10-18 20:51:13 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 102288 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.703, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=101.7, ups=0.93, wpb=109.8, bsz=40, num_updates=1130, lr=2.76189e-06, gnorm=1.615, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5133
2022-10-18 20:51:24 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 102288 loss=0.807, loss_v1=0, loss_v2=0, nll_loss=0.741, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=100.8, ups=0.91, wpb=110.6, bsz=40, num_updates=1140, lr=2.78633e-06, gnorm=1.669, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5144
2022-10-18 20:51:36 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 102288 loss=0.808, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=1150, lr=2.81077e-06, gnorm=1.653, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5155
2022-10-18 20:51:47 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 102288 loss=0.799, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99.9, ups=0.9, wpb=111.2, bsz=40, num_updates=1160, lr=2.83522e-06, gnorm=1.626, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5166
2022-10-18 20:51:58 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 102288 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.695, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=1170, lr=2.85966e-06, gnorm=1.64, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5178
2022-10-18 20:52:10 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 102288 loss=0.824, loss_v1=0, loss_v2=0, nll_loss=0.754, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=95.7, ups=0.88, wpb=108.7, bsz=40, num_updates=1180, lr=2.8841e-06, gnorm=1.788, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5189
2022-10-18 20:52:21 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 102288 loss=0.826, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=1190, lr=2.90854e-06, gnorm=1.84, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5201
2022-10-18 20:52:32 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=1200, lr=2.93298e-06, gnorm=1.671, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5212
2022-10-18 20:52:44 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=95.9, ups=0.88, wpb=109.1, bsz=40, num_updates=1210, lr=2.95742e-06, gnorm=1.773, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5223
2022-10-18 20:52:55 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 102288 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=1220, lr=2.98186e-06, gnorm=1.729, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5234
2022-10-18 20:53:06 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 102288 loss=0.811, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=100.4, ups=0.91, wpb=109.9, bsz=40, num_updates=1230, lr=3.00631e-06, gnorm=1.763, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5245
2022-10-18 20:53:17 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 102288 loss=0.809, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=98.5, ups=0.9, wpb=109, bsz=40, num_updates=1240, lr=3.03075e-06, gnorm=1.618, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5257
2022-10-18 20:53:28 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 102288 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.8, ups=0.88, wpb=111.2, bsz=40, num_updates=1250, lr=3.05519e-06, gnorm=1.673, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5268
2022-10-18 20:53:40 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=1260, lr=3.07963e-06, gnorm=1.616, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5279
2022-10-18 20:53:51 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 102288 loss=0.822, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=97.2, ups=0.89, wpb=109.3, bsz=40, num_updates=1270, lr=3.10407e-06, gnorm=1.753, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5291
2022-10-18 20:54:01 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 102288 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=103.2, ups=0.95, wpb=109.1, bsz=40, num_updates=1280, lr=3.12851e-06, gnorm=1.552, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5301
2022-10-18 20:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 102288 loss=0.83, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=93.5, ups=0.87, wpb=107.8, bsz=40, num_updates=1290, lr=3.15295e-06, gnorm=1.559, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5313
2022-10-18 20:54:24 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 102288 loss=0.793, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=101.3, ups=0.91, wpb=110.9, bsz=40, num_updates=1300, lr=3.1774e-06, gnorm=1.547, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5324
2022-10-18 20:54:35 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 102288 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=1310, lr=3.20184e-06, gnorm=1.643, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5335
2022-10-18 20:54:46 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 102288 loss=0.801, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=101.5, ups=0.91, wpb=110.9, bsz=40, num_updates=1320, lr=3.22628e-06, gnorm=1.63, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5346
2022-10-18 20:54:57 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 102288 loss=0.765, loss_v1=0, loss_v2=0, nll_loss=0.696, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=1330, lr=3.25072e-06, gnorm=1.589, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5357
2022-10-18 20:55:09 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 102288 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=97, ups=0.88, wpb=110.6, bsz=40, num_updates=1340, lr=3.27516e-06, gnorm=1.485, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5368
2022-10-18 20:55:20 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.679, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=1350, lr=3.2996e-06, gnorm=1.567, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5380
2022-10-18 20:55:31 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 102288 loss=0.792, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=102.2, ups=0.93, wpb=110.2, bsz=40, num_updates=1360, lr=3.32405e-06, gnorm=1.67, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5390
2022-10-18 20:55:42 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 102288 loss=0.799, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99, ups=0.9, wpb=109.7, bsz=40, num_updates=1370, lr=3.34849e-06, gnorm=1.623, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5401
2022-10-18 20:55:53 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=1380, lr=3.37293e-06, gnorm=1.615, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5413
2022-10-18 20:56:04 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=99.8, ups=0.9, wpb=110.8, bsz=40, num_updates=1390, lr=3.39737e-06, gnorm=1.672, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5424
2022-10-18 20:56:15 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=1400, lr=3.42181e-06, gnorm=1.734, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5435
2022-10-18 20:56:27 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 102288 loss=0.805, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=96.4, ups=0.88, wpb=110.1, bsz=40, num_updates=1410, lr=3.44625e-06, gnorm=1.74, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5447
2022-10-18 20:56:38 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.694, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99, ups=0.9, wpb=109.8, bsz=40, num_updates=1420, lr=3.47069e-06, gnorm=1.621, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5458
2022-10-18 20:56:49 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 102288 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=1430, lr=3.49514e-06, gnorm=1.65, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5469
2022-10-18 20:57:00 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 102288 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=1440, lr=3.51958e-06, gnorm=1.734, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5480
2022-10-18 20:57:12 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=95.2, ups=0.87, wpb=109.8, bsz=40, num_updates=1450, lr=3.54402e-06, gnorm=1.608, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5492
2022-10-18 20:57:23 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.5, ups=0.87, wpb=111.1, bsz=40, num_updates=1460, lr=3.56846e-06, gnorm=1.655, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5503
2022-10-18 20:57:35 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.7, ups=0.91, wpb=109.9, bsz=40, num_updates=1470, lr=3.5929e-06, gnorm=1.655, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5514
2022-10-18 20:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 102288 loss=0.806, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=1480, lr=3.61734e-06, gnorm=1.638, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5526
2022-10-18 20:57:57 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.4, ups=0.87, wpb=112.1, bsz=40, num_updates=1490, lr=3.64179e-06, gnorm=1.554, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5537
2022-10-18 20:58:09 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 102288 loss=0.81, loss_v1=0, loss_v2=0, nll_loss=0.74, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=95.8, ups=0.88, wpb=109.3, bsz=40, num_updates=1500, lr=3.66623e-06, gnorm=1.655, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5549
2022-10-18 20:58:20 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 102288 loss=0.818, loss_v1=0, loss_v2=0, nll_loss=0.754, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=1510, lr=3.69067e-06, gnorm=1.667, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5560
2022-10-18 20:58:31 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.692, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=1520, lr=3.71511e-06, gnorm=1.671, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5571
2022-10-18 20:58:43 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.704, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=1530, lr=3.73955e-06, gnorm=1.556, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5582
2022-10-18 20:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 102288 loss=0.797, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=1540, lr=3.76399e-06, gnorm=1.643, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5594
2022-10-18 20:59:06 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 102288 loss=0.792, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=94.5, ups=0.87, wpb=109.2, bsz=40, num_updates=1550, lr=3.78843e-06, gnorm=1.643, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5605
2022-10-18 20:59:17 - progress_bar.py[line:274] - INFO: epoch 001:   1560 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.4, ups=0.89, wpb=109.6, bsz=40, num_updates=1560, lr=3.81288e-06, gnorm=1.603, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5617
2022-10-18 20:59:28 - progress_bar.py[line:274] - INFO: epoch 001:   1570 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=103.4, ups=0.93, wpb=111, bsz=40, num_updates=1570, lr=3.83732e-06, gnorm=1.59, clip=100, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5627
2022-10-18 20:59:38 - progress_bar.py[line:274] - INFO: epoch 001:   1580 / 102288 loss=0.796, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=102.3, ups=0.93, wpb=110.1, bsz=40, num_updates=1580, lr=3.86176e-06, gnorm=1.636, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5638
2022-10-18 20:59:50 - progress_bar.py[line:274] - INFO: epoch 001:   1590 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=1590, lr=3.8862e-06, gnorm=1.487, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5649
2022-10-18 21:00:01 - progress_bar.py[line:274] - INFO: epoch 001:   1600 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.6, ups=0.88, wpb=110.3, bsz=40, num_updates=1600, lr=3.91064e-06, gnorm=1.56, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5661
2022-10-18 21:00:13 - progress_bar.py[line:274] - INFO: epoch 001:   1610 / 102288 loss=0.773, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=94.6, ups=0.86, wpb=110, bsz=40, num_updates=1610, lr=3.93508e-06, gnorm=1.631, clip=100, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5673
2022-10-18 21:00:24 - progress_bar.py[line:274] - INFO: epoch 001:   1620 / 102288 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.72, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=98.8, ups=0.89, wpb=111.3, bsz=40, num_updates=1620, lr=3.95952e-06, gnorm=1.64, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5684
2022-10-18 21:00:35 - progress_bar.py[line:274] - INFO: epoch 001:   1630 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.3, ups=0.91, wpb=110.1, bsz=40, num_updates=1630, lr=3.98397e-06, gnorm=1.573, clip=100, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5695
2022-10-18 21:00:47 - progress_bar.py[line:274] - INFO: epoch 001:   1640 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=1640, lr=4.00841e-06, gnorm=1.59, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5706
2022-10-18 21:00:58 - progress_bar.py[line:274] - INFO: epoch 001:   1650 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=1650, lr=4.03285e-06, gnorm=1.567, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5717
2022-10-18 21:01:09 - progress_bar.py[line:274] - INFO: epoch 001:   1660 / 102288 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=1660, lr=4.05729e-06, gnorm=1.647, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5729
2022-10-18 21:01:20 - progress_bar.py[line:274] - INFO: epoch 001:   1670 / 102288 loss=0.783, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=1670, lr=4.08173e-06, gnorm=1.56, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5740
2022-10-18 21:01:31 - progress_bar.py[line:274] - INFO: epoch 001:   1680 / 102288 loss=0.829, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=100.1, ups=0.92, wpb=108.6, bsz=40, num_updates=1680, lr=4.10617e-06, gnorm=1.75, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5751
2022-10-18 21:01:43 - progress_bar.py[line:274] - INFO: epoch 001:   1690 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.717, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=97.8, ups=0.88, wpb=110.7, bsz=40, num_updates=1690, lr=4.13062e-06, gnorm=1.576, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5762
2022-10-18 21:01:53 - progress_bar.py[line:274] - INFO: epoch 001:   1700 / 102288 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=102.6, ups=0.93, wpb=110.8, bsz=40, num_updates=1700, lr=4.15506e-06, gnorm=1.514, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5773
2022-10-18 21:02:05 - progress_bar.py[line:274] - INFO: epoch 001:   1710 / 102288 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.8, ups=0.89, wpb=111.3, bsz=40, num_updates=1710, lr=4.1795e-06, gnorm=1.555, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5784
2022-10-18 21:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   1720 / 102288 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.696, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=1720, lr=4.20394e-06, gnorm=1.563, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5796
2022-10-18 21:02:27 - progress_bar.py[line:274] - INFO: epoch 001:   1730 / 102288 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=1730, lr=4.22838e-06, gnorm=1.501, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5807
2022-10-18 21:02:38 - progress_bar.py[line:274] - INFO: epoch 001:   1740 / 102288 loss=0.806, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=101.4, ups=0.92, wpb=109.8, bsz=40, num_updates=1740, lr=4.25282e-06, gnorm=1.492, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5818
2022-10-18 21:02:49 - progress_bar.py[line:274] - INFO: epoch 001:   1750 / 102288 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.693, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.6, ups=0.9, wpb=109.8, bsz=40, num_updates=1750, lr=4.27726e-06, gnorm=1.521, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5829
2022-10-18 21:03:01 - progress_bar.py[line:274] - INFO: epoch 001:   1760 / 102288 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.4, ups=0.89, wpb=110, bsz=40, num_updates=1760, lr=4.30171e-06, gnorm=1.567, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5840
2022-10-18 21:03:12 - progress_bar.py[line:274] - INFO: epoch 001:   1770 / 102288 loss=0.814, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=95, ups=0.88, wpb=107.8, bsz=40, num_updates=1770, lr=4.32615e-06, gnorm=1.564, clip=100, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=5852
2022-10-18 21:03:23 - progress_bar.py[line:274] - INFO: epoch 001:   1780 / 102288 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=99.5, ups=0.9, wpb=111.1, bsz=40, num_updates=1780, lr=4.35059e-06, gnorm=1.537, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5863
2022-10-18 21:03:35 - progress_bar.py[line:274] - INFO: epoch 001:   1790 / 102288 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=96.9, ups=0.88, wpb=109.7, bsz=40, num_updates=1790, lr=4.37503e-06, gnorm=1.526, clip=100, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5874
2022-10-18 21:03:45 - progress_bar.py[line:274] - INFO: epoch 001:   1800 / 102288 loss=0.77, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=101.3, ups=0.91, wpb=111.1, bsz=40, num_updates=1800, lr=4.39947e-06, gnorm=1.443, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5885
2022-10-18 21:03:57 - progress_bar.py[line:274] - INFO: epoch 001:   1810 / 102288 loss=0.804, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=99.7, ups=0.9, wpb=110.9, bsz=40, num_updates=1810, lr=4.42391e-06, gnorm=1.74, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5896
2022-10-18 21:04:08 - progress_bar.py[line:274] - INFO: epoch 001:   1820 / 102288 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.6, ups=0.9, wpb=109.7, bsz=40, num_updates=1820, lr=4.44836e-06, gnorm=1.706, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5908
2022-10-18 21:04:19 - progress_bar.py[line:274] - INFO: epoch 001:   1830 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100.4, ups=0.91, wpb=110.3, bsz=40, num_updates=1830, lr=4.4728e-06, gnorm=1.425, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5919
2022-10-18 21:04:30 - progress_bar.py[line:274] - INFO: epoch 001:   1840 / 102288 loss=0.751, loss_v1=0, loss_v2=0, nll_loss=0.673, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.8, ups=0.89, wpb=111.7, bsz=40, num_updates=1840, lr=4.49724e-06, gnorm=1.649, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5930
2022-10-18 21:04:41 - progress_bar.py[line:274] - INFO: epoch 001:   1850 / 102288 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98, ups=0.89, wpb=110.6, bsz=40, num_updates=1850, lr=4.52168e-06, gnorm=1.673, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5941
2022-10-18 21:04:52 - progress_bar.py[line:274] - INFO: epoch 001:   1860 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=101.3, ups=0.91, wpb=110.8, bsz=40, num_updates=1860, lr=4.54612e-06, gnorm=1.568, clip=100, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=5952
2022-10-18 21:05:04 - progress_bar.py[line:274] - INFO: epoch 001:   1870 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=101.4, ups=0.92, wpb=110.1, bsz=40, num_updates=1870, lr=4.57056e-06, gnorm=1.456, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5963
2022-10-18 21:05:15 - progress_bar.py[line:274] - INFO: epoch 001:   1880 / 102288 loss=0.761, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.2, ups=0.9, wpb=109.1, bsz=40, num_updates=1880, lr=4.595e-06, gnorm=1.547, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5975
2022-10-18 21:05:26 - progress_bar.py[line:274] - INFO: epoch 001:   1890 / 102288 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.68, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.8, ups=0.9, wpb=111, bsz=40, num_updates=1890, lr=4.61945e-06, gnorm=1.537, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5986
2022-10-18 21:05:37 - progress_bar.py[line:274] - INFO: epoch 001:   1900 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=105.5, ups=0.95, wpb=110.9, bsz=40, num_updates=1900, lr=4.64389e-06, gnorm=1.528, clip=100, loss_scale=1024, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=5996
2022-10-18 21:05:48 - progress_bar.py[line:274] - INFO: epoch 001:   1910 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=95.8, ups=0.87, wpb=110.7, bsz=40, num_updates=1910, lr=4.66833e-06, gnorm=1.653, clip=100, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6008
2022-10-18 21:05:59 - progress_bar.py[line:274] - INFO: epoch 001:   1920 / 102288 loss=0.835, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=97.7, ups=0.91, wpb=107.7, bsz=40, num_updates=1920, lr=4.69277e-06, gnorm=1.585, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6019
2022-10-18 21:06:04 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-18 21:06:12 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=88, ups=0.8, wpb=109.8, bsz=40, num_updates=1930, lr=4.71721e-06, gnorm=1.538, clip=100, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6032
2022-10-18 21:06:23 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 102288 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.689, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.7, ups=0.89, wpb=110.1, bsz=40, num_updates=1940, lr=4.74165e-06, gnorm=1.429, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6043
2022-10-18 21:06:35 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97, ups=0.87, wpb=111, bsz=40, num_updates=1950, lr=4.76609e-06, gnorm=1.546, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6054
2022-10-18 21:06:46 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97, ups=0.87, wpb=111.3, bsz=40, num_updates=1960, lr=4.79054e-06, gnorm=1.435, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6066
2022-10-18 21:06:57 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 102288 loss=0.803, loss_v1=0, loss_v2=0, nll_loss=0.731, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=102.2, ups=0.94, wpb=109.3, bsz=40, num_updates=1970, lr=4.81498e-06, gnorm=1.51, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6077
2022-10-18 21:07:08 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=97.5, ups=0.89, wpb=109.9, bsz=40, num_updates=1980, lr=4.83942e-06, gnorm=1.474, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=6088
2022-10-18 21:07:19 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 102288 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.2, ups=0.9, wpb=110.3, bsz=40, num_updates=1990, lr=4.86386e-06, gnorm=1.552, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6099
2022-10-18 21:07:31 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 102288 loss=0.806, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=2000, lr=4.8883e-06, gnorm=1.711, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6110
2022-10-18 21:07:31 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-18 21:07:32 - train.py[line:549] - INFO: 0 / 4988
2022-10-18 21:07:32 - train.py[line:551] - INFO: load:1.09 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-18 21:10:06 - train.py[line:549] - INFO: 200 / 4988
2022-10-18 21:10:06 - train.py[line:551] - INFO: load:1.12 valid_run:154.13 task_valid:149.30 collect_output:3.55
2022-10-18 21:12:38 - train.py[line:549] - INFO: 400 / 4988
2022-10-18 21:12:38 - train.py[line:551] - INFO: load:1.14 valid_run:305.56 task_valid:294.14 collect_output:9.00
2022-10-18 21:15:13 - train.py[line:549] - INFO: 600 / 4988
2022-10-18 21:15:13 - train.py[line:551] - INFO: load:1.17 valid_run:461.09 task_valid:438.70 collect_output:18.82
2022-10-18 21:17:45 - train.py[line:549] - INFO: 800 / 4988
2022-10-18 21:17:45 - train.py[line:551] - INFO: load:1.19 valid_run:612.27 task_valid:584.57 collect_output:23.02
2022-10-18 21:20:20 - train.py[line:549] - INFO: 1000 / 4988
2022-10-18 21:20:20 - train.py[line:551] - INFO: load:1.22 valid_run:767.32 task_valid:733.44 collect_output:27.92
2022-10-18 21:22:54 - train.py[line:549] - INFO: 1200 / 4988
2022-10-18 21:22:54 - train.py[line:551] - INFO: load:1.25 valid_run:921.50 task_valid:879.96 collect_output:34.47
2022-10-18 21:25:28 - train.py[line:549] - INFO: 1400 / 4988
2022-10-18 21:25:28 - train.py[line:551] - INFO: load:1.27 valid_run:1075.70 task_valid:1026.25 collect_output:41.33
2022-10-18 21:28:00 - train.py[line:549] - INFO: 1600 / 4988
2022-10-18 21:28:00 - train.py[line:551] - INFO: load:1.30 valid_run:1227.34 task_valid:1167.34 collect_output:50.89
2022-10-18 21:30:30 - train.py[line:549] - INFO: 1800 / 4988
2022-10-18 21:30:30 - train.py[line:551] - INFO: load:1.32 valid_run:1377.46 task_valid:1312.21 collect_output:55.12
2022-10-18 21:33:01 - train.py[line:549] - INFO: 2000 / 4988
2022-10-18 21:33:01 - train.py[line:551] - INFO: load:1.35 valid_run:1528.39 task_valid:1456.80 collect_output:60.32
2022-10-18 21:35:35 - train.py[line:549] - INFO: 2200 / 4988
2022-10-18 21:35:35 - train.py[line:551] - INFO: load:1.40 valid_run:1682.47 task_valid:1604.57 collect_output:65.28
2022-10-18 21:38:09 - train.py[line:549] - INFO: 2400 / 4988
2022-10-18 21:38:09 - train.py[line:551] - INFO: load:1.43 valid_run:1836.01 task_valid:1751.97 collect_output:70.13
2022-10-18 21:40:42 - train.py[line:549] - INFO: 2600 / 4988
2022-10-18 21:40:42 - train.py[line:551] - INFO: load:1.47 valid_run:1988.95 task_valid:1895.63 collect_output:78.16
2022-10-18 21:43:15 - train.py[line:549] - INFO: 2800 / 4988
2022-10-18 21:43:15 - train.py[line:551] - INFO: load:1.49 valid_run:2142.37 task_valid:2043.29 collect_output:82.68
2022-10-18 21:45:49 - train.py[line:549] - INFO: 3000 / 4988
2022-10-18 21:45:49 - train.py[line:551] - INFO: load:1.52 valid_run:2295.77 task_valid:2192.04 collect_output:86.11
2022-10-18 21:48:23 - train.py[line:549] - INFO: 3200 / 4988
2022-10-18 21:48:23 - train.py[line:551] - INFO: load:1.54 valid_run:2449.83 task_valid:2338.95 collect_output:91.95
2022-10-18 21:50:56 - train.py[line:549] - INFO: 3400 / 4988
2022-10-18 21:50:56 - train.py[line:551] - INFO: load:1.57 valid_run:2602.63 task_valid:2484.78 collect_output:97.87
2022-10-18 21:53:27 - train.py[line:549] - INFO: 3600 / 4988
2022-10-18 21:53:27 - train.py[line:551] - INFO: load:1.60 valid_run:2753.66 task_valid:2631.85 collect_output:100.81
2022-10-18 21:55:56 - train.py[line:549] - INFO: 3800 / 4988
2022-10-18 21:55:56 - train.py[line:551] - INFO: load:1.62 valid_run:2903.02 task_valid:2773.68 collect_output:107.32
2022-10-18 21:58:28 - train.py[line:549] - INFO: 4000 / 4988
2022-10-18 21:58:28 - train.py[line:551] - INFO: load:1.65 valid_run:3054.44 task_valid:2919.24 collect_output:112.11
2022-10-18 22:01:01 - train.py[line:549] - INFO: 4200 / 4988
2022-10-18 22:01:01 - train.py[line:551] - INFO: load:1.67 valid_run:3207.07 task_valid:3063.93 collect_output:119.04
2022-10-18 22:03:34 - train.py[line:549] - INFO: 4400 / 4988
2022-10-18 22:03:34 - train.py[line:551] - INFO: load:1.70 valid_run:3360.17 task_valid:3211.19 collect_output:123.70
2022-10-18 22:06:09 - train.py[line:549] - INFO: 4600 / 4988
2022-10-18 22:06:09 - train.py[line:551] - INFO: load:1.73 valid_run:3515.14 task_valid:3359.95 collect_output:128.80
2022-10-18 22:08:41 - train.py[line:549] - INFO: 4800 / 4988
2022-10-18 22:08:41 - train.py[line:551] - INFO: load:1.76 valid_run:3666.92 task_valid:3506.54 collect_output:133.00

====================================================================================================
SGG eval:     R @ 50: 0.1962;     R @ 100: 0.2734;     R @ 500: 0.3649;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0895;    mR @ 100: 0.1446;    mR @ 500: 0.1951;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0171) (covered in:0.0000) (covering:0.1429) (eating:0.3529) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.2346) (says:0.0000) (sitting on:0.3444) (standing on:0.4800) (using:0.1500) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1962;     R @ 100: 0.2734;     R @ 500: 0.3649;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0895;    mR @ 100: 0.1446;    mR @ 500: 0.1951;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0171) (covered in:0.0000) (covering:0.1429) (eating:0.3529) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.2346) (says:0.0000) (sitting on:0.3444) (standing on:0.4800) (using:0.1500) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2022-10-18 22:11:11 - train.py[line:487] - INFO: 0.27336666666666665
2022-10-18 22:11:12 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-18 22:11:12 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.423 | loss_v1 0 | loss_v2 0 | nll_loss 0.315 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.273367 | ppl 1.24 | vqa_score 0.161 | wps 117.5 | wpb 89.9 | bsz 30 | num_updates 2000 | best_R@100 0.273367
2022-10-18 22:11:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2022-10-18 22:11:12 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-18 22:11:18 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-18 22:11:23 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.27336666666666665) (writing took 11.150946825742722 seconds)
2022-10-18 22:11:34 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 102288 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=0.3, ups=0, wpb=109.2, bsz=40, num_updates=2010, lr=4.91274e-06, gnorm=1.577, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9954
2022-10-18 22:11:46 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 102288 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=96.2, ups=0.87, wpb=110.8, bsz=40, num_updates=2020, lr=4.93719e-06, gnorm=1.504, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9965
2022-10-18 22:11:56 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 102288 loss=0.783, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=100.4, ups=0.91, wpb=109.8, bsz=40, num_updates=2030, lr=4.96163e-06, gnorm=1.588, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9976
2022-10-18 22:12:17 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.7, ups=0.92, wpb=110, bsz=40, num_updates=2040, lr=4.98607e-06, gnorm=1.51, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9987
2022-10-18 22:12:28 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 102288 loss=0.795, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=100, ups=0.92, wpb=108.5, bsz=40, num_updates=2050, lr=5.01051e-06, gnorm=1.578, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10007
2022-10-18 22:12:39 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 102288 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.708, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.2, ups=0.88, wpb=110.7, bsz=40, num_updates=2060, lr=5.03495e-06, gnorm=1.41, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10019
2022-10-18 22:12:50 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 102288 loss=0.784, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=95.7, ups=0.88, wpb=109.1, bsz=40, num_updates=2070, lr=5.05939e-06, gnorm=1.546, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10030
2022-10-18 22:13:01 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 102288 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.702, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=100.2, ups=0.92, wpb=109, bsz=40, num_updates=2080, lr=5.08383e-06, gnorm=1.489, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10041
2022-10-18 22:13:12 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 102288 loss=0.754, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99, ups=0.9, wpb=109.8, bsz=40, num_updates=2090, lr=5.10828e-06, gnorm=1.532, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10052
2022-10-18 22:13:24 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 102288 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=2100, lr=5.13272e-06, gnorm=1.521, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10063
2022-10-18 22:13:35 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 102288 loss=0.779, loss_v1=0, loss_v2=0, nll_loss=0.702, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=96.6, ups=0.88, wpb=109.3, bsz=40, num_updates=2110, lr=5.15716e-06, gnorm=1.454, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10075
2022-10-18 22:13:46 - progress_bar.py[line:274] - INFO: epoch 001:   2121 / 102288 loss=0.716, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.1, ups=0.88, wpb=111.5, bsz=40, num_updates=2120, lr=5.1816e-06, gnorm=1.381, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10086
2022-10-18 22:13:57 - progress_bar.py[line:274] - INFO: epoch 001:   2131 / 102288 loss=0.748, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=2130, lr=5.20604e-06, gnorm=1.496, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10097
2022-10-18 22:14:08 - progress_bar.py[line:274] - INFO: epoch 001:   2141 / 102288 loss=0.794, loss_v1=0, loss_v2=0, nll_loss=0.723, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=101.2, ups=0.91, wpb=110.7, bsz=40, num_updates=2140, lr=5.23048e-06, gnorm=1.641, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10108
2022-10-18 22:14:19 - progress_bar.py[line:274] - INFO: epoch 001:   2151 / 102288 loss=0.803, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99.8, ups=0.91, wpb=109.3, bsz=40, num_updates=2150, lr=5.25492e-06, gnorm=1.411, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10119
2022-10-18 22:14:30 - progress_bar.py[line:274] - INFO: epoch 001:   2161 / 102288 loss=0.77, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=101.1, ups=0.91, wpb=111, bsz=40, num_updates=2160, lr=5.27937e-06, gnorm=1.432, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10130
2022-10-18 22:14:41 - progress_bar.py[line:274] - INFO: epoch 001:   2171 / 102288 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=100.8, ups=0.91, wpb=110.4, bsz=40, num_updates=2170, lr=5.30381e-06, gnorm=1.468, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10141
2022-10-18 22:14:52 - progress_bar.py[line:274] - INFO: epoch 001:   2181 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=101.4, ups=0.91, wpb=111.2, bsz=40, num_updates=2180, lr=5.32825e-06, gnorm=1.537, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10152
2022-10-18 22:15:03 - progress_bar.py[line:274] - INFO: epoch 001:   2191 / 102288 loss=0.826, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=96.6, ups=0.89, wpb=108.9, bsz=40, num_updates=2190, lr=5.35269e-06, gnorm=1.453, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10163
2022-10-18 22:15:15 - progress_bar.py[line:274] - INFO: epoch 001:   2201 / 102288 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.693, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=2200, lr=5.37713e-06, gnorm=1.431, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10174
2022-10-18 22:15:26 - progress_bar.py[line:274] - INFO: epoch 001:   2211 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.673, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=2210, lr=5.40157e-06, gnorm=1.473, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10185
2022-10-18 22:15:36 - progress_bar.py[line:274] - INFO: epoch 001:   2221 / 102288 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=105.7, ups=0.96, wpb=109.7, bsz=40, num_updates=2220, lr=5.42602e-06, gnorm=1.439, clip=100, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=10196
2022-10-18 22:15:47 - progress_bar.py[line:274] - INFO: epoch 001:   2231 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=2230, lr=5.45046e-06, gnorm=1.487, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10207
2022-10-18 22:15:59 - progress_bar.py[line:274] - INFO: epoch 001:   2241 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98, ups=0.88, wpb=111.5, bsz=40, num_updates=2240, lr=5.4749e-06, gnorm=1.398, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10218
2022-10-18 22:16:10 - progress_bar.py[line:274] - INFO: epoch 001:   2251 / 102288 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=2250, lr=5.49934e-06, gnorm=1.505, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10230
2022-10-18 22:16:21 - progress_bar.py[line:274] - INFO: epoch 001:   2261 / 102288 loss=0.8, loss_v1=0, loss_v2=0, nll_loss=0.731, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=98.6, ups=0.9, wpb=109.4, bsz=40, num_updates=2260, lr=5.52378e-06, gnorm=1.466, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10241
2022-10-18 22:16:32 - progress_bar.py[line:274] - INFO: epoch 001:   2271 / 102288 loss=0.789, loss_v1=0, loss_v2=0, nll_loss=0.717, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=2270, lr=5.54822e-06, gnorm=1.45, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10252
2022-10-18 22:16:43 - progress_bar.py[line:274] - INFO: epoch 001:   2281 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.2, ups=0.89, wpb=111.5, bsz=40, num_updates=2280, lr=5.57266e-06, gnorm=1.298, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10263
2022-10-18 22:16:55 - progress_bar.py[line:274] - INFO: epoch 001:   2291 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100.8, ups=0.9, wpb=111.9, bsz=40, num_updates=2290, lr=5.59711e-06, gnorm=1.412, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10274
2022-10-18 22:17:06 - progress_bar.py[line:274] - INFO: epoch 001:   2301 / 102288 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.68, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.5, ups=0.88, wpb=110.1, bsz=40, num_updates=2300, lr=5.62155e-06, gnorm=1.366, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10286
2022-10-18 22:17:17 - progress_bar.py[line:274] - INFO: epoch 001:   2311 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=101.3, ups=0.92, wpb=109.6, bsz=40, num_updates=2310, lr=5.64599e-06, gnorm=1.473, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10297
2022-10-18 22:17:28 - progress_bar.py[line:274] - INFO: epoch 001:   2321 / 102288 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.1, ups=0.89, wpb=109.2, bsz=40, num_updates=2320, lr=5.67043e-06, gnorm=1.597, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10308
2022-10-18 22:17:39 - progress_bar.py[line:274] - INFO: epoch 001:   2331 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.692, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=2330, lr=5.69487e-06, gnorm=1.344, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10319
2022-10-18 22:17:51 - progress_bar.py[line:274] - INFO: epoch 001:   2341 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=2340, lr=5.71931e-06, gnorm=1.448, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10330
2022-10-18 22:18:02 - progress_bar.py[line:274] - INFO: epoch 001:   2351 / 102288 loss=0.782, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.5, ups=0.89, wpb=109.4, bsz=40, num_updates=2350, lr=5.74376e-06, gnorm=1.472, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10342
2022-10-18 22:18:13 - progress_bar.py[line:274] - INFO: epoch 001:   2361 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.2, ups=0.89, wpb=110.6, bsz=40, num_updates=2360, lr=5.7682e-06, gnorm=1.447, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10353
2022-10-18 22:18:24 - progress_bar.py[line:274] - INFO: epoch 001:   2371 / 102288 loss=0.784, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98.5, ups=0.9, wpb=108.9, bsz=40, num_updates=2370, lr=5.79264e-06, gnorm=1.641, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10364
2022-10-18 22:18:35 - progress_bar.py[line:274] - INFO: epoch 001:   2381 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.694, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=2380, lr=5.81708e-06, gnorm=1.659, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10375
2022-10-18 22:18:46 - progress_bar.py[line:274] - INFO: epoch 001:   2391 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=102.1, ups=0.91, wpb=111.6, bsz=40, num_updates=2390, lr=5.84152e-06, gnorm=1.477, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10386
2022-10-18 22:18:57 - progress_bar.py[line:274] - INFO: epoch 001:   2401 / 102288 loss=0.783, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=2400, lr=5.86596e-06, gnorm=1.557, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10397
2022-10-18 22:19:09 - progress_bar.py[line:274] - INFO: epoch 001:   2411 / 102288 loss=0.789, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=2410, lr=5.8904e-06, gnorm=1.601, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10408
2022-10-18 22:19:20 - progress_bar.py[line:274] - INFO: epoch 001:   2421 / 102288 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=2420, lr=5.91485e-06, gnorm=1.598, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10420
2022-10-18 22:19:31 - progress_bar.py[line:274] - INFO: epoch 001:   2431 / 102288 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.3, ups=0.88, wpb=109.5, bsz=40, num_updates=2430, lr=5.93929e-06, gnorm=1.589, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10431
2022-10-18 22:19:43 - progress_bar.py[line:274] - INFO: epoch 001:   2441 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=2440, lr=5.96373e-06, gnorm=1.387, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10443
2022-10-18 22:19:54 - progress_bar.py[line:274] - INFO: epoch 001:   2451 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=2450, lr=5.98817e-06, gnorm=1.394, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10454
2022-10-18 22:20:06 - progress_bar.py[line:274] - INFO: epoch 001:   2461 / 102288 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.68, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=2460, lr=6.01261e-06, gnorm=1.445, clip=100, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10465
2022-10-18 22:20:17 - progress_bar.py[line:274] - INFO: epoch 001:   2471 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=101, ups=0.91, wpb=110.4, bsz=40, num_updates=2470, lr=6.03705e-06, gnorm=1.518, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10476
2022-10-18 22:20:28 - progress_bar.py[line:274] - INFO: epoch 001:   2481 / 102288 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=99.9, ups=0.91, wpb=109.4, bsz=40, num_updates=2480, lr=6.06149e-06, gnorm=1.42, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10487
2022-10-18 22:20:39 - progress_bar.py[line:274] - INFO: epoch 001:   2491 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.65, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=96.1, ups=0.88, wpb=109.5, bsz=40, num_updates=2490, lr=6.08594e-06, gnorm=1.369, clip=100, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10499
2022-10-18 22:20:50 - progress_bar.py[line:274] - INFO: epoch 001:   2501 / 102288 loss=0.761, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=101, ups=0.91, wpb=110.4, bsz=40, num_updates=2500, lr=6.11038e-06, gnorm=1.459, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10510
2022-10-18 22:21:01 - progress_bar.py[line:274] - INFO: epoch 001:   2511 / 102288 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=100.6, ups=0.9, wpb=111.4, bsz=40, num_updates=2510, lr=6.13482e-06, gnorm=1.372, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10521
2022-10-18 22:21:12 - progress_bar.py[line:274] - INFO: epoch 001:   2521 / 102288 loss=0.736, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=102.8, ups=0.94, wpb=109.9, bsz=40, num_updates=2520, lr=6.15926e-06, gnorm=1.378, clip=100, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10531
2022-10-18 22:21:23 - progress_bar.py[line:274] - INFO: epoch 001:   2531 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.654, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100.4, ups=0.91, wpb=110, bsz=40, num_updates=2530, lr=6.1837e-06, gnorm=1.465, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10542
2022-10-18 22:21:34 - progress_bar.py[line:274] - INFO: epoch 001:   2541 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=2540, lr=6.20814e-06, gnorm=1.422, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10554
2022-10-18 22:21:45 - progress_bar.py[line:274] - INFO: epoch 001:   2551 / 102288 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=2550, lr=6.23259e-06, gnorm=1.521, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10565
2022-10-18 22:21:56 - progress_bar.py[line:274] - INFO: epoch 001:   2561 / 102288 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.68, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.9, ups=0.9, wpb=110.9, bsz=40, num_updates=2560, lr=6.25703e-06, gnorm=1.383, clip=100, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10576
2022-10-18 22:22:08 - progress_bar.py[line:274] - INFO: epoch 001:   2571 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=2570, lr=6.28147e-06, gnorm=1.465, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10588
2022-10-18 22:22:19 - progress_bar.py[line:274] - INFO: epoch 001:   2581 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.645, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.7, ups=0.89, wpb=112.4, bsz=40, num_updates=2580, lr=6.30591e-06, gnorm=1.283, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10599
2022-10-18 22:22:30 - progress_bar.py[line:274] - INFO: epoch 001:   2591 / 102288 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=100.3, ups=0.91, wpb=110, bsz=40, num_updates=2590, lr=6.33035e-06, gnorm=1.389, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10610
2022-10-18 22:22:41 - progress_bar.py[line:274] - INFO: epoch 001:   2601 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=2600, lr=6.35479e-06, gnorm=1.486, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10621
2022-10-18 22:22:53 - progress_bar.py[line:274] - INFO: epoch 001:   2611 / 102288 loss=0.76, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=100.1, ups=0.9, wpb=111.1, bsz=40, num_updates=2610, lr=6.37923e-06, gnorm=1.385, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10632
2022-10-18 22:23:04 - progress_bar.py[line:274] - INFO: epoch 001:   2621 / 102288 loss=0.748, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.5, ups=0.9, wpb=110.5, bsz=40, num_updates=2620, lr=6.40368e-06, gnorm=1.452, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10643
2022-10-18 22:23:15 - progress_bar.py[line:274] - INFO: epoch 001:   2631 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=2630, lr=6.42812e-06, gnorm=1.439, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10655
2022-10-18 22:23:26 - progress_bar.py[line:274] - INFO: epoch 001:   2641 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=95.5, ups=0.87, wpb=110.1, bsz=40, num_updates=2640, lr=6.45256e-06, gnorm=1.346, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10666
2022-10-18 22:23:38 - progress_bar.py[line:274] - INFO: epoch 001:   2651 / 102288 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=2650, lr=6.477e-06, gnorm=1.448, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10677
2022-10-18 22:23:49 - progress_bar.py[line:274] - INFO: epoch 001:   2661 / 102288 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=2660, lr=6.50144e-06, gnorm=1.511, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10689
2022-10-18 22:24:00 - progress_bar.py[line:274] - INFO: epoch 001:   2671 / 102288 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=100.4, ups=0.91, wpb=109.7, bsz=40, num_updates=2670, lr=6.52588e-06, gnorm=1.523, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10700
2022-10-18 22:24:11 - progress_bar.py[line:274] - INFO: epoch 001:   2681 / 102288 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.698, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=2680, lr=6.55033e-06, gnorm=1.574, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10711
2022-10-18 22:24:22 - progress_bar.py[line:274] - INFO: epoch 001:   2691 / 102288 loss=0.803, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=97.1, ups=0.89, wpb=108.9, bsz=40, num_updates=2690, lr=6.57477e-06, gnorm=1.522, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10722
2022-10-18 22:24:34 - progress_bar.py[line:274] - INFO: epoch 001:   2701 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=95.6, ups=0.87, wpb=110.2, bsz=40, num_updates=2700, lr=6.59921e-06, gnorm=1.34, clip=100, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10733
2022-10-18 22:24:45 - progress_bar.py[line:274] - INFO: epoch 001:   2711 / 102288 loss=0.761, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=95.5, ups=0.87, wpb=110.3, bsz=40, num_updates=2710, lr=6.62365e-06, gnorm=1.455, clip=100, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10745
2022-10-18 22:24:56 - progress_bar.py[line:274] - INFO: epoch 001:   2721 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=101.1, ups=0.92, wpb=110.1, bsz=40, num_updates=2720, lr=6.64809e-06, gnorm=1.413, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10756
2022-10-18 22:25:08 - progress_bar.py[line:274] - INFO: epoch 001:   2731 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=2730, lr=6.67253e-06, gnorm=1.392, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10767
2022-10-18 22:25:15 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-18 22:25:20 - progress_bar.py[line:274] - INFO: epoch 001:   2742 / 102288 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.629, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=90.3, ups=0.82, wpb=110.7, bsz=40, num_updates=2740, lr=6.69697e-06, gnorm=1.29, clip=100, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=10780
2022-10-18 22:25:31 - progress_bar.py[line:274] - INFO: epoch 001:   2752 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.3, ups=0.9, wpb=111.6, bsz=40, num_updates=2750, lr=6.72142e-06, gnorm=1.298, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10791
2022-10-18 22:25:43 - progress_bar.py[line:274] - INFO: epoch 001:   2762 / 102288 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.9, ups=0.89, wpb=110.2, bsz=40, num_updates=2760, lr=6.74586e-06, gnorm=1.35, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10802
2022-10-18 22:25:54 - progress_bar.py[line:274] - INFO: epoch 001:   2772 / 102288 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=2770, lr=6.7703e-06, gnorm=1.384, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10814
2022-10-18 22:26:05 - progress_bar.py[line:274] - INFO: epoch 001:   2782 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=2780, lr=6.79474e-06, gnorm=1.452, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10825
2022-10-18 22:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   2792 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.1, ups=0.9, wpb=109.9, bsz=40, num_updates=2790, lr=6.81918e-06, gnorm=1.371, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10836
2022-10-18 22:26:27 - progress_bar.py[line:274] - INFO: epoch 001:   2802 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=101.9, ups=0.92, wpb=110.2, bsz=40, num_updates=2800, lr=6.84362e-06, gnorm=1.458, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=10847
2022-10-18 22:26:39 - progress_bar.py[line:274] - INFO: epoch 001:   2812 / 102288 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.8, ups=0.88, wpb=112.4, bsz=40, num_updates=2810, lr=6.86806e-06, gnorm=1.533, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10858
2022-10-18 22:26:50 - progress_bar.py[line:274] - INFO: epoch 001:   2822 / 102288 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.694, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.4, ups=0.9, wpb=109.2, bsz=40, num_updates=2820, lr=6.89251e-06, gnorm=1.589, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10870
2022-10-18 22:27:01 - progress_bar.py[line:274] - INFO: epoch 001:   2832 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=2830, lr=6.91695e-06, gnorm=1.547, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10881
2022-10-18 22:27:12 - progress_bar.py[line:274] - INFO: epoch 001:   2842 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99, ups=0.89, wpb=111.4, bsz=40, num_updates=2840, lr=6.94139e-06, gnorm=1.284, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10892
2022-10-18 22:27:23 - progress_bar.py[line:274] - INFO: epoch 001:   2852 / 102288 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=2850, lr=6.96583e-06, gnorm=1.455, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10903
2022-10-18 22:27:35 - progress_bar.py[line:274] - INFO: epoch 001:   2862 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=2860, lr=6.99027e-06, gnorm=1.377, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10914
2022-10-18 22:27:46 - progress_bar.py[line:274] - INFO: epoch 001:   2872 / 102288 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=2870, lr=7.01471e-06, gnorm=1.299, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10926
2022-10-18 22:27:57 - progress_bar.py[line:274] - INFO: epoch 001:   2882 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=95.8, ups=0.87, wpb=110.4, bsz=40, num_updates=2880, lr=7.03916e-06, gnorm=1.313, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10937
2022-10-18 22:28:09 - progress_bar.py[line:274] - INFO: epoch 001:   2892 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.4, ups=0.89, wpb=109.8, bsz=40, num_updates=2890, lr=7.0636e-06, gnorm=1.455, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10949
2022-10-18 22:28:20 - progress_bar.py[line:274] - INFO: epoch 001:   2902 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=102.3, ups=0.93, wpb=110.3, bsz=40, num_updates=2900, lr=7.08804e-06, gnorm=1.437, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10959
2022-10-18 22:28:31 - progress_bar.py[line:274] - INFO: epoch 001:   2912 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.1, ups=0.87, wpb=111, bsz=40, num_updates=2910, lr=7.11248e-06, gnorm=1.405, clip=100, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=10971
2022-10-18 22:28:42 - progress_bar.py[line:274] - INFO: epoch 001:   2922 / 102288 loss=0.741, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=2920, lr=7.13692e-06, gnorm=1.253, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10982
2022-10-18 22:28:54 - progress_bar.py[line:274] - INFO: epoch 001:   2932 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=2930, lr=7.16136e-06, gnorm=1.495, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10994
2022-10-18 22:29:05 - progress_bar.py[line:274] - INFO: epoch 001:   2942 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=102.1, ups=0.92, wpb=111.5, bsz=40, num_updates=2940, lr=7.1858e-06, gnorm=1.243, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=11004
2022-10-18 22:29:16 - progress_bar.py[line:274] - INFO: epoch 001:   2952 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=2950, lr=7.21025e-06, gnorm=1.336, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=11016
2022-10-18 22:29:27 - progress_bar.py[line:274] - INFO: epoch 001:   2962 / 102288 loss=0.768, loss_v1=0, loss_v2=0, nll_loss=0.693, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.3, ups=0.9, wpb=108.9, bsz=40, num_updates=2960, lr=7.23469e-06, gnorm=1.35, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=11027
2022-10-18 22:29:38 - progress_bar.py[line:274] - INFO: epoch 001:   2972 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97.4, ups=0.88, wpb=110.8, bsz=40, num_updates=2970, lr=7.25913e-06, gnorm=1.44, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=11038
2022-10-18 22:29:49 - progress_bar.py[line:274] - INFO: epoch 001:   2982 / 102288 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=102.3, ups=0.92, wpb=111.5, bsz=40, num_updates=2980, lr=7.28357e-06, gnorm=1.318, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=11049
2022-10-18 22:30:00 - progress_bar.py[line:274] - INFO: epoch 001:   2992 / 102288 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=101, ups=0.91, wpb=110.8, bsz=40, num_updates=2990, lr=7.30801e-06, gnorm=1.354, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=11060
2022-10-18 22:30:12 - progress_bar.py[line:274] - INFO: epoch 001:   3002 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.644, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99, ups=0.89, wpb=111.4, bsz=40, num_updates=3000, lr=7.33245e-06, gnorm=1.338, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=11071
2022-10-18 22:30:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-18 22:30:13 - train.py[line:549] - INFO: 0 / 4988
2022-10-18 22:30:13 - train.py[line:551] - INFO: load:1.09 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-18 22:32:45 - train.py[line:549] - INFO: 200 / 4988
2022-10-18 22:32:45 - train.py[line:551] - INFO: load:1.11 valid_run:152.47 task_valid:148.36 collect_output:3.08
2022-10-18 22:35:16 - train.py[line:549] - INFO: 400 / 4988
2022-10-18 22:35:16 - train.py[line:551] - INFO: load:1.14 valid_run:302.88 task_valid:293.09 collect_output:7.59
2022-10-18 22:37:50 - train.py[line:549] - INFO: 600 / 4988
2022-10-18 22:37:50 - train.py[line:551] - INFO: load:1.16 valid_run:457.25 task_valid:437.63 collect_output:16.33
2022-10-18 22:40:20 - train.py[line:549] - INFO: 800 / 4988
2022-10-18 22:40:20 - train.py[line:551] - INFO: load:1.19 valid_run:606.54 task_valid:582.50 collect_output:19.72
2022-10-18 22:42:53 - train.py[line:549] - INFO: 1000 / 4988
2022-10-18 22:42:53 - train.py[line:551] - INFO: load:1.22 valid_run:759.71 task_valid:730.27 collect_output:24.05
2022-10-18 22:45:26 - train.py[line:549] - INFO: 1200 / 4988
2022-10-18 22:45:26 - train.py[line:551] - INFO: load:1.25 valid_run:912.27 task_valid:876.72 collect_output:28.96
2022-10-18 22:48:00 - train.py[line:549] - INFO: 1400 / 4988
2022-10-18 22:48:00 - train.py[line:551] - INFO: load:1.28 valid_run:1066.75 task_valid:1023.48 collect_output:35.59
2022-10-18 22:50:32 - train.py[line:549] - INFO: 1600 / 4988
2022-10-18 22:50:32 - train.py[line:551] - INFO: load:1.31 valid_run:1218.88 task_valid:1165.37 collect_output:44.74
2022-10-18 22:53:03 - train.py[line:549] - INFO: 1800 / 4988
2022-10-18 22:53:03 - train.py[line:551] - INFO: load:1.34 valid_run:1369.53 task_valid:1310.70 collect_output:48.99
2022-10-18 22:55:33 - train.py[line:549] - INFO: 2000 / 4988
2022-10-18 22:55:33 - train.py[line:551] - INFO: load:1.37 valid_run:1519.45 task_valid:1454.91 collect_output:53.60
2022-10-18 22:58:04 - train.py[line:549] - INFO: 2200 / 4988
2022-10-18 22:58:04 - train.py[line:551] - INFO: load:1.41 valid_run:1670.45 task_valid:1600.92 collect_output:57.46
2022-10-18 23:00:35 - train.py[line:549] - INFO: 2400 / 4988
2022-10-18 23:00:35 - train.py[line:551] - INFO: load:1.43 valid_run:1821.37 task_valid:1746.61 collect_output:61.52
2022-10-18 23:03:06 - train.py[line:549] - INFO: 2600 / 4988
2022-10-18 23:03:06 - train.py[line:551] - INFO: load:1.46 valid_run:1972.28 task_valid:1889.20 collect_output:68.74
2022-10-18 23:05:38 - train.py[line:549] - INFO: 2800 / 4988
2022-10-18 23:05:38 - train.py[line:551] - INFO: load:1.49 valid_run:2123.74 task_valid:2035.42 collect_output:72.92
2022-10-18 23:08:08 - train.py[line:549] - INFO: 3000 / 4988
2022-10-18 23:08:08 - train.py[line:551] - INFO: load:1.52 valid_run:2274.46 task_valid:2182.54 collect_output:75.40
2022-10-18 23:10:39 - train.py[line:549] - INFO: 3200 / 4988
2022-10-18 23:10:39 - train.py[line:551] - INFO: load:1.55 valid_run:2425.21 task_valid:2327.38 collect_output:80.24
2022-10-18 23:13:12 - train.py[line:549] - INFO: 3400 / 4988
2022-10-18 23:13:12 - train.py[line:551] - INFO: load:1.58 valid_run:2577.94 task_valid:2473.67 collect_output:85.59
2022-10-18 23:15:43 - train.py[line:549] - INFO: 3600 / 4988
2022-10-18 23:15:43 - train.py[line:551] - INFO: load:1.60 valid_run:2729.06 task_valid:2620.92 collect_output:88.42
2022-10-18 23:18:12 - train.py[line:549] - INFO: 3800 / 4988
2022-10-18 23:18:12 - train.py[line:551] - INFO: load:1.63 valid_run:2877.96 task_valid:2762.66 collect_output:94.52
2022-10-18 23:20:43 - train.py[line:549] - INFO: 4000 / 4988
2022-10-18 23:20:43 - train.py[line:551] - INFO: load:1.66 valid_run:3028.81 task_valid:2907.89 collect_output:99.07
2022-10-18 23:23:16 - train.py[line:549] - INFO: 4200 / 4988
2022-10-18 23:23:16 - train.py[line:551] - INFO: load:1.69 valid_run:3181.72 task_valid:3052.84 collect_output:105.96
2022-10-18 23:25:46 - train.py[line:549] - INFO: 4400 / 4988
2022-10-18 23:25:46 - train.py[line:551] - INFO: load:1.71 valid_run:3331.68 task_valid:3197.59 collect_output:110.09
2022-10-18 23:28:18 - train.py[line:549] - INFO: 4600 / 4988
2022-10-18 23:28:18 - train.py[line:551] - INFO: load:1.74 valid_run:3484.05 task_valid:3344.42 collect_output:114.55
2022-10-18 23:30:51 - train.py[line:549] - INFO: 4800 / 4988
2022-10-18 23:30:51 - train.py[line:551] - INFO: load:1.77 valid_run:3636.17 task_valid:3491.40 collect_output:118.61

====================================================================================================
SGG eval:     R @ 50: 0.2694;     R @ 100: 0.3369;     R @ 500: 0.4153;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1178;    mR @ 100: 0.1730;    mR @ 500: 0.2375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0341) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.3451) (says:0.0000) (sitting on:0.4586) (standing on:0.4550) (using:0.1500) (walking in:0.0000) (walking on:0.0766) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2694;     R @ 100: 0.3369;     R @ 500: 0.4153;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1178;    mR @ 100: 0.1730;    mR @ 500: 0.2375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0341) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.3451) (says:0.0000) (sitting on:0.4586) (standing on:0.4550) (using:0.1500) (walking in:0.0000) (walking on:0.0766) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2022-10-18 23:33:22 - train.py[line:487] - INFO: 0.33686666666666665
2022-10-18 23:33:22 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-18 23:33:22 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.346 | loss_v1 0 | loss_v2 0 | nll_loss 0.213 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.336867 | ppl 1.16 | vqa_score 0.1813 | wps 118.4 | wpb 89.9 | bsz 30 | num_updates 3000 | best_R@100 0.336867
2022-10-18 23:33:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2022-10-18 23:33:22 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-18 23:33:31 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-18 23:33:37 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 0.33686666666666665) (writing took 15.252719565294683 seconds)
2022-10-18 23:33:49 - progress_bar.py[line:274] - INFO: epoch 001:   3012 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=0.3, ups=0, wpb=110.4, bsz=40, num_updates=3010, lr=7.35689e-06, gnorm=1.313, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14889
2022-10-18 23:34:00 - progress_bar.py[line:274] - INFO: epoch 001:   3022 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.9, ups=0.92, wpb=110, bsz=40, num_updates=3020, lr=7.38134e-06, gnorm=1.327, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14899
2022-10-18 23:34:11 - progress_bar.py[line:274] - INFO: epoch 001:   3032 / 102288 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=96.9, ups=0.87, wpb=111.7, bsz=40, num_updates=3030, lr=7.40578e-06, gnorm=1.247, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14911
2022-10-18 23:34:22 - progress_bar.py[line:274] - INFO: epoch 001:   3042 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.3, ups=0.89, wpb=109.3, bsz=40, num_updates=3040, lr=7.43022e-06, gnorm=1.538, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=14922
2022-10-18 23:34:34 - progress_bar.py[line:274] - INFO: epoch 001:   3052 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=3050, lr=7.45466e-06, gnorm=1.345, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14933
2022-10-18 23:34:45 - progress_bar.py[line:274] - INFO: epoch 001:   3062 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=3060, lr=7.4791e-06, gnorm=1.478, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14944
2022-10-18 23:34:56 - progress_bar.py[line:274] - INFO: epoch 001:   3072 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.8, ups=0.89, wpb=110.1, bsz=40, num_updates=3070, lr=7.50354e-06, gnorm=1.449, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14956
2022-10-18 23:35:07 - progress_bar.py[line:274] - INFO: epoch 001:   3082 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.9, ups=0.89, wpb=110.1, bsz=40, num_updates=3080, lr=7.52799e-06, gnorm=1.544, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14967
2022-10-18 23:35:18 - progress_bar.py[line:274] - INFO: epoch 001:   3092 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=3090, lr=7.55243e-06, gnorm=1.32, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14978
2022-10-18 23:35:30 - progress_bar.py[line:274] - INFO: epoch 001:   3102 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=3100, lr=7.57687e-06, gnorm=1.24, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=14989
2022-10-18 23:35:41 - progress_bar.py[line:274] - INFO: epoch 001:   3112 / 102288 loss=0.78, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=3110, lr=7.60131e-06, gnorm=1.312, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15001
2022-10-18 23:35:52 - progress_bar.py[line:274] - INFO: epoch 001:   3122 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.8, ups=0.89, wpb=108.6, bsz=40, num_updates=3120, lr=7.62575e-06, gnorm=1.251, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15012
2022-10-18 23:36:03 - progress_bar.py[line:274] - INFO: epoch 001:   3132 / 102288 loss=0.781, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=3130, lr=7.65019e-06, gnorm=1.201, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15023
2022-10-18 23:36:15 - progress_bar.py[line:274] - INFO: epoch 001:   3142 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.8, ups=0.89, wpb=111.2, bsz=40, num_updates=3140, lr=7.67463e-06, gnorm=1.392, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15034
2022-10-18 23:36:26 - progress_bar.py[line:274] - INFO: epoch 001:   3152 / 102288 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.1, ups=0.87, wpb=110.6, bsz=40, num_updates=3150, lr=7.69908e-06, gnorm=1.402, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15046
2022-10-18 23:36:38 - progress_bar.py[line:274] - INFO: epoch 001:   3162 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.5, ups=0.88, wpb=109.9, bsz=40, num_updates=3160, lr=7.72352e-06, gnorm=1.383, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15057
2022-10-18 23:36:49 - progress_bar.py[line:274] - INFO: epoch 001:   3172 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=3170, lr=7.74796e-06, gnorm=1.334, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15069
2022-10-18 23:37:00 - progress_bar.py[line:274] - INFO: epoch 001:   3182 / 102288 loss=0.769, loss_v1=0, loss_v2=0, nll_loss=0.695, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=3180, lr=7.7724e-06, gnorm=1.299, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15080
2022-10-18 23:37:11 - progress_bar.py[line:274] - INFO: epoch 001:   3192 / 102288 loss=0.776, loss_v1=0, loss_v2=0, nll_loss=0.704, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=3190, lr=7.79684e-06, gnorm=1.279, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15091
2022-10-18 23:37:22 - progress_bar.py[line:274] - INFO: epoch 001:   3202 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.66, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.6, ups=0.91, wpb=110.4, bsz=40, num_updates=3200, lr=7.82128e-06, gnorm=1.282, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15102
2022-10-18 23:37:34 - progress_bar.py[line:274] - INFO: epoch 001:   3212 / 102288 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.1, ups=0.86, wpb=112.5, bsz=40, num_updates=3210, lr=7.84573e-06, gnorm=1.344, clip=90, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=15114
2022-10-18 23:37:45 - progress_bar.py[line:274] - INFO: epoch 001:   3222 / 102288 loss=0.755, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=101.5, ups=0.91, wpb=111, bsz=40, num_updates=3220, lr=7.87017e-06, gnorm=1.448, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15125
2022-10-18 23:37:56 - progress_bar.py[line:274] - INFO: epoch 001:   3232 / 102288 loss=0.775, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=100.4, ups=0.91, wpb=109.8, bsz=40, num_updates=3230, lr=7.89461e-06, gnorm=1.341, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15136
2022-10-18 23:38:07 - progress_bar.py[line:274] - INFO: epoch 001:   3242 / 102288 loss=0.768, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96, ups=0.88, wpb=109.2, bsz=40, num_updates=3240, lr=7.91905e-06, gnorm=1.266, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15147
2022-10-18 23:38:18 - progress_bar.py[line:274] - INFO: epoch 001:   3252 / 102288 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=3250, lr=7.94349e-06, gnorm=1.214, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15158
2022-10-18 23:38:29 - progress_bar.py[line:274] - INFO: epoch 001:   3262 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=101.3, ups=0.92, wpb=110.7, bsz=40, num_updates=3260, lr=7.96793e-06, gnorm=1.418, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15169
2022-10-18 23:38:40 - progress_bar.py[line:274] - INFO: epoch 001:   3272 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=99, ups=0.89, wpb=111.2, bsz=40, num_updates=3270, lr=7.99237e-06, gnorm=1.263, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15180
2022-10-18 23:38:51 - progress_bar.py[line:274] - INFO: epoch 001:   3282 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=101.3, ups=0.91, wpb=110.8, bsz=40, num_updates=3280, lr=8.01682e-06, gnorm=1.322, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15191
2022-10-18 23:39:03 - progress_bar.py[line:274] - INFO: epoch 001:   3292 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.1, ups=0.89, wpb=111.7, bsz=40, num_updates=3290, lr=8.04126e-06, gnorm=1.229, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15202
2022-10-18 23:39:14 - progress_bar.py[line:274] - INFO: epoch 001:   3302 / 102288 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.2, ups=0.89, wpb=109.5, bsz=40, num_updates=3300, lr=8.0657e-06, gnorm=1.417, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15214
2022-10-18 23:39:25 - progress_bar.py[line:274] - INFO: epoch 001:   3312 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.4, ups=0.91, wpb=108.9, bsz=40, num_updates=3310, lr=8.09014e-06, gnorm=1.297, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15225
2022-10-18 23:39:36 - progress_bar.py[line:274] - INFO: epoch 001:   3322 / 102288 loss=0.716, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=3320, lr=8.11458e-06, gnorm=1.396, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15236
2022-10-18 23:39:47 - progress_bar.py[line:274] - INFO: epoch 001:   3332 / 102288 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=3330, lr=8.13902e-06, gnorm=1.249, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15247
2022-10-18 23:39:58 - progress_bar.py[line:274] - INFO: epoch 001:   3342 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=101.4, ups=0.93, wpb=109.5, bsz=40, num_updates=3340, lr=8.16346e-06, gnorm=1.331, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15258
2022-10-18 23:40:09 - progress_bar.py[line:274] - INFO: epoch 001:   3352 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=3350, lr=8.18791e-06, gnorm=1.386, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15269
2022-10-18 23:40:21 - progress_bar.py[line:274] - INFO: epoch 001:   3362 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=3360, lr=8.21235e-06, gnorm=1.337, clip=100, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15280
2022-10-18 23:40:24 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-18 23:40:33 - progress_bar.py[line:274] - INFO: epoch 001:   3373 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=91.3, ups=0.83, wpb=110.6, bsz=40, num_updates=3370, lr=8.23679e-06, gnorm=1.358, clip=100, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=15293
2022-10-18 23:40:44 - progress_bar.py[line:274] - INFO: epoch 001:   3383 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=3380, lr=8.26123e-06, gnorm=1.258, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15304
2022-10-18 23:40:55 - progress_bar.py[line:274] - INFO: epoch 001:   3393 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.5, ups=0.91, wpb=108.8, bsz=40, num_updates=3390, lr=8.28567e-06, gnorm=1.393, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15315
2022-10-18 23:41:06 - progress_bar.py[line:274] - INFO: epoch 001:   3403 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=3400, lr=8.31011e-06, gnorm=1.242, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15326
2022-10-18 23:41:17 - progress_bar.py[line:274] - INFO: epoch 001:   3413 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.673, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=3410, lr=8.33456e-06, gnorm=1.4, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15337
2022-10-18 23:41:28 - progress_bar.py[line:274] - INFO: epoch 001:   3423 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=3420, lr=8.359e-06, gnorm=1.388, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15348
2022-10-18 23:41:40 - progress_bar.py[line:274] - INFO: epoch 001:   3433 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=96.4, ups=0.88, wpb=109.5, bsz=40, num_updates=3430, lr=8.38344e-06, gnorm=1.369, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15360
2022-10-18 23:41:51 - progress_bar.py[line:274] - INFO: epoch 001:   3443 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=3440, lr=8.40788e-06, gnorm=1.625, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15371
2022-10-18 23:42:02 - progress_bar.py[line:274] - INFO: epoch 001:   3453 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=3450, lr=8.43232e-06, gnorm=1.322, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15382
2022-10-18 23:42:13 - progress_bar.py[line:274] - INFO: epoch 001:   3463 / 102288 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=105.5, ups=0.96, wpb=110.5, bsz=40, num_updates=3460, lr=8.45676e-06, gnorm=1.358, clip=100, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=15393
2022-10-18 23:42:24 - progress_bar.py[line:274] - INFO: epoch 001:   3473 / 102288 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=100.3, ups=0.91, wpb=110, bsz=40, num_updates=3470, lr=8.4812e-06, gnorm=1.383, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15403
2022-10-18 23:42:35 - progress_bar.py[line:274] - INFO: epoch 001:   3483 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.2, ups=0.9, wpb=110.1, bsz=40, num_updates=3480, lr=8.50565e-06, gnorm=1.451, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15415
2022-10-18 23:42:46 - progress_bar.py[line:274] - INFO: epoch 001:   3493 / 102288 loss=0.767, loss_v1=0, loss_v2=0, nll_loss=0.689, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.3, ups=0.88, wpb=109.5, bsz=40, num_updates=3490, lr=8.53009e-06, gnorm=1.356, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15426
2022-10-18 23:42:57 - progress_bar.py[line:274] - INFO: epoch 001:   3503 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=3500, lr=8.55453e-06, gnorm=1.312, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15437
2022-10-18 23:43:09 - progress_bar.py[line:274] - INFO: epoch 001:   3513 / 102288 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=97.1, ups=0.89, wpb=109.1, bsz=40, num_updates=3510, lr=8.57897e-06, gnorm=1.322, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15448
2022-10-18 23:43:20 - progress_bar.py[line:274] - INFO: epoch 001:   3523 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=3520, lr=8.60341e-06, gnorm=1.332, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15460
2022-10-18 23:43:31 - progress_bar.py[line:274] - INFO: epoch 001:   3533 / 102288 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=3530, lr=8.62785e-06, gnorm=1.319, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15471
2022-10-18 23:43:42 - progress_bar.py[line:274] - INFO: epoch 001:   3543 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=3540, lr=8.6523e-06, gnorm=1.32, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15482
2022-10-18 23:43:54 - progress_bar.py[line:274] - INFO: epoch 001:   3553 / 102288 loss=0.741, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=3550, lr=8.67674e-06, gnorm=1.341, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15493
2022-10-18 23:44:05 - progress_bar.py[line:274] - INFO: epoch 001:   3563 / 102288 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=3560, lr=8.70118e-06, gnorm=1.233, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15505
2022-10-18 23:44:16 - progress_bar.py[line:274] - INFO: epoch 001:   3573 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=101.6, ups=0.93, wpb=109.7, bsz=40, num_updates=3570, lr=8.72562e-06, gnorm=1.314, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15516
2022-10-18 23:44:27 - progress_bar.py[line:274] - INFO: epoch 001:   3583 / 102288 loss=0.748, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.5, ups=0.88, wpb=109.7, bsz=40, num_updates=3580, lr=8.75006e-06, gnorm=1.248, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15527
2022-10-18 23:44:39 - progress_bar.py[line:274] - INFO: epoch 001:   3593 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.8, ups=0.88, wpb=111.3, bsz=40, num_updates=3590, lr=8.7745e-06, gnorm=1.365, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15538
2022-10-18 23:44:49 - progress_bar.py[line:274] - INFO: epoch 001:   3603 / 102288 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=101.1, ups=0.91, wpb=110.7, bsz=40, num_updates=3600, lr=8.79894e-06, gnorm=1.315, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15549
2022-10-18 23:45:01 - progress_bar.py[line:274] - INFO: epoch 001:   3613 / 102288 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=3610, lr=8.82339e-06, gnorm=1.284, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15560
2022-10-18 23:45:12 - progress_bar.py[line:274] - INFO: epoch 001:   3623 / 102288 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=3620, lr=8.84783e-06, gnorm=1.344, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=15572
2022-10-18 23:45:23 - progress_bar.py[line:274] - INFO: epoch 001:   3633 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.4, ups=0.9, wpb=110.5, bsz=40, num_updates=3630, lr=8.87227e-06, gnorm=1.299, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15583
2022-10-18 23:45:34 - progress_bar.py[line:274] - INFO: epoch 001:   3643 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=3640, lr=8.89671e-06, gnorm=1.305, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15594
2022-10-18 23:45:45 - progress_bar.py[line:274] - INFO: epoch 001:   3653 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.5, ups=0.89, wpb=110.8, bsz=40, num_updates=3650, lr=8.92115e-06, gnorm=1.267, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15605
2022-10-18 23:45:56 - progress_bar.py[line:274] - INFO: epoch 001:   3663 / 102288 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100.6, ups=0.9, wpb=111.7, bsz=40, num_updates=3660, lr=8.94559e-06, gnorm=1.242, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=15616
2022-10-18 23:46:08 - progress_bar.py[line:274] - INFO: epoch 001:   3673 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=3670, lr=8.97003e-06, gnorm=1.429, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15628
2022-10-18 23:46:19 - progress_bar.py[line:274] - INFO: epoch 001:   3683 / 102288 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=3680, lr=8.99448e-06, gnorm=1.231, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15639
2022-10-18 23:46:30 - progress_bar.py[line:274] - INFO: epoch 001:   3693 / 102288 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=100.7, ups=0.92, wpb=109.9, bsz=40, num_updates=3690, lr=9.01892e-06, gnorm=1.242, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15650
2022-10-18 23:46:41 - progress_bar.py[line:274] - INFO: epoch 001:   3703 / 102288 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=3700, lr=9.04336e-06, gnorm=1.269, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15661
2022-10-18 23:46:52 - progress_bar.py[line:274] - INFO: epoch 001:   3713 / 102288 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=101.3, ups=0.92, wpb=110.4, bsz=40, num_updates=3710, lr=9.0678e-06, gnorm=1.325, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15672
2022-10-18 23:47:03 - progress_bar.py[line:274] - INFO: epoch 001:   3723 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.5, ups=0.9, wpb=109.7, bsz=40, num_updates=3720, lr=9.09224e-06, gnorm=1.254, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15683
2022-10-18 23:47:14 - progress_bar.py[line:274] - INFO: epoch 001:   3733 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99, ups=0.91, wpb=109.3, bsz=40, num_updates=3730, lr=9.11668e-06, gnorm=1.322, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15694
2022-10-18 23:47:25 - progress_bar.py[line:274] - INFO: epoch 001:   3743 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.5, ups=0.9, wpb=109.8, bsz=40, num_updates=3740, lr=9.14113e-06, gnorm=1.286, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15705
2022-10-18 23:47:36 - progress_bar.py[line:274] - INFO: epoch 001:   3753 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100.8, ups=0.92, wpb=109.9, bsz=40, num_updates=3750, lr=9.16557e-06, gnorm=1.32, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15716
2022-10-18 23:47:47 - progress_bar.py[line:274] - INFO: epoch 001:   3763 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=3760, lr=9.19001e-06, gnorm=1.486, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15727
2022-10-18 23:47:59 - progress_bar.py[line:274] - INFO: epoch 001:   3773 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=3770, lr=9.21445e-06, gnorm=1.314, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15739
2022-10-18 23:48:10 - progress_bar.py[line:274] - INFO: epoch 001:   3783 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=3780, lr=9.23889e-06, gnorm=1.149, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15750
2022-10-18 23:48:21 - progress_bar.py[line:274] - INFO: epoch 001:   3793 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=95.9, ups=0.88, wpb=109.4, bsz=40, num_updates=3790, lr=9.26333e-06, gnorm=1.213, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15761
2022-10-18 23:48:33 - progress_bar.py[line:274] - INFO: epoch 001:   3803 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=95.1, ups=0.85, wpb=111.5, bsz=40, num_updates=3800, lr=9.28777e-06, gnorm=1.179, clip=100, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=15773
2022-10-18 23:48:44 - progress_bar.py[line:274] - INFO: epoch 001:   3813 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=3810, lr=9.31222e-06, gnorm=1.256, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15784
2022-10-18 23:48:55 - progress_bar.py[line:274] - INFO: epoch 001:   3823 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=102.5, ups=0.93, wpb=109.7, bsz=40, num_updates=3820, lr=9.33666e-06, gnorm=1.307, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15795
2022-10-18 23:49:06 - progress_bar.py[line:274] - INFO: epoch 001:   3833 / 102288 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=100.1, ups=0.91, wpb=109.9, bsz=40, num_updates=3830, lr=9.3611e-06, gnorm=1.248, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15806
2022-10-18 23:49:17 - progress_bar.py[line:274] - INFO: epoch 001:   3843 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.7, ups=0.9, wpb=109.5, bsz=40, num_updates=3840, lr=9.38554e-06, gnorm=1.17, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15817
2022-10-18 23:49:29 - progress_bar.py[line:274] - INFO: epoch 001:   3853 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=95.9, ups=0.87, wpb=110.5, bsz=40, num_updates=3850, lr=9.40998e-06, gnorm=1.284, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15828
2022-10-18 23:49:40 - progress_bar.py[line:274] - INFO: epoch 001:   3863 / 102288 loss=0.748, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.3, ups=0.9, wpb=111.1, bsz=40, num_updates=3860, lr=9.43442e-06, gnorm=1.456, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15839
2022-10-18 23:49:51 - progress_bar.py[line:274] - INFO: epoch 001:   3873 / 102288 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=97.3, ups=0.89, wpb=109.2, bsz=40, num_updates=3870, lr=9.45886e-06, gnorm=1.223, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15851
2022-10-18 23:50:02 - progress_bar.py[line:274] - INFO: epoch 001:   3883 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.1, ups=0.89, wpb=109.2, bsz=40, num_updates=3880, lr=9.48331e-06, gnorm=1.324, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15862
2022-10-18 23:50:13 - progress_bar.py[line:274] - INFO: epoch 001:   3893 / 102288 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.3, ups=0.89, wpb=110.7, bsz=40, num_updates=3890, lr=9.50775e-06, gnorm=1.184, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15873
2022-10-18 23:50:25 - progress_bar.py[line:274] - INFO: epoch 001:   3903 / 102288 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=3900, lr=9.53219e-06, gnorm=1.235, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15884
2022-10-18 23:50:36 - progress_bar.py[line:274] - INFO: epoch 001:   3913 / 102288 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.7, ups=0.9, wpb=110.7, bsz=40, num_updates=3910, lr=9.55663e-06, gnorm=1.254, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15896
2022-10-18 23:50:47 - progress_bar.py[line:274] - INFO: epoch 001:   3923 / 102288 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.9, ups=0.92, wpb=111.2, bsz=40, num_updates=3920, lr=9.58107e-06, gnorm=1.322, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15906
2022-10-18 23:50:58 - progress_bar.py[line:274] - INFO: epoch 001:   3933 / 102288 loss=0.791, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=95.1, ups=0.88, wpb=108.3, bsz=40, num_updates=3930, lr=9.60551e-06, gnorm=1.249, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15918
2022-10-18 23:51:09 - progress_bar.py[line:274] - INFO: epoch 001:   3943 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100, ups=0.91, wpb=109.5, bsz=40, num_updates=3940, lr=9.62996e-06, gnorm=1.286, clip=90, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=15929
2022-10-18 23:51:20 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-18 23:51:21 - progress_bar.py[line:274] - INFO: epoch 001:   3954 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=91.3, ups=0.81, wpb=112.1, bsz=40, num_updates=3950, lr=9.6544e-06, gnorm=1.286, clip=100, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=15941
2022-10-18 23:51:33 - progress_bar.py[line:274] - INFO: epoch 001:   3964 / 102288 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.613, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=98.8, ups=0.89, wpb=111.2, bsz=40, num_updates=3960, lr=9.67884e-06, gnorm=1.418, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15952
2022-10-18 23:51:44 - progress_bar.py[line:274] - INFO: epoch 001:   3974 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=3970, lr=9.70328e-06, gnorm=1.288, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15963
2022-10-18 23:51:55 - progress_bar.py[line:274] - INFO: epoch 001:   3984 / 102288 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=3980, lr=9.72772e-06, gnorm=1.183, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15975
2022-10-18 23:52:06 - progress_bar.py[line:274] - INFO: epoch 001:   3994 / 102288 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=102.9, ups=0.91, wpb=112.9, bsz=40, num_updates=3990, lr=9.75216e-06, gnorm=1.221, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15986
2022-10-18 23:52:17 - progress_bar.py[line:274] - INFO: epoch 001:   4004 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.1, ups=0.9, wpb=109, bsz=40, num_updates=4000, lr=9.7766e-06, gnorm=1.335, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15997
2022-10-18 23:52:17 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-18 23:52:18 - train.py[line:549] - INFO: 0 / 4988
2022-10-18 23:52:18 - train.py[line:551] - INFO: load:1.20 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-18 23:54:50 - train.py[line:549] - INFO: 200 / 4988
2022-10-18 23:54:50 - train.py[line:551] - INFO: load:1.23 valid_run:151.71 task_valid:147.98 collect_output:2.67
2022-10-18 23:57:19 - train.py[line:549] - INFO: 400 / 4988
2022-10-18 23:57:19 - train.py[line:551] - INFO: load:1.25 valid_run:300.59 task_valid:291.15 collect_output:7.34
2022-10-18 23:59:53 - train.py[line:549] - INFO: 600 / 4988
2022-10-18 23:59:53 - train.py[line:551] - INFO: load:1.28 valid_run:453.98 task_valid:434.68 collect_output:16.17
2022-10-19 00:02:28 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 00:02:28 - train.py[line:551] - INFO: load:1.30 valid_run:608.84 task_valid:583.33 collect_output:20.81
2022-10-19 00:05:06 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 00:05:06 - train.py[line:551] - INFO: load:1.36 valid_run:767.04 task_valid:734.40 collect_output:26.50
2022-10-19 00:07:43 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 00:07:43 - train.py[line:551] - INFO: load:1.38 valid_run:924.51 task_valid:884.19 collect_output:32.52
2022-10-19 00:10:20 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 00:10:20 - train.py[line:551] - INFO: load:1.42 valid_run:1081.16 task_valid:1032.40 collect_output:39.62
2022-10-19 00:12:52 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 00:12:52 - train.py[line:551] - INFO: load:1.45 valid_run:1233.03 task_valid:1173.65 collect_output:49.16
2022-10-19 00:15:23 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 00:15:23 - train.py[line:551] - INFO: load:1.48 valid_run:1383.54 task_valid:1318.75 collect_output:53.46
2022-10-19 00:17:52 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 00:17:52 - train.py[line:551] - INFO: load:1.51 valid_run:1532.93 task_valid:1462.28 collect_output:58.21
2022-10-19 00:20:22 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 00:20:22 - train.py[line:551] - INFO: load:1.53 valid_run:1683.25 task_valid:1607.44 collect_output:62.31
2022-10-19 00:22:54 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 00:22:54 - train.py[line:551] - INFO: load:1.56 valid_run:1834.84 task_valid:1753.38 collect_output:66.84
2022-10-19 00:25:25 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 00:25:25 - train.py[line:551] - INFO: load:1.59 valid_run:1985.35 task_valid:1895.29 collect_output:74.41
2022-10-19 00:27:56 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 00:27:56 - train.py[line:551] - INFO: load:1.61 valid_run:2136.36 task_valid:2040.84 collect_output:78.78
2022-10-19 00:30:26 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 00:30:26 - train.py[line:551] - INFO: load:1.64 valid_run:2286.39 task_valid:2187.06 collect_output:81.62
2022-10-19 00:32:56 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 00:32:56 - train.py[line:551] - INFO: load:1.66 valid_run:2436.94 task_valid:2331.33 collect_output:86.90
2022-10-19 00:35:29 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 00:35:29 - train.py[line:551] - INFO: load:1.69 valid_run:2588.93 task_valid:2476.54 collect_output:92.72
2022-10-19 00:37:59 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 00:37:59 - train.py[line:551] - INFO: load:1.71 valid_run:2739.49 task_valid:2623.33 collect_output:95.50
2022-10-19 00:40:28 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 00:40:28 - train.py[line:551] - INFO: load:1.74 valid_run:2888.17 task_valid:2764.70 collect_output:101.84
2022-10-19 00:42:59 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 00:42:59 - train.py[line:551] - INFO: load:1.76 valid_run:3039.13 task_valid:2909.91 collect_output:106.61
2022-10-19 00:45:32 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 00:45:32 - train.py[line:551] - INFO: load:1.78 valid_run:3191.70 task_valid:3054.37 collect_output:113.72
2022-10-19 00:48:01 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 00:48:01 - train.py[line:551] - INFO: load:1.81 valid_run:3341.33 task_valid:3198.77 collect_output:117.98
2022-10-19 00:50:33 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 00:50:33 - train.py[line:551] - INFO: load:1.83 valid_run:3492.83 task_valid:3344.73 collect_output:122.53
2022-10-19 00:53:05 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 00:53:05 - train.py[line:551] - INFO: load:1.86 valid_run:3644.72 task_valid:3491.24 collect_output:126.92

====================================================================================================
SGG eval:     R @ 50: 0.3506;     R @ 100: 0.4126;     R @ 500: 0.4986;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1547;    mR @ 100: 0.2084;    mR @ 500: 0.2961;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0854) (covered in:0.0625) (covering:0.1429) (eating:0.4412) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2917) (playing:0.0000) (riding:0.6049) (says:0.0000) (sitting on:0.5539) (standing on:0.4450) (using:0.1500) (walking in:0.0000) (walking on:0.2477) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3506;     R @ 100: 0.4126;     R @ 500: 0.4986;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1547;    mR @ 100: 0.2084;    mR @ 500: 0.2961;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0854) (covered in:0.0625) (covering:0.1429) (eating:0.4412) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4355) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2917) (playing:0.0000) (riding:0.6049) (says:0.0000) (sitting on:0.5539) (standing on:0.4450) (using:0.1500) (walking in:0.0000) (walking on:0.2477) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2022-10-19 00:55:36 - train.py[line:487] - INFO: 0.4126190476190476
2022-10-19 00:55:36 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 00:55:36 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.419 | loss_v1 0 | loss_v2 0 | nll_loss 0.302 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.412619 | ppl 1.23 | vqa_score 0.2264 | wps 118.1 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.412619
2022-10-19 00:55:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2022-10-19 00:55:36 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-19 00:55:42 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-19 00:55:47 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.4126190476190476) (writing took 11.104699371848255 seconds)
2022-10-19 00:55:58 - progress_bar.py[line:274] - INFO: epoch 001:   4014 / 102288 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.624, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=0.3, ups=0, wpb=111.1, bsz=40, num_updates=4010, lr=9.80105e-06, gnorm=1.198, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19818
2022-10-19 00:56:09 - progress_bar.py[line:274] - INFO: epoch 001:   4024 / 102288 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.6, ups=0.91, wpb=111.2, bsz=40, num_updates=4020, lr=9.82549e-06, gnorm=1.36, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19829
2022-10-19 00:56:21 - progress_bar.py[line:274] - INFO: epoch 001:   4034 / 102288 loss=0.754, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.3, ups=0.88, wpb=109.6, bsz=40, num_updates=4030, lr=9.84993e-06, gnorm=1.305, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19840
2022-10-19 00:56:34 - progress_bar.py[line:274] - INFO: epoch 001:   4044 / 102288 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.2, ups=0.9, wpb=110.3, bsz=40, num_updates=4040, lr=9.87437e-06, gnorm=1.235, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19854
2022-10-19 00:56:45 - progress_bar.py[line:274] - INFO: epoch 001:   4054 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=4050, lr=9.89881e-06, gnorm=1.192, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19865
2022-10-19 00:56:57 - progress_bar.py[line:274] - INFO: epoch 001:   4064 / 102288 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.7, ups=0.88, wpb=111.4, bsz=40, num_updates=4060, lr=9.92325e-06, gnorm=1.356, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19876
2022-10-19 00:57:08 - progress_bar.py[line:274] - INFO: epoch 001:   4074 / 102288 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=95.6, ups=0.87, wpb=110.1, bsz=40, num_updates=4070, lr=9.9477e-06, gnorm=1.226, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19888
2022-10-19 00:57:19 - progress_bar.py[line:274] - INFO: epoch 001:   4084 / 102288 loss=0.761, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=98.2, ups=0.9, wpb=108.8, bsz=40, num_updates=4080, lr=9.97214e-06, gnorm=1.468, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=19899
2022-10-19 00:57:31 - progress_bar.py[line:274] - INFO: epoch 001:   4094 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=4090, lr=9.99658e-06, gnorm=1.159, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19910
2022-10-19 00:57:42 - progress_bar.py[line:274] - INFO: epoch 001:   4104 / 102288 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.698, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=96.1, ups=0.88, wpb=109.2, bsz=40, num_updates=4100, lr=1.0021e-05, gnorm=1.291, clip=70, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19922
2022-10-19 00:57:53 - progress_bar.py[line:274] - INFO: epoch 001:   4114 / 102288 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.6, ups=0.88, wpb=111, bsz=40, num_updates=4110, lr=1.00455e-05, gnorm=1.173, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19933
2022-10-19 00:58:05 - progress_bar.py[line:274] - INFO: epoch 001:   4124 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.3, ups=0.88, wpb=110.7, bsz=40, num_updates=4120, lr=1.00699e-05, gnorm=1.121, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19944
2022-10-19 00:58:16 - progress_bar.py[line:274] - INFO: epoch 001:   4134 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.2, ups=0.89, wpb=109.3, bsz=40, num_updates=4130, lr=1.00943e-05, gnorm=1.123, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19956
2022-10-19 00:58:27 - progress_bar.py[line:274] - INFO: epoch 001:   4144 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.5, ups=0.9, wpb=109, bsz=40, num_updates=4140, lr=1.01188e-05, gnorm=1.159, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19967
2022-10-19 00:58:38 - progress_bar.py[line:274] - INFO: epoch 001:   4154 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=4150, lr=1.01432e-05, gnorm=1.312, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19978
2022-10-19 00:58:50 - progress_bar.py[line:274] - INFO: epoch 001:   4164 / 102288 loss=0.787, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=95.6, ups=0.88, wpb=108.5, bsz=40, num_updates=4160, lr=1.01677e-05, gnorm=1.395, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19989
2022-10-19 00:59:01 - progress_bar.py[line:274] - INFO: epoch 001:   4174 / 102288 loss=0.762, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=4170, lr=1.01921e-05, gnorm=1.311, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20001
2022-10-19 00:59:12 - progress_bar.py[line:274] - INFO: epoch 001:   4184 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=4180, lr=1.02166e-05, gnorm=1.184, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20012
2022-10-19 00:59:23 - progress_bar.py[line:274] - INFO: epoch 001:   4194 / 102288 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=100.3, ups=0.91, wpb=109.6, bsz=40, num_updates=4190, lr=1.0241e-05, gnorm=1.191, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20023
2022-10-19 00:59:34 - progress_bar.py[line:274] - INFO: epoch 001:   4204 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=4200, lr=1.02654e-05, gnorm=1.263, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20034
2022-10-19 00:59:45 - progress_bar.py[line:274] - INFO: epoch 001:   4214 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=4210, lr=1.02899e-05, gnorm=1.218, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20045
2022-10-19 00:59:56 - progress_bar.py[line:274] - INFO: epoch 001:   4224 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.2, ups=0.91, wpb=111.1, bsz=40, num_updates=4220, lr=1.03143e-05, gnorm=1.13, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20056
2022-10-19 01:00:08 - progress_bar.py[line:274] - INFO: epoch 001:   4234 / 102288 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.644, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=4230, lr=1.03388e-05, gnorm=1.136, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20067
2022-10-19 01:00:19 - progress_bar.py[line:274] - INFO: epoch 001:   4244 / 102288 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.3, ups=0.89, wpb=109.1, bsz=40, num_updates=4240, lr=1.03632e-05, gnorm=1.196, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20079
2022-10-19 01:00:30 - progress_bar.py[line:274] - INFO: epoch 001:   4254 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=95.7, ups=0.87, wpb=110.3, bsz=40, num_updates=4250, lr=1.03876e-05, gnorm=1.189, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20090
2022-10-19 01:00:42 - progress_bar.py[line:274] - INFO: epoch 001:   4264 / 102288 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.679, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=97.9, ups=0.88, wpb=111.2, bsz=40, num_updates=4260, lr=1.04121e-05, gnorm=1.094, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20101
2022-10-19 01:00:53 - progress_bar.py[line:274] - INFO: epoch 001:   4274 / 102288 loss=0.729, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=4270, lr=1.04365e-05, gnorm=1.202, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20112
2022-10-19 01:01:04 - progress_bar.py[line:274] - INFO: epoch 001:   4284 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=95.6, ups=0.86, wpb=111.7, bsz=40, num_updates=4280, lr=1.0461e-05, gnorm=1.149, clip=80, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20124
2022-10-19 01:01:16 - progress_bar.py[line:274] - INFO: epoch 001:   4294 / 102288 loss=0.764, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=96.5, ups=0.89, wpb=108.6, bsz=40, num_updates=4290, lr=1.04854e-05, gnorm=1.147, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20135
2022-10-19 01:01:27 - progress_bar.py[line:274] - INFO: epoch 001:   4304 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=4300, lr=1.05098e-05, gnorm=1.113, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20147
2022-10-19 01:01:38 - progress_bar.py[line:274] - INFO: epoch 001:   4314 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=4310, lr=1.05343e-05, gnorm=1.175, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20158
2022-10-19 01:01:49 - progress_bar.py[line:274] - INFO: epoch 001:   4324 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.7, ups=0.9, wpb=109.4, bsz=40, num_updates=4320, lr=1.05587e-05, gnorm=1.298, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20169
2022-10-19 01:02:01 - progress_bar.py[line:274] - INFO: epoch 001:   4334 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.6, ups=0.88, wpb=110.7, bsz=40, num_updates=4330, lr=1.05832e-05, gnorm=1.247, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20180
2022-10-19 01:02:12 - progress_bar.py[line:274] - INFO: epoch 001:   4344 / 102288 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=96, ups=0.87, wpb=110.6, bsz=40, num_updates=4340, lr=1.06076e-05, gnorm=1.188, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20192
2022-10-19 01:02:23 - progress_bar.py[line:274] - INFO: epoch 001:   4354 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.7, ups=0.91, wpb=110.4, bsz=40, num_updates=4350, lr=1.06321e-05, gnorm=1.076, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20203
2022-10-19 01:02:34 - progress_bar.py[line:274] - INFO: epoch 001:   4364 / 102288 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.7, ups=0.91, wpb=109, bsz=40, num_updates=4360, lr=1.06565e-05, gnorm=1.198, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20214
2022-10-19 01:02:45 - progress_bar.py[line:274] - INFO: epoch 001:   4374 / 102288 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=102.9, ups=0.93, wpb=110.9, bsz=40, num_updates=4370, lr=1.06809e-05, gnorm=1.176, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20225
2022-10-19 01:02:56 - progress_bar.py[line:274] - INFO: epoch 001:   4384 / 102288 loss=0.749, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=4380, lr=1.07054e-05, gnorm=1.417, clip=90, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20236
2022-10-19 01:03:07 - progress_bar.py[line:274] - INFO: epoch 001:   4394 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.629, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=4390, lr=1.07298e-05, gnorm=1.197, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20247
2022-10-19 01:03:18 - progress_bar.py[line:274] - INFO: epoch 001:   4404 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=4400, lr=1.07543e-05, gnorm=1.118, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20258
2022-10-19 01:03:29 - progress_bar.py[line:274] - INFO: epoch 001:   4414 / 102288 loss=0.735, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97, ups=0.88, wpb=109.8, bsz=40, num_updates=4410, lr=1.07787e-05, gnorm=1.228, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20269
2022-10-19 01:03:41 - progress_bar.py[line:274] - INFO: epoch 001:   4424 / 102288 loss=0.785, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=94.5, ups=0.87, wpb=108.8, bsz=40, num_updates=4420, lr=1.08031e-05, gnorm=1.228, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20281
2022-10-19 01:03:52 - progress_bar.py[line:274] - INFO: epoch 001:   4434 / 102288 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=101.5, ups=0.93, wpb=109.4, bsz=40, num_updates=4430, lr=1.08276e-05, gnorm=1.126, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20292
2022-10-19 01:04:03 - progress_bar.py[line:274] - INFO: epoch 001:   4444 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.7, ups=0.88, wpb=111.2, bsz=40, num_updates=4440, lr=1.0852e-05, gnorm=1.186, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20303
2022-10-19 01:04:15 - progress_bar.py[line:274] - INFO: epoch 001:   4454 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.673, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.2, ups=0.88, wpb=109.3, bsz=40, num_updates=4450, lr=1.08765e-05, gnorm=1.244, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20314
2022-10-19 01:04:25 - progress_bar.py[line:274] - INFO: epoch 001:   4464 / 102288 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=101.1, ups=0.91, wpb=110.5, bsz=40, num_updates=4460, lr=1.09009e-05, gnorm=1.073, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20325
2022-10-19 01:04:37 - progress_bar.py[line:274] - INFO: epoch 001:   4474 / 102288 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=96.6, ups=0.88, wpb=109.8, bsz=40, num_updates=4470, lr=1.09254e-05, gnorm=1.186, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20337
2022-10-19 01:04:48 - progress_bar.py[line:274] - INFO: epoch 001:   4484 / 102288 loss=0.759, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=98.7, ups=0.9, wpb=109.4, bsz=40, num_updates=4480, lr=1.09498e-05, gnorm=1.236, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20348
2022-10-19 01:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   4494 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.613, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=4490, lr=1.09742e-05, gnorm=1.104, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20359
2022-10-19 01:05:10 - progress_bar.py[line:274] - INFO: epoch 001:   4504 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=4500, lr=1.09987e-05, gnorm=1.137, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20370
2022-10-19 01:05:21 - progress_bar.py[line:274] - INFO: epoch 001:   4514 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.633, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=105, ups=0.94, wpb=111.7, bsz=40, num_updates=4510, lr=1.10231e-05, gnorm=1.123, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20381
2022-10-19 01:05:32 - progress_bar.py[line:274] - INFO: epoch 001:   4524 / 102288 loss=0.71, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.4, ups=0.89, wpb=111.5, bsz=40, num_updates=4520, lr=1.10476e-05, gnorm=1.003, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20392
2022-10-19 01:05:43 - progress_bar.py[line:274] - INFO: epoch 001:   4534 / 102288 loss=0.736, loss_v1=0, loss_v2=0, nll_loss=0.654, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=4530, lr=1.1072e-05, gnorm=1.098, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20403
2022-10-19 01:05:55 - progress_bar.py[line:274] - INFO: epoch 001:   4544 / 102288 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=4540, lr=1.10964e-05, gnorm=1.188, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20414
2022-10-19 01:06:06 - progress_bar.py[line:274] - INFO: epoch 001:   4554 / 102288 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=4550, lr=1.11209e-05, gnorm=1.084, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20426
2022-10-19 01:06:17 - progress_bar.py[line:274] - INFO: epoch 001:   4564 / 102288 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=4560, lr=1.11453e-05, gnorm=1.139, clip=80, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20437
2022-10-19 01:06:29 - progress_bar.py[line:274] - INFO: epoch 001:   4574 / 102288 loss=0.758, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.1, ups=0.88, wpb=109.3, bsz=40, num_updates=4570, lr=1.11698e-05, gnorm=1.248, clip=90, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20448
2022-10-19 01:06:40 - progress_bar.py[line:274] - INFO: epoch 001:   4584 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.3, ups=0.9, wpb=108.8, bsz=40, num_updates=4580, lr=1.11942e-05, gnorm=1.083, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20459
2022-10-19 01:06:51 - progress_bar.py[line:274] - INFO: epoch 001:   4594 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.679, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=94.6, ups=0.87, wpb=109.1, bsz=40, num_updates=4590, lr=1.12187e-05, gnorm=1.364, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20471
2022-10-19 01:07:02 - progress_bar.py[line:274] - INFO: epoch 001:   4604 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.7, ups=0.89, wpb=109.5, bsz=40, num_updates=4600, lr=1.12431e-05, gnorm=1.126, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20482
2022-10-19 01:07:13 - progress_bar.py[line:274] - INFO: epoch 001:   4614 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99, ups=0.9, wpb=109.5, bsz=40, num_updates=4610, lr=1.12675e-05, gnorm=1.145, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20493
2022-10-19 01:07:24 - progress_bar.py[line:274] - INFO: epoch 001:   4624 / 102288 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=4620, lr=1.1292e-05, gnorm=1.125, clip=60, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20504
2022-10-19 01:07:36 - progress_bar.py[line:274] - INFO: epoch 001:   4634 / 102288 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=97.8, ups=0.88, wpb=111.4, bsz=40, num_updates=4630, lr=1.13164e-05, gnorm=1.001, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20516
2022-10-19 01:07:47 - progress_bar.py[line:274] - INFO: epoch 001:   4644 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=101.8, ups=0.9, wpb=112.7, bsz=40, num_updates=4640, lr=1.13409e-05, gnorm=1.019, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20527
2022-10-19 01:07:58 - progress_bar.py[line:274] - INFO: epoch 001:   4654 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=4650, lr=1.13653e-05, gnorm=1.121, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20538
2022-10-19 01:08:10 - progress_bar.py[line:274] - INFO: epoch 001:   4664 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=94.8, ups=0.87, wpb=109.1, bsz=40, num_updates=4660, lr=1.13897e-05, gnorm=1.11, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20549
2022-10-19 01:08:21 - progress_bar.py[line:274] - INFO: epoch 001:   4674 / 102288 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=4670, lr=1.14142e-05, gnorm=1.101, clip=70, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20561
2022-10-19 01:08:32 - progress_bar.py[line:274] - INFO: epoch 001:   4684 / 102288 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.3, ups=0.9, wpb=108.9, bsz=40, num_updates=4680, lr=1.14386e-05, gnorm=1.271, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20572
2022-10-19 01:08:43 - progress_bar.py[line:274] - INFO: epoch 001:   4694 / 102288 loss=0.751, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=95.8, ups=0.88, wpb=109, bsz=40, num_updates=4690, lr=1.14631e-05, gnorm=1.118, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20583
2022-10-19 01:08:55 - progress_bar.py[line:274] - INFO: epoch 001:   4704 / 102288 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=4700, lr=1.14875e-05, gnorm=1.03, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20594
2022-10-19 01:09:06 - progress_bar.py[line:274] - INFO: epoch 001:   4714 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=4710, lr=1.1512e-05, gnorm=1.088, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20606
2022-10-19 01:09:08 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 01:09:18 - progress_bar.py[line:274] - INFO: epoch 001:   4725 / 102288 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=88.3, ups=0.8, wpb=110, bsz=40, num_updates=4720, lr=1.15364e-05, gnorm=1.169, clip=80, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=20618
2022-10-19 01:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   4735 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=4730, lr=1.15608e-05, gnorm=1.155, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20629
2022-10-19 01:09:41 - progress_bar.py[line:274] - INFO: epoch 001:   4745 / 102288 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=4740, lr=1.15853e-05, gnorm=1.088, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20641
2022-10-19 01:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   4755 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=95.8, ups=0.88, wpb=109.1, bsz=40, num_updates=4750, lr=1.16097e-05, gnorm=1.198, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20652
2022-10-19 01:10:04 - progress_bar.py[line:274] - INFO: epoch 001:   4765 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.587, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=4760, lr=1.16342e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20663
2022-10-19 01:10:15 - progress_bar.py[line:274] - INFO: epoch 001:   4775 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.6, ups=0.89, wpb=109.7, bsz=40, num_updates=4770, lr=1.16586e-05, gnorm=1.216, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20675
2022-10-19 01:10:26 - progress_bar.py[line:274] - INFO: epoch 001:   4785 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=4780, lr=1.1683e-05, gnorm=1.301, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20686
2022-10-19 01:10:37 - progress_bar.py[line:274] - INFO: epoch 001:   4795 / 102288 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=4790, lr=1.17075e-05, gnorm=1.083, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20697
2022-10-19 01:10:48 - progress_bar.py[line:274] - INFO: epoch 001:   4805 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.656, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.1, ups=0.92, wpb=108.7, bsz=40, num_updates=4800, lr=1.17319e-05, gnorm=1.24, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20708
2022-10-19 01:11:00 - progress_bar.py[line:274] - INFO: epoch 001:   4815 / 102288 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.619, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=4810, lr=1.17564e-05, gnorm=1.025, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20720
2022-10-19 01:11:11 - progress_bar.py[line:274] - INFO: epoch 001:   4825 / 102288 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.5, ups=0.91, wpb=111, bsz=40, num_updates=4820, lr=1.17808e-05, gnorm=1.07, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20730
2022-10-19 01:11:22 - progress_bar.py[line:274] - INFO: epoch 001:   4835 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=4830, lr=1.18053e-05, gnorm=1.157, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20742
2022-10-19 01:11:33 - progress_bar.py[line:274] - INFO: epoch 001:   4845 / 102288 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=4840, lr=1.18297e-05, gnorm=1.11, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20753
2022-10-19 01:11:44 - progress_bar.py[line:274] - INFO: epoch 001:   4855 / 102288 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.3, ups=0.9, wpb=110.2, bsz=40, num_updates=4850, lr=1.18541e-05, gnorm=1.17, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20764
2022-10-19 01:11:55 - progress_bar.py[line:274] - INFO: epoch 001:   4865 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.66, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100.1, ups=0.92, wpb=109.4, bsz=40, num_updates=4860, lr=1.18786e-05, gnorm=1.169, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20775
2022-10-19 01:12:06 - progress_bar.py[line:274] - INFO: epoch 001:   4875 / 102288 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.6, ups=0.89, wpb=109.9, bsz=40, num_updates=4870, lr=1.1903e-05, gnorm=1.208, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20786
2022-10-19 01:12:18 - progress_bar.py[line:274] - INFO: epoch 001:   4885 / 102288 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=4880, lr=1.19275e-05, gnorm=1.243, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20797
2022-10-19 01:12:29 - progress_bar.py[line:274] - INFO: epoch 001:   4895 / 102288 loss=0.716, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=95.7, ups=0.88, wpb=109.1, bsz=40, num_updates=4890, lr=1.19519e-05, gnorm=1.168, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20809
2022-10-19 01:12:40 - progress_bar.py[line:274] - INFO: epoch 001:   4905 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.644, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100.5, ups=0.91, wpb=109.9, bsz=40, num_updates=4900, lr=1.19763e-05, gnorm=1.037, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20820
2022-10-19 01:12:51 - progress_bar.py[line:274] - INFO: epoch 001:   4915 / 102288 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99, ups=0.89, wpb=111.2, bsz=40, num_updates=4910, lr=1.20008e-05, gnorm=1.113, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20831
2022-10-19 01:13:02 - progress_bar.py[line:274] - INFO: epoch 001:   4925 / 102288 loss=0.748, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=4920, lr=1.20252e-05, gnorm=1.098, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20842
2022-10-19 01:13:13 - progress_bar.py[line:274] - INFO: epoch 001:   4935 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=100.3, ups=0.9, wpb=111.2, bsz=40, num_updates=4930, lr=1.20497e-05, gnorm=1.099, clip=80, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=20853
2022-10-19 01:13:25 - progress_bar.py[line:274] - INFO: epoch 001:   4945 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.8, ups=0.9, wpb=110.8, bsz=40, num_updates=4940, lr=1.20741e-05, gnorm=1.198, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20864
2022-10-19 01:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   4955 / 102288 loss=0.763, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.3, ups=0.89, wpb=109.3, bsz=40, num_updates=4950, lr=1.20985e-05, gnorm=1.217, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20876
2022-10-19 01:13:47 - progress_bar.py[line:274] - INFO: epoch 001:   4965 / 102288 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=103.2, ups=0.93, wpb=110.8, bsz=40, num_updates=4960, lr=1.2123e-05, gnorm=1.025, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20886
2022-10-19 01:13:58 - progress_bar.py[line:274] - INFO: epoch 001:   4975 / 102288 loss=0.727, loss_v1=0, loss_v2=0, nll_loss=0.642, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.4, ups=0.88, wpb=110.9, bsz=40, num_updates=4970, lr=1.21474e-05, gnorm=1.243, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20898
2022-10-19 01:14:09 - progress_bar.py[line:274] - INFO: epoch 001:   4985 / 102288 loss=0.736, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=4980, lr=1.21719e-05, gnorm=1.113, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20909
2022-10-19 01:14:20 - progress_bar.py[line:274] - INFO: epoch 001:   4995 / 102288 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=4990, lr=1.21963e-05, gnorm=1.144, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20920
2022-10-19 01:14:31 - progress_bar.py[line:274] - INFO: epoch 001:   5005 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.648, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=5000, lr=1.22208e-05, gnorm=1.173, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20931
2022-10-19 01:14:31 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 01:14:33 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 01:14:33 - train.py[line:551] - INFO: load:1.23 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 01:14:49 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.90 GiB already allocated; 3.13 GiB free; 33.97 GiB reserved in total by PyTorch)
2022-10-19 01:14:49 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 8         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9112 MB |   14342 MB |    3005 TB |    3005 TB |
|       from large pool |    8967 MB |   14197 MB |    3004 TB |    3004 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9112 MB |   14342 MB |    3005 TB |    3005 TB |
|       from large pool |    8967 MB |   14197 MB |    3004 TB |    3004 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34786 MB |   35066 MB |  121762 MB |   86976 MB |
|       from large pool |   34640 MB |   34914 MB |  121480 MB |   86840 MB |
|       from small pool |     146 MB |     152 MB |     282 MB |     136 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25673 MB |   25673 MB |    2928 TB |    2928 TB |
|       from large pool |   25672 MB |   25672 MB |    2927 TB |    2927 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  138141 K  |  138137 K  |
|       from large pool |     563    |     575    |   44995 K  |   44994 K  |
|       from small pool |    3106    |    3116    |   93146 K  |   93143 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  138141 K  |  138137 K  |
|       from large pool |     563    |     575    |   44995 K  |   44994 K  |
|       from small pool |    3106    |    3116    |   93146 K  |   93143 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     180    |     185    |     435    |     255    |
|       from large pool |     107    |     109    |     294    |     187    |
|       from small pool |      73    |      76    |     141    |      68    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     132    |     141    |   96929 K  |   96929 K  |
|       from large pool |      94    |      96    |   16017 K  |   16017 K  |
|       from small pool |      38    |      49    |   80911 K  |   80911 K  |
|===========================================================================|

2022-10-19 01:14:49 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-19 01:14:49 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-19 01:17:06 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 01:17:06 - train.py[line:551] - INFO: load:1.25 valid_run:153.08 task_valid:148.21 collect_output:2.79
2022-10-19 01:19:35 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 01:19:35 - train.py[line:551] - INFO: load:1.27 valid_run:301.92 task_valid:291.14 collect_output:7.65
2022-10-19 01:22:08 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 01:22:08 - train.py[line:551] - INFO: load:1.30 valid_run:454.81 task_valid:434.26 collect_output:16.37
2022-10-19 01:24:38 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 01:24:38 - train.py[line:551] - INFO: load:1.32 valid_run:604.37 task_valid:579.20 collect_output:19.93
2022-10-19 01:27:11 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 01:27:11 - train.py[line:551] - INFO: load:1.35 valid_run:757.60 task_valid:726.86 collect_output:24.42
2022-10-19 01:29:43 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 01:29:43 - train.py[line:551] - INFO: load:1.37 valid_run:909.71 task_valid:872.32 collect_output:30.02
2022-10-19 01:32:17 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 01:32:17 - train.py[line:551] - INFO: load:1.40 valid_run:1063.62 task_valid:1018.40 collect_output:36.80
2022-10-19 01:34:49 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 01:34:49 - train.py[line:551] - INFO: load:1.42 valid_run:1215.51 task_valid:1159.75 collect_output:46.27
2022-10-19 01:37:19 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 01:37:19 - train.py[line:551] - INFO: load:1.45 valid_run:1365.78 task_valid:1304.91 collect_output:50.31
2022-10-19 01:39:49 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 01:39:49 - train.py[line:551] - INFO: load:1.48 valid_run:1514.93 task_valid:1448.20 collect_output:55.17
2022-10-19 01:42:19 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 01:42:19 - train.py[line:551] - INFO: load:1.50 valid_run:1664.93 task_valid:1593.11 collect_output:59.25
2022-10-19 01:44:49 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 01:44:49 - train.py[line:551] - INFO: load:1.53 valid_run:1815.16 task_valid:1737.93 collect_output:63.66
2022-10-19 01:47:19 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 01:47:19 - train.py[line:551] - INFO: load:1.55 valid_run:1965.45 task_valid:1879.77 collect_output:71.12
2022-10-19 01:49:50 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 01:49:50 - train.py[line:551] - INFO: load:1.58 valid_run:2116.15 task_valid:2024.98 collect_output:75.62
2022-10-19 01:52:20 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 01:52:20 - train.py[line:551] - INFO: load:1.60 valid_run:2266.12 task_valid:2171.18 collect_output:78.39
2022-10-19 01:54:50 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 01:54:50 - train.py[line:551] - INFO: load:1.63 valid_run:2416.18 task_valid:2315.04 collect_output:83.60
2022-10-19 01:57:22 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 01:57:22 - train.py[line:551] - INFO: load:1.65 valid_run:2568.09 task_valid:2460.16 collect_output:89.42
2022-10-19 01:59:53 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 01:59:53 - train.py[line:551] - INFO: load:1.68 valid_run:2718.72 task_valid:2606.83 collect_output:92.42
2022-10-19 02:02:22 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 02:02:22 - train.py[line:551] - INFO: load:1.70 valid_run:2867.42 task_valid:2748.15 collect_output:98.81
2022-10-19 02:04:52 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 02:04:52 - train.py[line:551] - INFO: load:1.73 valid_run:3018.05 task_valid:2893.05 collect_output:103.56
2022-10-19 02:07:25 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 02:07:25 - train.py[line:551] - INFO: load:1.75 valid_run:3170.56 task_valid:3037.41 collect_output:110.73
2022-10-19 02:09:54 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 02:09:54 - train.py[line:551] - INFO: load:1.78 valid_run:3320.11 task_valid:3181.79 collect_output:114.92
2022-10-19 02:12:26 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 02:12:26 - train.py[line:551] - INFO: load:1.80 valid_run:3471.81 task_valid:3327.70 collect_output:119.72
2022-10-19 02:14:58 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 02:14:58 - train.py[line:551] - INFO: load:1.83 valid_run:3623.37 task_valid:3474.16 collect_output:123.83

====================================================================================================
SGG eval:     R @ 50: 0.4110;     R @ 100: 0.4720;     R @ 500: 0.5298;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2020;    mR @ 100: 0.2681;    mR @ 500: 0.3242;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1512) (covered in:0.1250) (covering:0.2857) (eating:0.5294) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4290) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.4583) (playing:0.0000) (riding:0.7039) (says:0.0000) (sitting on:0.6519) (standing on:0.3400) (using:0.2500) (walking in:0.0000) (walking on:0.4595) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4110;     R @ 100: 0.4720;     R @ 500: 0.5298;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2020;    mR @ 100: 0.2681;    mR @ 500: 0.3242;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1512) (covered in:0.1250) (covering:0.2857) (eating:0.5294) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4290) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.4583) (playing:0.0000) (riding:0.7039) (says:0.0000) (sitting on:0.6519) (standing on:0.3400) (using:0.2500) (walking in:0.0000) (walking on:0.4595) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================

2022-10-19 02:17:29 - train.py[line:487] - INFO: 0.4720138528138528
2022-10-19 02:17:29 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 02:17:30 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.381 | loss_v1 0 | loss_v2 0 | nll_loss 0.248 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.472014 | ppl 1.19 | vqa_score 0.2759 | wps 118.8 | wpb 89.9 | bsz 30 | num_updates 5000 | best_R@100 0.472014
2022-10-19 02:17:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 5000 updates
2022-10-19 02:17:31 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-19 02:17:36 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-19 02:17:41 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 0.4720138528138528) (writing took 10.829596555791795 seconds)
2022-10-19 02:17:53 - progress_bar.py[line:274] - INFO: epoch 001:   5015 / 102288 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=0.3, ups=0, wpb=111.5, bsz=40, num_updates=5010, lr=1.22452e-05, gnorm=1.023, clip=60, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=24733
2022-10-19 02:18:04 - progress_bar.py[line:274] - INFO: epoch 001:   5025 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=5020, lr=1.22696e-05, gnorm=1.183, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24744
2022-10-19 02:18:15 - progress_bar.py[line:274] - INFO: epoch 001:   5035 / 102288 loss=0.788, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=98.2, ups=0.9, wpb=108.9, bsz=40, num_updates=5030, lr=1.22941e-05, gnorm=1.18, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24755
2022-10-19 02:18:27 - progress_bar.py[line:274] - INFO: epoch 001:   5045 / 102288 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=95.3, ups=0.87, wpb=109.4, bsz=40, num_updates=5040, lr=1.23185e-05, gnorm=1.114, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24767
2022-10-19 02:18:38 - progress_bar.py[line:274] - INFO: epoch 001:   5055 / 102288 loss=0.735, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.6, ups=0.9, wpb=109.3, bsz=40, num_updates=5050, lr=1.2343e-05, gnorm=1.097, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24778
2022-10-19 02:18:49 - progress_bar.py[line:274] - INFO: epoch 001:   5065 / 102288 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.619, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.7, ups=0.9, wpb=109.4, bsz=40, num_updates=5060, lr=1.23674e-05, gnorm=1.166, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24789
2022-10-19 02:19:00 - progress_bar.py[line:274] - INFO: epoch 001:   5075 / 102288 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=5070, lr=1.23918e-05, gnorm=1.013, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24800
2022-10-19 02:19:12 - progress_bar.py[line:274] - INFO: epoch 001:   5085 / 102288 loss=0.743, loss_v1=0, loss_v2=0, nll_loss=0.657, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=5080, lr=1.24163e-05, gnorm=1.146, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24812
2022-10-19 02:19:23 - progress_bar.py[line:274] - INFO: epoch 001:   5095 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.3, ups=0.88, wpb=112.1, bsz=40, num_updates=5090, lr=1.24407e-05, gnorm=1.165, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24823
2022-10-19 02:19:34 - progress_bar.py[line:274] - INFO: epoch 001:   5105 / 102288 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=5100, lr=1.24652e-05, gnorm=1.129, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24834
2022-10-19 02:19:46 - progress_bar.py[line:274] - INFO: epoch 001:   5115 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=100.3, ups=0.9, wpb=111.2, bsz=40, num_updates=5110, lr=1.24896e-05, gnorm=1.114, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24845
2022-10-19 02:19:57 - progress_bar.py[line:274] - INFO: epoch 001:   5125 / 102288 loss=0.734, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=5120, lr=1.25141e-05, gnorm=1.196, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24857
2022-10-19 02:20:08 - progress_bar.py[line:274] - INFO: epoch 001:   5135 / 102288 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=96.5, ups=0.88, wpb=110.1, bsz=40, num_updates=5130, lr=1.25385e-05, gnorm=1.254, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24868
2022-10-19 02:20:19 - progress_bar.py[line:274] - INFO: epoch 001:   5145 / 102288 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=102.8, ups=0.93, wpb=110.9, bsz=40, num_updates=5140, lr=1.25629e-05, gnorm=1.147, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24879
2022-10-19 02:20:30 - progress_bar.py[line:274] - INFO: epoch 001:   5155 / 102288 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=101.1, ups=0.9, wpb=112, bsz=40, num_updates=5150, lr=1.25874e-05, gnorm=1.157, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24890
2022-10-19 02:20:42 - progress_bar.py[line:274] - INFO: epoch 001:   5165 / 102288 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.69, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=5160, lr=1.26118e-05, gnorm=1.224, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24901
2022-10-19 02:20:53 - progress_bar.py[line:274] - INFO: epoch 001:   5175 / 102288 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=100.2, ups=0.89, wpb=112.5, bsz=40, num_updates=5170, lr=1.26363e-05, gnorm=1.215, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24913
2022-10-19 02:21:04 - progress_bar.py[line:274] - INFO: epoch 001:   5185 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=5180, lr=1.26607e-05, gnorm=1.023, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24924
2022-10-19 02:21:15 - progress_bar.py[line:274] - INFO: epoch 001:   5195 / 102288 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.4, ups=0.9, wpb=111.2, bsz=40, num_updates=5190, lr=1.26851e-05, gnorm=1.082, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24935
2022-10-19 02:21:26 - progress_bar.py[line:274] - INFO: epoch 001:   5205 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.639, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=96.1, ups=0.87, wpb=110.7, bsz=40, num_updates=5200, lr=1.27096e-05, gnorm=1.099, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24946
2022-10-19 02:21:37 - progress_bar.py[line:274] - INFO: epoch 001:   5215 / 102288 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.658, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=100, ups=0.91, wpb=109.4, bsz=40, num_updates=5210, lr=1.2734e-05, gnorm=1.173, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24957
2022-10-19 02:21:49 - progress_bar.py[line:274] - INFO: epoch 001:   5225 / 102288 loss=0.746, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=95, ups=0.87, wpb=109.6, bsz=40, num_updates=5220, lr=1.27585e-05, gnorm=1.098, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24969
2022-10-19 02:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   5235 / 102288 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.7, ups=0.9, wpb=109.6, bsz=40, num_updates=5230, lr=1.27829e-05, gnorm=1.171, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24980
2022-10-19 02:22:11 - progress_bar.py[line:274] - INFO: epoch 001:   5245 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=100.2, ups=0.92, wpb=109, bsz=40, num_updates=5240, lr=1.28074e-05, gnorm=1.222, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24991
2022-10-19 02:22:22 - progress_bar.py[line:274] - INFO: epoch 001:   5255 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=96.3, ups=0.88, wpb=110, bsz=40, num_updates=5250, lr=1.28318e-05, gnorm=1.093, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25002
2022-10-19 02:22:33 - progress_bar.py[line:274] - INFO: epoch 001:   5265 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=5260, lr=1.28562e-05, gnorm=1.092, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25013
2022-10-19 02:22:45 - progress_bar.py[line:274] - INFO: epoch 001:   5275 / 102288 loss=0.74, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=94.9, ups=0.87, wpb=109.3, bsz=40, num_updates=5270, lr=1.28807e-05, gnorm=1.168, clip=80, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25025
2022-10-19 02:22:56 - progress_bar.py[line:274] - INFO: epoch 001:   5285 / 102288 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.65, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=5280, lr=1.29051e-05, gnorm=1.247, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25036
2022-10-19 02:23:07 - progress_bar.py[line:274] - INFO: epoch 001:   5295 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.631, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.8, ups=0.91, wpb=109.1, bsz=40, num_updates=5290, lr=1.29296e-05, gnorm=1.137, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25047
2022-10-19 02:23:18 - progress_bar.py[line:274] - INFO: epoch 001:   5305 / 102288 loss=0.752, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=5300, lr=1.2954e-05, gnorm=1.264, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25058
2022-10-19 02:23:29 - progress_bar.py[line:274] - INFO: epoch 001:   5315 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.651, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100.3, ups=0.91, wpb=109.7, bsz=40, num_updates=5310, lr=1.29784e-05, gnorm=1.141, clip=70, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25069
2022-10-19 02:23:40 - progress_bar.py[line:274] - INFO: epoch 001:   5325 / 102288 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.2, ups=0.91, wpb=110.9, bsz=40, num_updates=5320, lr=1.30029e-05, gnorm=1.085, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25080
2022-10-19 02:23:51 - progress_bar.py[line:274] - INFO: epoch 001:   5335 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.1, ups=0.9, wpb=108.8, bsz=40, num_updates=5330, lr=1.30273e-05, gnorm=1.168, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25091
2022-10-19 02:24:02 - progress_bar.py[line:274] - INFO: epoch 001:   5345 / 102288 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=5340, lr=1.30518e-05, gnorm=1.259, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25102
2022-10-19 02:24:14 - progress_bar.py[line:274] - INFO: epoch 001:   5355 / 102288 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=97.9, ups=0.89, wpb=110.3, bsz=40, num_updates=5350, lr=1.30762e-05, gnorm=1.2, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25113
2022-10-19 02:24:25 - progress_bar.py[line:274] - INFO: epoch 001:   5365 / 102288 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=5360, lr=1.31007e-05, gnorm=1.035, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25124
2022-10-19 02:24:36 - progress_bar.py[line:274] - INFO: epoch 001:   5375 / 102288 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=94, ups=0.85, wpb=110.1, bsz=40, num_updates=5370, lr=1.31251e-05, gnorm=1.239, clip=100, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=25136
2022-10-19 02:24:47 - progress_bar.py[line:274] - INFO: epoch 001:   5385 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=5380, lr=1.31495e-05, gnorm=1.247, clip=80, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25147
2022-10-19 02:24:58 - progress_bar.py[line:274] - INFO: epoch 001:   5395 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.3, ups=0.91, wpb=108.6, bsz=40, num_updates=5390, lr=1.3174e-05, gnorm=1.314, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25158
2022-10-19 02:25:10 - progress_bar.py[line:274] - INFO: epoch 001:   5405 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.1, ups=0.9, wpb=109.9, bsz=40, num_updates=5400, lr=1.31984e-05, gnorm=1.135, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25169
2022-10-19 02:25:21 - progress_bar.py[line:274] - INFO: epoch 001:   5415 / 102288 loss=0.745, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=5410, lr=1.32229e-05, gnorm=1.137, clip=80, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25181
2022-10-19 02:25:32 - progress_bar.py[line:274] - INFO: epoch 001:   5425 / 102288 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.1, ups=0.9, wpb=111.2, bsz=40, num_updates=5420, lr=1.32473e-05, gnorm=1.097, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25192
2022-10-19 02:25:43 - progress_bar.py[line:274] - INFO: epoch 001:   5435 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.635, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=5430, lr=1.32717e-05, gnorm=1.131, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25203
2022-10-19 02:25:54 - progress_bar.py[line:274] - INFO: epoch 001:   5445 / 102288 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=101, ups=0.91, wpb=110.5, bsz=40, num_updates=5440, lr=1.32962e-05, gnorm=1.286, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25214
2022-10-19 02:26:05 - progress_bar.py[line:274] - INFO: epoch 001:   5455 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=5450, lr=1.33206e-05, gnorm=1.397, clip=90, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25225
2022-10-19 02:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   5465 / 102288 loss=0.723, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=99.3, ups=0.9, wpb=110.3, bsz=40, num_updates=5460, lr=1.33451e-05, gnorm=1.349, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25236
2022-10-19 02:26:28 - progress_bar.py[line:274] - INFO: epoch 001:   5475 / 102288 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97.7, ups=0.89, wpb=110.4, bsz=40, num_updates=5470, lr=1.33695e-05, gnorm=1.235, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25248
2022-10-19 02:26:39 - progress_bar.py[line:274] - INFO: epoch 001:   5485 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=5480, lr=1.33939e-05, gnorm=1.143, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25258
2022-10-19 02:26:49 - progress_bar.py[line:274] - INFO: epoch 001:   5495 / 102288 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=101.3, ups=0.93, wpb=109.3, bsz=40, num_updates=5490, lr=1.34184e-05, gnorm=1.197, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25269
2022-10-19 02:27:01 - progress_bar.py[line:274] - INFO: epoch 001:   5505 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=95.8, ups=0.88, wpb=109.2, bsz=40, num_updates=5500, lr=1.34428e-05, gnorm=1.245, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25281
2022-10-19 02:27:12 - progress_bar.py[line:274] - INFO: epoch 001:   5515 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=100.6, ups=0.9, wpb=111.5, bsz=40, num_updates=5510, lr=1.34673e-05, gnorm=1.213, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25292
2022-10-19 02:27:23 - progress_bar.py[line:274] - INFO: epoch 001:   5525 / 102288 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=5520, lr=1.34917e-05, gnorm=1.532, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25303
2022-10-19 02:27:34 - progress_bar.py[line:274] - INFO: epoch 001:   5535 / 102288 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.587, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=101.2, ups=0.91, wpb=110.9, bsz=40, num_updates=5530, lr=1.35162e-05, gnorm=1.33, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25314
2022-10-19 02:27:45 - progress_bar.py[line:274] - INFO: epoch 001:   5545 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=5540, lr=1.35406e-05, gnorm=1.321, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25325
2022-10-19 02:27:57 - progress_bar.py[line:274] - INFO: epoch 001:   5555 / 102288 loss=0.709, loss_v1=0, loss_v2=0, nll_loss=0.621, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=96.4, ups=0.87, wpb=110.6, bsz=40, num_updates=5550, lr=1.3565e-05, gnorm=1.246, clip=100, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=25336
2022-10-19 02:28:00 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 02:28:09 - progress_bar.py[line:274] - INFO: epoch 001:   5566 / 102288 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=89.2, ups=0.81, wpb=109.7, bsz=40, num_updates=5560, lr=1.35895e-05, gnorm=1.392, clip=100, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=25349
2022-10-19 02:28:20 - progress_bar.py[line:274] - INFO: epoch 001:   5576 / 102288 loss=0.761, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=96.1, ups=0.89, wpb=107.8, bsz=40, num_updates=5570, lr=1.36139e-05, gnorm=1.395, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25360
2022-10-19 02:28:31 - progress_bar.py[line:274] - INFO: epoch 001:   5586 / 102288 loss=0.744, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=5580, lr=1.36384e-05, gnorm=1.29, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25371
2022-10-19 02:28:42 - progress_bar.py[line:274] - INFO: epoch 001:   5596 / 102288 loss=0.714, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=5590, lr=1.36628e-05, gnorm=1.526, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25382
2022-10-19 02:28:54 - progress_bar.py[line:274] - INFO: epoch 001:   5606 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97.1, ups=0.88, wpb=110.5, bsz=40, num_updates=5600, lr=1.36872e-05, gnorm=1.513, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25393
2022-10-19 02:29:05 - progress_bar.py[line:274] - INFO: epoch 001:   5616 / 102288 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.586, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=5610, lr=1.37117e-05, gnorm=1.255, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25405
2022-10-19 02:29:17 - progress_bar.py[line:274] - INFO: epoch 001:   5626 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=95.5, ups=0.87, wpb=110.2, bsz=40, num_updates=5620, lr=1.37361e-05, gnorm=1.321, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25416
2022-10-19 02:29:28 - progress_bar.py[line:274] - INFO: epoch 001:   5636 / 102288 loss=0.719, loss_v1=0, loss_v2=0, nll_loss=0.633, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=98.6, ups=0.9, wpb=109.4, bsz=40, num_updates=5630, lr=1.37606e-05, gnorm=1.292, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25427
2022-10-19 02:29:39 - progress_bar.py[line:274] - INFO: epoch 001:   5646 / 102288 loss=0.72, loss_v1=0, loss_v2=0, nll_loss=0.633, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.9, ups=0.89, wpb=110.2, bsz=40, num_updates=5640, lr=1.3785e-05, gnorm=1.336, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25439
2022-10-19 02:29:49 - progress_bar.py[line:274] - INFO: epoch 001:   5656 / 102288 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=104.5, ups=0.94, wpb=110.8, bsz=40, num_updates=5650, lr=1.38095e-05, gnorm=1.275, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25449
2022-10-19 02:30:00 - progress_bar.py[line:274] - INFO: epoch 001:   5666 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.622, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=100.7, ups=0.92, wpb=109.6, bsz=40, num_updates=5660, lr=1.38339e-05, gnorm=1.359, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25460
2022-10-19 02:30:12 - progress_bar.py[line:274] - INFO: epoch 001:   5676 / 102288 loss=0.726, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.5, ups=0.89, wpb=109.7, bsz=40, num_updates=5670, lr=1.38583e-05, gnorm=1.277, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25471
2022-10-19 02:30:23 - progress_bar.py[line:274] - INFO: epoch 001:   5686 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.626, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=94.4, ups=0.87, wpb=108.9, bsz=40, num_updates=5680, lr=1.38828e-05, gnorm=1.306, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25483
2022-10-19 02:30:34 - progress_bar.py[line:274] - INFO: epoch 001:   5696 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=5690, lr=1.39072e-05, gnorm=1.256, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25494
2022-10-19 02:30:46 - progress_bar.py[line:274] - INFO: epoch 001:   5706 / 102288 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=95.7, ups=0.87, wpb=110.3, bsz=40, num_updates=5700, lr=1.39317e-05, gnorm=1.326, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25506
2022-10-19 02:30:57 - progress_bar.py[line:274] - INFO: epoch 001:   5716 / 102288 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=5710, lr=1.39561e-05, gnorm=1.361, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25517
2022-10-19 02:31:08 - progress_bar.py[line:274] - INFO: epoch 001:   5726 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.2, ups=0.89, wpb=112.6, bsz=40, num_updates=5720, lr=1.39805e-05, gnorm=1.325, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25528
2022-10-19 02:31:20 - progress_bar.py[line:274] - INFO: epoch 001:   5736 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=96.8, ups=0.89, wpb=108.9, bsz=40, num_updates=5730, lr=1.4005e-05, gnorm=1.319, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25539
2022-10-19 02:31:30 - progress_bar.py[line:274] - INFO: epoch 001:   5746 / 102288 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=101.5, ups=0.93, wpb=109.7, bsz=40, num_updates=5740, lr=1.40294e-05, gnorm=1.386, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25550
2022-10-19 02:31:42 - progress_bar.py[line:274] - INFO: epoch 001:   5756 / 102288 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=5750, lr=1.40539e-05, gnorm=1.382, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25562
2022-10-19 02:31:53 - progress_bar.py[line:274] - INFO: epoch 001:   5766 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.8, ups=0.87, wpb=111.5, bsz=40, num_updates=5760, lr=1.40783e-05, gnorm=1.591, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25573
2022-10-19 02:32:04 - progress_bar.py[line:274] - INFO: epoch 001:   5776 / 102288 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=101.7, ups=0.91, wpb=111.7, bsz=40, num_updates=5770, lr=1.41028e-05, gnorm=1.472, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=25584
2022-10-19 02:32:16 - progress_bar.py[line:274] - INFO: epoch 001:   5786 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.5, ups=0.88, wpb=109.8, bsz=40, num_updates=5780, lr=1.41272e-05, gnorm=1.319, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25595
2022-10-19 02:32:27 - progress_bar.py[line:274] - INFO: epoch 001:   5796 / 102288 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.9, ups=0.9, wpb=110, bsz=40, num_updates=5790, lr=1.41516e-05, gnorm=1.32, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25607
2022-10-19 02:32:38 - progress_bar.py[line:274] - INFO: epoch 001:   5806 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=98.7, ups=0.9, wpb=109.4, bsz=40, num_updates=5800, lr=1.41761e-05, gnorm=1.44, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25618
2022-10-19 02:32:49 - progress_bar.py[line:274] - INFO: epoch 001:   5816 / 102288 loss=0.747, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=99.9, ups=0.91, wpb=109.2, bsz=40, num_updates=5810, lr=1.42005e-05, gnorm=1.536, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25629
2022-10-19 02:33:00 - progress_bar.py[line:274] - INFO: epoch 001:   5826 / 102288 loss=0.717, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=96.8, ups=0.87, wpb=110.6, bsz=40, num_updates=5820, lr=1.4225e-05, gnorm=1.414, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25640
2022-10-19 02:33:12 - progress_bar.py[line:274] - INFO: epoch 001:   5836 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=96.8, ups=0.88, wpb=110.6, bsz=40, num_updates=5830, lr=1.42494e-05, gnorm=1.275, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25651
2022-10-19 02:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   5846 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=5840, lr=1.42738e-05, gnorm=1.409, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25663
2022-10-19 02:33:34 - progress_bar.py[line:274] - INFO: epoch 001:   5856 / 102288 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=101.1, ups=0.9, wpb=112.1, bsz=40, num_updates=5850, lr=1.42983e-05, gnorm=1.296, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25674
2022-10-19 02:33:45 - progress_bar.py[line:274] - INFO: epoch 001:   5866 / 102288 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=100.1, ups=0.92, wpb=108.9, bsz=40, num_updates=5860, lr=1.43227e-05, gnorm=1.418, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25685
2022-10-19 02:33:56 - progress_bar.py[line:274] - INFO: epoch 001:   5876 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=96.6, ups=0.88, wpb=109.8, bsz=40, num_updates=5870, lr=1.43472e-05, gnorm=1.244, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25696
2022-10-19 02:34:07 - progress_bar.py[line:274] - INFO: epoch 001:   5886 / 102288 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=5880, lr=1.43716e-05, gnorm=1.513, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25707
2022-10-19 02:34:19 - progress_bar.py[line:274] - INFO: epoch 001:   5896 / 102288 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.1, ups=0.88, wpb=110.4, bsz=40, num_updates=5890, lr=1.43961e-05, gnorm=1.426, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25719
2022-10-19 02:34:30 - progress_bar.py[line:274] - INFO: epoch 001:   5906 / 102288 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=102.3, ups=0.93, wpb=110.3, bsz=40, num_updates=5900, lr=1.44205e-05, gnorm=1.467, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25729
2022-10-19 02:34:41 - progress_bar.py[line:274] - INFO: epoch 001:   5916 / 102288 loss=0.725, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=99, ups=0.9, wpb=109.8, bsz=40, num_updates=5910, lr=1.44449e-05, gnorm=1.555, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25740
2022-10-19 02:34:52 - progress_bar.py[line:274] - INFO: epoch 001:   5926 / 102288 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.587, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=95.8, ups=0.87, wpb=110.6, bsz=40, num_updates=5920, lr=1.44694e-05, gnorm=1.438, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25752
2022-10-19 02:35:03 - progress_bar.py[line:274] - INFO: epoch 001:   5936 / 102288 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=5930, lr=1.44938e-05, gnorm=1.328, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25763
2022-10-19 02:35:15 - progress_bar.py[line:274] - INFO: epoch 001:   5946 / 102288 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=5940, lr=1.45183e-05, gnorm=1.289, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25774
2022-10-19 02:35:26 - progress_bar.py[line:274] - INFO: epoch 001:   5956 / 102288 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.619, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=100.1, ups=0.91, wpb=109.9, bsz=40, num_updates=5950, lr=1.45427e-05, gnorm=1.44, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25785
2022-10-19 02:35:37 - progress_bar.py[line:274] - INFO: epoch 001:   5966 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=101.1, ups=0.91, wpb=110.6, bsz=40, num_updates=5960, lr=1.45671e-05, gnorm=1.369, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25796
2022-10-19 02:35:48 - progress_bar.py[line:274] - INFO: epoch 001:   5976 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=5970, lr=1.45916e-05, gnorm=1.426, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25808
2022-10-19 02:35:59 - progress_bar.py[line:274] - INFO: epoch 001:   5986 / 102288 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=5980, lr=1.4616e-05, gnorm=1.403, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25819
2022-10-19 02:36:10 - progress_bar.py[line:274] - INFO: epoch 001:   5996 / 102288 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.611, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.6, ups=0.93, wpb=108.7, bsz=40, num_updates=5990, lr=1.46405e-05, gnorm=1.559, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25830
2022-10-19 02:36:21 - progress_bar.py[line:274] - INFO: epoch 001:   6006 / 102288 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.617, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=97.1, ups=0.89, wpb=109.3, bsz=40, num_updates=6000, lr=1.46649e-05, gnorm=1.513, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25841
2022-10-19 02:36:21 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 02:36:22 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 02:36:22 - train.py[line:551] - INFO: load:1.01 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 02:38:55 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 02:38:55 - train.py[line:551] - INFO: load:1.03 valid_run:152.52 task_valid:148.51 collect_output:2.93
2022-10-19 02:41:24 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 02:41:24 - train.py[line:551] - INFO: load:1.06 valid_run:301.67 task_valid:291.97 collect_output:7.60
2022-10-19 02:43:57 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 02:43:57 - train.py[line:551] - INFO: load:1.08 valid_run:454.75 task_valid:435.13 collect_output:16.40
2022-10-19 02:46:27 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 02:46:27 - train.py[line:551] - INFO: load:1.11 valid_run:604.40 task_valid:580.26 collect_output:19.85
2022-10-19 02:49:00 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 02:49:00 - train.py[line:551] - INFO: load:1.13 valid_run:757.31 task_valid:727.88 collect_output:24.08
2022-10-19 02:51:32 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 02:51:32 - train.py[line:551] - INFO: load:1.16 valid_run:909.71 task_valid:873.83 collect_output:29.46
2022-10-19 02:54:06 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 02:54:06 - train.py[line:551] - INFO: load:1.18 valid_run:1063.38 task_valid:1019.88 collect_output:36.08
2022-10-19 02:56:38 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 02:56:38 - train.py[line:551] - INFO: load:1.21 valid_run:1215.30 task_valid:1161.11 collect_output:45.78
2022-10-19 02:59:08 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 02:59:08 - train.py[line:551] - INFO: load:1.24 valid_run:1365.24 task_valid:1305.92 collect_output:49.93
2022-10-19 03:01:37 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 03:01:37 - train.py[line:551] - INFO: load:1.26 valid_run:1514.34 task_valid:1449.26 collect_output:54.69
2022-10-19 03:04:07 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 03:04:07 - train.py[line:551] - INFO: load:1.29 valid_run:1664.31 task_valid:1594.18 collect_output:58.74
2022-10-19 03:06:38 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 03:06:38 - train.py[line:551] - INFO: load:1.31 valid_run:1814.78 task_valid:1739.34 collect_output:63.07
2022-10-19 03:09:08 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 03:09:08 - train.py[line:551] - INFO: load:1.34 valid_run:1965.15 task_valid:1881.34 collect_output:70.46
2022-10-19 03:11:39 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 03:11:39 - train.py[line:551] - INFO: load:1.36 valid_run:2116.13 task_valid:2027.08 collect_output:74.70
2022-10-19 03:14:10 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 03:14:10 - train.py[line:551] - INFO: load:1.39 valid_run:2266.40 task_valid:2173.75 collect_output:77.31
2022-10-19 03:16:40 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 03:16:40 - train.py[line:551] - INFO: load:1.41 valid_run:2416.82 task_valid:2317.89 collect_output:82.58
2022-10-19 03:19:12 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 03:19:12 - train.py[line:551] - INFO: load:1.44 valid_run:2568.90 task_valid:2463.34 collect_output:88.21
2022-10-19 03:21:43 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 03:21:43 - train.py[line:551] - INFO: load:1.46 valid_run:2719.59 task_valid:2610.20 collect_output:91.03
2022-10-19 03:24:12 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 03:24:12 - train.py[line:551] - INFO: load:1.49 valid_run:2868.57 task_valid:2751.78 collect_output:97.44
2022-10-19 03:26:43 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 03:26:43 - train.py[line:551] - INFO: load:1.51 valid_run:3019.34 task_valid:2896.88 collect_output:102.12
2022-10-19 03:29:16 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 03:29:16 - train.py[line:551] - INFO: load:1.54 valid_run:3171.89 task_valid:3041.38 collect_output:109.17
2022-10-19 03:31:45 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 03:31:45 - train.py[line:551] - INFO: load:1.57 valid_run:3321.41 task_valid:3185.81 collect_output:113.27
2022-10-19 03:34:17 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 03:34:17 - train.py[line:551] - INFO: load:1.59 valid_run:3473.02 task_valid:3332.09 collect_output:117.61
2022-10-19 03:36:49 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 03:36:49 - train.py[line:551] - INFO: load:1.62 valid_run:3624.84 task_valid:3478.73 collect_output:121.74

====================================================================================================
SGG eval:     R @ 50: 0.4637;     R @ 100: 0.5145;     R @ 500: 0.5708;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2725;    mR @ 100: 0.3252;    mR @ 500: 0.3736;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2585) (covered in:0.1875) (covering:0.2857) (eating:0.6471) (flying in:1.0000) (growing on:0.3750) (hanging from:0.3871) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.5625) (playing:0.0000) (riding:0.7801) (says:0.0000) (sitting on:0.6652) (standing on:0.2850) (using:0.3500) (walking in:0.0000) (walking on:0.5946) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4637;     R @ 100: 0.5145;     R @ 500: 0.5708;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2725;    mR @ 100: 0.3252;    mR @ 500: 0.3736;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2585) (covered in:0.1875) (covering:0.2857) (eating:0.6471) (flying in:1.0000) (growing on:0.3750) (hanging from:0.3871) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.5625) (playing:0.0000) (riding:0.7801) (says:0.0000) (sitting on:0.6652) (standing on:0.2850) (using:0.3500) (walking in:0.0000) (walking on:0.5946) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================

2022-10-19 03:39:20 - train.py[line:487] - INFO: 0.5145380952380951
2022-10-19 03:39:20 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 03:39:20 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.375 | loss_v1 0 | loss_v2 0 | nll_loss 0.238 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.514538 | ppl 1.18 | vqa_score 0.3378 | wps 118.7 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.514538
2022-10-19 03:39:20 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-10-19 03:39:20 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-19 03:39:26 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-19 03:39:32 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.5145380952380951) (writing took 11.506912786979228 seconds)
2022-10-19 03:39:45 - progress_bar.py[line:274] - INFO: epoch 001:   6016 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=0.3, ups=0, wpb=108.8, bsz=40, num_updates=6010, lr=1.46893e-05, gnorm=1.413, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29643
2022-10-19 03:39:56 - progress_bar.py[line:274] - INFO: epoch 001:   6026 / 102288 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=6020, lr=1.47138e-05, gnorm=1.533, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29656
2022-10-19 03:40:07 - progress_bar.py[line:274] - INFO: epoch 001:   6036 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=6030, lr=1.47382e-05, gnorm=1.451, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29667
2022-10-19 03:40:18 - progress_bar.py[line:274] - INFO: epoch 001:   6046 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.7, ups=0.9, wpb=109.6, bsz=40, num_updates=6040, lr=1.47627e-05, gnorm=1.396, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29678
2022-10-19 03:40:30 - progress_bar.py[line:274] - INFO: epoch 001:   6056 / 102288 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=95.9, ups=0.88, wpb=109.1, bsz=40, num_updates=6050, lr=1.47871e-05, gnorm=1.513, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29689
2022-10-19 03:40:41 - progress_bar.py[line:274] - INFO: epoch 001:   6066 / 102288 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=95.8, ups=0.88, wpb=109.2, bsz=40, num_updates=6060, lr=1.48116e-05, gnorm=1.381, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29701
2022-10-19 03:40:52 - progress_bar.py[line:274] - INFO: epoch 001:   6076 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=103.8, ups=0.92, wpb=112.2, bsz=40, num_updates=6070, lr=1.4836e-05, gnorm=1.449, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29712
2022-10-19 03:40:56 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 03:41:04 - progress_bar.py[line:274] - INFO: epoch 001:   6087 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=94.1, ups=0.85, wpb=110.6, bsz=40, num_updates=6080, lr=1.48604e-05, gnorm=1.35, clip=100, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=29723
2022-10-19 03:41:14 - progress_bar.py[line:274] - INFO: epoch 001:   6097 / 102288 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=103.3, ups=0.94, wpb=110, bsz=40, num_updates=6090, lr=1.48849e-05, gnorm=1.449, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29734
2022-10-19 03:41:25 - progress_bar.py[line:274] - INFO: epoch 001:   6107 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=6100, lr=1.49093e-05, gnorm=1.35, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29745
2022-10-19 03:41:37 - progress_bar.py[line:274] - INFO: epoch 001:   6117 / 102288 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.5, ups=0.9, wpb=110.7, bsz=40, num_updates=6110, lr=1.49338e-05, gnorm=1.335, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=29756
2022-10-19 03:41:48 - progress_bar.py[line:274] - INFO: epoch 001:   6127 / 102288 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=6120, lr=1.49582e-05, gnorm=1.38, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29768
2022-10-19 03:41:59 - progress_bar.py[line:274] - INFO: epoch 001:   6137 / 102288 loss=0.715, loss_v1=0, loss_v2=0, nll_loss=0.62, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=97.3, ups=0.89, wpb=109.4, bsz=40, num_updates=6130, lr=1.49826e-05, gnorm=1.385, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29779
2022-10-19 03:42:10 - progress_bar.py[line:274] - INFO: epoch 001:   6147 / 102288 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=6140, lr=1.50071e-05, gnorm=1.235, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29790
2022-10-19 03:42:22 - progress_bar.py[line:274] - INFO: epoch 001:   6157 / 102288 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=95.3, ups=0.88, wpb=108.4, bsz=40, num_updates=6150, lr=1.50315e-05, gnorm=1.321, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29801
2022-10-19 03:42:33 - progress_bar.py[line:274] - INFO: epoch 001:   6167 / 102288 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=6160, lr=1.5056e-05, gnorm=1.392, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29813
2022-10-19 03:42:44 - progress_bar.py[line:274] - INFO: epoch 001:   6177 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=6170, lr=1.50804e-05, gnorm=1.316, clip=90, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=29824
2022-10-19 03:42:55 - progress_bar.py[line:274] - INFO: epoch 001:   6187 / 102288 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=99.2, ups=0.9, wpb=110.1, bsz=40, num_updates=6180, lr=1.51049e-05, gnorm=1.323, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=29835
2022-10-19 03:43:06 - progress_bar.py[line:274] - INFO: epoch 001:   6197 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=6190, lr=1.51293e-05, gnorm=1.254, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29846
2022-10-19 03:43:18 - progress_bar.py[line:274] - INFO: epoch 001:   6207 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.5, ups=0.88, wpb=109.7, bsz=40, num_updates=6200, lr=1.51537e-05, gnorm=1.367, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29858
2022-10-19 03:43:28 - progress_bar.py[line:274] - INFO: epoch 001:   6217 / 102288 loss=0.718, loss_v1=0, loss_v2=0, nll_loss=0.623, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=101.5, ups=0.94, wpb=108.1, bsz=40, num_updates=6210, lr=1.51782e-05, gnorm=1.417, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29868
2022-10-19 03:43:39 - progress_bar.py[line:274] - INFO: epoch 001:   6227 / 102288 loss=0.721, loss_v1=0, loss_v2=0, nll_loss=0.627, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=100.1, ups=0.91, wpb=109.5, bsz=40, num_updates=6220, lr=1.52026e-05, gnorm=1.451, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29879
2022-10-19 03:43:51 - progress_bar.py[line:274] - INFO: epoch 001:   6237 / 102288 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=97.6, ups=0.89, wpb=110, bsz=40, num_updates=6230, lr=1.52271e-05, gnorm=1.421, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29890
2022-10-19 03:44:02 - progress_bar.py[line:274] - INFO: epoch 001:   6247 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=6240, lr=1.52515e-05, gnorm=1.434, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=29902
2022-10-19 03:44:13 - progress_bar.py[line:274] - INFO: epoch 001:   6257 / 102288 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.2, ups=0.88, wpb=110.7, bsz=40, num_updates=6250, lr=1.52759e-05, gnorm=1.379, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29913
2022-10-19 03:44:24 - progress_bar.py[line:274] - INFO: epoch 001:   6267 / 102288 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=102.9, ups=0.93, wpb=110.9, bsz=40, num_updates=6260, lr=1.53004e-05, gnorm=1.332, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29924
2022-10-19 03:44:35 - progress_bar.py[line:274] - INFO: epoch 001:   6277 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=6270, lr=1.53248e-05, gnorm=1.355, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29935
2022-10-19 03:44:46 - progress_bar.py[line:274] - INFO: epoch 001:   6287 / 102288 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=101, ups=0.91, wpb=110.4, bsz=40, num_updates=6280, lr=1.53493e-05, gnorm=1.361, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29946
2022-10-19 03:44:58 - progress_bar.py[line:274] - INFO: epoch 001:   6297 / 102288 loss=0.722, loss_v1=0, loss_v2=0, nll_loss=0.632, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=97.3, ups=0.89, wpb=109.1, bsz=40, num_updates=6290, lr=1.53737e-05, gnorm=1.431, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29957
2022-10-19 03:45:09 - progress_bar.py[line:274] - INFO: epoch 001:   6307 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=94.6, ups=0.87, wpb=109.2, bsz=40, num_updates=6300, lr=1.53982e-05, gnorm=1.348, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=29969
2022-10-19 03:45:20 - progress_bar.py[line:274] - INFO: epoch 001:   6317 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.3, ups=0.89, wpb=111.5, bsz=40, num_updates=6310, lr=1.54226e-05, gnorm=1.479, clip=90, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=29980
2022-10-19 03:45:32 - progress_bar.py[line:274] - INFO: epoch 001:   6327 / 102288 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=96.5, ups=0.89, wpb=108.4, bsz=40, num_updates=6320, lr=1.5447e-05, gnorm=1.242, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=29991
2022-10-19 03:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   6337 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98, ups=0.88, wpb=111.4, bsz=40, num_updates=6330, lr=1.54715e-05, gnorm=1.172, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30003
2022-10-19 03:45:54 - progress_bar.py[line:274] - INFO: epoch 001:   6347 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=6340, lr=1.54959e-05, gnorm=1.452, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30014
2022-10-19 03:46:05 - progress_bar.py[line:274] - INFO: epoch 001:   6357 / 102288 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=6350, lr=1.55204e-05, gnorm=1.519, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30025
2022-10-19 03:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   6367 / 102288 loss=0.689, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=6360, lr=1.55448e-05, gnorm=1.515, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30036
2022-10-19 03:46:28 - progress_bar.py[line:274] - INFO: epoch 001:   6377 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.9, ups=0.88, wpb=110.4, bsz=40, num_updates=6370, lr=1.55692e-05, gnorm=1.255, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30048
2022-10-19 03:46:39 - progress_bar.py[line:274] - INFO: epoch 001:   6387 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.584, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=6380, lr=1.55937e-05, gnorm=1.264, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30059
2022-10-19 03:46:50 - progress_bar.py[line:274] - INFO: epoch 001:   6397 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=6390, lr=1.56181e-05, gnorm=1.245, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30070
2022-10-19 03:47:01 - progress_bar.py[line:274] - INFO: epoch 001:   6407 / 102288 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=6400, lr=1.56426e-05, gnorm=1.281, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30081
2022-10-19 03:47:13 - progress_bar.py[line:274] - INFO: epoch 001:   6417 / 102288 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=6410, lr=1.5667e-05, gnorm=1.446, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30092
2022-10-19 03:47:24 - progress_bar.py[line:274] - INFO: epoch 001:   6427 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.3, ups=0.89, wpb=110.7, bsz=40, num_updates=6420, lr=1.56915e-05, gnorm=1.431, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30104
2022-10-19 03:47:35 - progress_bar.py[line:274] - INFO: epoch 001:   6437 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.9, ups=0.88, wpb=111.3, bsz=40, num_updates=6430, lr=1.57159e-05, gnorm=1.517, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30115
2022-10-19 03:47:46 - progress_bar.py[line:274] - INFO: epoch 001:   6447 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.6, ups=0.91, wpb=109.4, bsz=40, num_updates=6440, lr=1.57403e-05, gnorm=1.421, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30126
2022-10-19 03:47:57 - progress_bar.py[line:274] - INFO: epoch 001:   6457 / 102288 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.7, ups=0.9, wpb=108.4, bsz=40, num_updates=6450, lr=1.57648e-05, gnorm=1.337, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30137
2022-10-19 03:48:08 - progress_bar.py[line:274] - INFO: epoch 001:   6467 / 102288 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=102.6, ups=0.92, wpb=111, bsz=40, num_updates=6460, lr=1.57892e-05, gnorm=1.287, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30148
2022-10-19 03:48:19 - progress_bar.py[line:274] - INFO: epoch 001:   6477 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.5, ups=0.9, wpb=110.7, bsz=40, num_updates=6470, lr=1.58137e-05, gnorm=1.364, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30159
2022-10-19 03:48:31 - progress_bar.py[line:274] - INFO: epoch 001:   6487 / 102288 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=6480, lr=1.58381e-05, gnorm=1.325, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30171
2022-10-19 03:48:41 - progress_bar.py[line:274] - INFO: epoch 001:   6497 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=103.7, ups=0.94, wpb=110.7, bsz=40, num_updates=6490, lr=1.58625e-05, gnorm=1.35, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30181
2022-10-19 03:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   6507 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=6500, lr=1.5887e-05, gnorm=1.22, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30192
2022-10-19 03:49:04 - progress_bar.py[line:274] - INFO: epoch 001:   6517 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.4, ups=0.9, wpb=110.4, bsz=40, num_updates=6510, lr=1.59114e-05, gnorm=1.355, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30204
2022-10-19 03:49:15 - progress_bar.py[line:274] - INFO: epoch 001:   6527 / 102288 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=97.6, ups=0.89, wpb=109.7, bsz=40, num_updates=6520, lr=1.59359e-05, gnorm=1.402, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30215
2022-10-19 03:49:26 - progress_bar.py[line:274] - INFO: epoch 001:   6537 / 102288 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=100.8, ups=0.91, wpb=110.2, bsz=40, num_updates=6530, lr=1.59603e-05, gnorm=1.435, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30226
2022-10-19 03:49:37 - progress_bar.py[line:274] - INFO: epoch 001:   6547 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=6540, lr=1.59847e-05, gnorm=1.335, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30237
2022-10-19 03:49:48 - progress_bar.py[line:274] - INFO: epoch 001:   6557 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.7, ups=0.9, wpb=111.5, bsz=40, num_updates=6550, lr=1.60092e-05, gnorm=1.263, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30248
2022-10-19 03:49:59 - progress_bar.py[line:274] - INFO: epoch 001:   6567 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=100.2, ups=0.9, wpb=111.3, bsz=40, num_updates=6560, lr=1.60336e-05, gnorm=1.346, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30259
2022-10-19 03:50:11 - progress_bar.py[line:274] - INFO: epoch 001:   6577 / 102288 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=97.4, ups=0.88, wpb=111, bsz=40, num_updates=6570, lr=1.60581e-05, gnorm=1.311, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30270
2022-10-19 03:50:22 - progress_bar.py[line:274] - INFO: epoch 001:   6587 / 102288 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.8, ups=0.9, wpb=110.8, bsz=40, num_updates=6580, lr=1.60825e-05, gnorm=1.229, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30282
2022-10-19 03:50:32 - progress_bar.py[line:274] - INFO: epoch 001:   6597 / 102288 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=106.4, ups=0.96, wpb=110.4, bsz=40, num_updates=6590, lr=1.6107e-05, gnorm=1.397, clip=100, loss_scale=1024, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=30292
2022-10-19 03:50:44 - progress_bar.py[line:274] - INFO: epoch 001:   6607 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.2, ups=0.87, wpb=110.7, bsz=40, num_updates=6600, lr=1.61314e-05, gnorm=1.466, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30303
2022-10-19 03:50:55 - progress_bar.py[line:274] - INFO: epoch 001:   6617 / 102288 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=6610, lr=1.61558e-05, gnorm=1.387, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30315
2022-10-19 03:51:06 - progress_bar.py[line:274] - INFO: epoch 001:   6627 / 102288 loss=0.683, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=6620, lr=1.61803e-05, gnorm=1.421, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30326
2022-10-19 03:51:17 - progress_bar.py[line:274] - INFO: epoch 001:   6637 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.9, ups=0.89, wpb=110.8, bsz=40, num_updates=6630, lr=1.62047e-05, gnorm=1.299, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30337
2022-10-19 03:51:28 - progress_bar.py[line:274] - INFO: epoch 001:   6647 / 102288 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.7, ups=0.9, wpb=109.3, bsz=40, num_updates=6640, lr=1.62292e-05, gnorm=1.232, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30348
2022-10-19 03:51:39 - progress_bar.py[line:274] - INFO: epoch 001:   6657 / 102288 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=6650, lr=1.62536e-05, gnorm=1.237, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30359
2022-10-19 03:51:50 - progress_bar.py[line:274] - INFO: epoch 001:   6667 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=6660, lr=1.6278e-05, gnorm=1.419, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30370
2022-10-19 03:52:02 - progress_bar.py[line:274] - INFO: epoch 001:   6677 / 102288 loss=0.696, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=95.6, ups=0.89, wpb=107.3, bsz=40, num_updates=6670, lr=1.63025e-05, gnorm=1.397, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30381
2022-10-19 03:52:13 - progress_bar.py[line:274] - INFO: epoch 001:   6687 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.3, ups=0.91, wpb=111, bsz=40, num_updates=6680, lr=1.63269e-05, gnorm=1.337, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30392
2022-10-19 03:52:24 - progress_bar.py[line:274] - INFO: epoch 001:   6697 / 102288 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.1, ups=0.9, wpb=110.3, bsz=40, num_updates=6690, lr=1.63514e-05, gnorm=1.459, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30404
2022-10-19 03:52:35 - progress_bar.py[line:274] - INFO: epoch 001:   6707 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=94.9, ups=0.87, wpb=109.4, bsz=40, num_updates=6700, lr=1.63758e-05, gnorm=1.284, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30415
2022-10-19 03:52:46 - progress_bar.py[line:274] - INFO: epoch 001:   6717 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=6710, lr=1.64003e-05, gnorm=1.486, clip=100, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30426
2022-10-19 03:52:58 - progress_bar.py[line:274] - INFO: epoch 001:   6727 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=6720, lr=1.64247e-05, gnorm=1.285, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30437
2022-10-19 03:53:09 - progress_bar.py[line:274] - INFO: epoch 001:   6737 / 102288 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=6730, lr=1.64491e-05, gnorm=1.344, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30449
2022-10-19 03:53:20 - progress_bar.py[line:274] - INFO: epoch 001:   6747 / 102288 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.1, ups=0.88, wpb=110.8, bsz=40, num_updates=6740, lr=1.64736e-05, gnorm=1.331, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30460
2022-10-19 03:53:32 - progress_bar.py[line:274] - INFO: epoch 001:   6757 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.9, ups=0.89, wpb=110.2, bsz=40, num_updates=6750, lr=1.6498e-05, gnorm=1.357, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30471
2022-10-19 03:53:43 - progress_bar.py[line:274] - INFO: epoch 001:   6767 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=6760, lr=1.65225e-05, gnorm=1.277, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30483
2022-10-19 03:53:54 - progress_bar.py[line:274] - INFO: epoch 001:   6777 / 102288 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=6770, lr=1.65469e-05, gnorm=1.284, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30494
2022-10-19 03:54:04 - progress_bar.py[line:274] - INFO: epoch 001:   6787 / 102288 loss=0.7, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=102.5, ups=0.94, wpb=109.1, bsz=40, num_updates=6780, lr=1.65713e-05, gnorm=1.378, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30504
2022-10-19 03:54:16 - progress_bar.py[line:274] - INFO: epoch 001:   6797 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=6790, lr=1.65958e-05, gnorm=1.368, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30515
2022-10-19 03:54:27 - progress_bar.py[line:274] - INFO: epoch 001:   6807 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.1, ups=0.87, wpb=110.8, bsz=40, num_updates=6800, lr=1.66202e-05, gnorm=1.23, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30527
2022-10-19 03:54:38 - progress_bar.py[line:274] - INFO: epoch 001:   6817 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=6810, lr=1.66447e-05, gnorm=1.31, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30538
2022-10-19 03:54:50 - progress_bar.py[line:274] - INFO: epoch 001:   6827 / 102288 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=6820, lr=1.66691e-05, gnorm=1.345, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30549
2022-10-19 03:55:01 - progress_bar.py[line:274] - INFO: epoch 001:   6837 / 102288 loss=0.699, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=95.9, ups=0.89, wpb=108.2, bsz=40, num_updates=6830, lr=1.66936e-05, gnorm=1.403, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30561
2022-10-19 03:55:12 - progress_bar.py[line:274] - INFO: epoch 001:   6847 / 102288 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.4, ups=0.9, wpb=110.3, bsz=40, num_updates=6840, lr=1.6718e-05, gnorm=1.184, clip=90, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30572
2022-10-19 03:55:23 - progress_bar.py[line:274] - INFO: epoch 001:   6857 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=6850, lr=1.67424e-05, gnorm=1.385, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30583
2022-10-19 03:55:34 - progress_bar.py[line:274] - INFO: epoch 001:   6867 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.1, ups=0.89, wpb=111.3, bsz=40, num_updates=6860, lr=1.67669e-05, gnorm=1.227, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30594
2022-10-19 03:55:46 - progress_bar.py[line:274] - INFO: epoch 001:   6877 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.4, ups=0.9, wpb=109, bsz=40, num_updates=6870, lr=1.67913e-05, gnorm=1.419, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30605
2022-10-19 03:55:56 - progress_bar.py[line:274] - INFO: epoch 001:   6887 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102, ups=0.91, wpb=111.6, bsz=40, num_updates=6880, lr=1.68158e-05, gnorm=1.291, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30616
2022-10-19 03:56:08 - progress_bar.py[line:274] - INFO: epoch 001:   6897 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.6, ups=0.9, wpb=111.7, bsz=40, num_updates=6890, lr=1.68402e-05, gnorm=1.51, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30627
2022-10-19 03:56:19 - progress_bar.py[line:274] - INFO: epoch 001:   6907 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96, ups=0.86, wpb=111, bsz=40, num_updates=6900, lr=1.68646e-05, gnorm=1.252, clip=100, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=30639
2022-10-19 03:56:30 - progress_bar.py[line:274] - INFO: epoch 001:   6917 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=104.6, ups=0.95, wpb=110.3, bsz=40, num_updates=6910, lr=1.68891e-05, gnorm=1.362, clip=100, loss_scale=1024, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=30649
2022-10-19 03:56:41 - progress_bar.py[line:274] - INFO: epoch 001:   6927 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=6920, lr=1.69135e-05, gnorm=1.432, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30661
2022-10-19 03:56:52 - progress_bar.py[line:274] - INFO: epoch 001:   6937 / 102288 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=6930, lr=1.6938e-05, gnorm=1.426, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30672
2022-10-19 03:57:03 - progress_bar.py[line:274] - INFO: epoch 001:   6947 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.6, ups=0.89, wpb=109.6, bsz=40, num_updates=6940, lr=1.69624e-05, gnorm=1.275, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30683
2022-10-19 03:57:14 - progress_bar.py[line:274] - INFO: epoch 001:   6957 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=102.9, ups=0.92, wpb=112, bsz=40, num_updates=6950, lr=1.69869e-05, gnorm=1.312, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30694
2022-10-19 03:57:25 - progress_bar.py[line:274] - INFO: epoch 001:   6967 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=6960, lr=1.70113e-05, gnorm=1.344, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30705
2022-10-19 03:57:37 - progress_bar.py[line:274] - INFO: epoch 001:   6977 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101.3, ups=0.9, wpb=112.3, bsz=40, num_updates=6970, lr=1.70357e-05, gnorm=1.305, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30716
2022-10-19 03:57:48 - progress_bar.py[line:274] - INFO: epoch 001:   6987 / 102288 loss=0.691, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=95.6, ups=0.88, wpb=108.9, bsz=40, num_updates=6980, lr=1.70602e-05, gnorm=1.411, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30728
2022-10-19 03:57:59 - progress_bar.py[line:274] - INFO: epoch 001:   6997 / 102288 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.6, ups=0.89, wpb=109.7, bsz=40, num_updates=6990, lr=1.70846e-05, gnorm=1.211, clip=80, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30739
2022-10-19 03:58:10 - progress_bar.py[line:274] - INFO: epoch 001:   7007 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.5, ups=0.9, wpb=110.5, bsz=40, num_updates=7000, lr=1.71091e-05, gnorm=1.182, clip=80, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30750
2022-10-19 03:58:10 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 03:58:12 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 03:58:12 - train.py[line:551] - INFO: load:1.22 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 03:58:13 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.86 GiB already allocated; 3.63 GiB free; 33.46 GiB reserved in total by PyTorch)
2022-10-19 03:58:13 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-19 03:58:13 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 14        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9075 MB |   10300 MB |    4430 TB |    4430 TB |
|       from large pool |    8930 MB |   10154 MB |    4429 TB |    4429 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9075 MB |   10300 MB |    4430 TB |    4430 TB |
|       from large pool |    8930 MB |   10154 MB |    4429 TB |    4429 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34266 MB |   37576 MB |  147576 MB |  113310 MB |
|       from large pool |   34120 MB |   37424 MB |  147356 MB |  113236 MB |
|       from small pool |     146 MB |     152 MB |     220 MB |      74 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25190 MB |   25190 MB |    4146 TB |    4146 TB |
|       from large pool |   25189 MB |   25189 MB |    4145 TB |    4145 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  204370 K  |  204367 K  |
|       from large pool |     563    |     575    |   66090 K  |   66089 K  |
|       from small pool |    3095    |    3114    |  138280 K  |  138277 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  204370 K  |  204367 K  |
|       from large pool |     563    |     575    |   66090 K  |   66089 K  |
|       from small pool |    3095    |    3114    |  138280 K  |  138277 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     190    |     199    |     406    |     216    |
|       from large pool |     117    |     123    |     296    |     179    |
|       from small pool |      73    |      76    |     110    |      37    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     137    |     142    |  144230 K  |  144230 K  |
|       from large pool |      94    |      97    |   24612 K  |   24612 K  |
|       from small pool |      43    |      50    |  119617 K  |  119617 K  |
|===========================================================================|

2022-10-19 03:58:13 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-19 04:00:45 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 04:00:45 - train.py[line:551] - INFO: load:1.24 valid_run:153.35 task_valid:148.37 collect_output:3.88
2022-10-19 04:03:14 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 04:03:14 - train.py[line:551] - INFO: load:1.26 valid_run:302.43 task_valid:291.60 collect_output:8.68
2022-10-19 04:05:47 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 04:05:47 - train.py[line:551] - INFO: load:1.29 valid_run:455.14 task_valid:434.66 collect_output:17.31
2022-10-19 04:08:16 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 04:08:16 - train.py[line:551] - INFO: load:1.31 valid_run:604.32 task_valid:579.66 collect_output:20.50
2022-10-19 04:10:49 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 04:10:49 - train.py[line:551] - INFO: load:1.34 valid_run:756.76 task_valid:727.07 collect_output:24.56
2022-10-19 04:13:21 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 04:13:21 - train.py[line:551] - INFO: load:1.36 valid_run:908.86 task_valid:872.66 collect_output:30.10
2022-10-19 04:15:55 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 04:15:55 - train.py[line:551] - INFO: load:1.39 valid_run:1062.52 task_valid:1018.57 collect_output:36.83
2022-10-19 04:18:26 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 04:18:26 - train.py[line:551] - INFO: load:1.41 valid_run:1214.18 task_valid:1159.71 collect_output:46.32
2022-10-19 04:20:56 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 04:20:56 - train.py[line:551] - INFO: load:1.44 valid_run:1363.88 task_valid:1304.46 collect_output:50.29
2022-10-19 04:23:25 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 04:23:25 - train.py[line:551] - INFO: load:1.46 valid_run:1512.80 task_valid:1447.78 collect_output:54.89
2022-10-19 04:25:55 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 04:25:55 - train.py[line:551] - INFO: load:1.48 valid_run:1662.85 task_valid:1592.57 collect_output:59.17
2022-10-19 04:28:25 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 04:28:25 - train.py[line:551] - INFO: load:1.51 valid_run:1812.96 task_valid:1737.50 collect_output:63.36
2022-10-19 04:30:56 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 04:30:56 - train.py[line:551] - INFO: load:1.53 valid_run:1963.19 task_valid:1879.23 collect_output:70.85
2022-10-19 04:33:27 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 04:33:27 - train.py[line:551] - INFO: load:1.56 valid_run:2114.06 task_valid:2024.91 collect_output:75.04
2022-10-19 04:35:57 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 04:35:57 - train.py[line:551] - INFO: load:1.58 valid_run:2264.42 task_valid:2171.49 collect_output:77.84
2022-10-19 04:38:27 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 04:38:27 - train.py[line:551] - INFO: load:1.61 valid_run:2414.55 task_valid:2315.60 collect_output:82.87
2022-10-19 04:40:59 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 04:40:59 - train.py[line:551] - INFO: load:1.63 valid_run:2566.53 task_valid:2461.03 collect_output:88.44
2022-10-19 04:43:30 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 04:43:30 - train.py[line:551] - INFO: load:1.66 valid_run:2717.37 task_valid:2608.07 collect_output:91.23
2022-10-19 04:45:59 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 04:45:59 - train.py[line:551] - INFO: load:1.68 valid_run:2866.28 task_valid:2749.63 collect_output:97.59
2022-10-19 04:48:30 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 04:48:30 - train.py[line:551] - INFO: load:1.71 valid_run:3016.94 task_valid:2894.73 collect_output:102.16
2022-10-19 04:51:03 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 04:51:03 - train.py[line:551] - INFO: load:1.73 valid_run:3169.73 task_valid:3039.62 collect_output:109.05
2022-10-19 04:53:33 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 04:53:33 - train.py[line:551] - INFO: load:1.76 valid_run:3319.61 task_valid:3184.27 collect_output:113.12
2022-10-19 04:56:05 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 04:56:05 - train.py[line:551] - INFO: load:1.78 valid_run:3471.71 task_valid:3330.89 collect_output:117.55
2022-10-19 04:58:37 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 04:58:37 - train.py[line:551] - INFO: load:1.81 valid_run:3623.50 task_valid:3477.58 collect_output:121.56

====================================================================================================
SGG eval:     R @ 50: 0.5191;     R @ 100: 0.5664;     R @ 500: 0.6056;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3209;    mR @ 100: 0.3872;    mR @ 500: 0.4199;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4171) (covered in:0.5000) (covering:0.3571) (eating:0.7647) (flying in:1.0000) (growing on:0.5000) (hanging from:0.3226) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7083) (playing:0.0000) (riding:0.8497) (says:0.0000) (sitting on:0.7307) (standing on:0.2000) (using:0.3500) (walking in:0.0000) (walking on:0.7432) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5191;     R @ 100: 0.5664;     R @ 500: 0.6056;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3209;    mR @ 100: 0.3872;    mR @ 500: 0.4199;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4171) (covered in:0.5000) (covering:0.3571) (eating:0.7647) (flying in:1.0000) (growing on:0.5000) (hanging from:0.3226) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7083) (playing:0.0000) (riding:0.8497) (says:0.0000) (sitting on:0.7307) (standing on:0.2000) (using:0.3500) (walking in:0.0000) (walking on:0.7432) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================

2022-10-19 05:01:08 - train.py[line:487] - INFO: 0.566404761904762
2022-10-19 05:01:08 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 05:01:08 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.349 | loss_v1 0 | loss_v2 0 | nll_loss 0.199 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.566405 | ppl 1.15 | vqa_score 0.3896 | wps 118.8 | wpb 89.9 | bsz 30 | num_updates 7000 | best_R@100 0.566405
2022-10-19 05:01:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 7000 updates
2022-10-19 05:01:08 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-19 05:01:14 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-19 05:01:19 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 0.566404761904762) (writing took 11.267454606015235 seconds)
2022-10-19 05:01:35 - progress_bar.py[line:274] - INFO: epoch 001:   7017 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=0.3, ups=0, wpb=110, bsz=40, num_updates=7010, lr=1.71335e-05, gnorm=1.34, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34550
2022-10-19 05:01:46 - progress_bar.py[line:274] - INFO: epoch 001:   7027 / 102288 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.6, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=95.6, ups=0.87, wpb=109.5, bsz=40, num_updates=7020, lr=1.71579e-05, gnorm=1.277, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34566
2022-10-19 05:01:57 - progress_bar.py[line:274] - INFO: epoch 001:   7037 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.9, ups=0.9, wpb=110.8, bsz=40, num_updates=7030, lr=1.71824e-05, gnorm=1.31, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34577
2022-10-19 05:02:09 - progress_bar.py[line:274] - INFO: epoch 001:   7047 / 102288 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.4, ups=0.89, wpb=110.8, bsz=40, num_updates=7040, lr=1.72068e-05, gnorm=1.401, clip=100, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=34588
2022-10-19 05:02:20 - progress_bar.py[line:274] - INFO: epoch 001:   7057 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.8, ups=0.89, wpb=111.1, bsz=40, num_updates=7050, lr=1.72313e-05, gnorm=1.407, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34600
2022-10-19 05:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   7067 / 102288 loss=0.698, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.3, ups=0.9, wpb=109.2, bsz=40, num_updates=7060, lr=1.72557e-05, gnorm=1.449, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34611
2022-10-19 05:02:42 - progress_bar.py[line:274] - INFO: epoch 001:   7077 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.594, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=95, ups=0.87, wpb=109.2, bsz=40, num_updates=7070, lr=1.72801e-05, gnorm=1.206, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34622
2022-10-19 05:02:46 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 05:02:55 - progress_bar.py[line:274] - INFO: epoch 001:   7088 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=90.4, ups=0.81, wpb=111, bsz=40, num_updates=7080, lr=1.73046e-05, gnorm=1.214, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=34635
2022-10-19 05:03:06 - progress_bar.py[line:274] - INFO: epoch 001:   7098 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=7090, lr=1.7329e-05, gnorm=1.335, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34646
2022-10-19 05:03:18 - progress_bar.py[line:274] - INFO: epoch 001:   7108 / 102288 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=96.7, ups=0.88, wpb=110.3, bsz=40, num_updates=7100, lr=1.73535e-05, gnorm=1.344, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34657
2022-10-19 05:03:28 - progress_bar.py[line:274] - INFO: epoch 001:   7118 / 102288 loss=0.708, loss_v1=0, loss_v2=0, nll_loss=0.612, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=102.3, ups=0.94, wpb=109.3, bsz=40, num_updates=7110, lr=1.73779e-05, gnorm=1.32, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34668
2022-10-19 05:03:39 - progress_bar.py[line:274] - INFO: epoch 001:   7128 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101, ups=0.91, wpb=110.8, bsz=40, num_updates=7120, lr=1.74024e-05, gnorm=1.367, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34679
2022-10-19 05:03:51 - progress_bar.py[line:274] - INFO: epoch 001:   7138 / 102288 loss=0.692, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.6, ups=0.89, wpb=109.9, bsz=40, num_updates=7130, lr=1.74268e-05, gnorm=1.288, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34690
2022-10-19 05:04:02 - progress_bar.py[line:274] - INFO: epoch 001:   7148 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=100.8, ups=0.9, wpb=111.6, bsz=40, num_updates=7140, lr=1.74512e-05, gnorm=1.294, clip=90, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=34701
2022-10-19 05:04:13 - progress_bar.py[line:274] - INFO: epoch 001:   7158 / 102288 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100.6, ups=0.91, wpb=110.4, bsz=40, num_updates=7150, lr=1.74757e-05, gnorm=1.288, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34712
2022-10-19 05:04:24 - progress_bar.py[line:274] - INFO: epoch 001:   7168 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.8, ups=0.91, wpb=112.4, bsz=40, num_updates=7160, lr=1.75001e-05, gnorm=1.217, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34723
2022-10-19 05:04:35 - progress_bar.py[line:274] - INFO: epoch 001:   7178 / 102288 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=96.3, ups=0.88, wpb=109.2, bsz=40, num_updates=7170, lr=1.75246e-05, gnorm=1.415, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34735
2022-10-19 05:04:46 - progress_bar.py[line:274] - INFO: epoch 001:   7188 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=101.8, ups=0.92, wpb=111, bsz=40, num_updates=7180, lr=1.7549e-05, gnorm=1.476, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34746
2022-10-19 05:04:58 - progress_bar.py[line:274] - INFO: epoch 001:   7198 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.8, ups=0.87, wpb=110, bsz=40, num_updates=7190, lr=1.75734e-05, gnorm=1.136, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34757
2022-10-19 05:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   7208 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=7200, lr=1.75979e-05, gnorm=1.444, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34769
2022-10-19 05:05:20 - progress_bar.py[line:274] - INFO: epoch 001:   7218 / 102288 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=95.7, ups=0.88, wpb=109.2, bsz=40, num_updates=7210, lr=1.76223e-05, gnorm=1.357, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34780
2022-10-19 05:05:31 - progress_bar.py[line:274] - INFO: epoch 001:   7228 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.7, ups=0.92, wpb=110, bsz=40, num_updates=7220, lr=1.76468e-05, gnorm=1.294, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34791
2022-10-19 05:05:42 - progress_bar.py[line:274] - INFO: epoch 001:   7238 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=7230, lr=1.76712e-05, gnorm=1.247, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34802
2022-10-19 05:05:54 - progress_bar.py[line:274] - INFO: epoch 001:   7248 / 102288 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=7240, lr=1.76957e-05, gnorm=1.267, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34814
2022-10-19 05:06:05 - progress_bar.py[line:274] - INFO: epoch 001:   7258 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.3, ups=0.9, wpb=110.2, bsz=40, num_updates=7250, lr=1.77201e-05, gnorm=1.212, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34825
2022-10-19 05:06:16 - progress_bar.py[line:274] - INFO: epoch 001:   7268 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=102.4, ups=0.91, wpb=112, bsz=40, num_updates=7260, lr=1.77445e-05, gnorm=1.28, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34836
2022-10-19 05:06:27 - progress_bar.py[line:274] - INFO: epoch 001:   7278 / 102288 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.9, ups=0.9, wpb=110.4, bsz=40, num_updates=7270, lr=1.7769e-05, gnorm=1.35, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34847
2022-10-19 05:06:38 - progress_bar.py[line:274] - INFO: epoch 001:   7288 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=7280, lr=1.77934e-05, gnorm=1.426, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34858
2022-10-19 05:06:50 - progress_bar.py[line:274] - INFO: epoch 001:   7298 / 102288 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.5, ups=0.89, wpb=109.2, bsz=40, num_updates=7290, lr=1.78179e-05, gnorm=1.425, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34869
2022-10-19 05:07:01 - progress_bar.py[line:274] - INFO: epoch 001:   7308 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=7300, lr=1.78423e-05, gnorm=1.363, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34881
2022-10-19 05:07:12 - progress_bar.py[line:274] - INFO: epoch 001:   7318 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102, ups=0.91, wpb=111.6, bsz=40, num_updates=7310, lr=1.78667e-05, gnorm=1.247, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34892
2022-10-19 05:07:24 - progress_bar.py[line:274] - INFO: epoch 001:   7328 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.8, ups=0.87, wpb=110.4, bsz=40, num_updates=7320, lr=1.78912e-05, gnorm=1.254, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34903
2022-10-19 05:07:35 - progress_bar.py[line:274] - INFO: epoch 001:   7338 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=7330, lr=1.79156e-05, gnorm=1.309, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34915
2022-10-19 05:07:46 - progress_bar.py[line:274] - INFO: epoch 001:   7348 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.9, ups=0.9, wpb=110.8, bsz=40, num_updates=7340, lr=1.79401e-05, gnorm=1.27, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34926
2022-10-19 05:07:57 - progress_bar.py[line:274] - INFO: epoch 001:   7358 / 102288 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=100.7, ups=0.92, wpb=110, bsz=40, num_updates=7350, lr=1.79645e-05, gnorm=1.327, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34937
2022-10-19 05:08:08 - progress_bar.py[line:274] - INFO: epoch 001:   7368 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=7360, lr=1.7989e-05, gnorm=1.325, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34948
2022-10-19 05:08:20 - progress_bar.py[line:274] - INFO: epoch 001:   7378 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.2, ups=0.89, wpb=109.5, bsz=40, num_updates=7370, lr=1.80134e-05, gnorm=1.411, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34959
2022-10-19 05:08:31 - progress_bar.py[line:274] - INFO: epoch 001:   7388 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.9, ups=0.9, wpb=108.6, bsz=40, num_updates=7380, lr=1.80378e-05, gnorm=1.295, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34970
2022-10-19 05:08:42 - progress_bar.py[line:274] - INFO: epoch 001:   7398 / 102288 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=97.9, ups=0.89, wpb=110.1, bsz=40, num_updates=7390, lr=1.80623e-05, gnorm=1.411, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34982
2022-10-19 05:08:53 - progress_bar.py[line:274] - INFO: epoch 001:   7408 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=7400, lr=1.80867e-05, gnorm=1.28, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34993
2022-10-19 05:09:04 - progress_bar.py[line:274] - INFO: epoch 001:   7418 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.1, ups=0.91, wpb=109.8, bsz=40, num_updates=7410, lr=1.81112e-05, gnorm=1.22, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35004
2022-10-19 05:09:15 - progress_bar.py[line:274] - INFO: epoch 001:   7428 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.5, ups=0.89, wpb=111.1, bsz=40, num_updates=7420, lr=1.81356e-05, gnorm=1.249, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35015
2022-10-19 05:09:27 - progress_bar.py[line:274] - INFO: epoch 001:   7438 / 102288 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.1, ups=0.89, wpb=111.2, bsz=40, num_updates=7430, lr=1.816e-05, gnorm=1.347, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35026
2022-10-19 05:09:38 - progress_bar.py[line:274] - INFO: epoch 001:   7448 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=97.7, ups=0.89, wpb=110.1, bsz=40, num_updates=7440, lr=1.81845e-05, gnorm=1.393, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35038
2022-10-19 05:09:49 - progress_bar.py[line:274] - INFO: epoch 001:   7458 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.2, ups=0.88, wpb=110.9, bsz=40, num_updates=7450, lr=1.82089e-05, gnorm=1.218, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35049
2022-10-19 05:10:01 - progress_bar.py[line:274] - INFO: epoch 001:   7468 / 102288 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.3, ups=0.89, wpb=111, bsz=40, num_updates=7460, lr=1.82334e-05, gnorm=1.529, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35060
2022-10-19 05:10:12 - progress_bar.py[line:274] - INFO: epoch 001:   7478 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.1, ups=0.9, wpb=108.6, bsz=40, num_updates=7470, lr=1.82578e-05, gnorm=1.333, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35072
2022-10-19 05:10:23 - progress_bar.py[line:274] - INFO: epoch 001:   7488 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.8, ups=0.88, wpb=111.8, bsz=40, num_updates=7480, lr=1.82823e-05, gnorm=1.224, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35083
2022-10-19 05:10:34 - progress_bar.py[line:274] - INFO: epoch 001:   7498 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99, ups=0.9, wpb=109.7, bsz=40, num_updates=7490, lr=1.83067e-05, gnorm=1.253, clip=100, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=35094
2022-10-19 05:10:46 - progress_bar.py[line:274] - INFO: epoch 001:   7508 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.539, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97, ups=0.87, wpb=112, bsz=40, num_updates=7500, lr=1.83311e-05, gnorm=1.269, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35106
2022-10-19 05:10:57 - progress_bar.py[line:274] - INFO: epoch 001:   7518 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=7510, lr=1.83556e-05, gnorm=1.209, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35117
2022-10-19 05:11:09 - progress_bar.py[line:274] - INFO: epoch 001:   7528 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.3, ups=0.89, wpb=109.6, bsz=40, num_updates=7520, lr=1.838e-05, gnorm=1.2, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35128
2022-10-19 05:11:20 - progress_bar.py[line:274] - INFO: epoch 001:   7538 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.1, ups=0.87, wpb=111.5, bsz=40, num_updates=7530, lr=1.84045e-05, gnorm=1.25, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35140
2022-10-19 05:11:32 - progress_bar.py[line:274] - INFO: epoch 001:   7548 / 102288 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=94.6, ups=0.87, wpb=109.3, bsz=40, num_updates=7540, lr=1.84289e-05, gnorm=1.153, clip=70, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=35151
2022-10-19 05:11:43 - progress_bar.py[line:274] - INFO: epoch 001:   7558 / 102288 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=7550, lr=1.84533e-05, gnorm=1.413, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=35163
2022-10-19 05:11:54 - progress_bar.py[line:274] - INFO: epoch 001:   7568 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.7, ups=0.9, wpb=111.6, bsz=40, num_updates=7560, lr=1.84778e-05, gnorm=1.307, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35174
2022-10-19 05:12:05 - progress_bar.py[line:274] - INFO: epoch 001:   7578 / 102288 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.4, ups=0.9, wpb=109, bsz=40, num_updates=7570, lr=1.85022e-05, gnorm=1.299, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35185
2022-10-19 05:12:16 - progress_bar.py[line:274] - INFO: epoch 001:   7588 / 102288 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.8, ups=0.9, wpb=110.3, bsz=40, num_updates=7580, lr=1.85267e-05, gnorm=1.2, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35196
2022-10-19 05:12:27 - progress_bar.py[line:274] - INFO: epoch 001:   7598 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=7590, lr=1.85511e-05, gnorm=1.332, clip=100, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35207
2022-10-19 05:12:39 - progress_bar.py[line:274] - INFO: epoch 001:   7608 / 102288 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=7600, lr=1.85755e-05, gnorm=1.196, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=35218
2022-10-19 05:12:50 - progress_bar.py[line:274] - INFO: epoch 001:   7618 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=7610, lr=1.86e-05, gnorm=1.255, clip=90, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=35230
2022-10-19 05:13:01 - progress_bar.py[line:274] - INFO: epoch 001:   7628 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.2, ups=0.9, wpb=112.1, bsz=40, num_updates=7620, lr=1.86244e-05, gnorm=1.309, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35241
2022-10-19 05:13:12 - progress_bar.py[line:274] - INFO: epoch 001:   7638 / 102288 loss=0.675, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=100, ups=0.91, wpb=109.3, bsz=40, num_updates=7630, lr=1.86489e-05, gnorm=1.313, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35252
2022-10-19 05:13:23 - progress_bar.py[line:274] - INFO: epoch 001:   7648 / 102288 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.618, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.5, ups=0.91, wpb=110, bsz=40, num_updates=7640, lr=1.86733e-05, gnorm=1.324, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35263
2022-10-19 05:13:34 - progress_bar.py[line:274] - INFO: epoch 001:   7658 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.3, ups=0.91, wpb=111, bsz=40, num_updates=7650, lr=1.86978e-05, gnorm=1.272, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35274
2022-10-19 05:13:45 - progress_bar.py[line:274] - INFO: epoch 001:   7668 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.9, ups=0.88, wpb=111.4, bsz=40, num_updates=7660, lr=1.87222e-05, gnorm=1.344, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35285
2022-10-19 05:13:56 - progress_bar.py[line:274] - INFO: epoch 001:   7678 / 102288 loss=0.694, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=7670, lr=1.87466e-05, gnorm=1.383, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35296
2022-10-19 05:14:07 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 05:14:08 - progress_bar.py[line:274] - INFO: epoch 001:   7689 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=91.8, ups=0.84, wpb=109.9, bsz=40, num_updates=7680, lr=1.87711e-05, gnorm=1.169, clip=90, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=35308
2022-10-19 05:14:20 - progress_bar.py[line:274] - INFO: epoch 001:   7699 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.7, ups=0.86, wpb=110.7, bsz=40, num_updates=7690, lr=1.87955e-05, gnorm=1.212, clip=70, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=35320
2022-10-19 05:14:32 - progress_bar.py[line:274] - INFO: epoch 001:   7709 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=95.6, ups=0.88, wpb=108.6, bsz=40, num_updates=7700, lr=1.882e-05, gnorm=1.294, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35331
2022-10-19 05:14:43 - progress_bar.py[line:274] - INFO: epoch 001:   7719 / 102288 loss=0.733, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=98.3, ups=0.91, wpb=108.6, bsz=40, num_updates=7710, lr=1.88444e-05, gnorm=1.403, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35342
2022-10-19 05:14:54 - progress_bar.py[line:274] - INFO: epoch 001:   7729 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.9, ups=0.9, wpb=110.4, bsz=40, num_updates=7720, lr=1.88688e-05, gnorm=1.242, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35354
2022-10-19 05:15:05 - progress_bar.py[line:274] - INFO: epoch 001:   7739 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=7730, lr=1.88933e-05, gnorm=1.342, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35365
2022-10-19 05:15:16 - progress_bar.py[line:274] - INFO: epoch 001:   7749 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.3, ups=0.92, wpb=109.6, bsz=40, num_updates=7740, lr=1.89177e-05, gnorm=1.122, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35376
2022-10-19 05:15:27 - progress_bar.py[line:274] - INFO: epoch 001:   7759 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.2, ups=0.9, wpb=110.6, bsz=40, num_updates=7750, lr=1.89422e-05, gnorm=1.221, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35387
2022-10-19 05:15:39 - progress_bar.py[line:274] - INFO: epoch 001:   7769 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=7760, lr=1.89666e-05, gnorm=1.237, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35398
2022-10-19 05:15:50 - progress_bar.py[line:274] - INFO: epoch 001:   7779 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=7770, lr=1.89911e-05, gnorm=1.198, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35410
2022-10-19 05:16:01 - progress_bar.py[line:274] - INFO: epoch 001:   7789 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=7780, lr=1.90155e-05, gnorm=1.138, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35421
2022-10-19 05:16:12 - progress_bar.py[line:274] - INFO: epoch 001:   7799 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99, ups=0.9, wpb=110.1, bsz=40, num_updates=7790, lr=1.90399e-05, gnorm=1.142, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35432
2022-10-19 05:16:24 - progress_bar.py[line:274] - INFO: epoch 001:   7809 / 102288 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=7800, lr=1.90644e-05, gnorm=1.25, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35443
2022-10-19 05:16:35 - progress_bar.py[line:274] - INFO: epoch 001:   7819 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=101.7, ups=0.92, wpb=110, bsz=40, num_updates=7810, lr=1.90888e-05, gnorm=1.426, clip=100, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=35454
2022-10-19 05:16:46 - progress_bar.py[line:274] - INFO: epoch 001:   7829 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.5, ups=0.9, wpb=110.6, bsz=40, num_updates=7820, lr=1.91133e-05, gnorm=1.307, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35465
2022-10-19 05:16:57 - progress_bar.py[line:274] - INFO: epoch 001:   7839 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=7830, lr=1.91377e-05, gnorm=1.236, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35477
2022-10-19 05:17:09 - progress_bar.py[line:274] - INFO: epoch 001:   7849 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.3, ups=0.87, wpb=110.7, bsz=40, num_updates=7840, lr=1.91621e-05, gnorm=1.25, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35488
2022-10-19 05:17:20 - progress_bar.py[line:274] - INFO: epoch 001:   7859 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.4, ups=0.9, wpb=110.3, bsz=40, num_updates=7850, lr=1.91866e-05, gnorm=1.484, clip=100, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=35499
2022-10-19 05:17:31 - progress_bar.py[line:274] - INFO: epoch 001:   7869 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=7860, lr=1.9211e-05, gnorm=1.135, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35511
2022-10-19 05:17:42 - progress_bar.py[line:274] - INFO: epoch 001:   7879 / 102288 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=95.6, ups=0.88, wpb=109.1, bsz=40, num_updates=7870, lr=1.92355e-05, gnorm=1.233, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35522
2022-10-19 05:17:54 - progress_bar.py[line:274] - INFO: epoch 001:   7889 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=7880, lr=1.92599e-05, gnorm=1.337, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35533
2022-10-19 05:18:04 - progress_bar.py[line:274] - INFO: epoch 001:   7899 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.5, ups=0.91, wpb=111.1, bsz=40, num_updates=7890, lr=1.92844e-05, gnorm=1.219, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35544
2022-10-19 05:18:16 - progress_bar.py[line:274] - INFO: epoch 001:   7909 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.8, ups=0.88, wpb=112.5, bsz=40, num_updates=7900, lr=1.93088e-05, gnorm=1.34, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35556
2022-10-19 05:18:27 - progress_bar.py[line:274] - INFO: epoch 001:   7919 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=7910, lr=1.93332e-05, gnorm=1.327, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35567
2022-10-19 05:18:38 - progress_bar.py[line:274] - INFO: epoch 001:   7929 / 102288 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=7920, lr=1.93577e-05, gnorm=1.267, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35578
2022-10-19 05:18:49 - progress_bar.py[line:274] - INFO: epoch 001:   7939 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=7930, lr=1.93821e-05, gnorm=1.283, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35589
2022-10-19 05:19:00 - progress_bar.py[line:274] - INFO: epoch 001:   7949 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=103.4, ups=0.94, wpb=110.4, bsz=40, num_updates=7940, lr=1.94066e-05, gnorm=1.069, clip=80, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=35600
2022-10-19 05:19:11 - progress_bar.py[line:274] - INFO: epoch 001:   7959 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=104.1, ups=0.94, wpb=110.9, bsz=40, num_updates=7950, lr=1.9431e-05, gnorm=1.179, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35611
2022-10-19 05:19:22 - progress_bar.py[line:274] - INFO: epoch 001:   7969 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=7960, lr=1.94554e-05, gnorm=1.409, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35622
2022-10-19 05:19:33 - progress_bar.py[line:274] - INFO: epoch 001:   7979 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.579, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=7970, lr=1.94799e-05, gnorm=1.273, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35633
2022-10-19 05:19:44 - progress_bar.py[line:274] - INFO: epoch 001:   7989 / 102288 loss=0.69, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.1, ups=0.9, wpb=108.7, bsz=40, num_updates=7980, lr=1.95043e-05, gnorm=1.254, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35644
2022-10-19 05:19:55 - progress_bar.py[line:274] - INFO: epoch 001:   7999 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=7990, lr=1.95288e-05, gnorm=1.136, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35655
2022-10-19 05:20:07 - progress_bar.py[line:274] - INFO: epoch 001:   8009 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=8000, lr=1.95532e-05, gnorm=1.135, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35666
2022-10-19 05:20:07 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 05:20:08 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 05:20:08 - train.py[line:551] - INFO: load:1.03 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 05:22:40 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 05:22:40 - train.py[line:551] - INFO: load:1.06 valid_run:152.07 task_valid:148.12 collect_output:2.89
2022-10-19 05:25:09 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 05:25:09 - train.py[line:551] - INFO: load:1.08 valid_run:301.05 task_valid:291.17 collect_output:7.80
2022-10-19 05:27:43 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 05:27:43 - train.py[line:551] - INFO: load:1.11 valid_run:454.36 task_valid:434.44 collect_output:16.85
2022-10-19 05:30:12 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 05:30:12 - train.py[line:551] - INFO: load:1.13 valid_run:603.73 task_valid:579.35 collect_output:20.30
2022-10-19 05:32:44 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 05:32:44 - train.py[line:551] - INFO: load:1.15 valid_run:756.13 task_valid:726.68 collect_output:24.37
2022-10-19 05:35:16 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 05:35:16 - train.py[line:551] - INFO: load:1.18 valid_run:907.94 task_valid:872.22 collect_output:29.64
2022-10-19 05:37:50 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 05:37:50 - train.py[line:551] - INFO: load:1.20 valid_run:1061.48 task_valid:1018.16 collect_output:36.25
2022-10-19 05:40:22 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 05:40:22 - train.py[line:551] - INFO: load:1.23 valid_run:1213.18 task_valid:1159.51 collect_output:45.61
2022-10-19 05:42:52 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 05:42:52 - train.py[line:551] - INFO: load:1.25 valid_run:1363.04 task_valid:1304.25 collect_output:49.73
2022-10-19 05:45:21 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 05:45:21 - train.py[line:551] - INFO: load:1.28 valid_run:1511.87 task_valid:1447.41 collect_output:54.41
2022-10-19 05:47:51 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 05:47:51 - train.py[line:551] - INFO: load:1.30 valid_run:1661.95 task_valid:1592.27 collect_output:58.62
2022-10-19 05:50:21 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 05:50:21 - train.py[line:551] - INFO: load:1.33 valid_run:1812.38 task_valid:1737.37 collect_output:62.96
2022-10-19 05:52:52 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 05:52:52 - train.py[line:551] - INFO: load:1.36 valid_run:1962.70 task_valid:1879.21 collect_output:70.44
2022-10-19 05:55:22 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 05:55:22 - train.py[line:551] - INFO: load:1.38 valid_run:2113.34 task_valid:2024.65 collect_output:74.64
2022-10-19 05:57:52 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 05:57:52 - train.py[line:551] - INFO: load:1.41 valid_run:2263.40 task_valid:2171.00 collect_output:77.38
2022-10-19 06:00:23 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 06:00:23 - train.py[line:551] - INFO: load:1.43 valid_run:2413.76 task_valid:2315.35 collect_output:82.37
2022-10-19 06:02:55 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 06:02:55 - train.py[line:551] - INFO: load:1.46 valid_run:2566.09 task_valid:2461.12 collect_output:87.92
2022-10-19 06:05:26 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 06:05:26 - train.py[line:551] - INFO: load:1.48 valid_run:2717.11 task_valid:2608.27 collect_output:90.69
2022-10-19 06:07:55 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 06:07:55 - train.py[line:551] - INFO: load:1.51 valid_run:2866.14 task_valid:2749.87 collect_output:97.07
2022-10-19 06:10:26 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 06:10:26 - train.py[line:551] - INFO: load:1.53 valid_run:3017.15 task_valid:2895.21 collect_output:101.69
2022-10-19 06:12:59 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 06:12:59 - train.py[line:551] - INFO: load:1.56 valid_run:3170.02 task_valid:3039.87 collect_output:108.88
2022-10-19 06:15:29 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 06:15:29 - train.py[line:551] - INFO: load:1.58 valid_run:3319.90 task_valid:3184.51 collect_output:113.09
2022-10-19 06:18:01 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 06:18:01 - train.py[line:551] - INFO: load:1.61 valid_run:3471.54 task_valid:3330.69 collect_output:117.53
2022-10-19 06:20:33 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 06:20:33 - train.py[line:551] - INFO: load:1.63 valid_run:3623.38 task_valid:3477.41 collect_output:121.63

====================================================================================================
SGG eval:     R @ 50: 0.5407;     R @ 100: 0.5732;     R @ 500: 0.6110;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3756;    mR @ 100: 0.4090;    mR @ 500: 0.4465;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4707) (covered in:0.6667) (covering:0.4286) (eating:0.7647) (flying in:1.0000) (growing on:0.5000) (hanging from:0.2581) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7500) (playing:0.0000) (riding:0.8889) (says:0.0000) (sitting on:0.7319) (standing on:0.1700) (using:0.3500) (walking in:0.0000) (walking on:0.7973) (watching:0.2361) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5407;     R @ 100: 0.5732;     R @ 500: 0.6110;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3756;    mR @ 100: 0.4090;    mR @ 500: 0.4465;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4707) (covered in:0.6667) (covering:0.4286) (eating:0.7647) (flying in:1.0000) (growing on:0.5000) (hanging from:0.2581) (lying on:0.0833) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7500) (playing:0.0000) (riding:0.8889) (says:0.0000) (sitting on:0.7319) (standing on:0.1700) (using:0.3500) (walking in:0.0000) (walking on:0.7973) (watching:0.2361) 
--------------------------------------------------------
====================================================================================================

2022-10-19 06:23:04 - train.py[line:487] - INFO: 0.5732047619047619
2022-10-19 06:23:04 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 06:23:05 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.352 | loss_v1 0 | loss_v2 0 | nll_loss 0.208 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.573205 | ppl 1.16 | vqa_score 0.4133 | wps 118.8 | wpb 89.9 | bsz 30 | num_updates 8000 | best_R@100 0.573205
2022-10-19 06:23:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2022-10-19 06:23:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-19 06:23:10 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-19 06:23:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.5732047619047619) (writing took 13.151245612185448 seconds)
2022-10-19 06:23:29 - progress_bar.py[line:274] - INFO: epoch 001:   8019 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=0.3, ups=0, wpb=110.1, bsz=40, num_updates=8010, lr=1.95777e-05, gnorm=1.151, clip=90, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=39469
2022-10-19 06:23:40 - progress_bar.py[line:274] - INFO: epoch 001:   8029 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.8, ups=0.9, wpb=111.8, bsz=40, num_updates=8020, lr=1.96021e-05, gnorm=1.28, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39480
2022-10-19 06:23:52 - progress_bar.py[line:274] - INFO: epoch 001:   8039 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=8030, lr=1.96265e-05, gnorm=1.208, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39491
2022-10-19 06:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   8049 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.8, ups=0.91, wpb=110.5, bsz=40, num_updates=8040, lr=1.9651e-05, gnorm=1.215, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39502
2022-10-19 06:24:14 - progress_bar.py[line:274] - INFO: epoch 001:   8059 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.8, ups=0.87, wpb=110.2, bsz=40, num_updates=8050, lr=1.96754e-05, gnorm=1.209, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39514
2022-10-19 06:24:26 - progress_bar.py[line:274] - INFO: epoch 001:   8069 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=95.9, ups=0.87, wpb=110.6, bsz=40, num_updates=8060, lr=1.96999e-05, gnorm=1.266, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39525
2022-10-19 06:24:37 - progress_bar.py[line:274] - INFO: epoch 001:   8079 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.6, ups=0.89, wpb=109.9, bsz=40, num_updates=8070, lr=1.97243e-05, gnorm=1.336, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39537
2022-10-19 06:24:48 - progress_bar.py[line:274] - INFO: epoch 001:   8089 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.9, ups=0.92, wpb=110.2, bsz=40, num_updates=8080, lr=1.97487e-05, gnorm=1.176, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39548
2022-10-19 06:24:59 - progress_bar.py[line:274] - INFO: epoch 001:   8099 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.5, ups=0.89, wpb=111, bsz=40, num_updates=8090, lr=1.97732e-05, gnorm=1.195, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39559
2022-10-19 06:25:10 - progress_bar.py[line:274] - INFO: epoch 001:   8109 / 102288 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.567, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=102, ups=0.93, wpb=109.9, bsz=40, num_updates=8100, lr=1.97976e-05, gnorm=1.115, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39570
2022-10-19 06:25:22 - progress_bar.py[line:274] - INFO: epoch 001:   8119 / 102288 loss=0.705, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=96.3, ups=0.88, wpb=109.6, bsz=40, num_updates=8110, lr=1.98221e-05, gnorm=1.275, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39581
2022-10-19 06:25:33 - progress_bar.py[line:274] - INFO: epoch 001:   8129 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=8120, lr=1.98465e-05, gnorm=1.252, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39593
2022-10-19 06:25:44 - progress_bar.py[line:274] - INFO: epoch 001:   8139 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=8130, lr=1.98709e-05, gnorm=1.317, clip=100, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=39604
2022-10-19 06:25:56 - progress_bar.py[line:274] - INFO: epoch 001:   8149 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.2, ups=0.88, wpb=111.9, bsz=40, num_updates=8140, lr=1.98954e-05, gnorm=1.2, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39615
2022-10-19 06:26:07 - progress_bar.py[line:274] - INFO: epoch 001:   8159 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.3, ups=0.88, wpb=109.8, bsz=40, num_updates=8150, lr=1.99198e-05, gnorm=1.138, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39627
2022-10-19 06:26:18 - progress_bar.py[line:274] - INFO: epoch 001:   8169 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=8160, lr=1.99443e-05, gnorm=1.233, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39638
2022-10-19 06:26:29 - progress_bar.py[line:274] - INFO: epoch 001:   8179 / 102288 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=101.3, ups=0.93, wpb=109.4, bsz=40, num_updates=8170, lr=1.99687e-05, gnorm=1.479, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39649
2022-10-19 06:26:40 - progress_bar.py[line:274] - INFO: epoch 001:   8189 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.6, ups=0.89, wpb=109.8, bsz=40, num_updates=8180, lr=1.99932e-05, gnorm=1.248, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39660
2022-10-19 06:26:52 - progress_bar.py[line:274] - INFO: epoch 001:   8199 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=8190, lr=2.00176e-05, gnorm=1.253, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39672
2022-10-19 06:27:03 - progress_bar.py[line:274] - INFO: epoch 001:   8209 / 102288 loss=0.693, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.3, ups=0.88, wpb=110.1, bsz=40, num_updates=8200, lr=2.0042e-05, gnorm=1.306, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39683
2022-10-19 06:27:14 - progress_bar.py[line:274] - INFO: epoch 001:   8219 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.5, ups=0.92, wpb=110.9, bsz=40, num_updates=8210, lr=2.00665e-05, gnorm=1.193, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39694
2022-10-19 06:27:26 - progress_bar.py[line:274] - INFO: epoch 001:   8229 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.9, ups=0.89, wpb=110.4, bsz=40, num_updates=8220, lr=2.00909e-05, gnorm=1.22, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39705
2022-10-19 06:27:37 - progress_bar.py[line:274] - INFO: epoch 001:   8239 / 102288 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.575, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=8230, lr=2.01154e-05, gnorm=1.271, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39716
2022-10-19 06:27:48 - progress_bar.py[line:274] - INFO: epoch 001:   8249 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=96.9, ups=0.89, wpb=108.6, bsz=40, num_updates=8240, lr=2.01398e-05, gnorm=1.355, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39728
2022-10-19 06:27:59 - progress_bar.py[line:274] - INFO: epoch 001:   8259 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.9, ups=0.91, wpb=111.3, bsz=40, num_updates=8250, lr=2.01642e-05, gnorm=1.22, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39739
2022-10-19 06:28:10 - progress_bar.py[line:274] - INFO: epoch 001:   8269 / 102288 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.7, ups=0.88, wpb=111.2, bsz=40, num_updates=8260, lr=2.01887e-05, gnorm=1.163, clip=80, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39750
2022-10-19 06:28:22 - progress_bar.py[line:274] - INFO: epoch 001:   8279 / 102288 loss=0.682, loss_v1=0, loss_v2=0, nll_loss=0.582, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=95.7, ups=0.88, wpb=108.3, bsz=40, num_updates=8270, lr=2.02131e-05, gnorm=1.152, clip=80, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39762
2022-10-19 06:28:33 - progress_bar.py[line:274] - INFO: epoch 001:   8289 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.5, ups=0.88, wpb=110, bsz=40, num_updates=8280, lr=2.02376e-05, gnorm=1.268, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39773
2022-10-19 06:28:38 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 06:28:45 - progress_bar.py[line:274] - INFO: epoch 001:   8300 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=93.8, ups=0.84, wpb=111.6, bsz=40, num_updates=8290, lr=2.0262e-05, gnorm=1.259, clip=90, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=39785
2022-10-19 06:28:56 - progress_bar.py[line:274] - INFO: epoch 001:   8310 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.3, ups=0.9, wpb=110.2, bsz=40, num_updates=8300, lr=2.02865e-05, gnorm=1.237, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39796
2022-10-19 06:29:08 - progress_bar.py[line:274] - INFO: epoch 001:   8320 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=8310, lr=2.03109e-05, gnorm=1.283, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39808
2022-10-19 06:29:19 - progress_bar.py[line:274] - INFO: epoch 001:   8330 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100.8, ups=0.91, wpb=110.4, bsz=40, num_updates=8320, lr=2.03353e-05, gnorm=1.264, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39819
2022-10-19 06:29:30 - progress_bar.py[line:274] - INFO: epoch 001:   8340 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=95.2, ups=0.87, wpb=109.6, bsz=40, num_updates=8330, lr=2.03598e-05, gnorm=1.28, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39830
2022-10-19 06:29:42 - progress_bar.py[line:274] - INFO: epoch 001:   8350 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.1, ups=0.9, wpb=110.2, bsz=40, num_updates=8340, lr=2.03842e-05, gnorm=1.303, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39841
2022-10-19 06:29:53 - progress_bar.py[line:274] - INFO: epoch 001:   8360 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=8350, lr=2.04087e-05, gnorm=1.288, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39853
2022-10-19 06:30:04 - progress_bar.py[line:274] - INFO: epoch 001:   8370 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=8360, lr=2.04331e-05, gnorm=1.271, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=39864
2022-10-19 06:30:15 - progress_bar.py[line:274] - INFO: epoch 001:   8380 / 102288 loss=0.68, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.6, ups=0.91, wpb=108.8, bsz=40, num_updates=8370, lr=2.04575e-05, gnorm=1.276, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39875
2022-10-19 06:30:26 - progress_bar.py[line:274] - INFO: epoch 001:   8390 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=8380, lr=2.0482e-05, gnorm=1.259, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39886
2022-10-19 06:30:38 - progress_bar.py[line:274] - INFO: epoch 001:   8400 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=8390, lr=2.05064e-05, gnorm=1.367, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39898
2022-10-19 06:30:49 - progress_bar.py[line:274] - INFO: epoch 001:   8410 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=8400, lr=2.05309e-05, gnorm=1.281, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39909
2022-10-19 06:31:01 - progress_bar.py[line:274] - INFO: epoch 001:   8420 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.6, ups=0.87, wpb=110.7, bsz=40, num_updates=8410, lr=2.05553e-05, gnorm=1.192, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39920
2022-10-19 06:31:12 - progress_bar.py[line:274] - INFO: epoch 001:   8430 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=8420, lr=2.05798e-05, gnorm=1.159, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39932
2022-10-19 06:31:23 - progress_bar.py[line:274] - INFO: epoch 001:   8440 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=8430, lr=2.06042e-05, gnorm=1.161, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39943
2022-10-19 06:31:35 - progress_bar.py[line:274] - INFO: epoch 001:   8450 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=8440, lr=2.06286e-05, gnorm=1.195, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39955
2022-10-19 06:31:46 - progress_bar.py[line:274] - INFO: epoch 001:   8460 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.5, ups=0.88, wpb=112.1, bsz=40, num_updates=8450, lr=2.06531e-05, gnorm=1.315, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39966
2022-10-19 06:31:58 - progress_bar.py[line:274] - INFO: epoch 001:   8470 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.8, ups=0.87, wpb=112.7, bsz=40, num_updates=8460, lr=2.06775e-05, gnorm=1.255, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39978
2022-10-19 06:32:09 - progress_bar.py[line:274] - INFO: epoch 001:   8480 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.2, ups=0.87, wpb=109.8, bsz=40, num_updates=8470, lr=2.0702e-05, gnorm=1.356, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39989
2022-10-19 06:32:21 - progress_bar.py[line:274] - INFO: epoch 001:   8490 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=8480, lr=2.07264e-05, gnorm=1.161, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40001
2022-10-19 06:32:32 - progress_bar.py[line:274] - INFO: epoch 001:   8500 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=8490, lr=2.07508e-05, gnorm=1.269, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40012
2022-10-19 06:32:44 - progress_bar.py[line:274] - INFO: epoch 001:   8510 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=94.9, ups=0.87, wpb=109.5, bsz=40, num_updates=8500, lr=2.07753e-05, gnorm=1.122, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40023
2022-10-19 06:32:55 - progress_bar.py[line:274] - INFO: epoch 001:   8520 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=8510, lr=2.07997e-05, gnorm=1.196, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40035
2022-10-19 06:33:06 - progress_bar.py[line:274] - INFO: epoch 001:   8530 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.4, ups=0.91, wpb=108.6, bsz=40, num_updates=8520, lr=2.08242e-05, gnorm=1.485, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40046
2022-10-19 06:33:17 - progress_bar.py[line:274] - INFO: epoch 001:   8540 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=8530, lr=2.08486e-05, gnorm=1.234, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=40057
2022-10-19 06:33:29 - progress_bar.py[line:274] - INFO: epoch 001:   8550 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.1, ups=0.87, wpb=110.7, bsz=40, num_updates=8540, lr=2.08731e-05, gnorm=1.248, clip=80, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=40069
2022-10-19 06:33:40 - progress_bar.py[line:274] - INFO: epoch 001:   8560 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=102.4, ups=0.93, wpb=110.5, bsz=40, num_updates=8550, lr=2.08975e-05, gnorm=1.13, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40080
2022-10-19 06:33:51 - progress_bar.py[line:274] - INFO: epoch 001:   8570 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100, ups=0.91, wpb=110.2, bsz=40, num_updates=8560, lr=2.09219e-05, gnorm=1.273, clip=90, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=40091
2022-10-19 06:34:02 - progress_bar.py[line:274] - INFO: epoch 001:   8580 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.7, ups=0.91, wpb=111.2, bsz=40, num_updates=8570, lr=2.09464e-05, gnorm=1.444, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40102
2022-10-19 06:34:13 - progress_bar.py[line:274] - INFO: epoch 001:   8590 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.2, ups=0.91, wpb=109.5, bsz=40, num_updates=8580, lr=2.09708e-05, gnorm=1.217, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40113
2022-10-19 06:34:24 - progress_bar.py[line:274] - INFO: epoch 001:   8600 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.8, ups=0.87, wpb=110.2, bsz=40, num_updates=8590, lr=2.09953e-05, gnorm=1.258, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40124
2022-10-19 06:34:36 - progress_bar.py[line:274] - INFO: epoch 001:   8610 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.9, ups=0.91, wpb=110.4, bsz=40, num_updates=8600, lr=2.10197e-05, gnorm=1.309, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40135
2022-10-19 06:34:47 - progress_bar.py[line:274] - INFO: epoch 001:   8620 / 102288 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=8610, lr=2.10441e-05, gnorm=1.4, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40147
2022-10-19 06:34:58 - progress_bar.py[line:274] - INFO: epoch 001:   8630 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.4, ups=0.87, wpb=109.9, bsz=40, num_updates=8620, lr=2.10686e-05, gnorm=1.095, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40158
2022-10-19 06:35:09 - progress_bar.py[line:274] - INFO: epoch 001:   8640 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=102.1, ups=0.93, wpb=110.3, bsz=40, num_updates=8630, lr=2.1093e-05, gnorm=1.24, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40169
2022-10-19 06:35:21 - progress_bar.py[line:274] - INFO: epoch 001:   8650 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.6, ups=0.87, wpb=111.2, bsz=40, num_updates=8640, lr=2.11175e-05, gnorm=1.227, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40181
2022-10-19 06:35:32 - progress_bar.py[line:274] - INFO: epoch 001:   8660 / 102288 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=8650, lr=2.11419e-05, gnorm=1.117, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40192
2022-10-19 06:35:43 - progress_bar.py[line:274] - INFO: epoch 001:   8670 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=8660, lr=2.11663e-05, gnorm=1.177, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40203
2022-10-19 06:35:54 - progress_bar.py[line:274] - INFO: epoch 001:   8680 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=8670, lr=2.11908e-05, gnorm=1.29, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40214
2022-10-19 06:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   8690 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.2, ups=0.9, wpb=110.3, bsz=40, num_updates=8680, lr=2.12152e-05, gnorm=1.144, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40225
2022-10-19 06:36:17 - progress_bar.py[line:274] - INFO: epoch 001:   8700 / 102288 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=8690, lr=2.12397e-05, gnorm=1.22, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40237
2022-10-19 06:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   8710 / 102288 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.3, ups=0.92, wpb=109.6, bsz=40, num_updates=8700, lr=2.12641e-05, gnorm=1.108, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40247
2022-10-19 06:36:39 - progress_bar.py[line:274] - INFO: epoch 001:   8720 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=102.7, ups=0.93, wpb=111, bsz=40, num_updates=8710, lr=2.12886e-05, gnorm=1.015, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40258
2022-10-19 06:36:50 - progress_bar.py[line:274] - INFO: epoch 001:   8730 / 102288 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=8720, lr=2.1313e-05, gnorm=1.415, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40269
2022-10-19 06:37:01 - progress_bar.py[line:274] - INFO: epoch 001:   8740 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.4, ups=0.89, wpb=109.6, bsz=40, num_updates=8730, lr=2.13374e-05, gnorm=1.318, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40281
2022-10-19 06:37:12 - progress_bar.py[line:274] - INFO: epoch 001:   8750 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=8740, lr=2.13619e-05, gnorm=1.172, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=40292
2022-10-19 06:37:24 - progress_bar.py[line:274] - INFO: epoch 001:   8760 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=8750, lr=2.13863e-05, gnorm=1.121, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40303
2022-10-19 06:37:35 - progress_bar.py[line:274] - INFO: epoch 001:   8770 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.4, ups=0.87, wpb=109.9, bsz=40, num_updates=8760, lr=2.14108e-05, gnorm=1.264, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40315
2022-10-19 06:37:46 - progress_bar.py[line:274] - INFO: epoch 001:   8780 / 102288 loss=0.684, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.7, ups=0.91, wpb=109.2, bsz=40, num_updates=8770, lr=2.14352e-05, gnorm=1.122, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40326
2022-10-19 06:37:58 - progress_bar.py[line:274] - INFO: epoch 001:   8790 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.2, ups=0.88, wpb=109.3, bsz=40, num_updates=8780, lr=2.14596e-05, gnorm=1.085, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40337
2022-10-19 06:38:09 - progress_bar.py[line:274] - INFO: epoch 001:   8800 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=8790, lr=2.14841e-05, gnorm=1.226, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40349
2022-10-19 06:38:18 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 06:38:21 - progress_bar.py[line:274] - INFO: epoch 001:   8811 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=91.8, ups=0.84, wpb=109.6, bsz=40, num_updates=8800, lr=2.15085e-05, gnorm=1.337, clip=90, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=40361
2022-10-19 06:38:32 - progress_bar.py[line:274] - INFO: epoch 001:   8821 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=8810, lr=2.1533e-05, gnorm=1.166, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40372
2022-10-19 06:38:43 - progress_bar.py[line:274] - INFO: epoch 001:   8831 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.1, ups=0.91, wpb=109.6, bsz=40, num_updates=8820, lr=2.15574e-05, gnorm=1.181, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40383
2022-10-19 06:38:54 - progress_bar.py[line:274] - INFO: epoch 001:   8841 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.9, ups=0.9, wpb=109.7, bsz=40, num_updates=8830, lr=2.15819e-05, gnorm=1.141, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40394
2022-10-19 06:39:06 - progress_bar.py[line:274] - INFO: epoch 001:   8851 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=8840, lr=2.16063e-05, gnorm=1.155, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40405
2022-10-19 06:39:17 - progress_bar.py[line:274] - INFO: epoch 001:   8861 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.9, ups=0.9, wpb=110.8, bsz=40, num_updates=8850, lr=2.16307e-05, gnorm=1.119, clip=90, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=40417
2022-10-19 06:39:28 - progress_bar.py[line:274] - INFO: epoch 001:   8871 / 102288 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100, ups=0.91, wpb=110.2, bsz=40, num_updates=8860, lr=2.16552e-05, gnorm=1.264, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40428
2022-10-19 06:39:39 - progress_bar.py[line:274] - INFO: epoch 001:   8881 / 102288 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=94.5, ups=0.87, wpb=109, bsz=40, num_updates=8870, lr=2.16796e-05, gnorm=1.297, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40439
2022-10-19 06:39:51 - progress_bar.py[line:274] - INFO: epoch 001:   8891 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.3, ups=0.91, wpb=109.7, bsz=40, num_updates=8880, lr=2.17041e-05, gnorm=1.164, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40450
2022-10-19 06:40:02 - progress_bar.py[line:274] - INFO: epoch 001:   8901 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.8, ups=0.88, wpb=109.2, bsz=40, num_updates=8890, lr=2.17285e-05, gnorm=1.303, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40462
2022-10-19 06:40:13 - progress_bar.py[line:274] - INFO: epoch 001:   8911 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=8900, lr=2.17529e-05, gnorm=1.172, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40473
2022-10-19 06:40:25 - progress_bar.py[line:274] - INFO: epoch 001:   8921 / 102288 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=8910, lr=2.17774e-05, gnorm=1.113, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40484
2022-10-19 06:40:36 - progress_bar.py[line:274] - INFO: epoch 001:   8931 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=8920, lr=2.18018e-05, gnorm=1.326, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40496
2022-10-19 06:40:47 - progress_bar.py[line:274] - INFO: epoch 001:   8941 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99, ups=0.9, wpb=109.8, bsz=40, num_updates=8930, lr=2.18263e-05, gnorm=1.3, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40507
2022-10-19 06:40:58 - progress_bar.py[line:274] - INFO: epoch 001:   8951 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101.8, ups=0.92, wpb=110.7, bsz=40, num_updates=8940, lr=2.18507e-05, gnorm=1.405, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40518
2022-10-19 06:41:10 - progress_bar.py[line:274] - INFO: epoch 001:   8961 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.5, ups=0.87, wpb=111.1, bsz=40, num_updates=8950, lr=2.18752e-05, gnorm=1.074, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=40529
2022-10-19 06:41:21 - progress_bar.py[line:274] - INFO: epoch 001:   8971 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101.9, ups=0.91, wpb=111.5, bsz=40, num_updates=8960, lr=2.18996e-05, gnorm=1.055, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40540
2022-10-19 06:41:32 - progress_bar.py[line:274] - INFO: epoch 001:   8981 / 102288 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.9, ups=0.91, wpb=109.2, bsz=40, num_updates=8970, lr=2.1924e-05, gnorm=1.09, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40551
2022-10-19 06:41:43 - progress_bar.py[line:274] - INFO: epoch 001:   8991 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=8980, lr=2.19485e-05, gnorm=1.032, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40563
2022-10-19 06:41:54 - progress_bar.py[line:274] - INFO: epoch 001:   9001 / 102288 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.8, ups=0.89, wpb=108.3, bsz=40, num_updates=8990, lr=2.19729e-05, gnorm=1.246, clip=80, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=40574
2022-10-19 06:42:06 - progress_bar.py[line:274] - INFO: epoch 001:   9011 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=9000, lr=2.19974e-05, gnorm=1.294, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40585
2022-10-19 06:42:06 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 06:42:07 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 06:42:07 - train.py[line:551] - INFO: load:1.12 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 06:44:39 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 06:44:39 - train.py[line:551] - INFO: load:1.14 valid_run:152.12 task_valid:148.15 collect_output:2.90
2022-10-19 06:47:08 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 06:47:08 - train.py[line:551] - INFO: load:1.17 valid_run:301.11 task_valid:291.38 collect_output:7.64
2022-10-19 06:49:42 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 06:49:42 - train.py[line:551] - INFO: load:1.20 valid_run:454.29 task_valid:434.41 collect_output:16.81
2022-10-19 06:52:11 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 06:52:11 - train.py[line:551] - INFO: load:1.22 valid_run:603.75 task_valid:579.42 collect_output:20.25
2022-10-19 06:54:44 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 06:54:44 - train.py[line:551] - INFO: load:1.25 valid_run:756.27 task_valid:726.85 collect_output:24.34
2022-10-19 06:57:16 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 06:57:16 - train.py[line:551] - INFO: load:1.28 valid_run:908.30 task_valid:872.53 collect_output:29.66
2022-10-19 06:59:49 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 06:59:49 - train.py[line:551] - INFO: load:1.30 valid_run:1061.95 task_valid:1018.61 collect_output:36.24
2022-10-19 07:02:21 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 07:02:21 - train.py[line:551] - INFO: load:1.33 valid_run:1213.59 task_valid:1159.66 collect_output:45.83
2022-10-19 07:04:51 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 07:04:51 - train.py[line:551] - INFO: load:1.35 valid_run:1363.42 task_valid:1304.30 collect_output:50.01
2022-10-19 07:07:20 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 07:07:20 - train.py[line:551] - INFO: load:1.38 valid_run:1512.42 task_valid:1447.68 collect_output:54.61
2022-10-19 07:09:50 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 07:09:50 - train.py[line:551] - INFO: load:1.40 valid_run:1662.35 task_valid:1592.61 collect_output:58.61
2022-10-19 07:12:20 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 07:12:20 - train.py[line:551] - INFO: load:1.43 valid_run:1812.63 task_valid:1737.53 collect_output:62.95
2022-10-19 07:14:51 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 07:14:51 - train.py[line:551] - INFO: load:1.45 valid_run:1963.01 task_valid:1879.38 collect_output:70.44
2022-10-19 07:17:22 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 07:17:22 - train.py[line:551] - INFO: load:1.48 valid_run:2114.12 task_valid:2025.12 collect_output:74.66
2022-10-19 07:19:53 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 07:19:53 - train.py[line:551] - INFO: load:1.50 valid_run:2264.71 task_valid:2171.94 collect_output:77.28
2022-10-19 07:22:23 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 07:22:23 - train.py[line:551] - INFO: load:1.53 valid_run:2415.43 task_valid:2316.43 collect_output:82.45
2022-10-19 07:24:56 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 07:24:56 - train.py[line:551] - INFO: load:1.56 valid_run:2568.10 task_valid:2462.19 collect_output:88.26
2022-10-19 07:27:27 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 07:27:27 - train.py[line:551] - INFO: load:1.58 valid_run:2719.07 task_valid:2609.27 collect_output:91.07
2022-10-19 07:29:57 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 07:29:57 - train.py[line:551] - INFO: load:1.61 valid_run:2868.56 task_valid:2751.56 collect_output:97.14
2022-10-19 07:32:28 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 07:32:28 - train.py[line:551] - INFO: load:1.63 valid_run:3019.89 task_valid:2897.00 collect_output:101.89
2022-10-19 07:35:02 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 07:35:02 - train.py[line:551] - INFO: load:1.66 valid_run:3173.19 task_valid:3042.02 collect_output:109.05
2022-10-19 07:37:34 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 07:37:34 - train.py[line:551] - INFO: load:1.71 valid_run:3325.37 task_valid:3188.52 collect_output:113.40
2022-10-19 07:40:06 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 07:40:06 - train.py[line:551] - INFO: load:1.73 valid_run:3477.48 task_valid:3335.13 collect_output:117.83
2022-10-19 07:42:38 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 07:42:38 - train.py[line:551] - INFO: load:1.76 valid_run:3629.66 task_valid:3482.07 collect_output:121.94

====================================================================================================
SGG eval:     R @ 50: 0.5459;     R @ 100: 0.5698;     R @ 500: 0.6046;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3913;    mR @ 100: 0.4163;    mR @ 500: 0.4469;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5195) (covered in:0.8750) (covering:0.4286) (eating:0.7059) (flying in:1.0000) (growing on:0.3750) (hanging from:0.2903) (lying on:0.1167) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8333) (playing:0.0000) (riding:0.9036) (says:0.0000) (sitting on:0.7234) (standing on:0.1300) (using:0.3500) (walking in:0.0000) (walking on:0.8243) (watching:0.2500) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5459;     R @ 100: 0.5698;     R @ 500: 0.6046;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3913;    mR @ 100: 0.4163;    mR @ 500: 0.4469;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5195) (covered in:0.8750) (covering:0.4286) (eating:0.7059) (flying in:1.0000) (growing on:0.3750) (hanging from:0.2903) (lying on:0.1167) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8333) (playing:0.0000) (riding:0.9036) (says:0.0000) (sitting on:0.7234) (standing on:0.1300) (using:0.3500) (walking in:0.0000) (walking on:0.8243) (watching:0.2500) 
--------------------------------------------------------
====================================================================================================

2022-10-19 07:45:10 - train.py[line:487] - INFO: 0.5697714285714286
2022-10-19 07:45:10 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 07:45:13 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.353 | loss_v1 0 | loss_v2 0 | nll_loss 0.2 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.569771 | ppl 1.15 | vqa_score 0.42 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 9000 | best_R@100 0.573205
2022-10-19 07:45:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 9000 updates
2022-10-19 07:45:13 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_9000.pt
2022-10-19 07:45:19 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_9000.pt
2022-10-19 07:45:22 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 0.5697714285714286) (writing took 8.485630600247532 seconds)
2022-10-19 07:45:33 - progress_bar.py[line:274] - INFO: epoch 001:   9021 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=0.3, ups=0, wpb=112, bsz=40, num_updates=9010, lr=2.20218e-05, gnorm=1.136, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44393
2022-10-19 07:45:44 - progress_bar.py[line:274] - INFO: epoch 001:   9031 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.6, ups=0.91, wpb=109, bsz=40, num_updates=9020, lr=2.20462e-05, gnorm=1.163, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44404
2022-10-19 07:45:55 - progress_bar.py[line:274] - INFO: epoch 001:   9041 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.6, ups=0.9, wpb=110.8, bsz=40, num_updates=9030, lr=2.20707e-05, gnorm=1.173, clip=90, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=44415
2022-10-19 07:46:06 - progress_bar.py[line:274] - INFO: epoch 001:   9051 / 102288 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=101.2, ups=0.93, wpb=109.3, bsz=40, num_updates=9040, lr=2.20951e-05, gnorm=1.139, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44426
2022-10-19 07:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   9061 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.1, ups=0.89, wpb=111.3, bsz=40, num_updates=9050, lr=2.21196e-05, gnorm=1.158, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44437
2022-10-19 07:46:28 - progress_bar.py[line:274] - INFO: epoch 001:   9071 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=9060, lr=2.2144e-05, gnorm=1.157, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44448
2022-10-19 07:46:40 - progress_bar.py[line:274] - INFO: epoch 001:   9081 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=9070, lr=2.21685e-05, gnorm=1.247, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44460
2022-10-19 07:46:51 - progress_bar.py[line:274] - INFO: epoch 001:   9091 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.1, ups=0.88, wpb=109.4, bsz=40, num_updates=9080, lr=2.21929e-05, gnorm=1.264, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44471
2022-10-19 07:47:02 - progress_bar.py[line:274] - INFO: epoch 001:   9101 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=9090, lr=2.22173e-05, gnorm=1.091, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44482
2022-10-19 07:47:13 - progress_bar.py[line:274] - INFO: epoch 001:   9111 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.8, ups=0.9, wpb=110.8, bsz=40, num_updates=9100, lr=2.22418e-05, gnorm=1.165, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44493
2022-10-19 07:47:24 - progress_bar.py[line:274] - INFO: epoch 001:   9121 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=9110, lr=2.22662e-05, gnorm=1.123, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44504
2022-10-19 07:47:35 - progress_bar.py[line:274] - INFO: epoch 001:   9131 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=106, ups=0.95, wpb=111.4, bsz=40, num_updates=9120, lr=2.22907e-05, gnorm=1.313, clip=90, loss_scale=512, train_wall=10, gb_free=10.5, ema_decay=0.9999, wall=44515
2022-10-19 07:47:46 - progress_bar.py[line:274] - INFO: epoch 001:   9141 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=9130, lr=2.23151e-05, gnorm=1.17, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44526
2022-10-19 07:47:57 - progress_bar.py[line:274] - INFO: epoch 001:   9151 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.2, ups=0.9, wpb=110.2, bsz=40, num_updates=9140, lr=2.23395e-05, gnorm=1.257, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44537
2022-10-19 07:48:08 - progress_bar.py[line:274] - INFO: epoch 001:   9161 / 102288 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=97.1, ups=0.9, wpb=107.9, bsz=40, num_updates=9150, lr=2.2364e-05, gnorm=1.334, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44548
2022-10-19 07:48:19 - progress_bar.py[line:274] - INFO: epoch 001:   9171 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.7, ups=0.89, wpb=109.5, bsz=40, num_updates=9160, lr=2.23884e-05, gnorm=1.142, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44559
2022-10-19 07:48:31 - progress_bar.py[line:274] - INFO: epoch 001:   9181 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=9170, lr=2.24129e-05, gnorm=1.11, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44571
2022-10-19 07:48:42 - progress_bar.py[line:274] - INFO: epoch 001:   9191 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=102.3, ups=0.91, wpb=112.1, bsz=40, num_updates=9180, lr=2.24373e-05, gnorm=1.435, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44581
2022-10-19 07:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   9201 / 102288 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=9190, lr=2.24617e-05, gnorm=1.358, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44593
2022-10-19 07:49:04 - progress_bar.py[line:274] - INFO: epoch 001:   9211 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=9200, lr=2.24862e-05, gnorm=1.065, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44604
2022-10-19 07:49:15 - progress_bar.py[line:274] - INFO: epoch 001:   9221 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.8, ups=0.89, wpb=109.9, bsz=40, num_updates=9210, lr=2.25106e-05, gnorm=1.217, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44615
2022-10-19 07:49:27 - progress_bar.py[line:274] - INFO: epoch 001:   9231 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.7, ups=0.88, wpb=112.1, bsz=40, num_updates=9220, lr=2.25351e-05, gnorm=1.144, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44626
2022-10-19 07:49:38 - progress_bar.py[line:274] - INFO: epoch 001:   9241 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=9230, lr=2.25595e-05, gnorm=1.201, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44638
2022-10-19 07:49:49 - progress_bar.py[line:274] - INFO: epoch 001:   9251 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.4, ups=0.89, wpb=108.5, bsz=40, num_updates=9240, lr=2.2584e-05, gnorm=1.314, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44649
2022-10-19 07:50:00 - progress_bar.py[line:274] - INFO: epoch 001:   9261 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.7, ups=0.9, wpb=111.5, bsz=40, num_updates=9250, lr=2.26084e-05, gnorm=1.197, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44660
2022-10-19 07:50:11 - progress_bar.py[line:274] - INFO: epoch 001:   9271 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.7, ups=0.88, wpb=111.3, bsz=40, num_updates=9260, lr=2.26328e-05, gnorm=1.372, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44671
2022-10-19 07:50:22 - progress_bar.py[line:274] - INFO: epoch 001:   9281 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=102.1, ups=0.91, wpb=112, bsz=40, num_updates=9270, lr=2.26573e-05, gnorm=1.072, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44682
2022-10-19 07:50:34 - progress_bar.py[line:274] - INFO: epoch 001:   9291 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99, ups=0.9, wpb=109.8, bsz=40, num_updates=9280, lr=2.26817e-05, gnorm=1.122, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44693
2022-10-19 07:50:45 - progress_bar.py[line:274] - INFO: epoch 001:   9301 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100.5, ups=0.91, wpb=110.2, bsz=40, num_updates=9290, lr=2.27062e-05, gnorm=1.211, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44704
2022-10-19 07:50:56 - progress_bar.py[line:274] - INFO: epoch 001:   9311 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.1, ups=0.87, wpb=109.7, bsz=40, num_updates=9300, lr=2.27306e-05, gnorm=1.305, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44716
2022-10-19 07:51:07 - progress_bar.py[line:274] - INFO: epoch 001:   9321 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.573, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=96.8, ups=0.89, wpb=108.5, bsz=40, num_updates=9310, lr=2.2755e-05, gnorm=1.108, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44727
2022-10-19 07:51:18 - progress_bar.py[line:274] - INFO: epoch 001:   9331 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=9320, lr=2.27795e-05, gnorm=1.079, clip=70, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44738
2022-10-19 07:51:30 - progress_bar.py[line:274] - INFO: epoch 001:   9341 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.3, ups=0.89, wpb=110.6, bsz=40, num_updates=9330, lr=2.28039e-05, gnorm=1.114, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=44749
2022-10-19 07:51:41 - progress_bar.py[line:274] - INFO: epoch 001:   9351 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.2, ups=0.87, wpb=110.5, bsz=40, num_updates=9340, lr=2.28284e-05, gnorm=1.281, clip=100, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44761
2022-10-19 07:51:52 - progress_bar.py[line:274] - INFO: epoch 001:   9361 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.1, ups=0.89, wpb=111.2, bsz=40, num_updates=9350, lr=2.28528e-05, gnorm=1.028, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44772
2022-10-19 07:52:03 - progress_bar.py[line:274] - INFO: epoch 001:   9371 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.6, ups=0.9, wpb=110.8, bsz=40, num_updates=9360, lr=2.28773e-05, gnorm=1.121, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44783
2022-10-19 07:52:15 - progress_bar.py[line:274] - INFO: epoch 001:   9381 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.3, ups=0.89, wpb=108.2, bsz=40, num_updates=9370, lr=2.29017e-05, gnorm=1.244, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44794
2022-10-19 07:52:26 - progress_bar.py[line:274] - INFO: epoch 001:   9391 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=9380, lr=2.29261e-05, gnorm=1.207, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44806
2022-10-19 07:52:37 - progress_bar.py[line:274] - INFO: epoch 001:   9401 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=9390, lr=2.29506e-05, gnorm=1.301, clip=80, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=44817
2022-10-19 07:52:48 - progress_bar.py[line:274] - INFO: epoch 001:   9411 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=9400, lr=2.2975e-05, gnorm=1.281, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44828
2022-10-19 07:52:59 - progress_bar.py[line:274] - INFO: epoch 001:   9421 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=104.7, ups=0.95, wpb=110.2, bsz=40, num_updates=9410, lr=2.29995e-05, gnorm=1.051, clip=60, loss_scale=1024, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=44838
2022-10-19 07:53:10 - progress_bar.py[line:274] - INFO: epoch 001:   9431 / 102288 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=99.6, ups=0.91, wpb=109.1, bsz=40, num_updates=9420, lr=2.30239e-05, gnorm=1.365, clip=100, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44849
2022-10-19 07:53:21 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 07:53:22 - progress_bar.py[line:274] - INFO: epoch 001:   9442 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.2, ups=0.83, wpb=110.4, bsz=40, num_updates=9430, lr=2.30483e-05, gnorm=1.096, clip=70, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=44862
2022-10-19 07:53:33 - progress_bar.py[line:274] - INFO: epoch 001:   9452 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.5, ups=0.89, wpb=111.6, bsz=40, num_updates=9440, lr=2.30728e-05, gnorm=1.12, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44873
2022-10-19 07:53:44 - progress_bar.py[line:274] - INFO: epoch 001:   9462 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.5, ups=0.9, wpb=109.6, bsz=40, num_updates=9450, lr=2.30972e-05, gnorm=1.193, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44884
2022-10-19 07:53:56 - progress_bar.py[line:274] - INFO: epoch 001:   9472 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.3, ups=0.88, wpb=111.7, bsz=40, num_updates=9460, lr=2.31217e-05, gnorm=1.006, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44895
2022-10-19 07:54:07 - progress_bar.py[line:274] - INFO: epoch 001:   9482 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.4, ups=0.89, wpb=111, bsz=40, num_updates=9470, lr=2.31461e-05, gnorm=1.024, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44907
2022-10-19 07:54:18 - progress_bar.py[line:274] - INFO: epoch 001:   9492 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=9480, lr=2.31706e-05, gnorm=0.991, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44918
2022-10-19 07:54:29 - progress_bar.py[line:274] - INFO: epoch 001:   9502 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=9490, lr=2.3195e-05, gnorm=1.095, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44929
2022-10-19 07:54:41 - progress_bar.py[line:274] - INFO: epoch 001:   9512 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.3, ups=0.87, wpb=111.1, bsz=40, num_updates=9500, lr=2.32194e-05, gnorm=1.352, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44940
2022-10-19 07:54:51 - progress_bar.py[line:274] - INFO: epoch 001:   9522 / 102288 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=102.4, ups=0.94, wpb=109.2, bsz=40, num_updates=9510, lr=2.32439e-05, gnorm=1.224, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44951
2022-10-19 07:55:02 - progress_bar.py[line:274] - INFO: epoch 001:   9532 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.1, ups=0.92, wpb=110.5, bsz=40, num_updates=9520, lr=2.32683e-05, gnorm=1.227, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44962
2022-10-19 07:55:13 - progress_bar.py[line:274] - INFO: epoch 001:   9542 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.5, ups=0.9, wpb=109.1, bsz=40, num_updates=9530, lr=2.32928e-05, gnorm=1.091, clip=80, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44973
2022-10-19 07:55:25 - progress_bar.py[line:274] - INFO: epoch 001:   9552 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95, ups=0.86, wpb=110.8, bsz=40, num_updates=9540, lr=2.33172e-05, gnorm=1.19, clip=70, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=44985
2022-10-19 07:55:36 - progress_bar.py[line:274] - INFO: epoch 001:   9562 / 102288 loss=0.674, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=9550, lr=2.33416e-05, gnorm=1.184, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44996
2022-10-19 07:55:47 - progress_bar.py[line:274] - INFO: epoch 001:   9572 / 102288 loss=0.668, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=96.7, ups=0.89, wpb=108.6, bsz=40, num_updates=9560, lr=2.33661e-05, gnorm=1.166, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45007
2022-10-19 07:55:59 - progress_bar.py[line:274] - INFO: epoch 001:   9582 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=9570, lr=2.33905e-05, gnorm=1.128, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45018
2022-10-19 07:56:10 - progress_bar.py[line:274] - INFO: epoch 001:   9592 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.1, ups=0.88, wpb=109.3, bsz=40, num_updates=9580, lr=2.3415e-05, gnorm=1.245, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45030
2022-10-19 07:56:21 - progress_bar.py[line:274] - INFO: epoch 001:   9602 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.7, ups=0.91, wpb=111.3, bsz=40, num_updates=9590, lr=2.34394e-05, gnorm=1.126, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45041
2022-10-19 07:56:33 - progress_bar.py[line:274] - INFO: epoch 001:   9612 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=93.7, ups=0.85, wpb=109.7, bsz=40, num_updates=9600, lr=2.34639e-05, gnorm=1.27, clip=80, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=45053
2022-10-19 07:56:44 - progress_bar.py[line:274] - INFO: epoch 001:   9622 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.5, ups=0.9, wpb=111.5, bsz=40, num_updates=9610, lr=2.34883e-05, gnorm=1.204, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45064
2022-10-19 07:56:55 - progress_bar.py[line:274] - INFO: epoch 001:   9632 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.5, ups=0.9, wpb=110.5, bsz=40, num_updates=9620, lr=2.35127e-05, gnorm=1.428, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45075
2022-10-19 07:57:06 - progress_bar.py[line:274] - INFO: epoch 001:   9642 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.8, ups=0.88, wpb=111.6, bsz=40, num_updates=9630, lr=2.35372e-05, gnorm=1.037, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45086
2022-10-19 07:57:18 - progress_bar.py[line:274] - INFO: epoch 001:   9652 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=9640, lr=2.35616e-05, gnorm=1.065, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45097
2022-10-19 07:57:29 - progress_bar.py[line:274] - INFO: epoch 001:   9662 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=96.1, ups=0.88, wpb=109.3, bsz=40, num_updates=9650, lr=2.35861e-05, gnorm=1.143, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45109
2022-10-19 07:57:40 - progress_bar.py[line:274] - INFO: epoch 001:   9672 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=9660, lr=2.36105e-05, gnorm=1.131, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45120
2022-10-19 07:57:52 - progress_bar.py[line:274] - INFO: epoch 001:   9682 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.1, ups=0.88, wpb=111.5, bsz=40, num_updates=9670, lr=2.36349e-05, gnorm=1.147, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45131
2022-10-19 07:58:02 - progress_bar.py[line:274] - INFO: epoch 001:   9692 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.7, ups=0.91, wpb=108.1, bsz=40, num_updates=9680, lr=2.36594e-05, gnorm=1.221, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45142
2022-10-19 07:58:14 - progress_bar.py[line:274] - INFO: epoch 001:   9702 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.7, ups=0.89, wpb=110, bsz=40, num_updates=9690, lr=2.36838e-05, gnorm=1.199, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45153
2022-10-19 07:58:25 - progress_bar.py[line:274] - INFO: epoch 001:   9712 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=9700, lr=2.37083e-05, gnorm=1.102, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45165
2022-10-19 07:58:36 - progress_bar.py[line:274] - INFO: epoch 001:   9722 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=9710, lr=2.37327e-05, gnorm=1.274, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45176
2022-10-19 07:58:47 - progress_bar.py[line:274] - INFO: epoch 001:   9732 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=9720, lr=2.37571e-05, gnorm=1.151, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45187
2022-10-19 07:58:58 - progress_bar.py[line:274] - INFO: epoch 001:   9742 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=9730, lr=2.37816e-05, gnorm=1.139, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45198
2022-10-19 07:59:10 - progress_bar.py[line:274] - INFO: epoch 001:   9752 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.5, ups=0.89, wpb=109.4, bsz=40, num_updates=9740, lr=2.3806e-05, gnorm=1.114, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45209
2022-10-19 07:59:21 - progress_bar.py[line:274] - INFO: epoch 001:   9762 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=95.7, ups=0.87, wpb=110.3, bsz=40, num_updates=9750, lr=2.38305e-05, gnorm=1.143, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45221
2022-10-19 07:59:32 - progress_bar.py[line:274] - INFO: epoch 001:   9772 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=9760, lr=2.38549e-05, gnorm=1.096, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45232
2022-10-19 07:59:43 - progress_bar.py[line:274] - INFO: epoch 001:   9782 / 102288 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.56, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.9, ups=0.9, wpb=108.6, bsz=40, num_updates=9770, lr=2.38794e-05, gnorm=1.106, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45243
2022-10-19 07:59:55 - progress_bar.py[line:274] - INFO: epoch 001:   9792 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.7, ups=0.9, wpb=110.3, bsz=40, num_updates=9780, lr=2.39038e-05, gnorm=1.006, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45254
2022-10-19 08:00:06 - progress_bar.py[line:274] - INFO: epoch 001:   9802 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.5, ups=0.89, wpb=110.8, bsz=40, num_updates=9790, lr=2.39282e-05, gnorm=1.248, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45266
2022-10-19 08:00:17 - progress_bar.py[line:274] - INFO: epoch 001:   9812 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=96.9, ups=0.89, wpb=108.7, bsz=40, num_updates=9800, lr=2.39527e-05, gnorm=1.216, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45277
2022-10-19 08:00:28 - progress_bar.py[line:274] - INFO: epoch 001:   9822 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=103.2, ups=0.93, wpb=111.1, bsz=40, num_updates=9810, lr=2.39771e-05, gnorm=1.013, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45288
2022-10-19 08:00:39 - progress_bar.py[line:274] - INFO: epoch 001:   9832 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.2, ups=0.9, wpb=110, bsz=40, num_updates=9820, lr=2.40016e-05, gnorm=1.063, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45299
2022-10-19 08:00:50 - progress_bar.py[line:274] - INFO: epoch 001:   9842 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=9830, lr=2.4026e-05, gnorm=1.017, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45310
2022-10-19 08:01:01 - progress_bar.py[line:274] - INFO: epoch 001:   9852 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=9840, lr=2.40504e-05, gnorm=1.272, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45321
2022-10-19 08:01:13 - progress_bar.py[line:274] - INFO: epoch 001:   9862 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=9850, lr=2.40749e-05, gnorm=0.989, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45332
2022-10-19 08:01:24 - progress_bar.py[line:274] - INFO: epoch 001:   9872 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=9860, lr=2.40993e-05, gnorm=0.984, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45344
2022-10-19 08:01:35 - progress_bar.py[line:274] - INFO: epoch 001:   9882 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.8, ups=0.88, wpb=108.8, bsz=40, num_updates=9870, lr=2.41238e-05, gnorm=1.074, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45355
2022-10-19 08:01:46 - progress_bar.py[line:274] - INFO: epoch 001:   9892 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=9880, lr=2.41482e-05, gnorm=1.097, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45366
2022-10-19 08:01:57 - progress_bar.py[line:274] - INFO: epoch 001:   9902 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.7, ups=0.92, wpb=110, bsz=40, num_updates=9890, lr=2.41727e-05, gnorm=1.291, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45377
2022-10-19 08:02:09 - progress_bar.py[line:274] - INFO: epoch 001:   9912 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.3, ups=0.87, wpb=109.9, bsz=40, num_updates=9900, lr=2.41971e-05, gnorm=1.216, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45389
2022-10-19 08:02:20 - progress_bar.py[line:274] - INFO: epoch 001:   9922 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.5, ups=0.9, wpb=109.1, bsz=40, num_updates=9910, lr=2.42215e-05, gnorm=1.081, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45400
2022-10-19 08:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   9932 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.1, ups=0.87, wpb=110.4, bsz=40, num_updates=9920, lr=2.4246e-05, gnorm=1.117, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45411
2022-10-19 08:02:42 - progress_bar.py[line:274] - INFO: epoch 001:   9942 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=102.4, ups=0.93, wpb=110.7, bsz=40, num_updates=9930, lr=2.42704e-05, gnorm=1.116, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45422
2022-10-19 08:02:54 - progress_bar.py[line:274] - INFO: epoch 001:   9952 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.7, ups=0.88, wpb=111.2, bsz=40, num_updates=9940, lr=2.42949e-05, gnorm=1.362, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45433
2022-10-19 08:03:05 - progress_bar.py[line:274] - INFO: epoch 001:   9962 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.3, ups=0.88, wpb=110.6, bsz=40, num_updates=9950, lr=2.43193e-05, gnorm=1.25, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45445
2022-10-19 08:03:16 - progress_bar.py[line:274] - INFO: epoch 001:   9972 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=9960, lr=2.43437e-05, gnorm=1.067, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45456
2022-10-19 08:03:27 - progress_bar.py[line:274] - INFO: epoch 001:   9982 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=9970, lr=2.43682e-05, gnorm=1.187, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45467
2022-10-19 08:03:38 - progress_bar.py[line:274] - INFO: epoch 001:   9992 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.9, ups=0.93, wpb=110.1, bsz=40, num_updates=9980, lr=2.43926e-05, gnorm=1.089, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45478
2022-10-19 08:03:50 - progress_bar.py[line:274] - INFO: epoch 001:  10002 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.7, ups=0.88, wpb=111.2, bsz=40, num_updates=9990, lr=2.44171e-05, gnorm=1.087, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45489
2022-10-19 08:04:01 - progress_bar.py[line:274] - INFO: epoch 001:  10012 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.2, ups=0.88, wpb=110.8, bsz=40, num_updates=10000, lr=2.44415e-05, gnorm=1.148, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45501
2022-10-19 08:04:01 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 08:04:03 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 08:04:03 - train.py[line:551] - INFO: load:1.32 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 08:06:34 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 08:06:34 - train.py[line:551] - INFO: load:1.34 valid_run:151.64 task_valid:148.20 collect_output:2.43
2022-10-19 08:09:03 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 08:09:03 - train.py[line:551] - INFO: load:1.37 valid_run:300.25 task_valid:291.38 collect_output:6.85
2022-10-19 08:11:36 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 08:11:36 - train.py[line:551] - INFO: load:1.39 valid_run:452.87 task_valid:434.71 collect_output:15.14
2022-10-19 08:14:05 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 08:14:05 - train.py[line:551] - INFO: load:1.42 valid_run:602.41 task_valid:579.70 collect_output:18.69
2022-10-19 08:16:38 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 08:16:38 - train.py[line:551] - INFO: load:1.44 valid_run:754.93 task_valid:727.17 collect_output:22.71
2022-10-19 08:19:10 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 08:19:10 - train.py[line:551] - INFO: load:1.47 valid_run:906.94 task_valid:873.03 collect_output:27.84
2022-10-19 08:21:44 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 08:21:44 - train.py[line:551] - INFO: load:1.49 valid_run:1060.60 task_valid:1019.20 collect_output:34.33
2022-10-19 08:24:15 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 08:24:15 - train.py[line:551] - INFO: load:1.52 valid_run:1212.32 task_valid:1160.34 collect_output:43.92
2022-10-19 08:26:45 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 08:26:45 - train.py[line:551] - INFO: load:1.54 valid_run:1362.19 task_valid:1305.23 collect_output:47.88
2022-10-19 08:29:15 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 08:29:15 - train.py[line:551] - INFO: load:1.57 valid_run:1511.47 task_valid:1448.94 collect_output:52.35
2022-10-19 08:31:45 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 08:31:45 - train.py[line:551] - INFO: load:1.59 valid_run:1661.65 task_valid:1594.06 collect_output:56.38
2022-10-19 08:34:16 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 08:34:16 - train.py[line:551] - INFO: load:1.62 valid_run:1812.30 task_valid:1739.28 collect_output:60.80
2022-10-19 08:36:46 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 08:36:46 - train.py[line:551] - INFO: load:1.64 valid_run:1962.94 task_valid:1881.40 collect_output:68.26
2022-10-19 08:39:18 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 08:39:18 - train.py[line:551] - INFO: load:1.67 valid_run:2114.04 task_valid:2027.40 collect_output:72.35
2022-10-19 08:41:48 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 08:41:48 - train.py[line:551] - INFO: load:1.69 valid_run:2264.51 task_valid:2174.03 collect_output:75.11
2022-10-19 08:44:19 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 08:44:19 - train.py[line:551] - INFO: load:1.72 valid_run:2415.04 task_valid:2318.60 collect_output:80.04
2022-10-19 08:46:51 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 08:46:51 - train.py[line:551] - INFO: load:1.74 valid_run:2567.67 task_valid:2464.36 collect_output:85.87
2022-10-19 08:49:23 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 08:49:23 - train.py[line:551] - INFO: load:1.77 valid_run:2719.02 task_valid:2611.90 collect_output:88.59
2022-10-19 08:51:52 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 08:51:52 - train.py[line:551] - INFO: load:1.80 valid_run:2868.00 task_valid:2753.65 collect_output:94.75
2022-10-19 08:54:23 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 08:54:23 - train.py[line:551] - INFO: load:1.82 valid_run:3019.04 task_valid:2899.11 collect_output:99.26
2022-10-19 08:56:56 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 08:56:56 - train.py[line:551] - INFO: load:1.85 valid_run:3171.89 task_valid:3043.83 collect_output:106.35
2022-10-19 08:59:25 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 08:59:25 - train.py[line:551] - INFO: load:1.87 valid_run:3321.47 task_valid:3188.37 collect_output:110.37
2022-10-19 09:01:57 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 09:01:57 - train.py[line:551] - INFO: load:1.90 valid_run:3473.24 task_valid:3334.71 collect_output:114.77
2022-10-19 09:04:29 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 09:04:29 - train.py[line:551] - INFO: load:1.93 valid_run:3624.98 task_valid:3481.31 collect_output:118.92

====================================================================================================
SGG eval:     R @ 50: 0.5499;     R @ 100: 0.5733;     R @ 500: 0.6073;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3913;    mR @ 100: 0.4202;    mR @ 500: 0.4512;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5366) (covered in:0.8750) (covering:0.2857) (eating:0.7353) (flying in:1.0000) (growing on:0.3750) (hanging from:0.2903) (lying on:0.1500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9048) (playing:0.0000) (riding:0.9134) (says:0.0000) (sitting on:0.7132) (standing on:0.1100) (using:0.4000) (walking in:0.0000) (walking on:0.8378) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5499;     R @ 100: 0.5733;     R @ 500: 0.6073;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3913;    mR @ 100: 0.4202;    mR @ 500: 0.4512;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5366) (covered in:0.8750) (covering:0.2857) (eating:0.7353) (flying in:1.0000) (growing on:0.3750) (hanging from:0.2903) (lying on:0.1500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9048) (playing:0.0000) (riding:0.9134) (says:0.0000) (sitting on:0.7132) (standing on:0.1100) (using:0.4000) (walking in:0.0000) (walking on:0.8378) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2022-10-19 09:07:00 - train.py[line:487] - INFO: 0.5732666666666667
2022-10-19 09:07:00 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 09:07:03 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.346 | loss_v1 0 | loss_v2 0 | nll_loss 0.193 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.573267 | ppl 1.14 | vqa_score 0.4572 | wps 118.7 | wpb 89.9 | bsz 30 | num_updates 10000 | best_R@100 0.573267
2022-10-19 09:07:03 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2022-10-19 09:07:03 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_10000.pt
2022-10-19 09:07:09 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_10000.pt
2022-10-19 09:07:14 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.5732666666666667) (writing took 11.372132862918079 seconds)
2022-10-19 09:07:26 - progress_bar.py[line:274] - INFO: epoch 001:  10022 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=0.3, ups=0, wpb=111.6, bsz=40, num_updates=10010, lr=2.4466e-05, gnorm=1.165, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49305
2022-10-19 09:07:37 - progress_bar.py[line:274] - INFO: epoch 001:  10032 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=10020, lr=2.44904e-05, gnorm=1.105, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=49317
2022-10-19 09:07:44 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 09:07:49 - progress_bar.py[line:274] - INFO: epoch 001:  10043 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=92.1, ups=0.84, wpb=110.2, bsz=40, num_updates=10030, lr=2.45148e-05, gnorm=1.054, clip=60, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=49329
2022-10-19 09:08:00 - progress_bar.py[line:274] - INFO: epoch 001:  10053 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.9, ups=0.89, wpb=112.3, bsz=40, num_updates=10040, lr=2.45393e-05, gnorm=1.22, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49340
2022-10-19 09:08:11 - progress_bar.py[line:274] - INFO: epoch 001:  10063 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=10050, lr=2.45637e-05, gnorm=1.023, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49351
2022-10-19 09:08:22 - progress_bar.py[line:274] - INFO: epoch 001:  10073 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.9, ups=0.89, wpb=110.2, bsz=40, num_updates=10060, lr=2.45882e-05, gnorm=1.179, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49362
2022-10-19 09:08:33 - progress_bar.py[line:274] - INFO: epoch 001:  10083 / 102288 loss=0.678, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=10070, lr=2.46126e-05, gnorm=1.202, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49373
2022-10-19 09:08:45 - progress_bar.py[line:274] - INFO: epoch 001:  10093 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=10080, lr=2.4637e-05, gnorm=1.13, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49385
2022-10-19 09:08:56 - progress_bar.py[line:274] - INFO: epoch 001:  10103 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=10090, lr=2.46615e-05, gnorm=1.269, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49396
2022-10-19 09:09:07 - progress_bar.py[line:274] - INFO: epoch 001:  10113 / 102288 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.554, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.6, ups=0.9, wpb=109.4, bsz=40, num_updates=10100, lr=2.46859e-05, gnorm=1.233, clip=70, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=49407
2022-10-19 09:09:18 - progress_bar.py[line:274] - INFO: epoch 001:  10123 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.6, ups=0.92, wpb=110.8, bsz=40, num_updates=10110, lr=2.47104e-05, gnorm=1.037, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49418
2022-10-19 09:09:29 - progress_bar.py[line:274] - INFO: epoch 001:  10133 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=10120, lr=2.47348e-05, gnorm=1.13, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49429
2022-10-19 09:09:41 - progress_bar.py[line:274] - INFO: epoch 001:  10143 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=10130, lr=2.47593e-05, gnorm=1.214, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49440
2022-10-19 09:09:52 - progress_bar.py[line:274] - INFO: epoch 001:  10153 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.8, ups=0.9, wpb=111.6, bsz=40, num_updates=10140, lr=2.47837e-05, gnorm=1.023, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49451
2022-10-19 09:10:03 - progress_bar.py[line:274] - INFO: epoch 001:  10163 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.9, ups=0.89, wpb=111.2, bsz=40, num_updates=10150, lr=2.48081e-05, gnorm=1.055, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49463
2022-10-19 09:10:14 - progress_bar.py[line:274] - INFO: epoch 001:  10173 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97, ups=0.89, wpb=109.1, bsz=40, num_updates=10160, lr=2.48326e-05, gnorm=1.233, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49474
2022-10-19 09:10:25 - progress_bar.py[line:274] - INFO: epoch 001:  10183 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.6, ups=0.93, wpb=109.8, bsz=40, num_updates=10170, lr=2.4857e-05, gnorm=1.21, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49485
2022-10-19 09:10:37 - progress_bar.py[line:274] - INFO: epoch 001:  10193 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.5, ups=0.87, wpb=111.3, bsz=40, num_updates=10180, lr=2.48815e-05, gnorm=1.107, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49496
2022-10-19 09:10:48 - progress_bar.py[line:274] - INFO: epoch 001:  10203 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=10190, lr=2.49059e-05, gnorm=1.186, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49508
2022-10-19 09:10:59 - progress_bar.py[line:274] - INFO: epoch 001:  10213 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=10200, lr=2.49303e-05, gnorm=1.03, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49519
2022-10-19 09:11:10 - progress_bar.py[line:274] - INFO: epoch 001:  10223 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.3, ups=0.89, wpb=109.5, bsz=40, num_updates=10210, lr=2.49548e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49530
2022-10-19 09:11:21 - progress_bar.py[line:274] - INFO: epoch 001:  10233 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.7, ups=0.9, wpb=109.4, bsz=40, num_updates=10220, lr=2.49792e-05, gnorm=1.056, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49541
2022-10-19 09:11:33 - progress_bar.py[line:274] - INFO: epoch 001:  10243 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=10230, lr=2.50037e-05, gnorm=1.061, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49552
2022-10-19 09:11:44 - progress_bar.py[line:274] - INFO: epoch 001:  10253 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.9, ups=0.89, wpb=108.6, bsz=40, num_updates=10240, lr=2.50281e-05, gnorm=1.046, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49564
2022-10-19 09:11:55 - progress_bar.py[line:274] - INFO: epoch 001:  10263 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=10250, lr=2.50525e-05, gnorm=1.239, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49575
2022-10-19 09:12:06 - progress_bar.py[line:274] - INFO: epoch 001:  10273 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.3, ups=0.9, wpb=110, bsz=40, num_updates=10260, lr=2.5077e-05, gnorm=1.192, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49586
2022-10-19 09:12:17 - progress_bar.py[line:274] - INFO: epoch 001:  10283 / 102288 loss=0.65, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96, ups=0.88, wpb=109.2, bsz=40, num_updates=10270, lr=2.51014e-05, gnorm=1.02, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49597
2022-10-19 09:12:29 - progress_bar.py[line:274] - INFO: epoch 001:  10293 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.1, ups=0.89, wpb=109, bsz=40, num_updates=10280, lr=2.51259e-05, gnorm=1.04, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49608
2022-10-19 09:12:40 - progress_bar.py[line:274] - INFO: epoch 001:  10303 / 102288 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=95.7, ups=0.88, wpb=108.9, bsz=40, num_updates=10290, lr=2.51503e-05, gnorm=1.151, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49620
2022-10-19 09:12:51 - progress_bar.py[line:274] - INFO: epoch 001:  10313 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=10300, lr=2.51748e-05, gnorm=1.132, clip=60, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=49631
2022-10-19 09:13:02 - progress_bar.py[line:274] - INFO: epoch 001:  10323 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.5, ups=0.9, wpb=109.1, bsz=40, num_updates=10310, lr=2.51992e-05, gnorm=1.219, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49642
2022-10-19 09:13:13 - progress_bar.py[line:274] - INFO: epoch 001:  10333 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101.6, ups=0.91, wpb=111.2, bsz=40, num_updates=10320, lr=2.52236e-05, gnorm=1.196, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49653
2022-10-19 09:13:24 - progress_bar.py[line:274] - INFO: epoch 001:  10343 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=10330, lr=2.52481e-05, gnorm=0.998, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49664
2022-10-19 09:13:36 - progress_bar.py[line:274] - INFO: epoch 001:  10353 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.4, ups=0.9, wpb=110.5, bsz=40, num_updates=10340, lr=2.52725e-05, gnorm=1.034, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49675
2022-10-19 09:13:47 - progress_bar.py[line:274] - INFO: epoch 001:  10363 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=10350, lr=2.5297e-05, gnorm=1.237, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49686
2022-10-19 09:13:58 - progress_bar.py[line:274] - INFO: epoch 001:  10373 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.8, ups=0.89, wpb=111.3, bsz=40, num_updates=10360, lr=2.53214e-05, gnorm=1.206, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49698
2022-10-19 09:14:09 - progress_bar.py[line:274] - INFO: epoch 001:  10383 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.1, ups=0.88, wpb=109.5, bsz=40, num_updates=10370, lr=2.53458e-05, gnorm=1.131, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49709
2022-10-19 09:14:20 - progress_bar.py[line:274] - INFO: epoch 001:  10393 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=105.5, ups=0.94, wpb=111.8, bsz=40, num_updates=10380, lr=2.53703e-05, gnorm=1.149, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49720
2022-10-19 09:14:31 - progress_bar.py[line:274] - INFO: epoch 001:  10403 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=10390, lr=2.53947e-05, gnorm=1.011, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49731
2022-10-19 09:14:42 - progress_bar.py[line:274] - INFO: epoch 001:  10413 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.4, ups=0.9, wpb=109.8, bsz=40, num_updates=10400, lr=2.54192e-05, gnorm=1.127, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49742
2022-10-19 09:14:53 - progress_bar.py[line:274] - INFO: epoch 001:  10423 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.4, ups=0.9, wpb=111.2, bsz=40, num_updates=10410, lr=2.54436e-05, gnorm=1.033, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49753
2022-10-19 09:15:04 - progress_bar.py[line:274] - INFO: epoch 001:  10433 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=10420, lr=2.54681e-05, gnorm=0.969, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49764
2022-10-19 09:15:16 - progress_bar.py[line:274] - INFO: epoch 001:  10443 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.5, ups=0.87, wpb=111, bsz=40, num_updates=10430, lr=2.54925e-05, gnorm=0.986, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49776
2022-10-19 09:15:27 - progress_bar.py[line:274] - INFO: epoch 001:  10453 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.6, ups=0.91, wpb=109, bsz=40, num_updates=10440, lr=2.55169e-05, gnorm=1.099, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49787
2022-10-19 09:15:38 - progress_bar.py[line:274] - INFO: epoch 001:  10463 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.1, ups=0.87, wpb=111.6, bsz=40, num_updates=10450, lr=2.55414e-05, gnorm=1.174, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49798
2022-10-19 09:15:49 - progress_bar.py[line:274] - INFO: epoch 001:  10473 / 102288 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=10460, lr=2.55658e-05, gnorm=1.289, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49809
2022-10-19 09:16:01 - progress_bar.py[line:274] - INFO: epoch 001:  10483 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.2, ups=0.9, wpb=111.2, bsz=40, num_updates=10470, lr=2.55903e-05, gnorm=0.955, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49820
2022-10-19 09:16:12 - progress_bar.py[line:274] - INFO: epoch 001:  10493 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102, ups=0.91, wpb=111.7, bsz=40, num_updates=10480, lr=2.56147e-05, gnorm=1.043, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49831
2022-10-19 09:16:23 - progress_bar.py[line:274] - INFO: epoch 001:  10503 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.2, ups=0.89, wpb=109.3, bsz=40, num_updates=10490, lr=2.56391e-05, gnorm=1.037, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49843
2022-10-19 09:16:34 - progress_bar.py[line:274] - INFO: epoch 001:  10513 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.5, ups=0.88, wpb=108.6, bsz=40, num_updates=10500, lr=2.56636e-05, gnorm=1.116, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49854
2022-10-19 09:16:45 - progress_bar.py[line:274] - INFO: epoch 001:  10523 / 102288 loss=0.659, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.5, ups=0.91, wpb=107.8, bsz=40, num_updates=10510, lr=2.5688e-05, gnorm=1.244, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49865
2022-10-19 09:16:56 - progress_bar.py[line:274] - INFO: epoch 001:  10533 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98, ups=0.89, wpb=110.5, bsz=40, num_updates=10520, lr=2.57125e-05, gnorm=1.143, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=49876
2022-10-19 09:17:08 - progress_bar.py[line:274] - INFO: epoch 001:  10543 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=10530, lr=2.57369e-05, gnorm=1.199, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49887
2022-10-19 09:17:18 - progress_bar.py[line:274] - INFO: epoch 001:  10553 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=104.1, ups=0.95, wpb=109.4, bsz=40, num_updates=10540, lr=2.57614e-05, gnorm=1.139, clip=80, loss_scale=1024, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=49898
2022-10-19 09:17:29 - progress_bar.py[line:274] - INFO: epoch 001:  10563 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102.9, ups=0.93, wpb=111, bsz=40, num_updates=10550, lr=2.57858e-05, gnorm=1.142, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49909
2022-10-19 09:17:40 - progress_bar.py[line:274] - INFO: epoch 001:  10573 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.1, ups=0.9, wpb=109.9, bsz=40, num_updates=10560, lr=2.58102e-05, gnorm=1.094, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49920
2022-10-19 09:17:51 - progress_bar.py[line:274] - INFO: epoch 001:  10583 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=10570, lr=2.58347e-05, gnorm=1.1, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49931
2022-10-19 09:18:02 - progress_bar.py[line:274] - INFO: epoch 001:  10593 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.5, ups=0.91, wpb=111.1, bsz=40, num_updates=10580, lr=2.58591e-05, gnorm=1.221, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49942
2022-10-19 09:18:13 - progress_bar.py[line:274] - INFO: epoch 001:  10603 / 102288 loss=0.665, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=10590, lr=2.58836e-05, gnorm=1.145, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49953
2022-10-19 09:18:24 - progress_bar.py[line:274] - INFO: epoch 001:  10613 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102.9, ups=0.93, wpb=111, bsz=40, num_updates=10600, lr=2.5908e-05, gnorm=1.072, clip=80, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49964
2022-10-19 09:18:35 - progress_bar.py[line:274] - INFO: epoch 001:  10623 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.7, ups=0.91, wpb=109.1, bsz=40, num_updates=10610, lr=2.59324e-05, gnorm=1.225, clip=80, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49975
2022-10-19 09:18:46 - progress_bar.py[line:274] - INFO: epoch 001:  10633 / 102288 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=10620, lr=2.59569e-05, gnorm=1.073, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49986
2022-10-19 09:18:57 - progress_bar.py[line:274] - INFO: epoch 001:  10643 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=10630, lr=2.59813e-05, gnorm=1.06, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49997
2022-10-19 09:19:08 - progress_bar.py[line:274] - INFO: epoch 001:  10653 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101, ups=0.9, wpb=112, bsz=40, num_updates=10640, lr=2.60058e-05, gnorm=1.056, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50008
2022-10-19 09:19:20 - progress_bar.py[line:274] - INFO: epoch 001:  10663 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=10650, lr=2.60302e-05, gnorm=1.113, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50019
2022-10-19 09:19:31 - progress_bar.py[line:274] - INFO: epoch 001:  10673 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=10660, lr=2.60547e-05, gnorm=1.159, clip=70, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50031
2022-10-19 09:19:42 - progress_bar.py[line:274] - INFO: epoch 001:  10683 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.2, ups=0.89, wpb=110.6, bsz=40, num_updates=10670, lr=2.60791e-05, gnorm=1.117, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50042
2022-10-19 09:19:53 - progress_bar.py[line:274] - INFO: epoch 001:  10693 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=10680, lr=2.61035e-05, gnorm=1.061, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50053
2022-10-19 09:20:05 - progress_bar.py[line:274] - INFO: epoch 001:  10703 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.1, ups=0.9, wpb=111.9, bsz=40, num_updates=10690, lr=2.6128e-05, gnorm=1.15, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50064
2022-10-19 09:20:15 - progress_bar.py[line:274] - INFO: epoch 001:  10713 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.8, ups=0.91, wpb=110.3, bsz=40, num_updates=10700, lr=2.61524e-05, gnorm=1.178, clip=80, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=50075
2022-10-19 09:20:27 - progress_bar.py[line:274] - INFO: epoch 001:  10723 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.9, ups=0.88, wpb=110.3, bsz=40, num_updates=10710, lr=2.61769e-05, gnorm=0.997, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50087
2022-10-19 09:20:38 - progress_bar.py[line:274] - INFO: epoch 001:  10733 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=10720, lr=2.62013e-05, gnorm=1.053, clip=80, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=50098
2022-10-19 09:20:49 - progress_bar.py[line:274] - INFO: epoch 001:  10743 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.3, ups=0.91, wpb=109.6, bsz=40, num_updates=10730, lr=2.62257e-05, gnorm=1.027, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50109
2022-10-19 09:21:00 - progress_bar.py[line:274] - INFO: epoch 001:  10753 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=10740, lr=2.62502e-05, gnorm=1.3, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50120
2022-10-19 09:21:12 - progress_bar.py[line:274] - INFO: epoch 001:  10763 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.3, ups=0.87, wpb=111, bsz=40, num_updates=10750, lr=2.62746e-05, gnorm=1.214, clip=80, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50132
2022-10-19 09:21:23 - progress_bar.py[line:274] - INFO: epoch 001:  10773 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.2, ups=0.89, wpb=109.4, bsz=40, num_updates=10760, lr=2.62991e-05, gnorm=1.09, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50143
2022-10-19 09:21:27 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 09:21:35 - progress_bar.py[line:274] - INFO: epoch 001:  10784 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=91.6, ups=0.83, wpb=109.7, bsz=40, num_updates=10770, lr=2.63235e-05, gnorm=1.085, clip=60, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=50155
2022-10-19 09:21:46 - progress_bar.py[line:274] - INFO: epoch 001:  10794 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.8, ups=0.9, wpb=111.8, bsz=40, num_updates=10780, lr=2.63479e-05, gnorm=1.139, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50166
2022-10-19 09:21:57 - progress_bar.py[line:274] - INFO: epoch 001:  10804 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=10790, lr=2.63724e-05, gnorm=1.045, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50177
2022-10-19 09:22:08 - progress_bar.py[line:274] - INFO: epoch 001:  10814 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.1, ups=0.91, wpb=110.5, bsz=40, num_updates=10800, lr=2.63968e-05, gnorm=0.961, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50188
2022-10-19 09:22:20 - progress_bar.py[line:274] - INFO: epoch 001:  10824 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.5, ups=0.87, wpb=110.1, bsz=40, num_updates=10810, lr=2.64213e-05, gnorm=1.194, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50200
2022-10-19 09:22:31 - progress_bar.py[line:274] - INFO: epoch 001:  10834 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.1, ups=0.87, wpb=109.6, bsz=40, num_updates=10820, lr=2.64457e-05, gnorm=1.211, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50211
2022-10-19 09:22:42 - progress_bar.py[line:274] - INFO: epoch 001:  10844 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.2, ups=0.9, wpb=110, bsz=40, num_updates=10830, lr=2.64702e-05, gnorm=1.142, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50222
2022-10-19 09:22:54 - progress_bar.py[line:274] - INFO: epoch 001:  10854 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=10840, lr=2.64946e-05, gnorm=1.158, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50234
2022-10-19 09:23:04 - progress_bar.py[line:274] - INFO: epoch 001:  10864 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=103.8, ups=0.94, wpb=110.6, bsz=40, num_updates=10850, lr=2.6519e-05, gnorm=1.068, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50244
2022-10-19 09:23:16 - progress_bar.py[line:274] - INFO: epoch 001:  10874 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=10860, lr=2.65435e-05, gnorm=1.095, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50255
2022-10-19 09:23:26 - progress_bar.py[line:274] - INFO: epoch 001:  10884 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=102.8, ups=0.93, wpb=110.7, bsz=40, num_updates=10870, lr=2.65679e-05, gnorm=1.123, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50266
2022-10-19 09:23:38 - progress_bar.py[line:274] - INFO: epoch 001:  10894 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=10880, lr=2.65924e-05, gnorm=1.036, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50278
2022-10-19 09:23:49 - progress_bar.py[line:274] - INFO: epoch 001:  10904 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102.2, ups=0.92, wpb=111.6, bsz=40, num_updates=10890, lr=2.66168e-05, gnorm=1.202, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50289
2022-10-19 09:24:00 - progress_bar.py[line:274] - INFO: epoch 001:  10914 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=10900, lr=2.66412e-05, gnorm=1.105, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50300
2022-10-19 09:24:11 - progress_bar.py[line:274] - INFO: epoch 001:  10924 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=10910, lr=2.66657e-05, gnorm=1.132, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50311
2022-10-19 09:24:23 - progress_bar.py[line:274] - INFO: epoch 001:  10934 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.528, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=10920, lr=2.66901e-05, gnorm=1.117, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50322
2022-10-19 09:24:34 - progress_bar.py[line:274] - INFO: epoch 001:  10944 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=10930, lr=2.67146e-05, gnorm=1.159, clip=70, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=50333
2022-10-19 09:24:45 - progress_bar.py[line:274] - INFO: epoch 001:  10954 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.7, ups=0.88, wpb=111.1, bsz=40, num_updates=10940, lr=2.6739e-05, gnorm=1.123, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50345
2022-10-19 09:24:56 - progress_bar.py[line:274] - INFO: epoch 001:  10964 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=103.8, ups=0.94, wpb=110.6, bsz=40, num_updates=10950, lr=2.67635e-05, gnorm=1.411, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50355
2022-10-19 09:25:07 - progress_bar.py[line:274] - INFO: epoch 001:  10974 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.9, ups=0.89, wpb=109.1, bsz=40, num_updates=10960, lr=2.67879e-05, gnorm=1.022, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50367
2022-10-19 09:25:18 - progress_bar.py[line:274] - INFO: epoch 001:  10984 / 102288 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.4, ups=0.88, wpb=108.8, bsz=40, num_updates=10970, lr=2.68123e-05, gnorm=1.182, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50378
2022-10-19 09:25:30 - progress_bar.py[line:274] - INFO: epoch 001:  10994 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.6, ups=0.88, wpb=110.3, bsz=40, num_updates=10980, lr=2.68368e-05, gnorm=0.981, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50390
2022-10-19 09:25:41 - progress_bar.py[line:274] - INFO: epoch 001:  11004 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=10990, lr=2.68612e-05, gnorm=1.162, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50401
2022-10-19 09:25:53 - progress_bar.py[line:274] - INFO: epoch 001:  11014 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.7, ups=0.88, wpb=111.2, bsz=40, num_updates=11000, lr=2.68857e-05, gnorm=1.09, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50412
2022-10-19 09:25:53 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 09:25:54 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 09:25:54 - train.py[line:551] - INFO: load:1.01 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 09:28:26 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 09:28:26 - train.py[line:551] - INFO: load:1.04 valid_run:151.77 task_valid:148.03 collect_output:2.72
2022-10-19 09:30:54 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 09:30:54 - train.py[line:551] - INFO: load:1.06 valid_run:300.39 task_valid:291.11 collect_output:7.23
2022-10-19 09:33:27 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 09:33:27 - train.py[line:551] - INFO: load:1.09 valid_run:453.15 task_valid:434.38 collect_output:15.71
2022-10-19 09:35:57 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 09:35:57 - train.py[line:551] - INFO: load:1.11 valid_run:602.51 task_valid:579.42 collect_output:19.02
2022-10-19 09:38:29 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 09:38:29 - train.py[line:551] - INFO: load:1.14 valid_run:755.16 task_valid:726.93 collect_output:23.16
2022-10-19 09:41:01 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 09:41:01 - train.py[line:551] - INFO: load:1.16 valid_run:907.18 task_valid:872.43 collect_output:28.62
2022-10-19 09:43:36 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 09:43:36 - train.py[line:551] - INFO: load:1.19 valid_run:1061.23 task_valid:1018.77 collect_output:35.21
2022-10-19 09:46:08 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 09:46:08 - train.py[line:551] - INFO: load:1.21 valid_run:1213.32 task_valid:1160.38 collect_output:44.63
2022-10-19 09:48:38 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 09:48:38 - train.py[line:551] - INFO: load:1.24 valid_run:1363.44 task_valid:1305.50 collect_output:48.55
2022-10-19 09:51:07 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 09:51:07 - train.py[line:551] - INFO: load:1.28 valid_run:1512.88 task_valid:1449.13 collect_output:53.25
2022-10-19 09:53:38 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 09:53:38 - train.py[line:551] - INFO: load:1.30 valid_run:1663.15 task_valid:1594.26 collect_output:57.30
2022-10-19 09:56:08 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 09:56:08 - train.py[line:551] - INFO: load:1.33 valid_run:1813.88 task_valid:1739.71 collect_output:61.50
2022-10-19 09:58:39 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 09:58:39 - train.py[line:551] - INFO: load:1.35 valid_run:1964.51 task_valid:1881.84 collect_output:68.93
2022-10-19 10:01:10 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 10:01:10 - train.py[line:551] - INFO: load:1.38 valid_run:2115.71 task_valid:2027.63 collect_output:73.23
2022-10-19 10:03:41 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 10:03:41 - train.py[line:551] - INFO: load:1.40 valid_run:2266.30 task_valid:2174.44 collect_output:75.93
2022-10-19 10:06:12 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 10:06:12 - train.py[line:551] - INFO: load:1.43 valid_run:2417.31 task_valid:2319.18 collect_output:81.13
2022-10-19 10:08:45 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 10:08:45 - train.py[line:551] - INFO: load:1.45 valid_run:2569.70 task_valid:2465.00 collect_output:86.64
2022-10-19 10:11:16 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 10:11:16 - train.py[line:551] - INFO: load:1.48 valid_run:2720.55 task_valid:2612.14 collect_output:89.32
2022-10-19 10:13:44 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 10:13:44 - train.py[line:551] - INFO: load:1.51 valid_run:2869.37 task_valid:2753.69 collect_output:95.58
2022-10-19 10:16:15 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 10:16:15 - train.py[line:551] - INFO: load:1.53 valid_run:3020.36 task_valid:2898.83 collect_output:100.43
2022-10-19 10:18:48 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 10:18:48 - train.py[line:551] - INFO: load:1.56 valid_run:3173.10 task_valid:3043.68 collect_output:107.30
2022-10-19 10:21:18 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 10:21:18 - train.py[line:551] - INFO: load:1.58 valid_run:3322.81 task_valid:3188.27 collect_output:111.41
2022-10-19 10:23:50 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 10:23:50 - train.py[line:551] - INFO: load:1.61 valid_run:3474.35 task_valid:3334.38 collect_output:115.85
2022-10-19 10:26:22 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 10:26:22 - train.py[line:551] - INFO: load:1.64 valid_run:3626.44 task_valid:3480.94 collect_output:120.31

====================================================================================================
SGG eval:     R @ 50: 0.5493;     R @ 100: 0.5870;     R @ 500: 0.6141;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3803;    mR @ 100: 0.4172;    mR @ 500: 0.4558;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5854) (covered in:0.8750) (covering:0.2857) (eating:0.7647) (flying in:0.5909) (growing on:0.3750) (hanging from:0.2839) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.9167) (says:0.0000) (sitting on:0.7120) (standing on:0.1300) (using:0.5000) (walking in:0.0000) (walking on:0.8378) (watching:0.3194) 
--------------------------------------------------------
====================================================================================================

2022-10-19 10:28:53 - train.py[line:487] - INFO: 0.5869683982683982

====================================================================================================
SGG eval:     R @ 50: 0.5493;     R @ 100: 0.5870;     R @ 500: 0.6141;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3803;    mR @ 100: 0.4172;    mR @ 500: 0.4558;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5854) (covered in:0.8750) (covering:0.2857) (eating:0.7647) (flying in:0.5909) (growing on:0.3750) (hanging from:0.2839) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.9167) (says:0.0000) (sitting on:0.7120) (standing on:0.1300) (using:0.5000) (walking in:0.0000) (walking on:0.8378) (watching:0.3194) 
--------------------------------------------------------
====================================================================================================

2022-10-19 10:28:53 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 10:28:53 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.338 | loss_v1 0 | loss_v2 0 | nll_loss 0.182 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.586968 | ppl 1.13 | vqa_score 0.473 | wps 118.7 | wpb 89.9 | bsz 30 | num_updates 11000 | best_R@100 0.586968
2022-10-19 10:28:53 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 11000 updates
2022-10-19 10:28:53 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_11000.pt
2022-10-19 10:28:59 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_11000.pt
2022-10-19 10:29:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 0.5869683982683982) (writing took 11.390611767303199 seconds)
2022-10-19 10:29:16 - progress_bar.py[line:274] - INFO: epoch 001:  11024 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=0.3, ups=0, wpb=110.2, bsz=40, num_updates=11010, lr=2.69101e-05, gnorm=1.229, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54216
2022-10-19 10:29:27 - progress_bar.py[line:274] - INFO: epoch 001:  11034 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=11020, lr=2.69345e-05, gnorm=1.026, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54227
2022-10-19 10:29:38 - progress_bar.py[line:274] - INFO: epoch 001:  11044 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=11030, lr=2.6959e-05, gnorm=1.158, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54238
2022-10-19 10:29:50 - progress_bar.py[line:274] - INFO: epoch 001:  11054 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=11040, lr=2.69834e-05, gnorm=1.124, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54249
2022-10-19 10:30:00 - progress_bar.py[line:274] - INFO: epoch 001:  11064 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.6, ups=0.91, wpb=111.2, bsz=40, num_updates=11050, lr=2.70079e-05, gnorm=1.12, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54260
2022-10-19 10:30:12 - progress_bar.py[line:274] - INFO: epoch 001:  11074 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.6, ups=0.9, wpb=111.7, bsz=40, num_updates=11060, lr=2.70323e-05, gnorm=1.159, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54271
2022-10-19 10:30:22 - progress_bar.py[line:274] - INFO: epoch 001:  11084 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102.5, ups=0.92, wpb=111, bsz=40, num_updates=11070, lr=2.70568e-05, gnorm=1.173, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=54282
2022-10-19 10:30:33 - progress_bar.py[line:274] - INFO: epoch 001:  11094 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.4, ups=0.92, wpb=109.7, bsz=40, num_updates=11080, lr=2.70812e-05, gnorm=1.182, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54293
2022-10-19 10:30:45 - progress_bar.py[line:274] - INFO: epoch 001:  11104 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.8, ups=0.89, wpb=108.7, bsz=40, num_updates=11090, lr=2.71056e-05, gnorm=1.153, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54304
2022-10-19 10:30:56 - progress_bar.py[line:274] - INFO: epoch 001:  11114 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.8, ups=0.89, wpb=110.3, bsz=40, num_updates=11100, lr=2.71301e-05, gnorm=1.26, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54316
2022-10-19 10:31:07 - progress_bar.py[line:274] - INFO: epoch 001:  11124 / 102288 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.9, ups=0.9, wpb=110.4, bsz=40, num_updates=11110, lr=2.71545e-05, gnorm=1.049, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54327
2022-10-19 10:31:18 - progress_bar.py[line:274] - INFO: epoch 001:  11134 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=11120, lr=2.7179e-05, gnorm=1.093, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54338
2022-10-19 10:31:29 - progress_bar.py[line:274] - INFO: epoch 001:  11144 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.9, ups=0.89, wpb=108.8, bsz=40, num_updates=11130, lr=2.72034e-05, gnorm=1.113, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54349
2022-10-19 10:31:40 - progress_bar.py[line:274] - INFO: epoch 001:  11154 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=11140, lr=2.72278e-05, gnorm=1.163, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54360
2022-10-19 10:31:52 - progress_bar.py[line:274] - INFO: epoch 001:  11164 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.7, ups=0.9, wpb=109.3, bsz=40, num_updates=11150, lr=2.72523e-05, gnorm=1.143, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54371
2022-10-19 10:32:03 - progress_bar.py[line:274] - INFO: epoch 001:  11174 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.3, ups=0.88, wpb=109.7, bsz=40, num_updates=11160, lr=2.72767e-05, gnorm=1.164, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54383
2022-10-19 10:32:14 - progress_bar.py[line:274] - INFO: epoch 001:  11184 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101, ups=0.91, wpb=110.5, bsz=40, num_updates=11170, lr=2.73012e-05, gnorm=0.946, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54394
2022-10-19 10:32:25 - progress_bar.py[line:274] - INFO: epoch 001:  11194 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.9, ups=0.87, wpb=110.5, bsz=40, num_updates=11180, lr=2.73256e-05, gnorm=0.91, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54405
2022-10-19 10:32:37 - progress_bar.py[line:274] - INFO: epoch 001:  11204 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99, ups=0.89, wpb=111.4, bsz=40, num_updates=11190, lr=2.73501e-05, gnorm=1.105, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54416
2022-10-19 10:32:48 - progress_bar.py[line:274] - INFO: epoch 001:  11214 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=11200, lr=2.73745e-05, gnorm=1.165, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=54428
2022-10-19 10:32:59 - progress_bar.py[line:274] - INFO: epoch 001:  11224 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.4, ups=0.9, wpb=111.4, bsz=40, num_updates=11210, lr=2.73989e-05, gnorm=1.161, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54439
2022-10-19 10:33:11 - progress_bar.py[line:274] - INFO: epoch 001:  11234 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.1, ups=0.87, wpb=110.6, bsz=40, num_updates=11220, lr=2.74234e-05, gnorm=1.146, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54450
2022-10-19 10:33:22 - progress_bar.py[line:274] - INFO: epoch 001:  11244 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=11230, lr=2.74478e-05, gnorm=1.094, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54462
2022-10-19 10:33:33 - progress_bar.py[line:274] - INFO: epoch 001:  11254 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=11240, lr=2.74723e-05, gnorm=1.183, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54473
2022-10-19 10:33:44 - progress_bar.py[line:274] - INFO: epoch 001:  11264 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=11250, lr=2.74967e-05, gnorm=1.083, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54484
2022-10-19 10:33:55 - progress_bar.py[line:274] - INFO: epoch 001:  11274 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.8, ups=0.92, wpb=109, bsz=40, num_updates=11260, lr=2.75211e-05, gnorm=1.192, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54495
2022-10-19 10:34:07 - progress_bar.py[line:274] - INFO: epoch 001:  11284 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.4, ups=0.88, wpb=110.9, bsz=40, num_updates=11270, lr=2.75456e-05, gnorm=0.949, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54506
2022-10-19 10:34:13 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 10:34:19 - progress_bar.py[line:274] - INFO: epoch 001:  11295 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=87.7, ups=0.8, wpb=109.9, bsz=40, num_updates=11280, lr=2.757e-05, gnorm=1.074, clip=50, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=54519
2022-10-19 10:34:30 - progress_bar.py[line:274] - INFO: epoch 001:  11305 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.1, ups=0.89, wpb=108.6, bsz=40, num_updates=11290, lr=2.75945e-05, gnorm=1.095, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54530
2022-10-19 10:34:41 - progress_bar.py[line:274] - INFO: epoch 001:  11315 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.3, ups=0.9, wpb=111.2, bsz=40, num_updates=11300, lr=2.76189e-05, gnorm=1.028, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54541
2022-10-19 10:34:53 - progress_bar.py[line:274] - INFO: epoch 001:  11325 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96, ups=0.88, wpb=109.4, bsz=40, num_updates=11310, lr=2.76433e-05, gnorm=1.182, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54553
2022-10-19 10:35:04 - progress_bar.py[line:274] - INFO: epoch 001:  11335 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=11320, lr=2.76678e-05, gnorm=1.068, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54564
2022-10-19 10:35:15 - progress_bar.py[line:274] - INFO: epoch 001:  11345 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=11330, lr=2.76922e-05, gnorm=1.297, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54575
2022-10-19 10:35:26 - progress_bar.py[line:274] - INFO: epoch 001:  11355 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=103.8, ups=0.94, wpb=109.9, bsz=40, num_updates=11340, lr=2.77167e-05, gnorm=1.088, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54586
2022-10-19 10:35:37 - progress_bar.py[line:274] - INFO: epoch 001:  11365 / 102288 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100.2, ups=0.92, wpb=109.3, bsz=40, num_updates=11350, lr=2.77411e-05, gnorm=1.148, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54597
2022-10-19 10:35:48 - progress_bar.py[line:274] - INFO: epoch 001:  11375 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98, ups=0.88, wpb=111.4, bsz=40, num_updates=11360, lr=2.77656e-05, gnorm=1.131, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54608
2022-10-19 10:36:00 - progress_bar.py[line:274] - INFO: epoch 001:  11385 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.3, ups=0.88, wpb=109.4, bsz=40, num_updates=11370, lr=2.779e-05, gnorm=1.13, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54619
2022-10-19 10:36:10 - progress_bar.py[line:274] - INFO: epoch 001:  11395 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102.9, ups=0.94, wpb=109, bsz=40, num_updates=11380, lr=2.78144e-05, gnorm=0.963, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54630
2022-10-19 10:36:22 - progress_bar.py[line:274] - INFO: epoch 001:  11405 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.4, ups=0.87, wpb=109.8, bsz=40, num_updates=11390, lr=2.78389e-05, gnorm=1.135, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54641
2022-10-19 10:36:33 - progress_bar.py[line:274] - INFO: epoch 001:  11415 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=11400, lr=2.78633e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54653
2022-10-19 10:36:44 - progress_bar.py[line:274] - INFO: epoch 001:  11425 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.3, ups=0.92, wpb=110.6, bsz=40, num_updates=11410, lr=2.78878e-05, gnorm=1.078, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54664
2022-10-19 10:36:55 - progress_bar.py[line:274] - INFO: epoch 001:  11435 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.9, ups=0.91, wpb=110.3, bsz=40, num_updates=11420, lr=2.79122e-05, gnorm=1.043, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54675
2022-10-19 10:37:06 - progress_bar.py[line:274] - INFO: epoch 001:  11445 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.6, ups=0.88, wpb=109.9, bsz=40, num_updates=11430, lr=2.79366e-05, gnorm=1.183, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54686
2022-10-19 10:37:18 - progress_bar.py[line:274] - INFO: epoch 001:  11455 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.2, ups=0.88, wpb=109.5, bsz=40, num_updates=11440, lr=2.79611e-05, gnorm=1.136, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54697
2022-10-19 10:37:29 - progress_bar.py[line:274] - INFO: epoch 001:  11465 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=11450, lr=2.79855e-05, gnorm=1.106, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54709
2022-10-19 10:37:40 - progress_bar.py[line:274] - INFO: epoch 001:  11475 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.3, ups=0.87, wpb=112.1, bsz=40, num_updates=11460, lr=2.801e-05, gnorm=1.124, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54720
2022-10-19 10:37:51 - progress_bar.py[line:274] - INFO: epoch 001:  11485 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.5, ups=0.91, wpb=109, bsz=40, num_updates=11470, lr=2.80344e-05, gnorm=1.139, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54731
2022-10-19 10:38:02 - progress_bar.py[line:274] - INFO: epoch 001:  11495 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=11480, lr=2.80589e-05, gnorm=1.144, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54742
2022-10-19 10:38:13 - progress_bar.py[line:274] - INFO: epoch 001:  11505 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=11490, lr=2.80833e-05, gnorm=0.98, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54753
2022-10-19 10:38:25 - progress_bar.py[line:274] - INFO: epoch 001:  11515 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=11500, lr=2.81077e-05, gnorm=0.981, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54764
2022-10-19 10:38:36 - progress_bar.py[line:274] - INFO: epoch 001:  11525 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=11510, lr=2.81322e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54775
2022-10-19 10:38:47 - progress_bar.py[line:274] - INFO: epoch 001:  11535 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.4, ups=0.88, wpb=112, bsz=40, num_updates=11520, lr=2.81566e-05, gnorm=0.996, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54787
2022-10-19 10:38:58 - progress_bar.py[line:274] - INFO: epoch 001:  11545 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=11530, lr=2.81811e-05, gnorm=0.998, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54798
2022-10-19 10:39:09 - progress_bar.py[line:274] - INFO: epoch 001:  11555 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=103, ups=0.94, wpb=109.9, bsz=40, num_updates=11540, lr=2.82055e-05, gnorm=1.139, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54809
2022-10-19 10:39:20 - progress_bar.py[line:274] - INFO: epoch 001:  11565 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.5, ups=0.9, wpb=110.5, bsz=40, num_updates=11550, lr=2.82299e-05, gnorm=1.101, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54820
2022-10-19 10:39:31 - progress_bar.py[line:274] - INFO: epoch 001:  11575 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.5, ups=0.9, wpb=111.2, bsz=40, num_updates=11560, lr=2.82544e-05, gnorm=1.171, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54831
2022-10-19 10:39:42 - progress_bar.py[line:274] - INFO: epoch 001:  11585 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.5, ups=0.91, wpb=111.1, bsz=40, num_updates=11570, lr=2.82788e-05, gnorm=1.103, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54842
2022-10-19 10:39:53 - progress_bar.py[line:274] - INFO: epoch 001:  11595 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=11580, lr=2.83033e-05, gnorm=1.05, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=54853
2022-10-19 10:40:05 - progress_bar.py[line:274] - INFO: epoch 001:  11605 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=11590, lr=2.83277e-05, gnorm=0.999, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54864
2022-10-19 10:40:16 - progress_bar.py[line:274] - INFO: epoch 001:  11615 / 102288 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=95, ups=0.87, wpb=109.6, bsz=40, num_updates=11600, lr=2.83522e-05, gnorm=1.152, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54876
2022-10-19 10:40:28 - progress_bar.py[line:274] - INFO: epoch 001:  11625 / 102288 loss=0.655, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.2, ups=0.88, wpb=108.3, bsz=40, num_updates=11610, lr=2.83766e-05, gnorm=1.136, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54887
2022-10-19 10:40:39 - progress_bar.py[line:274] - INFO: epoch 001:  11635 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=11620, lr=2.8401e-05, gnorm=0.999, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54899
2022-10-19 10:40:50 - progress_bar.py[line:274] - INFO: epoch 001:  11645 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=101.6, ups=0.92, wpb=110.3, bsz=40, num_updates=11630, lr=2.84255e-05, gnorm=1.177, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54909
2022-10-19 10:41:01 - progress_bar.py[line:274] - INFO: epoch 001:  11655 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=11640, lr=2.84499e-05, gnorm=1.02, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54921
2022-10-19 10:41:12 - progress_bar.py[line:274] - INFO: epoch 001:  11665 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=11650, lr=2.84744e-05, gnorm=1.115, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54932
2022-10-19 10:41:23 - progress_bar.py[line:274] - INFO: epoch 001:  11675 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=11660, lr=2.84988e-05, gnorm=0.971, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54943
2022-10-19 10:41:34 - progress_bar.py[line:274] - INFO: epoch 001:  11685 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.7, ups=0.9, wpb=109.9, bsz=40, num_updates=11670, lr=2.85232e-05, gnorm=1.016, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54954
2022-10-19 10:41:46 - progress_bar.py[line:274] - INFO: epoch 001:  11695 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.7, ups=0.87, wpb=110.5, bsz=40, num_updates=11680, lr=2.85477e-05, gnorm=1.089, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54966
2022-10-19 10:41:57 - progress_bar.py[line:274] - INFO: epoch 001:  11705 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=95.7, ups=0.88, wpb=108.8, bsz=40, num_updates=11690, lr=2.85721e-05, gnorm=1.165, clip=70, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54977
2022-10-19 10:42:08 - progress_bar.py[line:274] - INFO: epoch 001:  11715 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=11700, lr=2.85966e-05, gnorm=1.15, clip=70, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54988
2022-10-19 10:42:20 - progress_bar.py[line:274] - INFO: epoch 001:  11725 / 102288 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=11710, lr=2.8621e-05, gnorm=1.233, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54999
2022-10-19 10:42:31 - progress_bar.py[line:274] - INFO: epoch 001:  11735 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=11720, lr=2.86455e-05, gnorm=1.005, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55010
2022-10-19 10:42:42 - progress_bar.py[line:274] - INFO: epoch 001:  11745 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.4, ups=0.9, wpb=111.1, bsz=40, num_updates=11730, lr=2.86699e-05, gnorm=1.152, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55022
2022-10-19 10:42:53 - progress_bar.py[line:274] - INFO: epoch 001:  11755 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=11740, lr=2.86943e-05, gnorm=1.029, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55033
2022-10-19 10:43:04 - progress_bar.py[line:274] - INFO: epoch 001:  11765 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=11750, lr=2.87188e-05, gnorm=1.136, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55044
2022-10-19 10:43:16 - progress_bar.py[line:274] - INFO: epoch 001:  11775 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.7, ups=0.86, wpb=111.8, bsz=40, num_updates=11760, lr=2.87432e-05, gnorm=1.099, clip=80, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=55056
2022-10-19 10:43:27 - progress_bar.py[line:274] - INFO: epoch 001:  11785 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.7, ups=0.91, wpb=112.3, bsz=40, num_updates=11770, lr=2.87677e-05, gnorm=1.054, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=55066
2022-10-19 10:43:38 - progress_bar.py[line:274] - INFO: epoch 001:  11795 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=11780, lr=2.87921e-05, gnorm=1.173, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55078
2022-10-19 10:43:49 - progress_bar.py[line:274] - INFO: epoch 001:  11805 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=11790, lr=2.88165e-05, gnorm=1.04, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55089
2022-10-19 10:44:01 - progress_bar.py[line:274] - INFO: epoch 001:  11815 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.4, ups=0.87, wpb=109.5, bsz=40, num_updates=11800, lr=2.8841e-05, gnorm=1.066, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=55100
2022-10-19 10:44:11 - progress_bar.py[line:274] - INFO: epoch 001:  11825 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=101.9, ups=0.93, wpb=109.9, bsz=40, num_updates=11810, lr=2.88654e-05, gnorm=0.958, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55111
2022-10-19 10:44:23 - progress_bar.py[line:274] - INFO: epoch 001:  11835 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=11820, lr=2.88899e-05, gnorm=1.004, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55122
2022-10-19 10:44:34 - progress_bar.py[line:274] - INFO: epoch 001:  11845 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=11830, lr=2.89143e-05, gnorm=1.021, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55134
2022-10-19 10:44:45 - progress_bar.py[line:274] - INFO: epoch 001:  11855 / 102288 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=102.8, ups=0.93, wpb=111, bsz=40, num_updates=11840, lr=2.89387e-05, gnorm=1.161, clip=80, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55144
2022-10-19 10:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  11865 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=11850, lr=2.89632e-05, gnorm=0.953, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55155
2022-10-19 10:45:07 - progress_bar.py[line:274] - INFO: epoch 001:  11875 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=11860, lr=2.89876e-05, gnorm=1.018, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=55167
2022-10-19 10:45:17 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 10:45:19 - progress_bar.py[line:274] - INFO: epoch 001:  11886 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=93.3, ups=0.85, wpb=110.1, bsz=40, num_updates=11870, lr=2.90121e-05, gnorm=1.072, clip=70, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=55178
2022-10-19 10:45:29 - progress_bar.py[line:274] - INFO: epoch 001:  11896 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.5, ups=0.93, wpb=109.5, bsz=40, num_updates=11880, lr=2.90365e-05, gnorm=1.042, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55189
2022-10-19 10:45:41 - progress_bar.py[line:274] - INFO: epoch 001:  11906 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.3, ups=0.87, wpb=110.7, bsz=40, num_updates=11890, lr=2.9061e-05, gnorm=1.079, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55201
2022-10-19 10:45:52 - progress_bar.py[line:274] - INFO: epoch 001:  11916 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.6, ups=0.9, wpb=112.4, bsz=40, num_updates=11900, lr=2.90854e-05, gnorm=0.959, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55212
2022-10-19 10:46:03 - progress_bar.py[line:274] - INFO: epoch 001:  11926 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.6, ups=0.88, wpb=109.9, bsz=40, num_updates=11910, lr=2.91098e-05, gnorm=1.103, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55223
2022-10-19 10:46:14 - progress_bar.py[line:274] - INFO: epoch 001:  11936 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.4, ups=0.9, wpb=109.3, bsz=40, num_updates=11920, lr=2.91343e-05, gnorm=1.045, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55234
2022-10-19 10:46:26 - progress_bar.py[line:274] - INFO: epoch 001:  11946 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=11930, lr=2.91587e-05, gnorm=0.894, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55245
2022-10-19 10:46:37 - progress_bar.py[line:274] - INFO: epoch 001:  11956 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.1, ups=0.87, wpb=110.8, bsz=40, num_updates=11940, lr=2.91832e-05, gnorm=1.066, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55257
2022-10-19 10:46:48 - progress_bar.py[line:274] - INFO: epoch 001:  11966 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=11950, lr=2.92076e-05, gnorm=1.058, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55268
2022-10-19 10:47:00 - progress_bar.py[line:274] - INFO: epoch 001:  11976 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=11960, lr=2.9232e-05, gnorm=1.243, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55279
2022-10-19 10:47:11 - progress_bar.py[line:274] - INFO: epoch 001:  11986 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=11970, lr=2.92565e-05, gnorm=0.946, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=55291
2022-10-19 10:47:22 - progress_bar.py[line:274] - INFO: epoch 001:  11996 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.6, ups=0.91, wpb=111.6, bsz=40, num_updates=11980, lr=2.92809e-05, gnorm=0.994, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55302
2022-10-19 10:47:33 - progress_bar.py[line:274] - INFO: epoch 001:  12006 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99, ups=0.91, wpb=108.8, bsz=40, num_updates=11990, lr=2.93054e-05, gnorm=1.108, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55313
2022-10-19 10:47:44 - progress_bar.py[line:274] - INFO: epoch 001:  12016 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=12000, lr=2.93298e-05, gnorm=0.973, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55324
2022-10-19 10:47:44 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 10:47:45 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 10:47:45 - train.py[line:551] - INFO: load:1.01 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 10:50:17 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 10:50:17 - train.py[line:551] - INFO: load:1.03 valid_run:151.75 task_valid:148.04 collect_output:2.69
2022-10-19 10:52:46 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 10:52:46 - train.py[line:551] - INFO: load:1.06 valid_run:300.88 task_valid:291.40 collect_output:7.41
2022-10-19 10:55:19 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 10:55:19 - train.py[line:551] - INFO: load:1.08 valid_run:453.81 task_valid:434.74 collect_output:15.94
2022-10-19 10:57:49 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 10:57:49 - train.py[line:551] - INFO: load:1.11 valid_run:603.68 task_valid:580.05 collect_output:19.43
2022-10-19 11:00:22 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 11:00:22 - train.py[line:551] - INFO: load:1.13 valid_run:756.52 task_valid:727.80 collect_output:23.43
2022-10-19 11:02:54 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 11:02:54 - train.py[line:551] - INFO: load:1.16 valid_run:908.80 task_valid:873.60 collect_output:28.85
2022-10-19 11:05:28 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 11:05:28 - train.py[line:551] - INFO: load:1.18 valid_run:1062.91 task_valid:1019.92 collect_output:35.58
2022-10-19 11:08:06 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 11:08:06 - train.py[line:551] - INFO: load:1.21 valid_run:1220.87 task_valid:1167.08 collect_output:44.85
2022-10-19 11:10:42 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 11:10:42 - train.py[line:551] - INFO: load:1.23 valid_run:1376.30 task_valid:1314.42 collect_output:51.29
2022-10-19 11:13:12 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 11:13:12 - train.py[line:551] - INFO: load:1.26 valid_run:1525.81 task_valid:1458.05 collect_output:56.13
2022-10-19 11:15:42 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 11:15:42 - train.py[line:551] - INFO: load:1.28 valid_run:1676.34 task_valid:1603.28 collect_output:60.35
2022-10-19 11:18:13 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 11:18:13 - train.py[line:551] - INFO: load:1.31 valid_run:1827.39 task_valid:1749.08 collect_output:64.44
2022-10-19 11:20:45 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 11:20:45 - train.py[line:551] - INFO: load:1.34 valid_run:1978.57 task_valid:1891.92 collect_output:71.58
2022-10-19 11:23:17 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 11:23:17 - train.py[line:551] - INFO: load:1.36 valid_run:2131.42 task_valid:2039.10 collect_output:75.88
2022-10-19 11:25:48 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 11:25:48 - train.py[line:551] - INFO: load:1.39 valid_run:2282.31 task_valid:2185.97 collect_output:78.89
2022-10-19 11:28:20 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 11:28:20 - train.py[line:551] - INFO: load:1.41 valid_run:2433.49 task_valid:2331.00 collect_output:83.87
2022-10-19 11:30:53 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 11:30:53 - train.py[line:551] - INFO: load:1.44 valid_run:2586.98 task_valid:2477.45 collect_output:89.59
2022-10-19 11:33:24 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 11:33:24 - train.py[line:551] - INFO: load:1.46 valid_run:2738.17 task_valid:2624.99 collect_output:92.23
2022-10-19 11:35:56 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 11:35:56 - train.py[line:551] - INFO: load:1.49 valid_run:2889.78 task_valid:2768.77 collect_output:98.93
2022-10-19 11:38:30 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 11:38:30 - train.py[line:551] - INFO: load:1.52 valid_run:3043.34 task_valid:2915.49 collect_output:104.74
2022-10-19 11:41:02 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 11:41:02 - train.py[line:551] - INFO: load:1.54 valid_run:3196.00 task_valid:3060.15 collect_output:111.73
2022-10-19 11:43:32 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 11:43:32 - train.py[line:551] - INFO: load:1.57 valid_run:3345.55 task_valid:3204.64 collect_output:115.79
2022-10-19 11:46:04 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 11:46:04 - train.py[line:551] - INFO: load:1.59 valid_run:3497.27 task_valid:3351.07 collect_output:120.08
2022-10-19 11:48:36 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 11:48:36 - train.py[line:551] - INFO: load:1.62 valid_run:3649.00 task_valid:3497.49 collect_output:124.38

====================================================================================================
SGG eval:     R @ 50: 0.5461;     R @ 100: 0.5798;     R @ 500: 0.6047;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3868;    mR @ 100: 0.4175;    mR @ 500: 0.4380;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5854) (covered in:0.8750) (covering:0.3143) (eating:0.7647) (flying in:0.5000) (growing on:0.3750) (hanging from:0.3419) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8693) (says:0.0000) (sitting on:0.7075) (standing on:0.1350) (using:0.6000) (walking in:0.0000) (walking on:0.8378) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5461;     R @ 100: 0.5798;     R @ 500: 0.6047;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3868;    mR @ 100: 0.4175;    mR @ 500: 0.4380;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5854) (covered in:0.8750) (covering:0.3143) (eating:0.7647) (flying in:0.5000) (growing on:0.3750) (hanging from:0.3419) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8693) (says:0.0000) (sitting on:0.7075) (standing on:0.1350) (using:0.6000) (walking in:0.0000) (walking on:0.8378) (watching:0.2778) 
--------------------------------------------------------
====================================================================================================

2022-10-19 11:51:07 - train.py[line:487] - INFO: 0.5797747899159663
2022-10-19 11:51:07 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 11:51:07 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.331 | loss_v1 0 | loss_v2 0 | nll_loss 0.169 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.579775 | ppl 1.12 | vqa_score 0.4865 | wps 118 | wpb 89.9 | bsz 30 | num_updates 12000 | best_R@100 0.586968
2022-10-19 11:51:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2022-10-19 11:51:07 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_12000.pt
2022-10-19 11:51:13 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_12000.pt
2022-10-19 11:51:16 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.5797747899159663) (writing took 8.548718380276114 seconds)
2022-10-19 11:51:27 - progress_bar.py[line:274] - INFO: epoch 001:  12026 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=0.3, ups=0, wpb=111.7, bsz=40, num_updates=12010, lr=2.93543e-05, gnorm=1.059, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59147
2022-10-19 11:51:38 - progress_bar.py[line:274] - INFO: epoch 001:  12036 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.4, ups=0.9, wpb=111.3, bsz=40, num_updates=12020, lr=2.93787e-05, gnorm=0.994, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59158
2022-10-19 11:51:49 - progress_bar.py[line:274] - INFO: epoch 001:  12046 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.1, ups=0.93, wpb=110.3, bsz=40, num_updates=12030, lr=2.94031e-05, gnorm=1.142, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59169
2022-10-19 11:52:00 - progress_bar.py[line:274] - INFO: epoch 001:  12056 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.1, ups=0.91, wpb=110.6, bsz=40, num_updates=12040, lr=2.94276e-05, gnorm=1.299, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59180
2022-10-19 11:52:11 - progress_bar.py[line:274] - INFO: epoch 001:  12066 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=12050, lr=2.9452e-05, gnorm=1.086, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59191
2022-10-19 11:52:22 - progress_bar.py[line:274] - INFO: epoch 001:  12076 / 102288 loss=0.637, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=12060, lr=2.94765e-05, gnorm=0.991, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59202
2022-10-19 11:52:33 - progress_bar.py[line:274] - INFO: epoch 001:  12086 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=12070, lr=2.95009e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59213
2022-10-19 11:52:44 - progress_bar.py[line:274] - INFO: epoch 001:  12096 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=102.2, ups=0.93, wpb=110.3, bsz=40, num_updates=12080, lr=2.95253e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59224
2022-10-19 11:52:55 - progress_bar.py[line:274] - INFO: epoch 001:  12106 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.3, ups=0.91, wpb=109.9, bsz=40, num_updates=12090, lr=2.95498e-05, gnorm=0.998, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59235
2022-10-19 11:53:06 - progress_bar.py[line:274] - INFO: epoch 001:  12116 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.8, ups=0.89, wpb=108.6, bsz=40, num_updates=12100, lr=2.95742e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59246
2022-10-19 11:53:17 - progress_bar.py[line:274] - INFO: epoch 001:  12126 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=12110, lr=2.95987e-05, gnorm=0.953, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59257
2022-10-19 11:53:29 - progress_bar.py[line:274] - INFO: epoch 001:  12136 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=12120, lr=2.96231e-05, gnorm=0.943, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59268
2022-10-19 11:53:40 - progress_bar.py[line:274] - INFO: epoch 001:  12146 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=12130, lr=2.96476e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=59280
2022-10-19 11:53:51 - progress_bar.py[line:274] - INFO: epoch 001:  12156 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99, ups=0.9, wpb=109.8, bsz=40, num_updates=12140, lr=2.9672e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=59291
2022-10-19 11:54:02 - progress_bar.py[line:274] - INFO: epoch 001:  12166 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.3, ups=0.92, wpb=109.5, bsz=40, num_updates=12150, lr=2.96964e-05, gnorm=0.98, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59302
2022-10-19 11:54:13 - progress_bar.py[line:274] - INFO: epoch 001:  12176 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.3, ups=0.87, wpb=109.7, bsz=40, num_updates=12160, lr=2.97209e-05, gnorm=1.083, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59313
2022-10-19 11:54:25 - progress_bar.py[line:274] - INFO: epoch 001:  12186 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=12170, lr=2.97453e-05, gnorm=0.984, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59324
2022-10-19 11:54:36 - progress_bar.py[line:274] - INFO: epoch 001:  12196 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=12180, lr=2.97698e-05, gnorm=1.045, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59336
2022-10-19 11:54:47 - progress_bar.py[line:274] - INFO: epoch 001:  12206 / 102288 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.2, ups=0.9, wpb=109.1, bsz=40, num_updates=12190, lr=2.97942e-05, gnorm=1.01, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59347
2022-10-19 11:54:58 - progress_bar.py[line:274] - INFO: epoch 001:  12216 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=12200, lr=2.98186e-05, gnorm=1.049, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59358
2022-10-19 11:55:10 - progress_bar.py[line:274] - INFO: epoch 001:  12226 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.1, ups=0.88, wpb=109.8, bsz=40, num_updates=12210, lr=2.98431e-05, gnorm=1.116, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59369
2022-10-19 11:55:21 - progress_bar.py[line:274] - INFO: epoch 001:  12236 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=12220, lr=2.98675e-05, gnorm=1.062, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59381
2022-10-19 11:55:32 - progress_bar.py[line:274] - INFO: epoch 001:  12246 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=12230, lr=2.9892e-05, gnorm=1.058, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59392
2022-10-19 11:55:43 - progress_bar.py[line:274] - INFO: epoch 001:  12256 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=12240, lr=2.99164e-05, gnorm=1.039, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59403
2022-10-19 11:55:55 - progress_bar.py[line:274] - INFO: epoch 001:  12266 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.5, ups=0.87, wpb=110.1, bsz=40, num_updates=12250, lr=2.99409e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59415
2022-10-19 11:56:06 - progress_bar.py[line:274] - INFO: epoch 001:  12276 / 102288 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.5, ups=0.88, wpb=109.7, bsz=40, num_updates=12260, lr=2.99653e-05, gnorm=1.086, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59426
2022-10-19 11:56:17 - progress_bar.py[line:274] - INFO: epoch 001:  12286 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.8, ups=0.91, wpb=110.2, bsz=40, num_updates=12270, lr=2.99897e-05, gnorm=1.046, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59437
2022-10-19 11:56:28 - progress_bar.py[line:274] - INFO: epoch 001:  12296 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.5, ups=0.9, wpb=109.1, bsz=40, num_updates=12280, lr=3.00142e-05, gnorm=1.001, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59448
2022-10-19 11:56:39 - progress_bar.py[line:274] - INFO: epoch 001:  12306 / 102288 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.3, ups=0.89, wpb=109.1, bsz=40, num_updates=12290, lr=3.00386e-05, gnorm=0.968, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59459
2022-10-19 11:56:51 - progress_bar.py[line:274] - INFO: epoch 001:  12316 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=12300, lr=3.00631e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59471
2022-10-19 11:57:02 - progress_bar.py[line:274] - INFO: epoch 001:  12326 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=12310, lr=3.00875e-05, gnorm=1.006, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=59482
2022-10-19 11:57:13 - progress_bar.py[line:274] - INFO: epoch 001:  12336 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=12320, lr=3.01119e-05, gnorm=1.105, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59493
2022-10-19 11:57:24 - progress_bar.py[line:274] - INFO: epoch 001:  12346 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.6, ups=0.88, wpb=110, bsz=40, num_updates=12330, lr=3.01364e-05, gnorm=0.987, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59504
2022-10-19 11:57:36 - progress_bar.py[line:274] - INFO: epoch 001:  12356 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.6, ups=0.88, wpb=110, bsz=40, num_updates=12340, lr=3.01608e-05, gnorm=0.992, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59516
2022-10-19 11:57:47 - progress_bar.py[line:274] - INFO: epoch 001:  12366 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=12350, lr=3.01853e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59527
2022-10-19 11:57:58 - progress_bar.py[line:274] - INFO: epoch 001:  12376 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.6, ups=0.91, wpb=110.4, bsz=40, num_updates=12360, lr=3.02097e-05, gnorm=1.145, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59538
2022-10-19 11:58:09 - progress_bar.py[line:274] - INFO: epoch 001:  12386 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=103.8, ups=0.95, wpb=109.7, bsz=40, num_updates=12370, lr=3.02341e-05, gnorm=0.993, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59548
2022-10-19 11:58:20 - progress_bar.py[line:274] - INFO: epoch 001:  12396 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.2, ups=0.87, wpb=111, bsz=40, num_updates=12380, lr=3.02586e-05, gnorm=0.872, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59560
2022-10-19 11:58:31 - progress_bar.py[line:274] - INFO: epoch 001:  12406 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=12390, lr=3.0283e-05, gnorm=1.062, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59571
2022-10-19 11:58:43 - progress_bar.py[line:274] - INFO: epoch 001:  12416 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=12400, lr=3.03075e-05, gnorm=1.172, clip=80, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59582
2022-10-19 11:58:54 - progress_bar.py[line:274] - INFO: epoch 001:  12426 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.5, ups=0.87, wpb=110, bsz=40, num_updates=12410, lr=3.03319e-05, gnorm=0.912, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59594
2022-10-19 11:59:05 - progress_bar.py[line:274] - INFO: epoch 001:  12436 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=12420, lr=3.03564e-05, gnorm=0.889, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59605
2022-10-19 11:59:16 - progress_bar.py[line:274] - INFO: epoch 001:  12446 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=12430, lr=3.03808e-05, gnorm=1.089, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59616
2022-10-19 11:59:27 - progress_bar.py[line:274] - INFO: epoch 001:  12456 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=12440, lr=3.04052e-05, gnorm=0.987, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59627
2022-10-19 11:59:39 - progress_bar.py[line:274] - INFO: epoch 001:  12466 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=12450, lr=3.04297e-05, gnorm=0.983, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59638
2022-10-19 11:59:50 - progress_bar.py[line:274] - INFO: epoch 001:  12476 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.4, ups=0.9, wpb=111.3, bsz=40, num_updates=12460, lr=3.04541e-05, gnorm=1.08, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59649
2022-10-19 12:00:01 - progress_bar.py[line:274] - INFO: epoch 001:  12486 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=12470, lr=3.04786e-05, gnorm=1.041, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59661
2022-10-19 12:00:12 - progress_bar.py[line:274] - INFO: epoch 001:  12496 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.1, ups=0.87, wpb=109.3, bsz=40, num_updates=12480, lr=3.0503e-05, gnorm=1.062, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59672
2022-10-19 12:00:24 - progress_bar.py[line:274] - INFO: epoch 001:  12506 / 102288 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=12490, lr=3.05274e-05, gnorm=1.055, clip=50, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=59684
2022-10-19 12:00:35 - progress_bar.py[line:274] - INFO: epoch 001:  12516 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=12500, lr=3.05519e-05, gnorm=1.083, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59695
2022-10-19 12:00:46 - progress_bar.py[line:274] - INFO: epoch 001:  12526 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.3, ups=0.89, wpb=110.8, bsz=40, num_updates=12510, lr=3.05763e-05, gnorm=1.069, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59706
2022-10-19 12:00:57 - progress_bar.py[line:274] - INFO: epoch 001:  12536 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101, ups=0.92, wpb=109.8, bsz=40, num_updates=12520, lr=3.06008e-05, gnorm=1.01, clip=60, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=59717
2022-10-19 12:01:08 - progress_bar.py[line:274] - INFO: epoch 001:  12546 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=12530, lr=3.06252e-05, gnorm=1.147, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59728
2022-10-19 12:01:20 - progress_bar.py[line:274] - INFO: epoch 001:  12556 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.6, ups=0.89, wpb=109.6, bsz=40, num_updates=12540, lr=3.06497e-05, gnorm=1.092, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59739
2022-10-19 12:01:31 - progress_bar.py[line:274] - INFO: epoch 001:  12566 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.3, ups=0.88, wpb=110.7, bsz=40, num_updates=12550, lr=3.06741e-05, gnorm=0.966, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59751
2022-10-19 12:01:39 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 12:01:43 - progress_bar.py[line:274] - INFO: epoch 001:  12577 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=90.4, ups=0.82, wpb=110.7, bsz=40, num_updates=12560, lr=3.06985e-05, gnorm=0.971, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=59763
2022-10-19 12:01:54 - progress_bar.py[line:274] - INFO: epoch 001:  12587 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.5, ups=0.9, wpb=111.5, bsz=40, num_updates=12570, lr=3.0723e-05, gnorm=1.053, clip=70, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=59774
2022-10-19 12:02:06 - progress_bar.py[line:274] - INFO: epoch 001:  12597 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.6, ups=0.88, wpb=111.3, bsz=40, num_updates=12580, lr=3.07474e-05, gnorm=1.033, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59785
2022-10-19 12:02:16 - progress_bar.py[line:274] - INFO: epoch 001:  12607 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.9, ups=0.93, wpb=108.9, bsz=40, num_updates=12590, lr=3.07719e-05, gnorm=1.156, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59796
2022-10-19 12:02:28 - progress_bar.py[line:274] - INFO: epoch 001:  12617 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=12600, lr=3.07963e-05, gnorm=1.05, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59808
2022-10-19 12:02:39 - progress_bar.py[line:274] - INFO: epoch 001:  12627 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.4, ups=0.89, wpb=111.8, bsz=40, num_updates=12610, lr=3.08207e-05, gnorm=1.369, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59819
2022-10-19 12:02:50 - progress_bar.py[line:274] - INFO: epoch 001:  12637 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.7, ups=0.91, wpb=109.8, bsz=40, num_updates=12620, lr=3.08452e-05, gnorm=0.975, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59830
2022-10-19 12:03:01 - progress_bar.py[line:274] - INFO: epoch 001:  12647 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.91, wpb=108.7, bsz=40, num_updates=12630, lr=3.08696e-05, gnorm=1.128, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59841
2022-10-19 12:03:12 - progress_bar.py[line:274] - INFO: epoch 001:  12657 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.9, ups=0.91, wpb=109.4, bsz=40, num_updates=12640, lr=3.08941e-05, gnorm=1.132, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59852
2022-10-19 12:03:23 - progress_bar.py[line:274] - INFO: epoch 001:  12667 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=12650, lr=3.09185e-05, gnorm=1.061, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59863
2022-10-19 12:03:35 - progress_bar.py[line:274] - INFO: epoch 001:  12677 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.3, ups=0.87, wpb=111.2, bsz=40, num_updates=12660, lr=3.0943e-05, gnorm=1.249, clip=80, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=59874
2022-10-19 12:03:46 - progress_bar.py[line:274] - INFO: epoch 001:  12687 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=12670, lr=3.09674e-05, gnorm=0.94, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59886
2022-10-19 12:03:57 - progress_bar.py[line:274] - INFO: epoch 001:  12697 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=12680, lr=3.09918e-05, gnorm=0.943, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59897
2022-10-19 12:04:08 - progress_bar.py[line:274] - INFO: epoch 001:  12707 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.5, ups=0.89, wpb=109.6, bsz=40, num_updates=12690, lr=3.10163e-05, gnorm=1.024, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59908
2022-10-19 12:04:20 - progress_bar.py[line:274] - INFO: epoch 001:  12717 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=12700, lr=3.10407e-05, gnorm=1.18, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59920
2022-10-19 12:04:31 - progress_bar.py[line:274] - INFO: epoch 001:  12727 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=12710, lr=3.10652e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59931
2022-10-19 12:04:42 - progress_bar.py[line:274] - INFO: epoch 001:  12737 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=103.1, ups=0.93, wpb=111.1, bsz=40, num_updates=12720, lr=3.10896e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59942
2022-10-19 12:04:53 - progress_bar.py[line:274] - INFO: epoch 001:  12747 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.1, ups=0.89, wpb=108.9, bsz=40, num_updates=12730, lr=3.1114e-05, gnorm=0.992, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59953
2022-10-19 12:05:05 - progress_bar.py[line:274] - INFO: epoch 001:  12757 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.3, ups=0.88, wpb=109.4, bsz=40, num_updates=12740, lr=3.11385e-05, gnorm=0.955, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59964
2022-10-19 12:05:16 - progress_bar.py[line:274] - INFO: epoch 001:  12767 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=12750, lr=3.11629e-05, gnorm=1.186, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59975
2022-10-19 12:05:27 - progress_bar.py[line:274] - INFO: epoch 001:  12777 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=12760, lr=3.11874e-05, gnorm=1.074, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=59987
2022-10-19 12:05:38 - progress_bar.py[line:274] - INFO: epoch 001:  12787 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.3, ups=0.89, wpb=109.4, bsz=40, num_updates=12770, lr=3.12118e-05, gnorm=1.003, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59998
2022-10-19 12:05:49 - progress_bar.py[line:274] - INFO: epoch 001:  12797 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=12780, lr=3.12363e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60009
2022-10-19 12:06:00 - progress_bar.py[line:274] - INFO: epoch 001:  12807 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.3, ups=0.9, wpb=109.2, bsz=40, num_updates=12790, lr=3.12607e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60020
2022-10-19 12:06:11 - progress_bar.py[line:274] - INFO: epoch 001:  12817 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.6, ups=0.91, wpb=110, bsz=40, num_updates=12800, lr=3.12851e-05, gnorm=1.148, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60031
2022-10-19 12:06:22 - progress_bar.py[line:274] - INFO: epoch 001:  12827 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.7, ups=0.91, wpb=110.4, bsz=40, num_updates=12810, lr=3.13096e-05, gnorm=0.978, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60042
2022-10-19 12:06:33 - progress_bar.py[line:274] - INFO: epoch 001:  12837 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.5, ups=0.91, wpb=110.2, bsz=40, num_updates=12820, lr=3.1334e-05, gnorm=1.076, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60053
2022-10-19 12:06:44 - progress_bar.py[line:274] - INFO: epoch 001:  12847 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.3, ups=0.9, wpb=108.9, bsz=40, num_updates=12830, lr=3.13585e-05, gnorm=0.963, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60064
2022-10-19 12:06:56 - progress_bar.py[line:274] - INFO: epoch 001:  12857 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.5, ups=0.88, wpb=109.9, bsz=40, num_updates=12840, lr=3.13829e-05, gnorm=0.997, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60075
2022-10-19 12:07:07 - progress_bar.py[line:274] - INFO: epoch 001:  12867 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.3, ups=0.88, wpb=110.8, bsz=40, num_updates=12850, lr=3.14073e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=60087
2022-10-19 12:07:18 - progress_bar.py[line:274] - INFO: epoch 001:  12877 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.2, ups=0.89, wpb=109.3, bsz=40, num_updates=12860, lr=3.14318e-05, gnorm=1.059, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60098
2022-10-19 12:07:29 - progress_bar.py[line:274] - INFO: epoch 001:  12887 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=12870, lr=3.14562e-05, gnorm=0.925, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60109
2022-10-19 12:07:41 - progress_bar.py[line:274] - INFO: epoch 001:  12897 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.7, ups=0.89, wpb=112, bsz=40, num_updates=12880, lr=3.14807e-05, gnorm=1.068, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60120
2022-10-19 12:07:52 - progress_bar.py[line:274] - INFO: epoch 001:  12907 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=12890, lr=3.15051e-05, gnorm=1.013, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60132
2022-10-19 12:08:03 - progress_bar.py[line:274] - INFO: epoch 001:  12917 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.6, ups=0.87, wpb=111.3, bsz=40, num_updates=12900, lr=3.15295e-05, gnorm=1.116, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60143
2022-10-19 12:08:15 - progress_bar.py[line:274] - INFO: epoch 001:  12927 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.2, ups=0.88, wpb=109.5, bsz=40, num_updates=12910, lr=3.1554e-05, gnorm=0.967, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60154
2022-10-19 12:08:26 - progress_bar.py[line:274] - INFO: epoch 001:  12937 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.7, ups=0.88, wpb=111.3, bsz=40, num_updates=12920, lr=3.15784e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60166
2022-10-19 12:08:37 - progress_bar.py[line:274] - INFO: epoch 001:  12947 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=12930, lr=3.16029e-05, gnorm=0.96, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=60177
2022-10-19 12:08:48 - progress_bar.py[line:274] - INFO: epoch 001:  12957 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.9, ups=0.9, wpb=110.8, bsz=40, num_updates=12940, lr=3.16273e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60188
2022-10-19 12:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  12967 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.5, ups=0.9, wpb=111.4, bsz=40, num_updates=12950, lr=3.16518e-05, gnorm=1.066, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60199
2022-10-19 12:09:11 - progress_bar.py[line:274] - INFO: epoch 001:  12977 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.1, ups=0.89, wpb=110.4, bsz=40, num_updates=12960, lr=3.16762e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60211
2022-10-19 12:09:22 - progress_bar.py[line:274] - INFO: epoch 001:  12987 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.9, ups=0.89, wpb=111.2, bsz=40, num_updates=12970, lr=3.17006e-05, gnorm=1.103, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=60222
2022-10-19 12:09:33 - progress_bar.py[line:274] - INFO: epoch 001:  12997 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=12980, lr=3.17251e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60233
2022-10-19 12:09:45 - progress_bar.py[line:274] - INFO: epoch 001:  13007 / 102288 loss=0.644, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=12990, lr=3.17495e-05, gnorm=0.957, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60244
2022-10-19 12:09:56 - progress_bar.py[line:274] - INFO: epoch 001:  13017 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.1, ups=0.9, wpb=111.1, bsz=40, num_updates=13000, lr=3.1774e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60256
2022-10-19 12:09:56 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 12:09:57 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 12:09:57 - train.py[line:551] - INFO: load:1.13 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 12:12:29 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 12:12:29 - train.py[line:551] - INFO: load:1.15 valid_run:151.94 task_valid:148.08 collect_output:2.76
2022-10-19 12:14:58 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 12:14:58 - train.py[line:551] - INFO: load:1.18 valid_run:300.96 task_valid:291.28 collect_output:7.52
2022-10-19 12:17:31 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 12:17:31 - train.py[line:551] - INFO: load:1.20 valid_run:453.93 task_valid:434.62 collect_output:16.04
2022-10-19 12:20:01 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 12:20:01 - train.py[line:551] - INFO: load:1.22 valid_run:603.54 task_valid:579.67 collect_output:19.56
2022-10-19 12:22:34 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 12:22:34 - train.py[line:551] - INFO: load:1.25 valid_run:756.33 task_valid:727.19 collect_output:23.74
2022-10-19 12:25:06 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 12:25:06 - train.py[line:551] - INFO: load:1.27 valid_run:908.45 task_valid:872.78 collect_output:29.22
2022-10-19 12:27:40 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 12:27:40 - train.py[line:551] - INFO: load:1.30 valid_run:1062.47 task_valid:1019.08 collect_output:35.90
2022-10-19 12:30:12 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 12:30:12 - train.py[line:551] - INFO: load:1.32 valid_run:1214.44 task_valid:1160.40 collect_output:45.54
2022-10-19 12:32:43 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 12:32:43 - train.py[line:551] - INFO: load:1.35 valid_run:1364.89 task_valid:1305.30 collect_output:50.00
2022-10-19 12:35:12 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 12:35:12 - train.py[line:551] - INFO: load:1.37 valid_run:1514.32 task_valid:1448.78 collect_output:54.91
2022-10-19 12:37:44 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 12:37:44 - train.py[line:551] - INFO: load:1.40 valid_run:1666.47 task_valid:1595.08 collect_output:59.45
2022-10-19 12:40:16 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 12:40:16 - train.py[line:551] - INFO: load:1.43 valid_run:1817.70 task_valid:1740.85 collect_output:63.79
2022-10-19 12:42:46 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 12:42:46 - train.py[line:551] - INFO: load:1.45 valid_run:1968.37 task_valid:1882.86 collect_output:71.44
2022-10-19 12:45:17 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 12:45:17 - train.py[line:551] - INFO: load:1.48 valid_run:2119.26 task_valid:2028.55 collect_output:75.62
2022-10-19 12:47:48 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 12:47:48 - train.py[line:551] - INFO: load:1.50 valid_run:2269.49 task_valid:2174.96 collect_output:78.41
2022-10-19 12:50:18 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 12:50:18 - train.py[line:551] - INFO: load:1.53 valid_run:2420.01 task_valid:2319.13 collect_output:83.75
2022-10-19 12:52:50 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 12:52:50 - train.py[line:551] - INFO: load:1.55 valid_run:2572.27 task_valid:2464.55 collect_output:89.60
2022-10-19 12:55:21 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 12:55:21 - train.py[line:551] - INFO: load:1.58 valid_run:2723.05 task_valid:2611.42 collect_output:92.51
2022-10-19 12:57:50 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 12:57:50 - train.py[line:551] - INFO: load:1.60 valid_run:2871.90 task_valid:2752.94 collect_output:98.83
2022-10-19 13:00:21 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 13:00:21 - train.py[line:551] - INFO: load:1.63 valid_run:3022.86 task_valid:2898.19 collect_output:103.54
2022-10-19 13:02:54 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 13:02:54 - train.py[line:551] - INFO: load:1.66 valid_run:3175.61 task_valid:3042.73 collect_output:110.74
2022-10-19 13:05:24 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 13:05:24 - train.py[line:551] - INFO: load:1.68 valid_run:3325.39 task_valid:3187.28 collect_output:114.95
2022-10-19 13:07:56 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 13:07:56 - train.py[line:551] - INFO: load:1.71 valid_run:3477.02 task_valid:3333.48 collect_output:119.40
2022-10-19 13:10:27 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 13:10:27 - train.py[line:551] - INFO: load:1.73 valid_run:3628.87 task_valid:3480.03 collect_output:123.69

====================================================================================================
SGG eval:     R @ 50: 0.5468;     R @ 100: 0.5939;     R @ 500: 0.6134;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3739;    mR @ 100: 0.4172;    mR @ 500: 0.4328;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.8750) (covering:0.3429) (eating:0.6176) (flying in:0.5000) (growing on:0.2188) (hanging from:0.5097) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.8644) (says:0.0000) (sitting on:0.7324) (standing on:0.1350) (using:0.6000) (walking in:0.0000) (walking on:0.8514) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5468;     R @ 100: 0.5939;     R @ 500: 0.6134;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3739;    mR @ 100: 0.4172;    mR @ 500: 0.4328;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.8750) (covering:0.3429) (eating:0.6176) (flying in:0.5000) (growing on:0.2188) (hanging from:0.5097) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.8644) (says:0.0000) (sitting on:0.7324) (standing on:0.1350) (using:0.6000) (walking in:0.0000) (walking on:0.8514) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================

2022-10-19 13:12:59 - train.py[line:487] - INFO: 0.5939114845938376
2022-10-19 13:12:59 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 13:12:59 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.328 | loss_v1 0 | loss_v2 0 | nll_loss 0.172 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.593911 | ppl 1.13 | vqa_score 0.5101 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 13000 | best_R@100 0.593911
2022-10-19 13:12:59 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 13000 updates
2022-10-19 13:12:59 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_13000.pt
2022-10-19 13:13:05 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_13000.pt
2022-10-19 13:13:10 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_13000.pt (epoch 1 @ 13000 updates, score 0.5939114845938376) (writing took 11.023033717647195 seconds)
2022-10-19 13:13:21 - progress_bar.py[line:274] - INFO: epoch 001:  13027 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=0.3, ups=0, wpb=111.1, bsz=40, num_updates=13010, lr=3.17984e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64061
2022-10-19 13:13:33 - progress_bar.py[line:274] - INFO: epoch 001:  13037 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=13020, lr=3.18228e-05, gnorm=0.944, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64072
2022-10-19 13:13:44 - progress_bar.py[line:274] - INFO: epoch 001:  13047 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.9, ups=0.93, wpb=109.8, bsz=40, num_updates=13030, lr=3.18473e-05, gnorm=1.148, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64084
2022-10-19 13:13:55 - progress_bar.py[line:274] - INFO: epoch 001:  13057 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=13040, lr=3.18717e-05, gnorm=1.033, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64095
2022-10-19 13:14:06 - progress_bar.py[line:274] - INFO: epoch 001:  13067 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=13050, lr=3.18962e-05, gnorm=1.05, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64106
2022-10-19 13:14:18 - progress_bar.py[line:274] - INFO: epoch 001:  13077 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.2, ups=0.88, wpb=110.7, bsz=40, num_updates=13060, lr=3.19206e-05, gnorm=0.877, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64117
2022-10-19 13:14:29 - progress_bar.py[line:274] - INFO: epoch 001:  13087 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=13070, lr=3.19451e-05, gnorm=0.919, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64129
2022-10-19 13:14:40 - progress_bar.py[line:274] - INFO: epoch 001:  13097 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.7, ups=0.88, wpb=108.8, bsz=40, num_updates=13080, lr=3.19695e-05, gnorm=1.012, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64140
2022-10-19 13:14:52 - progress_bar.py[line:274] - INFO: epoch 001:  13107 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=13090, lr=3.19939e-05, gnorm=1.135, clip=60, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=64151
2022-10-19 13:15:03 - progress_bar.py[line:274] - INFO: epoch 001:  13117 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=13100, lr=3.20184e-05, gnorm=0.926, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64163
2022-10-19 13:15:14 - progress_bar.py[line:274] - INFO: epoch 001:  13127 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.6, ups=0.9, wpb=109.3, bsz=40, num_updates=13110, lr=3.20428e-05, gnorm=0.885, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64174
2022-10-19 13:15:25 - progress_bar.py[line:274] - INFO: epoch 001:  13137 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=13120, lr=3.20673e-05, gnorm=0.938, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64185
2022-10-19 13:15:36 - progress_bar.py[line:274] - INFO: epoch 001:  13147 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.7, ups=0.88, wpb=111, bsz=40, num_updates=13130, lr=3.20917e-05, gnorm=0.955, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64196
2022-10-19 13:15:47 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 13:15:49 - progress_bar.py[line:274] - INFO: epoch 001:  13158 / 102288 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=87.1, ups=0.8, wpb=109.3, bsz=40, num_updates=13140, lr=3.21161e-05, gnorm=1.058, clip=40, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=64209
2022-10-19 13:16:00 - progress_bar.py[line:274] - INFO: epoch 001:  13168 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.5, ups=0.89, wpb=109.3, bsz=40, num_updates=13150, lr=3.21406e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64220
2022-10-19 13:16:11 - progress_bar.py[line:274] - INFO: epoch 001:  13178 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=13160, lr=3.2165e-05, gnorm=0.981, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64231
2022-10-19 13:16:23 - progress_bar.py[line:274] - INFO: epoch 001:  13188 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.2, ups=0.87, wpb=109.5, bsz=40, num_updates=13170, lr=3.21895e-05, gnorm=0.992, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64243
2022-10-19 13:16:34 - progress_bar.py[line:274] - INFO: epoch 001:  13198 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.7, ups=0.88, wpb=111.2, bsz=40, num_updates=13180, lr=3.22139e-05, gnorm=1.009, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64254
2022-10-19 13:16:45 - progress_bar.py[line:274] - INFO: epoch 001:  13208 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101, ups=0.91, wpb=110.4, bsz=40, num_updates=13190, lr=3.22384e-05, gnorm=1.159, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64265
2022-10-19 13:16:56 - progress_bar.py[line:274] - INFO: epoch 001:  13218 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.1, ups=0.89, wpb=108.9, bsz=40, num_updates=13200, lr=3.22628e-05, gnorm=1.119, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64276
2022-10-19 13:17:08 - progress_bar.py[line:274] - INFO: epoch 001:  13228 / 102288 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=93.8, ups=0.87, wpb=107.8, bsz=40, num_updates=13210, lr=3.22872e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=64288
2022-10-19 13:17:19 - progress_bar.py[line:274] - INFO: epoch 001:  13238 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.6, ups=0.9, wpb=110, bsz=40, num_updates=13220, lr=3.23117e-05, gnorm=1.006, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=64299
2022-10-19 13:17:30 - progress_bar.py[line:274] - INFO: epoch 001:  13248 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=13230, lr=3.23361e-05, gnorm=0.958, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64310
2022-10-19 13:17:42 - progress_bar.py[line:274] - INFO: epoch 001:  13258 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.3, ups=0.86, wpb=110.2, bsz=40, num_updates=13240, lr=3.23606e-05, gnorm=1.051, clip=50, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=64322
2022-10-19 13:17:53 - progress_bar.py[line:274] - INFO: epoch 001:  13268 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.8, ups=0.9, wpb=111.2, bsz=40, num_updates=13250, lr=3.2385e-05, gnorm=1.041, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64333
2022-10-19 13:18:05 - progress_bar.py[line:274] - INFO: epoch 001:  13278 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=13260, lr=3.24094e-05, gnorm=1.086, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64344
2022-10-19 13:18:16 - progress_bar.py[line:274] - INFO: epoch 001:  13288 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=13270, lr=3.24339e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64356
2022-10-19 13:18:27 - progress_bar.py[line:274] - INFO: epoch 001:  13298 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=13280, lr=3.24583e-05, gnorm=1.101, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64367
2022-10-19 13:18:38 - progress_bar.py[line:274] - INFO: epoch 001:  13308 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.8, ups=0.88, wpb=111.5, bsz=40, num_updates=13290, lr=3.24828e-05, gnorm=0.927, clip=30, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=64378
2022-10-19 13:18:50 - progress_bar.py[line:274] - INFO: epoch 001:  13318 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.5, ups=0.88, wpb=108.9, bsz=40, num_updates=13300, lr=3.25072e-05, gnorm=1.068, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64390
2022-10-19 13:19:01 - progress_bar.py[line:274] - INFO: epoch 001:  13328 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.9, wpb=110.5, bsz=40, num_updates=13310, lr=3.25317e-05, gnorm=1.21, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64401
2022-10-19 13:19:12 - progress_bar.py[line:274] - INFO: epoch 001:  13338 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.3, ups=0.9, wpb=111.3, bsz=40, num_updates=13320, lr=3.25561e-05, gnorm=0.939, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64412
2022-10-19 13:19:23 - progress_bar.py[line:274] - INFO: epoch 001:  13348 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.5, ups=0.88, wpb=110, bsz=40, num_updates=13330, lr=3.25805e-05, gnorm=0.964, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64423
2022-10-19 13:19:35 - progress_bar.py[line:274] - INFO: epoch 001:  13358 / 102288 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97, ups=0.89, wpb=108.8, bsz=40, num_updates=13340, lr=3.2605e-05, gnorm=1.046, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64434
2022-10-19 13:19:46 - progress_bar.py[line:274] - INFO: epoch 001:  13368 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=13350, lr=3.26294e-05, gnorm=1.055, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64446
2022-10-19 13:19:57 - progress_bar.py[line:274] - INFO: epoch 001:  13378 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=13360, lr=3.26539e-05, gnorm=1.159, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64457
2022-10-19 13:20:08 - progress_bar.py[line:274] - INFO: epoch 001:  13388 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.6, ups=0.92, wpb=110.1, bsz=40, num_updates=13370, lr=3.26783e-05, gnorm=1.039, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64468
2022-10-19 13:20:19 - progress_bar.py[line:274] - INFO: epoch 001:  13398 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.6, ups=0.9, wpb=109.8, bsz=40, num_updates=13380, lr=3.27027e-05, gnorm=1.057, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64479
2022-10-19 13:20:30 - progress_bar.py[line:274] - INFO: epoch 001:  13408 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.8, ups=0.91, wpb=110.2, bsz=40, num_updates=13390, lr=3.27272e-05, gnorm=0.962, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64490
2022-10-19 13:20:41 - progress_bar.py[line:274] - INFO: epoch 001:  13418 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=13400, lr=3.27516e-05, gnorm=0.926, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64501
2022-10-19 13:20:53 - progress_bar.py[line:274] - INFO: epoch 001:  13428 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96, ups=0.87, wpb=110.5, bsz=40, num_updates=13410, lr=3.27761e-05, gnorm=1.229, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64512
2022-10-19 13:21:04 - progress_bar.py[line:274] - INFO: epoch 001:  13438 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=13420, lr=3.28005e-05, gnorm=0.962, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64524
2022-10-19 13:21:15 - progress_bar.py[line:274] - INFO: epoch 001:  13448 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.6, ups=0.9, wpb=109.6, bsz=40, num_updates=13430, lr=3.28249e-05, gnorm=0.967, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64535
2022-10-19 13:21:26 - progress_bar.py[line:274] - INFO: epoch 001:  13458 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.8, ups=0.89, wpb=110.1, bsz=40, num_updates=13440, lr=3.28494e-05, gnorm=1.212, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64546
2022-10-19 13:21:37 - progress_bar.py[line:274] - INFO: epoch 001:  13468 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=13450, lr=3.28738e-05, gnorm=1.098, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64557
2022-10-19 13:21:49 - progress_bar.py[line:274] - INFO: epoch 001:  13478 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.2, ups=0.88, wpb=109.6, bsz=40, num_updates=13460, lr=3.28983e-05, gnorm=0.995, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64569
2022-10-19 13:22:00 - progress_bar.py[line:274] - INFO: epoch 001:  13488 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=13470, lr=3.29227e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64580
2022-10-19 13:22:11 - progress_bar.py[line:274] - INFO: epoch 001:  13498 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102, ups=0.91, wpb=112, bsz=40, num_updates=13480, lr=3.29472e-05, gnorm=0.896, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64591
2022-10-19 13:22:22 - progress_bar.py[line:274] - INFO: epoch 001:  13508 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.8, ups=0.9, wpb=111.7, bsz=40, num_updates=13490, lr=3.29716e-05, gnorm=1.035, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64602
2022-10-19 13:22:33 - progress_bar.py[line:274] - INFO: epoch 001:  13518 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=13500, lr=3.2996e-05, gnorm=0.889, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64613
2022-10-19 13:22:45 - progress_bar.py[line:274] - INFO: epoch 001:  13528 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=13510, lr=3.30205e-05, gnorm=1.072, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64624
2022-10-19 13:22:56 - progress_bar.py[line:274] - INFO: epoch 001:  13538 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99, ups=0.9, wpb=110.3, bsz=40, num_updates=13520, lr=3.30449e-05, gnorm=0.973, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64636
2022-10-19 13:23:07 - progress_bar.py[line:274] - INFO: epoch 001:  13548 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.7, ups=0.89, wpb=110.1, bsz=40, num_updates=13530, lr=3.30694e-05, gnorm=1.165, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64647
2022-10-19 13:23:18 - progress_bar.py[line:274] - INFO: epoch 001:  13558 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.6, ups=0.89, wpb=111.1, bsz=40, num_updates=13540, lr=3.30938e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64658
2022-10-19 13:23:29 - progress_bar.py[line:274] - INFO: epoch 001:  13568 / 102288 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.5, ups=0.91, wpb=111.7, bsz=40, num_updates=13550, lr=3.31182e-05, gnorm=0.984, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64669
2022-10-19 13:23:41 - progress_bar.py[line:274] - INFO: epoch 001:  13578 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.3, ups=0.88, wpb=109.7, bsz=40, num_updates=13560, lr=3.31427e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64681
2022-10-19 13:23:52 - progress_bar.py[line:274] - INFO: epoch 001:  13588 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.7, ups=0.89, wpb=111.8, bsz=40, num_updates=13570, lr=3.31671e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64692
2022-10-19 13:24:03 - progress_bar.py[line:274] - INFO: epoch 001:  13598 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=13580, lr=3.31916e-05, gnorm=1.105, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64703
2022-10-19 13:24:14 - progress_bar.py[line:274] - INFO: epoch 001:  13608 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.89, wpb=110.8, bsz=40, num_updates=13590, lr=3.3216e-05, gnorm=1.042, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64714
2022-10-19 13:24:26 - progress_bar.py[line:274] - INFO: epoch 001:  13618 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=13600, lr=3.32405e-05, gnorm=0.925, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64725
2022-10-19 13:24:36 - progress_bar.py[line:274] - INFO: epoch 001:  13628 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.4, ups=0.92, wpb=110.8, bsz=40, num_updates=13610, lr=3.32649e-05, gnorm=0.937, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=64736
2022-10-19 13:24:48 - progress_bar.py[line:274] - INFO: epoch 001:  13638 / 102288 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=13620, lr=3.32893e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64748
2022-10-19 13:24:59 - progress_bar.py[line:274] - INFO: epoch 001:  13648 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=13630, lr=3.33138e-05, gnorm=0.97, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=64759
2022-10-19 13:25:10 - progress_bar.py[line:274] - INFO: epoch 001:  13658 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.9, ups=0.91, wpb=111.9, bsz=40, num_updates=13640, lr=3.33382e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=64770
2022-10-19 13:25:21 - progress_bar.py[line:274] - INFO: epoch 001:  13668 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102, ups=0.91, wpb=111.6, bsz=40, num_updates=13650, lr=3.33627e-05, gnorm=0.863, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64781
2022-10-19 13:25:32 - progress_bar.py[line:274] - INFO: epoch 001:  13678 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=13660, lr=3.33871e-05, gnorm=0.948, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64792
2022-10-19 13:25:43 - progress_bar.py[line:274] - INFO: epoch 001:  13688 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=13670, lr=3.34115e-05, gnorm=1.014, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64803
2022-10-19 13:25:55 - progress_bar.py[line:274] - INFO: epoch 001:  13698 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=94.7, ups=0.87, wpb=109.3, bsz=40, num_updates=13680, lr=3.3436e-05, gnorm=1.057, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64815
2022-10-19 13:26:06 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 13:26:07 - progress_bar.py[line:274] - INFO: epoch 001:  13709 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=92.9, ups=0.84, wpb=111, bsz=40, num_updates=13690, lr=3.34604e-05, gnorm=0.977, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=64826
2022-10-19 13:26:18 - progress_bar.py[line:274] - INFO: epoch 001:  13719 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.6, ups=0.89, wpb=111.9, bsz=40, num_updates=13700, lr=3.34849e-05, gnorm=1.037, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64838
2022-10-19 13:26:29 - progress_bar.py[line:274] - INFO: epoch 001:  13729 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.5, ups=0.9, wpb=111.6, bsz=40, num_updates=13710, lr=3.35093e-05, gnorm=0.985, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64849
2022-10-19 13:26:40 - progress_bar.py[line:274] - INFO: epoch 001:  13739 / 102288 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.4, ups=0.91, wpb=109.8, bsz=40, num_updates=13720, lr=3.35338e-05, gnorm=1.19, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64860
2022-10-19 13:26:51 - progress_bar.py[line:274] - INFO: epoch 001:  13749 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=13730, lr=3.35582e-05, gnorm=1.084, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64871
2022-10-19 13:27:03 - progress_bar.py[line:274] - INFO: epoch 001:  13759 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=91.8, ups=0.84, wpb=109.5, bsz=40, num_updates=13740, lr=3.35826e-05, gnorm=1.056, clip=40, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=64883
2022-10-19 13:27:14 - progress_bar.py[line:274] - INFO: epoch 001:  13769 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.8, ups=0.88, wpb=109.1, bsz=40, num_updates=13750, lr=3.36071e-05, gnorm=0.975, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64894
2022-10-19 13:27:25 - progress_bar.py[line:274] - INFO: epoch 001:  13779 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=13760, lr=3.36315e-05, gnorm=0.992, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=64905
2022-10-19 13:27:37 - progress_bar.py[line:274] - INFO: epoch 001:  13789 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.1, ups=0.87, wpb=109.9, bsz=40, num_updates=13770, lr=3.3656e-05, gnorm=1.165, clip=90, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=64917
2022-10-19 13:27:49 - progress_bar.py[line:274] - INFO: epoch 001:  13799 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=94.7, ups=0.86, wpb=109.7, bsz=40, num_updates=13780, lr=3.36804e-05, gnorm=1.11, clip=60, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=64928
2022-10-19 13:28:00 - progress_bar.py[line:274] - INFO: epoch 001:  13809 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96, ups=0.88, wpb=109.3, bsz=40, num_updates=13790, lr=3.37048e-05, gnorm=1.067, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64940
2022-10-19 13:28:11 - progress_bar.py[line:274] - INFO: epoch 001:  13819 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.7, ups=0.89, wpb=112.1, bsz=40, num_updates=13800, lr=3.37293e-05, gnorm=1.166, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=64951
2022-10-19 13:28:23 - progress_bar.py[line:274] - INFO: epoch 001:  13829 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=13810, lr=3.37537e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=64962
2022-10-19 13:28:33 - progress_bar.py[line:274] - INFO: epoch 001:  13839 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.6, ups=0.93, wpb=110.6, bsz=40, num_updates=13820, lr=3.37782e-05, gnorm=0.984, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=64973
2022-10-19 13:28:45 - progress_bar.py[line:274] - INFO: epoch 001:  13849 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.2, ups=0.87, wpb=111.1, bsz=40, num_updates=13830, lr=3.38026e-05, gnorm=1.13, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=64985
2022-10-19 13:28:56 - progress_bar.py[line:274] - INFO: epoch 001:  13859 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=13840, lr=3.38271e-05, gnorm=0.981, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=64996
2022-10-19 13:29:07 - progress_bar.py[line:274] - INFO: epoch 001:  13869 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=13850, lr=3.38515e-05, gnorm=1.071, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65007
2022-10-19 13:29:18 - progress_bar.py[line:274] - INFO: epoch 001:  13879 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100, ups=0.91, wpb=109.4, bsz=40, num_updates=13860, lr=3.38759e-05, gnorm=0.958, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=65018
2022-10-19 13:29:29 - progress_bar.py[line:274] - INFO: epoch 001:  13889 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=13870, lr=3.39004e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65029
2022-10-19 13:29:41 - progress_bar.py[line:274] - INFO: epoch 001:  13899 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.8, ups=0.87, wpb=110.4, bsz=40, num_updates=13880, lr=3.39248e-05, gnorm=0.926, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=65040
2022-10-19 13:29:52 - progress_bar.py[line:274] - INFO: epoch 001:  13909 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=13890, lr=3.39493e-05, gnorm=0.987, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65052
2022-10-19 13:30:03 - progress_bar.py[line:274] - INFO: epoch 001:  13919 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=13900, lr=3.39737e-05, gnorm=1.11, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65063
2022-10-19 13:30:14 - progress_bar.py[line:274] - INFO: epoch 001:  13929 / 102288 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=13910, lr=3.39981e-05, gnorm=0.968, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=65074
2022-10-19 13:30:26 - progress_bar.py[line:274] - INFO: epoch 001:  13939 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98, ups=0.89, wpb=110.3, bsz=40, num_updates=13920, lr=3.40226e-05, gnorm=1.198, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=65085
2022-10-19 13:30:37 - progress_bar.py[line:274] - INFO: epoch 001:  13949 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.8, ups=0.91, wpb=111.5, bsz=40, num_updates=13930, lr=3.4047e-05, gnorm=1.015, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=65096
2022-10-19 13:30:48 - progress_bar.py[line:274] - INFO: epoch 001:  13959 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.1, ups=0.87, wpb=108.5, bsz=40, num_updates=13940, lr=3.40715e-05, gnorm=1.141, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65108
2022-10-19 13:30:59 - progress_bar.py[line:274] - INFO: epoch 001:  13969 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.7, ups=0.88, wpb=112.2, bsz=40, num_updates=13950, lr=3.40959e-05, gnorm=0.958, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=65119
2022-10-19 13:31:11 - progress_bar.py[line:274] - INFO: epoch 001:  13979 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.5, ups=0.9, wpb=111.9, bsz=40, num_updates=13960, lr=3.41204e-05, gnorm=0.875, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=65130
2022-10-19 13:31:22 - progress_bar.py[line:274] - INFO: epoch 001:  13989 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.4, ups=0.87, wpb=110, bsz=40, num_updates=13970, lr=3.41448e-05, gnorm=1.009, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=65142
2022-10-19 13:31:33 - progress_bar.py[line:274] - INFO: epoch 001:  13999 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.1, ups=0.9, wpb=110.1, bsz=40, num_updates=13980, lr=3.41692e-05, gnorm=0.949, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=65153
2022-10-19 13:31:45 - progress_bar.py[line:274] - INFO: epoch 001:  14009 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.2, ups=0.87, wpb=110.7, bsz=40, num_updates=13990, lr=3.41937e-05, gnorm=1.018, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=65165
2022-10-19 13:31:56 - progress_bar.py[line:274] - INFO: epoch 001:  14019 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.2, ups=0.89, wpb=111.6, bsz=40, num_updates=14000, lr=3.42181e-05, gnorm=1.076, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=65176
2022-10-19 13:31:56 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 13:31:57 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 13:31:57 - train.py[line:551] - INFO: load:1.01 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 13:34:30 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 13:34:30 - train.py[line:551] - INFO: load:1.04 valid_run:152.30 task_valid:148.42 collect_output:2.79
2022-10-19 13:37:01 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 13:37:01 - train.py[line:551] - INFO: load:1.06 valid_run:303.24 task_valid:293.31 collect_output:7.62
2022-10-19 13:39:34 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 13:39:34 - train.py[line:551] - INFO: load:1.08 valid_run:456.17 task_valid:436.85 collect_output:15.95
2022-10-19 13:42:06 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 13:42:06 - train.py[line:551] - INFO: load:1.14 valid_run:608.19 task_valid:583.41 collect_output:20.15
2022-10-19 13:44:39 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 13:44:39 - train.py[line:551] - INFO: load:1.17 valid_run:761.18 task_valid:731.27 collect_output:24.22
2022-10-19 13:47:11 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 13:47:11 - train.py[line:551] - INFO: load:1.19 valid_run:913.15 task_valid:876.86 collect_output:29.62
2022-10-19 13:49:45 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 13:49:45 - train.py[line:551] - INFO: load:1.22 valid_run:1067.02 task_valid:1023.00 collect_output:36.33
2022-10-19 13:52:17 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 13:52:17 - train.py[line:551] - INFO: load:1.24 valid_run:1219.52 task_valid:1165.28 collect_output:45.33
2022-10-19 13:54:47 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 13:54:47 - train.py[line:551] - INFO: load:1.27 valid_run:1369.52 task_valid:1310.09 collect_output:49.51
2022-10-19 13:57:16 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 13:57:16 - train.py[line:551] - INFO: load:1.29 valid_run:1518.41 task_valid:1453.38 collect_output:54.12
2022-10-19 13:59:46 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 13:59:46 - train.py[line:551] - INFO: load:1.32 valid_run:1668.35 task_valid:1598.26 collect_output:58.16
2022-10-19 14:02:17 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 14:02:17 - train.py[line:551] - INFO: load:1.34 valid_run:1818.55 task_valid:1743.09 collect_output:62.55
2022-10-19 14:04:47 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 14:04:47 - train.py[line:551] - INFO: load:1.37 valid_run:1968.91 task_valid:1885.04 collect_output:69.96
2022-10-19 14:07:18 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 14:07:18 - train.py[line:551] - INFO: load:1.39 valid_run:2120.15 task_valid:2031.07 collect_output:74.14
2022-10-19 14:09:50 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 14:09:50 - train.py[line:551] - INFO: load:1.42 valid_run:2271.41 task_valid:2178.34 collect_output:76.94
2022-10-19 14:12:22 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 14:12:22 - train.py[line:551] - INFO: load:1.44 valid_run:2423.81 task_valid:2324.04 collect_output:82.41
2022-10-19 14:14:54 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 14:14:54 - train.py[line:551] - INFO: load:1.47 valid_run:2576.13 task_valid:2469.88 collect_output:87.86
2022-10-19 14:17:26 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 14:17:26 - train.py[line:551] - INFO: load:1.49 valid_run:2727.14 task_valid:2617.11 collect_output:90.63
2022-10-19 14:19:55 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 14:19:55 - train.py[line:551] - INFO: load:1.52 valid_run:2876.12 task_valid:2758.67 collect_output:97.06
2022-10-19 14:22:26 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 14:22:26 - train.py[line:551] - INFO: load:1.55 valid_run:3027.95 task_valid:2904.57 collect_output:101.82
2022-10-19 14:25:01 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 14:25:01 - train.py[line:551] - INFO: load:1.57 valid_run:3182.32 task_valid:3050.09 collect_output:109.46
2022-10-19 14:27:31 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 14:27:31 - train.py[line:551] - INFO: load:1.60 valid_run:3332.14 task_valid:3194.78 collect_output:113.57
2022-10-19 14:30:02 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 14:30:02 - train.py[line:551] - INFO: load:1.62 valid_run:3483.75 task_valid:3341.03 collect_output:117.92
2022-10-19 14:32:35 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 14:32:35 - train.py[line:551] - INFO: load:1.65 valid_run:3635.85 task_valid:3487.92 collect_output:122.11

====================================================================================================
SGG eval:     R @ 50: 0.5450;     R @ 100: 0.5866;     R @ 500: 0.6079;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3720;    mR @ 100: 0.4108;    mR @ 500: 0.4339;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.8750) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8644) (says:0.0000) (sitting on:0.7079) (standing on:0.1420) (using:0.6000) (walking in:0.0000) (walking on:0.8288) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2022-10-19 14:35:06 - train.py[line:487] - INFO: 0.5866148459383753
2022-10-19 14:35:07 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.5450;     R @ 100: 0.5866;     R @ 500: 0.6079;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3720;    mR @ 100: 0.4108;    mR @ 500: 0.4339;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.8750) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8644) (says:0.0000) (sitting on:0.7079) (standing on:0.1420) (using:0.6000) (walking in:0.0000) (walking on:0.8288) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2022-10-19 14:35:07 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.337 | loss_v1 0 | loss_v2 0 | nll_loss 0.179 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.586615 | ppl 1.13 | vqa_score 0.5135 | wps 118.4 | wpb 89.9 | bsz 30 | num_updates 14000 | best_R@100 0.593911
2022-10-19 14:35:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 14000 updates
2022-10-19 14:35:07 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_14000.pt
2022-10-19 14:35:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_14000.pt
2022-10-19 14:35:15 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 0.5866148459383753) (writing took 8.577136664651334 seconds)
2022-10-19 14:35:27 - progress_bar.py[line:274] - INFO: epoch 001:  14029 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=0.3, ups=0, wpb=109.6, bsz=40, num_updates=14010, lr=3.42426e-05, gnorm=1.1, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=68986
2022-10-19 14:35:38 - progress_bar.py[line:274] - INFO: epoch 001:  14039 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=14020, lr=3.4267e-05, gnorm=1.049, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=68997
2022-10-19 14:35:53 - progress_bar.py[line:274] - INFO: epoch 001:  14049 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.6, ups=0.9, wpb=111.5, bsz=40, num_updates=14030, lr=3.42914e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69009
2022-10-19 14:36:04 - progress_bar.py[line:274] - INFO: epoch 001:  14059 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.8, ups=0.9, wpb=109, bsz=40, num_updates=14040, lr=3.43159e-05, gnorm=0.93, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69024
2022-10-19 14:36:15 - progress_bar.py[line:274] - INFO: epoch 001:  14069 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.3, ups=0.89, wpb=109.5, bsz=40, num_updates=14050, lr=3.43403e-05, gnorm=1.112, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69035
2022-10-19 14:36:27 - progress_bar.py[line:274] - INFO: epoch 001:  14079 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.4, ups=0.87, wpb=110.2, bsz=40, num_updates=14060, lr=3.43648e-05, gnorm=0.88, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69046
2022-10-19 14:36:38 - progress_bar.py[line:274] - INFO: epoch 001:  14089 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.6, ups=0.88, wpb=110.3, bsz=40, num_updates=14070, lr=3.43892e-05, gnorm=1.109, clip=60, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=69058
2022-10-19 14:36:49 - progress_bar.py[line:274] - INFO: epoch 001:  14099 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.6, ups=0.91, wpb=109.9, bsz=40, num_updates=14080, lr=3.44136e-05, gnorm=1.043, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=69069
2022-10-19 14:37:00 - progress_bar.py[line:274] - INFO: epoch 001:  14109 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102.7, ups=0.92, wpb=111.5, bsz=40, num_updates=14090, lr=3.44381e-05, gnorm=1.039, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69080
2022-10-19 14:37:11 - progress_bar.py[line:274] - INFO: epoch 001:  14119 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.3, ups=0.89, wpb=110.6, bsz=40, num_updates=14100, lr=3.44625e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69091
2022-10-19 14:37:22 - progress_bar.py[line:274] - INFO: epoch 001:  14129 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.9, ups=0.89, wpb=110.3, bsz=40, num_updates=14110, lr=3.4487e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69102
2022-10-19 14:37:34 - progress_bar.py[line:274] - INFO: epoch 001:  14139 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=14120, lr=3.45114e-05, gnorm=1.168, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69113
2022-10-19 14:37:45 - progress_bar.py[line:274] - INFO: epoch 001:  14149 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=14130, lr=3.45359e-05, gnorm=0.963, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69125
2022-10-19 14:37:56 - progress_bar.py[line:274] - INFO: epoch 001:  14159 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102.3, ups=0.92, wpb=110.6, bsz=40, num_updates=14140, lr=3.45603e-05, gnorm=1.016, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69136
2022-10-19 14:38:07 - progress_bar.py[line:274] - INFO: epoch 001:  14169 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=14150, lr=3.45847e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69147
2022-10-19 14:38:19 - progress_bar.py[line:274] - INFO: epoch 001:  14179 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.2, ups=0.88, wpb=110.7, bsz=40, num_updates=14160, lr=3.46092e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69158
2022-10-19 14:38:30 - progress_bar.py[line:274] - INFO: epoch 001:  14189 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.1, ups=0.91, wpb=109.7, bsz=40, num_updates=14170, lr=3.46336e-05, gnorm=1.017, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69169
2022-10-19 14:38:41 - progress_bar.py[line:274] - INFO: epoch 001:  14199 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.8, ups=0.9, wpb=111, bsz=40, num_updates=14180, lr=3.46581e-05, gnorm=0.922, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69180
2022-10-19 14:38:52 - progress_bar.py[line:274] - INFO: epoch 001:  14209 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.4, ups=0.9, wpb=109.4, bsz=40, num_updates=14190, lr=3.46825e-05, gnorm=1.022, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69192
2022-10-19 14:39:03 - progress_bar.py[line:274] - INFO: epoch 001:  14219 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.2, ups=0.9, wpb=108.8, bsz=40, num_updates=14200, lr=3.47069e-05, gnorm=1.051, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=69203
2022-10-19 14:39:14 - progress_bar.py[line:274] - INFO: epoch 001:  14229 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=14210, lr=3.47314e-05, gnorm=1.002, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=69214
2022-10-19 14:39:25 - progress_bar.py[line:274] - INFO: epoch 001:  14239 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.5, ups=0.89, wpb=108.4, bsz=40, num_updates=14220, lr=3.47558e-05, gnorm=1.031, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69225
2022-10-19 14:39:37 - progress_bar.py[line:274] - INFO: epoch 001:  14249 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.9, ups=0.89, wpb=110.1, bsz=40, num_updates=14230, lr=3.47803e-05, gnorm=0.985, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69236
2022-10-19 14:39:48 - progress_bar.py[line:274] - INFO: epoch 001:  14259 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=14240, lr=3.48047e-05, gnorm=0.917, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69248
2022-10-19 14:39:59 - progress_bar.py[line:274] - INFO: epoch 001:  14269 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.8, ups=0.92, wpb=109, bsz=40, num_updates=14250, lr=3.48292e-05, gnorm=0.989, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=69259
2022-10-19 14:40:10 - progress_bar.py[line:274] - INFO: epoch 001:  14279 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=14260, lr=3.48536e-05, gnorm=1.011, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=69270
2022-10-19 14:40:21 - progress_bar.py[line:274] - INFO: epoch 001:  14289 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=14270, lr=3.4878e-05, gnorm=0.987, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69281
2022-10-19 14:40:32 - progress_bar.py[line:274] - INFO: epoch 001:  14299 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=14280, lr=3.49025e-05, gnorm=0.92, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=69292
2022-10-19 14:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  14309 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.5, ups=0.91, wpb=108.1, bsz=40, num_updates=14290, lr=3.49269e-05, gnorm=1.043, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69303
2022-10-19 14:40:55 - progress_bar.py[line:274] - INFO: epoch 001:  14319 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=14300, lr=3.49514e-05, gnorm=0.939, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69314
2022-10-19 14:41:06 - progress_bar.py[line:274] - INFO: epoch 001:  14329 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.3, ups=0.9, wpb=111.9, bsz=40, num_updates=14310, lr=3.49758e-05, gnorm=0.926, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69326
2022-10-19 14:41:17 - progress_bar.py[line:274] - INFO: epoch 001:  14339 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.6, ups=0.9, wpb=109.3, bsz=40, num_updates=14320, lr=3.50002e-05, gnorm=1.078, clip=50, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=69337
2022-10-19 14:41:28 - progress_bar.py[line:274] - INFO: epoch 001:  14349 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.88, wpb=110.8, bsz=40, num_updates=14330, lr=3.50247e-05, gnorm=0.968, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69348
2022-10-19 14:41:33 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 14:41:40 - progress_bar.py[line:274] - INFO: epoch 001:  14360 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.3, ups=0.82, wpb=110.5, bsz=40, num_updates=14340, lr=3.50491e-05, gnorm=0.971, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=69360
2022-10-19 14:41:52 - progress_bar.py[line:274] - INFO: epoch 001:  14370 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.4, ups=0.87, wpb=110.1, bsz=40, num_updates=14350, lr=3.50736e-05, gnorm=1.106, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69372
2022-10-19 14:42:03 - progress_bar.py[line:274] - INFO: epoch 001:  14380 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.5, ups=0.93, wpb=109.5, bsz=40, num_updates=14360, lr=3.5098e-05, gnorm=1.041, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69383
2022-10-19 14:42:14 - progress_bar.py[line:274] - INFO: epoch 001:  14390 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.6, ups=0.87, wpb=110.2, bsz=40, num_updates=14370, lr=3.51225e-05, gnorm=0.944, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69394
2022-10-19 14:42:26 - progress_bar.py[line:274] - INFO: epoch 001:  14400 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.3, ups=0.88, wpb=109.5, bsz=40, num_updates=14380, lr=3.51469e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69405
2022-10-19 14:42:37 - progress_bar.py[line:274] - INFO: epoch 001:  14410 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=14390, lr=3.51713e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69417
2022-10-19 14:42:48 - progress_bar.py[line:274] - INFO: epoch 001:  14420 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.9, ups=0.91, wpb=109.4, bsz=40, num_updates=14400, lr=3.51958e-05, gnorm=0.976, clip=60, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=69428
2022-10-19 14:42:59 - progress_bar.py[line:274] - INFO: epoch 001:  14430 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=14410, lr=3.52202e-05, gnorm=1.078, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=69439
2022-10-19 14:43:10 - progress_bar.py[line:274] - INFO: epoch 001:  14440 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102.6, ups=0.93, wpb=110.8, bsz=40, num_updates=14420, lr=3.52447e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69450
2022-10-19 14:43:21 - progress_bar.py[line:274] - INFO: epoch 001:  14450 / 102288 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=102.4, ups=0.93, wpb=110.6, bsz=40, num_updates=14430, lr=3.52691e-05, gnorm=0.963, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69461
2022-10-19 14:43:32 - progress_bar.py[line:274] - INFO: epoch 001:  14460 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.1, ups=0.9, wpb=109.9, bsz=40, num_updates=14440, lr=3.52935e-05, gnorm=0.966, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69472
2022-10-19 14:43:43 - progress_bar.py[line:274] - INFO: epoch 001:  14470 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97, ups=0.89, wpb=109.1, bsz=40, num_updates=14450, lr=3.5318e-05, gnorm=0.947, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69483
2022-10-19 14:43:54 - progress_bar.py[line:274] - INFO: epoch 001:  14480 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=14460, lr=3.53424e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69494
2022-10-19 14:44:06 - progress_bar.py[line:274] - INFO: epoch 001:  14490 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=14470, lr=3.53669e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69505
2022-10-19 14:44:17 - progress_bar.py[line:274] - INFO: epoch 001:  14500 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.9, ups=0.89, wpb=111.4, bsz=40, num_updates=14480, lr=3.53913e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69517
2022-10-19 14:44:28 - progress_bar.py[line:274] - INFO: epoch 001:  14510 / 102288 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=101.8, ups=0.92, wpb=110.3, bsz=40, num_updates=14490, lr=3.54158e-05, gnorm=1.032, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=69528
2022-10-19 14:44:39 - progress_bar.py[line:274] - INFO: epoch 001:  14520 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.9, ups=0.9, wpb=109.9, bsz=40, num_updates=14500, lr=3.54402e-05, gnorm=0.946, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=69539
2022-10-19 14:44:50 - progress_bar.py[line:274] - INFO: epoch 001:  14530 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=14510, lr=3.54646e-05, gnorm=0.99, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=69550
2022-10-19 14:45:01 - progress_bar.py[line:274] - INFO: epoch 001:  14540 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.8, ups=0.9, wpb=110.8, bsz=40, num_updates=14520, lr=3.54891e-05, gnorm=0.952, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=69561
2022-10-19 14:45:12 - progress_bar.py[line:274] - INFO: epoch 001:  14550 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96, ups=0.88, wpb=109.1, bsz=40, num_updates=14530, lr=3.55135e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69572
2022-10-19 14:45:24 - progress_bar.py[line:274] - INFO: epoch 001:  14560 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=14540, lr=3.5538e-05, gnorm=1.04, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69583
2022-10-19 14:45:35 - progress_bar.py[line:274] - INFO: epoch 001:  14570 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=14550, lr=3.55624e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69595
2022-10-19 14:45:46 - progress_bar.py[line:274] - INFO: epoch 001:  14580 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=14560, lr=3.55868e-05, gnorm=0.901, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69606
2022-10-19 14:45:57 - progress_bar.py[line:274] - INFO: epoch 001:  14590 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=103.2, ups=0.94, wpb=109.7, bsz=40, num_updates=14570, lr=3.56113e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69617
2022-10-19 14:46:08 - progress_bar.py[line:274] - INFO: epoch 001:  14600 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100, ups=0.9, wpb=111.1, bsz=40, num_updates=14580, lr=3.56357e-05, gnorm=0.955, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69628
2022-10-19 14:46:19 - progress_bar.py[line:274] - INFO: epoch 001:  14610 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.4, ups=0.87, wpb=111.3, bsz=40, num_updates=14590, lr=3.56602e-05, gnorm=0.978, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69639
2022-10-19 14:46:31 - progress_bar.py[line:274] - INFO: epoch 001:  14620 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=14600, lr=3.56846e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=69651
2022-10-19 14:46:42 - progress_bar.py[line:274] - INFO: epoch 001:  14630 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.6, ups=0.9, wpb=110.4, bsz=40, num_updates=14610, lr=3.5709e-05, gnorm=0.915, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69662
2022-10-19 14:46:53 - progress_bar.py[line:274] - INFO: epoch 001:  14640 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.2, ups=0.91, wpb=110.7, bsz=40, num_updates=14620, lr=3.57335e-05, gnorm=1.147, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69673
2022-10-19 14:47:04 - progress_bar.py[line:274] - INFO: epoch 001:  14650 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.1, ups=0.88, wpb=109.4, bsz=40, num_updates=14630, lr=3.57579e-05, gnorm=1.15, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69684
2022-10-19 14:47:16 - progress_bar.py[line:274] - INFO: epoch 001:  14660 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98, ups=0.89, wpb=110.3, bsz=40, num_updates=14640, lr=3.57824e-05, gnorm=1.074, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69695
2022-10-19 14:47:27 - progress_bar.py[line:274] - INFO: epoch 001:  14670 / 102288 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.6, ups=0.91, wpb=110.3, bsz=40, num_updates=14650, lr=3.58068e-05, gnorm=1.089, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69706
2022-10-19 14:47:38 - progress_bar.py[line:274] - INFO: epoch 001:  14680 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.8, ups=0.88, wpb=109.2, bsz=40, num_updates=14660, lr=3.58313e-05, gnorm=0.979, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69718
2022-10-19 14:47:49 - progress_bar.py[line:274] - INFO: epoch 001:  14690 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=14670, lr=3.58557e-05, gnorm=0.943, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69729
2022-10-19 14:48:00 - progress_bar.py[line:274] - INFO: epoch 001:  14700 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.2, ups=0.89, wpb=109.3, bsz=40, num_updates=14680, lr=3.58801e-05, gnorm=0.977, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69740
2022-10-19 14:48:11 - progress_bar.py[line:274] - INFO: epoch 001:  14710 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101, ups=0.92, wpb=109.4, bsz=40, num_updates=14690, lr=3.59046e-05, gnorm=1.087, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=69751
2022-10-19 14:48:22 - progress_bar.py[line:274] - INFO: epoch 001:  14720 / 102288 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=14700, lr=3.5929e-05, gnorm=0.964, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69762
2022-10-19 14:48:33 - progress_bar.py[line:274] - INFO: epoch 001:  14730 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=103.3, ups=0.94, wpb=110, bsz=40, num_updates=14710, lr=3.59535e-05, gnorm=0.843, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=69773
2022-10-19 14:48:44 - progress_bar.py[line:274] - INFO: epoch 001:  14740 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.7, ups=0.89, wpb=108.6, bsz=40, num_updates=14720, lr=3.59779e-05, gnorm=0.97, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=69784
2022-10-19 14:48:55 - progress_bar.py[line:274] - INFO: epoch 001:  14750 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=14730, lr=3.60023e-05, gnorm=0.911, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69795
2022-10-19 14:49:06 - progress_bar.py[line:274] - INFO: epoch 001:  14760 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.7, ups=0.9, wpb=109.5, bsz=40, num_updates=14740, lr=3.60268e-05, gnorm=1.024, clip=50, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=69806
2022-10-19 14:49:18 - progress_bar.py[line:274] - INFO: epoch 001:  14770 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.3, ups=0.87, wpb=110.9, bsz=40, num_updates=14750, lr=3.60512e-05, gnorm=0.968, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=69818
2022-10-19 14:49:29 - progress_bar.py[line:274] - INFO: epoch 001:  14780 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.6, ups=0.91, wpb=111.3, bsz=40, num_updates=14760, lr=3.60757e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69829
2022-10-19 14:49:41 - progress_bar.py[line:274] - INFO: epoch 001:  14790 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=14770, lr=3.61001e-05, gnorm=1.115, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69840
2022-10-19 14:49:52 - progress_bar.py[line:274] - INFO: epoch 001:  14800 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.9, ups=0.89, wpb=110.2, bsz=40, num_updates=14780, lr=3.61246e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69852
2022-10-19 14:50:03 - progress_bar.py[line:274] - INFO: epoch 001:  14810 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.9, ups=0.9, wpb=111.9, bsz=40, num_updates=14790, lr=3.6149e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=69863
2022-10-19 14:50:14 - progress_bar.py[line:274] - INFO: epoch 001:  14820 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.5, ups=0.91, wpb=110.2, bsz=40, num_updates=14800, lr=3.61734e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69874
2022-10-19 14:50:25 - progress_bar.py[line:274] - INFO: epoch 001:  14830 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.8, ups=0.89, wpb=110.1, bsz=40, num_updates=14810, lr=3.61979e-05, gnorm=1.06, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=69885
2022-10-19 14:50:36 - progress_bar.py[line:274] - INFO: epoch 001:  14840 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.6, ups=0.89, wpb=108.5, bsz=40, num_updates=14820, lr=3.62223e-05, gnorm=1.057, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69896
2022-10-19 14:50:47 - progress_bar.py[line:274] - INFO: epoch 001:  14850 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.7, ups=0.9, wpb=109.8, bsz=40, num_updates=14830, lr=3.62468e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69907
2022-10-19 14:50:58 - progress_bar.py[line:274] - INFO: epoch 001:  14860 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.2, ups=0.91, wpb=109.7, bsz=40, num_updates=14840, lr=3.62712e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69918
2022-10-19 14:51:10 - progress_bar.py[line:274] - INFO: epoch 001:  14870 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.7, ups=0.9, wpb=109.8, bsz=40, num_updates=14850, lr=3.62956e-05, gnorm=0.982, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69929
2022-10-19 14:51:21 - progress_bar.py[line:274] - INFO: epoch 001:  14880 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.9, wpb=108.9, bsz=40, num_updates=14860, lr=3.63201e-05, gnorm=0.895, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69940
2022-10-19 14:51:32 - progress_bar.py[line:274] - INFO: epoch 001:  14890 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.6, ups=0.87, wpb=111.3, bsz=40, num_updates=14870, lr=3.63445e-05, gnorm=0.974, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=69952
2022-10-19 14:51:44 - progress_bar.py[line:274] - INFO: epoch 001:  14900 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.5, ups=0.87, wpb=109.8, bsz=40, num_updates=14880, lr=3.6369e-05, gnorm=0.969, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69963
2022-10-19 14:51:55 - progress_bar.py[line:274] - INFO: epoch 001:  14910 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.2, ups=0.89, wpb=110.6, bsz=40, num_updates=14890, lr=3.63934e-05, gnorm=0.96, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=69975
2022-10-19 14:52:06 - progress_bar.py[line:274] - INFO: epoch 001:  14920 / 102288 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=94.4, ups=0.88, wpb=107.6, bsz=40, num_updates=14900, lr=3.64179e-05, gnorm=1.029, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=69986
2022-10-19 14:52:17 - progress_bar.py[line:274] - INFO: epoch 001:  14930 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.9, ups=0.91, wpb=112.6, bsz=40, num_updates=14910, lr=3.64423e-05, gnorm=0.983, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=69997
2022-10-19 14:52:28 - progress_bar.py[line:274] - INFO: epoch 001:  14940 / 102288 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.9, ups=0.9, wpb=109.9, bsz=40, num_updates=14920, lr=3.64667e-05, gnorm=1.028, clip=70, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=70008
2022-10-19 14:52:40 - progress_bar.py[line:274] - INFO: epoch 001:  14950 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.8, ups=0.88, wpb=109, bsz=40, num_updates=14930, lr=3.64912e-05, gnorm=0.932, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=70020
2022-10-19 14:52:51 - progress_bar.py[line:274] - INFO: epoch 001:  14960 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.1, ups=0.87, wpb=109.3, bsz=40, num_updates=14940, lr=3.65156e-05, gnorm=1.005, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=70031
2022-10-19 14:53:03 - progress_bar.py[line:274] - INFO: epoch 001:  14970 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.89, wpb=110.8, bsz=40, num_updates=14950, lr=3.65401e-05, gnorm=1.006, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=70042
2022-10-19 14:53:14 - progress_bar.py[line:274] - INFO: epoch 001:  14980 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=14960, lr=3.65645e-05, gnorm=1.267, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=70054
2022-10-19 14:53:25 - progress_bar.py[line:274] - INFO: epoch 001:  14990 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=14970, lr=3.65889e-05, gnorm=1.04, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=70065
2022-10-19 14:53:36 - progress_bar.py[line:274] - INFO: epoch 001:  15000 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.9, ups=0.9, wpb=110.1, bsz=40, num_updates=14980, lr=3.66134e-05, gnorm=0.941, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=70076
2022-10-19 14:53:47 - progress_bar.py[line:274] - INFO: epoch 001:  15010 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.8, ups=0.87, wpb=109.1, bsz=40, num_updates=14990, lr=3.66378e-05, gnorm=0.856, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=70087
2022-10-19 14:54:00 - progress_bar.py[line:274] - INFO: epoch 001:  15020 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92, ups=0.82, wpb=112, bsz=40, num_updates=15000, lr=3.66623e-05, gnorm=0.857, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=70099
2022-10-19 14:54:00 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 14:54:01 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 14:54:01 - train.py[line:551] - INFO: load:1.38 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 14:56:42 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 14:56:42 - train.py[line:551] - INFO: load:1.41 valid_run:160.17 task_valid:155.52 collect_output:3.25
2022-10-19 14:59:13 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 14:59:13 - train.py[line:551] - INFO: load:1.44 valid_run:311.85 task_valid:300.79 collect_output:8.49
2022-10-19 15:01:47 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 15:01:47 - train.py[line:551] - INFO: load:1.46 valid_run:465.18 task_valid:444.37 collect_output:17.18
2022-10-19 15:04:16 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 15:04:16 - train.py[line:551] - INFO: load:1.49 valid_run:614.51 task_valid:589.32 collect_output:20.55
2022-10-19 15:06:49 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 15:06:49 - train.py[line:551] - INFO: load:1.51 valid_run:766.99 task_valid:736.85 collect_output:24.49
2022-10-19 15:09:21 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 15:09:21 - train.py[line:551] - INFO: load:1.54 valid_run:919.13 task_valid:882.68 collect_output:29.81
2022-10-19 15:11:55 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 15:11:55 - train.py[line:551] - INFO: load:1.56 valid_run:1072.95 task_valid:1028.67 collect_output:36.66
2022-10-19 15:14:26 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 15:14:26 - train.py[line:551] - INFO: load:1.59 valid_run:1224.41 task_valid:1169.74 collect_output:46.05
2022-10-19 15:16:56 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 15:16:56 - train.py[line:551] - INFO: load:1.61 valid_run:1374.19 task_valid:1314.45 collect_output:50.14
2022-10-19 15:19:25 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 15:19:25 - train.py[line:551] - INFO: load:1.64 valid_run:1523.02 task_valid:1457.54 collect_output:54.89
2022-10-19 15:21:56 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 15:21:56 - train.py[line:551] - INFO: load:1.66 valid_run:1673.68 task_valid:1603.28 collect_output:58.79
2022-10-19 15:24:26 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 15:24:26 - train.py[line:551] - INFO: load:1.69 valid_run:1824.18 task_valid:1748.25 collect_output:63.31
2022-10-19 15:26:57 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 15:26:57 - train.py[line:551] - INFO: load:1.71 valid_run:1974.42 task_valid:1889.86 collect_output:70.96
2022-10-19 15:29:27 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 15:29:27 - train.py[line:551] - INFO: load:1.74 valid_run:2125.15 task_valid:2035.36 collect_output:75.20
2022-10-19 15:31:58 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 15:31:58 - train.py[line:551] - INFO: load:1.76 valid_run:2275.53 task_valid:2181.97 collect_output:77.97
2022-10-19 15:34:28 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 15:34:28 - train.py[line:551] - INFO: load:1.79 valid_run:2426.03 task_valid:2326.01 collect_output:83.43
2022-10-19 15:37:00 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 15:37:00 - train.py[line:551] - INFO: load:1.81 valid_run:2578.09 task_valid:2471.44 collect_output:89.07
2022-10-19 15:39:31 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 15:39:31 - train.py[line:551] - INFO: load:1.84 valid_run:2728.85 task_valid:2618.37 collect_output:91.92
2022-10-19 15:42:00 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 15:42:00 - train.py[line:551] - INFO: load:1.86 valid_run:2877.73 task_valid:2760.16 collect_output:98.01
2022-10-19 15:44:31 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 15:44:31 - train.py[line:551] - INFO: load:1.89 valid_run:3028.68 task_valid:2905.30 collect_output:102.83
2022-10-19 15:47:04 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 15:47:04 - train.py[line:551] - INFO: load:1.91 valid_run:3181.46 task_valid:3050.03 collect_output:109.85
2022-10-19 15:49:34 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 15:49:34 - train.py[line:551] - INFO: load:1.94 valid_run:3331.46 task_valid:3194.80 collect_output:114.04
2022-10-19 15:52:06 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 15:52:06 - train.py[line:551] - INFO: load:1.96 valid_run:3483.50 task_valid:3341.40 collect_output:118.40
2022-10-19 15:54:38 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 15:54:38 - train.py[line:551] - INFO: load:1.99 valid_run:3635.61 task_valid:3488.13 collect_output:122.70

====================================================================================================
SGG eval:     R @ 50: 0.5543;     R @ 100: 0.5848;     R @ 500: 0.6080;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3879;    mR @ 100: 0.4122;    mR @ 500: 0.4319;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.8750) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.6129) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8595) (says:0.0000) (sitting on:0.6848) (standing on:0.1553) (using:0.6000) (walking in:0.0000) (walking on:0.8153) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5543;     R @ 100: 0.5848;     R @ 500: 0.6080;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3879;    mR @ 100: 0.4122;    mR @ 500: 0.4319;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.8750) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.6129) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8595) (says:0.0000) (sitting on:0.6848) (standing on:0.1553) (using:0.6000) (walking in:0.0000) (walking on:0.8153) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================

2022-10-19 15:57:10 - train.py[line:487] - INFO: 0.5847815126050421
2022-10-19 15:57:10 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 15:57:10 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.335 | loss_v1 0 | loss_v2 0 | nll_loss 0.172 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.584782 | ppl 1.13 | vqa_score 0.5236 | wps 118.4 | wpb 89.9 | bsz 30 | num_updates 15000 | best_R@100 0.593911
2022-10-19 15:57:10 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 15000 updates
2022-10-19 15:57:10 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_15000.pt
2022-10-19 15:57:16 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_15000.pt
2022-10-19 15:57:19 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_15000.pt (epoch 1 @ 15000 updates, score 0.5847815126050421) (writing took 8.63560845842585 seconds)
2022-10-19 15:57:31 - progress_bar.py[line:274] - INFO: epoch 001:  15030 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=0.3, ups=0, wpb=109.4, bsz=40, num_updates=15010, lr=3.66867e-05, gnorm=0.907, clip=40, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=73910
2022-10-19 15:57:46 - progress_bar.py[line:274] - INFO: epoch 001:  15040 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=15020, lr=3.67112e-05, gnorm=1.083, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73922
2022-10-19 15:57:57 - progress_bar.py[line:274] - INFO: epoch 001:  15050 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97, ups=0.89, wpb=109.2, bsz=40, num_updates=15030, lr=3.67356e-05, gnorm=0.989, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=73937
2022-10-19 15:58:08 - progress_bar.py[line:274] - INFO: epoch 001:  15060 / 102288 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.9, ups=0.87, wpb=109.6, bsz=40, num_updates=15040, lr=3.676e-05, gnorm=1.015, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73948
2022-10-19 15:58:20 - progress_bar.py[line:274] - INFO: epoch 001:  15070 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.4, ups=0.87, wpb=110.2, bsz=40, num_updates=15050, lr=3.67845e-05, gnorm=0.99, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=73960
2022-10-19 15:58:31 - progress_bar.py[line:274] - INFO: epoch 001:  15080 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=15060, lr=3.68089e-05, gnorm=0.85, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73971
2022-10-19 15:58:42 - progress_bar.py[line:274] - INFO: epoch 001:  15090 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.5, ups=0.86, wpb=111.6, bsz=40, num_updates=15070, lr=3.68334e-05, gnorm=0.896, clip=30, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=73982
2022-10-19 15:58:54 - progress_bar.py[line:274] - INFO: epoch 001:  15100 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.2, ups=0.89, wpb=111.6, bsz=40, num_updates=15080, lr=3.68578e-05, gnorm=0.88, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=73994
2022-10-19 15:59:05 - progress_bar.py[line:274] - INFO: epoch 001:  15110 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=15090, lr=3.68822e-05, gnorm=1.073, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74005
2022-10-19 15:59:10 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 15:59:17 - progress_bar.py[line:274] - INFO: epoch 001:  15121 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=89.9, ups=0.82, wpb=110.1, bsz=40, num_updates=15100, lr=3.69067e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=74017
2022-10-19 15:59:29 - progress_bar.py[line:274] - INFO: epoch 001:  15131 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.3, ups=0.88, wpb=109.6, bsz=40, num_updates=15110, lr=3.69311e-05, gnorm=1.068, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74028
2022-10-19 15:59:40 - progress_bar.py[line:274] - INFO: epoch 001:  15141 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.2, ups=0.9, wpb=111.2, bsz=40, num_updates=15120, lr=3.69556e-05, gnorm=0.92, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74039
2022-10-19 15:59:51 - progress_bar.py[line:274] - INFO: epoch 001:  15151 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.5, ups=0.87, wpb=111.2, bsz=40, num_updates=15130, lr=3.698e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74051
2022-10-19 16:00:02 - progress_bar.py[line:274] - INFO: epoch 001:  15161 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=15140, lr=3.70044e-05, gnorm=1.025, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74062
2022-10-19 16:00:14 - progress_bar.py[line:274] - INFO: epoch 001:  15171 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=15150, lr=3.70289e-05, gnorm=1.008, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=74074
2022-10-19 16:00:25 - progress_bar.py[line:274] - INFO: epoch 001:  15181 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.1, ups=0.9, wpb=108.9, bsz=40, num_updates=15160, lr=3.70533e-05, gnorm=1.026, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74085
2022-10-19 16:00:36 - progress_bar.py[line:274] - INFO: epoch 001:  15191 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98, ups=0.89, wpb=110.2, bsz=40, num_updates=15170, lr=3.70778e-05, gnorm=0.91, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74096
2022-10-19 16:00:48 - progress_bar.py[line:274] - INFO: epoch 001:  15201 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.1, ups=0.87, wpb=110.1, bsz=40, num_updates=15180, lr=3.71022e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74107
2022-10-19 16:00:59 - progress_bar.py[line:274] - INFO: epoch 001:  15211 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=15190, lr=3.71267e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74119
2022-10-19 16:01:10 - progress_bar.py[line:274] - INFO: epoch 001:  15221 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.2, ups=0.9, wpb=110.1, bsz=40, num_updates=15200, lr=3.71511e-05, gnorm=0.967, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=74130
2022-10-19 16:01:21 - progress_bar.py[line:274] - INFO: epoch 001:  15231 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.7, ups=0.91, wpb=109.2, bsz=40, num_updates=15210, lr=3.71755e-05, gnorm=0.981, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74141
2022-10-19 16:01:32 - progress_bar.py[line:274] - INFO: epoch 001:  15241 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.52, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.7, ups=0.88, wpb=110.3, bsz=40, num_updates=15220, lr=3.72e-05, gnorm=1.061, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74152
2022-10-19 16:01:43 - progress_bar.py[line:274] - INFO: epoch 001:  15251 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100, ups=0.92, wpb=109.1, bsz=40, num_updates=15230, lr=3.72244e-05, gnorm=0.973, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74163
2022-10-19 16:01:55 - progress_bar.py[line:274] - INFO: epoch 001:  15261 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95, ups=0.86, wpb=109.9, bsz=40, num_updates=15240, lr=3.72489e-05, gnorm=1.087, clip=70, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74175
2022-10-19 16:02:06 - progress_bar.py[line:274] - INFO: epoch 001:  15271 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=101.2, ups=0.92, wpb=109.5, bsz=40, num_updates=15250, lr=3.72733e-05, gnorm=0.933, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=74186
2022-10-19 16:02:17 - progress_bar.py[line:274] - INFO: epoch 001:  15281 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.7, ups=0.92, wpb=111.1, bsz=40, num_updates=15260, lr=3.72977e-05, gnorm=1.051, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74196
2022-10-19 16:02:28 - progress_bar.py[line:274] - INFO: epoch 001:  15291 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.4, ups=0.9, wpb=109, bsz=40, num_updates=15270, lr=3.73222e-05, gnorm=0.94, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74208
2022-10-19 16:02:38 - progress_bar.py[line:274] - INFO: epoch 001:  15301 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=104.3, ups=0.94, wpb=111.1, bsz=40, num_updates=15280, lr=3.73466e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74218
2022-10-19 16:02:50 - progress_bar.py[line:274] - INFO: epoch 001:  15311 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.2, ups=0.88, wpb=111.7, bsz=40, num_updates=15290, lr=3.73711e-05, gnorm=1.062, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74230
2022-10-19 16:03:01 - progress_bar.py[line:274] - INFO: epoch 001:  15321 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=15300, lr=3.73955e-05, gnorm=0.88, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74241
2022-10-19 16:03:12 - progress_bar.py[line:274] - INFO: epoch 001:  15331 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.3, ups=0.88, wpb=110.8, bsz=40, num_updates=15310, lr=3.742e-05, gnorm=0.926, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74252
2022-10-19 16:03:24 - progress_bar.py[line:274] - INFO: epoch 001:  15341 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.1, ups=0.89, wpb=108, bsz=40, num_updates=15320, lr=3.74444e-05, gnorm=1.046, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74263
2022-10-19 16:03:35 - progress_bar.py[line:274] - INFO: epoch 001:  15351 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.7, ups=0.9, wpb=110.7, bsz=40, num_updates=15330, lr=3.74688e-05, gnorm=0.912, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74275
2022-10-19 16:03:46 - progress_bar.py[line:274] - INFO: epoch 001:  15361 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98, ups=0.89, wpb=110.3, bsz=40, num_updates=15340, lr=3.74933e-05, gnorm=0.992, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74286
2022-10-19 16:03:57 - progress_bar.py[line:274] - INFO: epoch 001:  15371 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.9, ups=0.89, wpb=110.1, bsz=40, num_updates=15350, lr=3.75177e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74297
2022-10-19 16:04:09 - progress_bar.py[line:274] - INFO: epoch 001:  15381 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=15360, lr=3.75422e-05, gnorm=0.922, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74308
2022-10-19 16:04:20 - progress_bar.py[line:274] - INFO: epoch 001:  15391 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.8, ups=0.87, wpb=110.4, bsz=40, num_updates=15370, lr=3.75666e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74320
2022-10-19 16:04:32 - progress_bar.py[line:274] - INFO: epoch 001:  15401 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.8, ups=0.88, wpb=110.4, bsz=40, num_updates=15380, lr=3.7591e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74331
2022-10-19 16:04:43 - progress_bar.py[line:274] - INFO: epoch 001:  15411 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.4, ups=0.89, wpb=112.1, bsz=40, num_updates=15390, lr=3.76155e-05, gnorm=0.823, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74343
2022-10-19 16:04:54 - progress_bar.py[line:274] - INFO: epoch 001:  15421 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.2, ups=0.91, wpb=109.9, bsz=40, num_updates=15400, lr=3.76399e-05, gnorm=1.066, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74354
2022-10-19 16:05:05 - progress_bar.py[line:274] - INFO: epoch 001:  15431 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99, ups=0.9, wpb=110.2, bsz=40, num_updates=15410, lr=3.76644e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=74365
2022-10-19 16:05:17 - progress_bar.py[line:274] - INFO: epoch 001:  15441 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.3, ups=0.87, wpb=110.9, bsz=40, num_updates=15420, lr=3.76888e-05, gnorm=1.042, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74376
2022-10-19 16:05:28 - progress_bar.py[line:274] - INFO: epoch 001:  15451 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=15430, lr=3.77133e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74388
2022-10-19 16:05:39 - progress_bar.py[line:274] - INFO: epoch 001:  15461 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97, ups=0.89, wpb=109.4, bsz=40, num_updates=15440, lr=3.77377e-05, gnorm=0.95, clip=40, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=74399
2022-10-19 16:05:51 - progress_bar.py[line:274] - INFO: epoch 001:  15471 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=15450, lr=3.77621e-05, gnorm=0.928, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74410
2022-10-19 16:06:02 - progress_bar.py[line:274] - INFO: epoch 001:  15481 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=15460, lr=3.77866e-05, gnorm=0.978, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74422
2022-10-19 16:06:13 - progress_bar.py[line:274] - INFO: epoch 001:  15491 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=15470, lr=3.7811e-05, gnorm=1.058, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74433
2022-10-19 16:06:24 - progress_bar.py[line:274] - INFO: epoch 001:  15501 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.1, ups=0.92, wpb=109.4, bsz=40, num_updates=15480, lr=3.78355e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74444
2022-10-19 16:06:35 - progress_bar.py[line:274] - INFO: epoch 001:  15511 / 102288 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=102.1, ups=0.91, wpb=111.7, bsz=40, num_updates=15490, lr=3.78599e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74455
2022-10-19 16:06:46 - progress_bar.py[line:274] - INFO: epoch 001:  15521 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.6, ups=0.9, wpb=110.8, bsz=40, num_updates=15500, lr=3.78843e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74466
2022-10-19 16:06:57 - progress_bar.py[line:274] - INFO: epoch 001:  15531 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=95.7, ups=0.88, wpb=109, bsz=40, num_updates=15510, lr=3.79088e-05, gnorm=0.932, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74477
2022-10-19 16:07:09 - progress_bar.py[line:274] - INFO: epoch 001:  15541 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=15520, lr=3.79332e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74488
2022-10-19 16:07:20 - progress_bar.py[line:274] - INFO: epoch 001:  15551 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.1, ups=0.86, wpb=108.9, bsz=40, num_updates=15530, lr=3.79577e-05, gnorm=0.807, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=74500
2022-10-19 16:07:31 - progress_bar.py[line:274] - INFO: epoch 001:  15561 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.1, ups=0.89, wpb=109.1, bsz=40, num_updates=15540, lr=3.79821e-05, gnorm=0.814, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74511
2022-10-19 16:07:43 - progress_bar.py[line:274] - INFO: epoch 001:  15571 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=15550, lr=3.80066e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74523
2022-10-19 16:07:54 - progress_bar.py[line:274] - INFO: epoch 001:  15581 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.8, ups=0.88, wpb=109.2, bsz=40, num_updates=15560, lr=3.8031e-05, gnorm=1.011, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=74534
2022-10-19 16:08:05 - progress_bar.py[line:274] - INFO: epoch 001:  15591 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.91, wpb=108, bsz=40, num_updates=15570, lr=3.80554e-05, gnorm=0.997, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74545
2022-10-19 16:08:17 - progress_bar.py[line:274] - INFO: epoch 001:  15601 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.1, ups=0.86, wpb=110.5, bsz=40, num_updates=15580, lr=3.80799e-05, gnorm=1.044, clip=30, loss_scale=512, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=74557
2022-10-19 16:08:28 - progress_bar.py[line:274] - INFO: epoch 001:  15611 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.8, ups=0.9, wpb=109.7, bsz=40, num_updates=15590, lr=3.81043e-05, gnorm=0.982, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=74568
2022-10-19 16:08:39 - progress_bar.py[line:274] - INFO: epoch 001:  15621 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.8, ups=0.89, wpb=109.3, bsz=40, num_updates=15600, lr=3.81288e-05, gnorm=1.144, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74579
2022-10-19 16:08:51 - progress_bar.py[line:274] - INFO: epoch 001:  15631 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.9, ups=0.87, wpb=109.4, bsz=40, num_updates=15610, lr=3.81532e-05, gnorm=0.999, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74591
2022-10-19 16:09:02 - progress_bar.py[line:274] - INFO: epoch 001:  15641 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.6, ups=0.89, wpb=112, bsz=40, num_updates=15620, lr=3.81776e-05, gnorm=0.805, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74602
2022-10-19 16:09:13 - progress_bar.py[line:274] - INFO: epoch 001:  15651 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.8, ups=0.92, wpb=110.9, bsz=40, num_updates=15630, lr=3.82021e-05, gnorm=0.913, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74613
2022-10-19 16:09:24 - progress_bar.py[line:274] - INFO: epoch 001:  15661 / 102288 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=15640, lr=3.82265e-05, gnorm=0.904, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74624
2022-10-19 16:09:36 - progress_bar.py[line:274] - INFO: epoch 001:  15671 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.6, ups=0.88, wpb=110.1, bsz=40, num_updates=15650, lr=3.8251e-05, gnorm=0.931, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74635
2022-10-19 16:09:47 - progress_bar.py[line:274] - INFO: epoch 001:  15681 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=15660, lr=3.82754e-05, gnorm=0.963, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74646
2022-10-19 16:09:57 - progress_bar.py[line:274] - INFO: epoch 001:  15691 / 102288 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=102.1, ups=0.92, wpb=110.9, bsz=40, num_updates=15670, lr=3.82998e-05, gnorm=1.142, clip=40, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=74657
2022-10-19 16:10:09 - progress_bar.py[line:274] - INFO: epoch 001:  15701 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.2, ups=0.89, wpb=110.7, bsz=40, num_updates=15680, lr=3.83243e-05, gnorm=0.873, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74669
2022-10-19 16:10:20 - progress_bar.py[line:274] - INFO: epoch 001:  15711 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.7, ups=0.91, wpb=110.1, bsz=40, num_updates=15690, lr=3.83487e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=74679
2022-10-19 16:10:31 - progress_bar.py[line:274] - INFO: epoch 001:  15721 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=15700, lr=3.83732e-05, gnorm=1.018, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74691
2022-10-19 16:10:42 - progress_bar.py[line:274] - INFO: epoch 001:  15731 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.4, ups=0.91, wpb=109.1, bsz=40, num_updates=15710, lr=3.83976e-05, gnorm=1.041, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74702
2022-10-19 16:10:53 - progress_bar.py[line:274] - INFO: epoch 001:  15741 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96, ups=0.87, wpb=110.8, bsz=40, num_updates=15720, lr=3.84221e-05, gnorm=1.004, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74713
2022-10-19 16:11:05 - progress_bar.py[line:274] - INFO: epoch 001:  15751 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=15730, lr=3.84465e-05, gnorm=1.082, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74724
2022-10-19 16:11:16 - progress_bar.py[line:274] - INFO: epoch 001:  15761 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.1, ups=0.88, wpb=109.4, bsz=40, num_updates=15740, lr=3.84709e-05, gnorm=0.976, clip=40, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=74736
2022-10-19 16:11:27 - progress_bar.py[line:274] - INFO: epoch 001:  15771 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.7, ups=0.9, wpb=109.7, bsz=40, num_updates=15750, lr=3.84954e-05, gnorm=1.104, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74747
2022-10-19 16:11:38 - progress_bar.py[line:274] - INFO: epoch 001:  15781 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.1, ups=0.93, wpb=110.3, bsz=40, num_updates=15760, lr=3.85198e-05, gnorm=1.001, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74758
2022-10-19 16:11:49 - progress_bar.py[line:274] - INFO: epoch 001:  15791 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=15770, lr=3.85443e-05, gnorm=1.157, clip=90, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74769
2022-10-19 16:12:00 - progress_bar.py[line:274] - INFO: epoch 001:  15801 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.8, ups=0.91, wpb=110.4, bsz=40, num_updates=15780, lr=3.85687e-05, gnorm=0.888, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74780
2022-10-19 16:12:11 - progress_bar.py[line:274] - INFO: epoch 001:  15811 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=15790, lr=3.85931e-05, gnorm=0.913, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74791
2022-10-19 16:12:22 - progress_bar.py[line:274] - INFO: epoch 001:  15821 / 102288 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.9, ups=0.89, wpb=109.3, bsz=40, num_updates=15800, lr=3.86176e-05, gnorm=0.933, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74802
2022-10-19 16:12:34 - progress_bar.py[line:274] - INFO: epoch 001:  15831 / 102288 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.5, ups=0.9, wpb=108.6, bsz=40, num_updates=15810, lr=3.8642e-05, gnorm=1.064, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=74813
2022-10-19 16:12:45 - progress_bar.py[line:274] - INFO: epoch 001:  15841 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=15820, lr=3.86665e-05, gnorm=1.112, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74824
2022-10-19 16:12:56 - progress_bar.py[line:274] - INFO: epoch 001:  15851 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.5, ups=0.85, wpb=109.4, bsz=40, num_updates=15830, lr=3.86909e-05, gnorm=0.915, clip=30, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=74836
2022-10-19 16:13:07 - progress_bar.py[line:274] - INFO: epoch 001:  15861 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99, ups=0.89, wpb=111.2, bsz=40, num_updates=15840, lr=3.87154e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74847
2022-10-19 16:13:19 - progress_bar.py[line:274] - INFO: epoch 001:  15871 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=15850, lr=3.87398e-05, gnorm=1.019, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74858
2022-10-19 16:13:30 - progress_bar.py[line:274] - INFO: epoch 001:  15881 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=15860, lr=3.87642e-05, gnorm=0.951, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74870
2022-10-19 16:13:41 - progress_bar.py[line:274] - INFO: epoch 001:  15891 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.4, ups=0.9, wpb=110.6, bsz=40, num_updates=15870, lr=3.87887e-05, gnorm=0.852, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74881
2022-10-19 16:13:52 - progress_bar.py[line:274] - INFO: epoch 001:  15901 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.7, ups=0.88, wpb=110.4, bsz=40, num_updates=15880, lr=3.88131e-05, gnorm=0.884, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74892
2022-10-19 16:14:03 - progress_bar.py[line:274] - INFO: epoch 001:  15911 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.4, ups=0.91, wpb=110.3, bsz=40, num_updates=15890, lr=3.88376e-05, gnorm=0.837, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74903
2022-10-19 16:14:15 - progress_bar.py[line:274] - INFO: epoch 001:  15921 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.9, ups=0.88, wpb=108.2, bsz=40, num_updates=15900, lr=3.8862e-05, gnorm=0.921, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74915
2022-10-19 16:14:26 - progress_bar.py[line:274] - INFO: epoch 001:  15931 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=15910, lr=3.88864e-05, gnorm=1.06, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=74926
2022-10-19 16:14:37 - progress_bar.py[line:274] - INFO: epoch 001:  15941 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=15920, lr=3.89109e-05, gnorm=0.9, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74937
2022-10-19 16:14:49 - progress_bar.py[line:274] - INFO: epoch 001:  15951 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.4, ups=0.88, wpb=110.3, bsz=40, num_updates=15930, lr=3.89353e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74948
2022-10-19 16:15:00 - progress_bar.py[line:274] - INFO: epoch 001:  15961 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.8, ups=0.88, wpb=109.1, bsz=40, num_updates=15940, lr=3.89598e-05, gnorm=0.991, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74960
2022-10-19 16:15:12 - progress_bar.py[line:274] - INFO: epoch 001:  15971 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.8, ups=0.87, wpb=111.4, bsz=40, num_updates=15950, lr=3.89842e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=74971
2022-10-19 16:15:23 - progress_bar.py[line:274] - INFO: epoch 001:  15981 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=15960, lr=3.90087e-05, gnorm=0.974, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=74982
2022-10-19 16:15:34 - progress_bar.py[line:274] - INFO: epoch 001:  15991 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.9, wpb=109.4, bsz=40, num_updates=15970, lr=3.90331e-05, gnorm=0.914, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=74994
2022-10-19 16:15:46 - progress_bar.py[line:274] - INFO: epoch 001:  16001 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.8, ups=0.86, wpb=112.1, bsz=40, num_updates=15980, lr=3.90575e-05, gnorm=0.991, clip=40, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=75005
2022-10-19 16:15:57 - progress_bar.py[line:274] - INFO: epoch 001:  16011 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.8, ups=0.87, wpb=109.2, bsz=40, num_updates=15990, lr=3.9082e-05, gnorm=1.008, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=75017
2022-10-19 16:16:08 - progress_bar.py[line:274] - INFO: epoch 001:  16021 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.8, ups=0.88, wpb=112.4, bsz=40, num_updates=16000, lr=3.91064e-05, gnorm=0.959, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=75028
2022-10-19 16:16:08 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 16:16:10 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 16:16:10 - train.py[line:551] - INFO: load:1.03 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 16:18:42 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 16:18:42 - train.py[line:551] - INFO: load:1.06 valid_run:152.02 task_valid:147.85 collect_output:3.15
2022-10-19 16:21:10 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 16:21:10 - train.py[line:551] - INFO: load:1.08 valid_run:300.65 task_valid:290.81 collect_output:7.79
2022-10-19 16:23:43 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 16:23:43 - train.py[line:551] - INFO: load:1.11 valid_run:453.25 task_valid:433.82 collect_output:16.37
2022-10-19 16:26:13 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 16:26:13 - train.py[line:551] - INFO: load:1.13 valid_run:602.66 task_valid:578.84 collect_output:19.76
2022-10-19 16:28:45 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 16:28:45 - train.py[line:551] - INFO: load:1.16 valid_run:755.46 task_valid:726.42 collect_output:23.87
2022-10-19 16:31:19 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 16:31:19 - train.py[line:551] - INFO: load:1.18 valid_run:908.54 task_valid:872.68 collect_output:29.51
2022-10-19 16:33:52 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 16:33:52 - train.py[line:551] - INFO: load:1.21 valid_run:1062.30 task_valid:1018.83 collect_output:36.10
2022-10-19 16:36:24 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 16:36:24 - train.py[line:551] - INFO: load:1.23 valid_run:1214.12 task_valid:1160.15 collect_output:45.58
2022-10-19 16:38:54 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 16:38:54 - train.py[line:551] - INFO: load:1.25 valid_run:1363.91 task_valid:1304.79 collect_output:49.75
2022-10-19 16:41:26 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 16:41:26 - train.py[line:551] - INFO: load:1.28 valid_run:1515.34 task_valid:1449.38 collect_output:55.27
2022-10-19 16:43:56 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 16:43:56 - train.py[line:551] - INFO: load:1.31 valid_run:1665.83 task_valid:1594.69 collect_output:59.31
2022-10-19 16:46:28 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 16:46:28 - train.py[line:551] - INFO: load:1.33 valid_run:1817.54 task_valid:1740.62 collect_output:63.78
2022-10-19 16:48:59 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 16:48:59 - train.py[line:551] - INFO: load:1.36 valid_run:1968.15 task_valid:1882.60 collect_output:71.37
2022-10-19 16:51:30 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 16:51:30 - train.py[line:551] - INFO: load:1.38 valid_run:2119.24 task_valid:2028.07 collect_output:75.99
2022-10-19 16:54:00 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 16:54:00 - train.py[line:551] - INFO: load:1.41 valid_run:2269.68 task_valid:2174.50 collect_output:79.00
2022-10-19 16:56:31 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 16:56:31 - train.py[line:551] - INFO: load:1.43 valid_run:2420.19 task_valid:2318.75 collect_output:84.26
2022-10-19 16:59:03 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 16:59:03 - train.py[line:551] - INFO: load:1.46 valid_run:2572.39 task_valid:2464.52 collect_output:89.64
2022-10-19 17:01:34 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 17:01:34 - train.py[line:551] - INFO: load:1.48 valid_run:2723.58 task_valid:2611.86 collect_output:92.46
2022-10-19 17:04:04 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 17:04:04 - train.py[line:551] - INFO: load:1.51 valid_run:2872.78 task_valid:2753.80 collect_output:98.63
2022-10-19 17:06:35 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 17:06:35 - train.py[line:551] - INFO: load:1.53 valid_run:3023.82 task_valid:2899.12 collect_output:103.32
2022-10-19 17:09:08 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 17:09:08 - train.py[line:551] - INFO: load:1.56 valid_run:3176.63 task_valid:3044.15 collect_output:110.04
2022-10-19 17:11:38 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 17:11:38 - train.py[line:551] - INFO: load:1.58 valid_run:3326.63 task_valid:3188.99 collect_output:114.15
2022-10-19 17:14:10 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 17:14:10 - train.py[line:551] - INFO: load:1.61 valid_run:3478.75 task_valid:3335.50 collect_output:118.64
2022-10-19 17:16:42 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 17:16:42 - train.py[line:551] - INFO: load:1.63 valid_run:3630.64 task_valid:3482.38 collect_output:122.62

====================================================================================================
SGG eval:     R @ 50: 0.5387;     R @ 100: 0.5758;     R @ 500: 0.5997;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3767;    mR @ 100: 0.4089;    mR @ 500: 0.4297;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.8750) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.6194) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8497) (says:0.0000) (sitting on:0.6882) (standing on:0.1553) (using:0.6500) (walking in:0.0000) (walking on:0.7207) (watching:0.2708) 
--------------------------------------------------------
====================================================================================================

2022-10-19 17:19:13 - train.py[line:487] - INFO: 0.5758481792717086

====================================================================================================
SGG eval:     R @ 50: 0.5387;     R @ 100: 0.5758;     R @ 500: 0.5997;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3767;    mR @ 100: 0.4089;    mR @ 500: 0.4297;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.8750) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.6194) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8497) (says:0.0000) (sitting on:0.6882) (standing on:0.1553) (using:0.6500) (walking in:0.0000) (walking on:0.7207) (watching:0.2708) 
--------------------------------------------------------
====================================================================================================

2022-10-19 17:19:13 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 17:19:14 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.349 | loss_v1 0 | loss_v2 0 | nll_loss 0.195 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.575848 | ppl 1.14 | vqa_score 0.5124 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 16000 | best_R@100 0.593911
2022-10-19 17:19:14 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 16000 updates
2022-10-19 17:19:14 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_16000.pt
2022-10-19 17:19:19 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_16000.pt
2022-10-19 17:19:22 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 0.5758481792717086) (writing took 8.53409461863339 seconds)
2022-10-19 17:19:33 - progress_bar.py[line:274] - INFO: epoch 001:  16031 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=0.3, ups=0, wpb=109.1, bsz=40, num_updates=16010, lr=3.91309e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78833
2022-10-19 17:19:42 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 17:19:45 - progress_bar.py[line:274] - INFO: epoch 001:  16042 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.3, ups=0.84, wpb=110.5, bsz=40, num_updates=16020, lr=3.91553e-05, gnorm=0.88, clip=10, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=78845
2022-10-19 17:19:56 - progress_bar.py[line:274] - INFO: epoch 001:  16052 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=103, ups=0.94, wpb=110, bsz=40, num_updates=16030, lr=3.91797e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78856
2022-10-19 17:20:07 - progress_bar.py[line:274] - INFO: epoch 001:  16062 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=16040, lr=3.92042e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78867
2022-10-19 17:20:18 - progress_bar.py[line:274] - INFO: epoch 001:  16072 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.9, wpb=109.8, bsz=40, num_updates=16050, lr=3.92286e-05, gnorm=0.988, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=78878
2022-10-19 17:20:29 - progress_bar.py[line:274] - INFO: epoch 001:  16082 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.5, ups=0.91, wpb=109, bsz=40, num_updates=16060, lr=3.92531e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78889
2022-10-19 17:20:41 - progress_bar.py[line:274] - INFO: epoch 001:  16092 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.8, ups=0.88, wpb=110.3, bsz=40, num_updates=16070, lr=3.92775e-05, gnorm=0.84, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78901
2022-10-19 17:20:52 - progress_bar.py[line:274] - INFO: epoch 001:  16102 / 102288 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.3, ups=0.9, wpb=112.7, bsz=40, num_updates=16080, lr=3.9302e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78912
2022-10-19 17:21:03 - progress_bar.py[line:274] - INFO: epoch 001:  16112 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98, ups=0.89, wpb=109.5, bsz=40, num_updates=16090, lr=3.93264e-05, gnorm=0.971, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78923
2022-10-19 17:21:14 - progress_bar.py[line:274] - INFO: epoch 001:  16122 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.5, ups=0.92, wpb=109.4, bsz=40, num_updates=16100, lr=3.93508e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=78934
2022-10-19 17:21:26 - progress_bar.py[line:274] - INFO: epoch 001:  16132 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=16110, lr=3.93753e-05, gnorm=1.07, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=78945
2022-10-19 17:21:37 - progress_bar.py[line:274] - INFO: epoch 001:  16142 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100, ups=0.9, wpb=111.2, bsz=40, num_updates=16120, lr=3.93997e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=78956
2022-10-19 17:21:48 - progress_bar.py[line:274] - INFO: epoch 001:  16152 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=16130, lr=3.94242e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78968
2022-10-19 17:21:59 - progress_bar.py[line:274] - INFO: epoch 001:  16162 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.8, ups=0.91, wpb=108.4, bsz=40, num_updates=16140, lr=3.94486e-05, gnorm=1.084, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78979
2022-10-19 17:22:10 - progress_bar.py[line:274] - INFO: epoch 001:  16172 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.1, ups=0.9, wpb=110, bsz=40, num_updates=16150, lr=3.9473e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=78990
2022-10-19 17:22:22 - progress_bar.py[line:274] - INFO: epoch 001:  16182 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=16160, lr=3.94975e-05, gnorm=0.947, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79001
2022-10-19 17:22:33 - progress_bar.py[line:274] - INFO: epoch 001:  16192 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.9, wpb=110.2, bsz=40, num_updates=16170, lr=3.95219e-05, gnorm=0.961, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79012
2022-10-19 17:22:44 - progress_bar.py[line:274] - INFO: epoch 001:  16202 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=16180, lr=3.95464e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79024
2022-10-19 17:22:55 - progress_bar.py[line:274] - INFO: epoch 001:  16212 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=16190, lr=3.95708e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79035
2022-10-19 17:23:06 - progress_bar.py[line:274] - INFO: epoch 001:  16222 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=16200, lr=3.95952e-05, gnorm=0.81, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79046
2022-10-19 17:23:18 - progress_bar.py[line:274] - INFO: epoch 001:  16232 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=16210, lr=3.96197e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79057
2022-10-19 17:23:29 - progress_bar.py[line:274] - INFO: epoch 001:  16242 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=16220, lr=3.96441e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79069
2022-10-19 17:23:40 - progress_bar.py[line:274] - INFO: epoch 001:  16252 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.6, ups=0.9, wpb=109.4, bsz=40, num_updates=16230, lr=3.96686e-05, gnorm=0.961, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79080
2022-10-19 17:23:51 - progress_bar.py[line:274] - INFO: epoch 001:  16262 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.6, ups=0.89, wpb=109.9, bsz=40, num_updates=16240, lr=3.9693e-05, gnorm=0.995, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79091
2022-10-19 17:24:03 - progress_bar.py[line:274] - INFO: epoch 001:  16272 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.6, ups=0.87, wpb=110.2, bsz=40, num_updates=16250, lr=3.97175e-05, gnorm=0.989, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79103
2022-10-19 17:24:14 - progress_bar.py[line:274] - INFO: epoch 001:  16282 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.7, ups=0.91, wpb=110.2, bsz=40, num_updates=16260, lr=3.97419e-05, gnorm=0.911, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79114
2022-10-19 17:24:25 - progress_bar.py[line:274] - INFO: epoch 001:  16292 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=16270, lr=3.97663e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79125
2022-10-19 17:24:36 - progress_bar.py[line:274] - INFO: epoch 001:  16302 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.4, ups=0.89, wpb=110.7, bsz=40, num_updates=16280, lr=3.97908e-05, gnorm=1.065, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79136
2022-10-19 17:24:47 - progress_bar.py[line:274] - INFO: epoch 001:  16312 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.5, ups=0.91, wpb=110.8, bsz=40, num_updates=16290, lr=3.98152e-05, gnorm=0.929, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79147
2022-10-19 17:24:59 - progress_bar.py[line:274] - INFO: epoch 001:  16322 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=16300, lr=3.98397e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79159
2022-10-19 17:25:10 - progress_bar.py[line:274] - INFO: epoch 001:  16332 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.7, ups=0.89, wpb=108, bsz=40, num_updates=16310, lr=3.98641e-05, gnorm=1.051, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79170
2022-10-19 17:25:21 - progress_bar.py[line:274] - INFO: epoch 001:  16342 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.7, ups=0.91, wpb=110, bsz=40, num_updates=16320, lr=3.98885e-05, gnorm=1.031, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79181
2022-10-19 17:25:32 - progress_bar.py[line:274] - INFO: epoch 001:  16352 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99, ups=0.9, wpb=110, bsz=40, num_updates=16330, lr=3.9913e-05, gnorm=0.88, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79192
2022-10-19 17:25:44 - progress_bar.py[line:274] - INFO: epoch 001:  16362 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.8, ups=0.9, wpb=111.4, bsz=40, num_updates=16340, lr=3.99374e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79203
2022-10-19 17:25:55 - progress_bar.py[line:274] - INFO: epoch 001:  16372 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=16350, lr=3.99619e-05, gnorm=0.884, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79215
2022-10-19 17:26:06 - progress_bar.py[line:274] - INFO: epoch 001:  16382 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=16360, lr=3.99863e-05, gnorm=1.021, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79226
2022-10-19 17:26:18 - progress_bar.py[line:274] - INFO: epoch 001:  16392 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.5, ups=0.87, wpb=110, bsz=40, num_updates=16370, lr=4.00108e-05, gnorm=1.071, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79237
2022-10-19 17:26:29 - progress_bar.py[line:274] - INFO: epoch 001:  16402 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.7, ups=0.92, wpb=111.9, bsz=40, num_updates=16380, lr=4.00352e-05, gnorm=0.881, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79248
2022-10-19 17:26:40 - progress_bar.py[line:274] - INFO: epoch 001:  16412 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=16390, lr=4.00596e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79260
2022-10-19 17:26:52 - progress_bar.py[line:274] - INFO: epoch 001:  16422 / 102288 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.6, ups=0.86, wpb=110.4, bsz=40, num_updates=16400, lr=4.00841e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=79271
2022-10-19 17:27:03 - progress_bar.py[line:274] - INFO: epoch 001:  16432 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=16410, lr=4.01085e-05, gnorm=1.058, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=79283
2022-10-19 17:27:14 - progress_bar.py[line:274] - INFO: epoch 001:  16442 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=16420, lr=4.0133e-05, gnorm=1.017, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79294
2022-10-19 17:27:25 - progress_bar.py[line:274] - INFO: epoch 001:  16452 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=16430, lr=4.01574e-05, gnorm=0.99, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79305
2022-10-19 17:27:37 - progress_bar.py[line:274] - INFO: epoch 001:  16462 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.9, ups=0.87, wpb=110.4, bsz=40, num_updates=16440, lr=4.01818e-05, gnorm=1.058, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79317
2022-10-19 17:27:48 - progress_bar.py[line:274] - INFO: epoch 001:  16472 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=16450, lr=4.02063e-05, gnorm=1.024, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79328
2022-10-19 17:27:59 - progress_bar.py[line:274] - INFO: epoch 001:  16482 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.5, ups=0.9, wpb=108.3, bsz=40, num_updates=16460, lr=4.02307e-05, gnorm=0.842, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79339
2022-10-19 17:28:10 - progress_bar.py[line:274] - INFO: epoch 001:  16492 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.6, ups=0.91, wpb=111.1, bsz=40, num_updates=16470, lr=4.02552e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79350
2022-10-19 17:28:21 - progress_bar.py[line:274] - INFO: epoch 001:  16502 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=16480, lr=4.02796e-05, gnorm=0.827, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=79361
2022-10-19 17:28:32 - progress_bar.py[line:274] - INFO: epoch 001:  16512 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=16490, lr=4.03041e-05, gnorm=0.889, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79372
2022-10-19 17:28:44 - progress_bar.py[line:274] - INFO: epoch 001:  16522 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.9, ups=0.89, wpb=111.2, bsz=40, num_updates=16500, lr=4.03285e-05, gnorm=0.889, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79383
2022-10-19 17:28:55 - progress_bar.py[line:274] - INFO: epoch 001:  16532 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.2, ups=0.87, wpb=111.9, bsz=40, num_updates=16510, lr=4.03529e-05, gnorm=0.837, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79395
2022-10-19 17:29:06 - progress_bar.py[line:274] - INFO: epoch 001:  16542 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102.6, ups=0.94, wpb=109.5, bsz=40, num_updates=16520, lr=4.03774e-05, gnorm=0.919, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79406
2022-10-19 17:29:17 - progress_bar.py[line:274] - INFO: epoch 001:  16552 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.2, ups=0.87, wpb=110.8, bsz=40, num_updates=16530, lr=4.04018e-05, gnorm=0.879, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79417
2022-10-19 17:29:29 - progress_bar.py[line:274] - INFO: epoch 001:  16562 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=16540, lr=4.04263e-05, gnorm=0.897, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79428
2022-10-19 17:29:40 - progress_bar.py[line:274] - INFO: epoch 001:  16572 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.8, ups=0.87, wpb=110.3, bsz=40, num_updates=16550, lr=4.04507e-05, gnorm=1.077, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79440
2022-10-19 17:29:51 - progress_bar.py[line:274] - INFO: epoch 001:  16582 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=16560, lr=4.04751e-05, gnorm=0.894, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79451
2022-10-19 17:30:03 - progress_bar.py[line:274] - INFO: epoch 001:  16592 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=16570, lr=4.04996e-05, gnorm=1.06, clip=80, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=79462
2022-10-19 17:30:14 - progress_bar.py[line:274] - INFO: epoch 001:  16602 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=16580, lr=4.0524e-05, gnorm=0.918, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79474
2022-10-19 17:30:25 - progress_bar.py[line:274] - INFO: epoch 001:  16612 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.2, ups=0.9, wpb=110.3, bsz=40, num_updates=16590, lr=4.05485e-05, gnorm=0.945, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79485
2022-10-19 17:30:36 - progress_bar.py[line:274] - INFO: epoch 001:  16622 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=16600, lr=4.05729e-05, gnorm=1.051, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79496
2022-10-19 17:30:48 - progress_bar.py[line:274] - INFO: epoch 001:  16632 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.9, ups=0.87, wpb=110.6, bsz=40, num_updates=16610, lr=4.05974e-05, gnorm=1.133, clip=50, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=79508
2022-10-19 17:30:59 - progress_bar.py[line:274] - INFO: epoch 001:  16642 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=16620, lr=4.06218e-05, gnorm=1.077, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79519
2022-10-19 17:31:10 - progress_bar.py[line:274] - INFO: epoch 001:  16652 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=16630, lr=4.06462e-05, gnorm=0.933, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79530
2022-10-19 17:31:21 - progress_bar.py[line:274] - INFO: epoch 001:  16662 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.3, ups=0.91, wpb=111.1, bsz=40, num_updates=16640, lr=4.06707e-05, gnorm=0.867, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79541
2022-10-19 17:31:32 - progress_bar.py[line:274] - INFO: epoch 001:  16672 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=16650, lr=4.06951e-05, gnorm=0.916, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79552
2022-10-19 17:31:44 - progress_bar.py[line:274] - INFO: epoch 001:  16682 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=16660, lr=4.07196e-05, gnorm=0.952, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79563
2022-10-19 17:31:55 - progress_bar.py[line:274] - INFO: epoch 001:  16692 / 102288 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.8, ups=0.89, wpb=109.9, bsz=40, num_updates=16670, lr=4.0744e-05, gnorm=1.015, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79575
2022-10-19 17:32:06 - progress_bar.py[line:274] - INFO: epoch 001:  16702 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.9, ups=0.93, wpb=110.1, bsz=40, num_updates=16680, lr=4.07684e-05, gnorm=0.906, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79585
2022-10-19 17:32:17 - progress_bar.py[line:274] - INFO: epoch 001:  16712 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.3, ups=0.88, wpb=111.8, bsz=40, num_updates=16690, lr=4.07929e-05, gnorm=0.889, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=79597
2022-10-19 17:32:28 - progress_bar.py[line:274] - INFO: epoch 001:  16722 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.5, ups=0.9, wpb=109.5, bsz=40, num_updates=16700, lr=4.08173e-05, gnorm=1.009, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79608
2022-10-19 17:32:40 - progress_bar.py[line:274] - INFO: epoch 001:  16732 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98, ups=0.88, wpb=111.6, bsz=40, num_updates=16710, lr=4.08418e-05, gnorm=1.02, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79619
2022-10-19 17:32:51 - progress_bar.py[line:274] - INFO: epoch 001:  16742 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=16720, lr=4.08662e-05, gnorm=0.917, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79630
2022-10-19 17:33:02 - progress_bar.py[line:274] - INFO: epoch 001:  16752 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.9, wpb=109.6, bsz=40, num_updates=16730, lr=4.08906e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79642
2022-10-19 17:33:13 - progress_bar.py[line:274] - INFO: epoch 001:  16762 / 102288 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.7, ups=0.9, wpb=108.2, bsz=40, num_updates=16740, lr=4.09151e-05, gnorm=1.054, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79653
2022-10-19 17:33:24 - progress_bar.py[line:274] - INFO: epoch 001:  16772 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102.2, ups=0.93, wpb=110.3, bsz=40, num_updates=16750, lr=4.09395e-05, gnorm=0.904, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79663
2022-10-19 17:33:35 - progress_bar.py[line:274] - INFO: epoch 001:  16782 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97, ups=0.89, wpb=109.3, bsz=40, num_updates=16760, lr=4.0964e-05, gnorm=0.897, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79675
2022-10-19 17:33:46 - progress_bar.py[line:274] - INFO: epoch 001:  16792 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.5, ups=0.91, wpb=109.9, bsz=40, num_updates=16770, lr=4.09884e-05, gnorm=1.039, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79686
2022-10-19 17:33:57 - progress_bar.py[line:274] - INFO: epoch 001:  16802 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=16780, lr=4.10129e-05, gnorm=0.953, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79697
2022-10-19 17:34:08 - progress_bar.py[line:274] - INFO: epoch 001:  16812 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=16790, lr=4.10373e-05, gnorm=1.138, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79708
2022-10-19 17:34:20 - progress_bar.py[line:274] - INFO: epoch 001:  16822 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.8, ups=0.88, wpb=110, bsz=40, num_updates=16800, lr=4.10617e-05, gnorm=0.969, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79719
2022-10-19 17:34:31 - progress_bar.py[line:274] - INFO: epoch 001:  16832 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.3, ups=0.9, wpb=111.3, bsz=40, num_updates=16810, lr=4.10862e-05, gnorm=1.024, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79731
2022-10-19 17:34:42 - progress_bar.py[line:274] - INFO: epoch 001:  16842 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=16820, lr=4.11106e-05, gnorm=0.871, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79742
2022-10-19 17:34:53 - progress_bar.py[line:274] - INFO: epoch 001:  16852 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.3, ups=0.92, wpb=110.5, bsz=40, num_updates=16830, lr=4.11351e-05, gnorm=1.021, clip=70, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79753
2022-10-19 17:35:04 - progress_bar.py[line:274] - INFO: epoch 001:  16862 / 102288 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=16840, lr=4.11595e-05, gnorm=0.94, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79764
2022-10-19 17:35:15 - progress_bar.py[line:274] - INFO: epoch 001:  16872 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=16850, lr=4.11839e-05, gnorm=0.998, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79775
2022-10-19 17:35:17 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 17:35:28 - progress_bar.py[line:274] - INFO: epoch 001:  16883 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=90.2, ups=0.82, wpb=110.6, bsz=40, num_updates=16860, lr=4.12084e-05, gnorm=1.173, clip=60, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=79787
2022-10-19 17:35:39 - progress_bar.py[line:274] - INFO: epoch 001:  16893 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.7, ups=0.88, wpb=109.2, bsz=40, num_updates=16870, lr=4.12328e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79799
2022-10-19 17:35:50 - progress_bar.py[line:274] - INFO: epoch 001:  16903 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.7, ups=0.91, wpb=110.4, bsz=40, num_updates=16880, lr=4.12573e-05, gnorm=1.032, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79810
2022-10-19 17:36:01 - progress_bar.py[line:274] - INFO: epoch 001:  16913 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.1, ups=0.89, wpb=112.4, bsz=40, num_updates=16890, lr=4.12817e-05, gnorm=0.823, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79821
2022-10-19 17:36:12 - progress_bar.py[line:274] - INFO: epoch 001:  16923 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.2, ups=0.9, wpb=108.9, bsz=40, num_updates=16900, lr=4.13062e-05, gnorm=0.939, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79832
2022-10-19 17:36:24 - progress_bar.py[line:274] - INFO: epoch 001:  16933 / 102288 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=94.9, ups=0.86, wpb=109.7, bsz=40, num_updates=16910, lr=4.13306e-05, gnorm=0.975, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=79844
2022-10-19 17:36:35 - progress_bar.py[line:274] - INFO: epoch 001:  16943 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=102.1, ups=0.93, wpb=109.8, bsz=40, num_updates=16920, lr=4.1355e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79854
2022-10-19 17:36:45 - progress_bar.py[line:274] - INFO: epoch 001:  16953 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=105.4, ups=0.95, wpb=110.8, bsz=40, num_updates=16930, lr=4.13795e-05, gnorm=0.889, clip=40, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=79865
2022-10-19 17:36:56 - progress_bar.py[line:274] - INFO: epoch 001:  16963 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=16940, lr=4.14039e-05, gnorm=1.061, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=79876
2022-10-19 17:37:08 - progress_bar.py[line:274] - INFO: epoch 001:  16973 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=16950, lr=4.14284e-05, gnorm=0.89, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79887
2022-10-19 17:37:19 - progress_bar.py[line:274] - INFO: epoch 001:  16983 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=16960, lr=4.14528e-05, gnorm=0.975, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=79899
2022-10-19 17:37:30 - progress_bar.py[line:274] - INFO: epoch 001:  16993 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.9, ups=0.88, wpb=109.2, bsz=40, num_updates=16970, lr=4.14772e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=79910
2022-10-19 17:37:41 - progress_bar.py[line:274] - INFO: epoch 001:  17003 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.5, ups=0.9, wpb=109.2, bsz=40, num_updates=16980, lr=4.15017e-05, gnorm=0.979, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=79921
2022-10-19 17:37:53 - progress_bar.py[line:274] - INFO: epoch 001:  17013 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.2, ups=0.88, wpb=109.4, bsz=40, num_updates=16990, lr=4.15261e-05, gnorm=1.025, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=79932
2022-10-19 17:38:04 - progress_bar.py[line:274] - INFO: epoch 001:  17023 / 102288 loss=0.646, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.6, ups=0.89, wpb=107.5, bsz=40, num_updates=17000, lr=4.15506e-05, gnorm=1.021, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=79944
2022-10-19 17:38:04 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 17:38:05 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 17:38:05 - train.py[line:551] - INFO: load:1.10 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 17:40:37 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 17:40:37 - train.py[line:551] - INFO: load:1.13 valid_run:151.98 task_valid:147.77 collect_output:3.19
2022-10-19 17:43:06 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 17:43:06 - train.py[line:551] - INFO: load:1.15 valid_run:300.78 task_valid:291.06 collect_output:7.70
2022-10-19 17:45:39 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 17:45:39 - train.py[line:551] - INFO: load:1.18 valid_run:453.41 task_valid:434.12 collect_output:16.25
2022-10-19 17:48:08 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 17:48:08 - train.py[line:551] - INFO: load:1.20 valid_run:602.87 task_valid:578.98 collect_output:19.84
2022-10-19 17:50:41 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 17:50:41 - train.py[line:551] - INFO: load:1.23 valid_run:755.26 task_valid:726.32 collect_output:23.89
2022-10-19 17:53:13 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 17:53:13 - train.py[line:551] - INFO: load:1.25 valid_run:907.20 task_valid:872.04 collect_output:29.09
2022-10-19 17:55:47 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 17:55:47 - train.py[line:551] - INFO: load:1.28 valid_run:1060.85 task_valid:1018.01 collect_output:35.77
2022-10-19 17:58:18 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 17:58:18 - train.py[line:551] - INFO: load:1.30 valid_run:1212.58 task_valid:1159.09 collect_output:45.42
2022-10-19 18:00:48 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 18:00:48 - train.py[line:551] - INFO: load:1.33 valid_run:1362.37 task_valid:1303.76 collect_output:49.53
2022-10-19 18:03:17 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 18:03:17 - train.py[line:551] - INFO: load:1.36 valid_run:1511.30 task_valid:1446.95 collect_output:54.25
2022-10-19 18:05:47 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 18:05:47 - train.py[line:551] - INFO: load:1.38 valid_run:1661.30 task_valid:1591.88 collect_output:58.31
2022-10-19 18:08:17 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 18:08:17 - train.py[line:551] - INFO: load:1.41 valid_run:1811.48 task_valid:1736.74 collect_output:62.63
2022-10-19 18:10:48 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 18:10:48 - train.py[line:551] - INFO: load:1.44 valid_run:1961.98 task_valid:1878.56 collect_output:70.31
2022-10-19 18:13:19 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 18:13:19 - train.py[line:551] - INFO: load:1.46 valid_run:2113.19 task_valid:2024.41 collect_output:74.65
2022-10-19 18:15:50 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 18:15:50 - train.py[line:551] - INFO: load:1.49 valid_run:2263.58 task_valid:2171.06 collect_output:77.37
2022-10-19 18:18:20 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 18:18:20 - train.py[line:551] - INFO: load:1.52 valid_run:2414.16 task_valid:2315.26 collect_output:82.71
2022-10-19 18:20:58 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 18:20:58 - train.py[line:551] - INFO: load:1.56 valid_run:2572.05 task_valid:2464.31 collect_output:90.23
2022-10-19 18:23:29 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 18:23:29 - train.py[line:551] - INFO: load:1.58 valid_run:2723.08 task_valid:2611.37 collect_output:93.18
2022-10-19 18:25:59 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 18:25:59 - train.py[line:551] - INFO: load:1.61 valid_run:2872.74 task_valid:2753.69 collect_output:99.47
2022-10-19 18:28:36 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 18:28:36 - train.py[line:551] - INFO: load:1.65 valid_run:3029.98 task_valid:2903.27 collect_output:105.73
2022-10-19 18:31:16 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 18:31:16 - train.py[line:551] - INFO: load:1.67 valid_run:3189.21 task_valid:3052.53 collect_output:114.31
2022-10-19 18:33:51 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 18:33:51 - train.py[line:551] - INFO: load:1.70 valid_run:3344.79 task_valid:3201.69 collect_output:119.34
2022-10-19 18:36:28 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 18:36:28 - train.py[line:551] - INFO: load:1.74 valid_run:3501.11 task_valid:3351.87 collect_output:124.23
2022-10-19 18:39:05 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 18:39:05 - train.py[line:551] - INFO: load:1.76 valid_run:3658.61 task_valid:3503.46 collect_output:128.77

====================================================================================================
SGG eval:     R @ 50: 0.5347;     R @ 100: 0.5697;     R @ 500: 0.5966;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3671;    mR @ 100: 0.4051;    mR @ 500: 0.4279;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.8750) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5871) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8399) (says:0.0000) (sitting on:0.6769) (standing on:0.1803) (using:0.6500) (walking in:0.0000) (walking on:0.7207) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5347;     R @ 100: 0.5697;     R @ 500: 0.5966;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3671;    mR @ 100: 0.4051;    mR @ 500: 0.4279;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5683) (covered in:0.8750) (covering:0.3714) (eating:0.6176) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5871) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.8399) (says:0.0000) (sitting on:0.6769) (standing on:0.1803) (using:0.6500) (walking in:0.0000) (walking on:0.7207) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2022-10-19 18:41:44 - train.py[line:487] - INFO: 0.5696815126050421
2022-10-19 18:41:45 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 18:41:45 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.347 | loss_v1 0 | loss_v2 0 | nll_loss 0.194 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.569682 | ppl 1.14 | vqa_score 0.5034 | wps 117.5 | wpb 89.9 | bsz 30 | num_updates 17000 | best_R@100 0.593911
2022-10-19 18:41:45 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 17000 updates
2022-10-19 18:41:45 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_17000.pt
2022-10-19 18:41:51 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_17000.pt
2022-10-19 18:41:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_17000.pt (epoch 1 @ 17000 updates, score 0.5696815126050421) (writing took 8.734847054816782 seconds)
2022-10-19 18:42:05 - progress_bar.py[line:274] - INFO: epoch 001:  17033 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=17010, lr=4.1575e-05, gnorm=0.873, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=83785
2022-10-19 18:42:16 - progress_bar.py[line:274] - INFO: epoch 001:  17043 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.4, ups=0.89, wpb=112, bsz=40, num_updates=17020, lr=4.15995e-05, gnorm=1.089, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83796
2022-10-19 18:42:28 - progress_bar.py[line:274] - INFO: epoch 001:  17053 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=17030, lr=4.16239e-05, gnorm=1.017, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83807
2022-10-19 18:42:39 - progress_bar.py[line:274] - INFO: epoch 001:  17063 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.3, ups=0.91, wpb=111.5, bsz=40, num_updates=17040, lr=4.16483e-05, gnorm=0.883, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83818
2022-10-19 18:42:50 - progress_bar.py[line:274] - INFO: epoch 001:  17073 / 102288 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.8, ups=0.89, wpb=109, bsz=40, num_updates=17050, lr=4.16728e-05, gnorm=0.976, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=83830
2022-10-19 18:43:01 - progress_bar.py[line:274] - INFO: epoch 001:  17083 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.5, ups=0.91, wpb=110.7, bsz=40, num_updates=17060, lr=4.16972e-05, gnorm=1.056, clip=60, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=83841
2022-10-19 18:43:13 - progress_bar.py[line:274] - INFO: epoch 001:  17093 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=94.1, ups=0.85, wpb=111.1, bsz=40, num_updates=17070, lr=4.17217e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=83852
2022-10-19 18:43:24 - progress_bar.py[line:274] - INFO: epoch 001:  17103 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.5, ups=0.89, wpb=109.9, bsz=40, num_updates=17080, lr=4.17461e-05, gnorm=0.886, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83864
2022-10-19 18:43:35 - progress_bar.py[line:274] - INFO: epoch 001:  17113 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.2, ups=0.88, wpb=111, bsz=40, num_updates=17090, lr=4.17705e-05, gnorm=1.303, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=83875
2022-10-19 18:43:47 - progress_bar.py[line:274] - INFO: epoch 001:  17123 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.5, ups=0.89, wpb=111.2, bsz=40, num_updates=17100, lr=4.1795e-05, gnorm=0.99, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83887
2022-10-19 18:43:58 - progress_bar.py[line:274] - INFO: epoch 001:  17133 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.3, ups=0.92, wpb=110.6, bsz=40, num_updates=17110, lr=4.18194e-05, gnorm=0.944, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83897
2022-10-19 18:44:09 - progress_bar.py[line:274] - INFO: epoch 001:  17143 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.2, ups=0.9, wpb=108.7, bsz=40, num_updates=17120, lr=4.18439e-05, gnorm=0.879, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=83909
2022-10-19 18:44:20 - progress_bar.py[line:274] - INFO: epoch 001:  17153 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.9, ups=0.89, wpb=109.5, bsz=40, num_updates=17130, lr=4.18683e-05, gnorm=0.954, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=83920
2022-10-19 18:44:31 - progress_bar.py[line:274] - INFO: epoch 001:  17163 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=17140, lr=4.18928e-05, gnorm=1.023, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=83931
2022-10-19 18:44:43 - progress_bar.py[line:274] - INFO: epoch 001:  17173 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.4, ups=0.87, wpb=110.6, bsz=40, num_updates=17150, lr=4.19172e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=83942
2022-10-19 18:44:54 - progress_bar.py[line:274] - INFO: epoch 001:  17183 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.7, ups=0.89, wpb=108.1, bsz=40, num_updates=17160, lr=4.19416e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83954
2022-10-19 18:45:05 - progress_bar.py[line:274] - INFO: epoch 001:  17193 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97, ups=0.88, wpb=109.9, bsz=40, num_updates=17170, lr=4.19661e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=83965
2022-10-19 18:45:17 - progress_bar.py[line:274] - INFO: epoch 001:  17203 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=17180, lr=4.19905e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=83976
2022-10-19 18:45:28 - progress_bar.py[line:274] - INFO: epoch 001:  17213 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=17190, lr=4.2015e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=83987
2022-10-19 18:45:39 - progress_bar.py[line:274] - INFO: epoch 001:  17223 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=17200, lr=4.20394e-05, gnorm=0.882, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=83999
2022-10-19 18:45:51 - progress_bar.py[line:274] - INFO: epoch 001:  17233 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.1, ups=0.86, wpb=111.1, bsz=40, num_updates=17210, lr=4.20638e-05, gnorm=0.915, clip=40, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=84011
2022-10-19 18:46:02 - progress_bar.py[line:274] - INFO: epoch 001:  17243 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=17220, lr=4.20883e-05, gnorm=0.888, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84022
2022-10-19 18:46:13 - progress_bar.py[line:274] - INFO: epoch 001:  17253 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=17230, lr=4.21127e-05, gnorm=1.143, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=84033
2022-10-19 18:46:24 - progress_bar.py[line:274] - INFO: epoch 001:  17263 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.6, ups=0.91, wpb=111.4, bsz=40, num_updates=17240, lr=4.21372e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84044
2022-10-19 18:46:35 - progress_bar.py[line:274] - INFO: epoch 001:  17273 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101, ups=0.91, wpb=111.1, bsz=40, num_updates=17250, lr=4.21616e-05, gnorm=0.909, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84055
2022-10-19 18:46:46 - progress_bar.py[line:274] - INFO: epoch 001:  17283 / 102288 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=17260, lr=4.2186e-05, gnorm=1.015, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84066
2022-10-19 18:46:58 - progress_bar.py[line:274] - INFO: epoch 001:  17293 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=17270, lr=4.22105e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84077
2022-10-19 18:47:09 - progress_bar.py[line:274] - INFO: epoch 001:  17303 / 102288 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.8, ups=0.89, wpb=109.9, bsz=40, num_updates=17280, lr=4.22349e-05, gnorm=0.904, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84089
2022-10-19 18:47:20 - progress_bar.py[line:274] - INFO: epoch 001:  17313 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=17290, lr=4.22594e-05, gnorm=0.944, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84100
2022-10-19 18:47:31 - progress_bar.py[line:274] - INFO: epoch 001:  17323 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=17300, lr=4.22838e-05, gnorm=1.045, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84111
2022-10-19 18:47:42 - progress_bar.py[line:274] - INFO: epoch 001:  17333 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.1, ups=0.92, wpb=109.5, bsz=40, num_updates=17310, lr=4.23083e-05, gnorm=0.876, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84122
2022-10-19 18:47:53 - progress_bar.py[line:274] - INFO: epoch 001:  17343 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.5, ups=0.9, wpb=110.5, bsz=40, num_updates=17320, lr=4.23327e-05, gnorm=0.948, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84133
2022-10-19 18:48:05 - progress_bar.py[line:274] - INFO: epoch 001:  17353 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.3, ups=0.88, wpb=109.4, bsz=40, num_updates=17330, lr=4.23571e-05, gnorm=0.918, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84145
2022-10-19 18:48:16 - progress_bar.py[line:274] - INFO: epoch 001:  17363 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=17340, lr=4.23816e-05, gnorm=0.779, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=84156
2022-10-19 18:48:27 - progress_bar.py[line:274] - INFO: epoch 001:  17373 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.8, ups=0.91, wpb=111.4, bsz=40, num_updates=17350, lr=4.2406e-05, gnorm=0.786, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=84167
2022-10-19 18:48:38 - progress_bar.py[line:274] - INFO: epoch 001:  17383 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.8, ups=0.89, wpb=112.3, bsz=40, num_updates=17360, lr=4.24305e-05, gnorm=0.907, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84178
2022-10-19 18:48:49 - progress_bar.py[line:274] - INFO: epoch 001:  17393 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.8, ups=0.93, wpb=110.7, bsz=40, num_updates=17370, lr=4.24549e-05, gnorm=0.967, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=84189
2022-10-19 18:49:01 - progress_bar.py[line:274] - INFO: epoch 001:  17403 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=17380, lr=4.24793e-05, gnorm=0.953, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84200
2022-10-19 18:49:12 - progress_bar.py[line:274] - INFO: epoch 001:  17413 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=17390, lr=4.25038e-05, gnorm=0.965, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84212
2022-10-19 18:49:23 - progress_bar.py[line:274] - INFO: epoch 001:  17423 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.1, ups=0.9, wpb=112, bsz=40, num_updates=17400, lr=4.25282e-05, gnorm=0.809, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84223
2022-10-19 18:49:34 - progress_bar.py[line:274] - INFO: epoch 001:  17433 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.7, ups=0.89, wpb=108.6, bsz=40, num_updates=17410, lr=4.25527e-05, gnorm=0.783, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84234
2022-10-19 18:49:46 - progress_bar.py[line:274] - INFO: epoch 001:  17443 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=17420, lr=4.25771e-05, gnorm=0.975, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84245
2022-10-19 18:49:57 - progress_bar.py[line:274] - INFO: epoch 001:  17453 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.2, ups=0.87, wpb=109.3, bsz=40, num_updates=17430, lr=4.26016e-05, gnorm=0.865, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84257
2022-10-19 18:50:08 - progress_bar.py[line:274] - INFO: epoch 001:  17463 / 102288 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.7, ups=0.89, wpb=108.5, bsz=40, num_updates=17440, lr=4.2626e-05, gnorm=0.973, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84268
2022-10-19 18:50:20 - progress_bar.py[line:274] - INFO: epoch 001:  17473 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.3, ups=0.88, wpb=109.4, bsz=40, num_updates=17450, lr=4.26504e-05, gnorm=0.966, clip=40, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=84279
2022-10-19 18:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  17483 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.6, ups=0.9, wpb=109.3, bsz=40, num_updates=17460, lr=4.26749e-05, gnorm=0.976, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84291
2022-10-19 18:50:42 - progress_bar.py[line:274] - INFO: epoch 001:  17493 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=104.9, ups=0.93, wpb=112.8, bsz=40, num_updates=17470, lr=4.26993e-05, gnorm=0.949, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84301
2022-10-19 18:50:53 - progress_bar.py[line:274] - INFO: epoch 001:  17503 / 102288 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.4, ups=0.91, wpb=108.9, bsz=40, num_updates=17480, lr=4.27238e-05, gnorm=0.887, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84312
2022-10-19 18:51:04 - progress_bar.py[line:274] - INFO: epoch 001:  17513 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96, ups=0.87, wpb=110.7, bsz=40, num_updates=17490, lr=4.27482e-05, gnorm=0.751, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84324
2022-10-19 18:51:16 - progress_bar.py[line:274] - INFO: epoch 001:  17523 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.4, ups=0.89, wpb=110.8, bsz=40, num_updates=17500, lr=4.27726e-05, gnorm=0.832, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84335
2022-10-19 18:51:27 - progress_bar.py[line:274] - INFO: epoch 001:  17533 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=17510, lr=4.27971e-05, gnorm=1.014, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84346
2022-10-19 18:51:38 - progress_bar.py[line:274] - INFO: epoch 001:  17543 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.9, wpb=108.6, bsz=40, num_updates=17520, lr=4.28215e-05, gnorm=0.824, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84357
2022-10-19 18:51:49 - progress_bar.py[line:274] - INFO: epoch 001:  17553 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.8, ups=0.93, wpb=109.4, bsz=40, num_updates=17530, lr=4.2846e-05, gnorm=0.948, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84368
2022-10-19 18:52:00 - progress_bar.py[line:274] - INFO: epoch 001:  17563 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.2, ups=0.88, wpb=109.1, bsz=40, num_updates=17540, lr=4.28704e-05, gnorm=1.08, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84380
2022-10-19 18:52:11 - progress_bar.py[line:274] - INFO: epoch 001:  17573 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.8, ups=0.91, wpb=110.4, bsz=40, num_updates=17550, lr=4.28949e-05, gnorm=0.868, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84391
2022-10-19 18:52:12 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 18:52:23 - progress_bar.py[line:274] - INFO: epoch 001:  17584 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=92.2, ups=0.83, wpb=111.5, bsz=40, num_updates=17560, lr=4.29193e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=84403
2022-10-19 18:52:34 - progress_bar.py[line:274] - INFO: epoch 001:  17594 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.2, ups=0.91, wpb=109.2, bsz=40, num_updates=17570, lr=4.29437e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84414
2022-10-19 18:52:46 - progress_bar.py[line:274] - INFO: epoch 001:  17604 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.3, ups=0.88, wpb=109.5, bsz=40, num_updates=17580, lr=4.29682e-05, gnorm=0.992, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84425
2022-10-19 18:52:57 - progress_bar.py[line:274] - INFO: epoch 001:  17614 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=17590, lr=4.29926e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84437
2022-10-19 18:53:08 - progress_bar.py[line:274] - INFO: epoch 001:  17624 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.5, ups=0.91, wpb=111.9, bsz=40, num_updates=17600, lr=4.30171e-05, gnorm=1.021, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84448
2022-10-19 18:53:19 - progress_bar.py[line:274] - INFO: epoch 001:  17634 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.7, ups=0.9, wpb=108.5, bsz=40, num_updates=17610, lr=4.30415e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84459
2022-10-19 18:53:31 - progress_bar.py[line:274] - INFO: epoch 001:  17644 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.9, wpb=109.3, bsz=40, num_updates=17620, lr=4.30659e-05, gnorm=1.047, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84470
2022-10-19 18:53:42 - progress_bar.py[line:274] - INFO: epoch 001:  17654 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.5, ups=0.91, wpb=110.6, bsz=40, num_updates=17630, lr=4.30904e-05, gnorm=0.977, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=84481
2022-10-19 18:53:53 - progress_bar.py[line:274] - INFO: epoch 001:  17664 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.1, ups=0.9, wpb=110, bsz=40, num_updates=17640, lr=4.31148e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84493
2022-10-19 18:54:04 - progress_bar.py[line:274] - INFO: epoch 001:  17674 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.8, ups=0.91, wpb=110.2, bsz=40, num_updates=17650, lr=4.31393e-05, gnorm=0.872, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84504
2022-10-19 18:54:15 - progress_bar.py[line:274] - INFO: epoch 001:  17684 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.2, ups=0.9, wpb=110.3, bsz=40, num_updates=17660, lr=4.31637e-05, gnorm=1.042, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84515
2022-10-19 18:54:26 - progress_bar.py[line:274] - INFO: epoch 001:  17694 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=17670, lr=4.31882e-05, gnorm=0.923, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84526
2022-10-19 18:54:38 - progress_bar.py[line:274] - INFO: epoch 001:  17704 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.5, ups=0.88, wpb=109.8, bsz=40, num_updates=17680, lr=4.32126e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84537
2022-10-19 18:54:49 - progress_bar.py[line:274] - INFO: epoch 001:  17714 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=17690, lr=4.3237e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84549
2022-10-19 18:55:00 - progress_bar.py[line:274] - INFO: epoch 001:  17724 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=17700, lr=4.32615e-05, gnorm=0.81, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84560
2022-10-19 18:55:12 - progress_bar.py[line:274] - INFO: epoch 001:  17734 / 102288 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.5, ups=0.87, wpb=109.9, bsz=40, num_updates=17710, lr=4.32859e-05, gnorm=1.054, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84571
2022-10-19 18:55:23 - progress_bar.py[line:274] - INFO: epoch 001:  17744 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.3, ups=0.9, wpb=110.2, bsz=40, num_updates=17720, lr=4.33104e-05, gnorm=1.018, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84583
2022-10-19 18:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  17754 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.8, ups=0.93, wpb=108.8, bsz=40, num_updates=17730, lr=4.33348e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=84593
2022-10-19 18:55:45 - progress_bar.py[line:274] - INFO: epoch 001:  17764 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.1, ups=0.92, wpb=109.3, bsz=40, num_updates=17740, lr=4.33592e-05, gnorm=1.253, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=84604
2022-10-19 18:55:56 - progress_bar.py[line:274] - INFO: epoch 001:  17774 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=17750, lr=4.33837e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84616
2022-10-19 18:56:07 - progress_bar.py[line:274] - INFO: epoch 001:  17784 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.5, ups=0.89, wpb=110.9, bsz=40, num_updates=17760, lr=4.34081e-05, gnorm=0.979, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84627
2022-10-19 18:56:18 - progress_bar.py[line:274] - INFO: epoch 001:  17794 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.6, ups=0.93, wpb=110.3, bsz=40, num_updates=17770, lr=4.34326e-05, gnorm=1.018, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=84638
2022-10-19 18:56:29 - progress_bar.py[line:274] - INFO: epoch 001:  17804 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100, ups=0.91, wpb=109.8, bsz=40, num_updates=17780, lr=4.3457e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84649
2022-10-19 18:56:41 - progress_bar.py[line:274] - INFO: epoch 001:  17814 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=17790, lr=4.34814e-05, gnorm=0.893, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84660
2022-10-19 18:56:52 - progress_bar.py[line:274] - INFO: epoch 001:  17824 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.1, ups=0.88, wpb=112.7, bsz=40, num_updates=17800, lr=4.35059e-05, gnorm=1.035, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84672
2022-10-19 18:57:03 - progress_bar.py[line:274] - INFO: epoch 001:  17834 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.8, ups=0.91, wpb=110.5, bsz=40, num_updates=17810, lr=4.35303e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84683
2022-10-19 18:57:14 - progress_bar.py[line:274] - INFO: epoch 001:  17844 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.9, ups=0.87, wpb=110.7, bsz=40, num_updates=17820, lr=4.35548e-05, gnorm=0.859, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=84694
2022-10-19 18:57:26 - progress_bar.py[line:274] - INFO: epoch 001:  17854 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=17830, lr=4.35792e-05, gnorm=0.908, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84705
2022-10-19 18:57:36 - progress_bar.py[line:274] - INFO: epoch 001:  17864 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=104.6, ups=0.95, wpb=109.9, bsz=40, num_updates=17840, lr=4.36037e-05, gnorm=0.983, clip=50, loss_scale=512, train_wall=10, gb_free=11, ema_decay=0.9999, wall=84716
2022-10-19 18:57:47 - progress_bar.py[line:274] - INFO: epoch 001:  17874 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=17850, lr=4.36281e-05, gnorm=0.943, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84727
2022-10-19 18:57:59 - progress_bar.py[line:274] - INFO: epoch 001:  17884 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.4, ups=0.87, wpb=110.1, bsz=40, num_updates=17860, lr=4.36525e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84739
2022-10-19 18:58:10 - progress_bar.py[line:274] - INFO: epoch 001:  17894 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.1, ups=0.89, wpb=108.9, bsz=40, num_updates=17870, lr=4.3677e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84750
2022-10-19 18:58:22 - progress_bar.py[line:274] - INFO: epoch 001:  17904 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.4, ups=0.9, wpb=108.8, bsz=40, num_updates=17880, lr=4.37014e-05, gnorm=0.999, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84761
2022-10-19 18:58:33 - progress_bar.py[line:274] - INFO: epoch 001:  17914 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=17890, lr=4.37259e-05, gnorm=0.868, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84772
2022-10-19 18:58:44 - progress_bar.py[line:274] - INFO: epoch 001:  17924 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.8, ups=0.9, wpb=110.6, bsz=40, num_updates=17900, lr=4.37503e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84783
2022-10-19 18:58:55 - progress_bar.py[line:274] - INFO: epoch 001:  17934 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=17910, lr=4.37747e-05, gnorm=0.847, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=84795
2022-10-19 18:59:06 - progress_bar.py[line:274] - INFO: epoch 001:  17944 / 102288 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.9, ups=0.88, wpb=108.9, bsz=40, num_updates=17920, lr=4.37992e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84806
2022-10-19 18:59:17 - progress_bar.py[line:274] - INFO: epoch 001:  17954 / 102288 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.5, ups=0.9, wpb=108.9, bsz=40, num_updates=17930, lr=4.38236e-05, gnorm=0.99, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84817
2022-10-19 18:59:29 - progress_bar.py[line:274] - INFO: epoch 001:  17964 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=17940, lr=4.38481e-05, gnorm=1.074, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=84828
2022-10-19 18:59:40 - progress_bar.py[line:274] - INFO: epoch 001:  17974 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.4, ups=0.88, wpb=109.5, bsz=40, num_updates=17950, lr=4.38725e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84840
2022-10-19 18:59:51 - progress_bar.py[line:274] - INFO: epoch 001:  17984 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.8, ups=0.88, wpb=111.3, bsz=40, num_updates=17960, lr=4.3897e-05, gnorm=0.933, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84851
2022-10-19 19:00:03 - progress_bar.py[line:274] - INFO: epoch 001:  17994 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.9, ups=0.89, wpb=110.3, bsz=40, num_updates=17970, lr=4.39214e-05, gnorm=0.82, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84863
2022-10-19 19:00:14 - progress_bar.py[line:274] - INFO: epoch 001:  18004 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=17980, lr=4.39458e-05, gnorm=0.865, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=84873
2022-10-19 19:00:25 - progress_bar.py[line:274] - INFO: epoch 001:  18014 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=17990, lr=4.39703e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=84885
2022-10-19 19:00:37 - progress_bar.py[line:274] - INFO: epoch 001:  18024 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=94, ups=0.87, wpb=108.3, bsz=40, num_updates=18000, lr=4.39947e-05, gnorm=0.952, clip=50, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=84896
2022-10-19 19:00:37 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 19:00:38 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 19:00:38 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 19:03:10 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 19:03:10 - train.py[line:551] - INFO: load:1.02 valid_run:152.12 task_valid:148.08 collect_output:3.00
2022-10-19 19:05:39 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 19:05:39 - train.py[line:551] - INFO: load:1.04 valid_run:300.71 task_valid:291.11 collect_output:7.54
2022-10-19 19:08:11 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 19:08:11 - train.py[line:551] - INFO: load:1.07 valid_run:453.26 task_valid:434.26 collect_output:15.92
2022-10-19 19:10:41 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 19:10:41 - train.py[line:551] - INFO: load:1.10 valid_run:602.48 task_valid:579.06 collect_output:19.31
2022-10-19 19:13:13 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 19:13:13 - train.py[line:551] - INFO: load:1.13 valid_run:755.03 task_valid:726.39 collect_output:23.51
2022-10-19 19:15:45 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 19:15:45 - train.py[line:551] - INFO: load:1.15 valid_run:906.92 task_valid:871.69 collect_output:29.10
2022-10-19 19:18:19 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 19:18:19 - train.py[line:551] - INFO: load:1.18 valid_run:1060.78 task_valid:1017.75 collect_output:35.90
2022-10-19 19:20:51 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 19:20:51 - train.py[line:551] - INFO: load:1.21 valid_run:1212.33 task_valid:1158.68 collect_output:45.51
2022-10-19 19:23:21 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 19:23:21 - train.py[line:551] - INFO: load:1.23 valid_run:1362.37 task_valid:1303.37 collect_output:49.86
2022-10-19 19:25:50 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 19:25:50 - train.py[line:551] - INFO: load:1.26 valid_run:1511.33 task_valid:1446.46 collect_output:54.73
2022-10-19 19:28:20 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 19:28:20 - train.py[line:551] - INFO: load:1.29 valid_run:1661.69 task_valid:1591.60 collect_output:58.89
2022-10-19 19:30:51 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 19:30:51 - train.py[line:551] - INFO: load:1.31 valid_run:1812.38 task_valid:1737.09 collect_output:62.97
2022-10-19 19:33:22 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 19:33:22 - train.py[line:551] - INFO: load:1.34 valid_run:1963.18 task_valid:1879.12 collect_output:70.67
2022-10-19 19:35:53 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 19:35:53 - train.py[line:551] - INFO: load:1.37 valid_run:2114.05 task_valid:2024.71 collect_output:74.91
2022-10-19 19:38:23 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 19:38:23 - train.py[line:551] - INFO: load:1.39 valid_run:2264.44 task_valid:2171.29 collect_output:77.64
2022-10-19 19:40:54 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 19:40:54 - train.py[line:551] - INFO: load:1.42 valid_run:2415.14 task_valid:2315.80 collect_output:82.77
2022-10-19 19:43:27 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 19:43:27 - train.py[line:551] - INFO: load:1.45 valid_run:2567.49 task_valid:2461.41 collect_output:88.46
2022-10-19 19:45:58 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 19:45:58 - train.py[line:551] - INFO: load:1.47 valid_run:2718.62 task_valid:2608.53 collect_output:91.43
2022-10-19 19:48:27 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 19:48:27 - train.py[line:551] - INFO: load:1.50 valid_run:2867.75 task_valid:2750.25 collect_output:97.78
2022-10-19 19:50:58 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 19:50:58 - train.py[line:551] - INFO: load:1.53 valid_run:3019.19 task_valid:2896.01 collect_output:102.39
2022-10-19 19:53:32 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 19:53:32 - train.py[line:551] - INFO: load:1.55 valid_run:3172.45 task_valid:3040.88 collect_output:109.69
2022-10-19 19:56:02 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 19:56:02 - train.py[line:551] - INFO: load:1.58 valid_run:3322.91 task_valid:3185.99 collect_output:113.76
2022-10-19 19:58:35 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 19:58:35 - train.py[line:551] - INFO: load:1.61 valid_run:3475.21 task_valid:3332.64 collect_output:118.19
2022-10-19 20:01:08 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 20:01:08 - train.py[line:551] - INFO: load:1.63 valid_run:3628.84 task_valid:3480.76 collect_output:122.43

====================================================================================================
SGG eval:     R @ 50: 0.5287;     R @ 100: 0.5691;     R @ 500: 0.5970;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3582;    mR @ 100: 0.3988;    mR @ 500: 0.4210;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8958) (playing:0.0000) (riding:0.8350) (says:0.0000) (sitting on:0.6967) (standing on:0.1937) (using:0.6500) (walking in:0.0000) (walking on:0.6937) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5287;     R @ 100: 0.5691;     R @ 500: 0.5970;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3582;    mR @ 100: 0.3988;    mR @ 500: 0.4210;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8958) (playing:0.0000) (riding:0.8350) (says:0.0000) (sitting on:0.6967) (standing on:0.1937) (using:0.6500) (walking in:0.0000) (walking on:0.6937) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2022-10-19 20:03:42 - train.py[line:487] - INFO: 0.5691148459383754
2022-10-19 20:03:42 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 20:03:42 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.347 | loss_v1 0 | loss_v2 0 | nll_loss 0.19 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.569115 | ppl 1.14 | vqa_score 0.5056 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 18000 | best_R@100 0.593911
2022-10-19 20:03:42 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 18000 updates
2022-10-19 20:03:42 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_18000.pt
2022-10-19 20:03:48 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_18000.pt
2022-10-19 20:03:51 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 0.5691148459383754) (writing took 8.68641640106216 seconds)
2022-10-19 20:04:02 - progress_bar.py[line:274] - INFO: epoch 001:  18034 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=0.3, ups=0, wpb=108.7, bsz=40, num_updates=18010, lr=4.40192e-05, gnorm=1.068, clip=70, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=88702
2022-10-19 20:04:14 - progress_bar.py[line:274] - INFO: epoch 001:  18044 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=18020, lr=4.40436e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88713
2022-10-19 20:04:25 - progress_bar.py[line:274] - INFO: epoch 001:  18054 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=18030, lr=4.4068e-05, gnorm=1.02, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88725
2022-10-19 20:04:36 - progress_bar.py[line:274] - INFO: epoch 001:  18064 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.2, ups=0.9, wpb=110, bsz=40, num_updates=18040, lr=4.40925e-05, gnorm=1.062, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88736
2022-10-19 20:04:47 - progress_bar.py[line:274] - INFO: epoch 001:  18074 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.4, ups=0.88, wpb=110.9, bsz=40, num_updates=18050, lr=4.41169e-05, gnorm=1.029, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88747
2022-10-19 20:04:58 - progress_bar.py[line:274] - INFO: epoch 001:  18084 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.9, ups=0.9, wpb=109.6, bsz=40, num_updates=18060, lr=4.41414e-05, gnorm=0.81, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88758
2022-10-19 20:05:09 - progress_bar.py[line:274] - INFO: epoch 001:  18094 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.7, ups=0.9, wpb=108.5, bsz=40, num_updates=18070, lr=4.41658e-05, gnorm=0.945, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=88769
2022-10-19 20:05:21 - progress_bar.py[line:274] - INFO: epoch 001:  18104 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.4, ups=0.87, wpb=110.2, bsz=40, num_updates=18080, lr=4.41903e-05, gnorm=0.864, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88781
2022-10-19 20:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  18114 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.89, wpb=111.8, bsz=40, num_updates=18090, lr=4.42147e-05, gnorm=0.847, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88792
2022-10-19 20:05:43 - progress_bar.py[line:274] - INFO: epoch 001:  18124 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99, ups=0.91, wpb=109.3, bsz=40, num_updates=18100, lr=4.42391e-05, gnorm=1.011, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=88803
2022-10-19 20:05:55 - progress_bar.py[line:274] - INFO: epoch 001:  18134 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.6, ups=0.88, wpb=108.8, bsz=40, num_updates=18110, lr=4.42636e-05, gnorm=1.033, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88814
2022-10-19 20:06:06 - progress_bar.py[line:274] - INFO: epoch 001:  18144 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.6, ups=0.88, wpb=110.1, bsz=40, num_updates=18120, lr=4.4288e-05, gnorm=1.007, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88826
2022-10-19 20:06:17 - progress_bar.py[line:274] - INFO: epoch 001:  18154 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100, ups=0.91, wpb=109.4, bsz=40, num_updates=18130, lr=4.43125e-05, gnorm=1.032, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88837
2022-10-19 20:06:28 - progress_bar.py[line:274] - INFO: epoch 001:  18164 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.88, wpb=111, bsz=40, num_updates=18140, lr=4.43369e-05, gnorm=1.053, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88848
2022-10-19 20:06:40 - progress_bar.py[line:274] - INFO: epoch 001:  18174 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.7, ups=0.9, wpb=109.7, bsz=40, num_updates=18150, lr=4.43613e-05, gnorm=0.916, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88859
2022-10-19 20:06:51 - progress_bar.py[line:274] - INFO: epoch 001:  18184 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96, ups=0.87, wpb=110.6, bsz=40, num_updates=18160, lr=4.43858e-05, gnorm=0.802, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88871
2022-10-19 20:07:03 - progress_bar.py[line:274] - INFO: epoch 001:  18194 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.9, ups=0.88, wpb=109.3, bsz=40, num_updates=18170, lr=4.44102e-05, gnorm=0.947, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88882
2022-10-19 20:07:14 - progress_bar.py[line:274] - INFO: epoch 001:  18204 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.7, ups=0.88, wpb=110.2, bsz=40, num_updates=18180, lr=4.44347e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88894
2022-10-19 20:07:25 - progress_bar.py[line:274] - INFO: epoch 001:  18214 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=18190, lr=4.44591e-05, gnorm=0.904, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88905
2022-10-19 20:07:36 - progress_bar.py[line:274] - INFO: epoch 001:  18224 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.3, ups=0.89, wpb=109.2, bsz=40, num_updates=18200, lr=4.44836e-05, gnorm=0.912, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=88916
2022-10-19 20:07:47 - progress_bar.py[line:274] - INFO: epoch 001:  18234 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=18210, lr=4.4508e-05, gnorm=0.839, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88927
2022-10-19 20:07:59 - progress_bar.py[line:274] - INFO: epoch 001:  18244 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.5, ups=0.9, wpb=109.1, bsz=40, num_updates=18220, lr=4.45324e-05, gnorm=0.943, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88938
2022-10-19 20:08:10 - progress_bar.py[line:274] - INFO: epoch 001:  18254 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.7, ups=0.87, wpb=109, bsz=40, num_updates=18230, lr=4.45569e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88950
2022-10-19 20:08:21 - progress_bar.py[line:274] - INFO: epoch 001:  18264 / 102288 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.9, ups=0.88, wpb=109, bsz=40, num_updates=18240, lr=4.45813e-05, gnorm=1.006, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=88961
2022-10-19 20:08:33 - progress_bar.py[line:274] - INFO: epoch 001:  18274 / 102288 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=18250, lr=4.46058e-05, gnorm=0.902, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88972
2022-10-19 20:08:43 - progress_bar.py[line:274] - INFO: epoch 001:  18284 / 102288 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101, ups=0.91, wpb=110.5, bsz=40, num_updates=18260, lr=4.46302e-05, gnorm=0.808, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=88983
2022-10-19 20:08:55 - progress_bar.py[line:274] - INFO: epoch 001:  18294 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=18270, lr=4.46546e-05, gnorm=1.031, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=88994
2022-10-19 20:09:06 - progress_bar.py[line:274] - INFO: epoch 001:  18304 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=18280, lr=4.46791e-05, gnorm=0.864, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89006
2022-10-19 20:09:17 - progress_bar.py[line:274] - INFO: epoch 001:  18314 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.4, ups=0.87, wpb=109.9, bsz=40, num_updates=18290, lr=4.47035e-05, gnorm=0.967, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89017
2022-10-19 20:09:28 - progress_bar.py[line:274] - INFO: epoch 001:  18324 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=18300, lr=4.4728e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89028
2022-10-19 20:09:40 - progress_bar.py[line:274] - INFO: epoch 001:  18334 / 102288 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.2, ups=0.87, wpb=109.7, bsz=40, num_updates=18310, lr=4.47524e-05, gnorm=0.774, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89040
2022-10-19 20:09:51 - progress_bar.py[line:274] - INFO: epoch 001:  18344 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.7, ups=0.91, wpb=110.3, bsz=40, num_updates=18320, lr=4.47768e-05, gnorm=0.82, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89051
2022-10-19 20:10:02 - progress_bar.py[line:274] - INFO: epoch 001:  18354 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.6, ups=0.87, wpb=108.9, bsz=40, num_updates=18330, lr=4.48013e-05, gnorm=1.024, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89062
2022-10-19 20:10:14 - progress_bar.py[line:274] - INFO: epoch 001:  18364 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.3, ups=0.87, wpb=110.8, bsz=40, num_updates=18340, lr=4.48257e-05, gnorm=0.946, clip=40, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=89074
2022-10-19 20:10:25 - progress_bar.py[line:274] - INFO: epoch 001:  18374 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=18350, lr=4.48502e-05, gnorm=0.918, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89085
2022-10-19 20:10:36 - progress_bar.py[line:274] - INFO: epoch 001:  18384 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=18360, lr=4.48746e-05, gnorm=0.785, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89096
2022-10-19 20:10:47 - progress_bar.py[line:274] - INFO: epoch 001:  18394 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.7, ups=0.9, wpb=111.9, bsz=40, num_updates=18370, lr=4.48991e-05, gnorm=0.76, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89107
2022-10-19 20:10:59 - progress_bar.py[line:274] - INFO: epoch 001:  18404 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.2, ups=0.89, wpb=110.6, bsz=40, num_updates=18380, lr=4.49235e-05, gnorm=0.868, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89118
2022-10-19 20:11:10 - progress_bar.py[line:274] - INFO: epoch 001:  18414 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=18390, lr=4.49479e-05, gnorm=0.936, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89130
2022-10-19 20:11:21 - progress_bar.py[line:274] - INFO: epoch 001:  18424 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=18400, lr=4.49724e-05, gnorm=0.883, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89141
2022-10-19 20:11:33 - progress_bar.py[line:274] - INFO: epoch 001:  18434 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.8, ups=0.87, wpb=110.4, bsz=40, num_updates=18410, lr=4.49968e-05, gnorm=0.972, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89152
2022-10-19 20:11:44 - progress_bar.py[line:274] - INFO: epoch 001:  18444 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.8, ups=0.89, wpb=110.1, bsz=40, num_updates=18420, lr=4.50213e-05, gnorm=1.027, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89164
2022-10-19 20:11:55 - progress_bar.py[line:274] - INFO: epoch 001:  18454 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=103, ups=0.92, wpb=111.4, bsz=40, num_updates=18430, lr=4.50457e-05, gnorm=0.853, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89175
2022-10-19 20:11:58 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 20:12:07 - progress_bar.py[line:274] - INFO: epoch 001:  18465 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.2, ups=0.82, wpb=110.6, bsz=40, num_updates=18440, lr=4.50701e-05, gnorm=0.858, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=89187
2022-10-19 20:12:18 - progress_bar.py[line:274] - INFO: epoch 001:  18475 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=18450, lr=4.50946e-05, gnorm=0.953, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89198
2022-10-19 20:12:30 - progress_bar.py[line:274] - INFO: epoch 001:  18485 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.1, ups=0.87, wpb=110.3, bsz=40, num_updates=18460, lr=4.5119e-05, gnorm=0.937, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89210
2022-10-19 20:12:41 - progress_bar.py[line:274] - INFO: epoch 001:  18495 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.4, ups=0.9, wpb=109.6, bsz=40, num_updates=18470, lr=4.51435e-05, gnorm=0.933, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89221
2022-10-19 20:12:53 - progress_bar.py[line:274] - INFO: epoch 001:  18505 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97, ups=0.88, wpb=110.5, bsz=40, num_updates=18480, lr=4.51679e-05, gnorm=0.947, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89232
2022-10-19 20:13:04 - progress_bar.py[line:274] - INFO: epoch 001:  18515 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.5, ups=0.9, wpb=111.4, bsz=40, num_updates=18490, lr=4.51924e-05, gnorm=0.984, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89243
2022-10-19 20:13:15 - progress_bar.py[line:274] - INFO: epoch 001:  18525 / 102288 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=18500, lr=4.52168e-05, gnorm=0.937, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=89255
2022-10-19 20:13:26 - progress_bar.py[line:274] - INFO: epoch 001:  18535 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.3, ups=0.88, wpb=108.9, bsz=40, num_updates=18510, lr=4.52412e-05, gnorm=0.772, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89266
2022-10-19 20:13:38 - progress_bar.py[line:274] - INFO: epoch 001:  18545 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.1, ups=0.89, wpb=111.3, bsz=40, num_updates=18520, lr=4.52657e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89277
2022-10-19 20:13:49 - progress_bar.py[line:274] - INFO: epoch 001:  18555 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.2, ups=0.89, wpb=112.4, bsz=40, num_updates=18530, lr=4.52901e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89289
2022-10-19 20:14:00 - progress_bar.py[line:274] - INFO: epoch 001:  18565 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=18540, lr=4.53146e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89300
2022-10-19 20:14:11 - progress_bar.py[line:274] - INFO: epoch 001:  18575 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.1, ups=0.92, wpb=111.2, bsz=40, num_updates=18550, lr=4.5339e-05, gnorm=0.96, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89311
2022-10-19 20:14:22 - progress_bar.py[line:274] - INFO: epoch 001:  18585 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=18560, lr=4.53634e-05, gnorm=0.952, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89322
2022-10-19 20:14:34 - progress_bar.py[line:274] - INFO: epoch 001:  18595 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=18570, lr=4.53879e-05, gnorm=1.006, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89333
2022-10-19 20:14:45 - progress_bar.py[line:274] - INFO: epoch 001:  18605 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=18580, lr=4.54123e-05, gnorm=0.969, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=89344
2022-10-19 20:14:55 - progress_bar.py[line:274] - INFO: epoch 001:  18615 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=103, ups=0.94, wpb=109.7, bsz=40, num_updates=18590, lr=4.54368e-05, gnorm=0.993, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89355
2022-10-19 20:15:07 - progress_bar.py[line:274] - INFO: epoch 001:  18625 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.4, ups=0.87, wpb=111.7, bsz=40, num_updates=18600, lr=4.54612e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89367
2022-10-19 20:15:18 - progress_bar.py[line:274] - INFO: epoch 001:  18635 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.8, ups=0.9, wpb=110.1, bsz=40, num_updates=18610, lr=4.54857e-05, gnorm=0.893, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89378
2022-10-19 20:15:29 - progress_bar.py[line:274] - INFO: epoch 001:  18645 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=18620, lr=4.55101e-05, gnorm=0.852, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89389
2022-10-19 20:15:41 - progress_bar.py[line:274] - INFO: epoch 001:  18655 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.9, ups=0.86, wpb=110.6, bsz=40, num_updates=18630, lr=4.55345e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=89401
2022-10-19 20:15:52 - progress_bar.py[line:274] - INFO: epoch 001:  18665 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.3, ups=0.9, wpb=110, bsz=40, num_updates=18640, lr=4.5559e-05, gnorm=0.799, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89412
2022-10-19 20:16:03 - progress_bar.py[line:274] - INFO: epoch 001:  18675 / 102288 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.8, ups=0.89, wpb=109.9, bsz=40, num_updates=18650, lr=4.55834e-05, gnorm=0.998, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89423
2022-10-19 20:16:15 - progress_bar.py[line:274] - INFO: epoch 001:  18685 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.8, ups=0.88, wpb=110.4, bsz=40, num_updates=18660, lr=4.56079e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=89434
2022-10-19 20:16:26 - progress_bar.py[line:274] - INFO: epoch 001:  18695 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=18670, lr=4.56323e-05, gnorm=0.962, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89446
2022-10-19 20:16:37 - progress_bar.py[line:274] - INFO: epoch 001:  18705 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=103.7, ups=0.94, wpb=110.6, bsz=40, num_updates=18680, lr=4.56567e-05, gnorm=0.893, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89457
2022-10-19 20:16:48 - progress_bar.py[line:274] - INFO: epoch 001:  18715 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.9, ups=0.88, wpb=108.8, bsz=40, num_updates=18690, lr=4.56812e-05, gnorm=0.858, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89468
2022-10-19 20:17:00 - progress_bar.py[line:274] - INFO: epoch 001:  18725 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=18700, lr=4.57056e-05, gnorm=0.865, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89479
2022-10-19 20:17:11 - progress_bar.py[line:274] - INFO: epoch 001:  18735 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.4, ups=0.91, wpb=109.8, bsz=40, num_updates=18710, lr=4.57301e-05, gnorm=0.951, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=89490
2022-10-19 20:17:22 - progress_bar.py[line:274] - INFO: epoch 001:  18745 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=18720, lr=4.57545e-05, gnorm=0.941, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89502
2022-10-19 20:17:33 - progress_bar.py[line:274] - INFO: epoch 001:  18755 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=18730, lr=4.5779e-05, gnorm=0.994, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89513
2022-10-19 20:17:44 - progress_bar.py[line:274] - INFO: epoch 001:  18765 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=18740, lr=4.58034e-05, gnorm=1.056, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89524
2022-10-19 20:17:55 - progress_bar.py[line:274] - INFO: epoch 001:  18775 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99, ups=0.9, wpb=110.6, bsz=40, num_updates=18750, lr=4.58278e-05, gnorm=0.894, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89535
2022-10-19 20:18:06 - progress_bar.py[line:274] - INFO: epoch 001:  18785 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.7, ups=0.91, wpb=109, bsz=40, num_updates=18760, lr=4.58523e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89546
2022-10-19 20:18:18 - progress_bar.py[line:274] - INFO: epoch 001:  18795 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.4, ups=0.88, wpb=109.2, bsz=40, num_updates=18770, lr=4.58767e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89558
2022-10-19 20:18:29 - progress_bar.py[line:274] - INFO: epoch 001:  18805 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.8, ups=0.88, wpb=110, bsz=40, num_updates=18780, lr=4.59012e-05, gnorm=0.876, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=89569
2022-10-19 20:18:41 - progress_bar.py[line:274] - INFO: epoch 001:  18815 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=18790, lr=4.59256e-05, gnorm=0.882, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89580
2022-10-19 20:18:52 - progress_bar.py[line:274] - INFO: epoch 001:  18825 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.7, ups=0.91, wpb=108.9, bsz=40, num_updates=18800, lr=4.595e-05, gnorm=0.924, clip=40, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=89591
2022-10-19 20:19:03 - progress_bar.py[line:274] - INFO: epoch 001:  18835 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.5, ups=0.87, wpb=110.1, bsz=40, num_updates=18810, lr=4.59745e-05, gnorm=0.978, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89603
2022-10-19 20:19:15 - progress_bar.py[line:274] - INFO: epoch 001:  18845 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=18820, lr=4.59989e-05, gnorm=0.962, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=89614
2022-10-19 20:19:26 - progress_bar.py[line:274] - INFO: epoch 001:  18855 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.1, ups=0.89, wpb=110.6, bsz=40, num_updates=18830, lr=4.60234e-05, gnorm=0.899, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89626
2022-10-19 20:19:37 - progress_bar.py[line:274] - INFO: epoch 001:  18865 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=18840, lr=4.60478e-05, gnorm=1.07, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89637
2022-10-19 20:19:48 - progress_bar.py[line:274] - INFO: epoch 001:  18875 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.1, ups=0.89, wpb=109, bsz=40, num_updates=18850, lr=4.60722e-05, gnorm=1, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89648
2022-10-19 20:20:00 - progress_bar.py[line:274] - INFO: epoch 001:  18885 / 102288 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.9, wpb=109.5, bsz=40, num_updates=18860, lr=4.60967e-05, gnorm=0.892, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89659
2022-10-19 20:20:11 - progress_bar.py[line:274] - INFO: epoch 001:  18895 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.2, ups=0.91, wpb=110, bsz=40, num_updates=18870, lr=4.61211e-05, gnorm=0.966, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89670
2022-10-19 20:20:22 - progress_bar.py[line:274] - INFO: epoch 001:  18905 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=18880, lr=4.61456e-05, gnorm=0.99, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=89682
2022-10-19 20:20:33 - progress_bar.py[line:274] - INFO: epoch 001:  18915 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.1, ups=0.93, wpb=109.1, bsz=40, num_updates=18890, lr=4.617e-05, gnorm=0.947, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89693
2022-10-19 20:20:44 - progress_bar.py[line:274] - INFO: epoch 001:  18925 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102, ups=0.93, wpb=110.1, bsz=40, num_updates=18900, lr=4.61945e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89703
2022-10-19 20:20:55 - progress_bar.py[line:274] - INFO: epoch 001:  18935 / 102288 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.3, ups=0.91, wpb=109.8, bsz=40, num_updates=18910, lr=4.62189e-05, gnorm=1.019, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89714
2022-10-19 20:21:06 - progress_bar.py[line:274] - INFO: epoch 001:  18945 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=18920, lr=4.62433e-05, gnorm=1.048, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89726
2022-10-19 20:21:17 - progress_bar.py[line:274] - INFO: epoch 001:  18955 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.7, ups=0.9, wpb=110.8, bsz=40, num_updates=18930, lr=4.62678e-05, gnorm=0.858, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=89737
2022-10-19 20:21:28 - progress_bar.py[line:274] - INFO: epoch 001:  18965 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=18940, lr=4.62922e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89748
2022-10-19 20:21:40 - progress_bar.py[line:274] - INFO: epoch 001:  18975 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=18950, lr=4.63167e-05, gnorm=0.782, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=89759
2022-10-19 20:21:51 - progress_bar.py[line:274] - INFO: epoch 001:  18985 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97, ups=0.88, wpb=110.5, bsz=40, num_updates=18960, lr=4.63411e-05, gnorm=0.772, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89771
2022-10-19 20:22:02 - progress_bar.py[line:274] - INFO: epoch 001:  18995 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98, ups=0.89, wpb=109.6, bsz=40, num_updates=18970, lr=4.63655e-05, gnorm=0.81, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=89782
2022-10-19 20:22:13 - progress_bar.py[line:274] - INFO: epoch 001:  19005 / 102288 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=18980, lr=4.639e-05, gnorm=0.871, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=89793
2022-10-19 20:22:25 - progress_bar.py[line:274] - INFO: epoch 001:  19015 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.5, ups=0.89, wpb=109.6, bsz=40, num_updates=18990, lr=4.64144e-05, gnorm=0.812, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=89804
2022-10-19 20:22:36 - progress_bar.py[line:274] - INFO: epoch 001:  19025 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.9, ups=0.92, wpb=110.6, bsz=40, num_updates=19000, lr=4.64389e-05, gnorm=0.928, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89815
2022-10-19 20:22:36 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 20:22:37 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 20:22:37 - train.py[line:551] - INFO: load:1.12 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 20:25:09 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 20:25:09 - train.py[line:551] - INFO: load:1.15 valid_run:151.70 task_valid:148.11 collect_output:2.57
2022-10-19 20:27:38 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 20:27:38 - train.py[line:551] - INFO: load:1.17 valid_run:300.70 task_valid:291.30 collect_output:7.38
2022-10-19 20:30:11 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 20:30:11 - train.py[line:551] - INFO: load:1.19 valid_run:453.28 task_valid:434.44 collect_output:15.81
2022-10-19 20:32:40 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 20:32:40 - train.py[line:551] - INFO: load:1.22 valid_run:602.54 task_valid:579.31 collect_output:19.22
2022-10-19 20:35:12 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 20:35:12 - train.py[line:551] - INFO: load:1.24 valid_run:755.04 task_valid:726.84 collect_output:23.19
2022-10-19 20:37:45 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 20:37:45 - train.py[line:551] - INFO: load:1.27 valid_run:907.08 task_valid:872.30 collect_output:28.76
2022-10-19 20:40:19 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 20:40:19 - train.py[line:551] - INFO: load:1.29 valid_run:1061.39 task_valid:1018.77 collect_output:35.56
2022-10-19 20:42:51 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 20:42:51 - train.py[line:551] - INFO: load:1.32 valid_run:1213.20 task_valid:1160.21 collect_output:44.88
2022-10-19 20:45:21 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 20:45:21 - train.py[line:551] - INFO: load:1.34 valid_run:1363.07 task_valid:1305.03 collect_output:48.89
2022-10-19 20:47:50 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 20:47:50 - train.py[line:551] - INFO: load:1.36 valid_run:1512.40 task_valid:1448.48 collect_output:53.75
2022-10-19 20:50:21 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 20:50:21 - train.py[line:551] - INFO: load:1.39 valid_run:1662.78 task_valid:1593.77 collect_output:57.76
2022-10-19 20:52:51 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 20:52:51 - train.py[line:551] - INFO: load:1.41 valid_run:1813.21 task_valid:1738.82 collect_output:62.07
2022-10-19 20:55:22 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 20:55:22 - train.py[line:551] - INFO: load:1.44 valid_run:1963.81 task_valid:1880.91 collect_output:69.54
2022-10-19 20:57:53 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 20:57:53 - train.py[line:551] - INFO: load:1.46 valid_run:2114.56 task_valid:2026.49 collect_output:73.67
2022-10-19 21:00:23 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 21:00:23 - train.py[line:551] - INFO: load:1.49 valid_run:2265.34 task_valid:2173.37 collect_output:76.48
2022-10-19 21:02:54 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 21:02:54 - train.py[line:551] - INFO: load:1.51 valid_run:2415.82 task_valid:2317.77 collect_output:81.52
2022-10-19 21:05:26 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 21:05:26 - train.py[line:551] - INFO: load:1.54 valid_run:2568.04 task_valid:2463.36 collect_output:87.13
2022-10-19 21:07:57 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 21:07:57 - train.py[line:551] - INFO: load:1.56 valid_run:2718.84 task_valid:2610.39 collect_output:89.89
2022-10-19 21:10:26 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 21:10:26 - train.py[line:551] - INFO: load:1.59 valid_run:2867.69 task_valid:2752.00 collect_output:96.12
2022-10-19 21:12:57 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 21:12:57 - train.py[line:551] - INFO: load:1.61 valid_run:3018.60 task_valid:2897.35 collect_output:100.68
2022-10-19 21:15:30 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 21:15:30 - train.py[line:551] - INFO: load:1.64 valid_run:3171.28 task_valid:3042.06 collect_output:107.64
2022-10-19 21:18:00 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 21:18:00 - train.py[line:551] - INFO: load:1.66 valid_run:3321.17 task_valid:3186.71 collect_output:111.89
2022-10-19 21:20:31 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 21:20:31 - train.py[line:551] - INFO: load:1.69 valid_run:3473.03 task_valid:3332.95 collect_output:116.51
2022-10-19 21:23:04 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 21:23:04 - train.py[line:551] - INFO: load:1.71 valid_run:3625.17 task_valid:3479.91 collect_output:120.65

====================================================================================================
SGG eval:     R @ 50: 0.5178;     R @ 100: 0.5578;     R @ 500: 0.5857;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3526;    mR @ 100: 0.3899;    mR @ 500: 0.4145;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4516) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8438) (playing:0.0000) (riding:0.8252) (says:0.0000) (sitting on:0.6786) (standing on:0.1870) (using:0.6500) (walking in:0.0000) (walking on:0.6667) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5178;     R @ 100: 0.5578;     R @ 500: 0.5857;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3526;    mR @ 100: 0.3899;    mR @ 500: 0.4145;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.8750) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4516) (lying on:0.2500) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8438) (playing:0.0000) (riding:0.8252) (says:0.0000) (sitting on:0.6786) (standing on:0.1870) (using:0.6500) (walking in:0.0000) (walking on:0.6667) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2022-10-19 21:25:35 - train.py[line:487] - INFO: 0.557781512605042
2022-10-19 21:25:35 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 21:25:35 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.351 | loss_v1 0 | loss_v2 0 | nll_loss 0.187 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.557782 | ppl 1.14 | vqa_score 0.4966 | wps 118.7 | wpb 89.9 | bsz 30 | num_updates 19000 | best_R@100 0.593911
2022-10-19 21:25:35 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 19000 updates
2022-10-19 21:25:35 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_19000.pt
2022-10-19 21:25:41 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_19000.pt
2022-10-19 21:25:44 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_19000.pt (epoch 1 @ 19000 updates, score 0.557781512605042) (writing took 8.59899669000879 seconds)
2022-10-19 21:25:55 - progress_bar.py[line:274] - INFO: epoch 001:  19035 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=0.3, ups=0, wpb=109.4, bsz=40, num_updates=19010, lr=4.64633e-05, gnorm=0.965, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93615
2022-10-19 21:26:06 - progress_bar.py[line:274] - INFO: epoch 001:  19045 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=19020, lr=4.64878e-05, gnorm=0.907, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=93626
2022-10-19 21:26:18 - progress_bar.py[line:274] - INFO: epoch 001:  19055 / 102288 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=19030, lr=4.65122e-05, gnorm=0.886, clip=20, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=93637
2022-10-19 21:26:29 - progress_bar.py[line:274] - INFO: epoch 001:  19065 / 102288 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=19040, lr=4.65366e-05, gnorm=0.745, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=93649
2022-10-19 21:26:40 - progress_bar.py[line:274] - INFO: epoch 001:  19075 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.8, ups=0.89, wpb=108.6, bsz=40, num_updates=19050, lr=4.65611e-05, gnorm=0.86, clip=10, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=93660
2022-10-19 21:26:51 - progress_bar.py[line:274] - INFO: epoch 001:  19085 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.3, ups=0.9, wpb=110.2, bsz=40, num_updates=19060, lr=4.65855e-05, gnorm=0.939, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93671
2022-10-19 21:27:02 - progress_bar.py[line:274] - INFO: epoch 001:  19095 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=19070, lr=4.661e-05, gnorm=0.919, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93682
2022-10-19 21:27:14 - progress_bar.py[line:274] - INFO: epoch 001:  19105 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.3, ups=0.88, wpb=109.8, bsz=40, num_updates=19080, lr=4.66344e-05, gnorm=1.013, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93694
2022-10-19 21:27:25 - progress_bar.py[line:274] - INFO: epoch 001:  19115 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=19090, lr=4.66588e-05, gnorm=1.037, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93705
2022-10-19 21:27:36 - progress_bar.py[line:274] - INFO: epoch 001:  19125 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100, ups=0.92, wpb=109.2, bsz=40, num_updates=19100, lr=4.66833e-05, gnorm=0.984, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93716
2022-10-19 21:27:47 - progress_bar.py[line:274] - INFO: epoch 001:  19135 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=19110, lr=4.67077e-05, gnorm=0.893, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93727
2022-10-19 21:27:58 - progress_bar.py[line:274] - INFO: epoch 001:  19145 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=19120, lr=4.67322e-05, gnorm=0.892, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93738
2022-10-19 21:28:10 - progress_bar.py[line:274] - INFO: epoch 001:  19155 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.7, ups=0.9, wpb=110.2, bsz=40, num_updates=19130, lr=4.67566e-05, gnorm=0.988, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93749
2022-10-19 21:28:21 - progress_bar.py[line:274] - INFO: epoch 001:  19165 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.2, ups=0.87, wpb=109.6, bsz=40, num_updates=19140, lr=4.67811e-05, gnorm=0.996, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93761
2022-10-19 21:28:32 - progress_bar.py[line:274] - INFO: epoch 001:  19175 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.9, ups=0.91, wpb=110.5, bsz=40, num_updates=19150, lr=4.68055e-05, gnorm=0.916, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=93772
2022-10-19 21:28:44 - progress_bar.py[line:274] - INFO: epoch 001:  19185 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.2, ups=0.88, wpb=111.7, bsz=40, num_updates=19160, lr=4.68299e-05, gnorm=0.89, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93783
2022-10-19 21:28:55 - progress_bar.py[line:274] - INFO: epoch 001:  19195 / 102288 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.1, ups=0.89, wpb=111.3, bsz=40, num_updates=19170, lr=4.68544e-05, gnorm=0.82, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93795
2022-10-19 21:29:06 - progress_bar.py[line:274] - INFO: epoch 001:  19205 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.6, ups=0.89, wpb=109.7, bsz=40, num_updates=19180, lr=4.68788e-05, gnorm=0.901, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=93806
2022-10-19 21:29:18 - progress_bar.py[line:274] - INFO: epoch 001:  19215 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.5, ups=0.88, wpb=109.7, bsz=40, num_updates=19190, lr=4.69033e-05, gnorm=0.904, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93817
2022-10-19 21:29:29 - progress_bar.py[line:274] - INFO: epoch 001:  19225 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97, ups=0.89, wpb=108.9, bsz=40, num_updates=19200, lr=4.69277e-05, gnorm=0.899, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93829
2022-10-19 21:29:40 - progress_bar.py[line:274] - INFO: epoch 001:  19235 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.7, ups=0.9, wpb=111.7, bsz=40, num_updates=19210, lr=4.69521e-05, gnorm=0.95, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93840
2022-10-19 21:29:51 - progress_bar.py[line:274] - INFO: epoch 001:  19245 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.1, ups=0.88, wpb=109.2, bsz=40, num_updates=19220, lr=4.69766e-05, gnorm=0.978, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93851
2022-10-19 21:30:02 - progress_bar.py[line:274] - INFO: epoch 001:  19255 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=19230, lr=4.7001e-05, gnorm=0.91, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93862
2022-10-19 21:30:14 - progress_bar.py[line:274] - INFO: epoch 001:  19265 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.9, ups=0.88, wpb=110.3, bsz=40, num_updates=19240, lr=4.70255e-05, gnorm=0.952, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=93873
2022-10-19 21:30:25 - progress_bar.py[line:274] - INFO: epoch 001:  19275 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=19250, lr=4.70499e-05, gnorm=0.906, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93885
2022-10-19 21:30:36 - progress_bar.py[line:274] - INFO: epoch 001:  19285 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.7, ups=0.88, wpb=110.2, bsz=40, num_updates=19260, lr=4.70744e-05, gnorm=0.952, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93896
2022-10-19 21:30:48 - progress_bar.py[line:274] - INFO: epoch 001:  19295 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.6, ups=0.89, wpb=109.7, bsz=40, num_updates=19270, lr=4.70988e-05, gnorm=0.841, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93907
2022-10-19 21:30:59 - progress_bar.py[line:274] - INFO: epoch 001:  19305 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=19280, lr=4.71232e-05, gnorm=0.883, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=93919
2022-10-19 21:31:10 - progress_bar.py[line:274] - INFO: epoch 001:  19315 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=19290, lr=4.71477e-05, gnorm=1.066, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93930
2022-10-19 21:31:21 - progress_bar.py[line:274] - INFO: epoch 001:  19325 / 102288 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.9, ups=0.89, wpb=108.7, bsz=40, num_updates=19300, lr=4.71721e-05, gnorm=1.017, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93941
2022-10-19 21:31:33 - progress_bar.py[line:274] - INFO: epoch 001:  19335 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=19310, lr=4.71966e-05, gnorm=0.842, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=93952
2022-10-19 21:31:44 - progress_bar.py[line:274] - INFO: epoch 001:  19345 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=19320, lr=4.7221e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=93964
2022-10-19 21:31:55 - progress_bar.py[line:274] - INFO: epoch 001:  19355 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.4, ups=0.88, wpb=112.1, bsz=40, num_updates=19330, lr=4.72454e-05, gnorm=1.015, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=93975
2022-10-19 21:32:06 - progress_bar.py[line:274] - INFO: epoch 001:  19365 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.1, ups=0.89, wpb=111.3, bsz=40, num_updates=19340, lr=4.72699e-05, gnorm=0.86, clip=10, loss_scale=1024, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=93986
2022-10-19 21:32:18 - progress_bar.py[line:274] - INFO: epoch 001:  19375 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=19350, lr=4.72943e-05, gnorm=0.91, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=93998
2022-10-19 21:32:29 - progress_bar.py[line:274] - INFO: epoch 001:  19385 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.5, ups=0.93, wpb=109.5, bsz=40, num_updates=19360, lr=4.73188e-05, gnorm=0.857, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94008
2022-10-19 21:32:40 - progress_bar.py[line:274] - INFO: epoch 001:  19395 / 102288 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=19370, lr=4.73432e-05, gnorm=0.966, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94020
2022-10-19 21:32:52 - progress_bar.py[line:274] - INFO: epoch 001:  19405 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.8, ups=0.88, wpb=109.3, bsz=40, num_updates=19380, lr=4.73676e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94031
2022-10-19 21:33:02 - progress_bar.py[line:274] - INFO: epoch 001:  19415 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.7, ups=0.93, wpb=109.3, bsz=40, num_updates=19390, lr=4.73921e-05, gnorm=0.913, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94042
2022-10-19 21:33:14 - progress_bar.py[line:274] - INFO: epoch 001:  19425 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=19400, lr=4.74165e-05, gnorm=0.981, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94053
2022-10-19 21:33:25 - progress_bar.py[line:274] - INFO: epoch 001:  19435 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=19410, lr=4.7441e-05, gnorm=1.025, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94065
2022-10-19 21:33:37 - progress_bar.py[line:274] - INFO: epoch 001:  19445 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.5, ups=0.88, wpb=108.8, bsz=40, num_updates=19420, lr=4.74654e-05, gnorm=1.009, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=94076
2022-10-19 21:33:47 - progress_bar.py[line:274] - INFO: epoch 001:  19455 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.6, ups=0.92, wpb=111, bsz=40, num_updates=19430, lr=4.74899e-05, gnorm=0.891, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94087
2022-10-19 21:33:59 - progress_bar.py[line:274] - INFO: epoch 001:  19465 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.7, ups=0.9, wpb=109.4, bsz=40, num_updates=19440, lr=4.75143e-05, gnorm=0.864, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94098
2022-10-19 21:34:10 - progress_bar.py[line:274] - INFO: epoch 001:  19475 / 102288 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=19450, lr=4.75387e-05, gnorm=1.007, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94110
2022-10-19 21:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  19485 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=19460, lr=4.75632e-05, gnorm=0.928, clip=20, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94121
2022-10-19 21:34:25 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-19 21:34:34 - progress_bar.py[line:274] - INFO: epoch 001:  19496 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=88.7, ups=0.81, wpb=109.8, bsz=40, num_updates=19470, lr=4.75876e-05, gnorm=1.021, clip=50, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=94133
2022-10-19 21:34:45 - progress_bar.py[line:274] - INFO: epoch 001:  19506 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=19480, lr=4.76121e-05, gnorm=0.883, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94144
2022-10-19 21:34:56 - progress_bar.py[line:274] - INFO: epoch 001:  19516 / 102288 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.6, ups=0.88, wpb=108.8, bsz=40, num_updates=19490, lr=4.76365e-05, gnorm=0.909, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94156
2022-10-19 21:35:07 - progress_bar.py[line:274] - INFO: epoch 001:  19526 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.7, ups=0.88, wpb=111.9, bsz=40, num_updates=19500, lr=4.76609e-05, gnorm=0.912, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94167
2022-10-19 21:35:19 - progress_bar.py[line:274] - INFO: epoch 001:  19536 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=19510, lr=4.76854e-05, gnorm=0.908, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94179
2022-10-19 21:35:30 - progress_bar.py[line:274] - INFO: epoch 001:  19546 / 102288 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=94.2, ups=0.87, wpb=108.4, bsz=40, num_updates=19520, lr=4.77098e-05, gnorm=0.884, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94190
2022-10-19 21:35:42 - progress_bar.py[line:274] - INFO: epoch 001:  19556 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.3, ups=0.9, wpb=109.4, bsz=40, num_updates=19530, lr=4.77343e-05, gnorm=0.945, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94201
2022-10-19 21:35:52 - progress_bar.py[line:274] - INFO: epoch 001:  19566 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.5, ups=0.92, wpb=109.8, bsz=40, num_updates=19540, lr=4.77587e-05, gnorm=0.966, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=94212
2022-10-19 21:36:04 - progress_bar.py[line:274] - INFO: epoch 001:  19576 / 102288 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.5, ups=0.87, wpb=110, bsz=40, num_updates=19550, lr=4.77832e-05, gnorm=0.88, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94224
2022-10-19 21:36:15 - progress_bar.py[line:274] - INFO: epoch 001:  19586 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.3, ups=0.92, wpb=110.6, bsz=40, num_updates=19560, lr=4.78076e-05, gnorm=0.705, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94235
2022-10-19 21:36:26 - progress_bar.py[line:274] - INFO: epoch 001:  19596 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=19570, lr=4.7832e-05, gnorm=0.813, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94246
2022-10-19 21:36:37 - progress_bar.py[line:274] - INFO: epoch 001:  19606 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=103.5, ups=0.94, wpb=110.1, bsz=40, num_updates=19580, lr=4.78565e-05, gnorm=1.027, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94256
2022-10-19 21:36:47 - progress_bar.py[line:274] - INFO: epoch 001:  19616 / 102288 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.6, ups=0.91, wpb=108.9, bsz=40, num_updates=19590, lr=4.78809e-05, gnorm=0.981, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=94267
2022-10-19 21:36:59 - progress_bar.py[line:274] - INFO: epoch 001:  19626 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.89, wpb=109.4, bsz=40, num_updates=19600, lr=4.79054e-05, gnorm=0.935, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=94279
2022-10-19 21:37:10 - progress_bar.py[line:274] - INFO: epoch 001:  19636 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.5, ups=0.9, wpb=109.2, bsz=40, num_updates=19610, lr=4.79298e-05, gnorm=0.99, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94290
2022-10-19 21:37:21 - progress_bar.py[line:274] - INFO: epoch 001:  19646 / 102288 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.8, ups=0.88, wpb=109, bsz=40, num_updates=19620, lr=4.79542e-05, gnorm=0.859, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94301
2022-10-19 21:37:32 - progress_bar.py[line:274] - INFO: epoch 001:  19656 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=19630, lr=4.79787e-05, gnorm=0.959, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94312
2022-10-19 21:37:44 - progress_bar.py[line:274] - INFO: epoch 001:  19666 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.89, wpb=111.8, bsz=40, num_updates=19640, lr=4.80031e-05, gnorm=0.843, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=94323
2022-10-19 21:37:55 - progress_bar.py[line:274] - INFO: epoch 001:  19676 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=19650, lr=4.80276e-05, gnorm=0.887, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94334
2022-10-19 21:38:06 - progress_bar.py[line:274] - INFO: epoch 001:  19686 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.4, ups=0.88, wpb=110.9, bsz=40, num_updates=19660, lr=4.8052e-05, gnorm=0.907, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=94346
2022-10-19 21:38:17 - progress_bar.py[line:274] - INFO: epoch 001:  19696 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.3, ups=0.9, wpb=111.1, bsz=40, num_updates=19670, lr=4.80765e-05, gnorm=0.905, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94357
2022-10-19 21:38:29 - progress_bar.py[line:274] - INFO: epoch 001:  19706 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97, ups=0.88, wpb=110.6, bsz=40, num_updates=19680, lr=4.81009e-05, gnorm=0.917, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94368
2022-10-19 21:38:40 - progress_bar.py[line:274] - INFO: epoch 001:  19716 / 102288 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.3, ups=0.88, wpb=110.6, bsz=40, num_updates=19690, lr=4.81253e-05, gnorm=0.805, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94380
2022-10-19 21:38:51 - progress_bar.py[line:274] - INFO: epoch 001:  19726 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.9, ups=0.93, wpb=110.6, bsz=40, num_updates=19700, lr=4.81498e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=94391
2022-10-19 21:39:02 - progress_bar.py[line:274] - INFO: epoch 001:  19736 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.4, ups=0.87, wpb=109.2, bsz=40, num_updates=19710, lr=4.81742e-05, gnorm=0.945, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94402
2022-10-19 21:39:13 - progress_bar.py[line:274] - INFO: epoch 001:  19746 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.6, ups=0.91, wpb=109.9, bsz=40, num_updates=19720, lr=4.81987e-05, gnorm=0.883, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94413
2022-10-19 21:39:25 - progress_bar.py[line:274] - INFO: epoch 001:  19756 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=19730, lr=4.82231e-05, gnorm=1.029, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=94425
2022-10-19 21:39:36 - progress_bar.py[line:274] - INFO: epoch 001:  19766 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.2, ups=0.88, wpb=109.7, bsz=40, num_updates=19740, lr=4.82475e-05, gnorm=1.043, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94436
2022-10-19 21:39:48 - progress_bar.py[line:274] - INFO: epoch 001:  19776 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=19750, lr=4.8272e-05, gnorm=0.902, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94447
2022-10-19 21:39:59 - progress_bar.py[line:274] - INFO: epoch 001:  19786 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.7, ups=0.88, wpb=109.4, bsz=40, num_updates=19760, lr=4.82964e-05, gnorm=0.868, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94459
2022-10-19 21:40:10 - progress_bar.py[line:274] - INFO: epoch 001:  19796 / 102288 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.1, ups=0.92, wpb=110.3, bsz=40, num_updates=19770, lr=4.83209e-05, gnorm=0.882, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94470
2022-10-19 21:40:21 - progress_bar.py[line:274] - INFO: epoch 001:  19806 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=19780, lr=4.83453e-05, gnorm=0.976, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94481
2022-10-19 21:40:32 - progress_bar.py[line:274] - INFO: epoch 001:  19816 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=19790, lr=4.83698e-05, gnorm=0.965, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94492
2022-10-19 21:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  19826 / 102288 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.7, ups=0.93, wpb=110.6, bsz=40, num_updates=19800, lr=4.83942e-05, gnorm=0.879, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94503
2022-10-19 21:40:54 - progress_bar.py[line:274] - INFO: epoch 001:  19836 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.5, ups=0.88, wpb=112.2, bsz=40, num_updates=19810, lr=4.84186e-05, gnorm=0.94, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94514
2022-10-19 21:41:06 - progress_bar.py[line:274] - INFO: epoch 001:  19846 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.7, ups=0.88, wpb=109, bsz=40, num_updates=19820, lr=4.84431e-05, gnorm=0.836, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94526
2022-10-19 21:41:17 - progress_bar.py[line:274] - INFO: epoch 001:  19856 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=19830, lr=4.84675e-05, gnorm=1.026, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94537
2022-10-19 21:41:28 - progress_bar.py[line:274] - INFO: epoch 001:  19866 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.2, ups=0.9, wpb=108.8, bsz=40, num_updates=19840, lr=4.8492e-05, gnorm=0.923, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94548
2022-10-19 21:41:39 - progress_bar.py[line:274] - INFO: epoch 001:  19876 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=19850, lr=4.85164e-05, gnorm=0.897, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94559
2022-10-19 21:41:50 - progress_bar.py[line:274] - INFO: epoch 001:  19886 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=19860, lr=4.85408e-05, gnorm=0.918, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=94570
2022-10-19 21:42:01 - progress_bar.py[line:274] - INFO: epoch 001:  19896 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.7, ups=0.9, wpb=111.5, bsz=40, num_updates=19870, lr=4.85653e-05, gnorm=1.074, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94581
2022-10-19 21:42:12 - progress_bar.py[line:274] - INFO: epoch 001:  19906 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.1, ups=0.93, wpb=109, bsz=40, num_updates=19880, lr=4.85897e-05, gnorm=1.017, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=94592
2022-10-19 21:42:23 - progress_bar.py[line:274] - INFO: epoch 001:  19916 / 102288 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=104.2, ups=0.94, wpb=111, bsz=40, num_updates=19890, lr=4.86142e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94603
2022-10-19 21:42:34 - progress_bar.py[line:274] - INFO: epoch 001:  19926 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=19900, lr=4.86386e-05, gnorm=1.064, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94614
2022-10-19 21:42:46 - progress_bar.py[line:274] - INFO: epoch 001:  19936 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.89, wpb=110.8, bsz=40, num_updates=19910, lr=4.8663e-05, gnorm=0.912, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94625
2022-10-19 21:42:57 - progress_bar.py[line:274] - INFO: epoch 001:  19946 / 102288 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=102.7, ups=0.92, wpb=111.7, bsz=40, num_updates=19920, lr=4.86875e-05, gnorm=0.968, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94636
2022-10-19 21:43:08 - progress_bar.py[line:274] - INFO: epoch 001:  19956 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.1, ups=0.87, wpb=109.5, bsz=40, num_updates=19930, lr=4.87119e-05, gnorm=1.022, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=94648
2022-10-19 21:43:19 - progress_bar.py[line:274] - INFO: epoch 001:  19966 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.7, ups=0.9, wpb=111.3, bsz=40, num_updates=19940, lr=4.87364e-05, gnorm=0.951, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94659
2022-10-19 21:43:30 - progress_bar.py[line:274] - INFO: epoch 001:  19976 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.2, ups=0.9, wpb=110, bsz=40, num_updates=19950, lr=4.87608e-05, gnorm=1.057, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94670
2022-10-19 21:43:42 - progress_bar.py[line:274] - INFO: epoch 001:  19986 / 102288 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=19960, lr=4.87853e-05, gnorm=1.072, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=94681
2022-10-19 21:43:53 - progress_bar.py[line:274] - INFO: epoch 001:  19996 / 102288 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=19970, lr=4.88097e-05, gnorm=0.813, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94692
2022-10-19 21:44:04 - progress_bar.py[line:274] - INFO: epoch 001:  20006 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.4, ups=0.87, wpb=109.2, bsz=40, num_updates=19980, lr=4.88341e-05, gnorm=0.926, clip=30, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=94704
2022-10-19 21:44:08 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-19 21:44:16 - progress_bar.py[line:274] - INFO: epoch 001:  20017 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=91.4, ups=0.83, wpb=110.8, bsz=40, num_updates=19990, lr=4.88586e-05, gnorm=0.855, clip=20, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=94716
2022-10-19 21:44:28 - progress_bar.py[line:274] - INFO: epoch 001:  20027 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.5, ups=0.88, wpb=109.7, bsz=40, num_updates=20000, lr=4.8883e-05, gnorm=0.945, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=94727
2022-10-19 21:44:28 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 21:44:29 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 21:44:29 - train.py[line:551] - INFO: load:1.02 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 21:47:03 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 21:47:03 - train.py[line:551] - INFO: load:1.05 valid_run:153.91 task_valid:149.27 collect_output:3.44
2022-10-19 21:49:33 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 21:49:33 - train.py[line:551] - INFO: load:1.07 valid_run:303.74 task_valid:292.76 collect_output:8.55
2022-10-19 21:52:06 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 21:52:06 - train.py[line:551] - INFO: load:1.10 valid_run:456.67 task_valid:436.03 collect_output:17.16
2022-10-19 21:54:36 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 21:54:36 - train.py[line:551] - INFO: load:1.12 valid_run:606.27 task_valid:581.29 collect_output:20.44
2022-10-19 21:57:09 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 21:57:09 - train.py[line:551] - INFO: load:1.15 valid_run:759.25 task_valid:729.07 collect_output:24.59
2022-10-19 21:59:41 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 21:59:41 - train.py[line:551] - INFO: load:1.17 valid_run:911.98 task_valid:875.13 collect_output:30.16
2022-10-19 22:02:16 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 22:02:16 - train.py[line:551] - INFO: load:1.20 valid_run:1066.47 task_valid:1021.80 collect_output:36.86
2022-10-19 22:04:48 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 22:04:48 - train.py[line:551] - INFO: load:1.22 valid_run:1218.61 task_valid:1163.29 collect_output:46.43
2022-10-19 22:07:19 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 22:07:19 - train.py[line:551] - INFO: load:1.25 valid_run:1368.95 task_valid:1308.46 collect_output:50.53
2022-10-19 22:09:48 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 22:09:48 - train.py[line:551] - INFO: load:1.27 valid_run:1518.19 task_valid:1451.95 collect_output:55.22
2022-10-19 22:12:19 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 22:12:19 - train.py[line:551] - INFO: load:1.30 valid_run:1668.81 task_valid:1597.18 collect_output:59.51
2022-10-19 22:14:49 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 22:14:49 - train.py[line:551] - INFO: load:1.32 valid_run:1819.25 task_valid:1742.28 collect_output:63.77
2022-10-19 22:17:20 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 22:17:20 - train.py[line:551] - INFO: load:1.35 valid_run:1969.95 task_valid:1884.44 collect_output:71.24
2022-10-19 22:19:51 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 22:19:51 - train.py[line:551] - INFO: load:1.37 valid_run:2120.83 task_valid:2030.19 collect_output:75.32
2022-10-19 22:22:21 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 22:22:21 - train.py[line:551] - INFO: load:1.40 valid_run:2271.26 task_valid:2176.69 collect_output:78.21
2022-10-19 22:24:51 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 22:24:51 - train.py[line:551] - INFO: load:1.42 valid_run:2421.38 task_valid:2320.78 collect_output:83.27
2022-10-19 22:27:24 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 22:27:24 - train.py[line:551] - INFO: load:1.45 valid_run:2573.47 task_valid:2466.24 collect_output:88.87
2022-10-19 22:29:55 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 22:29:55 - train.py[line:551] - INFO: load:1.47 valid_run:2724.49 task_valid:2613.39 collect_output:91.74
2022-10-19 22:32:24 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 22:32:24 - train.py[line:551] - INFO: load:1.50 valid_run:2873.46 task_valid:2755.10 collect_output:97.97
2022-10-19 22:34:54 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 22:34:54 - train.py[line:551] - INFO: load:1.53 valid_run:3024.22 task_valid:2900.25 collect_output:102.57
2022-10-19 22:37:27 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 22:37:28 - train.py[line:551] - INFO: load:1.55 valid_run:3177.19 task_valid:3045.06 collect_output:109.67
2022-10-19 22:39:59 - train.py[line:549] - INFO: 4400 / 4988
2022-10-19 22:39:59 - train.py[line:551] - INFO: load:1.58 valid_run:3328.45 task_valid:3190.98 collect_output:113.79
2022-10-19 22:42:31 - train.py[line:549] - INFO: 4600 / 4988
2022-10-19 22:42:31 - train.py[line:551] - INFO: load:1.60 valid_run:3480.12 task_valid:3337.24 collect_output:118.15
2022-10-19 22:45:03 - train.py[line:549] - INFO: 4800 / 4988
2022-10-19 22:45:03 - train.py[line:551] - INFO: load:1.63 valid_run:3632.05 task_valid:3483.87 collect_output:122.46

====================================================================================================
SGG eval:     R @ 50: 0.5172;     R @ 100: 0.5483;     R @ 500: 0.5823;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3523;    mR @ 100: 0.3802;    mR @ 500: 0.4174;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.7500) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.2500) (hanging from:0.4355) (lying on:0.1833) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8438) (playing:0.0000) (riding:0.8088) (says:0.0000) (sitting on:0.6667) (standing on:0.1870) (using:0.6500) (walking in:0.0000) (walking on:0.6261) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5172;     R @ 100: 0.5483;     R @ 500: 0.5823;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3523;    mR @ 100: 0.3802;    mR @ 500: 0.4174;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.7500) (covering:0.3714) (eating:0.5588) (flying in:0.5000) (growing on:0.2500) (hanging from:0.4355) (lying on:0.1833) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8438) (playing:0.0000) (riding:0.8088) (says:0.0000) (sitting on:0.6667) (standing on:0.1870) (using:0.6500) (walking in:0.0000) (walking on:0.6261) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2022-10-19 22:47:34 - train.py[line:487] - INFO: 0.5483305322128852
2022-10-19 22:47:34 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-19 22:47:34 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.371 | loss_v1 0 | loss_v2 0 | nll_loss 0.22 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.548331 | ppl 1.17 | vqa_score 0.4932 | wps 118.5 | wpb 89.9 | bsz 30 | num_updates 20000 | best_R@100 0.593911
2022-10-19 22:47:34 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 20000 updates
2022-10-19 22:47:34 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_20000.pt
2022-10-19 22:47:40 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_20000.pt
2022-10-19 22:47:43 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_BERT_v1_data/1_B20_A1_E5_0.04_5e-5_480/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score 0.5483305322128852) (writing took 8.42492858786136 seconds)
2022-10-19 22:47:54 - progress_bar.py[line:274] - INFO: epoch 001:  20037 / 102288 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=0.3, ups=0, wpb=109.3, bsz=40, num_updates=20010, lr=4.89075e-05, gnorm=1.009, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98534
2022-10-19 22:48:05 - progress_bar.py[line:274] - INFO: epoch 001:  20047 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.9, ups=0.89, wpb=110.1, bsz=40, num_updates=20020, lr=4.89319e-05, gnorm=1.074, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98545
2022-10-19 22:48:17 - progress_bar.py[line:274] - INFO: epoch 001:  20057 / 102288 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=20030, lr=4.89563e-05, gnorm=1.09, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98556
2022-10-19 22:48:28 - progress_bar.py[line:274] - INFO: epoch 001:  20067 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=20040, lr=4.89808e-05, gnorm=0.932, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98567
2022-10-19 22:48:39 - progress_bar.py[line:274] - INFO: epoch 001:  20077 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=20050, lr=4.90052e-05, gnorm=0.908, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98579
2022-10-19 22:48:50 - progress_bar.py[line:274] - INFO: epoch 001:  20087 / 102288 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=102.7, ups=0.92, wpb=111.9, bsz=40, num_updates=20060, lr=4.90297e-05, gnorm=0.894, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98590
2022-10-19 22:49:01 - progress_bar.py[line:274] - INFO: epoch 001:  20097 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=20070, lr=4.90541e-05, gnorm=0.918, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98601
2022-10-19 22:49:12 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 22:49:13 - progress_bar.py[line:274] - INFO: epoch 001:  20108 / 102288 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=93.4, ups=0.84, wpb=110.6, bsz=40, num_updates=20080, lr=4.90786e-05, gnorm=0.941, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=98613
2022-10-19 22:49:24 - progress_bar.py[line:274] - INFO: epoch 001:  20118 / 102288 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=20090, lr=4.9103e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98624
2022-10-19 22:49:35 - progress_bar.py[line:274] - INFO: epoch 001:  20128 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.9, wpb=110.4, bsz=40, num_updates=20100, lr=4.91274e-05, gnorm=0.962, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98635
2022-10-19 22:49:46 - progress_bar.py[line:274] - INFO: epoch 001:  20138 / 102288 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=20110, lr=4.91519e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98646
2022-10-19 22:49:58 - progress_bar.py[line:274] - INFO: epoch 001:  20148 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=20120, lr=4.91763e-05, gnorm=0.917, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98657
2022-10-19 22:50:09 - progress_bar.py[line:274] - INFO: epoch 001:  20158 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=20130, lr=4.92008e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98669
2022-10-19 22:50:20 - progress_bar.py[line:274] - INFO: epoch 001:  20168 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=20140, lr=4.92252e-05, gnorm=0.922, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98680
2022-10-19 22:50:32 - progress_bar.py[line:274] - INFO: epoch 001:  20178 / 102288 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.3, ups=0.86, wpb=112.2, bsz=40, num_updates=20150, lr=4.92496e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=98692
2022-10-19 22:50:43 - progress_bar.py[line:274] - INFO: epoch 001:  20188 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.5, ups=0.88, wpb=109.6, bsz=40, num_updates=20160, lr=4.92741e-05, gnorm=0.929, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=98703
2022-10-19 22:50:54 - progress_bar.py[line:274] - INFO: epoch 001:  20198 / 102288 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.3, ups=0.92, wpb=110.7, bsz=40, num_updates=20170, lr=4.92985e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=98714
2022-10-19 22:51:05 - progress_bar.py[line:274] - INFO: epoch 001:  20208 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=20180, lr=4.9323e-05, gnorm=0.993, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98725
2022-10-19 22:51:17 - progress_bar.py[line:274] - INFO: epoch 001:  20218 / 102288 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.7, ups=0.87, wpb=109.3, bsz=40, num_updates=20190, lr=4.93474e-05, gnorm=1.064, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=98737
2022-10-19 22:51:28 - progress_bar.py[line:274] - INFO: epoch 001:  20228 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=20200, lr=4.93719e-05, gnorm=0.973, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98748
2022-10-19 22:51:40 - progress_bar.py[line:274] - INFO: epoch 001:  20238 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=20210, lr=4.93963e-05, gnorm=0.936, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98759
2022-10-19 22:51:51 - progress_bar.py[line:274] - INFO: epoch 001:  20248 / 102288 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.8, ups=0.9, wpb=109.2, bsz=40, num_updates=20220, lr=4.94207e-05, gnorm=0.94, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98770
2022-10-19 22:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  20258 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.6, ups=0.92, wpb=110.4, bsz=40, num_updates=20230, lr=4.94452e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=98781
2022-10-19 22:52:13 - progress_bar.py[line:274] - INFO: epoch 001:  20268 / 102288 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=20240, lr=4.94696e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=98793
2022-10-19 22:52:24 - progress_bar.py[line:274] - INFO: epoch 001:  20278 / 102288 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.2, ups=0.91, wpb=109.4, bsz=40, num_updates=20250, lr=4.94941e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98804
2022-10-19 22:52:35 - progress_bar.py[line:274] - INFO: epoch 001:  20288 / 102288 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98, ups=0.9, wpb=108.6, bsz=40, num_updates=20260, lr=4.95185e-05, gnorm=0.936, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98815
2022-10-19 22:52:46 - progress_bar.py[line:274] - INFO: epoch 001:  20298 / 102288 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=20270, lr=4.95429e-05, gnorm=0.901, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98826
2022-10-19 22:52:58 - progress_bar.py[line:274] - INFO: epoch 001:  20308 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=20280, lr=4.95674e-05, gnorm=0.92, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98837
2022-10-19 22:53:09 - progress_bar.py[line:274] - INFO: epoch 001:  20318 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=20290, lr=4.95918e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98849
2022-10-19 22:53:21 - progress_bar.py[line:274] - INFO: epoch 001:  20328 / 102288 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.5, ups=0.88, wpb=110, bsz=40, num_updates=20300, lr=4.96163e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98860
2022-10-19 22:53:32 - progress_bar.py[line:274] - INFO: epoch 001:  20338 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.4, ups=0.9, wpb=109.1, bsz=40, num_updates=20310, lr=4.96407e-05, gnorm=0.912, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=98872
2022-10-19 22:53:43 - progress_bar.py[line:274] - INFO: epoch 001:  20348 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.5, ups=0.9, wpb=109, bsz=40, num_updates=20320, lr=4.96652e-05, gnorm=0.938, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=98883
2022-10-19 22:53:54 - progress_bar.py[line:274] - INFO: epoch 001:  20358 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.9, ups=0.92, wpb=109, bsz=40, num_updates=20330, lr=4.96896e-05, gnorm=1.107, clip=70, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=98894
2022-10-19 22:54:05 - progress_bar.py[line:274] - INFO: epoch 001:  20368 / 102288 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.7, ups=0.92, wpb=110.4, bsz=40, num_updates=20340, lr=4.9714e-05, gnorm=1.048, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98904
2022-10-19 22:54:16 - progress_bar.py[line:274] - INFO: epoch 001:  20378 / 102288 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.9, ups=0.88, wpb=109.1, bsz=40, num_updates=20350, lr=4.97385e-05, gnorm=0.909, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98916
2022-10-19 22:54:27 - progress_bar.py[line:274] - INFO: epoch 001:  20388 / 102288 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=20360, lr=4.97629e-05, gnorm=0.758, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=98927
2022-10-19 22:54:38 - progress_bar.py[line:274] - INFO: epoch 001:  20398 / 102288 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.5, ups=0.92, wpb=109.4, bsz=40, num_updates=20370, lr=4.97874e-05, gnorm=0.926, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=98938
2022-10-19 22:54:50 - progress_bar.py[line:274] - INFO: epoch 001:  20408 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.8, ups=0.87, wpb=111.3, bsz=40, num_updates=20380, lr=4.98118e-05, gnorm=0.97, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98949
2022-10-19 22:55:01 - progress_bar.py[line:274] - INFO: epoch 001:  20418 / 102288 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.1, ups=0.9, wpb=112, bsz=40, num_updates=20390, lr=4.98362e-05, gnorm=0.862, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=98961
2022-10-19 22:55:12 - progress_bar.py[line:274] - INFO: epoch 001:  20428 / 102288 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=20400, lr=4.98607e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98972
2022-10-19 22:55:23 - progress_bar.py[line:274] - INFO: epoch 001:  20438 / 102288 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=20410, lr=4.98851e-05, gnorm=0.914, clip=40, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=98983
2022-10-19 22:55:34 - progress_bar.py[line:274] - INFO: epoch 001:  20448 / 102288 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.89, wpb=108.8, bsz=40, num_updates=20420, lr=4.99096e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98994
2022-10-19 22:55:46 - progress_bar.py[line:274] - INFO: epoch 001:  20458 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.5, ups=0.88, wpb=110.7, bsz=40, num_updates=20430, lr=4.9934e-05, gnorm=0.917, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=99006
2022-10-19 22:55:57 - progress_bar.py[line:274] - INFO: epoch 001:  20468 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.6, ups=0.9, wpb=111.6, bsz=40, num_updates=20440, lr=4.99584e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99017
2022-10-19 22:56:08 - progress_bar.py[line:274] - INFO: epoch 001:  20478 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.4, ups=0.9, wpb=109.3, bsz=40, num_updates=20450, lr=4.99829e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99028
2022-10-19 22:56:19 - progress_bar.py[line:274] - INFO: epoch 001:  20488 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=20460, lr=4.99997e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99039
2022-10-19 22:56:31 - progress_bar.py[line:274] - INFO: epoch 001:  20498 / 102288 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.6, ups=0.88, wpb=108.6, bsz=40, num_updates=20470, lr=4.99987e-05, gnorm=1.049, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99050
2022-10-19 22:56:42 - progress_bar.py[line:274] - INFO: epoch 001:  20508 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=20480, lr=4.99977e-05, gnorm=0.811, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99062
2022-10-19 22:56:53 - progress_bar.py[line:274] - INFO: epoch 001:  20518 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.9, ups=0.92, wpb=110.6, bsz=40, num_updates=20490, lr=4.99966e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99073
2022-10-19 22:57:04 - progress_bar.py[line:274] - INFO: epoch 001:  20528 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.2, ups=0.89, wpb=110.8, bsz=40, num_updates=20500, lr=4.99956e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99084
2022-10-19 22:57:15 - progress_bar.py[line:274] - INFO: epoch 001:  20538 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.4, ups=0.93, wpb=110.4, bsz=40, num_updates=20510, lr=4.99946e-05, gnorm=0.967, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=99095
2022-10-19 22:57:26 - progress_bar.py[line:274] - INFO: epoch 001:  20548 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=20520, lr=4.99936e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99106
2022-10-19 22:57:38 - progress_bar.py[line:274] - INFO: epoch 001:  20558 / 102288 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.3, ups=0.88, wpb=110, bsz=40, num_updates=20530, lr=4.99926e-05, gnorm=0.929, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99118
2022-10-19 22:57:49 - progress_bar.py[line:274] - INFO: epoch 001:  20568 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=20540, lr=4.99915e-05, gnorm=0.931, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99129
2022-10-19 22:58:00 - progress_bar.py[line:274] - INFO: epoch 001:  20578 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.6, ups=0.9, wpb=111, bsz=40, num_updates=20550, lr=4.99905e-05, gnorm=0.984, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99140
2022-10-19 22:58:12 - progress_bar.py[line:274] - INFO: epoch 001:  20588 / 102288 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=20560, lr=4.99895e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99151
2022-10-19 22:58:23 - progress_bar.py[line:274] - INFO: epoch 001:  20598 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.9, ups=0.9, wpb=109, bsz=40, num_updates=20570, lr=4.99885e-05, gnorm=0.911, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99163
2022-10-19 22:58:34 - progress_bar.py[line:274] - INFO: epoch 001:  20608 / 102288 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.7, ups=0.88, wpb=109.3, bsz=40, num_updates=20580, lr=4.99875e-05, gnorm=1.075, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99174
2022-10-19 22:58:46 - progress_bar.py[line:274] - INFO: epoch 001:  20618 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.4, ups=0.87, wpb=109.5, bsz=40, num_updates=20590, lr=4.99865e-05, gnorm=1.035, clip=70, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=99186
2022-10-19 22:58:57 - progress_bar.py[line:274] - INFO: epoch 001:  20628 / 102288 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.2, ups=0.9, wpb=111.4, bsz=40, num_updates=20600, lr=4.99854e-05, gnorm=0.894, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99197
2022-10-19 22:59:08 - progress_bar.py[line:274] - INFO: epoch 001:  20638 / 102288 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98, ups=0.89, wpb=110.2, bsz=40, num_updates=20610, lr=4.99844e-05, gnorm=0.971, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99208
2022-10-19 22:59:20 - progress_bar.py[line:274] - INFO: epoch 001:  20648 / 102288 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.1, ups=0.88, wpb=110.6, bsz=40, num_updates=20620, lr=4.99834e-05, gnorm=1.022, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99219
2022-10-19 22:59:31 - progress_bar.py[line:274] - INFO: epoch 001:  20658 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.6, ups=0.9, wpb=110.1, bsz=40, num_updates=20630, lr=4.99824e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=99231
2022-10-19 22:59:42 - progress_bar.py[line:274] - INFO: epoch 001:  20668 / 102288 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.2, ups=0.87, wpb=110.4, bsz=40, num_updates=20640, lr=4.99814e-05, gnorm=0.937, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99242
2022-10-19 22:59:54 - progress_bar.py[line:274] - INFO: epoch 001:  20678 / 102288 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.7, ups=0.91, wpb=109.1, bsz=40, num_updates=20650, lr=4.99803e-05, gnorm=0.981, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99253
2022-10-19 23:00:04 - progress_bar.py[line:274] - INFO: epoch 001:  20688 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.4, ups=0.93, wpb=110.7, bsz=40, num_updates=20660, lr=4.99793e-05, gnorm=0.944, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99264
2022-10-19 23:00:16 - progress_bar.py[line:274] - INFO: epoch 001:  20698 / 102288 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=20670, lr=4.99783e-05, gnorm=0.912, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99275
2022-10-19 23:00:27 - progress_bar.py[line:274] - INFO: epoch 001:  20708 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.8, ups=0.93, wpb=109.9, bsz=40, num_updates=20680, lr=4.99773e-05, gnorm=1.007, clip=50, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=99286
2022-10-19 23:00:38 - progress_bar.py[line:274] - INFO: epoch 001:  20718 / 102288 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.2, ups=0.88, wpb=109.4, bsz=40, num_updates=20690, lr=4.99763e-05, gnorm=0.838, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99298
2022-10-19 23:00:50 - progress_bar.py[line:274] - INFO: epoch 001:  20728 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.1, ups=0.86, wpb=110.3, bsz=40, num_updates=20700, lr=4.99753e-05, gnorm=0.933, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=99309
2022-10-19 23:01:01 - progress_bar.py[line:274] - INFO: epoch 001:  20738 / 102288 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.2, ups=0.88, wpb=109.4, bsz=40, num_updates=20710, lr=4.99742e-05, gnorm=1.053, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99321
2022-10-19 23:01:12 - progress_bar.py[line:274] - INFO: epoch 001:  20748 / 102288 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.2, ups=0.91, wpb=109.8, bsz=40, num_updates=20720, lr=4.99732e-05, gnorm=0.959, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99332
2022-10-19 23:01:23 - progress_bar.py[line:274] - INFO: epoch 001:  20758 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.3, ups=0.91, wpb=109.9, bsz=40, num_updates=20730, lr=4.99722e-05, gnorm=1.173, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99343
2022-10-19 23:01:34 - progress_bar.py[line:274] - INFO: epoch 001:  20768 / 102288 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.3, ups=0.9, wpb=109.1, bsz=40, num_updates=20740, lr=4.99712e-05, gnorm=1.117, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99354
2022-10-19 23:01:46 - progress_bar.py[line:274] - INFO: epoch 001:  20778 / 102288 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.5, ups=0.88, wpb=111.1, bsz=40, num_updates=20750, lr=4.99702e-05, gnorm=0.959, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99365
2022-10-19 23:01:57 - progress_bar.py[line:274] - INFO: epoch 001:  20788 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=20760, lr=4.99691e-05, gnorm=0.951, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99377
2022-10-19 23:02:08 - progress_bar.py[line:274] - INFO: epoch 001:  20798 / 102288 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.5, ups=0.93, wpb=110.8, bsz=40, num_updates=20770, lr=4.99681e-05, gnorm=1.016, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99387
2022-10-19 23:02:19 - progress_bar.py[line:274] - INFO: epoch 001:  20808 / 102288 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100, ups=0.91, wpb=109.4, bsz=40, num_updates=20780, lr=4.99671e-05, gnorm=0.956, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99398
2022-10-19 23:02:30 - progress_bar.py[line:274] - INFO: epoch 001:  20818 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.8, ups=0.89, wpb=110.2, bsz=40, num_updates=20790, lr=4.99661e-05, gnorm=1.075, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99410
2022-10-19 23:02:41 - progress_bar.py[line:274] - INFO: epoch 001:  20828 / 102288 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.3, ups=0.88, wpb=110, bsz=40, num_updates=20800, lr=4.99651e-05, gnorm=0.869, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99421
2022-10-19 23:02:53 - progress_bar.py[line:274] - INFO: epoch 001:  20838 / 102288 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.89, wpb=109.7, bsz=40, num_updates=20810, lr=4.99641e-05, gnorm=0.972, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99432
2022-10-19 23:03:04 - progress_bar.py[line:274] - INFO: epoch 001:  20848 / 102288 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.8, ups=0.91, wpb=109.2, bsz=40, num_updates=20820, lr=4.9963e-05, gnorm=0.967, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99443
2022-10-19 23:03:15 - progress_bar.py[line:274] - INFO: epoch 001:  20858 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=20830, lr=4.9962e-05, gnorm=0.872, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99455
2022-10-19 23:03:26 - progress_bar.py[line:274] - INFO: epoch 001:  20868 / 102288 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=20840, lr=4.9961e-05, gnorm=1.02, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=99466
2022-10-19 23:03:37 - progress_bar.py[line:274] - INFO: epoch 001:  20878 / 102288 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=20850, lr=4.996e-05, gnorm=0.797, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99477
2022-10-19 23:03:49 - progress_bar.py[line:274] - INFO: epoch 001:  20888 / 102288 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.4, ups=0.89, wpb=111.5, bsz=40, num_updates=20860, lr=4.9959e-05, gnorm=0.865, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99488
2022-10-19 23:04:00 - progress_bar.py[line:274] - INFO: epoch 001:  20898 / 102288 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=20870, lr=4.99579e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99500
2022-10-19 23:04:11 - progress_bar.py[line:274] - INFO: epoch 001:  20908 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.8, ups=0.92, wpb=108.7, bsz=40, num_updates=20880, lr=4.99569e-05, gnorm=1.032, clip=50, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=99511
2022-10-19 23:04:22 - progress_bar.py[line:274] - INFO: epoch 001:  20918 / 102288 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=20890, lr=4.99559e-05, gnorm=1.234, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99522
2022-10-19 23:04:33 - progress_bar.py[line:274] - INFO: epoch 001:  20928 / 102288 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.7, ups=0.89, wpb=109.9, bsz=40, num_updates=20900, lr=4.99549e-05, gnorm=0.912, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99533
2022-10-19 23:04:44 - progress_bar.py[line:274] - INFO: epoch 001:  20938 / 102288 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.4, ups=0.89, wpb=108.9, bsz=40, num_updates=20910, lr=4.99539e-05, gnorm=0.964, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=99544
2022-10-19 23:04:56 - progress_bar.py[line:274] - INFO: epoch 001:  20948 / 102288 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=20920, lr=4.99528e-05, gnorm=1.029, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99555
2022-10-19 23:04:59 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-19 23:05:08 - progress_bar.py[line:274] - INFO: epoch 001:  20959 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.6, ups=0.81, wpb=109.8, bsz=40, num_updates=20930, lr=4.99518e-05, gnorm=0.869, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=99568
2022-10-19 23:05:20 - progress_bar.py[line:274] - INFO: epoch 001:  20969 / 102288 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=20940, lr=4.99508e-05, gnorm=0.938, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99579
2022-10-19 23:05:31 - progress_bar.py[line:274] - INFO: epoch 001:  20979 / 102288 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.2, ups=0.9, wpb=110.1, bsz=40, num_updates=20950, lr=4.99498e-05, gnorm=1.043, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=99590
2022-10-19 23:05:42 - progress_bar.py[line:274] - INFO: epoch 001:  20989 / 102288 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.4, ups=0.89, wpb=109.6, bsz=40, num_updates=20960, lr=4.99488e-05, gnorm=1.113, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99602
2022-10-19 23:05:53 - progress_bar.py[line:274] - INFO: epoch 001:  20999 / 102288 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100, ups=0.9, wpb=111.1, bsz=40, num_updates=20970, lr=4.99478e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=99613
2022-10-19 23:06:05 - progress_bar.py[line:274] - INFO: epoch 001:  21009 / 102288 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.7, ups=0.87, wpb=109.4, bsz=40, num_updates=20980, lr=4.99467e-05, gnorm=0.967, clip=50, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=99625
2022-10-19 23:06:16 - progress_bar.py[line:274] - INFO: epoch 001:  21019 / 102288 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.6, ups=0.93, wpb=110.8, bsz=40, num_updates=20990, lr=4.99457e-05, gnorm=0.823, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=99635
2022-10-19 23:06:27 - progress_bar.py[line:274] - INFO: epoch 001:  21029 / 102288 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.6, ups=0.89, wpb=110.1, bsz=40, num_updates=21000, lr=4.99447e-05, gnorm=1.075, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=99647
2022-10-19 23:06:27 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-19 23:06:28 - train.py[line:549] - INFO: 0 / 4988
2022-10-19 23:06:28 - train.py[line:551] - INFO: load:1.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-19 23:06:44 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.88 GiB already allocated; 1.57 GiB free; 35.54 GiB reserved in total by PyTorch)
2022-10-19 23:06:44 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9092 MB |   14323 MB |   14338 TB |   14338 TB |
|       from large pool |    8948 MB |   14178 MB |   14334 TB |   14334 TB |
|       from small pool |     144 MB |     145 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9092 MB |   14323 MB |   14338 TB |   14338 TB |
|       from large pool |    8948 MB |   14178 MB |   14334 TB |   14334 TB |
|       from small pool |     144 MB |     145 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36388 MB |   36656 MB |  147050 MB |  110662 MB |
|       from large pool |   36242 MB |   36504 MB |  146738 MB |  110496 MB |
|       from small pool |     146 MB |     152 MB |     312 MB |     166 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   27295 MB |   27295 MB |   14458 TB |   14458 TB |
|       from large pool |   27293 MB |   27293 MB |   14453 TB |   14453 TB |
|       from small pool |       1 MB |       2 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  668984 K  |  668981 K  |
|       from large pool |     563    |     575    |  214049 K  |  214048 K  |
|       from small pool |    3106    |    3116    |  454935 K  |  454932 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  668984 K  |  668981 K  |
|       from large pool |     563    |     575    |  214049 K  |  214048 K  |
|       from small pool |    3106    |    3116    |  454935 K  |  454932 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     148    |     153    |     485    |     337    |
|       from large pool |      75    |      77    |     329    |     254    |
|       from small pool |      73    |      76    |     156    |      83    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     104    |     118    |  476075 K  |  476074 K  |
|       from large pool |      69    |      72    |   79044 K  |   79044 K  |
|       from small pool |      35    |      51    |  397030 K  |  397030 K  |
|===========================================================================|

2022-10-19 23:06:44 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-19 23:06:44 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-19 23:09:02 - train.py[line:549] - INFO: 200 / 4988
2022-10-19 23:09:02 - train.py[line:551] - INFO: load:1.08 valid_run:153.08 task_valid:148.53 collect_output:2.62
2022-10-19 23:11:30 - train.py[line:549] - INFO: 400 / 4988
2022-10-19 23:11:30 - train.py[line:551] - INFO: load:1.11 valid_run:301.90 task_valid:291.68 collect_output:7.18
2022-10-19 23:14:04 - train.py[line:549] - INFO: 600 / 4988
2022-10-19 23:14:04 - train.py[line:551] - INFO: load:1.13 valid_run:455.10 task_valid:435.12 collect_output:15.82
2022-10-19 23:16:33 - train.py[line:549] - INFO: 800 / 4988
2022-10-19 23:16:33 - train.py[line:551] - INFO: load:1.16 valid_run:604.88 task_valid:580.27 collect_output:19.39
2022-10-19 23:19:07 - train.py[line:549] - INFO: 1000 / 4988
2022-10-19 23:19:07 - train.py[line:551] - INFO: load:1.18 valid_run:757.86 task_valid:728.11 collect_output:23.45
2022-10-19 23:21:39 - train.py[line:549] - INFO: 1200 / 4988
2022-10-19 23:21:39 - train.py[line:551] - INFO: load:1.21 valid_run:910.18 task_valid:873.94 collect_output:28.84
2022-10-19 23:24:13 - train.py[line:549] - INFO: 1400 / 4988
2022-10-19 23:24:13 - train.py[line:551] - INFO: load:1.24 valid_run:1064.26 task_valid:1020.25 collect_output:35.56
2022-10-19 23:26:45 - train.py[line:549] - INFO: 1600 / 4988
2022-10-19 23:26:45 - train.py[line:551] - INFO: load:1.26 valid_run:1216.27 task_valid:1161.58 collect_output:45.21
2022-10-19 23:29:16 - train.py[line:549] - INFO: 1800 / 4988
2022-10-19 23:29:16 - train.py[line:551] - INFO: load:1.29 valid_run:1367.13 task_valid:1306.96 collect_output:49.58
2022-10-19 23:31:53 - train.py[line:549] - INFO: 2000 / 4988
2022-10-19 23:31:53 - train.py[line:551] - INFO: load:1.32 valid_run:1523.52 task_valid:1457.12 collect_output:54.18
2022-10-19 23:34:23 - train.py[line:549] - INFO: 2200 / 4988
2022-10-19 23:34:23 - train.py[line:551] - INFO: load:1.35 valid_run:1673.78 task_valid:1602.27 collect_output:58.25
2022-10-19 23:36:53 - train.py[line:549] - INFO: 2400 / 4988
2022-10-19 23:36:53 - train.py[line:551] - INFO: load:1.38 valid_run:1824.18 task_valid:1747.31 collect_output:62.58
2022-10-19 23:39:24 - train.py[line:549] - INFO: 2600 / 4988
2022-10-19 23:39:24 - train.py[line:551] - INFO: load:1.40 valid_run:1974.77 task_valid:1889.39 collect_output:70.06
2022-10-19 23:41:55 - train.py[line:549] - INFO: 2800 / 4988
2022-10-19 23:41:55 - train.py[line:551] - INFO: load:1.43 valid_run:2125.54 task_valid:2034.95 collect_output:74.27
2022-10-19 23:44:25 - train.py[line:549] - INFO: 3000 / 4988
2022-10-19 23:44:25 - train.py[line:551] - INFO: load:1.45 valid_run:2275.59 task_valid:2181.13 collect_output:77.11
2022-10-19 23:46:55 - train.py[line:549] - INFO: 3200 / 4988
2022-10-19 23:46:55 - train.py[line:551] - INFO: load:1.48 valid_run:2425.84 task_valid:2325.28 collect_output:82.18
2022-10-19 23:49:27 - train.py[line:549] - INFO: 3400 / 4988
2022-10-19 23:49:27 - train.py[line:551] - INFO: load:1.51 valid_run:2578.08 task_valid:2470.55 collect_output:88.14
2022-10-19 23:51:58 - train.py[line:549] - INFO: 3600 / 4988
2022-10-19 23:51:58 - train.py[line:551] - INFO: load:1.53 valid_run:2728.78 task_valid:2617.39 collect_output:90.96
2022-10-19 23:54:28 - train.py[line:549] - INFO: 3800 / 4988
2022-10-19 23:54:28 - train.py[line:551] - INFO: load:1.56 valid_run:2878.19 task_valid:2759.48 collect_output:97.10
2022-10-19 23:57:05 - train.py[line:549] - INFO: 4000 / 4988
2022-10-19 23:57:05 - train.py[line:551] - INFO: load:1.59 valid_run:3035.78 task_valid:2909.40 collect_output:103.20
2022-10-19 23:59:38 - train.py[line:549] - INFO: 4200 / 4988
2022-10-19 23:59:38 - train.py[line:551] - INFO: load:1.61 valid_run:3188.55 task_valid:3054.00 collect_output:110.33
2022-10-20 00:02:08 - train.py[line:549] - INFO: 4400 / 4988
2022-10-20 00:02:08 - train.py[line:551] - INFO: load:1.64 valid_run:3338.18 task_valid:3198.58 collect_output:114.33
