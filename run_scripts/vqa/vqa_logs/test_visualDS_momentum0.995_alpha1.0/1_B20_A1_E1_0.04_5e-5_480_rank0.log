2023-01-06 14:49:12 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2023-01-06 14:49:12 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2023-01-06 14:49:12 - utils.py[line:261] - INFO: Start init
2023-01-06 14:49:12 - utils.py[line:261] - INFO: Start init
2023-01-06 14:49:12 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-01-06 14:49:12 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-01-06 14:49:12 - utils.py[line:274] - INFO: initialized host node4 as rank 0
2023-01-06 14:49:13 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
single-machine distributed training is initialized.
2023-01-06 14:49:18 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_visualDS_momentum0.995_alpha1.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 2000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=1, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480', save_interval=10, save_interval_updates=2000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_visualDS_momentum0.995_alpha1.0', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=2000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-01-06 14:49:18 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-01-06 14:49:18 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2023-01-06 14:49:23 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-01-06 14:49:23 - train.py[line:118] - INFO: task: VqaGenTask
2023-01-06 14:49:23 - train.py[line:119] - INFO: model: OFAModel
2023-01-06 14:49:23 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-01-06 14:49:23 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-01-06 14:49:23 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-01-06 14:49:23 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-01-06 14:49:23 - trainer.py[line:126] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-01-06 14:49:24 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-01-06 14:49:24 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-06 14:49:24 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2023-01-06 14:49:24 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
Done 0.995 cuda cpu, cpu
Done 0.995 cuda cpu, cpu
2023-01-06 14:49:25 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2023-01-06 14:49:25 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2023-01-06 14:49:25 - trainer.py[line:499] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2023-01-06 14:49:37 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-01-06 14:49:37 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-06 14:49:37 - trainer.py[line:645] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-01-06 14:49:38 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-01-06 14:49:38 - trainer.py[line:314] - INFO: Exponential Moving Average Shadow Model is initialized.
2023-01-06 14:49:38 - trainer.py[line:674] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2023-01-06 14:49:38 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 0 row count 2316893 total row count 4633786
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_train_NA1_E0.tsv slice_id 1 row count 2316893 total row count 4633786
2023-01-06 14:49:42 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 115845, warmup steps 4633, warmup_factor 0.0002158428663932657
Total steps 115845, warmup steps 4633, warmup_factor 0.0002158428663932657
2023-01-06 14:49:43 - trainer.py[line:758] - INFO: begin training epoch 1
2023-01-06 14:49:43 - train.py[line:312] - INFO: Start iterating over samples
From cpu to cuda:0
From cpu to cuda:1
2023-01-06 14:50:14 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 115845 loss=0.977, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, vqa_score=0.0363, wps=87.4, ups=0.4, wpb=109.9, bsz=40, num_updates=10, lr=1.07921e-07, gnorm=7.477, clip=100, loss_scale=128, train_wall=29, gb_free=10.4, ema_decay=0.9999, wall=50
2023-01-06 14:50:36 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 115845 loss=1.01, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, vqa_score=0.0308, wps=100.9, ups=0.46, wpb=109.6, bsz=40, num_updates=20, lr=2.15843e-07, gnorm=8.04, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=72
2023-01-06 14:50:59 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0245, wps=102.4, ups=0.47, wpb=109, bsz=40, num_updates=30, lr=3.23764e-07, gnorm=9.018, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93
2023-01-06 14:51:20 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 115845 loss=1.005, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, vqa_score=0.0263, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=40, lr=4.31686e-07, gnorm=7.729, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=116
2023-01-06 14:51:42 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0297, wps=101.5, ups=0.47, wpb=108.8, bsz=40, num_updates=50, lr=5.39607e-07, gnorm=7.316, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=138
2023-01-06 14:52:04 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 115845 loss=1.084, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, vqa_score=0.0332, wps=101.2, ups=0.47, wpb=108.3, bsz=40, num_updates=60, lr=6.47529e-07, gnorm=8.527, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=160
2023-01-06 14:52:26 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 115845 loss=1.035, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, vqa_score=0.0283, wps=98, ups=0.45, wpb=109.6, bsz=40, num_updates=70, lr=7.5545e-07, gnorm=7.2, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=182
2023-01-06 14:52:49 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 115845 loss=0.99, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, vqa_score=0.0287, wps=98.1, ups=0.45, wpb=108.3, bsz=40, num_updates=80, lr=8.63371e-07, gnorm=6.8, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=205
2023-01-06 14:53:11 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 115845 loss=0.891, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, vqa_score=0.0291, wps=101, ups=0.46, wpb=109.4, bsz=40, num_updates=90, lr=9.71293e-07, gnorm=5.641, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=226
2023-01-06 14:53:32 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 115845 loss=0.867, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.68, vqa_score=0.0205, wps=103.7, ups=0.48, wpb=109, bsz=40, num_updates=100, lr=1.07921e-06, gnorm=5.205, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=248
2023-01-06 14:53:56 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 115845 loss=0.883, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, vqa_score=0.0321, wps=92.9, ups=0.43, wpb=108.4, bsz=40, num_updates=110, lr=1.18714e-06, gnorm=5.26, clip=100, loss_scale=128, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=271
2023-01-06 14:54:17 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 115845 loss=0.797, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, vqa_score=0.0361, wps=103.7, ups=0.47, wpb=109.9, bsz=40, num_updates=120, lr=1.29506e-06, gnorm=4.539, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=293
2023-01-06 14:54:39 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 115845 loss=0.751, loss_v1=0, loss_v2=0, nll_loss=0.637, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, vqa_score=0.0217, wps=101.2, ups=0.46, wpb=109.7, bsz=40, num_updates=130, lr=1.40298e-06, gnorm=3.774, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=315
2023-01-06 14:55:01 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0457, wps=99, ups=0.46, wpb=108.1, bsz=40, num_updates=140, lr=1.5109e-06, gnorm=3.872, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=337
2023-01-06 14:55:23 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0337, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=150, lr=1.61882e-06, gnorm=3.65, clip=100, loss_scale=128, train_wall=21, gb_free=10, ema_decay=0.9999, wall=359
2023-01-06 14:55:45 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 115845 loss=0.732, loss_v1=0, loss_v2=0, nll_loss=0.64, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.56, vqa_score=0.0195, wps=102.2, ups=0.46, wpb=110, bsz=40, num_updates=160, lr=1.72674e-06, gnorm=3.281, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=380
2023-01-06 14:56:06 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0263, wps=104.2, ups=0.47, wpb=110.4, bsz=40, num_updates=170, lr=1.83466e-06, gnorm=2.671, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=402
2023-01-06 14:56:28 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 115845 loss=0.756, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, vqa_score=0.0048, wps=98.9, ups=0.46, wpb=107.2, bsz=40, num_updates=180, lr=1.94259e-06, gnorm=3.205, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=424
2023-01-06 14:56:50 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 115845 loss=0.702, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0243, wps=102.4, ups=0.47, wpb=109.6, bsz=40, num_updates=190, lr=2.05051e-06, gnorm=2.926, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=445
2023-01-06 14:57:11 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 115845 loss=0.703, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0187, wps=100.1, ups=0.46, wpb=108.6, bsz=40, num_updates=200, lr=2.15843e-06, gnorm=2.613, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=467
2023-01-06 14:57:33 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 115845 loss=0.701, loss_v1=0, loss_v2=0, nll_loss=0.615, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, vqa_score=0.0147, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=210, lr=2.26635e-06, gnorm=2.545, clip=100, loss_scale=128, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=489
2023-01-06 14:57:56 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 115845 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, vqa_score=0.0194, wps=98.3, ups=0.45, wpb=110.1, bsz=40, num_updates=220, lr=2.37427e-06, gnorm=2.411, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=512
2023-01-06 14:58:18 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 115845 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, vqa_score=0.0303, wps=99, ups=0.45, wpb=109.2, bsz=40, num_updates=230, lr=2.48219e-06, gnorm=2.238, clip=100, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=534
2023-01-06 14:58:40 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0156, wps=102, ups=0.47, wpb=108.8, bsz=40, num_updates=240, lr=2.59011e-06, gnorm=2.125, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=555
2023-01-06 14:59:01 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.8, nsentences=40, sample_size=106.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0431, wps=99.9, ups=0.47, wpb=106.8, bsz=40, num_updates=250, lr=2.69804e-06, gnorm=2.057, clip=100, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=577
2023-01-06 14:59:23 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.04, wps=100.7, ups=0.47, wpb=108.1, bsz=40, num_updates=260, lr=2.80596e-06, gnorm=2.197, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=599
2023-01-06 14:59:44 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 115845 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.011, wps=106.3, ups=0.48, wpb=110.3, bsz=40, num_updates=270, lr=2.91388e-06, gnorm=2.064, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=620
2023-01-06 15:00:05 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 115845 loss=0.673, loss_v1=0, loss_v2=0, nll_loss=0.593, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.51, vqa_score=0.0047, wps=100.8, ups=0.47, wpb=107.1, bsz=40, num_updates=280, lr=3.0218e-06, gnorm=1.971, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=641
2023-01-06 15:00:27 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 115845 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0269, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=290, lr=3.12972e-06, gnorm=1.677, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=663
2023-01-06 15:00:49 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0052, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=300, lr=3.23764e-06, gnorm=1.816, clip=100, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=685
2023-01-06 15:01:11 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 115845 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.0348, wps=101.1, ups=0.46, wpb=110.3, bsz=40, num_updates=310, lr=3.34556e-06, gnorm=1.691, clip=100, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=707
2023-01-06 15:01:33 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0146, wps=99.1, ups=0.46, wpb=107.3, bsz=40, num_updates=320, lr=3.45349e-06, gnorm=1.717, clip=100, loss_scale=128, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=729
2023-01-06 15:01:55 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0047, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=330, lr=3.56141e-06, gnorm=1.746, clip=100, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=750
2023-01-06 15:02:16 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 115845 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, vqa_score=0.0204, wps=100.8, ups=0.46, wpb=109.1, bsz=40, num_updates=340, lr=3.66933e-06, gnorm=1.614, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=772
2023-01-06 15:02:39 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 115845 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.0317, wps=98.9, ups=0.45, wpb=109.1, bsz=40, num_updates=350, lr=3.77725e-06, gnorm=1.418, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=795
2023-01-06 15:03:00 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 115845 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.024, wps=102.8, ups=0.47, wpb=108.9, bsz=40, num_updates=360, lr=3.88517e-06, gnorm=1.496, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=816
2023-01-06 15:03:22 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 115845 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0156, wps=100.3, ups=0.46, wpb=108.3, bsz=40, num_updates=370, lr=3.99309e-06, gnorm=1.825, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=838
2023-01-06 15:03:44 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 115845 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0452, wps=100.3, ups=0.46, wpb=108.5, bsz=40, num_updates=380, lr=4.10101e-06, gnorm=1.44, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=860
2023-01-06 15:04:06 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 115845 loss=0.635, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, vqa_score=0.0376, wps=100.6, ups=0.46, wpb=108.6, bsz=40, num_updates=390, lr=4.20894e-06, gnorm=1.695, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=881
2023-01-06 15:04:27 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0281, wps=102.2, ups=0.46, wpb=110.6, bsz=40, num_updates=400, lr=4.31686e-06, gnorm=1.626, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=903
2023-01-06 15:04:50 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0296, wps=98.8, ups=0.46, wpb=108.1, bsz=40, num_updates=410, lr=4.42478e-06, gnorm=1.543, clip=100, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=925
2023-01-06 15:05:11 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 115845 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0323, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=420, lr=4.5327e-06, gnorm=1.501, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=947
2023-01-06 15:05:33 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 115845 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.533, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0309, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=430, lr=4.64062e-06, gnorm=1.755, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=969
2023-01-06 15:05:55 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 115845 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0051, wps=99.8, ups=0.46, wpb=108.8, bsz=40, num_updates=440, lr=4.74854e-06, gnorm=1.505, clip=100, loss_scale=128, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=991
2023-01-06 15:06:17 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 115845 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0472, wps=100.5, ups=0.46, wpb=109, bsz=40, num_updates=450, lr=4.85646e-06, gnorm=1.327, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1013
2023-01-06 15:06:38 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 115845 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, vqa_score=0.0329, wps=101.3, ups=0.47, wpb=108.3, bsz=40, num_updates=460, lr=4.96439e-06, gnorm=1.472, clip=100, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1034
2023-01-06 15:07:00 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 115845 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, vqa_score=0.0096, wps=101.1, ups=0.46, wpb=109.5, bsz=40, num_updates=470, lr=5.07231e-06, gnorm=1.316, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1056
2023-01-06 15:07:22 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 115845 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0538, wps=104, ups=0.47, wpb=110.5, bsz=40, num_updates=480, lr=5.18023e-06, gnorm=1.502, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1078
2023-01-06 15:07:44 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 115845 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.45, vqa_score=0.0242, wps=99.6, ups=0.46, wpb=108.7, bsz=40, num_updates=490, lr=5.28815e-06, gnorm=1.433, clip=100, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1100
2023-01-06 15:08:05 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0266, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=500, lr=5.39607e-06, gnorm=1.639, clip=100, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1121
2023-01-06 15:08:27 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.058, wps=104.1, ups=0.47, wpb=109.7, bsz=40, num_updates=510, lr=5.50399e-06, gnorm=1.519, clip=100, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1143
2023-01-06 15:08:49 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 115845 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, vqa_score=0.0286, wps=99, ups=0.46, wpb=107.9, bsz=40, num_updates=520, lr=5.61191e-06, gnorm=1.45, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1165
2023-01-06 15:09:10 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 115845 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0199, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=530, lr=5.71984e-06, gnorm=1.499, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1186
2023-01-06 15:09:32 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 115845 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0273, wps=101.9, ups=0.47, wpb=109.5, bsz=40, num_updates=540, lr=5.82776e-06, gnorm=1.363, clip=80, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1208
2023-01-06 15:09:54 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 115845 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0294, wps=100.1, ups=0.45, wpb=110.6, bsz=40, num_updates=550, lr=5.93568e-06, gnorm=1.409, clip=90, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=1230
2023-01-06 15:10:17 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 115845 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.051, wps=100.3, ups=0.46, wpb=109.3, bsz=40, num_updates=560, lr=6.0436e-06, gnorm=1.578, clip=100, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=1252
2023-01-06 15:10:38 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 115845 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, vqa_score=0.0299, wps=103.7, ups=0.47, wpb=109.5, bsz=40, num_updates=570, lr=6.15152e-06, gnorm=1.301, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1274
2023-01-06 15:11:00 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 115845 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0469, wps=101.8, ups=0.47, wpb=108.7, bsz=40, num_updates=580, lr=6.25944e-06, gnorm=1.3, clip=80, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=1295
2023-01-06 15:11:21 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 115845 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0198, wps=102.5, ups=0.47, wpb=109.4, bsz=40, num_updates=590, lr=6.36736e-06, gnorm=1.411, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1317
2023-01-06 15:11:44 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=99.9, ups=0.46, wpb=109.6, bsz=40, num_updates=600, lr=6.47529e-06, gnorm=1.312, clip=90, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=1339
2023-01-06 15:12:06 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 115845 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, vqa_score=0.0443, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=610, lr=6.58321e-06, gnorm=1.459, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1362
2023-01-06 15:12:28 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 115845 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0202, wps=103.1, ups=0.47, wpb=109.6, bsz=40, num_updates=620, lr=6.69113e-06, gnorm=1.348, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1383
2023-01-06 15:12:50 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0253, wps=101.6, ups=0.46, wpb=109.9, bsz=40, num_updates=630, lr=6.79905e-06, gnorm=1.409, clip=90, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1405
2023-01-06 15:13:12 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0514, wps=103.1, ups=0.46, wpb=111, bsz=40, num_updates=640, lr=6.90697e-06, gnorm=1.476, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1428
2023-01-06 15:13:34 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0326, wps=99.2, ups=0.46, wpb=107.6, bsz=40, num_updates=650, lr=7.01489e-06, gnorm=1.473, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1450
2023-01-06 15:13:56 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 115845 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0254, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=660, lr=7.12281e-06, gnorm=1.585, clip=100, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=1472
2023-01-06 15:14:18 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 115845 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0294, wps=103, ups=0.47, wpb=109.9, bsz=40, num_updates=670, lr=7.23074e-06, gnorm=1.22, clip=70, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1493
2023-01-06 15:14:39 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 115845 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, vqa_score=0.0202, wps=102.4, ups=0.47, wpb=109.6, bsz=40, num_updates=680, lr=7.33866e-06, gnorm=1.305, clip=90, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1515
2023-01-06 15:15:01 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0394, wps=102.1, ups=0.47, wpb=109.4, bsz=40, num_updates=690, lr=7.44658e-06, gnorm=1.438, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1537
2023-01-06 15:15:23 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 115845 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0205, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=700, lr=7.5545e-06, gnorm=1.475, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1559
2023-01-06 15:15:44 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0107, wps=103.2, ups=0.47, wpb=110.3, bsz=40, num_updates=710, lr=7.66242e-06, gnorm=1.27, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1580
2023-01-06 15:16:06 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0306, wps=104, ups=0.48, wpb=109.2, bsz=40, num_updates=720, lr=7.77034e-06, gnorm=1.304, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1601
2023-01-06 15:16:28 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 115845 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0324, wps=101.7, ups=0.46, wpb=110.5, bsz=40, num_updates=730, lr=7.87826e-06, gnorm=1.319, clip=90, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=1623
2023-01-06 15:16:49 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, vqa_score=0.0151, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=740, lr=7.98619e-06, gnorm=1.328, clip=90, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=1645
2023-01-06 15:17:11 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 115845 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.044, wps=103.1, ups=0.47, wpb=110.4, bsz=40, num_updates=750, lr=8.09411e-06, gnorm=1.44, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1667
2023-01-06 15:17:33 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0107, wps=100.4, ups=0.46, wpb=109.3, bsz=40, num_updates=760, lr=8.20203e-06, gnorm=1.178, clip=80, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1689
2023-01-06 15:17:54 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 115845 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0259, wps=105.5, ups=0.47, wpb=111.5, bsz=40, num_updates=770, lr=8.30995e-06, gnorm=1.23, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1710
2023-01-06 15:18:16 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0203, wps=100.6, ups=0.46, wpb=108.6, bsz=40, num_updates=780, lr=8.41787e-06, gnorm=1.414, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1732
2023-01-06 15:18:38 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 115845 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0359, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=790, lr=8.52579e-06, gnorm=1.212, clip=80, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1754
2023-01-06 15:19:00 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0294, wps=101.3, ups=0.47, wpb=108, bsz=40, num_updates=800, lr=8.63371e-06, gnorm=1.532, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1775
2023-01-06 15:19:21 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0248, wps=102.1, ups=0.47, wpb=108.6, bsz=40, num_updates=810, lr=8.74164e-06, gnorm=1.563, clip=100, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=1797
2023-01-06 15:19:43 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 115845 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0201, wps=101.6, ups=0.46, wpb=109.3, bsz=40, num_updates=820, lr=8.84956e-06, gnorm=1.343, clip=100, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1819
2023-01-06 15:20:05 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 115845 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0153, wps=101, ups=0.47, wpb=107.8, bsz=40, num_updates=830, lr=8.95748e-06, gnorm=1.357, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1840
2023-01-06 15:20:26 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 115845 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.035, wps=101.3, ups=0.47, wpb=108.5, bsz=40, num_updates=840, lr=9.0654e-06, gnorm=1.211, clip=90, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=1862
2023-01-06 15:20:48 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0239, wps=103, ups=0.47, wpb=109.3, bsz=40, num_updates=850, lr=9.17332e-06, gnorm=1.245, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1884
2023-01-06 15:21:09 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 115845 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0385, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=860, lr=9.28124e-06, gnorm=1.28, clip=60, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=1905
2023-01-06 15:21:31 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 115845 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0246, wps=100.2, ups=0.46, wpb=108.2, bsz=40, num_updates=870, lr=9.38916e-06, gnorm=1.293, clip=80, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=1927
2023-01-06 15:21:53 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0287, wps=100.9, ups=0.46, wpb=110.8, bsz=40, num_updates=880, lr=9.49709e-06, gnorm=1.269, clip=90, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=1949
2023-01-06 15:22:15 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=104.2, ups=0.47, wpb=111.1, bsz=40, num_updates=890, lr=9.60501e-06, gnorm=1.281, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=1971
2023-01-06 15:22:37 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 115845 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0154, wps=101.2, ups=0.47, wpb=108.3, bsz=40, num_updates=900, lr=9.71293e-06, gnorm=1.379, clip=100, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=1993
2023-01-06 15:22:59 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 115845 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, vqa_score=0.0381, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=910, lr=9.82085e-06, gnorm=1.328, clip=90, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=2014
2023-01-06 15:23:21 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 115845 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0192, wps=98.1, ups=0.45, wpb=107.9, bsz=40, num_updates=920, lr=9.92877e-06, gnorm=1.623, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2037
2023-01-06 15:23:43 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 115845 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0265, wps=98.9, ups=0.46, wpb=107.7, bsz=40, num_updates=930, lr=1.00367e-05, gnorm=1.413, clip=100, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2059
2023-01-06 15:24:05 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 115845 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0253, wps=98.8, ups=0.46, wpb=108.5, bsz=40, num_updates=940, lr=1.01446e-05, gnorm=1.427, clip=100, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=2081
2023-01-06 15:24:26 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 115845 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0343, wps=104, ups=0.48, wpb=108.8, bsz=40, num_updates=950, lr=1.02525e-05, gnorm=1.372, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2102
2023-01-06 15:24:48 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0197, wps=102.4, ups=0.47, wpb=109.3, bsz=40, num_updates=960, lr=1.03605e-05, gnorm=1.262, clip=90, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2124
2023-01-06 15:25:10 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0243, wps=98.6, ups=0.46, wpb=107.9, bsz=40, num_updates=970, lr=1.04684e-05, gnorm=1.146, clip=60, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=2146
2023-01-06 15:25:31 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0146, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=980, lr=1.05763e-05, gnorm=1.295, clip=100, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2167
2023-01-06 15:25:53 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0377, wps=102.1, ups=0.47, wpb=109.5, bsz=40, num_updates=990, lr=1.06842e-05, gnorm=1.435, clip=90, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2189
2023-01-06 15:26:15 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 115845 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0296, wps=101.4, ups=0.47, wpb=107.8, bsz=40, num_updates=1000, lr=1.07921e-05, gnorm=1.456, clip=100, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2211
2023-01-06 15:26:37 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 115845 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0242, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=1010, lr=1.09001e-05, gnorm=1.428, clip=90, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=2232
2023-01-06 15:26:58 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 115845 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0201, wps=102, ups=0.46, wpb=110.2, bsz=40, num_updates=1020, lr=1.1008e-05, gnorm=1.295, clip=90, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=2254
2023-01-06 15:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 115845 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0383, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=1030, lr=1.11159e-05, gnorm=1.296, clip=80, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2276
2023-01-06 15:27:42 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 115845 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, vqa_score=0.0195, wps=100.3, ups=0.46, wpb=108.9, bsz=40, num_updates=1040, lr=1.12238e-05, gnorm=1.414, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2298
2023-01-06 15:28:04 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0202, wps=101.6, ups=0.46, wpb=109.4, bsz=40, num_updates=1050, lr=1.13318e-05, gnorm=1.327, clip=90, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=2320
2023-01-06 15:28:26 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0321, wps=102.9, ups=0.47, wpb=110.4, bsz=40, num_updates=1060, lr=1.14397e-05, gnorm=1.113, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2341
2023-01-06 15:28:47 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 115845 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, vqa_score=0.0388, wps=101.7, ups=0.47, wpb=108.7, bsz=40, num_updates=1070, lr=1.15476e-05, gnorm=1.414, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2363
2023-01-06 15:29:09 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0421, wps=103, ups=0.47, wpb=110.1, bsz=40, num_updates=1080, lr=1.16555e-05, gnorm=1.31, clip=90, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=2385
2023-01-06 15:29:30 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 115845 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0258, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=1090, lr=1.17634e-05, gnorm=1.344, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2406
2023-01-06 15:29:52 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0335, wps=103.3, ups=0.47, wpb=110.1, bsz=40, num_updates=1100, lr=1.18714e-05, gnorm=1.266, clip=70, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2428
2023-01-06 15:30:14 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 115845 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0154, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=1110, lr=1.19793e-05, gnorm=1.341, clip=100, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2450
2023-01-06 15:30:35 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0048, wps=101.9, ups=0.47, wpb=108.2, bsz=40, num_updates=1120, lr=1.20872e-05, gnorm=1.413, clip=100, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2471
2023-01-06 15:30:57 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 115845 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.03, wps=100.5, ups=0.46, wpb=108.8, bsz=40, num_updates=1130, lr=1.21951e-05, gnorm=1.412, clip=100, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=2493
2023-01-06 15:31:19 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 115845 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0049, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=1140, lr=1.2303e-05, gnorm=1.202, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2515
2023-01-06 15:31:41 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 115845 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0426, wps=101.6, ups=0.46, wpb=109.5, bsz=40, num_updates=1150, lr=1.2411e-05, gnorm=1.285, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2537
2023-01-06 15:32:03 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 115845 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0327, wps=101.3, ups=0.47, wpb=108.3, bsz=40, num_updates=1160, lr=1.25189e-05, gnorm=1.337, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2558
2023-01-06 15:32:24 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 115845 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0308, wps=101.4, ups=0.46, wpb=109.9, bsz=40, num_updates=1170, lr=1.26268e-05, gnorm=1.352, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2580
2023-01-06 15:32:47 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0333, wps=99.4, ups=0.46, wpb=108.8, bsz=40, num_updates=1180, lr=1.27347e-05, gnorm=1.396, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2602
2023-01-06 15:33:09 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 115845 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0242, wps=99.9, ups=0.46, wpb=109.1, bsz=40, num_updates=1190, lr=1.28427e-05, gnorm=1.295, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2625
2023-01-06 15:33:30 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 115845 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, vqa_score=0.0234, wps=101.6, ups=0.47, wpb=107.9, bsz=40, num_updates=1200, lr=1.29506e-05, gnorm=1.381, clip=100, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=2646
2023-01-06 15:33:52 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 115845 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0431, wps=98, ups=0.45, wpb=108.4, bsz=40, num_updates=1210, lr=1.30585e-05, gnorm=1.42, clip=100, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2668
2023-01-06 15:34:14 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0254, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=1220, lr=1.31664e-05, gnorm=1.348, clip=80, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=2690
2023-01-06 15:34:36 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 115845 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0481, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=1230, lr=1.32743e-05, gnorm=1.481, clip=90, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=2712
2023-01-06 15:34:58 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0103, wps=101.3, ups=0.47, wpb=108.5, bsz=40, num_updates=1240, lr=1.33823e-05, gnorm=1.261, clip=80, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=2733
2023-01-06 15:35:19 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 115845 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0156, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=1250, lr=1.34902e-05, gnorm=1.3, clip=80, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2755
2023-01-06 15:35:41 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0106, wps=101.7, ups=0.47, wpb=108.8, bsz=40, num_updates=1260, lr=1.35981e-05, gnorm=1.139, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2777
2023-01-06 15:36:02 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0051, wps=102.1, ups=0.47, wpb=108.3, bsz=40, num_updates=1270, lr=1.3706e-05, gnorm=1.215, clip=80, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=2798
2023-01-06 15:36:24 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 115845 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0207, wps=101.6, ups=0.46, wpb=110, bsz=40, num_updates=1280, lr=1.38139e-05, gnorm=1.183, clip=70, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=2820
2023-01-06 15:36:46 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 115845 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0263, wps=100, ups=0.46, wpb=108.7, bsz=40, num_updates=1290, lr=1.39219e-05, gnorm=1.593, clip=100, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=2842
2023-01-06 15:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.01, wps=105.3, ups=0.48, wpb=109.3, bsz=40, num_updates=1300, lr=1.40298e-05, gnorm=1.241, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2863
2023-01-06 15:37:29 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 115845 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0345, wps=103.5, ups=0.47, wpb=109.4, bsz=40, num_updates=1310, lr=1.41377e-05, gnorm=1.301, clip=90, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=2885
2023-01-06 15:37:50 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0354, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=1320, lr=1.42456e-05, gnorm=1.242, clip=90, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=2906
2023-01-06 15:38:12 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0183, wps=103.7, ups=0.48, wpb=108.3, bsz=40, num_updates=1330, lr=1.43536e-05, gnorm=1.342, clip=100, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=2927
2023-01-06 15:38:33 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 115845 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0237, wps=101.1, ups=0.47, wpb=108.1, bsz=40, num_updates=1340, lr=1.44615e-05, gnorm=1.19, clip=70, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=2949
2023-01-06 15:38:55 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 115845 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0145, wps=99.6, ups=0.46, wpb=107.3, bsz=40, num_updates=1350, lr=1.45694e-05, gnorm=1.384, clip=90, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=2971
2023-01-06 15:39:16 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 115845 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.025, wps=101.4, ups=0.47, wpb=108, bsz=40, num_updates=1360, lr=1.46773e-05, gnorm=1.538, clip=100, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=2992
2023-01-06 15:39:38 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0206, wps=100.7, ups=0.46, wpb=109.1, bsz=40, num_updates=1370, lr=1.47852e-05, gnorm=1.571, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3014
2023-01-06 15:40:00 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 115845 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0097, wps=99.5, ups=0.46, wpb=108.7, bsz=40, num_updates=1380, lr=1.48932e-05, gnorm=1.203, clip=90, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3036
2023-01-06 15:40:22 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0273, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=1390, lr=1.50011e-05, gnorm=1.467, clip=80, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3058
2023-01-06 15:40:43 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 115845 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, vqa_score=0.0185, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=1400, lr=1.5109e-05, gnorm=1.186, clip=90, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=3079
2023-01-06 15:41:05 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0093, wps=100.5, ups=0.46, wpb=108.6, bsz=40, num_updates=1410, lr=1.52169e-05, gnorm=1.3, clip=80, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3101
2023-01-06 15:41:27 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 115845 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0291, wps=99.5, ups=0.46, wpb=108.5, bsz=40, num_updates=1420, lr=1.53248e-05, gnorm=1.41, clip=100, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3123
2023-01-06 15:41:49 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 115845 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0155, wps=101.1, ups=0.47, wpb=108.4, bsz=40, num_updates=1430, lr=1.54328e-05, gnorm=1.43, clip=90, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=3145
2023-01-06 15:42:11 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0419, wps=101.9, ups=0.47, wpb=109.5, bsz=40, num_updates=1440, lr=1.55407e-05, gnorm=1.231, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3167
2023-01-06 15:42:32 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0211, wps=105.1, ups=0.48, wpb=109.1, bsz=40, num_updates=1450, lr=1.56486e-05, gnorm=1.245, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3188
2023-01-06 15:42:53 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 115845 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0317, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=1460, lr=1.57565e-05, gnorm=1.151, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=3209
2023-01-06 15:43:15 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 115845 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0347, wps=103.5, ups=0.47, wpb=110.7, bsz=40, num_updates=1470, lr=1.58645e-05, gnorm=1.21, clip=90, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=3231
2023-01-06 15:43:37 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 115845 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0293, wps=102.1, ups=0.47, wpb=109.8, bsz=40, num_updates=1480, lr=1.59724e-05, gnorm=1.392, clip=80, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3253
2023-01-06 15:43:58 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 115845 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, vqa_score=0.0187, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=1490, lr=1.60803e-05, gnorm=1.329, clip=90, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=3274
2023-01-06 15:44:21 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0282, wps=99.5, ups=0.46, wpb=108.9, bsz=40, num_updates=1500, lr=1.61882e-05, gnorm=1.297, clip=70, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3296
2023-01-06 15:44:43 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 115845 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0377, wps=98.4, ups=0.46, wpb=107.7, bsz=40, num_updates=1510, lr=1.62961e-05, gnorm=1.355, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3319
2023-01-06 15:45:04 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0193, wps=101, ups=0.47, wpb=107.9, bsz=40, num_updates=1520, lr=1.64041e-05, gnorm=1.303, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3340
2023-01-06 15:45:26 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0251, wps=102, ups=0.46, wpb=109.7, bsz=40, num_updates=1530, lr=1.6512e-05, gnorm=1.219, clip=80, loss_scale=512, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=3362
2023-01-06 15:45:48 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.033, wps=100.7, ups=0.46, wpb=109.9, bsz=40, num_updates=1540, lr=1.66199e-05, gnorm=1.294, clip=100, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3384
2023-01-06 15:46:10 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 115845 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0209, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=1550, lr=1.67278e-05, gnorm=1.276, clip=90, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3406
2023-01-06 15:46:32 - progress_bar.py[line:274] - INFO: epoch 001:   1560 / 115845 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, vqa_score=0.0097, wps=100.6, ups=0.46, wpb=108.8, bsz=40, num_updates=1560, lr=1.68357e-05, gnorm=1.29, clip=90, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3428
2023-01-06 15:46:53 - progress_bar.py[line:274] - INFO: epoch 001:   1570 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.05, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=1570, lr=1.69437e-05, gnorm=1.162, clip=80, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3449
2023-01-06 15:47:15 - progress_bar.py[line:274] - INFO: epoch 001:   1580 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0207, wps=104.3, ups=0.47, wpb=110.1, bsz=40, num_updates=1580, lr=1.70516e-05, gnorm=1.181, clip=80, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3470
2023-01-06 15:47:37 - progress_bar.py[line:274] - INFO: epoch 001:   1590 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0105, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=1590, lr=1.71595e-05, gnorm=1.041, clip=70, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3492
2023-01-06 15:47:58 - progress_bar.py[line:274] - INFO: epoch 001:   1600 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0335, wps=98.7, ups=0.46, wpb=107, bsz=40, num_updates=1600, lr=1.72674e-05, gnorm=1.48, clip=100, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3514
2023-01-06 15:48:20 - progress_bar.py[line:274] - INFO: epoch 001:   1610 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0095, wps=100, ups=0.47, wpb=107.3, bsz=40, num_updates=1610, lr=1.73754e-05, gnorm=1.296, clip=90, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3536
2023-01-06 15:48:42 - progress_bar.py[line:274] - INFO: epoch 001:   1620 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0306, wps=102.2, ups=0.47, wpb=109.4, bsz=40, num_updates=1620, lr=1.74833e-05, gnorm=1.13, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3558
2023-01-06 15:49:03 - progress_bar.py[line:274] - INFO: epoch 001:   1630 / 115845 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0363, wps=104.1, ups=0.48, wpb=108.1, bsz=40, num_updates=1630, lr=1.75912e-05, gnorm=1.168, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3579
2023-01-06 15:49:24 - progress_bar.py[line:274] - INFO: epoch 001:   1640 / 115845 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0198, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=1640, lr=1.76991e-05, gnorm=1.17, clip=70, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3600
2023-01-06 15:49:46 - progress_bar.py[line:274] - INFO: epoch 001:   1650 / 115845 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0441, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=1650, lr=1.7807e-05, gnorm=1.16, clip=60, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=3622
2023-01-06 15:50:08 - progress_bar.py[line:274] - INFO: epoch 001:   1660 / 115845 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0251, wps=102.1, ups=0.47, wpb=109.3, bsz=40, num_updates=1660, lr=1.7915e-05, gnorm=1.124, clip=80, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3644
2023-01-06 15:50:16 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 15:50:32 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=109.476, nsentences=40, sample_size=109.476, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0327, wps=98.7, ups=0.43, wpb=109.5, bsz=40, num_updates=1670, lr=1.80229e-05, gnorm=1.227, clip=90, loss_scale=512, train_wall=23, gb_free=9.7, ema_decay=0.9999, wall=3667
2023-01-06 15:50:54 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 115845 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0404, wps=103.8, ups=0.47, wpb=110.1, bsz=40, num_updates=1680, lr=1.81308e-05, gnorm=1.055, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3689
2023-01-06 15:51:15 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0291, wps=104.2, ups=0.47, wpb=109.7, bsz=40, num_updates=1690, lr=1.82387e-05, gnorm=1.14, clip=70, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=3711
2023-01-06 15:51:37 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 115845 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0113, wps=102, ups=0.47, wpb=108.9, bsz=40, num_updates=1700, lr=1.83466e-05, gnorm=1.125, clip=80, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=3733
2023-01-06 15:52:00 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0256, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=1710, lr=1.84546e-05, gnorm=1.238, clip=90, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3755
2023-01-06 15:52:22 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0567, wps=101.8, ups=0.46, wpb=110, bsz=40, num_updates=1720, lr=1.85625e-05, gnorm=1.001, clip=40, loss_scale=512, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=3777
2023-01-06 15:52:45 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0273, wps=99.5, ups=0.45, wpb=109.4, bsz=40, num_updates=1730, lr=1.86704e-05, gnorm=1.083, clip=50, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=3800
2023-01-06 15:53:07 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0201, wps=100.6, ups=0.46, wpb=108.6, bsz=40, num_updates=1740, lr=1.87783e-05, gnorm=1.355, clip=90, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=3822
2023-01-06 15:53:30 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 115845 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.026, wps=99.1, ups=0.45, wpb=109.1, bsz=40, num_updates=1750, lr=1.88863e-05, gnorm=1.043, clip=40, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=3845
2023-01-06 15:53:53 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0192, wps=99.6, ups=0.46, wpb=108.9, bsz=40, num_updates=1760, lr=1.89942e-05, gnorm=1.053, clip=60, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=3868
2023-01-06 15:54:14 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 115845 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0148, wps=103.7, ups=0.48, wpb=108.7, bsz=40, num_updates=1770, lr=1.91021e-05, gnorm=1.21, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3890
2023-01-06 15:54:36 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0155, wps=100.1, ups=0.46, wpb=108.9, bsz=40, num_updates=1780, lr=1.921e-05, gnorm=1.139, clip=80, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=3912
2023-01-06 15:54:59 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 115845 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0326, wps=102.6, ups=0.46, wpb=110.5, bsz=40, num_updates=1790, lr=1.93179e-05, gnorm=1.096, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3934
2023-01-06 15:55:21 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.035, wps=101.1, ups=0.46, wpb=108.8, bsz=40, num_updates=1800, lr=1.94259e-05, gnorm=1.104, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3956
2023-01-06 15:55:43 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0196, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=1810, lr=1.95338e-05, gnorm=1.109, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=3978
2023-01-06 15:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0433, wps=102.6, ups=0.47, wpb=110, bsz=40, num_updates=1820, lr=1.96417e-05, gnorm=1.096, clip=70, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=4000
2023-01-06 15:56:28 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 115845 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0243, wps=98.1, ups=0.45, wpb=107.8, bsz=40, num_updates=1830, lr=1.97496e-05, gnorm=1.122, clip=80, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=4023
2023-01-06 15:56:50 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0242, wps=101.3, ups=0.47, wpb=108.9, bsz=40, num_updates=1840, lr=1.98575e-05, gnorm=1.217, clip=90, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4045
2023-01-06 15:57:13 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 115845 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0249, wps=98.6, ups=0.45, wpb=108.6, bsz=40, num_updates=1850, lr=1.99655e-05, gnorm=1.121, clip=80, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4068
2023-01-06 15:57:35 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 115845 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.041, wps=100.4, ups=0.46, wpb=108.6, bsz=40, num_updates=1860, lr=2.00734e-05, gnorm=1.17, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4090
2023-01-06 15:57:57 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 115845 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0145, wps=99.8, ups=0.47, wpb=107.3, bsz=40, num_updates=1870, lr=2.01813e-05, gnorm=1.088, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=4112
2023-01-06 15:58:19 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 115845 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0291, wps=100, ups=0.46, wpb=108.2, bsz=40, num_updates=1880, lr=2.02892e-05, gnorm=1.125, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4135
2023-01-06 15:58:41 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.034, wps=103.9, ups=0.47, wpb=109.9, bsz=40, num_updates=1890, lr=2.03972e-05, gnorm=1.148, clip=80, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4156
2023-01-06 15:59:04 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 115845 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, vqa_score=0.0243, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=1900, lr=2.05051e-05, gnorm=1.152, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4179
2023-01-06 15:59:26 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0226, wps=102.4, ups=0.46, wpb=111.5, bsz=40, num_updates=1910, lr=2.0613e-05, gnorm=1.178, clip=70, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4202
2023-01-06 15:59:48 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 115845 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0151, wps=103.5, ups=0.47, wpb=109.2, bsz=40, num_updates=1920, lr=2.07209e-05, gnorm=1.056, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=4223
2023-01-06 16:00:11 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0191, wps=100.3, ups=0.46, wpb=108.2, bsz=40, num_updates=1930, lr=2.08288e-05, gnorm=1.241, clip=90, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=4246
2023-01-06 16:00:33 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 115845 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0102, wps=102.4, ups=0.47, wpb=109.6, bsz=40, num_updates=1940, lr=2.09368e-05, gnorm=1.128, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4268
2023-01-06 16:00:55 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0284, wps=99.8, ups=0.46, wpb=109.5, bsz=40, num_updates=1950, lr=2.10447e-05, gnorm=1.053, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4291
2023-01-06 16:01:18 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 115845 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0191, wps=102.7, ups=0.47, wpb=109.1, bsz=40, num_updates=1960, lr=2.11526e-05, gnorm=1.202, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4313
2023-01-06 16:01:40 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 115845 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0243, wps=98.1, ups=0.45, wpb=108.1, bsz=40, num_updates=1970, lr=2.12605e-05, gnorm=1.111, clip=80, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=4336
2023-01-06 16:02:03 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 115845 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0208, wps=99.6, ups=0.46, wpb=108.4, bsz=40, num_updates=1980, lr=2.13684e-05, gnorm=1.033, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=4358
2023-01-06 16:02:25 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0185, wps=100.3, ups=0.46, wpb=107.9, bsz=40, num_updates=1990, lr=2.14764e-05, gnorm=1.155, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4380
2023-01-06 16:02:47 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0198, wps=101.1, ups=0.47, wpb=108.7, bsz=40, num_updates=2000, lr=2.15843e-05, gnorm=1.137, clip=70, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=4402
2023-01-06 16:02:47 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-06 16:02:47 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-01-06 16:02:49 - train.py[line:549] - INFO: 0 / 4988
2023-01-06 16:02:49 - train.py[line:551] - INFO: load:1.09 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-06 16:02:49 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 9.26 GiB already allocated; 5.99 GiB free; 31.12 GiB reserved in total by PyTorch)
2023-01-06 16:02:49 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-06 16:02:49 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 6         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9486 MB |   10711 MB |  658053 GB |  658043 GB |
|       from large pool |    9312 MB |   10537 MB |  657608 GB |  657599 GB |
|       from small pool |     174 MB |     175 MB |     445 GB |     444 GB |
|---------------------------------------------------------------------------|
| Active memory         |    9486 MB |   10711 MB |  658053 GB |  658043 GB |
|       from large pool |    9312 MB |   10537 MB |  657608 GB |  657599 GB |
|       from small pool |     174 MB |     175 MB |     445 GB |     444 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31864 MB |   33022 MB |  125902 MB |   94038 MB |
|       from large pool |   31688 MB |   32844 MB |  125606 MB |   93918 MB |
|       from small pool |     176 MB |     178 MB |     296 MB |     120 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22377 MB |   26780 MB |  623476 GB |  623454 GB |
|       from large pool |   22375 MB |   26778 MB |  623009 GB |  622987 GB |
|       from small pool |       1 MB |       3 MB |     467 GB |     467 GB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |   28242 K  |   28237 K  |
|       from large pool |     698    |     710    |    9340 K  |    9340 K  |
|       from small pool |    3925    |    3943    |   18901 K  |   18897 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |   28242 K  |   28237 K  |
|       from large pool |     698    |     710    |    9340 K  |    9340 K  |
|       from small pool |    3925    |    3943    |   18901 K  |   18897 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     199    |     206    |     446    |     247    |
|       from large pool |     111    |     117    |     298    |     187    |
|       from small pool |      88    |      89    |     148    |      60    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     133    |     135    |   20679 K  |   20679 K  |
|       from large pool |      68    |      68    |    5443 K  |    5443 K  |
|       from small pool |      65    |      72    |   15235 K  |   15235 K  |
|===========================================================================|

2023-01-06 16:02:49 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-06 16:05:23 - train.py[line:549] - INFO: 200 / 4988
2023-01-06 16:05:23 - train.py[line:551] - INFO: load:1.12 valid_run:154.38 task_valid:150.39 collect_output:2.93
2023-01-06 16:07:53 - train.py[line:549] - INFO: 400 / 4988
2023-01-06 16:07:53 - train.py[line:551] - INFO: load:1.14 valid_run:303.92 task_valid:293.29 collect_output:8.52
2023-01-06 16:10:26 - train.py[line:549] - INFO: 600 / 4988
2023-01-06 16:10:26 - train.py[line:551] - INFO: load:1.17 valid_run:457.16 task_valid:436.11 collect_output:17.90
2023-01-06 16:12:56 - train.py[line:549] - INFO: 800 / 4988
2023-01-06 16:12:56 - train.py[line:551] - INFO: load:1.19 valid_run:606.76 task_valid:580.66 collect_output:21.90
2023-01-06 16:15:29 - train.py[line:549] - INFO: 1000 / 4988
2023-01-06 16:15:29 - train.py[line:551] - INFO: load:1.22 valid_run:759.87 task_valid:728.21 collect_output:26.40
2023-01-06 16:18:02 - train.py[line:549] - INFO: 1200 / 4988
2023-01-06 16:18:02 - train.py[line:551] - INFO: load:1.24 valid_run:912.78 task_valid:873.74 collect_output:32.71
2023-01-06 16:20:36 - train.py[line:549] - INFO: 1400 / 4988
2023-01-06 16:20:36 - train.py[line:551] - INFO: load:1.27 valid_run:1067.34 task_valid:1019.67 collect_output:40.31
2023-01-06 16:23:09 - train.py[line:549] - INFO: 1600 / 4988
2023-01-06 16:23:09 - train.py[line:551] - INFO: load:1.30 valid_run:1219.81 task_valid:1160.49 collect_output:50.96
2023-01-06 16:25:40 - train.py[line:549] - INFO: 1800 / 4988
2023-01-06 16:25:40 - train.py[line:551] - INFO: load:1.32 valid_run:1370.67 task_valid:1305.31 collect_output:55.96
2023-01-06 16:28:09 - train.py[line:549] - INFO: 2000 / 4988
2023-01-06 16:28:10 - train.py[line:551] - INFO: load:1.35 valid_run:1520.19 task_valid:1448.33 collect_output:61.45
2023-01-06 16:30:40 - train.py[line:549] - INFO: 2200 / 4988
2023-01-06 16:30:40 - train.py[line:551] - INFO: load:1.37 valid_run:1670.77 task_valid:1593.13 collect_output:66.18
2023-01-06 16:33:11 - train.py[line:549] - INFO: 2400 / 4988
2023-01-06 16:33:11 - train.py[line:551] - INFO: load:1.40 valid_run:1821.66 task_valid:1737.63 collect_output:71.54
2023-01-06 16:35:42 - train.py[line:549] - INFO: 2600 / 4988
2023-01-06 16:35:42 - train.py[line:551] - INFO: load:1.42 valid_run:1972.72 task_valid:1879.20 collect_output:80.00
2023-01-06 16:38:13 - train.py[line:549] - INFO: 2800 / 4988
2023-01-06 16:38:14 - train.py[line:551] - INFO: load:1.45 valid_run:2123.91 task_valid:2024.34 collect_output:85.03
2023-01-06 16:40:44 - train.py[line:549] - INFO: 3000 / 4988
2023-01-06 16:40:44 - train.py[line:551] - INFO: load:1.48 valid_run:2274.19 task_valid:2170.47 collect_output:88.17
2023-01-06 16:43:15 - train.py[line:549] - INFO: 3200 / 4988
2023-01-06 16:43:15 - train.py[line:551] - INFO: load:1.50 valid_run:2424.91 task_valid:2314.31 collect_output:94.03
2023-01-06 16:45:48 - train.py[line:549] - INFO: 3400 / 4988
2023-01-06 16:45:48 - train.py[line:551] - INFO: load:1.53 valid_run:2577.89 task_valid:2459.75 collect_output:100.53
2023-01-06 16:48:19 - train.py[line:549] - INFO: 3600 / 4988
2023-01-06 16:48:19 - train.py[line:551] - INFO: load:1.55 valid_run:2729.45 task_valid:2606.39 collect_output:104.43
2023-01-06 16:50:49 - train.py[line:549] - INFO: 3800 / 4988
2023-01-06 16:50:49 - train.py[line:551] - INFO: load:1.58 valid_run:2879.14 task_valid:2747.61 collect_output:111.89
2023-01-06 16:53:20 - train.py[line:549] - INFO: 4000 / 4988
2023-01-06 16:53:20 - train.py[line:551] - INFO: load:1.60 valid_run:3030.47 task_valid:2892.50 collect_output:117.29
2023-01-06 16:55:55 - train.py[line:549] - INFO: 4200 / 4988
2023-01-06 16:55:55 - train.py[line:551] - INFO: load:1.63 valid_run:3184.68 task_valid:3037.24 collect_output:125.74
2023-01-06 16:58:25 - train.py[line:549] - INFO: 4400 / 4988
2023-01-06 16:58:25 - train.py[line:551] - INFO: load:1.66 valid_run:3335.24 task_valid:3181.76 collect_output:130.74
2023-01-06 17:00:58 - train.py[line:549] - INFO: 4600 / 4988
2023-01-06 17:00:58 - train.py[line:551] - INFO: load:1.69 valid_run:3487.31 task_valid:3327.62 collect_output:135.92
2023-01-06 17:03:30 - train.py[line:549] - INFO: 4800 / 4988
2023-01-06 17:03:30 - train.py[line:551] - INFO: load:1.71 valid_run:3639.23 task_valid:3473.94 collect_output:140.49

====================================================================================================
SGG eval:     R @ 50: 0.2758;     R @ 100: 0.3407;     R @ 500: 0.4061;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1231;    mR @ 100: 0.1769;    mR @ 500: 0.2209;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0488) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1667) (playing:0.0000) (riding:0.3833) (says:0.0000) (sitting on:0.4128) (standing on:0.5183) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-01-06 17:06:01 - train.py[line:487] - INFO: 0.34073333333333333
2023-01-06 17:06:01 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.2758;     R @ 100: 0.3407;     R @ 500: 0.4061;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1231;    mR @ 100: 0.1769;    mR @ 500: 0.2209;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0488) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1667) (playing:0.0000) (riding:0.3833) (says:0.0000) (sitting on:0.4128) (standing on:0.5183) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-01-06 17:06:01 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.317 | loss_v1 0 | loss_v2 0 | nll_loss 0.159 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.340733 | ppl 1.12 | vqa_score 0.1768 | wps 118.3 | wpb 89.9 | bsz 30 | num_updates 2000
2023-01-06 17:06:01 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2023-01-06 17:06:01 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt
2023-01-06 17:06:43 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt
2023-01-06 17:09:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.34073333333333333) (writing took 228.61412115767598 seconds)
2023-01-06 17:10:11 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0099, wps=0.5, ups=0, wpb=108.2, bsz=40, num_updates=2010, lr=2.16922e-05, gnorm=0.994, clip=30, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8447
2023-01-06 17:10:33 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0267, wps=100.9, ups=0.46, wpb=110, bsz=40, num_updates=2020, lr=2.18001e-05, gnorm=1.059, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8469
2023-01-06 17:10:55 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0193, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=2030, lr=2.19081e-05, gnorm=1.024, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8491
2023-01-06 17:11:17 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0169, wps=102.7, ups=0.47, wpb=110.2, bsz=40, num_updates=2040, lr=2.2016e-05, gnorm=1.161, clip=80, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8513
2023-01-06 17:11:39 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0222, wps=103.3, ups=0.47, wpb=111, bsz=40, num_updates=2050, lr=2.21239e-05, gnorm=1.056, clip=60, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8534
2023-01-06 17:12:00 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 115845 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0293, wps=103, ups=0.47, wpb=110, bsz=40, num_updates=2060, lr=2.22318e-05, gnorm=1.097, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=8556
2023-01-06 17:12:23 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 115845 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0287, wps=97.2, ups=0.45, wpb=108.8, bsz=40, num_updates=2070, lr=2.23397e-05, gnorm=1.057, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8579
2023-01-06 17:12:45 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0376, wps=100.4, ups=0.46, wpb=109.8, bsz=40, num_updates=2080, lr=2.24477e-05, gnorm=1.065, clip=40, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8601
2023-01-06 17:13:07 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 115845 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, vqa_score=0.0425, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=2090, lr=2.25556e-05, gnorm=1.035, clip=60, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8623
2023-01-06 17:13:28 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0093, wps=103.7, ups=0.48, wpb=108, bsz=40, num_updates=2100, lr=2.26635e-05, gnorm=1.15, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8644
2023-01-06 17:13:49 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0366, wps=102.3, ups=0.47, wpb=108.9, bsz=40, num_updates=2110, lr=2.27714e-05, gnorm=0.968, clip=40, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8665
2023-01-06 17:14:11 - progress_bar.py[line:274] - INFO: epoch 001:   2121 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0253, wps=102.2, ups=0.47, wpb=108.4, bsz=40, num_updates=2120, lr=2.28793e-05, gnorm=1.051, clip=70, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=8687
2023-01-06 17:14:33 - progress_bar.py[line:274] - INFO: epoch 001:   2131 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0214, wps=101.2, ups=0.46, wpb=110.1, bsz=40, num_updates=2130, lr=2.29873e-05, gnorm=1.018, clip=60, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8709
2023-01-06 17:14:55 - progress_bar.py[line:274] - INFO: epoch 001:   2141 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0269, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=2140, lr=2.30952e-05, gnorm=0.995, clip=60, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8731
2023-01-06 17:15:17 - progress_bar.py[line:274] - INFO: epoch 001:   2151 / 115845 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0185, wps=99.8, ups=0.47, wpb=106.7, bsz=40, num_updates=2150, lr=2.32031e-05, gnorm=1.014, clip=30, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=8752
2023-01-06 17:15:38 - progress_bar.py[line:274] - INFO: epoch 001:   2161 / 115845 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0248, wps=102.5, ups=0.47, wpb=108.6, bsz=40, num_updates=2160, lr=2.3311e-05, gnorm=1.035, clip=60, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=8774
2023-01-06 17:16:00 - progress_bar.py[line:274] - INFO: epoch 001:   2171 / 115845 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0191, wps=101.1, ups=0.47, wpb=108.4, bsz=40, num_updates=2170, lr=2.3419e-05, gnorm=0.965, clip=30, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=8796
2023-01-06 17:16:22 - progress_bar.py[line:274] - INFO: epoch 001:   2181 / 115845 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0144, wps=100.4, ups=0.46, wpb=108.6, bsz=40, num_updates=2180, lr=2.35269e-05, gnorm=1.108, clip=40, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8818
2023-01-06 17:16:44 - progress_bar.py[line:274] - INFO: epoch 001:   2191 / 115845 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0239, wps=100, ups=0.46, wpb=107.8, bsz=40, num_updates=2190, lr=2.36348e-05, gnorm=1.154, clip=70, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=8839
2023-01-06 17:16:48 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 17:17:08 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 115845 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110.048, nsentences=40, sample_size=110.048, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0271, wps=97.2, ups=0.42, wpb=110, bsz=40, num_updates=2200, lr=2.37427e-05, gnorm=1.117, clip=60, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=8863
2023-01-06 17:17:30 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0246, wps=100.8, ups=0.46, wpb=109.7, bsz=40, num_updates=2210, lr=2.38506e-05, gnorm=0.967, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8885
2023-01-06 17:17:51 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0226, wps=102.2, ups=0.48, wpb=107.6, bsz=40, num_updates=2220, lr=2.39586e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=8907
2023-01-06 17:18:13 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 115845 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0256, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=2230, lr=2.40665e-05, gnorm=1.299, clip=100, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=8928
2023-01-06 17:18:35 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 115845 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0347, wps=101.1, ups=0.46, wpb=110, bsz=40, num_updates=2240, lr=2.41744e-05, gnorm=0.979, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=8951
2023-01-06 17:18:58 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0049, wps=100.3, ups=0.47, wpb=107.6, bsz=40, num_updates=2250, lr=2.42823e-05, gnorm=1.054, clip=50, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=8973
2023-01-06 17:19:20 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0343, wps=100.6, ups=0.47, wpb=108.1, bsz=40, num_updates=2260, lr=2.43902e-05, gnorm=1.203, clip=50, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=8995
2023-01-06 17:19:42 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.005, wps=99, ups=0.46, wpb=108.5, bsz=40, num_updates=2270, lr=2.44982e-05, gnorm=1.144, clip=60, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9018
2023-01-06 17:20:05 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0203, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=2280, lr=2.46061e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9040
2023-01-06 17:20:27 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0314, wps=100.8, ups=0.46, wpb=109.3, bsz=40, num_updates=2290, lr=2.4714e-05, gnorm=0.944, clip=40, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9062
2023-01-06 17:20:49 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 115845 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0196, wps=99, ups=0.46, wpb=108, bsz=40, num_updates=2300, lr=2.48219e-05, gnorm=1.057, clip=40, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9085
2023-01-06 17:21:12 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0508, wps=98.4, ups=0.45, wpb=108.7, bsz=40, num_updates=2310, lr=2.49299e-05, gnorm=1.042, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9108
2023-01-06 17:21:34 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0335, wps=101.3, ups=0.46, wpb=109, bsz=40, num_updates=2320, lr=2.50378e-05, gnorm=1.098, clip=60, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9130
2023-01-06 17:21:57 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0191, wps=100.2, ups=0.46, wpb=107.9, bsz=40, num_updates=2330, lr=2.51457e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9152
2023-01-06 17:22:19 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 115845 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.029, wps=100.9, ups=0.47, wpb=108.3, bsz=40, num_updates=2340, lr=2.52536e-05, gnorm=1.017, clip=50, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=9174
2023-01-06 17:22:41 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0242, wps=101.9, ups=0.47, wpb=109.6, bsz=40, num_updates=2350, lr=2.53615e-05, gnorm=1.084, clip=50, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9196
2023-01-06 17:23:03 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0273, wps=105.2, ups=0.47, wpb=111.2, bsz=40, num_updates=2360, lr=2.54695e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=9218
2023-01-06 17:23:25 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0273, wps=100.4, ups=0.46, wpb=109.5, bsz=40, num_updates=2370, lr=2.55774e-05, gnorm=1.013, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9241
2023-01-06 17:23:47 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0345, wps=102.4, ups=0.47, wpb=108.5, bsz=40, num_updates=2380, lr=2.56853e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9262
2023-01-06 17:24:10 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 115845 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0198, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=2390, lr=2.57932e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=9285
2023-01-06 17:24:31 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0153, wps=102.5, ups=0.47, wpb=108.4, bsz=40, num_updates=2400, lr=2.59011e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9307
2023-01-06 17:24:54 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0457, wps=100.9, ups=0.46, wpb=108.6, bsz=40, num_updates=2410, lr=2.60091e-05, gnorm=0.997, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9329
2023-01-06 17:25:16 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0299, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=2420, lr=2.6117e-05, gnorm=1.011, clip=40, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=9351
2023-01-06 17:25:38 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 115845 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0139, wps=99.9, ups=0.47, wpb=106.5, bsz=40, num_updates=2430, lr=2.62249e-05, gnorm=0.915, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9373
2023-01-06 17:26:00 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 115845 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0338, wps=103.3, ups=0.47, wpb=109.3, bsz=40, num_updates=2440, lr=2.63328e-05, gnorm=1.098, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9395
2023-01-06 17:26:22 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0471, wps=103.4, ups=0.47, wpb=110.4, bsz=40, num_updates=2450, lr=2.64408e-05, gnorm=1.018, clip=50, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9417
2023-01-06 17:26:44 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 115845 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0312, wps=101.4, ups=0.46, wpb=109.4, bsz=40, num_updates=2460, lr=2.65487e-05, gnorm=1.063, clip=70, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=9439
2023-01-06 17:27:07 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0284, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=2470, lr=2.66566e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9462
2023-01-06 17:27:29 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0333, wps=101.3, ups=0.46, wpb=109.6, bsz=40, num_updates=2480, lr=2.67645e-05, gnorm=0.972, clip=50, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9485
2023-01-06 17:27:52 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 115845 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0478, wps=100.8, ups=0.46, wpb=108.4, bsz=40, num_updates=2490, lr=2.68724e-05, gnorm=0.941, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9507
2023-01-06 17:28:14 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0245, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=2500, lr=2.69804e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9529
2023-01-06 17:28:36 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 115845 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0248, wps=103.3, ups=0.47, wpb=109.4, bsz=40, num_updates=2510, lr=2.70883e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=9551
2023-01-06 17:28:59 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.019, wps=99.9, ups=0.46, wpb=109.4, bsz=40, num_updates=2520, lr=2.71962e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=9574
2023-01-06 17:29:20 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0262, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=2530, lr=2.73041e-05, gnorm=0.888, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9596
2023-01-06 17:29:42 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0345, wps=102.1, ups=0.47, wpb=109.2, bsz=40, num_updates=2540, lr=2.7412e-05, gnorm=0.991, clip=30, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=9618
2023-01-06 17:30:05 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0321, wps=102.6, ups=0.47, wpb=109.8, bsz=40, num_updates=2550, lr=2.752e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9640
2023-01-06 17:30:27 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0303, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=2560, lr=2.76279e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=9662
2023-01-06 17:30:49 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 115845 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, vqa_score=0.0326, wps=100.9, ups=0.47, wpb=108.2, bsz=40, num_updates=2570, lr=2.77358e-05, gnorm=0.852, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=9684
2023-01-06 17:31:11 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0419, wps=100.7, ups=0.46, wpb=109.9, bsz=40, num_updates=2580, lr=2.78437e-05, gnorm=1.012, clip=40, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=9707
2023-01-06 17:31:34 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0233, wps=97.3, ups=0.45, wpb=107.9, bsz=40, num_updates=2590, lr=2.79517e-05, gnorm=0.963, clip=30, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9730
2023-01-06 17:31:56 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.035, wps=101.7, ups=0.47, wpb=109.1, bsz=40, num_updates=2600, lr=2.80596e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9752
2023-01-06 17:32:18 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0291, wps=102.4, ups=0.47, wpb=110.1, bsz=40, num_updates=2610, lr=2.81675e-05, gnorm=1.065, clip=60, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9774
2023-01-06 17:32:41 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0404, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=2620, lr=2.82754e-05, gnorm=1.036, clip=40, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=9796
2023-01-06 17:33:03 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0337, wps=102.4, ups=0.47, wpb=109.7, bsz=40, num_updates=2630, lr=2.83833e-05, gnorm=0.922, clip=40, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9818
2023-01-06 17:33:25 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 115845 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0205, wps=100.1, ups=0.46, wpb=108, bsz=40, num_updates=2640, lr=2.84913e-05, gnorm=1.008, clip=50, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=9840
2023-01-06 17:33:47 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.019, wps=101.8, ups=0.47, wpb=107.5, bsz=40, num_updates=2650, lr=2.85992e-05, gnorm=1.026, clip=60, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=9862
2023-01-06 17:34:09 - progress_bar.py[line:274] - INFO: epoch 001:   2662 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0437, wps=102.4, ups=0.46, wpb=110.4, bsz=40, num_updates=2660, lr=2.87071e-05, gnorm=0.874, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=9885
2023-01-06 17:34:32 - progress_bar.py[line:274] - INFO: epoch 001:   2672 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.019, wps=102, ups=0.46, wpb=109.9, bsz=40, num_updates=2670, lr=2.8815e-05, gnorm=0.848, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=9907
2023-01-06 17:34:54 - progress_bar.py[line:274] - INFO: epoch 001:   2682 / 115845 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0372, wps=99.9, ups=0.46, wpb=108.6, bsz=40, num_updates=2680, lr=2.89229e-05, gnorm=0.984, clip=50, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9930
2023-01-06 17:35:17 - progress_bar.py[line:274] - INFO: epoch 001:   2692 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0311, wps=100.2, ups=0.46, wpb=108.5, bsz=40, num_updates=2690, lr=2.90309e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=9952
2023-01-06 17:35:39 - progress_bar.py[line:274] - INFO: epoch 001:   2702 / 115845 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0352, wps=102.6, ups=0.47, wpb=109.7, bsz=40, num_updates=2700, lr=2.91388e-05, gnorm=1.018, clip=50, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=9974
2023-01-06 17:36:01 - progress_bar.py[line:274] - INFO: epoch 001:   2712 / 115845 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0219, wps=100.3, ups=0.46, wpb=109.3, bsz=40, num_updates=2710, lr=2.92467e-05, gnorm=0.806, clip=20, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=9997
2023-01-06 17:36:24 - progress_bar.py[line:274] - INFO: epoch 001:   2722 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.02, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=2720, lr=2.93546e-05, gnorm=0.886, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10019
2023-01-06 17:36:46 - progress_bar.py[line:274] - INFO: epoch 001:   2732 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.037, wps=101.7, ups=0.47, wpb=107.8, bsz=40, num_updates=2730, lr=2.94626e-05, gnorm=0.937, clip=30, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10041
2023-01-06 17:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   2742 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0152, wps=104, ups=0.47, wpb=110, bsz=40, num_updates=2740, lr=2.95705e-05, gnorm=0.969, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10063
2023-01-06 17:37:30 - progress_bar.py[line:274] - INFO: epoch 001:   2752 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0266, wps=100.7, ups=0.47, wpb=108, bsz=40, num_updates=2750, lr=2.96784e-05, gnorm=0.994, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10085
2023-01-06 17:37:51 - progress_bar.py[line:274] - INFO: epoch 001:   2762 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0303, wps=105.2, ups=0.48, wpb=110.4, bsz=40, num_updates=2760, lr=2.97863e-05, gnorm=1.018, clip=40, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10107
2023-01-06 17:38:14 - progress_bar.py[line:274] - INFO: epoch 001:   2772 / 115845 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0386, wps=98.9, ups=0.46, wpb=107.9, bsz=40, num_updates=2770, lr=2.98942e-05, gnorm=1.009, clip=40, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10129
2023-01-06 17:38:36 - progress_bar.py[line:274] - INFO: epoch 001:   2782 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0524, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=2780, lr=3.00022e-05, gnorm=0.94, clip=60, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10152
2023-01-06 17:38:58 - progress_bar.py[line:274] - INFO: epoch 001:   2792 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0521, wps=102.4, ups=0.47, wpb=108.9, bsz=40, num_updates=2790, lr=3.01101e-05, gnorm=0.951, clip=50, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10174
2023-01-06 17:39:20 - progress_bar.py[line:274] - INFO: epoch 001:   2802 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0481, wps=102.1, ups=0.47, wpb=109.2, bsz=40, num_updates=2800, lr=3.0218e-05, gnorm=0.868, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10196
2023-01-06 17:39:42 - progress_bar.py[line:274] - INFO: epoch 001:   2812 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0405, wps=104.5, ups=0.47, wpb=111.3, bsz=40, num_updates=2810, lr=3.03259e-05, gnorm=0.879, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10218
2023-01-06 17:40:04 - progress_bar.py[line:274] - INFO: epoch 001:   2822 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0406, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=2820, lr=3.04338e-05, gnorm=1.045, clip=40, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10240
2023-01-06 17:40:26 - progress_bar.py[line:274] - INFO: epoch 001:   2832 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0051, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=2830, lr=3.05418e-05, gnorm=1.026, clip=40, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10262
2023-01-06 17:40:49 - progress_bar.py[line:274] - INFO: epoch 001:   2842 / 115845 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0221, wps=101.9, ups=0.47, wpb=109.3, bsz=40, num_updates=2840, lr=3.06497e-05, gnorm=0.919, clip=30, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10284
2023-01-06 17:41:10 - progress_bar.py[line:274] - INFO: epoch 001:   2852 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.015, wps=104.1, ups=0.48, wpb=109.3, bsz=40, num_updates=2850, lr=3.07576e-05, gnorm=0.907, clip=40, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10306
2023-01-06 17:41:33 - progress_bar.py[line:274] - INFO: epoch 001:   2862 / 115845 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.029, wps=98.9, ups=0.46, wpb=108.6, bsz=40, num_updates=2860, lr=3.08655e-05, gnorm=0.788, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10329
2023-01-06 17:41:56 - progress_bar.py[line:274] - INFO: epoch 001:   2872 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0435, wps=100.9, ups=0.46, wpb=109.3, bsz=40, num_updates=2870, lr=3.09735e-05, gnorm=0.897, clip=20, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=10351
2023-01-06 17:42:18 - progress_bar.py[line:274] - INFO: epoch 001:   2882 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0152, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=2880, lr=3.10814e-05, gnorm=0.882, clip=30, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10373
2023-01-06 17:42:40 - progress_bar.py[line:274] - INFO: epoch 001:   2892 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.025, wps=103.3, ups=0.47, wpb=109.3, bsz=40, num_updates=2890, lr=3.11893e-05, gnorm=0.849, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10395
2023-01-06 17:43:02 - progress_bar.py[line:274] - INFO: epoch 001:   2902 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0244, wps=102.5, ups=0.47, wpb=109.3, bsz=40, num_updates=2900, lr=3.12972e-05, gnorm=0.847, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10417
2023-01-06 17:43:24 - progress_bar.py[line:274] - INFO: epoch 001:   2912 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0303, wps=103.3, ups=0.47, wpb=108.8, bsz=40, num_updates=2910, lr=3.14051e-05, gnorm=0.848, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10439
2023-01-06 17:43:46 - progress_bar.py[line:274] - INFO: epoch 001:   2922 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0048, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=2920, lr=3.15131e-05, gnorm=0.892, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10461
2023-01-06 17:44:08 - progress_bar.py[line:274] - INFO: epoch 001:   2932 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0306, wps=102.4, ups=0.47, wpb=109.1, bsz=40, num_updates=2930, lr=3.1621e-05, gnorm=0.937, clip=40, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10483
2023-01-06 17:44:30 - progress_bar.py[line:274] - INFO: epoch 001:   2942 / 115845 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0243, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=2940, lr=3.17289e-05, gnorm=0.752, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10506
2023-01-06 17:44:52 - progress_bar.py[line:274] - INFO: epoch 001:   2952 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0309, wps=100.3, ups=0.46, wpb=109.7, bsz=40, num_updates=2950, lr=3.18368e-05, gnorm=0.878, clip=30, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10528
2023-01-06 17:45:14 - progress_bar.py[line:274] - INFO: epoch 001:   2962 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.045, wps=102.2, ups=0.47, wpb=109.8, bsz=40, num_updates=2960, lr=3.19447e-05, gnorm=0.841, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10550
2023-01-06 17:45:36 - progress_bar.py[line:274] - INFO: epoch 001:   2972 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0374, wps=103.6, ups=0.47, wpb=109.4, bsz=40, num_updates=2970, lr=3.20527e-05, gnorm=0.958, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10571
2023-01-06 17:45:58 - progress_bar.py[line:274] - INFO: epoch 001:   2982 / 115845 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0248, wps=100.3, ups=0.46, wpb=108.8, bsz=40, num_updates=2980, lr=3.21606e-05, gnorm=0.899, clip=30, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10593
2023-01-06 17:46:19 - progress_bar.py[line:274] - INFO: epoch 001:   2992 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0149, wps=101.8, ups=0.47, wpb=108.7, bsz=40, num_updates=2990, lr=3.22685e-05, gnorm=0.848, clip=30, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=10615
2023-01-06 17:46:41 - progress_bar.py[line:274] - INFO: epoch 001:   3002 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0, wps=102.5, ups=0.47, wpb=109.4, bsz=40, num_updates=3000, lr=3.23764e-05, gnorm=0.758, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10637
2023-01-06 17:47:03 - progress_bar.py[line:274] - INFO: epoch 001:   3012 / 115845 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0149, wps=100.6, ups=0.46, wpb=109.4, bsz=40, num_updates=3010, lr=3.24844e-05, gnorm=0.789, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10659
2023-01-06 17:47:24 - progress_bar.py[line:274] - INFO: epoch 001:   3022 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0202, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=3020, lr=3.25923e-05, gnorm=0.905, clip=30, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10680
2023-01-06 17:47:46 - progress_bar.py[line:274] - INFO: epoch 001:   3032 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0196, wps=102.6, ups=0.47, wpb=109.9, bsz=40, num_updates=3030, lr=3.27002e-05, gnorm=0.815, clip=20, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10702
2023-01-06 17:48:08 - progress_bar.py[line:274] - INFO: epoch 001:   3042 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0296, wps=102.6, ups=0.47, wpb=109.6, bsz=40, num_updates=3040, lr=3.28081e-05, gnorm=0.875, clip=20, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=10724
2023-01-06 17:48:30 - progress_bar.py[line:274] - INFO: epoch 001:   3052 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0242, wps=100.9, ups=0.46, wpb=108.5, bsz=40, num_updates=3050, lr=3.2916e-05, gnorm=0.968, clip=50, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10746
2023-01-06 17:48:51 - progress_bar.py[line:274] - INFO: epoch 001:   3062 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0197, wps=103.1, ups=0.47, wpb=108.9, bsz=40, num_updates=3060, lr=3.3024e-05, gnorm=0.936, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10767
2023-01-06 17:49:13 - progress_bar.py[line:274] - INFO: epoch 001:   3072 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0163, wps=102.3, ups=0.47, wpb=109.9, bsz=40, num_updates=3070, lr=3.31319e-05, gnorm=0.879, clip=20, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=10789
2023-01-06 17:49:35 - progress_bar.py[line:274] - INFO: epoch 001:   3082 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0051, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=3080, lr=3.32398e-05, gnorm=0.907, clip=50, loss_scale=1024, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=10811
2023-01-06 17:49:56 - progress_bar.py[line:274] - INFO: epoch 001:   3092 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0236, wps=103.8, ups=0.48, wpb=108.8, bsz=40, num_updates=3090, lr=3.33477e-05, gnorm=0.742, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=10832
2023-01-06 17:50:17 - progress_bar.py[line:274] - INFO: epoch 001:   3102 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0094, wps=104.9, ups=0.48, wpb=109.6, bsz=40, num_updates=3100, lr=3.34556e-05, gnorm=0.855, clip=30, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10853
2023-01-06 17:50:39 - progress_bar.py[line:274] - INFO: epoch 001:   3112 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0323, wps=101.5, ups=0.46, wpb=110.5, bsz=40, num_updates=3110, lr=3.35636e-05, gnorm=0.868, clip=40, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=10875
2023-01-06 17:51:01 - progress_bar.py[line:274] - INFO: epoch 001:   3122 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0591, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=3120, lr=3.36715e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=10897
2023-01-06 17:51:23 - progress_bar.py[line:274] - INFO: epoch 001:   3132 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0236, wps=99.8, ups=0.46, wpb=107.5, bsz=40, num_updates=3130, lr=3.37794e-05, gnorm=0.801, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=10919
2023-01-06 17:51:45 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 17:51:47 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.476, nsentences=40, sample_size=109.476, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0457, wps=96.7, ups=0.42, wpb=109.5, bsz=40, num_updates=3140, lr=3.38873e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=10943
2023-01-06 17:52:09 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0053, wps=100.8, ups=0.46, wpb=110.3, bsz=40, num_updates=3150, lr=3.39953e-05, gnorm=0.868, clip=30, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=10965
2023-01-06 17:52:31 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0259, wps=102, ups=0.47, wpb=109.4, bsz=40, num_updates=3160, lr=3.41032e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=10987
2023-01-06 17:52:53 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0186, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=3170, lr=3.42111e-05, gnorm=0.763, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=11009
2023-01-06 17:53:15 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.02, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=3180, lr=3.4319e-05, gnorm=0.981, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11031
2023-01-06 17:53:36 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0227, wps=100.8, ups=0.47, wpb=107.6, bsz=40, num_updates=3190, lr=3.44269e-05, gnorm=0.886, clip=30, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=11052
2023-01-06 17:53:58 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0159, wps=103.6, ups=0.47, wpb=109.5, bsz=40, num_updates=3200, lr=3.45349e-05, gnorm=0.847, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11074
2023-01-06 17:54:20 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0152, wps=101.1, ups=0.46, wpb=108.7, bsz=40, num_updates=3210, lr=3.46428e-05, gnorm=0.79, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11095
2023-01-06 17:54:42 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 115845 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0303, wps=99.7, ups=0.46, wpb=108.4, bsz=40, num_updates=3220, lr=3.47507e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11117
2023-01-06 17:55:03 - progress_bar.py[line:274] - INFO: epoch 001:   3233 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0214, wps=102.1, ups=0.47, wpb=108.9, bsz=40, num_updates=3230, lr=3.48586e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11139
2023-01-06 17:55:25 - progress_bar.py[line:274] - INFO: epoch 001:   3243 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.024, wps=101.7, ups=0.47, wpb=109.2, bsz=40, num_updates=3240, lr=3.49665e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11161
2023-01-06 17:55:47 - progress_bar.py[line:274] - INFO: epoch 001:   3253 / 115845 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0498, wps=100.4, ups=0.46, wpb=108.9, bsz=40, num_updates=3250, lr=3.50745e-05, gnorm=0.822, clip=30, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11183
2023-01-06 17:56:08 - progress_bar.py[line:274] - INFO: epoch 001:   3263 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0194, wps=102.7, ups=0.47, wpb=108.5, bsz=40, num_updates=3260, lr=3.51824e-05, gnorm=0.741, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11204
2023-01-06 17:56:30 - progress_bar.py[line:274] - INFO: epoch 001:   3273 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0448, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=3270, lr=3.52903e-05, gnorm=0.786, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11226
2023-01-06 17:56:51 - progress_bar.py[line:274] - INFO: epoch 001:   3283 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0383, wps=104.3, ups=0.48, wpb=109.2, bsz=40, num_updates=3280, lr=3.53982e-05, gnorm=0.948, clip=40, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11247
2023-01-06 17:57:13 - progress_bar.py[line:274] - INFO: epoch 001:   3293 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.005, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=3290, lr=3.55062e-05, gnorm=0.821, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11269
2023-01-06 17:57:34 - progress_bar.py[line:274] - INFO: epoch 001:   3303 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0484, wps=103.2, ups=0.47, wpb=109.5, bsz=40, num_updates=3300, lr=3.56141e-05, gnorm=0.807, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11290
2023-01-06 17:57:57 - progress_bar.py[line:274] - INFO: epoch 001:   3313 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.039, wps=97.4, ups=0.45, wpb=108.8, bsz=40, num_updates=3310, lr=3.5722e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=11313
2023-01-06 17:58:19 - progress_bar.py[line:274] - INFO: epoch 001:   3323 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0429, wps=97.1, ups=0.46, wpb=106.6, bsz=40, num_updates=3320, lr=3.58299e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11335
2023-01-06 17:58:41 - progress_bar.py[line:274] - INFO: epoch 001:   3333 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0526, wps=99.2, ups=0.46, wpb=107.7, bsz=40, num_updates=3330, lr=3.59378e-05, gnorm=0.849, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11357
2023-01-06 17:59:03 - progress_bar.py[line:274] - INFO: epoch 001:   3343 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0337, wps=104.6, ups=0.47, wpb=110.9, bsz=40, num_updates=3340, lr=3.60458e-05, gnorm=0.803, clip=30, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11378
2023-01-06 17:59:25 - progress_bar.py[line:274] - INFO: epoch 001:   3353 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0196, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=3350, lr=3.61537e-05, gnorm=0.909, clip=40, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=11400
2023-01-06 17:59:46 - progress_bar.py[line:274] - INFO: epoch 001:   3363 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0193, wps=103.7, ups=0.48, wpb=109.1, bsz=40, num_updates=3360, lr=3.62616e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=11422
2023-01-06 18:00:07 - progress_bar.py[line:274] - INFO: epoch 001:   3373 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0387, wps=105.7, ups=0.48, wpb=109.3, bsz=40, num_updates=3370, lr=3.63695e-05, gnorm=0.945, clip=40, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11443
2023-01-06 18:00:28 - progress_bar.py[line:274] - INFO: epoch 001:   3383 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0688, wps=103.5, ups=0.47, wpb=110.3, bsz=40, num_updates=3380, lr=3.64774e-05, gnorm=0.763, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11464
2023-01-06 18:00:50 - progress_bar.py[line:274] - INFO: epoch 001:   3393 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0102, wps=102.5, ups=0.47, wpb=109.4, bsz=40, num_updates=3390, lr=3.65854e-05, gnorm=0.816, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11486
2023-01-06 18:01:12 - progress_bar.py[line:274] - INFO: epoch 001:   3403 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0376, wps=101.1, ups=0.47, wpb=108.6, bsz=40, num_updates=3400, lr=3.66933e-05, gnorm=0.826, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11507
2023-01-06 18:01:33 - progress_bar.py[line:274] - INFO: epoch 001:   3413 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0296, wps=101.3, ups=0.47, wpb=108.2, bsz=40, num_updates=3410, lr=3.68012e-05, gnorm=0.826, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11529
2023-01-06 18:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   3423 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.029, wps=100.3, ups=0.46, wpb=108.3, bsz=40, num_updates=3420, lr=3.69091e-05, gnorm=0.927, clip=50, loss_scale=512, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=11551
2023-01-06 18:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   3433 / 115845 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0329, wps=102.8, ups=0.47, wpb=108.8, bsz=40, num_updates=3430, lr=3.70171e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11572
2023-01-06 18:02:38 - progress_bar.py[line:274] - INFO: epoch 001:   3443 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0253, wps=103.1, ups=0.47, wpb=109.6, bsz=40, num_updates=3440, lr=3.7125e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11594
2023-01-06 18:03:00 - progress_bar.py[line:274] - INFO: epoch 001:   3453 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0299, wps=101.6, ups=0.46, wpb=109.9, bsz=40, num_updates=3450, lr=3.72329e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11616
2023-01-06 18:03:21 - progress_bar.py[line:274] - INFO: epoch 001:   3463 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0532, wps=104.8, ups=0.47, wpb=110.7, bsz=40, num_updates=3460, lr=3.73408e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11637
2023-01-06 18:03:43 - progress_bar.py[line:274] - INFO: epoch 001:   3473 / 115845 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0338, wps=103.4, ups=0.47, wpb=110, bsz=40, num_updates=3470, lr=3.74487e-05, gnorm=0.74, clip=20, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=11659
2023-01-06 18:04:04 - progress_bar.py[line:274] - INFO: epoch 001:   3483 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0479, wps=103.6, ups=0.47, wpb=109.4, bsz=40, num_updates=3480, lr=3.75567e-05, gnorm=0.709, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11680
2023-01-06 18:04:25 - progress_bar.py[line:274] - INFO: epoch 001:   3493 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.033, wps=103.7, ups=0.48, wpb=109.1, bsz=40, num_updates=3490, lr=3.76646e-05, gnorm=0.701, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11701
2023-01-06 18:04:47 - progress_bar.py[line:274] - INFO: epoch 001:   3503 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0465, wps=100.7, ups=0.46, wpb=108.4, bsz=40, num_updates=3500, lr=3.77725e-05, gnorm=0.782, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11723
2023-01-06 18:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   3513 / 115845 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, vqa_score=0.0308, wps=100.4, ups=0.47, wpb=107.2, bsz=40, num_updates=3510, lr=3.78804e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=11745
2023-01-06 18:05:31 - progress_bar.py[line:274] - INFO: epoch 001:   3523 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.025, wps=101.5, ups=0.46, wpb=110.2, bsz=40, num_updates=3520, lr=3.79883e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11766
2023-01-06 18:05:52 - progress_bar.py[line:274] - INFO: epoch 001:   3533 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0329, wps=101.4, ups=0.47, wpb=107.7, bsz=40, num_updates=3530, lr=3.80963e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11788
2023-01-06 18:06:14 - progress_bar.py[line:274] - INFO: epoch 001:   3543 / 115845 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0237, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=3540, lr=3.82042e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=11810
2023-01-06 18:06:36 - progress_bar.py[line:274] - INFO: epoch 001:   3553 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0155, wps=101.3, ups=0.46, wpb=110.5, bsz=40, num_updates=3550, lr=3.83121e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=11832
2023-01-06 18:06:58 - progress_bar.py[line:274] - INFO: epoch 001:   3563 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0309, wps=102.4, ups=0.47, wpb=109.8, bsz=40, num_updates=3560, lr=3.842e-05, gnorm=0.736, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11853
2023-01-06 18:07:19 - progress_bar.py[line:274] - INFO: epoch 001:   3573 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0372, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=3570, lr=3.8528e-05, gnorm=0.738, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=11875
2023-01-06 18:07:41 - progress_bar.py[line:274] - INFO: epoch 001:   3583 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.024, wps=100.9, ups=0.47, wpb=107.7, bsz=40, num_updates=3580, lr=3.86359e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=11897
2023-01-06 18:08:03 - progress_bar.py[line:274] - INFO: epoch 001:   3593 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0489, wps=103.2, ups=0.47, wpb=109.9, bsz=40, num_updates=3590, lr=3.87438e-05, gnorm=0.764, clip=30, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=11918
2023-01-06 18:08:24 - progress_bar.py[line:274] - INFO: epoch 001:   3603 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0448, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=3600, lr=3.88517e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11940
2023-01-06 18:08:46 - progress_bar.py[line:274] - INFO: epoch 001:   3613 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0248, wps=102.5, ups=0.47, wpb=109.1, bsz=40, num_updates=3610, lr=3.89596e-05, gnorm=0.758, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=11962
2023-01-06 18:09:08 - progress_bar.py[line:274] - INFO: epoch 001:   3623 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0415, wps=102.3, ups=0.46, wpb=110.3, bsz=40, num_updates=3620, lr=3.90676e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=11984
2023-01-06 18:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   3633 / 115845 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0394, wps=99.2, ups=0.46, wpb=107.8, bsz=40, num_updates=3630, lr=3.91755e-05, gnorm=0.674, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12006
2023-01-06 18:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   3643 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0404, wps=99.8, ups=0.46, wpb=108.5, bsz=40, num_updates=3640, lr=3.92834e-05, gnorm=0.726, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=12028
2023-01-06 18:10:14 - progress_bar.py[line:274] - INFO: epoch 001:   3653 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0321, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=3650, lr=3.93913e-05, gnorm=0.693, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12050
2023-01-06 18:10:35 - progress_bar.py[line:274] - INFO: epoch 001:   3663 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0197, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=3660, lr=3.94992e-05, gnorm=0.752, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12071
2023-01-06 18:10:57 - progress_bar.py[line:274] - INFO: epoch 001:   3673 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0439, wps=102.3, ups=0.47, wpb=109.5, bsz=40, num_updates=3670, lr=3.96072e-05, gnorm=0.702, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12093
2023-01-06 18:11:19 - progress_bar.py[line:274] - INFO: epoch 001:   3683 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0155, wps=102.4, ups=0.47, wpb=110, bsz=40, num_updates=3680, lr=3.97151e-05, gnorm=0.751, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12115
2023-01-06 18:11:40 - progress_bar.py[line:274] - INFO: epoch 001:   3693 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0215, wps=103.7, ups=0.47, wpb=110, bsz=40, num_updates=3690, lr=3.9823e-05, gnorm=0.871, clip=30, loss_scale=1024, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=12136
2023-01-06 18:12:02 - progress_bar.py[line:274] - INFO: epoch 001:   3703 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0284, wps=103.4, ups=0.47, wpb=109.6, bsz=40, num_updates=3700, lr=3.99309e-05, gnorm=0.696, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12158
2023-01-06 18:12:23 - progress_bar.py[line:274] - INFO: epoch 001:   3713 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0299, wps=104.5, ups=0.48, wpb=109.8, bsz=40, num_updates=3710, lr=4.00389e-05, gnorm=0.723, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12179
2023-01-06 18:12:44 - progress_bar.py[line:274] - INFO: epoch 001:   3723 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0209, wps=103.4, ups=0.47, wpb=109.7, bsz=40, num_updates=3720, lr=4.01468e-05, gnorm=0.718, clip=10, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=12200
2023-01-06 18:13:06 - progress_bar.py[line:274] - INFO: epoch 001:   3733 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0303, wps=101.1, ups=0.46, wpb=109.9, bsz=40, num_updates=3730, lr=4.02547e-05, gnorm=0.595, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=12222
2023-01-06 18:13:28 - progress_bar.py[line:274] - INFO: epoch 001:   3743 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0512, wps=99.5, ups=0.46, wpb=107.5, bsz=40, num_updates=3740, lr=4.03626e-05, gnorm=0.822, clip=10, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=12244
2023-01-06 18:13:43 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 18:13:52 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0299, wps=97.4, ups=0.43, wpb=109, bsz=40, num_updates=3750, lr=4.04705e-05, gnorm=0.675, clip=0, loss_scale=512, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=12268
2023-01-06 18:14:13 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.051, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=3760, lr=4.05785e-05, gnorm=0.738, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=12289
2023-01-06 18:14:35 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0337, wps=101.6, ups=0.47, wpb=108.6, bsz=40, num_updates=3770, lr=4.06864e-05, gnorm=0.828, clip=30, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12311
2023-01-06 18:14:57 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0532, wps=101.3, ups=0.46, wpb=110.4, bsz=40, num_updates=3780, lr=4.07943e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12333
2023-01-06 18:15:19 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0191, wps=99.3, ups=0.46, wpb=108.3, bsz=40, num_updates=3790, lr=4.09022e-05, gnorm=0.696, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12355
2023-01-06 18:15:41 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0355, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=3800, lr=4.10101e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12377
2023-01-06 18:16:03 - progress_bar.py[line:274] - INFO: epoch 001:   3814 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0203, wps=101.1, ups=0.47, wpb=108.4, bsz=40, num_updates=3810, lr=4.11181e-05, gnorm=0.804, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12398
2023-01-06 18:16:24 - progress_bar.py[line:274] - INFO: epoch 001:   3824 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0464, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=3820, lr=4.1226e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=12420
2023-01-06 18:16:46 - progress_bar.py[line:274] - INFO: epoch 001:   3834 / 115845 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0362, wps=100.7, ups=0.47, wpb=107.7, bsz=40, num_updates=3830, lr=4.13339e-05, gnorm=0.828, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12442
2023-01-06 18:17:08 - progress_bar.py[line:274] - INFO: epoch 001:   3844 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0455, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=3840, lr=4.14418e-05, gnorm=0.781, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12464
2023-01-06 18:17:30 - progress_bar.py[line:274] - INFO: epoch 001:   3854 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0363, wps=101.7, ups=0.47, wpb=109, bsz=40, num_updates=3850, lr=4.15498e-05, gnorm=0.622, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12485
2023-01-06 18:17:51 - progress_bar.py[line:274] - INFO: epoch 001:   3864 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0309, wps=102.3, ups=0.47, wpb=108.9, bsz=40, num_updates=3860, lr=4.16577e-05, gnorm=0.601, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=12507
2023-01-06 18:18:13 - progress_bar.py[line:274] - INFO: epoch 001:   3874 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0329, wps=101.3, ups=0.47, wpb=108.2, bsz=40, num_updates=3870, lr=4.17656e-05, gnorm=0.734, clip=10, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=12529
2023-01-06 18:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   3884 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.051, wps=102.4, ups=0.47, wpb=108.8, bsz=40, num_updates=3880, lr=4.18735e-05, gnorm=0.859, clip=30, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=12550
2023-01-06 18:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   3894 / 115845 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0346, wps=99.5, ups=0.47, wpb=106.9, bsz=40, num_updates=3890, lr=4.19814e-05, gnorm=0.795, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12572
2023-01-06 18:19:18 - progress_bar.py[line:274] - INFO: epoch 001:   3904 / 115845 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0053, wps=101.2, ups=0.46, wpb=109.8, bsz=40, num_updates=3900, lr=4.20894e-05, gnorm=0.934, clip=50, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=12594
2023-01-06 18:19:39 - progress_bar.py[line:274] - INFO: epoch 001:   3914 / 115845 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0235, wps=102.9, ups=0.47, wpb=108.7, bsz=40, num_updates=3910, lr=4.21973e-05, gnorm=0.658, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12615
2023-01-06 18:20:01 - progress_bar.py[line:274] - INFO: epoch 001:   3924 / 115845 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0253, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=3920, lr=4.23052e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=12637
2023-01-06 18:20:22 - progress_bar.py[line:274] - INFO: epoch 001:   3934 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0102, wps=101.7, ups=0.47, wpb=109.1, bsz=40, num_updates=3930, lr=4.24131e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=12658
2023-01-06 18:20:44 - progress_bar.py[line:274] - INFO: epoch 001:   3944 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0376, wps=99.9, ups=0.46, wpb=109, bsz=40, num_updates=3940, lr=4.2521e-05, gnorm=0.706, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=12680
2023-01-06 18:21:07 - progress_bar.py[line:274] - INFO: epoch 001:   3954 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0251, wps=100.3, ups=0.45, wpb=110.6, bsz=40, num_updates=3950, lr=4.2629e-05, gnorm=0.627, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12703
2023-01-06 18:21:28 - progress_bar.py[line:274] - INFO: epoch 001:   3964 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0408, wps=103, ups=0.46, wpb=110.9, bsz=40, num_updates=3960, lr=4.27369e-05, gnorm=0.694, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12724
2023-01-06 18:21:50 - progress_bar.py[line:274] - INFO: epoch 001:   3974 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0653, wps=100.6, ups=0.46, wpb=108.7, bsz=40, num_updates=3970, lr=4.28448e-05, gnorm=0.723, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=12746
2023-01-06 18:22:12 - progress_bar.py[line:274] - INFO: epoch 001:   3984 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0365, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=3980, lr=4.29527e-05, gnorm=0.609, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=12768
2023-01-06 18:22:34 - progress_bar.py[line:274] - INFO: epoch 001:   3994 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0466, wps=101.2, ups=0.46, wpb=109.8, bsz=40, num_updates=3990, lr=4.30607e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=12790
2023-01-06 18:22:56 - progress_bar.py[line:274] - INFO: epoch 001:   4004 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0603, wps=101, ups=0.46, wpb=109.5, bsz=40, num_updates=4000, lr=4.31686e-05, gnorm=0.709, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=12812
2023-01-06 18:22:56 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-06 18:22:57 - train.py[line:549] - INFO: 0 / 4988
2023-01-06 18:22:57 - train.py[line:551] - INFO: load:1.24 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-06 18:25:31 - train.py[line:549] - INFO: 200 / 4988
2023-01-06 18:25:31 - train.py[line:551] - INFO: load:1.27 valid_run:153.44 task_valid:149.30 collect_output:3.06
2023-01-06 18:28:00 - train.py[line:549] - INFO: 400 / 4988
2023-01-06 18:28:00 - train.py[line:551] - INFO: load:1.29 valid_run:303.00 task_valid:292.40 collect_output:8.49
2023-01-06 18:30:35 - train.py[line:549] - INFO: 600 / 4988
2023-01-06 18:30:35 - train.py[line:551] - INFO: load:1.32 valid_run:457.05 task_valid:435.52 collect_output:18.36
2023-01-06 18:33:05 - train.py[line:549] - INFO: 800 / 4988
2023-01-06 18:33:05 - train.py[line:551] - INFO: load:1.34 valid_run:607.09 task_valid:580.58 collect_output:22.32
2023-01-06 18:35:38 - train.py[line:549] - INFO: 1000 / 4988
2023-01-06 18:35:38 - train.py[line:551] - INFO: load:1.37 valid_run:760.31 task_valid:728.17 collect_output:26.92
2023-01-06 18:38:11 - train.py[line:549] - INFO: 1200 / 4988
2023-01-06 18:38:11 - train.py[line:551] - INFO: load:1.40 valid_run:912.92 task_valid:873.75 collect_output:32.94
2023-01-06 18:40:45 - train.py[line:549] - INFO: 1400 / 4988
2023-01-06 18:40:45 - train.py[line:551] - INFO: load:1.43 valid_run:1067.48 task_valid:1019.70 collect_output:40.51
2023-01-06 18:43:18 - train.py[line:549] - INFO: 1600 / 4988
2023-01-06 18:43:18 - train.py[line:551] - INFO: load:1.45 valid_run:1219.77 task_valid:1160.61 collect_output:50.87
2023-01-06 18:45:48 - train.py[line:549] - INFO: 1800 / 4988
2023-01-06 18:45:48 - train.py[line:551] - INFO: load:1.48 valid_run:1370.53 task_valid:1305.29 collect_output:55.93
2023-01-06 18:48:18 - train.py[line:549] - INFO: 2000 / 4988
2023-01-06 18:48:18 - train.py[line:551] - INFO: load:1.50 valid_run:1519.94 task_valid:1448.45 collect_output:61.15
2023-01-06 18:50:48 - train.py[line:549] - INFO: 2200 / 4988
2023-01-06 18:50:48 - train.py[line:551] - INFO: load:1.53 valid_run:1670.18 task_valid:1593.09 collect_output:65.74
2023-01-06 18:53:19 - train.py[line:549] - INFO: 2400 / 4988
2023-01-06 18:53:19 - train.py[line:551] - INFO: load:1.55 valid_run:1820.96 task_valid:1738.15 collect_output:70.41
2023-01-06 18:55:50 - train.py[line:549] - INFO: 2600 / 4988
2023-01-06 18:55:50 - train.py[line:551] - INFO: load:1.58 valid_run:1971.86 task_valid:1879.78 collect_output:78.65
2023-01-06 18:58:21 - train.py[line:549] - INFO: 2800 / 4988
2023-01-06 18:58:21 - train.py[line:551] - INFO: load:1.61 valid_run:2122.93 task_valid:2025.08 collect_output:83.39
2023-01-06 19:00:52 - train.py[line:549] - INFO: 3000 / 4988
2023-01-06 19:00:52 - train.py[line:551] - INFO: load:1.63 valid_run:2273.39 task_valid:2171.51 collect_output:86.37
2023-01-06 19:03:23 - train.py[line:549] - INFO: 3200 / 4988
2023-01-06 19:03:23 - train.py[line:551] - INFO: load:1.66 valid_run:2424.12 task_valid:2315.82 collect_output:91.77
2023-01-06 19:05:55 - train.py[line:549] - INFO: 3400 / 4988
2023-01-06 19:05:55 - train.py[line:551] - INFO: load:1.68 valid_run:2576.70 task_valid:2461.46 collect_output:97.68
2023-01-06 19:08:26 - train.py[line:549] - INFO: 3600 / 4988
2023-01-06 19:08:26 - train.py[line:551] - INFO: load:1.71 valid_run:2727.67 task_valid:2608.46 collect_output:100.62
2023-01-06 19:10:56 - train.py[line:549] - INFO: 3800 / 4988
2023-01-06 19:10:56 - train.py[line:551] - INFO: load:1.74 valid_run:2877.01 task_valid:2750.17 collect_output:107.19
2023-01-06 19:13:27 - train.py[line:549] - INFO: 4000 / 4988
2023-01-06 19:13:27 - train.py[line:551] - INFO: load:1.76 valid_run:3028.28 task_valid:2895.50 collect_output:112.10
2023-01-06 19:16:00 - train.py[line:549] - INFO: 4200 / 4988
2023-01-06 19:16:00 - train.py[line:551] - INFO: load:1.79 valid_run:3181.06 task_valid:3040.02 collect_output:119.29
2023-01-06 19:18:30 - train.py[line:549] - INFO: 4400 / 4988
2023-01-06 19:18:30 - train.py[line:551] - INFO: load:1.81 valid_run:3331.02 task_valid:3184.52 collect_output:123.76
2023-01-06 19:21:02 - train.py[line:549] - INFO: 4600 / 4988
2023-01-06 19:21:02 - train.py[line:551] - INFO: load:1.84 valid_run:3483.14 task_valid:3330.88 collect_output:128.46
2023-01-06 19:23:36 - train.py[line:549] - INFO: 4800 / 4988
2023-01-06 19:23:36 - train.py[line:551] - INFO: load:1.86 valid_run:3636.66 task_valid:3479.00 collect_output:132.76

====================================================================================================
SGG eval:     R @ 50: 0.5171;     R @ 100: 0.5749;     R @ 500: 0.6274;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3012;    mR @ 100: 0.3833;    mR @ 500: 0.4411;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.1875) (covering:0.5429) (eating:0.7059) (flying in:0.8182) (growing on:0.5000) (hanging from:0.4516) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6667) (playing:0.0000) (riding:0.7761) (says:0.0000) (sitting on:0.6769) (standing on:0.4250) (using:0.4000) (walking in:0.0000) (walking on:0.5811) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-01-06 19:26:07 - train.py[line:487] - INFO: 0.5748822510822511
2023-01-06 19:26:07 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.5171;     R @ 100: 0.5749;     R @ 500: 0.6274;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3012;    mR @ 100: 0.3833;    mR @ 500: 0.4411;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5927) (covered in:0.1875) (covering:0.5429) (eating:0.7059) (flying in:0.8182) (growing on:0.5000) (hanging from:0.4516) (lying on:0.0500) (mounted on:0.0000) (painted on:0.0833) (parked on:0.6667) (playing:0.0000) (riding:0.7761) (says:0.0000) (sitting on:0.6769) (standing on:0.4250) (using:0.4000) (walking in:0.0000) (walking on:0.5811) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-01-06 19:26:08 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.363 | loss_v1 0 | loss_v2 0 | nll_loss 0.216 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.574882 | ppl 1.16 | vqa_score 0.3108 | wps 118.4 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.574882
2023-01-06 19:26:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2023-01-06 19:26:08 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt
2023-01-06 19:26:49 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt
2023-01-06 19:29:52 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.5748822510822511) (writing took 224.12285561300814 seconds)
2023-01-06 19:30:14 - progress_bar.py[line:274] - INFO: epoch 001:   4014 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0326, wps=0.5, ups=0, wpb=109.1, bsz=40, num_updates=4010, lr=4.32765e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=16850
2023-01-06 19:30:36 - progress_bar.py[line:274] - INFO: epoch 001:   4024 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0199, wps=103, ups=0.47, wpb=109.2, bsz=40, num_updates=4020, lr=4.33844e-05, gnorm=0.781, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=16872
2023-01-06 19:30:58 - progress_bar.py[line:274] - INFO: epoch 001:   4034 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0521, wps=102.6, ups=0.47, wpb=108.3, bsz=40, num_updates=4030, lr=4.34923e-05, gnorm=0.658, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=16893
2023-01-06 19:31:20 - progress_bar.py[line:274] - INFO: epoch 001:   4044 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0441, wps=99, ups=0.45, wpb=109.3, bsz=40, num_updates=4040, lr=4.36003e-05, gnorm=0.67, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=16916
2023-01-06 19:31:42 - progress_bar.py[line:274] - INFO: epoch 001:   4054 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0392, wps=100.3, ups=0.46, wpb=108.4, bsz=40, num_updates=4050, lr=4.37082e-05, gnorm=0.664, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=16938
2023-01-06 19:32:04 - progress_bar.py[line:274] - INFO: epoch 001:   4064 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0481, wps=99.4, ups=0.46, wpb=108.9, bsz=40, num_updates=4060, lr=4.38161e-05, gnorm=0.678, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=16960
2023-01-06 19:32:26 - progress_bar.py[line:274] - INFO: epoch 001:   4074 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0311, wps=101.2, ups=0.46, wpb=110.3, bsz=40, num_updates=4070, lr=4.3924e-05, gnorm=0.77, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=16982
2023-01-06 19:32:49 - progress_bar.py[line:274] - INFO: epoch 001:   4084 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0513, wps=100, ups=0.46, wpb=109.3, bsz=40, num_updates=4080, lr=4.40319e-05, gnorm=0.793, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=17004
2023-01-06 19:33:10 - progress_bar.py[line:274] - INFO: epoch 001:   4094 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0415, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=4090, lr=4.41399e-05, gnorm=0.724, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17026
2023-01-06 19:33:32 - progress_bar.py[line:274] - INFO: epoch 001:   4104 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0265, wps=102.9, ups=0.47, wpb=109, bsz=40, num_updates=4100, lr=4.42478e-05, gnorm=0.747, clip=30, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17048
2023-01-06 19:33:54 - progress_bar.py[line:274] - INFO: epoch 001:   4114 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0447, wps=103.4, ups=0.47, wpb=110.4, bsz=40, num_updates=4110, lr=4.43557e-05, gnorm=0.7, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17070
2023-01-06 19:34:16 - progress_bar.py[line:274] - INFO: epoch 001:   4124 / 115845 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0457, wps=98.4, ups=0.46, wpb=107.5, bsz=40, num_updates=4120, lr=4.44636e-05, gnorm=0.705, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17092
2023-01-06 19:34:38 - progress_bar.py[line:274] - INFO: epoch 001:   4134 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0354, wps=103.5, ups=0.47, wpb=109.7, bsz=40, num_updates=4130, lr=4.45716e-05, gnorm=0.739, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17113
2023-01-06 19:35:00 - progress_bar.py[line:274] - INFO: epoch 001:   4144 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0377, wps=99.3, ups=0.45, wpb=109.3, bsz=40, num_updates=4140, lr=4.46795e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17136
2023-01-06 19:35:22 - progress_bar.py[line:274] - INFO: epoch 001:   4154 / 115845 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0508, wps=98.4, ups=0.45, wpb=109.4, bsz=40, num_updates=4150, lr=4.47874e-05, gnorm=0.712, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17158
2023-01-06 19:35:44 - progress_bar.py[line:274] - INFO: epoch 001:   4164 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.028, wps=101, ups=0.47, wpb=108.3, bsz=40, num_updates=4160, lr=4.48953e-05, gnorm=0.794, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17180
2023-01-06 19:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   4174 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0101, wps=104.7, ups=0.48, wpb=110, bsz=40, num_updates=4170, lr=4.50032e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17201
2023-01-06 19:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   4184 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0319, wps=100.7, ups=0.46, wpb=109.2, bsz=40, num_updates=4180, lr=4.51112e-05, gnorm=0.686, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=17223
2023-01-06 19:36:50 - progress_bar.py[line:274] - INFO: epoch 001:   4194 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0561, wps=100.3, ups=0.46, wpb=108.3, bsz=40, num_updates=4190, lr=4.52191e-05, gnorm=0.732, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17245
2023-01-06 19:37:11 - progress_bar.py[line:274] - INFO: epoch 001:   4204 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0558, wps=102.6, ups=0.47, wpb=108.9, bsz=40, num_updates=4200, lr=4.5327e-05, gnorm=0.678, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17267
2023-01-06 19:37:33 - progress_bar.py[line:274] - INFO: epoch 001:   4214 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0545, wps=101.2, ups=0.47, wpb=108.5, bsz=40, num_updates=4210, lr=4.54349e-05, gnorm=0.613, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17289
2023-01-06 19:37:54 - progress_bar.py[line:274] - INFO: epoch 001:   4224 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0711, wps=102, ups=0.47, wpb=107.9, bsz=40, num_updates=4220, lr=4.55428e-05, gnorm=0.657, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17310
2023-01-06 19:38:16 - progress_bar.py[line:274] - INFO: epoch 001:   4234 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0441, wps=103.1, ups=0.47, wpb=109.2, bsz=40, num_updates=4230, lr=4.56508e-05, gnorm=0.691, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17332
2023-01-06 19:38:37 - progress_bar.py[line:274] - INFO: epoch 001:   4244 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0335, wps=100.9, ups=0.47, wpb=107.5, bsz=40, num_updates=4240, lr=4.57587e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17353
2023-01-06 19:38:59 - progress_bar.py[line:274] - INFO: epoch 001:   4254 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0542, wps=103.5, ups=0.47, wpb=109.3, bsz=40, num_updates=4250, lr=4.58666e-05, gnorm=0.827, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17375
2023-01-06 19:39:21 - progress_bar.py[line:274] - INFO: epoch 001:   4264 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0463, wps=101.3, ups=0.47, wpb=108, bsz=40, num_updates=4260, lr=4.59745e-05, gnorm=0.783, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17396
2023-01-06 19:39:42 - progress_bar.py[line:274] - INFO: epoch 001:   4274 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0338, wps=100.1, ups=0.46, wpb=108.1, bsz=40, num_updates=4270, lr=4.60825e-05, gnorm=0.843, clip=30, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17418
2023-01-06 19:40:04 - progress_bar.py[line:274] - INFO: epoch 001:   4284 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0498, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=4280, lr=4.61904e-05, gnorm=0.75, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=17440
2023-01-06 19:40:26 - progress_bar.py[line:274] - INFO: epoch 001:   4294 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0664, wps=100.5, ups=0.46, wpb=108.3, bsz=40, num_updates=4290, lr=4.62983e-05, gnorm=0.682, clip=10, loss_scale=1024, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=17462
2023-01-06 19:40:48 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 19:40:50 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 115845 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.19, nsentences=40, sample_size=109.19, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0369, wps=96.2, ups=0.42, wpb=109.2, bsz=40, num_updates=4300, lr=4.64062e-05, gnorm=0.678, clip=10, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=17486
2023-01-06 19:41:12 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.041, wps=101, ups=0.46, wpb=109.3, bsz=40, num_updates=4310, lr=4.65141e-05, gnorm=0.721, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17508
2023-01-06 19:41:34 - progress_bar.py[line:274] - INFO: epoch 001:   4325 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0455, wps=102.8, ups=0.47, wpb=108.6, bsz=40, num_updates=4320, lr=4.66221e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17529
2023-01-06 19:41:55 - progress_bar.py[line:274] - INFO: epoch 001:   4335 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0312, wps=102.1, ups=0.46, wpb=110.2, bsz=40, num_updates=4330, lr=4.673e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17551
2023-01-06 19:42:17 - progress_bar.py[line:274] - INFO: epoch 001:   4345 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0455, wps=99.4, ups=0.46, wpb=108.2, bsz=40, num_updates=4340, lr=4.68379e-05, gnorm=0.71, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17573
2023-01-06 19:42:39 - progress_bar.py[line:274] - INFO: epoch 001:   4355 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0357, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=4350, lr=4.69458e-05, gnorm=0.715, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17595
2023-01-06 19:43:01 - progress_bar.py[line:274] - INFO: epoch 001:   4365 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0446, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=4360, lr=4.70537e-05, gnorm=0.681, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=17617
2023-01-06 19:43:23 - progress_bar.py[line:274] - INFO: epoch 001:   4375 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0328, wps=105.9, ups=0.48, wpb=110.6, bsz=40, num_updates=4370, lr=4.71617e-05, gnorm=0.763, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=17638
2023-01-06 19:43:44 - progress_bar.py[line:274] - INFO: epoch 001:   4385 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0306, wps=105.3, ups=0.48, wpb=109.6, bsz=40, num_updates=4380, lr=4.72696e-05, gnorm=0.627, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17660
2023-01-06 19:44:06 - progress_bar.py[line:274] - INFO: epoch 001:   4395 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0153, wps=102.6, ups=0.47, wpb=109.1, bsz=40, num_updates=4390, lr=4.73775e-05, gnorm=0.622, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17682
2023-01-06 19:44:28 - progress_bar.py[line:274] - INFO: epoch 001:   4405 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0634, wps=99.8, ups=0.46, wpb=107.8, bsz=40, num_updates=4400, lr=4.74854e-05, gnorm=0.614, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17704
2023-01-06 19:44:50 - progress_bar.py[line:274] - INFO: epoch 001:   4415 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0193, wps=99.1, ups=0.46, wpb=108.2, bsz=40, num_updates=4410, lr=4.75934e-05, gnorm=0.723, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=17726
2023-01-06 19:45:12 - progress_bar.py[line:274] - INFO: epoch 001:   4425 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0348, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=4420, lr=4.77013e-05, gnorm=0.622, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17747
2023-01-06 19:45:33 - progress_bar.py[line:274] - INFO: epoch 001:   4435 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0439, wps=100.5, ups=0.47, wpb=108, bsz=40, num_updates=4430, lr=4.78092e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17769
2023-01-06 19:45:55 - progress_bar.py[line:274] - INFO: epoch 001:   4445 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0205, wps=100.4, ups=0.46, wpb=108.7, bsz=40, num_updates=4440, lr=4.79171e-05, gnorm=0.738, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17791
2023-01-06 19:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   4455 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0376, wps=99.6, ups=0.46, wpb=109.3, bsz=40, num_updates=4450, lr=4.8025e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=17813
2023-01-06 19:46:39 - progress_bar.py[line:274] - INFO: epoch 001:   4465 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0379, wps=99.5, ups=0.46, wpb=108.5, bsz=40, num_updates=4460, lr=4.8133e-05, gnorm=0.597, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17835
2023-01-06 19:47:01 - progress_bar.py[line:274] - INFO: epoch 001:   4475 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0357, wps=100.3, ups=0.46, wpb=108.4, bsz=40, num_updates=4470, lr=4.82409e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=17857
2023-01-06 19:47:23 - progress_bar.py[line:274] - INFO: epoch 001:   4485 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0603, wps=101.7, ups=0.47, wpb=108.4, bsz=40, num_updates=4480, lr=4.83488e-05, gnorm=0.717, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17879
2023-01-06 19:47:45 - progress_bar.py[line:274] - INFO: epoch 001:   4495 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0704, wps=103.3, ups=0.47, wpb=110.5, bsz=40, num_updates=4490, lr=4.84567e-05, gnorm=0.66, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=17900
2023-01-06 19:48:06 - progress_bar.py[line:274] - INFO: epoch 001:   4505 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0352, wps=103.1, ups=0.48, wpb=108.4, bsz=40, num_updates=4500, lr=4.85646e-05, gnorm=0.686, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=17922
2023-01-06 19:48:28 - progress_bar.py[line:274] - INFO: epoch 001:   4515 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0683, wps=98.6, ups=0.46, wpb=108, bsz=40, num_updates=4510, lr=4.86726e-05, gnorm=0.661, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=17944
2023-01-06 19:48:50 - progress_bar.py[line:274] - INFO: epoch 001:   4525 / 115845 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0392, wps=101.5, ups=0.47, wpb=108.1, bsz=40, num_updates=4520, lr=4.87805e-05, gnorm=0.644, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=17966
2023-01-06 19:49:12 - progress_bar.py[line:274] - INFO: epoch 001:   4535 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.04, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=4530, lr=4.88884e-05, gnorm=0.625, clip=0, loss_scale=512, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=17987
2023-01-06 19:49:33 - progress_bar.py[line:274] - INFO: epoch 001:   4545 / 115845 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0291, wps=101.2, ups=0.47, wpb=108.2, bsz=40, num_updates=4540, lr=4.89963e-05, gnorm=0.703, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18009
2023-01-06 19:49:55 - progress_bar.py[line:274] - INFO: epoch 001:   4555 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0201, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=4550, lr=4.91043e-05, gnorm=0.615, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18031
2023-01-06 19:50:17 - progress_bar.py[line:274] - INFO: epoch 001:   4565 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0529, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=4560, lr=4.92122e-05, gnorm=0.599, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18053
2023-01-06 19:50:39 - progress_bar.py[line:274] - INFO: epoch 001:   4575 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0462, wps=100.4, ups=0.46, wpb=109.2, bsz=40, num_updates=4570, lr=4.93201e-05, gnorm=0.693, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=18075
2023-01-06 19:51:02 - progress_bar.py[line:274] - INFO: epoch 001:   4585 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0439, wps=101.9, ups=0.46, wpb=110.3, bsz=40, num_updates=4580, lr=4.9428e-05, gnorm=0.688, clip=10, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=18097
2023-01-06 19:51:24 - progress_bar.py[line:274] - INFO: epoch 001:   4595 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.034, wps=101, ups=0.47, wpb=108.5, bsz=40, num_updates=4590, lr=4.95359e-05, gnorm=0.583, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18120
2023-01-06 19:51:46 - progress_bar.py[line:274] - INFO: epoch 001:   4605 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0606, wps=100.8, ups=0.46, wpb=109.2, bsz=40, num_updates=4600, lr=4.96439e-05, gnorm=0.628, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18141
2023-01-06 19:52:07 - progress_bar.py[line:274] - INFO: epoch 001:   4615 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.061, wps=100.2, ups=0.47, wpb=106.5, bsz=40, num_updates=4610, lr=4.97518e-05, gnorm=0.652, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18163
2023-01-06 19:52:29 - progress_bar.py[line:274] - INFO: epoch 001:   4625 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0343, wps=103.4, ups=0.48, wpb=108.8, bsz=40, num_updates=4620, lr=4.98597e-05, gnorm=0.641, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18184
2023-01-06 19:52:50 - progress_bar.py[line:274] - INFO: epoch 001:   4635 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0203, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=4630, lr=4.99676e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18206
2023-01-06 19:53:12 - progress_bar.py[line:274] - INFO: epoch 001:   4645 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0534, wps=101.2, ups=0.46, wpb=109.2, bsz=40, num_updates=4640, lr=4.99969e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18228
2023-01-06 19:53:33 - progress_bar.py[line:274] - INFO: epoch 001:   4655 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0657, wps=102.6, ups=0.47, wpb=108.6, bsz=40, num_updates=4650, lr=4.99924e-05, gnorm=0.678, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18249
2023-01-06 19:53:55 - progress_bar.py[line:274] - INFO: epoch 001:   4665 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.041, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=4660, lr=4.99879e-05, gnorm=0.628, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18271
2023-01-06 19:54:17 - progress_bar.py[line:274] - INFO: epoch 001:   4675 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0683, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=4670, lr=4.99834e-05, gnorm=0.586, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=18293
2023-01-06 19:54:39 - progress_bar.py[line:274] - INFO: epoch 001:   4685 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0374, wps=100.4, ups=0.47, wpb=107.8, bsz=40, num_updates=4680, lr=4.99789e-05, gnorm=0.62, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18314
2023-01-06 19:55:00 - progress_bar.py[line:274] - INFO: epoch 001:   4695 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0314, wps=102.4, ups=0.47, wpb=110.1, bsz=40, num_updates=4690, lr=4.99744e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18336
2023-01-06 19:55:22 - progress_bar.py[line:274] - INFO: epoch 001:   4705 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0312, wps=100.2, ups=0.46, wpb=108, bsz=40, num_updates=4700, lr=4.99699e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18358
2023-01-06 19:55:44 - progress_bar.py[line:274] - INFO: epoch 001:   4715 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0785, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=4710, lr=4.99654e-05, gnorm=0.588, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18380
2023-01-06 19:56:06 - progress_bar.py[line:274] - INFO: epoch 001:   4725 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0452, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=4720, lr=4.99609e-05, gnorm=0.647, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18402
2023-01-06 19:56:28 - progress_bar.py[line:274] - INFO: epoch 001:   4735 / 115845 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, vqa_score=0.0588, wps=100.1, ups=0.46, wpb=107.7, bsz=40, num_updates=4730, lr=4.99564e-05, gnorm=0.751, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=18424
2023-01-06 19:56:50 - progress_bar.py[line:274] - INFO: epoch 001:   4745 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0606, wps=99.1, ups=0.46, wpb=108.9, bsz=40, num_updates=4740, lr=4.99519e-05, gnorm=0.659, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18446
2023-01-06 19:57:12 - progress_bar.py[line:274] - INFO: epoch 001:   4755 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0348, wps=102.5, ups=0.47, wpb=110, bsz=40, num_updates=4750, lr=4.99474e-05, gnorm=0.744, clip=30, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=18468
2023-01-06 19:57:34 - progress_bar.py[line:274] - INFO: epoch 001:   4765 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0576, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=4760, lr=4.99429e-05, gnorm=0.549, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18489
2023-01-06 19:57:56 - progress_bar.py[line:274] - INFO: epoch 001:   4775 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0538, wps=101.4, ups=0.46, wpb=109.4, bsz=40, num_updates=4770, lr=4.99384e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18511
2023-01-06 19:58:17 - progress_bar.py[line:274] - INFO: epoch 001:   4785 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0483, wps=101.4, ups=0.47, wpb=107.8, bsz=40, num_updates=4780, lr=4.99339e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18533
2023-01-06 19:58:39 - progress_bar.py[line:274] - INFO: epoch 001:   4795 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0271, wps=98.1, ups=0.46, wpb=107.6, bsz=40, num_updates=4790, lr=4.99294e-05, gnorm=0.56, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18555
2023-01-06 19:59:02 - progress_bar.py[line:274] - INFO: epoch 001:   4805 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0753, wps=100.2, ups=0.45, wpb=110.4, bsz=40, num_updates=4800, lr=4.99249e-05, gnorm=0.618, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18578
2023-01-06 19:59:24 - progress_bar.py[line:274] - INFO: epoch 001:   4815 / 115845 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0619, wps=100, ups=0.46, wpb=109.4, bsz=40, num_updates=4810, lr=4.99204e-05, gnorm=0.633, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18600
2023-01-06 19:59:46 - progress_bar.py[line:274] - INFO: epoch 001:   4825 / 115845 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0493, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=4820, lr=4.99159e-05, gnorm=0.64, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18622
2023-01-06 20:00:08 - progress_bar.py[line:274] - INFO: epoch 001:   4835 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0597, wps=100.5, ups=0.46, wpb=109.9, bsz=40, num_updates=4830, lr=4.99114e-05, gnorm=0.563, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18644
2023-01-06 20:00:30 - progress_bar.py[line:274] - INFO: epoch 001:   4845 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0622, wps=102.2, ups=0.47, wpb=108.3, bsz=40, num_updates=4840, lr=4.99069e-05, gnorm=0.697, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=18665
2023-01-06 20:00:52 - progress_bar.py[line:274] - INFO: epoch 001:   4855 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0469, wps=98.7, ups=0.46, wpb=107.5, bsz=40, num_updates=4850, lr=4.99024e-05, gnorm=0.644, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18687
2023-01-06 20:01:15 - progress_bar.py[line:274] - INFO: epoch 001:   4865 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0725, wps=98.6, ups=0.46, wpb=108.3, bsz=40, num_updates=4860, lr=4.98979e-05, gnorm=0.643, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18710
2023-01-06 20:01:38 - progress_bar.py[line:274] - INFO: epoch 001:   4875 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0461, wps=99.8, ups=0.46, wpb=107.6, bsz=40, num_updates=4870, lr=4.98934e-05, gnorm=0.646, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18733
2023-01-06 20:02:00 - progress_bar.py[line:274] - INFO: epoch 001:   4885 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.05, wps=104.2, ups=0.48, wpb=109.5, bsz=40, num_updates=4880, lr=4.9889e-05, gnorm=0.604, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=18755
2023-01-06 20:02:22 - progress_bar.py[line:274] - INFO: epoch 001:   4895 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.075, wps=101.4, ups=0.46, wpb=109.3, bsz=40, num_updates=4890, lr=4.98845e-05, gnorm=0.613, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=18777
2023-01-06 20:02:44 - progress_bar.py[line:274] - INFO: epoch 001:   4905 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0564, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=4900, lr=4.988e-05, gnorm=0.468, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=18800
2023-01-06 20:03:07 - progress_bar.py[line:274] - INFO: epoch 001:   4915 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0383, wps=102.2, ups=0.47, wpb=109, bsz=40, num_updates=4910, lr=4.98755e-05, gnorm=0.73, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=18822
2023-01-06 20:03:28 - progress_bar.py[line:274] - INFO: epoch 001:   4925 / 115845 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, vqa_score=0.0443, wps=104.6, ups=0.48, wpb=109.4, bsz=40, num_updates=4920, lr=4.9871e-05, gnorm=0.708, clip=10, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=18844
2023-01-06 20:03:51 - progress_bar.py[line:274] - INFO: epoch 001:   4935 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0881, wps=100.6, ups=0.46, wpb=108.6, bsz=40, num_updates=4930, lr=4.98665e-05, gnorm=0.493, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18866
2023-01-06 20:04:13 - progress_bar.py[line:274] - INFO: epoch 001:   4945 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0657, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=4940, lr=4.9862e-05, gnorm=0.557, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=18889
2023-01-06 20:04:37 - progress_bar.py[line:274] - INFO: epoch 001:   4955 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0426, wps=96.5, ups=0.44, wpb=108.9, bsz=40, num_updates=4950, lr=4.98575e-05, gnorm=0.586, clip=0, loss_scale=1024, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=18912
2023-01-06 20:05:00 - progress_bar.py[line:274] - INFO: epoch 001:   4965 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0531, wps=99.4, ups=0.46, wpb=108.5, bsz=40, num_updates=4960, lr=4.9853e-05, gnorm=0.632, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=18935
2023-01-06 20:05:21 - progress_bar.py[line:274] - INFO: epoch 001:   4975 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0591, wps=103.6, ups=0.48, wpb=108.7, bsz=40, num_updates=4970, lr=4.98485e-05, gnorm=0.656, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=18957
2023-01-06 20:05:44 - progress_bar.py[line:274] - INFO: epoch 001:   4985 / 115845 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.061, wps=99.9, ups=0.46, wpb=108.2, bsz=40, num_updates=4980, lr=4.9844e-05, gnorm=0.741, clip=10, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=18979
2023-01-06 20:06:06 - progress_bar.py[line:274] - INFO: epoch 001:   4995 / 115845 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0639, wps=100.4, ups=0.47, wpb=107.7, bsz=40, num_updates=4990, lr=4.98395e-05, gnorm=0.559, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19002
2023-01-06 20:06:28 - progress_bar.py[line:274] - INFO: epoch 001:   5005 / 115845 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0483, wps=101.3, ups=0.47, wpb=107.3, bsz=40, num_updates=5000, lr=4.9835e-05, gnorm=0.632, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19023
2023-01-06 20:06:51 - progress_bar.py[line:274] - INFO: epoch 001:   5015 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0493, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=5010, lr=4.98305e-05, gnorm=0.603, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19046
2023-01-06 20:07:13 - progress_bar.py[line:274] - INFO: epoch 001:   5025 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0628, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=5020, lr=4.9826e-05, gnorm=0.585, clip=0, loss_scale=1024, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=19068
2023-01-06 20:07:35 - progress_bar.py[line:274] - INFO: epoch 001:   5035 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0419, wps=104.5, ups=0.48, wpb=108.9, bsz=40, num_updates=5030, lr=4.98215e-05, gnorm=0.554, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19090
2023-01-06 20:07:57 - progress_bar.py[line:274] - INFO: epoch 001:   5045 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.045, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=5040, lr=4.9817e-05, gnorm=0.61, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19112
2023-01-06 20:08:19 - progress_bar.py[line:274] - INFO: epoch 001:   5055 / 115845 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0576, wps=104.2, ups=0.47, wpb=110.6, bsz=40, num_updates=5050, lr=4.98125e-05, gnorm=0.55, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19134
2023-01-06 20:08:41 - progress_bar.py[line:274] - INFO: epoch 001:   5065 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0558, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=5060, lr=4.9808e-05, gnorm=0.624, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=19157
2023-01-06 20:09:04 - progress_bar.py[line:274] - INFO: epoch 001:   5075 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0505, wps=98.9, ups=0.45, wpb=108.9, bsz=40, num_updates=5070, lr=4.98035e-05, gnorm=0.614, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19180
2023-01-06 20:09:27 - progress_bar.py[line:274] - INFO: epoch 001:   5085 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0638, wps=100.7, ups=0.46, wpb=109.3, bsz=40, num_updates=5080, lr=4.9799e-05, gnorm=0.502, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19202
2023-01-06 20:09:49 - progress_bar.py[line:274] - INFO: epoch 001:   5095 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0813, wps=98.4, ups=0.45, wpb=108.2, bsz=40, num_updates=5090, lr=4.97945e-05, gnorm=0.562, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19225
2023-01-06 20:10:12 - progress_bar.py[line:274] - INFO: epoch 001:   5105 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0628, wps=99.4, ups=0.46, wpb=109.2, bsz=40, num_updates=5100, lr=4.979e-05, gnorm=0.545, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19247
2023-01-06 20:10:34 - progress_bar.py[line:274] - INFO: epoch 001:   5115 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0588, wps=103.3, ups=0.47, wpb=110.2, bsz=40, num_updates=5110, lr=4.97855e-05, gnorm=0.596, clip=10, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=19269
2023-01-06 20:10:57 - progress_bar.py[line:274] - INFO: epoch 001:   5125 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0507, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=5120, lr=4.9781e-05, gnorm=0.612, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19292
2023-01-06 20:10:59 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 20:11:21 - progress_bar.py[line:274] - INFO: epoch 001:   5136 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108.429, nsentences=40, sample_size=108.429, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0398, wps=96.3, ups=0.42, wpb=108.4, bsz=40, num_updates=5130, lr=4.97766e-05, gnorm=0.612, clip=0, loss_scale=512, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=19316
2023-01-06 20:11:44 - progress_bar.py[line:274] - INFO: epoch 001:   5146 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0428, wps=103.3, ups=0.46, wpb=111.8, bsz=40, num_updates=5140, lr=4.97721e-05, gnorm=0.611, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19339
2023-01-06 20:12:06 - progress_bar.py[line:274] - INFO: epoch 001:   5156 / 115845 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0616, wps=102.7, ups=0.48, wpb=107.8, bsz=40, num_updates=5150, lr=4.97676e-05, gnorm=0.631, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19361
2023-01-06 20:12:28 - progress_bar.py[line:274] - INFO: epoch 001:   5166 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0757, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=5160, lr=4.97631e-05, gnorm=0.624, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=19384
2023-01-06 20:12:50 - progress_bar.py[line:274] - INFO: epoch 001:   5176 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0571, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=5170, lr=4.97586e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19406
2023-01-06 20:13:13 - progress_bar.py[line:274] - INFO: epoch 001:   5186 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0635, wps=99.5, ups=0.46, wpb=109.2, bsz=40, num_updates=5180, lr=4.97541e-05, gnorm=0.599, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19428
2023-01-06 20:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   5196 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0481, wps=100.2, ups=0.45, wpb=110.4, bsz=40, num_updates=5190, lr=4.97496e-05, gnorm=0.667, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=19451
2023-01-06 20:13:58 - progress_bar.py[line:274] - INFO: epoch 001:   5206 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0691, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=5200, lr=4.97451e-05, gnorm=0.61, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=19473
2023-01-06 20:14:21 - progress_bar.py[line:274] - INFO: epoch 001:   5216 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0571, wps=100, ups=0.46, wpb=108, bsz=40, num_updates=5210, lr=4.97406e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19496
2023-01-06 20:14:43 - progress_bar.py[line:274] - INFO: epoch 001:   5226 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.066, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=5220, lr=4.97361e-05, gnorm=0.666, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19519
2023-01-06 20:15:06 - progress_bar.py[line:274] - INFO: epoch 001:   5236 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0633, wps=101.1, ups=0.47, wpb=108.2, bsz=40, num_updates=5230, lr=4.97316e-05, gnorm=0.666, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=19541
2023-01-06 20:15:28 - progress_bar.py[line:274] - INFO: epoch 001:   5246 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0606, wps=102.1, ups=0.47, wpb=108.5, bsz=40, num_updates=5240, lr=4.97271e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19563
2023-01-06 20:15:50 - progress_bar.py[line:274] - INFO: epoch 001:   5256 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0569, wps=100, ups=0.46, wpb=108.3, bsz=40, num_updates=5250, lr=4.97226e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19585
2023-01-06 20:16:13 - progress_bar.py[line:274] - INFO: epoch 001:   5266 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.099, wps=103.1, ups=0.47, wpb=110, bsz=40, num_updates=5260, lr=4.97181e-05, gnorm=0.637, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=19608
2023-01-06 20:16:35 - progress_bar.py[line:274] - INFO: epoch 001:   5276 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0539, wps=99.8, ups=0.46, wpb=109.2, bsz=40, num_updates=5270, lr=4.97136e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19631
2023-01-06 20:16:58 - progress_bar.py[line:274] - INFO: epoch 001:   5286 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0419, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=5280, lr=4.97091e-05, gnorm=0.623, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=19653
2023-01-06 20:17:21 - progress_bar.py[line:274] - INFO: epoch 001:   5296 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0476, wps=99.7, ups=0.46, wpb=108.9, bsz=40, num_updates=5290, lr=4.97046e-05, gnorm=0.667, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19676
2023-01-06 20:17:44 - progress_bar.py[line:274] - INFO: epoch 001:   5306 / 115845 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0936, wps=98.5, ups=0.45, wpb=108.3, bsz=40, num_updates=5300, lr=4.97001e-05, gnorm=0.573, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=19699
2023-01-06 20:18:06 - progress_bar.py[line:274] - INFO: epoch 001:   5316 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0895, wps=103.6, ups=0.48, wpb=108.8, bsz=40, num_updates=5310, lr=4.96956e-05, gnorm=0.598, clip=0, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=19721
2023-01-06 20:18:28 - progress_bar.py[line:274] - INFO: epoch 001:   5326 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0547, wps=101.8, ups=0.47, wpb=108.7, bsz=40, num_updates=5320, lr=4.96911e-05, gnorm=0.61, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19743
2023-01-06 20:18:50 - progress_bar.py[line:274] - INFO: epoch 001:   5336 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0744, wps=101.5, ups=0.47, wpb=107.5, bsz=40, num_updates=5330, lr=4.96866e-05, gnorm=0.578, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19765
2023-01-06 20:19:12 - progress_bar.py[line:274] - INFO: epoch 001:   5346 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0995, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=5340, lr=4.96821e-05, gnorm=0.721, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=19787
2023-01-06 20:19:34 - progress_bar.py[line:274] - INFO: epoch 001:   5356 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0781, wps=102.4, ups=0.47, wpb=109.2, bsz=40, num_updates=5350, lr=4.96776e-05, gnorm=0.603, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19809
2023-01-06 20:19:57 - progress_bar.py[line:274] - INFO: epoch 001:   5366 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.05, wps=99.8, ups=0.46, wpb=108.3, bsz=40, num_updates=5360, lr=4.96731e-05, gnorm=0.523, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19832
2023-01-06 20:20:19 - progress_bar.py[line:274] - INFO: epoch 001:   5376 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0638, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=5370, lr=4.96687e-05, gnorm=0.72, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19854
2023-01-06 20:20:41 - progress_bar.py[line:274] - INFO: epoch 001:   5386 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0691, wps=102.6, ups=0.47, wpb=110.2, bsz=40, num_updates=5380, lr=4.96642e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=19877
2023-01-06 20:21:04 - progress_bar.py[line:274] - INFO: epoch 001:   5396 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1171, wps=101.7, ups=0.46, wpb=109.8, bsz=40, num_updates=5390, lr=4.96597e-05, gnorm=0.55, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=19899
2023-01-06 20:21:27 - progress_bar.py[line:274] - INFO: epoch 001:   5406 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0773, wps=98.3, ups=0.46, wpb=107.8, bsz=40, num_updates=5400, lr=4.96552e-05, gnorm=0.612, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=19922
2023-01-06 20:21:49 - progress_bar.py[line:274] - INFO: epoch 001:   5416 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0663, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=5410, lr=4.96507e-05, gnorm=0.676, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=19944
2023-01-06 20:22:11 - progress_bar.py[line:274] - INFO: epoch 001:   5426 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0372, wps=103.2, ups=0.48, wpb=108.6, bsz=40, num_updates=5420, lr=4.96462e-05, gnorm=0.729, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=19966
2023-01-06 20:22:33 - progress_bar.py[line:274] - INFO: epoch 001:   5436 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0699, wps=103.8, ups=0.47, wpb=110.2, bsz=40, num_updates=5430, lr=4.96417e-05, gnorm=0.581, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=19988
2023-01-06 20:22:55 - progress_bar.py[line:274] - INFO: epoch 001:   5446 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0905, wps=99.6, ups=0.46, wpb=108.2, bsz=40, num_updates=5440, lr=4.96372e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20011
2023-01-06 20:23:18 - progress_bar.py[line:274] - INFO: epoch 001:   5456 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0874, wps=103.3, ups=0.47, wpb=109.7, bsz=40, num_updates=5450, lr=4.96327e-05, gnorm=0.627, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20033
2023-01-06 20:23:40 - progress_bar.py[line:274] - INFO: epoch 001:   5466 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0535, wps=104.3, ups=0.48, wpb=108.9, bsz=40, num_updates=5460, lr=4.96282e-05, gnorm=0.757, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20055
2023-01-06 20:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   5476 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0817, wps=100, ups=0.46, wpb=108.4, bsz=40, num_updates=5470, lr=4.96237e-05, gnorm=0.739, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20078
2023-01-06 20:24:26 - progress_bar.py[line:274] - INFO: epoch 001:   5486 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0568, wps=102.7, ups=0.46, wpb=111.5, bsz=40, num_updates=5480, lr=4.96192e-05, gnorm=0.671, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20101
2023-01-06 20:24:49 - progress_bar.py[line:274] - INFO: epoch 001:   5496 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0667, wps=99, ups=0.46, wpb=108, bsz=40, num_updates=5490, lr=4.96147e-05, gnorm=0.623, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=20124
2023-01-06 20:25:11 - progress_bar.py[line:274] - INFO: epoch 001:   5506 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0731, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=5500, lr=4.96102e-05, gnorm=0.637, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20146
2023-01-06 20:25:33 - progress_bar.py[line:274] - INFO: epoch 001:   5516 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0785, wps=103.8, ups=0.47, wpb=110.1, bsz=40, num_updates=5510, lr=4.96057e-05, gnorm=0.627, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20168
2023-01-06 20:25:56 - progress_bar.py[line:274] - INFO: epoch 001:   5526 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.071, wps=101.1, ups=0.46, wpb=110.9, bsz=40, num_updates=5520, lr=4.96012e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20191
2023-01-06 20:26:19 - progress_bar.py[line:274] - INFO: epoch 001:   5536 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0446, wps=101.2, ups=0.46, wpb=110.1, bsz=40, num_updates=5530, lr=4.95967e-05, gnorm=0.748, clip=20, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=20214
2023-01-06 20:26:42 - progress_bar.py[line:274] - INFO: epoch 001:   5546 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1053, wps=98.4, ups=0.46, wpb=107.5, bsz=40, num_updates=5540, lr=4.95922e-05, gnorm=0.678, clip=20, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=20237
2023-01-06 20:27:04 - progress_bar.py[line:274] - INFO: epoch 001:   5556 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0448, wps=103.8, ups=0.47, wpb=110, bsz=40, num_updates=5550, lr=4.95877e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20259
2023-01-06 20:27:26 - progress_bar.py[line:274] - INFO: epoch 001:   5566 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0398, wps=101.4, ups=0.47, wpb=108.5, bsz=40, num_updates=5560, lr=4.95832e-05, gnorm=0.583, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20281
2023-01-06 20:27:48 - progress_bar.py[line:274] - INFO: epoch 001:   5576 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0905, wps=100.7, ups=0.46, wpb=110.3, bsz=40, num_updates=5570, lr=4.95787e-05, gnorm=0.747, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20304
2023-01-06 20:28:11 - progress_bar.py[line:274] - INFO: epoch 001:   5586 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.08, wps=100.3, ups=0.46, wpb=110, bsz=40, num_updates=5580, lr=4.95742e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20326
2023-01-06 20:28:33 - progress_bar.py[line:274] - INFO: epoch 001:   5596 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.064, wps=100.1, ups=0.47, wpb=107.5, bsz=40, num_updates=5590, lr=4.95697e-05, gnorm=0.648, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20348
2023-01-06 20:28:55 - progress_bar.py[line:274] - INFO: epoch 001:   5606 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1123, wps=102.1, ups=0.46, wpb=110.6, bsz=40, num_updates=5600, lr=4.95652e-05, gnorm=0.68, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20371
2023-01-06 20:29:18 - progress_bar.py[line:274] - INFO: epoch 001:   5616 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.037, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=5610, lr=4.95607e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20393
2023-01-06 20:29:39 - progress_bar.py[line:274] - INFO: epoch 001:   5626 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1154, wps=102.5, ups=0.47, wpb=108.3, bsz=40, num_updates=5620, lr=4.95563e-05, gnorm=0.673, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=20415
2023-01-06 20:30:02 - progress_bar.py[line:274] - INFO: epoch 001:   5636 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0821, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=5630, lr=4.95518e-05, gnorm=0.758, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20437
2023-01-06 20:30:10 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 20:30:26 - progress_bar.py[line:274] - INFO: epoch 001:   5647 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=109.905, nsentences=40, sample_size=109.905, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0714, wps=98.9, ups=0.43, wpb=109.9, bsz=40, num_updates=5640, lr=4.95473e-05, gnorm=0.604, clip=10, loss_scale=512, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=20461
2023-01-06 20:30:49 - progress_bar.py[line:274] - INFO: epoch 001:   5657 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1146, wps=99, ups=0.45, wpb=109.5, bsz=40, num_updates=5650, lr=4.95428e-05, gnorm=0.583, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20484
2023-01-06 20:31:12 - progress_bar.py[line:274] - INFO: epoch 001:   5667 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0856, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=5660, lr=4.95383e-05, gnorm=0.559, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20507
2023-01-06 20:31:34 - progress_bar.py[line:274] - INFO: epoch 001:   5677 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0919, wps=103.1, ups=0.47, wpb=110.3, bsz=40, num_updates=5670, lr=4.95338e-05, gnorm=0.653, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20529
2023-01-06 20:31:56 - progress_bar.py[line:274] - INFO: epoch 001:   5687 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0761, wps=100.9, ups=0.46, wpb=110.1, bsz=40, num_updates=5680, lr=4.95293e-05, gnorm=0.652, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20552
2023-01-06 20:32:00 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-06 20:32:21 - progress_bar.py[line:274] - INFO: epoch 001:   5698 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.762, nsentences=40, sample_size=109.762, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0765, wps=97.5, ups=0.42, wpb=109.8, bsz=40, num_updates=5690, lr=4.95248e-05, gnorm=0.538, clip=0, loss_scale=256, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=20576
2023-01-06 20:32:42 - progress_bar.py[line:274] - INFO: epoch 001:   5708 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0594, wps=104.1, ups=0.48, wpb=109.4, bsz=40, num_updates=5700, lr=4.95203e-05, gnorm=0.625, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20598
2023-01-06 20:33:05 - progress_bar.py[line:274] - INFO: epoch 001:   5718 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0714, wps=102.2, ups=0.46, wpb=110.1, bsz=40, num_updates=5710, lr=4.95158e-05, gnorm=0.53, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=20620
2023-01-06 20:33:26 - progress_bar.py[line:274] - INFO: epoch 001:   5728 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0914, wps=105.2, ups=0.48, wpb=109.2, bsz=40, num_updates=5720, lr=4.95113e-05, gnorm=0.544, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20642
2023-01-06 20:33:49 - progress_bar.py[line:274] - INFO: epoch 001:   5738 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0615, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=5730, lr=4.95068e-05, gnorm=0.713, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20664
2023-01-06 20:34:11 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0887, wps=100.4, ups=0.47, wpb=107.7, bsz=40, num_updates=5740, lr=4.95023e-05, gnorm=0.82, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20686
2023-01-06 20:34:33 - progress_bar.py[line:274] - INFO: epoch 001:   5758 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0606, wps=100.7, ups=0.47, wpb=108.1, bsz=40, num_updates=5750, lr=4.94978e-05, gnorm=0.738, clip=20, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20708
2023-01-06 20:34:55 - progress_bar.py[line:274] - INFO: epoch 001:   5768 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1327, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=5760, lr=4.94933e-05, gnorm=0.572, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20730
2023-01-06 20:35:17 - progress_bar.py[line:274] - INFO: epoch 001:   5778 / 115845 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0867, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=5770, lr=4.94888e-05, gnorm=0.625, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=20752
2023-01-06 20:35:39 - progress_bar.py[line:274] - INFO: epoch 001:   5788 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0867, wps=100.7, ups=0.46, wpb=109.2, bsz=40, num_updates=5780, lr=4.94843e-05, gnorm=0.494, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=20774
2023-01-06 20:36:01 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1122, wps=99.6, ups=0.46, wpb=108.6, bsz=40, num_updates=5790, lr=4.94798e-05, gnorm=0.79, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20797
2023-01-06 20:36:23 - progress_bar.py[line:274] - INFO: epoch 001:   5808 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0406, wps=100.4, ups=0.47, wpb=107.8, bsz=40, num_updates=5800, lr=4.94753e-05, gnorm=0.579, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20819
2023-01-06 20:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   5818 / 115845 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.08, wps=102.5, ups=0.47, wpb=109, bsz=40, num_updates=5810, lr=4.94708e-05, gnorm=0.592, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=20840
2023-01-06 20:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   5828 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0773, wps=99, ups=0.46, wpb=108, bsz=40, num_updates=5820, lr=4.94663e-05, gnorm=0.669, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=20863
2023-01-06 20:37:29 - progress_bar.py[line:274] - INFO: epoch 001:   5838 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1224, wps=99.8, ups=0.46, wpb=107.5, bsz=40, num_updates=5830, lr=4.94618e-05, gnorm=0.576, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20885
2023-01-06 20:37:51 - progress_bar.py[line:274] - INFO: epoch 001:   5848 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0773, wps=103.2, ups=0.47, wpb=110.4, bsz=40, num_updates=5840, lr=4.94573e-05, gnorm=0.646, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20906
2023-01-06 20:38:13 - progress_bar.py[line:274] - INFO: epoch 001:   5858 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0924, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=5850, lr=4.94528e-05, gnorm=0.473, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=20928
2023-01-06 20:38:35 - progress_bar.py[line:274] - INFO: epoch 001:   5868 / 115845 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.069, wps=102.1, ups=0.47, wpb=108.2, bsz=40, num_updates=5860, lr=4.94484e-05, gnorm=0.531, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20950
2023-01-06 20:38:56 - progress_bar.py[line:274] - INFO: epoch 001:   5878 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0503, wps=103.7, ups=0.47, wpb=109.7, bsz=40, num_updates=5870, lr=4.94439e-05, gnorm=0.642, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=20972
2023-01-06 20:39:18 - progress_bar.py[line:274] - INFO: epoch 001:   5888 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0769, wps=101.8, ups=0.47, wpb=108.6, bsz=40, num_updates=5880, lr=4.94394e-05, gnorm=0.586, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=20994
2023-01-06 20:39:40 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0645, wps=103.4, ups=0.47, wpb=110.3, bsz=40, num_updates=5890, lr=4.94349e-05, gnorm=0.732, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21015
2023-01-06 20:40:02 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0931, wps=101.6, ups=0.47, wpb=108, bsz=40, num_updates=5900, lr=4.94304e-05, gnorm=0.721, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=21037
2023-01-06 20:40:24 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.049, wps=100.8, ups=0.46, wpb=109.5, bsz=40, num_updates=5910, lr=4.94259e-05, gnorm=0.665, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=21059
2023-01-06 20:40:46 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 115845 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0984, wps=100.2, ups=0.46, wpb=109.8, bsz=40, num_updates=5920, lr=4.94214e-05, gnorm=0.591, clip=0, loss_scale=256, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=21082
2023-01-06 20:41:08 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0808, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=5930, lr=4.94169e-05, gnorm=0.696, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21104
2023-01-06 20:41:30 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0532, wps=102.4, ups=0.47, wpb=109.9, bsz=40, num_updates=5940, lr=4.94124e-05, gnorm=0.541, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=21126
2023-01-06 20:41:52 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1313, wps=100.2, ups=0.46, wpb=108.3, bsz=40, num_updates=5950, lr=4.94079e-05, gnorm=0.473, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=21148
2023-01-06 20:42:14 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 115845 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0846, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=5960, lr=4.94034e-05, gnorm=0.896, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=21170
2023-01-06 20:42:36 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0976, wps=102.4, ups=0.47, wpb=109, bsz=40, num_updates=5970, lr=4.93989e-05, gnorm=0.513, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=21191
2023-01-06 20:42:58 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0918, wps=102.2, ups=0.46, wpb=110.4, bsz=40, num_updates=5980, lr=4.93944e-05, gnorm=0.561, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=21213
2023-01-06 20:43:20 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1048, wps=101, ups=0.47, wpb=108, bsz=40, num_updates=5990, lr=4.93899e-05, gnorm=0.58, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=21235
2023-01-06 20:43:41 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0663, wps=103.6, ups=0.47, wpb=109.7, bsz=40, num_updates=6000, lr=4.93854e-05, gnorm=0.66, clip=10, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=21257
2023-01-06 20:43:41 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-06 20:43:43 - train.py[line:549] - INFO: 0 / 4988
2023-01-06 20:43:43 - train.py[line:551] - INFO: load:1.27 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-06 20:43:44 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 39.59 GiB total capacity; 8.82 GiB already allocated; 3.11 GiB free; 33.99 GiB reserved in total by PyTorch)
2023-01-06 20:43:44 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 17        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9032 MB |   10164 MB |    3005 TB |    3005 TB |
|       from large pool |    8858 MB |    9990 MB |    3003 TB |    3003 TB |
|       from small pool |     174 MB |     174 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9032 MB |   10164 MB |    3005 TB |    3005 TB |
|       from large pool |    8858 MB |    9990 MB |    3003 TB |    3003 TB |
|       from small pool |     174 MB |     174 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34810 MB |   35320 MB |  208598 MB |  173788 MB |
|       from large pool |   34634 MB |   35138 MB |  208266 MB |  173632 MB |
|       from small pool |     176 MB |     182 MB |     332 MB |     156 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25777 MB |   29825 MB |    2776 TB |    2776 TB |
|       from large pool |   25775 MB |   29823 MB |    2775 TB |    2775 TB |
|       from small pool |       1 MB |       2 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  140486 K  |  140481 K  |
|       from large pool |     698    |     710    |   43762 K  |   43761 K  |
|       from small pool |    3925    |    3943    |   96724 K  |   96720 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  140486 K  |  140481 K  |
|       from large pool |     698    |     710    |   43762 K  |   43761 K  |
|       from small pool |    3925    |    3943    |   96724 K  |   96720 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     186    |     191    |     524    |     338    |
|       from large pool |      98    |     100    |     358    |     260    |
|       from small pool |      88    |      91    |     166    |      78    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     128    |     132    |  103860 K  |  103860 K  |
|       from large pool |      67    |      69    |   21322 K  |   21322 K  |
|       from small pool |      61    |      68    |   82537 K  |   82537 K  |
|===========================================================================|

2023-01-06 20:43:44 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-06 20:43:44 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-06 20:46:16 - train.py[line:549] - INFO: 200 / 4988
2023-01-06 20:46:16 - train.py[line:551] - INFO: load:1.29 valid_run:153.29 task_valid:148.17 collect_output:2.79
2023-01-06 20:48:46 - train.py[line:549] - INFO: 400 / 4988
2023-01-06 20:48:46 - train.py[line:551] - INFO: load:1.32 valid_run:302.83 task_valid:291.33 collect_output:8.09
2023-01-06 20:51:20 - train.py[line:549] - INFO: 600 / 4988
2023-01-06 20:51:20 - train.py[line:551] - INFO: load:1.34 valid_run:456.85 task_valid:434.58 collect_output:17.81
2023-01-06 20:53:50 - train.py[line:549] - INFO: 800 / 4988
2023-01-06 20:53:50 - train.py[line:551] - INFO: load:1.37 valid_run:606.56 task_valid:579.58 collect_output:21.42
2023-01-06 20:56:23 - train.py[line:549] - INFO: 1000 / 4988
2023-01-06 20:56:23 - train.py[line:551] - INFO: load:1.40 valid_run:759.47 task_valid:727.16 collect_output:25.65
2023-01-06 20:58:56 - train.py[line:549] - INFO: 1200 / 4988
2023-01-06 20:58:56 - train.py[line:551] - INFO: load:1.43 valid_run:912.26 task_valid:872.65 collect_output:31.89
2023-01-06 21:01:30 - train.py[line:549] - INFO: 1400 / 4988
2023-01-06 21:01:30 - train.py[line:551] - INFO: load:1.45 valid_run:1066.75 task_valid:1018.85 collect_output:39.13
2023-01-06 21:04:02 - train.py[line:549] - INFO: 1600 / 4988
2023-01-06 21:04:02 - train.py[line:551] - INFO: load:1.48 valid_run:1218.86 task_valid:1159.85 collect_output:49.18
2023-01-06 21:06:33 - train.py[line:549] - INFO: 1800 / 4988
2023-01-06 21:06:33 - train.py[line:551] - INFO: load:1.51 valid_run:1369.14 task_valid:1304.52 collect_output:53.75
2023-01-06 21:09:02 - train.py[line:549] - INFO: 2000 / 4988
2023-01-06 21:09:02 - train.py[line:551] - INFO: load:1.53 valid_run:1518.66 task_valid:1447.82 collect_output:58.91
2023-01-06 21:11:33 - train.py[line:549] - INFO: 2200 / 4988
2023-01-06 21:11:33 - train.py[line:551] - INFO: load:1.56 valid_run:1669.35 task_valid:1593.03 collect_output:63.27
2023-01-06 21:14:04 - train.py[line:549] - INFO: 2400 / 4988
2023-01-06 21:14:04 - train.py[line:551] - INFO: load:1.59 valid_run:1820.10 task_valid:1737.99 collect_output:67.99
2023-01-06 21:16:35 - train.py[line:549] - INFO: 2600 / 4988
2023-01-06 21:16:35 - train.py[line:551] - INFO: load:1.61 valid_run:1971.11 task_valid:1879.88 collect_output:76.04
2023-01-06 21:19:08 - train.py[line:549] - INFO: 2800 / 4988
2023-01-06 21:19:08 - train.py[line:551] - INFO: load:1.65 valid_run:2124.26 task_valid:2026.72 collect_output:81.21
2023-01-06 21:21:39 - train.py[line:549] - INFO: 3000 / 4988
2023-01-06 21:21:39 - train.py[line:551] - INFO: load:1.68 valid_run:2275.09 task_valid:2173.48 collect_output:84.22
2023-01-06 21:24:10 - train.py[line:549] - INFO: 3200 / 4988
2023-01-06 21:24:10 - train.py[line:551] - INFO: load:1.70 valid_run:2425.89 task_valid:2317.70 collect_output:89.78
2023-01-06 21:26:43 - train.py[line:549] - INFO: 3400 / 4988
2023-01-06 21:26:43 - train.py[line:551] - INFO: load:1.73 valid_run:2578.86 task_valid:2463.63 collect_output:95.75
2023-01-06 21:29:14 - train.py[line:549] - INFO: 3600 / 4988
2023-01-06 21:29:14 - train.py[line:551] - INFO: load:1.76 valid_run:2730.05 task_valid:2610.59 collect_output:98.95
2023-01-06 21:31:44 - train.py[line:549] - INFO: 3800 / 4988
2023-01-06 21:31:44 - train.py[line:551] - INFO: load:1.78 valid_run:2879.63 task_valid:2752.45 collect_output:105.59
2023-01-06 21:34:15 - train.py[line:549] - INFO: 4000 / 4988
2023-01-06 21:34:15 - train.py[line:551] - INFO: load:1.81 valid_run:3030.77 task_valid:2897.69 collect_output:110.43
2023-01-06 21:36:48 - train.py[line:549] - INFO: 4200 / 4988
2023-01-06 21:36:48 - train.py[line:551] - INFO: load:1.83 valid_run:3183.59 task_valid:3042.37 collect_output:117.53
2023-01-06 21:39:18 - train.py[line:549] - INFO: 4400 / 4988
2023-01-06 21:39:18 - train.py[line:551] - INFO: load:1.86 valid_run:3333.73 task_valid:3186.94 collect_output:122.04
2023-01-06 21:41:50 - train.py[line:549] - INFO: 4600 / 4988
2023-01-06 21:41:50 - train.py[line:551] - INFO: load:1.89 valid_run:3485.48 task_valid:3333.15 collect_output:126.56
2023-01-06 21:44:22 - train.py[line:549] - INFO: 4800 / 4988
2023-01-06 21:44:22 - train.py[line:551] - INFO: load:1.91 valid_run:3637.58 task_valid:3479.84 collect_output:130.91

====================================================================================================
SGG eval:     R @ 50: 0.5892;     R @ 100: 0.6419;     R @ 500: 0.6759;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3680;    mR @ 100: 0.4555;    mR @ 500: 0.5059;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7647) (flying in:0.7273) (growing on:0.3750) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9134) (says:0.0000) (sitting on:0.7279) (standing on:0.2750) (using:0.6000) (walking in:0.0000) (walking on:0.8108) (watching:0.3750) 
--------------------------------------------------------
====================================================================================================

2023-01-06 21:46:54 - train.py[line:487] - INFO: 0.641887242169595

====================================================================================================
SGG eval:     R @ 50: 0.5892;     R @ 100: 0.6419;     R @ 500: 0.6759;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3680;    mR @ 100: 0.4555;    mR @ 500: 0.5059;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7647) (flying in:0.7273) (growing on:0.3750) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9134) (says:0.0000) (sitting on:0.7279) (standing on:0.2750) (using:0.6000) (walking in:0.0000) (walking on:0.8108) (watching:0.3750) 
--------------------------------------------------------
====================================================================================================

2023-01-06 21:46:54 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-06 21:46:55 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.36 | loss_v1 0 | loss_v2 0 | nll_loss 0.211 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.641887 | ppl 1.16 | vqa_score 0.4583 | wps 118.4 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.641887
2023-01-06 21:46:55 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2023-01-06 21:46:55 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt
2023-01-06 21:47:52 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt
2023-01-06 21:51:21 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.641887242169595) (writing took 266.01431653648615 seconds)
2023-01-06 21:51:42 - progress_bar.py[line:274] - INFO: epoch 001:   6018 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1232, wps=0.5, ups=0, wpb=107.6, bsz=40, num_updates=6010, lr=4.93809e-05, gnorm=0.58, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25337
2023-01-06 21:52:04 - progress_bar.py[line:274] - INFO: epoch 001:   6028 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0714, wps=102.5, ups=0.47, wpb=109.8, bsz=40, num_updates=6020, lr=4.93764e-05, gnorm=0.51, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=25360
2023-01-06 21:52:26 - progress_bar.py[line:274] - INFO: epoch 001:   6038 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.8, nsentences=40, sample_size=106.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0977, wps=97.9, ups=0.46, wpb=106.8, bsz=40, num_updates=6030, lr=4.93719e-05, gnorm=0.669, clip=20, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=25382
2023-01-06 21:52:48 - progress_bar.py[line:274] - INFO: epoch 001:   6048 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.0704, wps=101.4, ups=0.46, wpb=109.3, bsz=40, num_updates=6040, lr=4.93674e-05, gnorm=0.597, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25404
2023-01-06 21:53:11 - progress_bar.py[line:274] - INFO: epoch 001:   6058 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0573, wps=99.2, ups=0.46, wpb=108.3, bsz=40, num_updates=6050, lr=4.93629e-05, gnorm=0.528, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=25426
2023-01-06 21:53:32 - progress_bar.py[line:274] - INFO: epoch 001:   6068 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0588, wps=103, ups=0.47, wpb=109.3, bsz=40, num_updates=6060, lr=4.93584e-05, gnorm=0.536, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25448
2023-01-06 21:53:54 - progress_bar.py[line:274] - INFO: epoch 001:   6078 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1133, wps=102.4, ups=0.47, wpb=108.2, bsz=40, num_updates=6070, lr=4.93539e-05, gnorm=0.499, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25469
2023-01-06 21:54:16 - progress_bar.py[line:274] - INFO: epoch 001:   6088 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0833, wps=101, ups=0.46, wpb=109.6, bsz=40, num_updates=6080, lr=4.93494e-05, gnorm=0.641, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25492
2023-01-06 21:54:38 - progress_bar.py[line:274] - INFO: epoch 001:   6098 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0995, wps=99, ups=0.46, wpb=108.5, bsz=40, num_updates=6090, lr=4.93449e-05, gnorm=0.631, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=25514
2023-01-06 21:55:00 - progress_bar.py[line:274] - INFO: epoch 001:   6108 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0765, wps=102.5, ups=0.47, wpb=110.1, bsz=40, num_updates=6100, lr=4.93404e-05, gnorm=0.565, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25536
2023-01-06 21:55:22 - progress_bar.py[line:274] - INFO: epoch 001:   6118 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.06, wps=103.8, ups=0.47, wpb=109.4, bsz=40, num_updates=6110, lr=4.9336e-05, gnorm=0.607, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25557
2023-01-06 21:55:44 - progress_bar.py[line:274] - INFO: epoch 001:   6128 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1077, wps=100.2, ups=0.46, wpb=108.2, bsz=40, num_updates=6120, lr=4.93315e-05, gnorm=0.659, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25579
2023-01-06 21:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   6138 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1204, wps=104.7, ups=0.47, wpb=111.2, bsz=40, num_updates=6130, lr=4.9327e-05, gnorm=0.557, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25601
2023-01-06 21:56:27 - progress_bar.py[line:274] - INFO: epoch 001:   6148 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0905, wps=100.7, ups=0.47, wpb=108.3, bsz=40, num_updates=6140, lr=4.93225e-05, gnorm=0.65, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=25623
2023-01-06 21:56:49 - progress_bar.py[line:274] - INFO: epoch 001:   6158 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.099, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=6150, lr=4.9318e-05, gnorm=0.555, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=25645
2023-01-06 21:57:11 - progress_bar.py[line:274] - INFO: epoch 001:   6168 / 115845 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, vqa_score=0.0784, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=6160, lr=4.93135e-05, gnorm=0.59, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25667
2023-01-06 21:57:33 - progress_bar.py[line:274] - INFO: epoch 001:   6178 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0861, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=6170, lr=4.9309e-05, gnorm=0.604, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25689
2023-01-06 21:57:55 - progress_bar.py[line:274] - INFO: epoch 001:   6188 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0843, wps=103.9, ups=0.47, wpb=111.3, bsz=40, num_updates=6180, lr=4.93045e-05, gnorm=0.546, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25711
2023-01-06 21:58:17 - progress_bar.py[line:274] - INFO: epoch 001:   6198 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.051, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=6190, lr=4.93e-05, gnorm=0.543, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=25732
2023-01-06 21:58:39 - progress_bar.py[line:274] - INFO: epoch 001:   6208 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1063, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=6200, lr=4.92955e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25754
2023-01-06 21:59:01 - progress_bar.py[line:274] - INFO: epoch 001:   6218 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1111, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=6210, lr=4.9291e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=25776
2023-01-06 21:59:23 - progress_bar.py[line:274] - INFO: epoch 001:   6228 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1324, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=6220, lr=4.92865e-05, gnorm=0.541, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25798
2023-01-06 21:59:44 - progress_bar.py[line:274] - INFO: epoch 001:   6238 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1152, wps=103.4, ups=0.47, wpb=109.6, bsz=40, num_updates=6230, lr=4.9282e-05, gnorm=0.579, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=25820
2023-01-06 22:00:06 - progress_bar.py[line:274] - INFO: epoch 001:   6248 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.102, wps=104.1, ups=0.48, wpb=108.8, bsz=40, num_updates=6240, lr=4.92775e-05, gnorm=0.486, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25841
2023-01-06 22:00:28 - progress_bar.py[line:274] - INFO: epoch 001:   6258 / 115845 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1016, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=6250, lr=4.9273e-05, gnorm=0.604, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=25863
2023-01-06 22:00:50 - progress_bar.py[line:274] - INFO: epoch 001:   6268 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.101, wps=100.1, ups=0.46, wpb=108.8, bsz=40, num_updates=6260, lr=4.92685e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=25885
2023-01-06 22:01:11 - progress_bar.py[line:274] - INFO: epoch 001:   6278 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0972, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=6270, lr=4.9264e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=25907
2023-01-06 22:01:22 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-06 22:01:36 - progress_bar.py[line:274] - INFO: epoch 001:   6289 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.238, nsentences=40, sample_size=109.238, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.137, wps=96.1, ups=0.42, wpb=109.2, bsz=40, num_updates=6280, lr=4.92595e-05, gnorm=0.437, clip=0, loss_scale=256, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=25931
2023-01-06 22:01:58 - progress_bar.py[line:274] - INFO: epoch 001:   6299 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1311, wps=101.2, ups=0.46, wpb=109.1, bsz=40, num_updates=6290, lr=4.9255e-05, gnorm=0.584, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=25954
2023-01-06 22:02:20 - progress_bar.py[line:274] - INFO: epoch 001:   6309 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1407, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=6300, lr=4.92505e-05, gnorm=0.48, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=25976
2023-01-06 22:02:42 - progress_bar.py[line:274] - INFO: epoch 001:   6319 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1058, wps=103.1, ups=0.47, wpb=109.8, bsz=40, num_updates=6310, lr=4.9246e-05, gnorm=0.508, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=25997
2023-01-06 22:03:03 - progress_bar.py[line:274] - INFO: epoch 001:   6329 / 115845 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1206, wps=102.4, ups=0.47, wpb=108.7, bsz=40, num_updates=6320, lr=4.92415e-05, gnorm=0.486, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26019
2023-01-06 22:03:25 - progress_bar.py[line:274] - INFO: epoch 001:   6339 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1535, wps=103.3, ups=0.48, wpb=108.5, bsz=40, num_updates=6330, lr=4.9237e-05, gnorm=0.628, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26041
2023-01-06 22:03:46 - progress_bar.py[line:274] - INFO: epoch 001:   6349 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1176, wps=104.5, ups=0.48, wpb=109.8, bsz=40, num_updates=6340, lr=4.92325e-05, gnorm=0.689, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26062
2023-01-06 22:04:08 - progress_bar.py[line:274] - INFO: epoch 001:   6359 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1129, wps=102.1, ups=0.47, wpb=108, bsz=40, num_updates=6350, lr=4.92281e-05, gnorm=0.653, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26084
2023-01-06 22:04:30 - progress_bar.py[line:274] - INFO: epoch 001:   6369 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0944, wps=104.5, ups=0.47, wpb=110.1, bsz=40, num_updates=6360, lr=4.92236e-05, gnorm=0.505, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=26105
2023-01-06 22:04:52 - progress_bar.py[line:274] - INFO: epoch 001:   6379 / 115845 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1029, wps=100.5, ups=0.47, wpb=108, bsz=40, num_updates=6370, lr=4.92191e-05, gnorm=0.593, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26127
2023-01-06 22:05:14 - progress_bar.py[line:274] - INFO: epoch 001:   6389 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1225, wps=102.1, ups=0.47, wpb=109.3, bsz=40, num_updates=6380, lr=4.92146e-05, gnorm=0.534, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=26149
2023-01-06 22:05:35 - progress_bar.py[line:274] - INFO: epoch 001:   6399 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.105, wps=100.8, ups=0.47, wpb=107.6, bsz=40, num_updates=6390, lr=4.92101e-05, gnorm=1.061, clip=20, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26171
2023-01-06 22:05:58 - progress_bar.py[line:274] - INFO: epoch 001:   6409 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.165, wps=98.8, ups=0.45, wpb=108.9, bsz=40, num_updates=6400, lr=4.92056e-05, gnorm=0.621, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26194
2023-01-06 22:06:20 - progress_bar.py[line:274] - INFO: epoch 001:   6419 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0739, wps=100.6, ups=0.46, wpb=109.6, bsz=40, num_updates=6410, lr=4.92011e-05, gnorm=0.585, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26216
2023-01-06 22:06:42 - progress_bar.py[line:274] - INFO: epoch 001:   6429 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.08, wps=104, ups=0.47, wpb=110.1, bsz=40, num_updates=6420, lr=4.91966e-05, gnorm=0.627, clip=0, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=26237
2023-01-06 22:07:04 - progress_bar.py[line:274] - INFO: epoch 001:   6439 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1667, wps=102.7, ups=0.47, wpb=109.5, bsz=40, num_updates=6430, lr=4.91921e-05, gnorm=0.728, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26259
2023-01-06 22:07:26 - progress_bar.py[line:274] - INFO: epoch 001:   6449 / 115845 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.0995, wps=99.4, ups=0.46, wpb=107, bsz=40, num_updates=6440, lr=4.91876e-05, gnorm=0.614, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26281
2023-01-06 22:07:48 - progress_bar.py[line:274] - INFO: epoch 001:   6459 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.161, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=6450, lr=4.91831e-05, gnorm=0.586, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26303
2023-01-06 22:08:09 - progress_bar.py[line:274] - INFO: epoch 001:   6469 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1324, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=6460, lr=4.91786e-05, gnorm=0.493, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26325
2023-01-06 22:08:32 - progress_bar.py[line:274] - INFO: epoch 001:   6479 / 115845 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, vqa_score=0.1111, wps=100.5, ups=0.46, wpb=109.2, bsz=40, num_updates=6470, lr=4.91741e-05, gnorm=0.71, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26347
2023-01-06 22:08:53 - progress_bar.py[line:274] - INFO: epoch 001:   6489 / 115845 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1274, wps=103.9, ups=0.48, wpb=107.2, bsz=40, num_updates=6480, lr=4.91696e-05, gnorm=0.483, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26368
2023-01-06 22:09:15 - progress_bar.py[line:274] - INFO: epoch 001:   6499 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1158, wps=99.6, ups=0.46, wpb=108.4, bsz=40, num_updates=6490, lr=4.91651e-05, gnorm=0.469, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26390
2023-01-06 22:09:37 - progress_bar.py[line:274] - INFO: epoch 001:   6509 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1082, wps=102.3, ups=0.47, wpb=109.7, bsz=40, num_updates=6500, lr=4.91606e-05, gnorm=0.432, clip=0, loss_scale=256, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=26412
2023-01-06 22:09:59 - progress_bar.py[line:274] - INFO: epoch 001:   6519 / 115845 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1131, wps=100.4, ups=0.46, wpb=108.7, bsz=40, num_updates=6510, lr=4.91561e-05, gnorm=0.575, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=26434
2023-01-06 22:10:20 - progress_bar.py[line:274] - INFO: epoch 001:   6529 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1088, wps=102.6, ups=0.47, wpb=109.2, bsz=40, num_updates=6520, lr=4.91516e-05, gnorm=0.504, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26456
2023-01-06 22:10:42 - progress_bar.py[line:274] - INFO: epoch 001:   6539 / 115845 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1472, wps=102, ups=0.47, wpb=108.9, bsz=40, num_updates=6530, lr=4.91471e-05, gnorm=0.561, clip=0, loss_scale=256, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=26478
2023-01-06 22:11:04 - progress_bar.py[line:274] - INFO: epoch 001:   6549 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1373, wps=102.2, ups=0.47, wpb=108.3, bsz=40, num_updates=6540, lr=4.91426e-05, gnorm=0.661, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26500
2023-01-06 22:11:25 - progress_bar.py[line:274] - INFO: epoch 001:   6559 / 115845 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1542, wps=104.6, ups=0.48, wpb=109.4, bsz=40, num_updates=6550, lr=4.91381e-05, gnorm=0.548, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26521
2023-01-06 22:11:47 - progress_bar.py[line:274] - INFO: epoch 001:   6569 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1951, wps=100.6, ups=0.46, wpb=108.8, bsz=40, num_updates=6560, lr=4.91336e-05, gnorm=0.468, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=26543
2023-01-06 22:12:09 - progress_bar.py[line:274] - INFO: epoch 001:   6579 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1584, wps=102.7, ups=0.47, wpb=108.5, bsz=40, num_updates=6570, lr=4.91291e-05, gnorm=0.595, clip=0, loss_scale=256, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=26565
2023-01-06 22:12:31 - progress_bar.py[line:274] - INFO: epoch 001:   6589 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1422, wps=101.4, ups=0.46, wpb=109.2, bsz=40, num_updates=6580, lr=4.91246e-05, gnorm=0.698, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26587
2023-01-06 22:12:53 - progress_bar.py[line:274] - INFO: epoch 001:   6599 / 115845 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1311, wps=102.8, ups=0.47, wpb=109.2, bsz=40, num_updates=6590, lr=4.91201e-05, gnorm=0.528, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26608
2023-01-06 22:13:15 - progress_bar.py[line:274] - INFO: epoch 001:   6609 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1354, wps=101, ups=0.46, wpb=110.5, bsz=40, num_updates=6600, lr=4.91157e-05, gnorm=0.543, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=26631
2023-01-06 22:13:37 - progress_bar.py[line:274] - INFO: epoch 001:   6619 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1429, wps=101, ups=0.47, wpb=108.1, bsz=40, num_updates=6610, lr=4.91112e-05, gnorm=0.539, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26653
2023-01-06 22:13:59 - progress_bar.py[line:274] - INFO: epoch 001:   6629 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0677, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=6620, lr=4.91067e-05, gnorm=0.564, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=26675
2023-01-06 22:14:20 - progress_bar.py[line:274] - INFO: epoch 001:   6639 / 115845 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1436, wps=105.9, ups=0.48, wpb=110.1, bsz=40, num_updates=6630, lr=4.91022e-05, gnorm=0.566, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26696
2023-01-06 22:14:43 - progress_bar.py[line:274] - INFO: epoch 001:   6649 / 115845 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1394, wps=99.7, ups=0.46, wpb=108.7, bsz=40, num_updates=6640, lr=4.90977e-05, gnorm=0.53, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26718
2023-01-06 22:15:04 - progress_bar.py[line:274] - INFO: epoch 001:   6659 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1373, wps=103.7, ups=0.47, wpb=109.8, bsz=40, num_updates=6650, lr=4.90932e-05, gnorm=0.453, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26740
2023-01-06 22:15:26 - progress_bar.py[line:274] - INFO: epoch 001:   6669 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.132, wps=100.7, ups=0.46, wpb=109.8, bsz=40, num_updates=6660, lr=4.90887e-05, gnorm=0.613, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26762
2023-01-06 22:15:48 - progress_bar.py[line:274] - INFO: epoch 001:   6679 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1111, wps=102.1, ups=0.47, wpb=108.5, bsz=40, num_updates=6670, lr=4.90842e-05, gnorm=0.713, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26784
2023-01-06 22:16:10 - progress_bar.py[line:274] - INFO: epoch 001:   6689 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1484, wps=103.5, ups=0.47, wpb=110, bsz=40, num_updates=6680, lr=4.90797e-05, gnorm=0.623, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26805
2023-01-06 22:16:32 - progress_bar.py[line:274] - INFO: epoch 001:   6699 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.115, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=6690, lr=4.90752e-05, gnorm=0.543, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26827
2023-01-06 22:16:54 - progress_bar.py[line:274] - INFO: epoch 001:   6709 / 115845 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1571, wps=101, ups=0.46, wpb=109.9, bsz=40, num_updates=6700, lr=4.90707e-05, gnorm=0.495, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=26849
2023-01-06 22:17:15 - progress_bar.py[line:274] - INFO: epoch 001:   6719 / 115845 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1159, wps=101.9, ups=0.47, wpb=107.8, bsz=40, num_updates=6710, lr=4.90662e-05, gnorm=0.731, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=26871
2023-01-06 22:17:37 - progress_bar.py[line:274] - INFO: epoch 001:   6729 / 115845 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1231, wps=103.3, ups=0.47, wpb=109.3, bsz=40, num_updates=6720, lr=4.90617e-05, gnorm=0.486, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26893
2023-01-06 22:17:59 - progress_bar.py[line:274] - INFO: epoch 001:   6739 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1582, wps=103.2, ups=0.47, wpb=110.1, bsz=40, num_updates=6730, lr=4.90572e-05, gnorm=0.564, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=26915
2023-01-06 22:18:20 - progress_bar.py[line:274] - INFO: epoch 001:   6749 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1401, wps=102.8, ups=0.47, wpb=108.6, bsz=40, num_updates=6740, lr=4.90527e-05, gnorm=0.568, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26936
2023-01-06 22:18:42 - progress_bar.py[line:274] - INFO: epoch 001:   6759 / 115845 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.0971, wps=101.5, ups=0.46, wpb=109.3, bsz=40, num_updates=6750, lr=4.90482e-05, gnorm=0.602, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=26958
2023-01-06 22:19:04 - progress_bar.py[line:274] - INFO: epoch 001:   6769 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1392, wps=103.5, ups=0.47, wpb=110.6, bsz=40, num_updates=6760, lr=4.90437e-05, gnorm=0.525, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=26980
2023-01-06 22:19:26 - progress_bar.py[line:274] - INFO: epoch 001:   6779 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1257, wps=100.8, ups=0.46, wpb=110, bsz=40, num_updates=6770, lr=4.90392e-05, gnorm=0.533, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=27002
2023-01-06 22:19:48 - progress_bar.py[line:274] - INFO: epoch 001:   6789 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1827, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=6780, lr=4.90347e-05, gnorm=0.548, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27024
2023-01-06 22:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   6799 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.0741, wps=100.6, ups=0.46, wpb=109.3, bsz=40, num_updates=6790, lr=4.90302e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27046
2023-01-06 22:20:32 - progress_bar.py[line:274] - INFO: epoch 001:   6809 / 115845 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1333, wps=100.7, ups=0.46, wpb=108.5, bsz=40, num_updates=6800, lr=4.90257e-05, gnorm=0.599, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=27068
2023-01-06 22:20:54 - progress_bar.py[line:274] - INFO: epoch 001:   6819 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1435, wps=102.2, ups=0.46, wpb=110, bsz=40, num_updates=6810, lr=4.90212e-05, gnorm=0.559, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27090
2023-01-06 22:21:16 - progress_bar.py[line:274] - INFO: epoch 001:   6829 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1422, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=6820, lr=4.90167e-05, gnorm=0.508, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27112
2023-01-06 22:21:39 - progress_bar.py[line:274] - INFO: epoch 001:   6839 / 115845 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1308, wps=98.9, ups=0.46, wpb=107.7, bsz=40, num_updates=6830, lr=4.90122e-05, gnorm=0.495, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27134
2023-01-06 22:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   6849 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.0984, wps=101.6, ups=0.47, wpb=108.1, bsz=40, num_updates=6840, lr=4.90078e-05, gnorm=0.538, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27156
2023-01-06 22:22:22 - progress_bar.py[line:274] - INFO: epoch 001:   6859 / 115845 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1378, wps=102.6, ups=0.47, wpb=109.7, bsz=40, num_updates=6850, lr=4.90033e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27178
2023-01-06 22:22:44 - progress_bar.py[line:274] - INFO: epoch 001:   6869 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1569, wps=102.6, ups=0.47, wpb=108.3, bsz=40, num_updates=6860, lr=4.89988e-05, gnorm=0.581, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27200
2023-01-06 22:23:06 - progress_bar.py[line:274] - INFO: epoch 001:   6879 / 115845 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1523, wps=100.7, ups=0.46, wpb=109.6, bsz=40, num_updates=6870, lr=4.89943e-05, gnorm=0.582, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=27222
2023-01-06 22:23:27 - progress_bar.py[line:274] - INFO: epoch 001:   6889 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1675, wps=101.8, ups=0.47, wpb=107.6, bsz=40, num_updates=6880, lr=4.89898e-05, gnorm=0.561, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27243
2023-01-06 22:23:49 - progress_bar.py[line:274] - INFO: epoch 001:   6899 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1735, wps=100.7, ups=0.46, wpb=108.4, bsz=40, num_updates=6890, lr=4.89853e-05, gnorm=0.491, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27265
2023-01-06 22:24:11 - progress_bar.py[line:274] - INFO: epoch 001:   6909 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1152, wps=103.9, ups=0.47, wpb=110.1, bsz=40, num_updates=6900, lr=4.89808e-05, gnorm=0.732, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27287
2023-01-06 22:24:33 - progress_bar.py[line:274] - INFO: epoch 001:   6919 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1463, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=6910, lr=4.89763e-05, gnorm=0.597, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=27309
2023-01-06 22:24:55 - progress_bar.py[line:274] - INFO: epoch 001:   6929 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1699, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=6920, lr=4.89718e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27330
2023-01-06 22:25:16 - progress_bar.py[line:274] - INFO: epoch 001:   6939 / 115845 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.0986, wps=102.9, ups=0.48, wpb=108.1, bsz=40, num_updates=6930, lr=4.89673e-05, gnorm=0.588, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27352
2023-01-06 22:25:38 - progress_bar.py[line:274] - INFO: epoch 001:   6949 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1487, wps=101.6, ups=0.46, wpb=110.3, bsz=40, num_updates=6940, lr=4.89628e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=27374
2023-01-06 22:26:00 - progress_bar.py[line:274] - INFO: epoch 001:   6959 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1277, wps=100.1, ups=0.46, wpb=109.9, bsz=40, num_updates=6950, lr=4.89583e-05, gnorm=0.621, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27396
2023-01-06 22:26:22 - progress_bar.py[line:274] - INFO: epoch 001:   6969 / 115845 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1635, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=6960, lr=4.89538e-05, gnorm=0.64, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27418
2023-01-06 22:26:44 - progress_bar.py[line:274] - INFO: epoch 001:   6979 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1784, wps=98.8, ups=0.46, wpb=108.1, bsz=40, num_updates=6970, lr=4.89493e-05, gnorm=0.741, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27440
2023-01-06 22:27:06 - progress_bar.py[line:274] - INFO: epoch 001:   6989 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1618, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=6980, lr=4.89448e-05, gnorm=0.528, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27462
2023-01-06 22:27:28 - progress_bar.py[line:274] - INFO: epoch 001:   6999 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1148, wps=100.7, ups=0.46, wpb=109.7, bsz=40, num_updates=6990, lr=4.89403e-05, gnorm=0.495, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27484
2023-01-06 22:27:51 - progress_bar.py[line:274] - INFO: epoch 001:   7009 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, vqa_score=0.1571, wps=98.9, ups=0.46, wpb=108.2, bsz=40, num_updates=7000, lr=4.89358e-05, gnorm=0.516, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27506
2023-01-06 22:28:13 - progress_bar.py[line:274] - INFO: epoch 001:   7019 / 115845 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1364, wps=99.6, ups=0.46, wpb=108.4, bsz=40, num_updates=7010, lr=4.89313e-05, gnorm=0.541, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27529
2023-01-06 22:28:35 - progress_bar.py[line:274] - INFO: epoch 001:   7029 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1469, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=7020, lr=4.89268e-05, gnorm=0.696, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27551
2023-01-06 22:28:56 - progress_bar.py[line:274] - INFO: epoch 001:   7039 / 115845 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1684, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=7030, lr=4.89223e-05, gnorm=0.479, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27572
2023-01-06 22:29:18 - progress_bar.py[line:274] - INFO: epoch 001:   7049 / 115845 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1359, wps=102.7, ups=0.47, wpb=109, bsz=40, num_updates=7040, lr=4.89178e-05, gnorm=0.53, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27594
2023-01-06 22:29:40 - progress_bar.py[line:274] - INFO: epoch 001:   7059 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1784, wps=101.8, ups=0.46, wpb=110.5, bsz=40, num_updates=7050, lr=4.89133e-05, gnorm=0.584, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27616
2023-01-06 22:30:02 - progress_bar.py[line:274] - INFO: epoch 001:   7069 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1559, wps=105.1, ups=0.48, wpb=110.3, bsz=40, num_updates=7060, lr=4.89088e-05, gnorm=0.639, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27637
2023-01-06 22:30:24 - progress_bar.py[line:274] - INFO: epoch 001:   7079 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1795, wps=101, ups=0.46, wpb=109.7, bsz=40, num_updates=7070, lr=4.89043e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27660
2023-01-06 22:30:46 - progress_bar.py[line:274] - INFO: epoch 001:   7089 / 115845 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1538, wps=101.3, ups=0.47, wpb=108.4, bsz=40, num_updates=7080, lr=4.88998e-05, gnorm=0.684, clip=10, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=27682
2023-01-06 22:31:08 - progress_bar.py[line:274] - INFO: epoch 001:   7099 / 115845 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1371, wps=99.9, ups=0.46, wpb=107.6, bsz=40, num_updates=7090, lr=4.88954e-05, gnorm=0.639, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=27704
2023-01-06 22:31:30 - progress_bar.py[line:274] - INFO: epoch 001:   7109 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2049, wps=100.8, ups=0.46, wpb=109, bsz=40, num_updates=7100, lr=4.88909e-05, gnorm=0.582, clip=0, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=27726
2023-01-06 22:31:52 - progress_bar.py[line:274] - INFO: epoch 001:   7119 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1658, wps=101.6, ups=0.46, wpb=109.8, bsz=40, num_updates=7110, lr=4.88864e-05, gnorm=0.573, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27748
2023-01-06 22:32:14 - progress_bar.py[line:274] - INFO: epoch 001:   7129 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1455, wps=100, ups=0.47, wpb=107.5, bsz=40, num_updates=7120, lr=4.88819e-05, gnorm=1.076, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=27770
2023-01-06 22:32:35 - progress_bar.py[line:274] - INFO: epoch 001:   7139 / 115845 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1449, wps=102.6, ups=0.48, wpb=107.6, bsz=40, num_updates=7130, lr=4.88774e-05, gnorm=0.521, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27791
2023-01-06 22:32:57 - progress_bar.py[line:274] - INFO: epoch 001:   7149 / 115845 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1759, wps=100.3, ups=0.46, wpb=108.7, bsz=40, num_updates=7140, lr=4.88729e-05, gnorm=0.664, clip=20, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=27813
2023-01-06 22:33:19 - progress_bar.py[line:274] - INFO: epoch 001:   7159 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1925, wps=101.8, ups=0.46, wpb=110.8, bsz=40, num_updates=7150, lr=4.88684e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27835
2023-01-06 22:33:41 - progress_bar.py[line:274] - INFO: epoch 001:   7169 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1534, wps=100.6, ups=0.46, wpb=109.7, bsz=40, num_updates=7160, lr=4.88639e-05, gnorm=0.58, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27857
2023-01-06 22:34:03 - progress_bar.py[line:274] - INFO: epoch 001:   7179 / 115845 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1746, wps=102.4, ups=0.46, wpb=110.4, bsz=40, num_updates=7170, lr=4.88594e-05, gnorm=0.437, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=27879
2023-01-06 22:34:25 - progress_bar.py[line:274] - INFO: epoch 001:   7189 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1472, wps=100.9, ups=0.46, wpb=109.5, bsz=40, num_updates=7180, lr=4.88549e-05, gnorm=0.525, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=27901
2023-01-06 22:34:46 - progress_bar.py[line:274] - INFO: epoch 001:   7199 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.224, wps=104.6, ups=0.48, wpb=109.2, bsz=40, num_updates=7190, lr=4.88504e-05, gnorm=0.67, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27922
2023-01-06 22:35:08 - progress_bar.py[line:274] - INFO: epoch 001:   7209 / 115845 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1859, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=7200, lr=4.88459e-05, gnorm=0.65, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=27943
2023-01-06 22:35:30 - progress_bar.py[line:274] - INFO: epoch 001:   7219 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1837, wps=99.4, ups=0.46, wpb=108.5, bsz=40, num_updates=7210, lr=4.88414e-05, gnorm=0.57, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=27965
2023-01-06 22:35:51 - progress_bar.py[line:274] - INFO: epoch 001:   7229 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2021, wps=104.8, ups=0.47, wpb=110.5, bsz=40, num_updates=7220, lr=4.88369e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=27987
2023-01-06 22:36:13 - progress_bar.py[line:274] - INFO: epoch 001:   7239 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1444, wps=101, ups=0.46, wpb=109.7, bsz=40, num_updates=7230, lr=4.88324e-05, gnorm=0.5, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28009
2023-01-06 22:36:34 - progress_bar.py[line:274] - INFO: epoch 001:   7249 / 115845 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, vqa_score=0.1884, wps=104.2, ups=0.48, wpb=108.3, bsz=40, num_updates=7240, lr=4.88279e-05, gnorm=0.578, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=28030
2023-01-06 22:36:55 - progress_bar.py[line:274] - INFO: epoch 001:   7259 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1707, wps=100.5, ups=0.47, wpb=107.3, bsz=40, num_updates=7250, lr=4.88234e-05, gnorm=0.508, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=28051
2023-01-06 22:37:18 - progress_bar.py[line:274] - INFO: epoch 001:   7269 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2327, wps=98.6, ups=0.45, wpb=108.9, bsz=40, num_updates=7260, lr=4.88189e-05, gnorm=0.605, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28074
2023-01-06 22:37:40 - progress_bar.py[line:274] - INFO: epoch 001:   7279 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1959, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=7270, lr=4.88144e-05, gnorm=0.652, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28095
2023-01-06 22:38:02 - progress_bar.py[line:274] - INFO: epoch 001:   7289 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.197, wps=100.9, ups=0.46, wpb=110.2, bsz=40, num_updates=7280, lr=4.88099e-05, gnorm=0.719, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28118
2023-01-06 22:38:24 - progress_bar.py[line:274] - INFO: epoch 001:   7299 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.206, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=7290, lr=4.88054e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28139
2023-01-06 22:38:46 - progress_bar.py[line:274] - INFO: epoch 001:   7309 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1818, wps=99.6, ups=0.45, wpb=109.5, bsz=40, num_updates=7300, lr=4.88009e-05, gnorm=0.544, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28162
2023-01-06 22:39:08 - progress_bar.py[line:274] - INFO: epoch 001:   7319 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.153, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=7310, lr=4.87964e-05, gnorm=0.834, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28184
2023-01-06 22:39:30 - progress_bar.py[line:274] - INFO: epoch 001:   7329 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.1961, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=7320, lr=4.87919e-05, gnorm=0.808, clip=30, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28206
2023-01-06 22:39:52 - progress_bar.py[line:274] - INFO: epoch 001:   7339 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.218, wps=98.6, ups=0.46, wpb=107.5, bsz=40, num_updates=7330, lr=4.87875e-05, gnorm=0.65, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28228
2023-01-06 22:40:14 - progress_bar.py[line:274] - INFO: epoch 001:   7349 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.215, wps=100.3, ups=0.46, wpb=108.4, bsz=40, num_updates=7340, lr=4.8783e-05, gnorm=0.681, clip=10, loss_scale=1024, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=28249
2023-01-06 22:40:24 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-06 22:40:37 - progress_bar.py[line:274] - INFO: epoch 001:   7360 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.571, nsentences=40, sample_size=109.571, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2083, wps=99, ups=0.43, wpb=109.6, bsz=40, num_updates=7350, lr=4.87785e-05, gnorm=0.558, clip=10, loss_scale=512, train_wall=23, gb_free=10.3, ema_decay=0.9999, wall=28273
2023-01-06 22:41:00 - progress_bar.py[line:274] - INFO: epoch 001:   7370 / 115845 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2049, wps=99.2, ups=0.46, wpb=108.3, bsz=40, num_updates=7360, lr=4.8774e-05, gnorm=0.484, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28295
2023-01-06 22:41:21 - progress_bar.py[line:274] - INFO: epoch 001:   7380 / 115845 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2353, wps=102.9, ups=0.47, wpb=109.1, bsz=40, num_updates=7370, lr=4.87695e-05, gnorm=0.547, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=28317
2023-01-06 22:41:42 - progress_bar.py[line:274] - INFO: epoch 001:   7390 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2292, wps=104.5, ups=0.47, wpb=110.2, bsz=40, num_updates=7380, lr=4.8765e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28338
2023-01-06 22:42:04 - progress_bar.py[line:274] - INFO: epoch 001:   7400 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2174, wps=102, ups=0.47, wpb=108.5, bsz=40, num_updates=7390, lr=4.87605e-05, gnorm=0.86, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28360
2023-01-06 22:42:26 - progress_bar.py[line:274] - INFO: epoch 001:   7410 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1726, wps=102.1, ups=0.47, wpb=109.3, bsz=40, num_updates=7400, lr=4.8756e-05, gnorm=0.503, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28381
2023-01-06 22:42:47 - progress_bar.py[line:274] - INFO: epoch 001:   7420 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2143, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=7410, lr=4.87515e-05, gnorm=0.504, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28403
2023-01-06 22:43:09 - progress_bar.py[line:274] - INFO: epoch 001:   7430 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1907, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=7420, lr=4.8747e-05, gnorm=0.643, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28425
2023-01-06 22:43:31 - progress_bar.py[line:274] - INFO: epoch 001:   7440 / 115845 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.18, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=7430, lr=4.87425e-05, gnorm=0.563, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28447
2023-01-06 22:43:53 - progress_bar.py[line:274] - INFO: epoch 001:   7450 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2019, wps=101.6, ups=0.47, wpb=108.7, bsz=40, num_updates=7440, lr=4.8738e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=28468
2023-01-06 22:44:14 - progress_bar.py[line:274] - INFO: epoch 001:   7460 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.226, wps=104.4, ups=0.47, wpb=111.9, bsz=40, num_updates=7450, lr=4.87335e-05, gnorm=0.528, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=28490
2023-01-06 22:44:36 - progress_bar.py[line:274] - INFO: epoch 001:   7470 / 115845 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1707, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=7460, lr=4.8729e-05, gnorm=0.625, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=28512
2023-01-06 22:44:38 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-06 22:45:00 - progress_bar.py[line:274] - INFO: epoch 001:   7481 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.524, nsentences=40, sample_size=108.524, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2158, wps=98.1, ups=0.43, wpb=108.5, bsz=40, num_updates=7470, lr=4.87245e-05, gnorm=0.859, clip=20, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=28536
2023-01-06 22:45:21 - progress_bar.py[line:274] - INFO: epoch 001:   7491 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.225, wps=102.4, ups=0.47, wpb=109.1, bsz=40, num_updates=7480, lr=4.872e-05, gnorm=0.646, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28557
2023-01-06 22:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   7501 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1754, wps=101, ups=0.46, wpb=108.8, bsz=40, num_updates=7490, lr=4.87155e-05, gnorm=0.622, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=28579
2023-01-06 22:46:07 - progress_bar.py[line:274] - INFO: epoch 001:   7511 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1856, wps=100.2, ups=0.45, wpb=110.5, bsz=40, num_updates=7500, lr=4.8711e-05, gnorm=0.464, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=28601
2023-01-06 22:46:29 - progress_bar.py[line:274] - INFO: epoch 001:   7521 / 115845 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1845, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=7510, lr=4.87065e-05, gnorm=0.558, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28624
2023-01-06 22:46:51 - progress_bar.py[line:274] - INFO: epoch 001:   7531 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2525, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=7520, lr=4.8702e-05, gnorm=0.557, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28646
2023-01-06 22:47:13 - progress_bar.py[line:274] - INFO: epoch 001:   7541 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1927, wps=100, ups=0.46, wpb=108.1, bsz=40, num_updates=7530, lr=4.86975e-05, gnorm=0.733, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=28668
2023-01-06 22:47:35 - progress_bar.py[line:274] - INFO: epoch 001:   7551 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1818, wps=102, ups=0.46, wpb=110.9, bsz=40, num_updates=7540, lr=4.8693e-05, gnorm=0.589, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28690
2023-01-06 22:47:56 - progress_bar.py[line:274] - INFO: epoch 001:   7561 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1863, wps=102.8, ups=0.47, wpb=108.9, bsz=40, num_updates=7550, lr=4.86885e-05, gnorm=0.827, clip=10, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=28712
2023-01-06 22:48:18 - progress_bar.py[line:274] - INFO: epoch 001:   7571 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2, wps=102.1, ups=0.47, wpb=109.5, bsz=40, num_updates=7560, lr=4.8684e-05, gnorm=0.583, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28734
2023-01-06 22:48:39 - progress_bar.py[line:274] - INFO: epoch 001:   7581 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2312, wps=102.4, ups=0.47, wpb=108.9, bsz=40, num_updates=7570, lr=4.86795e-05, gnorm=0.431, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28755
2023-01-06 22:49:00 - progress_bar.py[line:274] - INFO: epoch 001:   7591 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2087, wps=102.5, ups=0.47, wpb=107.9, bsz=40, num_updates=7580, lr=4.86751e-05, gnorm=0.609, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28776
2023-01-06 22:49:23 - progress_bar.py[line:274] - INFO: epoch 001:   7601 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2251, wps=100.9, ups=0.46, wpb=110.1, bsz=40, num_updates=7590, lr=4.86706e-05, gnorm=0.591, clip=10, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=28798
2023-01-06 22:49:44 - progress_bar.py[line:274] - INFO: epoch 001:   7611 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2404, wps=101.9, ups=0.47, wpb=108.7, bsz=40, num_updates=7600, lr=4.86661e-05, gnorm=0.548, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28820
2023-01-06 22:50:05 - progress_bar.py[line:274] - INFO: epoch 001:   7621 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2338, wps=103.7, ups=0.48, wpb=108.6, bsz=40, num_updates=7610, lr=4.86616e-05, gnorm=0.542, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28841
2023-01-06 22:50:27 - progress_bar.py[line:274] - INFO: epoch 001:   7631 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2449, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=7620, lr=4.86571e-05, gnorm=0.528, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=28863
2023-01-06 22:50:52 - progress_bar.py[line:274] - INFO: epoch 001:   7641 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.197, wps=90, ups=0.41, wpb=108.6, bsz=40, num_updates=7630, lr=4.86526e-05, gnorm=0.699, clip=10, loss_scale=256, train_wall=24, gb_free=10.1, ema_decay=0.9999, wall=28887
2023-01-06 22:51:13 - progress_bar.py[line:274] - INFO: epoch 001:   7651 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1707, wps=101, ups=0.46, wpb=109.3, bsz=40, num_updates=7640, lr=4.86481e-05, gnorm=0.624, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=28909
2023-01-06 22:51:35 - progress_bar.py[line:274] - INFO: epoch 001:   7661 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2051, wps=103.4, ups=0.47, wpb=109.4, bsz=40, num_updates=7650, lr=4.86436e-05, gnorm=0.629, clip=20, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=28931
2023-01-06 22:51:57 - progress_bar.py[line:274] - INFO: epoch 001:   7671 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2011, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=7660, lr=4.86391e-05, gnorm=0.528, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=28952
2023-01-06 22:52:18 - progress_bar.py[line:274] - INFO: epoch 001:   7681 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.1762, wps=102.1, ups=0.47, wpb=108.3, bsz=40, num_updates=7670, lr=4.86346e-05, gnorm=0.658, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28974
2023-01-06 22:52:40 - progress_bar.py[line:274] - INFO: epoch 001:   7691 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2183, wps=102.2, ups=0.47, wpb=109.5, bsz=40, num_updates=7680, lr=4.86301e-05, gnorm=0.493, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=28996
2023-01-06 22:53:01 - progress_bar.py[line:274] - INFO: epoch 001:   7701 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2347, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=7690, lr=4.86256e-05, gnorm=0.522, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29017
2023-01-06 22:53:23 - progress_bar.py[line:274] - INFO: epoch 001:   7711 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.215, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=7700, lr=4.86211e-05, gnorm=0.52, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29039
2023-01-06 22:53:45 - progress_bar.py[line:274] - INFO: epoch 001:   7721 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2394, wps=99.5, ups=0.46, wpb=108.3, bsz=40, num_updates=7710, lr=4.86166e-05, gnorm=0.499, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29061
2023-01-06 22:54:08 - progress_bar.py[line:274] - INFO: epoch 001:   7731 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.226, wps=98.1, ups=0.46, wpb=107.7, bsz=40, num_updates=7720, lr=4.86121e-05, gnorm=0.442, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29083
2023-01-06 22:54:30 - progress_bar.py[line:274] - INFO: epoch 001:   7741 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2347, wps=99.9, ups=0.45, wpb=109.8, bsz=40, num_updates=7730, lr=4.86076e-05, gnorm=0.683, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29106
2023-01-06 22:54:51 - progress_bar.py[line:274] - INFO: epoch 001:   7751 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2549, wps=102.8, ups=0.47, wpb=108.3, bsz=40, num_updates=7740, lr=4.86031e-05, gnorm=0.646, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=29127
2023-01-06 22:55:13 - progress_bar.py[line:274] - INFO: epoch 001:   7761 / 115845 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.204, wps=99.4, ups=0.46, wpb=108.6, bsz=40, num_updates=7750, lr=4.85986e-05, gnorm=0.623, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=29149
2023-01-06 22:55:35 - progress_bar.py[line:274] - INFO: epoch 001:   7771 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1827, wps=102.1, ups=0.47, wpb=109, bsz=40, num_updates=7760, lr=4.85941e-05, gnorm=0.478, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=29171
2023-01-06 22:55:57 - progress_bar.py[line:274] - INFO: epoch 001:   7781 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1576, wps=102.4, ups=0.47, wpb=109.8, bsz=40, num_updates=7770, lr=4.85896e-05, gnorm=0.541, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29193
2023-01-06 22:56:19 - progress_bar.py[line:274] - INFO: epoch 001:   7791 / 115845 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2857, wps=98.7, ups=0.46, wpb=108, bsz=40, num_updates=7780, lr=4.85851e-05, gnorm=0.721, clip=10, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=29215
2023-01-06 22:56:41 - progress_bar.py[line:274] - INFO: epoch 001:   7801 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1717, wps=99.4, ups=0.46, wpb=108.6, bsz=40, num_updates=7790, lr=4.85806e-05, gnorm=0.479, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29237
2023-01-06 22:57:03 - progress_bar.py[line:274] - INFO: epoch 001:   7811 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.228, wps=102.9, ups=0.47, wpb=108.9, bsz=40, num_updates=7800, lr=4.85761e-05, gnorm=0.584, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=29258
2023-01-06 22:57:24 - progress_bar.py[line:274] - INFO: epoch 001:   7821 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2347, wps=102.6, ups=0.47, wpb=109.6, bsz=40, num_updates=7810, lr=4.85716e-05, gnorm=0.529, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=29280
2023-01-06 22:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   7831 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.301, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=7820, lr=4.85672e-05, gnorm=0.581, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29302
2023-01-06 22:58:08 - progress_bar.py[line:274] - INFO: epoch 001:   7841 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2567, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=7830, lr=4.85627e-05, gnorm=0.728, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=29324
2023-01-06 22:58:30 - progress_bar.py[line:274] - INFO: epoch 001:   7851 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2059, wps=98.1, ups=0.45, wpb=108.3, bsz=40, num_updates=7840, lr=4.85582e-05, gnorm=0.588, clip=0, loss_scale=256, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=29346
2023-01-06 22:58:52 - progress_bar.py[line:274] - INFO: epoch 001:   7861 / 115845 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.3226, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=7850, lr=4.85537e-05, gnorm=0.67, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29368
2023-01-06 22:59:13 - progress_bar.py[line:274] - INFO: epoch 001:   7871 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.1827, wps=101.4, ups=0.47, wpb=107.2, bsz=40, num_updates=7860, lr=4.85492e-05, gnorm=0.587, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29389
2023-01-06 22:59:35 - progress_bar.py[line:274] - INFO: epoch 001:   7881 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2412, wps=100.5, ups=0.46, wpb=108.8, bsz=40, num_updates=7870, lr=4.85447e-05, gnorm=0.403, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29411
2023-01-06 22:59:58 - progress_bar.py[line:274] - INFO: epoch 001:   7891 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.256, wps=96.9, ups=0.45, wpb=107.2, bsz=40, num_updates=7880, lr=4.85402e-05, gnorm=0.64, clip=20, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=29434
2023-01-06 23:00:20 - progress_bar.py[line:274] - INFO: epoch 001:   7901 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2356, wps=99, ups=0.46, wpb=107.6, bsz=40, num_updates=7890, lr=4.85357e-05, gnorm=0.624, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=29456
2023-01-06 23:00:42 - progress_bar.py[line:274] - INFO: epoch 001:   7911 / 115845 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.1469, wps=98.8, ups=0.46, wpb=108.1, bsz=40, num_updates=7900, lr=4.85312e-05, gnorm=0.546, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29478
2023-01-06 23:01:03 - progress_bar.py[line:274] - INFO: epoch 001:   7921 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.1957, wps=105.4, ups=0.47, wpb=111.5, bsz=40, num_updates=7910, lr=4.85267e-05, gnorm=0.64, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=29499
2023-01-06 23:01:25 - progress_bar.py[line:274] - INFO: epoch 001:   7931 / 115845 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2475, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=7920, lr=4.85222e-05, gnorm=0.872, clip=30, loss_scale=256, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=29521
2023-01-06 23:01:47 - progress_bar.py[line:274] - INFO: epoch 001:   7941 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2474, wps=103.3, ups=0.47, wpb=110.5, bsz=40, num_updates=7930, lr=4.85177e-05, gnorm=0.619, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=29543
2023-01-06 23:02:09 - progress_bar.py[line:274] - INFO: epoch 001:   7951 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2338, wps=101.1, ups=0.47, wpb=108, bsz=40, num_updates=7940, lr=4.85132e-05, gnorm=0.506, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29564
2023-01-06 23:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   7961 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2784, wps=102.5, ups=0.46, wpb=110.4, bsz=40, num_updates=7950, lr=4.85087e-05, gnorm=0.547, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=29586
2023-01-06 23:02:52 - progress_bar.py[line:274] - INFO: epoch 001:   7971 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.225, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=7960, lr=4.85042e-05, gnorm=0.496, clip=0, loss_scale=256, train_wall=21, gb_free=9.3, ema_decay=0.9999, wall=29608
2023-01-06 23:03:14 - progress_bar.py[line:274] - INFO: epoch 001:   7981 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.268, wps=103.4, ups=0.47, wpb=110.1, bsz=40, num_updates=7970, lr=4.84997e-05, gnorm=0.566, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29630
2023-01-06 23:03:35 - progress_bar.py[line:274] - INFO: epoch 001:   7991 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2216, wps=101.7, ups=0.46, wpb=109.4, bsz=40, num_updates=7980, lr=4.84952e-05, gnorm=0.481, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=29651
2023-01-06 23:03:58 - progress_bar.py[line:274] - INFO: epoch 001:   8001 / 115845 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2611, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=7990, lr=4.84907e-05, gnorm=0.61, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=29673
2023-01-06 23:04:20 - progress_bar.py[line:274] - INFO: epoch 001:   8011 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.239, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=8000, lr=4.84862e-05, gnorm=0.526, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=29695
2023-01-06 23:04:20 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-06 23:04:21 - train.py[line:549] - INFO: 0 / 4988
2023-01-06 23:04:21 - train.py[line:551] - INFO: load:1.02 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-06 23:06:54 - train.py[line:549] - INFO: 200 / 4988
2023-01-06 23:06:54 - train.py[line:551] - INFO: load:1.05 valid_run:153.18 task_valid:149.14 collect_output:2.98
2023-01-06 23:09:23 - train.py[line:549] - INFO: 400 / 4988
2023-01-06 23:09:23 - train.py[line:551] - INFO: load:1.07 valid_run:302.26 task_valid:291.88 collect_output:8.26
2023-01-06 23:11:57 - train.py[line:549] - INFO: 600 / 4988
2023-01-06 23:11:57 - train.py[line:551] - INFO: load:1.10 valid_run:455.46 task_valid:434.52 collect_output:17.76
2023-01-06 23:14:27 - train.py[line:549] - INFO: 800 / 4988
2023-01-06 23:14:27 - train.py[line:551] - INFO: load:1.12 valid_run:605.40 task_valid:579.21 collect_output:21.95
2023-01-06 23:17:00 - train.py[line:549] - INFO: 1000 / 4988
2023-01-06 23:17:00 - train.py[line:551] - INFO: load:1.15 valid_run:758.49 task_valid:726.45 collect_output:26.76
2023-01-06 23:19:32 - train.py[line:549] - INFO: 1200 / 4988
2023-01-06 23:19:32 - train.py[line:551] - INFO: load:1.18 valid_run:910.79 task_valid:871.54 collect_output:32.92
2023-01-06 23:22:07 - train.py[line:549] - INFO: 1400 / 4988
2023-01-06 23:22:07 - train.py[line:551] - INFO: load:1.20 valid_run:1065.30 task_valid:1017.14 collect_output:40.80
2023-01-06 23:24:39 - train.py[line:549] - INFO: 1600 / 4988
2023-01-06 23:24:39 - train.py[line:551] - INFO: load:1.23 valid_run:1217.46 task_valid:1157.65 collect_output:51.45
2023-01-06 23:27:09 - train.py[line:549] - INFO: 1800 / 4988
2023-01-06 23:27:09 - train.py[line:551] - INFO: load:1.25 valid_run:1367.96 task_valid:1302.23 collect_output:56.32
2023-01-06 23:29:39 - train.py[line:549] - INFO: 2000 / 4988
2023-01-06 23:29:39 - train.py[line:551] - INFO: load:1.28 valid_run:1517.00 task_valid:1444.95 collect_output:61.62
2023-01-06 23:32:10 - train.py[line:549] - INFO: 2200 / 4988
2023-01-06 23:32:10 - train.py[line:551] - INFO: load:1.30 valid_run:1668.01 task_valid:1589.59 collect_output:66.97
2023-01-06 23:34:41 - train.py[line:549] - INFO: 2400 / 4988
2023-01-06 23:34:41 - train.py[line:551] - INFO: load:1.33 valid_run:1818.86 task_valid:1734.28 collect_output:72.11
2023-01-06 23:37:11 - train.py[line:549] - INFO: 2600 / 4988
2023-01-06 23:37:11 - train.py[line:551] - INFO: load:1.35 valid_run:1969.67 task_valid:1875.80 collect_output:80.38
2023-01-06 23:39:43 - train.py[line:549] - INFO: 2800 / 4988
2023-01-06 23:39:43 - train.py[line:551] - INFO: load:1.38 valid_run:2121.22 task_valid:2020.92 collect_output:85.80
2023-01-06 23:42:14 - train.py[line:549] - INFO: 3000 / 4988
2023-01-06 23:42:14 - train.py[line:551] - INFO: load:1.41 valid_run:2271.80 task_valid:2167.09 collect_output:89.19
2023-01-06 23:44:44 - train.py[line:549] - INFO: 3200 / 4988
2023-01-06 23:44:44 - train.py[line:551] - INFO: load:1.43 valid_run:2422.38 task_valid:2310.88 collect_output:94.98
2023-01-06 23:47:17 - train.py[line:549] - INFO: 3400 / 4988
2023-01-06 23:47:17 - train.py[line:551] - INFO: load:1.46 valid_run:2574.96 task_valid:2456.24 collect_output:101.19
2023-01-06 23:49:48 - train.py[line:549] - INFO: 3600 / 4988
2023-01-06 23:49:48 - train.py[line:551] - INFO: load:1.48 valid_run:2725.83 task_valid:2602.90 collect_output:104.36
2023-01-06 23:52:17 - train.py[line:549] - INFO: 3800 / 4988
2023-01-06 23:52:17 - train.py[line:551] - INFO: load:1.51 valid_run:2874.85 task_valid:2744.05 collect_output:111.23
2023-01-06 23:54:48 - train.py[line:549] - INFO: 4000 / 4988
2023-01-06 23:54:48 - train.py[line:551] - INFO: load:1.54 valid_run:3025.59 task_valid:2888.81 collect_output:116.19
2023-01-06 23:57:21 - train.py[line:549] - INFO: 4200 / 4988
2023-01-06 23:57:21 - train.py[line:551] - INFO: load:1.56 valid_run:3178.46 task_valid:3033.25 collect_output:123.64
2023-01-06 23:59:51 - train.py[line:549] - INFO: 4400 / 4988
2023-01-06 23:59:51 - train.py[line:551] - INFO: load:1.59 valid_run:3328.29 task_valid:3177.55 collect_output:128.15
2023-01-07 00:02:23 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 00:02:23 - train.py[line:551] - INFO: load:1.62 valid_run:3480.16 task_valid:3323.46 collect_output:133.11
2023-01-07 00:04:56 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 00:04:56 - train.py[line:551] - INFO: load:1.65 valid_run:3633.75 task_valid:3471.37 collect_output:137.69

====================================================================================================
SGG eval:     R @ 50: 0.5600;     R @ 100: 0.6210;     R @ 500: 0.6654;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3528;    mR @ 100: 0.4020;    mR @ 500: 0.4563;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9085) (says:0.0000) (sitting on:0.7285) (standing on:0.2233) (using:0.6500) (walking in:0.0000) (walking on:0.8108) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-01-07 00:07:28 - train.py[line:487] - INFO: 0.620978151260504

====================================================================================================
SGG eval:     R @ 50: 0.5600;     R @ 100: 0.6210;     R @ 500: 0.6654;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3528;    mR @ 100: 0.4020;    mR @ 500: 0.4563;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4516) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9085) (says:0.0000) (sitting on:0.7285) (standing on:0.2233) (using:0.6500) (walking in:0.0000) (walking on:0.8108) (watching:0.2222) 
--------------------------------------------------------
====================================================================================================

2023-01-07 00:07:28 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 00:07:28 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.34 | loss_v1 0 | loss_v2 0 | nll_loss 0.183 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.620978 | ppl 1.14 | vqa_score 0.5236 | wps 118.5 | wpb 89.9 | bsz 30 | num_updates 8000 | best_R@100 0.641887
2023-01-07 00:07:28 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2023-01-07 00:07:28 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt
2023-01-07 00:08:10 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt
2023-01-07 00:09:35 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.620978151260504) (writing took 126.43092785403132 seconds)
2023-01-07 00:09:57 - progress_bar.py[line:274] - INFO: epoch 001:   8021 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.25, wps=0.6, ups=0, wpb=110, bsz=40, num_updates=8010, lr=4.84817e-05, gnorm=0.713, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33632
2023-01-07 00:10:18 - progress_bar.py[line:274] - INFO: epoch 001:   8031 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2513, wps=104, ups=0.47, wpb=110.1, bsz=40, num_updates=8020, lr=4.84772e-05, gnorm=0.6, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=33654
2023-01-07 00:10:40 - progress_bar.py[line:274] - INFO: epoch 001:   8041 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2297, wps=100.4, ups=0.46, wpb=108.7, bsz=40, num_updates=8030, lr=4.84727e-05, gnorm=0.488, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=33676
2023-01-07 00:11:01 - progress_bar.py[line:274] - INFO: epoch 001:   8051 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2915, wps=103, ups=0.47, wpb=109.7, bsz=40, num_updates=8040, lr=4.84682e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=33697
2023-01-07 00:11:22 - progress_bar.py[line:274] - INFO: epoch 001:   8061 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2757, wps=105.6, ups=0.48, wpb=109.4, bsz=40, num_updates=8050, lr=4.84637e-05, gnorm=0.527, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33718
2023-01-07 00:11:44 - progress_bar.py[line:274] - INFO: epoch 001:   8071 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2513, wps=102.2, ups=0.47, wpb=109.8, bsz=40, num_updates=8060, lr=4.84592e-05, gnorm=0.474, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=33740
2023-01-07 00:12:06 - progress_bar.py[line:274] - INFO: epoch 001:   8081 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.264, wps=102.5, ups=0.47, wpb=108.5, bsz=40, num_updates=8070, lr=4.84548e-05, gnorm=0.601, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33761
2023-01-07 00:12:28 - progress_bar.py[line:274] - INFO: epoch 001:   8091 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2632, wps=99.8, ups=0.46, wpb=108.5, bsz=40, num_updates=8080, lr=4.84503e-05, gnorm=0.597, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=33783
2023-01-07 00:12:49 - progress_bar.py[line:274] - INFO: epoch 001:   8101 / 115845 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.2149, wps=100.9, ups=0.47, wpb=108.2, bsz=40, num_updates=8090, lr=4.84458e-05, gnorm=0.519, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=33805
2023-01-07 00:13:11 - progress_bar.py[line:274] - INFO: epoch 001:   8111 / 115845 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2139, wps=103.6, ups=0.47, wpb=109.1, bsz=40, num_updates=8100, lr=4.84413e-05, gnorm=0.569, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=33826
2023-01-07 00:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   8121 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2703, wps=99.9, ups=0.46, wpb=109.6, bsz=40, num_updates=8110, lr=4.84368e-05, gnorm=0.554, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=33849
2023-01-07 00:13:55 - progress_bar.py[line:274] - INFO: epoch 001:   8131 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2, wps=103.1, ups=0.47, wpb=110.2, bsz=40, num_updates=8120, lr=4.84323e-05, gnorm=0.359, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=33870
2023-01-07 00:14:17 - progress_bar.py[line:274] - INFO: epoch 001:   8141 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2577, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=8130, lr=4.84278e-05, gnorm=0.625, clip=20, loss_scale=512, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=33892
2023-01-07 00:14:39 - progress_bar.py[line:274] - INFO: epoch 001:   8151 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2772, wps=101.8, ups=0.46, wpb=110.6, bsz=40, num_updates=8140, lr=4.84233e-05, gnorm=0.52, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=33914
2023-01-07 00:15:00 - progress_bar.py[line:274] - INFO: epoch 001:   8161 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3211, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=8150, lr=4.84188e-05, gnorm=0.502, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=33936
2023-01-07 00:15:22 - progress_bar.py[line:274] - INFO: epoch 001:   8171 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2135, wps=104.6, ups=0.48, wpb=109.9, bsz=40, num_updates=8160, lr=4.84143e-05, gnorm=0.576, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=33958
2023-01-07 00:15:43 - progress_bar.py[line:274] - INFO: epoch 001:   8181 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3315, wps=104.3, ups=0.47, wpb=111, bsz=40, num_updates=8170, lr=4.84098e-05, gnorm=0.628, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=33979
2023-01-07 00:16:05 - progress_bar.py[line:274] - INFO: epoch 001:   8191 / 115845 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2783, wps=101.3, ups=0.47, wpb=108.9, bsz=40, num_updates=8180, lr=4.84053e-05, gnorm=0.605, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34001
2023-01-07 00:16:27 - progress_bar.py[line:274] - INFO: epoch 001:   8201 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2775, wps=101.2, ups=0.46, wpb=110.2, bsz=40, num_updates=8190, lr=4.84008e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34023
2023-01-07 00:16:49 - progress_bar.py[line:274] - INFO: epoch 001:   8211 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2823, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=8200, lr=4.83963e-05, gnorm=0.54, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34045
2023-01-07 00:17:11 - progress_bar.py[line:274] - INFO: epoch 001:   8221 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.241, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=8210, lr=4.83918e-05, gnorm=0.558, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34066
2023-01-07 00:17:33 - progress_bar.py[line:274] - INFO: epoch 001:   8231 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2723, wps=99.2, ups=0.46, wpb=108.7, bsz=40, num_updates=8220, lr=4.83873e-05, gnorm=0.622, clip=10, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=34089
2023-01-07 00:17:55 - progress_bar.py[line:274] - INFO: epoch 001:   8241 / 115845 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2864, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=8230, lr=4.83828e-05, gnorm=0.737, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34110
2023-01-07 00:18:17 - progress_bar.py[line:274] - INFO: epoch 001:   8251 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2374, wps=100.5, ups=0.46, wpb=108.8, bsz=40, num_updates=8240, lr=4.83783e-05, gnorm=0.532, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=34132
2023-01-07 00:18:27 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 00:18:41 - progress_bar.py[line:274] - INFO: epoch 001:   8262 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.952, nsentences=40, sample_size=108.952, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3319, wps=95.7, ups=0.42, wpb=109, bsz=40, num_updates=8250, lr=4.83738e-05, gnorm=0.504, clip=0, loss_scale=256, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=34157
2023-01-07 00:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   8272 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2475, wps=100.3, ups=0.46, wpb=108.5, bsz=40, num_updates=8260, lr=4.83693e-05, gnorm=0.492, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=34178
2023-01-07 00:19:24 - progress_bar.py[line:274] - INFO: epoch 001:   8282 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.276, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=8270, lr=4.83648e-05, gnorm=0.542, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34200
2023-01-07 00:19:46 - progress_bar.py[line:274] - INFO: epoch 001:   8292 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2486, wps=102.1, ups=0.47, wpb=109.7, bsz=40, num_updates=8280, lr=4.83603e-05, gnorm=0.402, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=34222
2023-01-07 00:20:08 - progress_bar.py[line:274] - INFO: epoch 001:   8302 / 115845 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2279, wps=99.4, ups=0.46, wpb=108, bsz=40, num_updates=8290, lr=4.83558e-05, gnorm=0.457, clip=0, loss_scale=256, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=34244
2023-01-07 00:20:30 - progress_bar.py[line:274] - INFO: epoch 001:   8312 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3229, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=8300, lr=4.83513e-05, gnorm=0.553, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34266
2023-01-07 00:20:52 - progress_bar.py[line:274] - INFO: epoch 001:   8322 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2698, wps=102.2, ups=0.47, wpb=109.6, bsz=40, num_updates=8310, lr=4.83469e-05, gnorm=0.628, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=34288
2023-01-07 00:21:13 - progress_bar.py[line:274] - INFO: epoch 001:   8332 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3302, wps=102, ups=0.47, wpb=108, bsz=40, num_updates=8320, lr=4.83424e-05, gnorm=0.479, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34309
2023-01-07 00:21:35 - progress_bar.py[line:274] - INFO: epoch 001:   8342 / 115845 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2514, wps=102, ups=0.47, wpb=109.4, bsz=40, num_updates=8330, lr=4.83379e-05, gnorm=0.552, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=34331
2023-01-07 00:21:56 - progress_bar.py[line:274] - INFO: epoch 001:   8352 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2769, wps=103.8, ups=0.47, wpb=109.5, bsz=40, num_updates=8340, lr=4.83334e-05, gnorm=0.446, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34352
2023-01-07 00:22:19 - progress_bar.py[line:274] - INFO: epoch 001:   8362 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3085, wps=99.7, ups=0.45, wpb=109.7, bsz=40, num_updates=8350, lr=4.83289e-05, gnorm=0.504, clip=0, loss_scale=256, train_wall=22, gb_free=9.4, ema_decay=0.9999, wall=34375
2023-01-07 00:22:41 - progress_bar.py[line:274] - INFO: epoch 001:   8372 / 115845 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2398, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=8360, lr=4.83244e-05, gnorm=0.548, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=34396
2023-01-07 00:23:03 - progress_bar.py[line:274] - INFO: epoch 001:   8382 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2857, wps=100.2, ups=0.46, wpb=108.9, bsz=40, num_updates=8370, lr=4.83199e-05, gnorm=0.547, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34418
2023-01-07 00:23:25 - progress_bar.py[line:274] - INFO: epoch 001:   8392 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2524, wps=99.7, ups=0.46, wpb=109.1, bsz=40, num_updates=8380, lr=4.83154e-05, gnorm=0.42, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34441
2023-01-07 00:23:47 - progress_bar.py[line:274] - INFO: epoch 001:   8402 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2704, wps=101.9, ups=0.47, wpb=109.4, bsz=40, num_updates=8390, lr=4.83109e-05, gnorm=0.516, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34462
2023-01-07 00:24:09 - progress_bar.py[line:274] - INFO: epoch 001:   8412 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2802, wps=99.7, ups=0.46, wpb=108.8, bsz=40, num_updates=8400, lr=4.83064e-05, gnorm=0.502, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=34484
2023-01-07 00:24:30 - progress_bar.py[line:274] - INFO: epoch 001:   8422 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2834, wps=102, ups=0.47, wpb=108.8, bsz=40, num_updates=8410, lr=4.83019e-05, gnorm=0.637, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=34506
2023-01-07 00:24:52 - progress_bar.py[line:274] - INFO: epoch 001:   8432 / 115845 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.283, wps=101.7, ups=0.47, wpb=108.7, bsz=40, num_updates=8420, lr=4.82974e-05, gnorm=0.724, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34528
2023-01-07 00:25:13 - progress_bar.py[line:274] - INFO: epoch 001:   8442 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2709, wps=103.7, ups=0.47, wpb=109.5, bsz=40, num_updates=8430, lr=4.82929e-05, gnorm=0.575, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34549
2023-01-07 00:25:34 - progress_bar.py[line:274] - INFO: epoch 001:   8452 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2292, wps=106.6, ups=0.48, wpb=110.8, bsz=40, num_updates=8440, lr=4.82884e-05, gnorm=0.556, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=34570
2023-01-07 00:25:56 - progress_bar.py[line:274] - INFO: epoch 001:   8462 / 115845 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3166, wps=102, ups=0.47, wpb=109.1, bsz=40, num_updates=8450, lr=4.82839e-05, gnorm=0.578, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=34592
2023-01-07 00:26:17 - progress_bar.py[line:274] - INFO: epoch 001:   8472 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2474, wps=101.8, ups=0.47, wpb=108.4, bsz=40, num_updates=8460, lr=4.82794e-05, gnorm=0.754, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34613
2023-01-07 00:26:39 - progress_bar.py[line:274] - INFO: epoch 001:   8482 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2814, wps=100.8, ups=0.47, wpb=108.2, bsz=40, num_updates=8470, lr=4.82749e-05, gnorm=0.501, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34635
2023-01-07 00:27:01 - progress_bar.py[line:274] - INFO: epoch 001:   8492 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2778, wps=100.4, ups=0.46, wpb=108.4, bsz=40, num_updates=8480, lr=4.82704e-05, gnorm=0.432, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34657
2023-01-07 00:27:22 - progress_bar.py[line:274] - INFO: epoch 001:   8502 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3096, wps=103.5, ups=0.47, wpb=109.7, bsz=40, num_updates=8490, lr=4.82659e-05, gnorm=0.522, clip=0, loss_scale=256, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=34678
2023-01-07 00:27:44 - progress_bar.py[line:274] - INFO: epoch 001:   8512 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3061, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=8500, lr=4.82614e-05, gnorm=0.477, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=34700
2023-01-07 00:28:06 - progress_bar.py[line:274] - INFO: epoch 001:   8522 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2809, wps=100.8, ups=0.46, wpb=110.4, bsz=40, num_updates=8510, lr=4.82569e-05, gnorm=0.49, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=34722
2023-01-07 00:28:28 - progress_bar.py[line:274] - INFO: epoch 001:   8532 / 115845 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2525, wps=100.1, ups=0.46, wpb=108.1, bsz=40, num_updates=8520, lr=4.82524e-05, gnorm=0.585, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34744
2023-01-07 00:28:50 - progress_bar.py[line:274] - INFO: epoch 001:   8542 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2915, wps=102.4, ups=0.46, wpb=110.1, bsz=40, num_updates=8530, lr=4.82479e-05, gnorm=0.692, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34766
2023-01-07 00:29:12 - progress_bar.py[line:274] - INFO: epoch 001:   8552 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3366, wps=102.9, ups=0.47, wpb=109.3, bsz=40, num_updates=8540, lr=4.82434e-05, gnorm=0.47, clip=0, loss_scale=256, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=34787
2023-01-07 00:29:33 - progress_bar.py[line:274] - INFO: epoch 001:   8562 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2871, wps=102.6, ups=0.47, wpb=110.1, bsz=40, num_updates=8550, lr=4.82389e-05, gnorm=0.531, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=34809
2023-01-07 00:29:55 - progress_bar.py[line:274] - INFO: epoch 001:   8572 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2917, wps=99.4, ups=0.46, wpb=108.5, bsz=40, num_updates=8560, lr=4.82345e-05, gnorm=0.434, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=34831
2023-01-07 00:30:17 - progress_bar.py[line:274] - INFO: epoch 001:   8582 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3267, wps=102.5, ups=0.47, wpb=109.5, bsz=40, num_updates=8570, lr=4.823e-05, gnorm=0.52, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34853
2023-01-07 00:30:39 - progress_bar.py[line:274] - INFO: epoch 001:   8592 / 115845 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2687, wps=99.9, ups=0.46, wpb=107.4, bsz=40, num_updates=8580, lr=4.82255e-05, gnorm=0.829, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=34875
2023-01-07 00:31:01 - progress_bar.py[line:274] - INFO: epoch 001:   8602 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2609, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=8590, lr=4.8221e-05, gnorm=0.45, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=34897
2023-01-07 00:31:22 - progress_bar.py[line:274] - INFO: epoch 001:   8612 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2959, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=8600, lr=4.82165e-05, gnorm=0.466, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=34918
2023-01-07 00:31:44 - progress_bar.py[line:274] - INFO: epoch 001:   8622 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3088, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=8610, lr=4.8212e-05, gnorm=0.451, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=34940
2023-01-07 00:32:06 - progress_bar.py[line:274] - INFO: epoch 001:   8632 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3065, wps=102.5, ups=0.47, wpb=108, bsz=40, num_updates=8620, lr=4.82075e-05, gnorm=0.449, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=34961
2023-01-07 00:32:27 - progress_bar.py[line:274] - INFO: epoch 001:   8642 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.2977, wps=100.2, ups=0.46, wpb=108.2, bsz=40, num_updates=8630, lr=4.8203e-05, gnorm=0.602, clip=10, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=34983
2023-01-07 00:32:49 - progress_bar.py[line:274] - INFO: epoch 001:   8652 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2973, wps=102.5, ups=0.47, wpb=110, bsz=40, num_updates=8640, lr=4.81985e-05, gnorm=0.513, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35005
2023-01-07 00:33:11 - progress_bar.py[line:274] - INFO: epoch 001:   8662 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2732, wps=98.8, ups=0.45, wpb=108.9, bsz=40, num_updates=8650, lr=4.8194e-05, gnorm=0.543, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35027
2023-01-07 00:33:33 - progress_bar.py[line:274] - INFO: epoch 001:   8672 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3122, wps=102.7, ups=0.47, wpb=110.2, bsz=40, num_updates=8660, lr=4.81895e-05, gnorm=0.509, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35049
2023-01-07 00:33:55 - progress_bar.py[line:274] - INFO: epoch 001:   8682 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3427, wps=100.6, ups=0.47, wpb=107.7, bsz=40, num_updates=8670, lr=4.8185e-05, gnorm=0.535, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35071
2023-01-07 00:34:17 - progress_bar.py[line:274] - INFO: epoch 001:   8692 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2849, wps=99.4, ups=0.45, wpb=109.6, bsz=40, num_updates=8680, lr=4.81805e-05, gnorm=0.557, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35093
2023-01-07 00:34:39 - progress_bar.py[line:274] - INFO: epoch 001:   8702 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3498, wps=102.6, ups=0.47, wpb=109.5, bsz=40, num_updates=8690, lr=4.8176e-05, gnorm=0.561, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35115
2023-01-07 00:35:01 - progress_bar.py[line:274] - INFO: epoch 001:   8712 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2696, wps=102.2, ups=0.47, wpb=109.1, bsz=40, num_updates=8700, lr=4.81715e-05, gnorm=0.654, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=35136
2023-01-07 00:35:22 - progress_bar.py[line:274] - INFO: epoch 001:   8722 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2593, wps=101.8, ups=0.46, wpb=109.8, bsz=40, num_updates=8710, lr=4.8167e-05, gnorm=0.511, clip=10, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=35158
2023-01-07 00:35:44 - progress_bar.py[line:274] - INFO: epoch 001:   8732 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2663, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=8720, lr=4.81625e-05, gnorm=0.383, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35180
2023-01-07 00:36:06 - progress_bar.py[line:274] - INFO: epoch 001:   8742 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3068, wps=102.3, ups=0.46, wpb=110.4, bsz=40, num_updates=8730, lr=4.8158e-05, gnorm=0.465, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=35202
2023-01-07 00:36:28 - progress_bar.py[line:274] - INFO: epoch 001:   8752 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3265, wps=100.5, ups=0.46, wpb=109.1, bsz=40, num_updates=8740, lr=4.81535e-05, gnorm=0.696, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35224
2023-01-07 00:36:49 - progress_bar.py[line:274] - INFO: epoch 001:   8762 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.315, wps=105.5, ups=0.48, wpb=110.7, bsz=40, num_updates=8750, lr=4.8149e-05, gnorm=0.419, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=35245
2023-01-07 00:37:12 - progress_bar.py[line:274] - INFO: epoch 001:   8772 / 115845 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, vqa_score=0.2922, wps=97.9, ups=0.46, wpb=107.5, bsz=40, num_updates=8760, lr=4.81445e-05, gnorm=0.651, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35267
2023-01-07 00:37:33 - progress_bar.py[line:274] - INFO: epoch 001:   8782 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2925, wps=99.9, ups=0.47, wpb=107, bsz=40, num_updates=8770, lr=4.814e-05, gnorm=0.58, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35289
2023-01-07 00:37:55 - progress_bar.py[line:274] - INFO: epoch 001:   8792 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3128, wps=99.1, ups=0.46, wpb=108.4, bsz=40, num_updates=8780, lr=4.81355e-05, gnorm=0.487, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35311
2023-01-07 00:38:17 - progress_bar.py[line:274] - INFO: epoch 001:   8802 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.2526, wps=101.5, ups=0.46, wpb=109.7, bsz=40, num_updates=8790, lr=4.8131e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=35333
2023-01-07 00:38:39 - progress_bar.py[line:274] - INFO: epoch 001:   8812 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3422, wps=104.3, ups=0.48, wpb=109.6, bsz=40, num_updates=8800, lr=4.81266e-05, gnorm=0.507, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35354
2023-01-07 00:39:00 - progress_bar.py[line:274] - INFO: epoch 001:   8822 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3487, wps=104.7, ups=0.48, wpb=110, bsz=40, num_updates=8810, lr=4.81221e-05, gnorm=0.494, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35376
2023-01-07 00:39:22 - progress_bar.py[line:274] - INFO: epoch 001:   8832 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3039, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=8820, lr=4.81176e-05, gnorm=0.508, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35398
2023-01-07 00:39:43 - progress_bar.py[line:274] - INFO: epoch 001:   8842 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.325, wps=106.2, ups=0.49, wpb=109.2, bsz=40, num_updates=8830, lr=4.81131e-05, gnorm=0.536, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35419
2023-01-07 00:40:05 - progress_bar.py[line:274] - INFO: epoch 001:   8852 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2963, wps=100.4, ups=0.45, wpb=110.5, bsz=40, num_updates=8840, lr=4.81086e-05, gnorm=0.44, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=35441
2023-01-07 00:40:27 - progress_bar.py[line:274] - INFO: epoch 001:   8862 / 115845 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=106.4, nsentences=40, sample_size=106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, vqa_score=0.3231, wps=99.7, ups=0.47, wpb=106.4, bsz=40, num_updates=8850, lr=4.81041e-05, gnorm=0.604, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35463
2023-01-07 00:40:48 - progress_bar.py[line:274] - INFO: epoch 001:   8872 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3667, wps=103.2, ups=0.47, wpb=109.7, bsz=40, num_updates=8860, lr=4.80996e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=35484
2023-01-07 00:41:10 - progress_bar.py[line:274] - INFO: epoch 001:   8882 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3812, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=8870, lr=4.80951e-05, gnorm=0.431, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=35506
2023-01-07 00:41:32 - progress_bar.py[line:274] - INFO: epoch 001:   8892 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3398, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=8880, lr=4.80906e-05, gnorm=0.504, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35528
2023-01-07 00:41:53 - progress_bar.py[line:274] - INFO: epoch 001:   8902 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3399, wps=103.9, ups=0.48, wpb=108.8, bsz=40, num_updates=8890, lr=4.80861e-05, gnorm=0.569, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35549
2023-01-07 00:42:15 - progress_bar.py[line:274] - INFO: epoch 001:   8912 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2284, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=8900, lr=4.80816e-05, gnorm=0.407, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35571
2023-01-07 00:42:36 - progress_bar.py[line:274] - INFO: epoch 001:   8922 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3267, wps=103.4, ups=0.48, wpb=108.3, bsz=40, num_updates=8910, lr=4.80771e-05, gnorm=0.688, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35592
2023-01-07 00:42:58 - progress_bar.py[line:274] - INFO: epoch 001:   8932 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3286, wps=100.4, ups=0.46, wpb=108, bsz=40, num_updates=8920, lr=4.80726e-05, gnorm=0.636, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35614
2023-01-07 00:43:20 - progress_bar.py[line:274] - INFO: epoch 001:   8942 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3349, wps=100.2, ups=0.46, wpb=108.4, bsz=40, num_updates=8930, lr=4.80681e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=35636
2023-01-07 00:43:42 - progress_bar.py[line:274] - INFO: epoch 001:   8952 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3204, wps=101.3, ups=0.46, wpb=110.6, bsz=40, num_updates=8940, lr=4.80636e-05, gnorm=0.541, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35658
2023-01-07 00:44:04 - progress_bar.py[line:274] - INFO: epoch 001:   8962 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3382, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=8950, lr=4.80591e-05, gnorm=0.448, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35680
2023-01-07 00:44:26 - progress_bar.py[line:274] - INFO: epoch 001:   8972 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3529, wps=102.5, ups=0.47, wpb=108.6, bsz=40, num_updates=8960, lr=4.80546e-05, gnorm=0.444, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35701
2023-01-07 00:44:47 - progress_bar.py[line:274] - INFO: epoch 001:   8982 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3027, wps=103.7, ups=0.47, wpb=111.1, bsz=40, num_updates=8970, lr=4.80501e-05, gnorm=0.416, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35723
2023-01-07 00:45:09 - progress_bar.py[line:274] - INFO: epoch 001:   8992 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2995, wps=100.9, ups=0.47, wpb=107.9, bsz=40, num_updates=8980, lr=4.80456e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35745
2023-01-07 00:45:31 - progress_bar.py[line:274] - INFO: epoch 001:   9002 / 115845 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3191, wps=101.5, ups=0.46, wpb=110.2, bsz=40, num_updates=8990, lr=4.80411e-05, gnorm=0.454, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35767
2023-01-07 00:45:52 - progress_bar.py[line:274] - INFO: epoch 001:   9012 / 115845 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3402, wps=104.3, ups=0.47, wpb=110.7, bsz=40, num_updates=9000, lr=4.80366e-05, gnorm=0.49, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35788
2023-01-07 00:46:03 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 00:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   9023 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.952, nsentences=40, sample_size=108.952, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.354, wps=96, ups=0.42, wpb=109, bsz=40, num_updates=9010, lr=4.80321e-05, gnorm=0.372, clip=0, loss_scale=256, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=35812
2023-01-07 00:46:38 - progress_bar.py[line:274] - INFO: epoch 001:   9033 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3557, wps=103.5, ups=0.47, wpb=110.2, bsz=40, num_updates=9020, lr=4.80276e-05, gnorm=0.501, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35834
2023-01-07 00:47:00 - progress_bar.py[line:274] - INFO: epoch 001:   9043 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3252, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=9030, lr=4.80231e-05, gnorm=0.554, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=35856
2023-01-07 00:47:22 - progress_bar.py[line:274] - INFO: epoch 001:   9053 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3366, wps=101.2, ups=0.47, wpb=108.3, bsz=40, num_updates=9040, lr=4.80186e-05, gnorm=0.759, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35877
2023-01-07 00:47:43 - progress_bar.py[line:274] - INFO: epoch 001:   9063 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.369, wps=102.6, ups=0.47, wpb=109.4, bsz=40, num_updates=9050, lr=4.80142e-05, gnorm=0.503, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=35899
2023-01-07 00:48:05 - progress_bar.py[line:274] - INFO: epoch 001:   9073 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2828, wps=99.8, ups=0.46, wpb=108.9, bsz=40, num_updates=9060, lr=4.80097e-05, gnorm=0.492, clip=0, loss_scale=256, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=35921
2023-01-07 00:48:27 - progress_bar.py[line:274] - INFO: epoch 001:   9083 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.395, wps=102.4, ups=0.47, wpb=109.2, bsz=40, num_updates=9070, lr=4.80052e-05, gnorm=0.557, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=35943
2023-01-07 00:48:49 - progress_bar.py[line:274] - INFO: epoch 001:   9093 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.351, wps=99.6, ups=0.46, wpb=107.7, bsz=40, num_updates=9080, lr=4.80007e-05, gnorm=0.573, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=35965
2023-01-07 00:49:11 - progress_bar.py[line:274] - INFO: epoch 001:   9103 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3386, wps=102.7, ups=0.47, wpb=109.9, bsz=40, num_updates=9090, lr=4.79962e-05, gnorm=0.87, clip=20, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=35987
2023-01-07 00:49:33 - progress_bar.py[line:274] - INFO: epoch 001:   9113 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3298, wps=100.3, ups=0.45, wpb=110.3, bsz=40, num_updates=9100, lr=4.79917e-05, gnorm=0.505, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36009
2023-01-07 00:49:55 - progress_bar.py[line:274] - INFO: epoch 001:   9123 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3613, wps=104.2, ups=0.47, wpb=110.4, bsz=40, num_updates=9110, lr=4.79872e-05, gnorm=0.425, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36031
2023-01-07 00:50:17 - progress_bar.py[line:274] - INFO: epoch 001:   9133 / 115845 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3316, wps=101.6, ups=0.46, wpb=109.6, bsz=40, num_updates=9120, lr=4.79827e-05, gnorm=0.622, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36053
2023-01-07 00:50:39 - progress_bar.py[line:274] - INFO: epoch 001:   9143 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3283, wps=99.3, ups=0.45, wpb=109.2, bsz=40, num_updates=9130, lr=4.79782e-05, gnorm=0.408, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=36075
2023-01-07 00:51:01 - progress_bar.py[line:274] - INFO: epoch 001:   9153 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.2938, wps=98.6, ups=0.46, wpb=108.2, bsz=40, num_updates=9140, lr=4.79737e-05, gnorm=0.535, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36097
2023-01-07 00:51:23 - progress_bar.py[line:274] - INFO: epoch 001:   9163 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.369, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=9150, lr=4.79692e-05, gnorm=0.543, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36119
2023-01-07 00:51:45 - progress_bar.py[line:274] - INFO: epoch 001:   9173 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.7, nsentences=40, sample_size=106.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.318, wps=98.3, ups=0.46, wpb=106.7, bsz=40, num_updates=9160, lr=4.79647e-05, gnorm=0.596, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=36141
2023-01-07 00:52:06 - progress_bar.py[line:274] - INFO: epoch 001:   9183 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3333, wps=103.4, ups=0.47, wpb=109.3, bsz=40, num_updates=9170, lr=4.79602e-05, gnorm=0.507, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36162
2023-01-07 00:52:28 - progress_bar.py[line:274] - INFO: epoch 001:   9193 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3333, wps=99.4, ups=0.46, wpb=108.4, bsz=40, num_updates=9180, lr=4.79557e-05, gnorm=0.491, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=36184
2023-01-07 00:52:50 - progress_bar.py[line:274] - INFO: epoch 001:   9203 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3385, wps=102.7, ups=0.47, wpb=109.5, bsz=40, num_updates=9190, lr=4.79512e-05, gnorm=0.554, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36206
2023-01-07 00:53:12 - progress_bar.py[line:274] - INFO: epoch 001:   9213 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3316, wps=102.2, ups=0.46, wpb=110, bsz=40, num_updates=9200, lr=4.79467e-05, gnorm=0.51, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36228
2023-01-07 00:53:34 - progress_bar.py[line:274] - INFO: epoch 001:   9223 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.2554, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=9210, lr=4.79422e-05, gnorm=0.494, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36250
2023-01-07 00:53:56 - progress_bar.py[line:274] - INFO: epoch 001:   9233 / 115845 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, vqa_score=0.319, wps=99.2, ups=0.45, wpb=109.5, bsz=40, num_updates=9220, lr=4.79377e-05, gnorm=0.574, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36272
2023-01-07 00:54:18 - progress_bar.py[line:274] - INFO: epoch 001:   9243 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3186, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=9230, lr=4.79332e-05, gnorm=0.574, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=36294
2023-01-07 00:54:40 - progress_bar.py[line:274] - INFO: epoch 001:   9253 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3744, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=9240, lr=4.79287e-05, gnorm=0.51, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=36316
2023-01-07 00:55:02 - progress_bar.py[line:274] - INFO: epoch 001:   9263 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3229, wps=101.2, ups=0.46, wpb=109.1, bsz=40, num_updates=9250, lr=4.79242e-05, gnorm=0.447, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36338
2023-01-07 00:55:23 - progress_bar.py[line:274] - INFO: epoch 001:   9273 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4242, wps=101.7, ups=0.47, wpb=108.6, bsz=40, num_updates=9260, lr=4.79197e-05, gnorm=0.477, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36359
2023-01-07 00:55:45 - progress_bar.py[line:274] - INFO: epoch 001:   9283 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3046, wps=102.4, ups=0.47, wpb=109.1, bsz=40, num_updates=9270, lr=4.79152e-05, gnorm=0.487, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36381
2023-01-07 00:56:06 - progress_bar.py[line:274] - INFO: epoch 001:   9293 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3472, wps=102.1, ups=0.47, wpb=108.1, bsz=40, num_updates=9280, lr=4.79107e-05, gnorm=0.574, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36402
2023-01-07 00:56:28 - progress_bar.py[line:274] - INFO: epoch 001:   9303 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.2872, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=9290, lr=4.79063e-05, gnorm=0.509, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36424
2023-01-07 00:56:49 - progress_bar.py[line:274] - INFO: epoch 001:   9313 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.397, wps=101.8, ups=0.47, wpb=108.8, bsz=40, num_updates=9300, lr=4.79018e-05, gnorm=0.473, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36445
2023-01-07 00:57:11 - progress_bar.py[line:274] - INFO: epoch 001:   9323 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.344, wps=99.9, ups=0.46, wpb=107.5, bsz=40, num_updates=9310, lr=4.78973e-05, gnorm=0.538, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=36467
2023-01-07 00:57:33 - progress_bar.py[line:274] - INFO: epoch 001:   9333 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3607, wps=101.6, ups=0.47, wpb=108.3, bsz=40, num_updates=9320, lr=4.78928e-05, gnorm=0.462, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36489
2023-01-07 00:57:54 - progress_bar.py[line:274] - INFO: epoch 001:   9343 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3284, wps=100.3, ups=0.46, wpb=108, bsz=40, num_updates=9330, lr=4.78883e-05, gnorm=0.604, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=36510
2023-01-07 00:58:17 - progress_bar.py[line:274] - INFO: epoch 001:   9353 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3069, wps=99.8, ups=0.46, wpb=108.5, bsz=40, num_updates=9340, lr=4.78838e-05, gnorm=0.449, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=36532
2023-01-07 00:58:39 - progress_bar.py[line:274] - INFO: epoch 001:   9363 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.377, wps=99.8, ups=0.46, wpb=108.9, bsz=40, num_updates=9350, lr=4.78793e-05, gnorm=0.443, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36554
2023-01-07 00:59:00 - progress_bar.py[line:274] - INFO: epoch 001:   9373 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3561, wps=100.9, ups=0.46, wpb=109.4, bsz=40, num_updates=9360, lr=4.78748e-05, gnorm=0.487, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36576
2023-01-07 00:59:22 - progress_bar.py[line:274] - INFO: epoch 001:   9383 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3604, wps=102.6, ups=0.47, wpb=108.4, bsz=40, num_updates=9370, lr=4.78703e-05, gnorm=0.527, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36598
2023-01-07 00:59:43 - progress_bar.py[line:274] - INFO: epoch 001:   9393 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3472, wps=102.5, ups=0.47, wpb=109.5, bsz=40, num_updates=9380, lr=4.78658e-05, gnorm=0.554, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36619
2023-01-07 01:00:05 - progress_bar.py[line:274] - INFO: epoch 001:   9403 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3596, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=9390, lr=4.78613e-05, gnorm=0.631, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36641
2023-01-07 01:00:27 - progress_bar.py[line:274] - INFO: epoch 001:   9413 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3865, wps=100.2, ups=0.46, wpb=109.4, bsz=40, num_updates=9400, lr=4.78568e-05, gnorm=0.601, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36663
2023-01-07 01:00:49 - progress_bar.py[line:274] - INFO: epoch 001:   9423 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3194, wps=102.9, ups=0.47, wpb=110.5, bsz=40, num_updates=9410, lr=4.78523e-05, gnorm=0.425, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=36685
2023-01-07 01:01:11 - progress_bar.py[line:274] - INFO: epoch 001:   9433 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3318, wps=101.4, ups=0.47, wpb=108.8, bsz=40, num_updates=9420, lr=4.78478e-05, gnorm=0.504, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36707
2023-01-07 01:01:33 - progress_bar.py[line:274] - INFO: epoch 001:   9443 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3333, wps=103.9, ups=0.47, wpb=109.8, bsz=40, num_updates=9430, lr=4.78433e-05, gnorm=0.601, clip=20, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=36729
2023-01-07 01:01:54 - progress_bar.py[line:274] - INFO: epoch 001:   9453 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.2929, wps=104, ups=0.47, wpb=109.8, bsz=40, num_updates=9440, lr=4.78388e-05, gnorm=0.416, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36750
2023-01-07 01:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   9463 / 115845 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3058, wps=102, ups=0.47, wpb=108, bsz=40, num_updates=9450, lr=4.78343e-05, gnorm=0.669, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36771
2023-01-07 01:02:38 - progress_bar.py[line:274] - INFO: epoch 001:   9473 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3707, wps=98.5, ups=0.46, wpb=108, bsz=40, num_updates=9460, lr=4.78298e-05, gnorm=0.594, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36794
2023-01-07 01:02:59 - progress_bar.py[line:274] - INFO: epoch 001:   9483 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3922, wps=102, ups=0.47, wpb=109.5, bsz=40, num_updates=9470, lr=4.78253e-05, gnorm=0.474, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36815
2023-01-07 01:03:21 - progress_bar.py[line:274] - INFO: epoch 001:   9493 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3333, wps=100.8, ups=0.47, wpb=107.6, bsz=40, num_updates=9480, lr=4.78208e-05, gnorm=0.868, clip=30, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36837
2023-01-07 01:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   9503 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3467, wps=103.9, ups=0.48, wpb=108.8, bsz=40, num_updates=9490, lr=4.78163e-05, gnorm=0.491, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36858
2023-01-07 01:04:04 - progress_bar.py[line:274] - INFO: epoch 001:   9513 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.375, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=9500, lr=4.78118e-05, gnorm=0.681, clip=20, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=36880
2023-01-07 01:04:26 - progress_bar.py[line:274] - INFO: epoch 001:   9523 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3627, wps=103.1, ups=0.47, wpb=109.4, bsz=40, num_updates=9510, lr=4.78073e-05, gnorm=0.504, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=36902
2023-01-07 01:04:47 - progress_bar.py[line:274] - INFO: epoch 001:   9533 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3333, wps=102.4, ups=0.47, wpb=108.8, bsz=40, num_updates=9520, lr=4.78028e-05, gnorm=0.498, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=36923
2023-01-07 01:05:08 - progress_bar.py[line:274] - INFO: epoch 001:   9543 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3632, wps=103.4, ups=0.48, wpb=108.6, bsz=40, num_updates=9530, lr=4.77983e-05, gnorm=0.469, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=36944
2023-01-07 01:05:31 - progress_bar.py[line:274] - INFO: epoch 001:   9553 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3608, wps=99.7, ups=0.46, wpb=109.2, bsz=40, num_updates=9540, lr=4.77939e-05, gnorm=0.405, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=36966
2023-01-07 01:05:52 - progress_bar.py[line:274] - INFO: epoch 001:   9563 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3264, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=9550, lr=4.77894e-05, gnorm=0.492, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=36988
2023-01-07 01:06:14 - progress_bar.py[line:274] - INFO: epoch 001:   9573 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3671, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=9560, lr=4.77849e-05, gnorm=0.506, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37010
2023-01-07 01:06:36 - progress_bar.py[line:274] - INFO: epoch 001:   9583 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3351, wps=100.4, ups=0.47, wpb=107.9, bsz=40, num_updates=9570, lr=4.77804e-05, gnorm=0.4, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=37032
2023-01-07 01:06:58 - progress_bar.py[line:274] - INFO: epoch 001:   9593 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3769, wps=101.6, ups=0.46, wpb=109.5, bsz=40, num_updates=9580, lr=4.77759e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37053
2023-01-07 01:07:19 - progress_bar.py[line:274] - INFO: epoch 001:   9603 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3444, wps=101.5, ups=0.46, wpb=109.8, bsz=40, num_updates=9590, lr=4.77714e-05, gnorm=0.345, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=37075
2023-01-07 01:07:41 - progress_bar.py[line:274] - INFO: epoch 001:   9613 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3641, wps=101, ups=0.46, wpb=109, bsz=40, num_updates=9600, lr=4.77669e-05, gnorm=0.568, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37097
2023-01-07 01:08:03 - progress_bar.py[line:274] - INFO: epoch 001:   9623 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3282, wps=102.2, ups=0.47, wpb=108, bsz=40, num_updates=9610, lr=4.77624e-05, gnorm=0.408, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=37118
2023-01-07 01:08:24 - progress_bar.py[line:274] - INFO: epoch 001:   9633 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3861, wps=102.6, ups=0.47, wpb=108.3, bsz=40, num_updates=9620, lr=4.77579e-05, gnorm=0.512, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=37140
2023-01-07 01:08:45 - progress_bar.py[line:274] - INFO: epoch 001:   9643 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3458, wps=101, ups=0.47, wpb=108.1, bsz=40, num_updates=9630, lr=4.77534e-05, gnorm=0.521, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=37161
2023-01-07 01:09:07 - progress_bar.py[line:274] - INFO: epoch 001:   9653 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4167, wps=102.3, ups=0.47, wpb=109.8, bsz=40, num_updates=9640, lr=4.77489e-05, gnorm=0.503, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37183
2023-01-07 01:09:29 - progress_bar.py[line:274] - INFO: epoch 001:   9663 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3627, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=9650, lr=4.77444e-05, gnorm=0.388, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37205
2023-01-07 01:09:51 - progress_bar.py[line:274] - INFO: epoch 001:   9673 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3523, wps=102.9, ups=0.47, wpb=110.1, bsz=40, num_updates=9660, lr=4.77399e-05, gnorm=0.512, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=37226
2023-01-07 01:10:13 - progress_bar.py[line:274] - INFO: epoch 001:   9683 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3299, wps=100, ups=0.46, wpb=108.8, bsz=40, num_updates=9670, lr=4.77354e-05, gnorm=0.656, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37248
2023-01-07 01:10:34 - progress_bar.py[line:274] - INFO: epoch 001:   9693 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3081, wps=102.6, ups=0.47, wpb=109.7, bsz=40, num_updates=9680, lr=4.77309e-05, gnorm=0.633, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37270
2023-01-07 01:10:55 - progress_bar.py[line:274] - INFO: epoch 001:   9703 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.424, wps=104.3, ups=0.48, wpb=109.4, bsz=40, num_updates=9690, lr=4.77264e-05, gnorm=0.631, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37291
2023-01-07 01:11:17 - progress_bar.py[line:274] - INFO: epoch 001:   9713 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4141, wps=102.3, ups=0.46, wpb=110.3, bsz=40, num_updates=9700, lr=4.77219e-05, gnorm=0.478, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=37313
2023-01-07 01:11:39 - progress_bar.py[line:274] - INFO: epoch 001:   9723 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4384, wps=100.2, ups=0.46, wpb=108.7, bsz=40, num_updates=9710, lr=4.77174e-05, gnorm=0.409, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=37335
2023-01-07 01:12:01 - progress_bar.py[line:274] - INFO: epoch 001:   9733 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3538, wps=100.8, ups=0.47, wpb=108.2, bsz=40, num_updates=9720, lr=4.77129e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37357
2023-01-07 01:12:22 - progress_bar.py[line:274] - INFO: epoch 001:   9743 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3387, wps=103.4, ups=0.47, wpb=109.4, bsz=40, num_updates=9730, lr=4.77084e-05, gnorm=0.583, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=37378
2023-01-07 01:12:44 - progress_bar.py[line:274] - INFO: epoch 001:   9753 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3768, wps=101.1, ups=0.46, wpb=108.9, bsz=40, num_updates=9740, lr=4.77039e-05, gnorm=0.762, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37400
2023-01-07 01:13:06 - progress_bar.py[line:274] - INFO: epoch 001:   9763 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3923, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=9750, lr=4.76994e-05, gnorm=0.557, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37421
2023-01-07 01:13:27 - progress_bar.py[line:274] - INFO: epoch 001:   9773 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.392, wps=102.9, ups=0.48, wpb=108.1, bsz=40, num_updates=9760, lr=4.76949e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37443
2023-01-07 01:13:49 - progress_bar.py[line:274] - INFO: epoch 001:   9783 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.375, wps=101.2, ups=0.46, wpb=110, bsz=40, num_updates=9770, lr=4.76904e-05, gnorm=0.42, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37465
2023-01-07 01:14:10 - progress_bar.py[line:274] - INFO: epoch 001:   9793 / 115845 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3255, wps=102.1, ups=0.47, wpb=108.2, bsz=40, num_updates=9780, lr=4.7686e-05, gnorm=0.438, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37486
2023-01-07 01:14:32 - progress_bar.py[line:274] - INFO: epoch 001:   9803 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.305, wps=99.3, ups=0.46, wpb=108.7, bsz=40, num_updates=9790, lr=4.76815e-05, gnorm=0.565, clip=10, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=37508
2023-01-07 01:14:54 - progress_bar.py[line:274] - INFO: epoch 001:   9813 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4565, wps=102, ups=0.46, wpb=110, bsz=40, num_updates=9800, lr=4.7677e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37530
2023-01-07 01:15:16 - progress_bar.py[line:274] - INFO: epoch 001:   9823 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3971, wps=102.1, ups=0.46, wpb=110, bsz=40, num_updates=9810, lr=4.76725e-05, gnorm=0.389, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37552
2023-01-07 01:15:38 - progress_bar.py[line:274] - INFO: epoch 001:   9833 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3179, wps=102.6, ups=0.47, wpb=110, bsz=40, num_updates=9820, lr=4.7668e-05, gnorm=0.457, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37574
2023-01-07 01:15:59 - progress_bar.py[line:274] - INFO: epoch 001:   9843 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.352, wps=104.4, ups=0.47, wpb=110.3, bsz=40, num_updates=9830, lr=4.76635e-05, gnorm=0.49, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37595
2023-01-07 01:16:21 - progress_bar.py[line:274] - INFO: epoch 001:   9853 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3632, wps=100.9, ups=0.46, wpb=109.9, bsz=40, num_updates=9840, lr=4.7659e-05, gnorm=0.382, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37617
2023-01-07 01:16:42 - progress_bar.py[line:274] - INFO: epoch 001:   9863 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3944, wps=102, ups=0.47, wpb=108.2, bsz=40, num_updates=9850, lr=4.76545e-05, gnorm=0.444, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37638
2023-01-07 01:17:04 - progress_bar.py[line:274] - INFO: epoch 001:   9873 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4258, wps=101.4, ups=0.47, wpb=108.2, bsz=40, num_updates=9860, lr=4.765e-05, gnorm=0.595, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37660
2023-01-07 01:17:25 - progress_bar.py[line:274] - INFO: epoch 001:   9883 / 115845 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3365, wps=104.6, ups=0.48, wpb=108.7, bsz=40, num_updates=9870, lr=4.76455e-05, gnorm=0.426, clip=0, loss_scale=512, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=37681
2023-01-07 01:17:46 - progress_bar.py[line:274] - INFO: epoch 001:   9893 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3385, wps=104.3, ups=0.47, wpb=110.6, bsz=40, num_updates=9880, lr=4.7641e-05, gnorm=0.423, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=37702
2023-01-07 01:18:08 - progress_bar.py[line:274] - INFO: epoch 001:   9903 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3596, wps=101.1, ups=0.46, wpb=108.9, bsz=40, num_updates=9890, lr=4.76365e-05, gnorm=0.421, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37724
2023-01-07 01:18:30 - progress_bar.py[line:274] - INFO: epoch 001:   9913 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3934, wps=101.7, ups=0.47, wpb=108.4, bsz=40, num_updates=9900, lr=4.7632e-05, gnorm=0.578, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37746
2023-01-07 01:18:51 - progress_bar.py[line:274] - INFO: epoch 001:   9923 / 115845 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3301, wps=101.1, ups=0.47, wpb=107.8, bsz=40, num_updates=9910, lr=4.76275e-05, gnorm=0.497, clip=10, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=37767
2023-01-07 01:19:13 - progress_bar.py[line:274] - INFO: epoch 001:   9933 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3793, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=9920, lr=4.7623e-05, gnorm=0.437, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=37789
2023-01-07 01:19:35 - progress_bar.py[line:274] - INFO: epoch 001:   9943 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3395, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=9930, lr=4.76185e-05, gnorm=0.668, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=37811
2023-01-07 01:19:57 - progress_bar.py[line:274] - INFO: epoch 001:   9953 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3832, wps=98.5, ups=0.46, wpb=108, bsz=40, num_updates=9940, lr=4.7614e-05, gnorm=0.537, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37833
2023-01-07 01:20:19 - progress_bar.py[line:274] - INFO: epoch 001:   9963 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3607, wps=101.4, ups=0.46, wpb=110.2, bsz=40, num_updates=9950, lr=4.76095e-05, gnorm=0.366, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=37855
2023-01-07 01:20:41 - progress_bar.py[line:274] - INFO: epoch 001:   9973 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4135, wps=101.3, ups=0.47, wpb=108.5, bsz=40, num_updates=9960, lr=4.7605e-05, gnorm=0.48, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=37877
2023-01-07 01:21:02 - progress_bar.py[line:274] - INFO: epoch 001:   9983 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3788, wps=102, ups=0.46, wpb=109.7, bsz=40, num_updates=9970, lr=4.76005e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37898
2023-01-07 01:21:24 - progress_bar.py[line:274] - INFO: epoch 001:   9993 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3978, wps=102, ups=0.47, wpb=109.1, bsz=40, num_updates=9980, lr=4.7596e-05, gnorm=0.438, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=37920
2023-01-07 01:21:46 - progress_bar.py[line:274] - INFO: epoch 001:  10003 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3598, wps=100.7, ups=0.46, wpb=110.5, bsz=40, num_updates=9990, lr=4.75915e-05, gnorm=0.585, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=37942
2023-01-07 01:22:08 - progress_bar.py[line:274] - INFO: epoch 001:  10013 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4455, wps=101.6, ups=0.46, wpb=109.3, bsz=40, num_updates=10000, lr=4.7587e-05, gnorm=0.547, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=37964
2023-01-07 01:22:08 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 01:22:09 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 01:22:09 - train.py[line:551] - INFO: load:1.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 01:22:25 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 9.29 GiB already allocated; 3.68 GiB free; 33.42 GiB reserved in total by PyTorch)
2023-01-07 01:22:25 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 22        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9515 MB |   14746 MB |    5370 TB |    5370 TB |
|       from large pool |    9341 MB |   14572 MB |    5367 TB |    5367 TB |
|       from small pool |     174 MB |     175 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9515 MB |   14746 MB |    5370 TB |    5370 TB |
|       from large pool |    9341 MB |   14572 MB |    5367 TB |    5367 TB |
|       from small pool |     174 MB |     175 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34226 MB |   34440 MB |  254204 MB |  219978 MB |
|       from large pool |   34050 MB |   34258 MB |  253836 MB |  219786 MB |
|       from small pool |     176 MB |     182 MB |     368 MB |     192 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24710 MB |   29076 MB |    5222 TB |    5222 TB |
|       from large pool |   24708 MB |   29074 MB |    5219 TB |    5219 TB |
|       from small pool |       1 MB |       2 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4634    |    4648    |  252818 K  |  252814 K  |
|       from large pool |     698    |     710    |   78208 K  |   78207 K  |
|       from small pool |    3936    |    3946    |  174610 K  |  174606 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4634    |    4648    |  252818 K  |  252814 K  |
|       from large pool |     698    |     710    |   78208 K  |   78207 K  |
|       from small pool |    3936    |    3946    |  174610 K  |  174606 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     187    |     195    |     589    |     402    |
|       from large pool |      99    |     104    |     405    |     306    |
|       from small pool |      88    |      91    |     184    |      96    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     114    |     124    |  189573 K  |  189573 K  |
|       from large pool |      69    |      73    |   39900 K  |   39900 K  |
|       from small pool |      45    |      57    |  149672 K  |  149672 K  |
|===========================================================================|

2023-01-07 01:22:25 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-07 01:22:25 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-07 01:24:42 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 01:24:42 - train.py[line:551] - INFO: load:1.09 valid_run:153.00 task_valid:148.24 collect_output:2.90
2023-01-07 01:27:12 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 01:27:12 - train.py[line:551] - INFO: load:1.11 valid_run:302.30 task_valid:291.26 collect_output:8.14
2023-01-07 01:29:45 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 01:29:45 - train.py[line:551] - INFO: load:1.14 valid_run:455.43 task_valid:434.13 collect_output:17.35
2023-01-07 01:32:15 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 01:32:15 - train.py[line:551] - INFO: load:1.16 valid_run:605.26 task_valid:578.91 collect_output:21.37
2023-01-07 01:34:48 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 01:34:48 - train.py[line:551] - INFO: load:1.19 valid_run:758.12 task_valid:726.26 collect_output:25.88
2023-01-07 01:37:20 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 01:37:20 - train.py[line:551] - INFO: load:1.21 valid_run:910.67 task_valid:872.06 collect_output:31.58
2023-01-07 01:39:55 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 01:39:55 - train.py[line:551] - INFO: load:1.24 valid_run:1064.86 task_valid:1018.16 collect_output:38.64
2023-01-07 01:42:27 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 01:42:27 - train.py[line:551] - INFO: load:1.26 valid_run:1217.08 task_valid:1159.03 collect_output:48.98
2023-01-07 01:44:57 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 01:44:57 - train.py[line:551] - INFO: load:1.29 valid_run:1367.29 task_valid:1303.54 collect_output:53.62
2023-01-07 01:47:27 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 01:47:27 - train.py[line:551] - INFO: load:1.31 valid_run:1516.79 task_valid:1446.84 collect_output:58.78
2023-01-07 01:49:57 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 01:49:57 - train.py[line:551] - INFO: load:1.34 valid_run:1667.17 task_valid:1591.77 collect_output:63.19
2023-01-07 01:52:28 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 01:52:28 - train.py[line:551] - INFO: load:1.36 valid_run:1817.89 task_valid:1736.56 collect_output:68.07
2023-01-07 01:54:59 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 01:54:59 - train.py[line:551] - INFO: load:1.39 valid_run:1968.62 task_valid:1878.21 collect_output:76.12
2023-01-07 01:57:30 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 01:57:30 - train.py[line:551] - INFO: load:1.42 valid_run:2119.86 task_valid:2023.67 collect_output:80.82
2023-01-07 02:00:01 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 02:00:01 - train.py[line:551] - INFO: load:1.44 valid_run:2270.29 task_valid:2170.02 collect_output:83.85
2023-01-07 02:02:32 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 02:02:32 - train.py[line:551] - INFO: load:1.47 valid_run:2421.22 task_valid:2314.10 collect_output:89.65
2023-01-07 02:05:05 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 02:05:05 - train.py[line:551] - INFO: load:1.49 valid_run:2574.58 task_valid:2460.27 collect_output:95.69
2023-01-07 02:07:37 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 02:07:37 - train.py[line:551] - INFO: load:1.52 valid_run:2726.23 task_valid:2607.83 collect_output:98.73
2023-01-07 02:10:06 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 02:10:06 - train.py[line:551] - INFO: load:1.55 valid_run:2875.87 task_valid:2749.75 collect_output:105.39
2023-01-07 02:12:38 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 02:12:38 - train.py[line:551] - INFO: load:1.57 valid_run:3027.46 task_valid:2895.49 collect_output:110.14
2023-01-07 02:15:11 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 02:15:11 - train.py[line:551] - INFO: load:1.60 valid_run:3180.36 task_valid:3040.25 collect_output:117.25
2023-01-07 02:17:41 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 02:17:41 - train.py[line:551] - INFO: load:1.63 valid_run:3330.61 task_valid:3184.87 collect_output:121.83
2023-01-07 02:20:13 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 02:20:13 - train.py[line:551] - INFO: load:1.65 valid_run:3482.43 task_valid:3330.84 collect_output:126.69
2023-01-07 02:22:45 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 02:22:45 - train.py[line:551] - INFO: load:1.68 valid_run:3634.41 task_valid:3477.18 collect_output:131.30

====================================================================================================
SGG eval:     R @ 50: 0.4961;     R @ 100: 0.5888;     R @ 500: 0.6458;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2978;    mR @ 100: 0.3882;    mR @ 500: 0.4398;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.8750) (covering:0.3714) (eating:0.6765) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4129) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.8399) (says:0.0000) (sitting on:0.7018) (standing on:0.1933) (using:0.6500) (walking in:0.0000) (walking on:0.6847) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4961;     R @ 100: 0.5888;     R @ 500: 0.6458;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2978;    mR @ 100: 0.3882;    mR @ 500: 0.4398;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.8750) (covering:0.3714) (eating:0.6765) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4129) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.8399) (says:0.0000) (sitting on:0.7018) (standing on:0.1933) (using:0.6500) (walking in:0.0000) (walking on:0.6847) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-07 02:25:16 - train.py[line:487] - INFO: 0.5887952380952381
2023-01-07 02:25:17 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 02:25:17 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.377 | loss_v1 0 | loss_v2 0 | nll_loss 0.225 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.588795 | ppl 1.17 | vqa_score 0.5439 | wps 118.4 | wpb 89.9 | bsz 30 | num_updates 10000 | best_R@100 0.641887
2023-01-07 02:25:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2023-01-07 02:25:17 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt
2023-01-07 02:25:56 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt
2023-01-07 02:27:16 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.5887952380952381) (writing took 119.01944482140243 seconds)
2023-01-07 02:27:37 - progress_bar.py[line:274] - INFO: epoch 001:  10023 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3922, wps=0.6, ups=0, wpb=108.1, bsz=40, num_updates=10010, lr=4.75825e-05, gnorm=0.418, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41893
2023-01-07 02:27:59 - progress_bar.py[line:274] - INFO: epoch 001:  10033 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3698, wps=102.4, ups=0.47, wpb=109.2, bsz=40, num_updates=10020, lr=4.7578e-05, gnorm=0.4, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=41914
2023-01-07 02:28:20 - progress_bar.py[line:274] - INFO: epoch 001:  10043 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3769, wps=102.1, ups=0.47, wpb=108.8, bsz=40, num_updates=10030, lr=4.75736e-05, gnorm=0.487, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=41936
2023-01-07 02:28:41 - progress_bar.py[line:274] - INFO: epoch 001:  10053 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4372, wps=103.3, ups=0.48, wpb=108.6, bsz=40, num_updates=10040, lr=4.75691e-05, gnorm=0.49, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41957
2023-01-07 02:29:03 - progress_bar.py[line:274] - INFO: epoch 001:  10063 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4049, wps=101.4, ups=0.47, wpb=107.1, bsz=40, num_updates=10050, lr=4.75646e-05, gnorm=0.589, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=41979
2023-01-07 02:29:25 - progress_bar.py[line:274] - INFO: epoch 001:  10073 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3704, wps=99.2, ups=0.46, wpb=107.9, bsz=40, num_updates=10060, lr=4.75601e-05, gnorm=0.544, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42001
2023-01-07 02:29:47 - progress_bar.py[line:274] - INFO: epoch 001:  10083 / 115845 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3615, wps=99.7, ups=0.46, wpb=107.3, bsz=40, num_updates=10070, lr=4.75556e-05, gnorm=0.598, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42022
2023-01-07 02:30:08 - progress_bar.py[line:274] - INFO: epoch 001:  10093 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3596, wps=102, ups=0.46, wpb=110.9, bsz=40, num_updates=10080, lr=4.75511e-05, gnorm=0.411, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42044
2023-01-07 02:30:30 - progress_bar.py[line:274] - INFO: epoch 001:  10103 / 115845 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3939, wps=102.5, ups=0.47, wpb=108.2, bsz=40, num_updates=10090, lr=4.75466e-05, gnorm=0.537, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42066
2023-01-07 02:30:53 - progress_bar.py[line:274] - INFO: epoch 001:  10113 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3699, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=10100, lr=4.75421e-05, gnorm=0.617, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42087
2023-01-07 02:31:15 - progress_bar.py[line:274] - INFO: epoch 001:  10123 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4183, wps=102.1, ups=0.46, wpb=109.8, bsz=40, num_updates=10110, lr=4.75376e-05, gnorm=0.454, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42110
2023-01-07 02:31:36 - progress_bar.py[line:274] - INFO: epoch 001:  10133 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3807, wps=103.4, ups=0.47, wpb=109, bsz=40, num_updates=10120, lr=4.75331e-05, gnorm=0.397, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42132
2023-01-07 02:31:57 - progress_bar.py[line:274] - INFO: epoch 001:  10143 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.365, wps=102.7, ups=0.47, wpb=109, bsz=40, num_updates=10130, lr=4.75286e-05, gnorm=0.439, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42153
2023-01-07 02:31:59 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 02:32:21 - progress_bar.py[line:274] - INFO: epoch 001:  10154 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=107.857, nsentences=40, sample_size=107.857, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4211, wps=95.6, ups=0.42, wpb=107.9, bsz=40, num_updates=10140, lr=4.75241e-05, gnorm=0.344, clip=0, loss_scale=512, train_wall=24, gb_free=10.5, ema_decay=0.9999, wall=42177
2023-01-07 02:32:43 - progress_bar.py[line:274] - INFO: epoch 001:  10164 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4153, wps=102, ups=0.46, wpb=110.3, bsz=40, num_updates=10150, lr=4.75196e-05, gnorm=0.408, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42199
2023-01-07 02:33:05 - progress_bar.py[line:274] - INFO: epoch 001:  10174 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4095, wps=100.5, ups=0.46, wpb=108.3, bsz=40, num_updates=10160, lr=4.75151e-05, gnorm=0.588, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=42221
2023-01-07 02:33:27 - progress_bar.py[line:274] - INFO: epoch 001:  10184 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4154, wps=99.6, ups=0.45, wpb=109.8, bsz=40, num_updates=10170, lr=4.75106e-05, gnorm=0.412, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=42243
2023-01-07 02:33:49 - progress_bar.py[line:274] - INFO: epoch 001:  10194 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.404, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=10180, lr=4.75061e-05, gnorm=0.444, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=42265
2023-01-07 02:34:11 - progress_bar.py[line:274] - INFO: epoch 001:  10204 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4264, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=10190, lr=4.75016e-05, gnorm=0.492, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42287
2023-01-07 02:34:32 - progress_bar.py[line:274] - INFO: epoch 001:  10214 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3938, wps=104.3, ups=0.48, wpb=109.3, bsz=40, num_updates=10200, lr=4.74971e-05, gnorm=0.478, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42308
2023-01-07 02:34:54 - progress_bar.py[line:274] - INFO: epoch 001:  10224 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3301, wps=99.2, ups=0.46, wpb=108.2, bsz=40, num_updates=10210, lr=4.74926e-05, gnorm=0.428, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42330
2023-01-07 02:35:16 - progress_bar.py[line:274] - INFO: epoch 001:  10234 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4897, wps=102.4, ups=0.47, wpb=109.6, bsz=40, num_updates=10220, lr=4.74881e-05, gnorm=0.553, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42351
2023-01-07 02:35:37 - progress_bar.py[line:274] - INFO: epoch 001:  10244 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4408, wps=101, ups=0.47, wpb=108.1, bsz=40, num_updates=10230, lr=4.74836e-05, gnorm=0.413, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42373
2023-01-07 02:35:59 - progress_bar.py[line:274] - INFO: epoch 001:  10254 / 115845 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.4118, wps=99, ups=0.46, wpb=107.2, bsz=40, num_updates=10240, lr=4.74791e-05, gnorm=0.64, clip=20, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=42395
2023-01-07 02:36:21 - progress_bar.py[line:274] - INFO: epoch 001:  10264 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3842, wps=100.2, ups=0.46, wpb=108.4, bsz=40, num_updates=10250, lr=4.74746e-05, gnorm=0.475, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42417
2023-01-07 02:36:43 - progress_bar.py[line:274] - INFO: epoch 001:  10274 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3679, wps=102.5, ups=0.47, wpb=110, bsz=40, num_updates=10260, lr=4.74701e-05, gnorm=0.593, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42438
2023-01-07 02:37:04 - progress_bar.py[line:274] - INFO: epoch 001:  10284 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3598, wps=101.3, ups=0.47, wpb=108.1, bsz=40, num_updates=10270, lr=4.74657e-05, gnorm=0.363, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42460
2023-01-07 02:37:26 - progress_bar.py[line:274] - INFO: epoch 001:  10294 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.419, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=10280, lr=4.74612e-05, gnorm=0.399, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=42482
2023-01-07 02:37:47 - progress_bar.py[line:274] - INFO: epoch 001:  10304 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4098, wps=103.5, ups=0.47, wpb=109.4, bsz=40, num_updates=10290, lr=4.74567e-05, gnorm=0.577, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42503
2023-01-07 02:38:09 - progress_bar.py[line:274] - INFO: epoch 001:  10314 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3894, wps=100.1, ups=0.46, wpb=108.8, bsz=40, num_updates=10300, lr=4.74522e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=42525
2023-01-07 02:38:31 - progress_bar.py[line:274] - INFO: epoch 001:  10324 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3865, wps=102.3, ups=0.47, wpb=107.7, bsz=40, num_updates=10310, lr=4.74477e-05, gnorm=0.395, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=42546
2023-01-07 02:38:52 - progress_bar.py[line:274] - INFO: epoch 001:  10334 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4264, wps=102.2, ups=0.47, wpb=109.5, bsz=40, num_updates=10320, lr=4.74432e-05, gnorm=0.347, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42568
2023-01-07 02:39:14 - progress_bar.py[line:274] - INFO: epoch 001:  10344 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3979, wps=103, ups=0.47, wpb=109.8, bsz=40, num_updates=10330, lr=4.74387e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42590
2023-01-07 02:39:35 - progress_bar.py[line:274] - INFO: epoch 001:  10354 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4124, wps=103.2, ups=0.47, wpb=109.4, bsz=40, num_updates=10340, lr=4.74342e-05, gnorm=0.441, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42611
2023-01-07 02:39:57 - progress_bar.py[line:274] - INFO: epoch 001:  10364 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3561, wps=101.8, ups=0.46, wpb=110.4, bsz=40, num_updates=10350, lr=4.74297e-05, gnorm=0.491, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=42633
2023-01-07 02:40:19 - progress_bar.py[line:274] - INFO: epoch 001:  10374 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.381, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=10360, lr=4.74252e-05, gnorm=0.489, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=42655
2023-01-07 02:40:41 - progress_bar.py[line:274] - INFO: epoch 001:  10384 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.43, wps=101.3, ups=0.46, wpb=109, bsz=40, num_updates=10370, lr=4.74207e-05, gnorm=0.486, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42677
2023-01-07 02:41:02 - progress_bar.py[line:274] - INFO: epoch 001:  10394 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4084, wps=102.2, ups=0.46, wpb=109.9, bsz=40, num_updates=10380, lr=4.74162e-05, gnorm=0.443, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42698
2023-01-07 02:41:24 - progress_bar.py[line:274] - INFO: epoch 001:  10404 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4802, wps=103.9, ups=0.47, wpb=109.9, bsz=40, num_updates=10390, lr=4.74117e-05, gnorm=0.663, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42720
2023-01-07 02:41:45 - progress_bar.py[line:274] - INFO: epoch 001:  10414 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.35, wps=102.8, ups=0.47, wpb=109.7, bsz=40, num_updates=10400, lr=4.74072e-05, gnorm=0.44, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42741
2023-01-07 02:42:07 - progress_bar.py[line:274] - INFO: epoch 001:  10424 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.383, wps=103.8, ups=0.48, wpb=109, bsz=40, num_updates=10410, lr=4.74027e-05, gnorm=0.492, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42762
2023-01-07 02:42:28 - progress_bar.py[line:274] - INFO: epoch 001:  10434 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4356, wps=103.2, ups=0.47, wpb=109.3, bsz=40, num_updates=10420, lr=4.73982e-05, gnorm=0.464, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42784
2023-01-07 02:42:50 - progress_bar.py[line:274] - INFO: epoch 001:  10444 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3782, wps=100.9, ups=0.47, wpb=108, bsz=40, num_updates=10430, lr=4.73937e-05, gnorm=0.435, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=42806
2023-01-07 02:43:12 - progress_bar.py[line:274] - INFO: epoch 001:  10454 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4033, wps=99.6, ups=0.46, wpb=109, bsz=40, num_updates=10440, lr=4.73892e-05, gnorm=0.517, clip=10, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=42828
2023-01-07 02:43:34 - progress_bar.py[line:274] - INFO: epoch 001:  10464 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4352, wps=100.7, ups=0.46, wpb=110.1, bsz=40, num_updates=10450, lr=4.73847e-05, gnorm=0.482, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=42850
2023-01-07 02:43:56 - progress_bar.py[line:274] - INFO: epoch 001:  10474 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.402, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=10460, lr=4.73802e-05, gnorm=0.49, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=42871
2023-01-07 02:44:17 - progress_bar.py[line:274] - INFO: epoch 001:  10484 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4072, wps=101.8, ups=0.46, wpb=109.9, bsz=40, num_updates=10470, lr=4.73757e-05, gnorm=0.374, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=42893
2023-01-07 02:44:39 - progress_bar.py[line:274] - INFO: epoch 001:  10494 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3894, wps=99.9, ups=0.46, wpb=109, bsz=40, num_updates=10480, lr=4.73712e-05, gnorm=0.481, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=42915
2023-01-07 02:45:01 - progress_bar.py[line:274] - INFO: epoch 001:  10504 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3613, wps=106, ups=0.48, wpb=110.6, bsz=40, num_updates=10490, lr=4.73667e-05, gnorm=0.43, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42936
2023-01-07 02:45:22 - progress_bar.py[line:274] - INFO: epoch 001:  10514 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3795, wps=104.2, ups=0.47, wpb=110.5, bsz=40, num_updates=10500, lr=4.73622e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=42958
2023-01-07 02:45:28 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 02:45:46 - progress_bar.py[line:274] - INFO: epoch 001:  10525 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.905, nsentences=40, sample_size=107.905, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4153, wps=95.3, ups=0.42, wpb=107.9, bsz=40, num_updates=10510, lr=4.73577e-05, gnorm=0.577, clip=0, loss_scale=256, train_wall=24, gb_free=10.8, ema_decay=0.9999, wall=42982
2023-01-07 02:46:08 - progress_bar.py[line:274] - INFO: epoch 001:  10535 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4306, wps=100.3, ups=0.46, wpb=108.8, bsz=40, num_updates=10520, lr=4.73533e-05, gnorm=0.357, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=43004
2023-01-07 02:46:30 - progress_bar.py[line:274] - INFO: epoch 001:  10545 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3579, wps=101, ups=0.46, wpb=108.6, bsz=40, num_updates=10530, lr=4.73488e-05, gnorm=0.365, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43025
2023-01-07 02:46:51 - progress_bar.py[line:274] - INFO: epoch 001:  10555 / 115845 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4018, wps=99.4, ups=0.46, wpb=107.1, bsz=40, num_updates=10540, lr=4.73443e-05, gnorm=0.51, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=43047
2023-01-07 02:47:13 - progress_bar.py[line:274] - INFO: epoch 001:  10565 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4341, wps=100.5, ups=0.46, wpb=108.4, bsz=40, num_updates=10550, lr=4.73398e-05, gnorm=0.525, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43069
2023-01-07 02:47:35 - progress_bar.py[line:274] - INFO: epoch 001:  10575 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3592, wps=101.1, ups=0.47, wpb=107.3, bsz=40, num_updates=10560, lr=4.73353e-05, gnorm=0.381, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43090
2023-01-07 02:47:56 - progress_bar.py[line:274] - INFO: epoch 001:  10585 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3878, wps=103.1, ups=0.47, wpb=110, bsz=40, num_updates=10570, lr=4.73308e-05, gnorm=0.377, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=43112
2023-01-07 02:48:18 - progress_bar.py[line:274] - INFO: epoch 001:  10595 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3876, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=10580, lr=4.73263e-05, gnorm=0.379, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43134
2023-01-07 02:48:39 - progress_bar.py[line:274] - INFO: epoch 001:  10605 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.385, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=10590, lr=4.73218e-05, gnorm=1.001, clip=20, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=43155
2023-01-07 02:49:01 - progress_bar.py[line:274] - INFO: epoch 001:  10615 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3386, wps=101.3, ups=0.46, wpb=109.1, bsz=40, num_updates=10600, lr=4.73173e-05, gnorm=0.49, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43177
2023-01-07 02:49:23 - progress_bar.py[line:274] - INFO: epoch 001:  10625 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4255, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=10610, lr=4.73128e-05, gnorm=0.492, clip=10, loss_scale=256, train_wall=21, gb_free=10.9, ema_decay=0.9999, wall=43198
2023-01-07 02:49:44 - progress_bar.py[line:274] - INFO: epoch 001:  10635 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3714, wps=100.1, ups=0.46, wpb=107.6, bsz=40, num_updates=10620, lr=4.73083e-05, gnorm=0.386, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=43220
2023-01-07 02:50:06 - progress_bar.py[line:274] - INFO: epoch 001:  10645 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4581, wps=104.8, ups=0.47, wpb=110.5, bsz=40, num_updates=10630, lr=4.73038e-05, gnorm=0.466, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=43241
2023-01-07 02:50:27 - progress_bar.py[line:274] - INFO: epoch 001:  10655 / 115845 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3706, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=10640, lr=4.72993e-05, gnorm=0.375, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43263
2023-01-07 02:50:48 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-01-07 02:50:51 - progress_bar.py[line:274] - INFO: epoch 001:  10666 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.381, nsentences=40, sample_size=109.381, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3884, wps=99.7, ups=0.43, wpb=109.4, bsz=40, num_updates=10650, lr=4.72948e-05, gnorm=0.397, clip=0, loss_scale=128, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=43286
2023-01-07 02:51:12 - progress_bar.py[line:274] - INFO: epoch 001:  10676 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.397, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=10660, lr=4.72903e-05, gnorm=0.478, clip=0, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=43308
2023-01-07 02:51:34 - progress_bar.py[line:274] - INFO: epoch 001:  10686 / 115845 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3778, wps=101.8, ups=0.48, wpb=107.1, bsz=40, num_updates=10670, lr=4.72858e-05, gnorm=0.44, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43329
2023-01-07 02:51:56 - progress_bar.py[line:274] - INFO: epoch 001:  10696 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3838, wps=101.3, ups=0.46, wpb=110.8, bsz=40, num_updates=10680, lr=4.72813e-05, gnorm=0.562, clip=10, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43352
2023-01-07 02:52:17 - progress_bar.py[line:274] - INFO: epoch 001:  10706 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3768, wps=101.4, ups=0.47, wpb=108.7, bsz=40, num_updates=10690, lr=4.72768e-05, gnorm=0.448, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43373
2023-01-07 02:52:39 - progress_bar.py[line:274] - INFO: epoch 001:  10716 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3949, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=10700, lr=4.72723e-05, gnorm=0.408, clip=10, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43395
2023-01-07 02:53:01 - progress_bar.py[line:274] - INFO: epoch 001:  10726 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3608, wps=99.6, ups=0.46, wpb=109.4, bsz=40, num_updates=10710, lr=4.72678e-05, gnorm=0.41, clip=0, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=43417
2023-01-07 02:53:24 - progress_bar.py[line:274] - INFO: epoch 001:  10736 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4258, wps=99.5, ups=0.46, wpb=108.9, bsz=40, num_updates=10720, lr=4.72633e-05, gnorm=0.419, clip=0, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43439
2023-01-07 02:53:45 - progress_bar.py[line:274] - INFO: epoch 001:  10746 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4096, wps=101.8, ups=0.46, wpb=109.6, bsz=40, num_updates=10730, lr=4.72588e-05, gnorm=0.614, clip=30, loss_scale=128, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=43461
2023-01-07 02:54:07 - progress_bar.py[line:274] - INFO: epoch 001:  10756 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3934, wps=100.1, ups=0.46, wpb=108.8, bsz=40, num_updates=10740, lr=4.72543e-05, gnorm=0.488, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43483
2023-01-07 02:54:29 - progress_bar.py[line:274] - INFO: epoch 001:  10766 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3782, wps=103.1, ups=0.47, wpb=109.4, bsz=40, num_updates=10750, lr=4.72498e-05, gnorm=0.451, clip=0, loss_scale=128, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=43505
2023-01-07 02:54:50 - progress_bar.py[line:274] - INFO: epoch 001:  10776 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.399, wps=100.7, ups=0.47, wpb=107.6, bsz=40, num_updates=10760, lr=4.72454e-05, gnorm=1.607, clip=10, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43526
2023-01-07 02:55:12 - progress_bar.py[line:274] - INFO: epoch 001:  10786 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4312, wps=100.4, ups=0.46, wpb=108.7, bsz=40, num_updates=10770, lr=4.72409e-05, gnorm=0.495, clip=0, loss_scale=128, train_wall=22, gb_free=9.6, ema_decay=0.9999, wall=43548
2023-01-07 02:55:33 - progress_bar.py[line:274] - INFO: epoch 001:  10796 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4219, wps=104.2, ups=0.47, wpb=110.2, bsz=40, num_updates=10780, lr=4.72364e-05, gnorm=0.584, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43569
2023-01-07 02:55:55 - progress_bar.py[line:274] - INFO: epoch 001:  10806 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3478, wps=102.4, ups=0.46, wpb=110.3, bsz=40, num_updates=10790, lr=4.72319e-05, gnorm=0.507, clip=10, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43591
2023-01-07 02:56:16 - progress_bar.py[line:274] - INFO: epoch 001:  10816 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.435, wps=104.8, ups=0.48, wpb=108.6, bsz=40, num_updates=10800, lr=4.72274e-05, gnorm=0.383, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43612
2023-01-07 02:56:38 - progress_bar.py[line:274] - INFO: epoch 001:  10826 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4, wps=101.2, ups=0.47, wpb=108.6, bsz=40, num_updates=10810, lr=4.72229e-05, gnorm=0.419, clip=10, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43634
2023-01-07 02:57:00 - progress_bar.py[line:274] - INFO: epoch 001:  10836 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4221, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=10820, lr=4.72184e-05, gnorm=0.399, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=43655
2023-01-07 02:57:21 - progress_bar.py[line:274] - INFO: epoch 001:  10846 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4308, wps=103.7, ups=0.47, wpb=109.6, bsz=40, num_updates=10830, lr=4.72139e-05, gnorm=0.539, clip=10, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43677
2023-01-07 02:57:42 - progress_bar.py[line:274] - INFO: epoch 001:  10856 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4196, wps=103, ups=0.48, wpb=108.1, bsz=40, num_updates=10840, lr=4.72094e-05, gnorm=0.401, clip=0, loss_scale=128, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=43698
2023-01-07 02:58:04 - progress_bar.py[line:274] - INFO: epoch 001:  10866 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4185, wps=99.3, ups=0.45, wpb=109.7, bsz=40, num_updates=10850, lr=4.72049e-05, gnorm=0.489, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43720
2023-01-07 02:58:26 - progress_bar.py[line:274] - INFO: epoch 001:  10876 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4038, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=10860, lr=4.72004e-05, gnorm=0.405, clip=0, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=43742
2023-01-07 02:58:48 - progress_bar.py[line:274] - INFO: epoch 001:  10886 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.392, wps=100.2, ups=0.46, wpb=108.7, bsz=40, num_updates=10870, lr=4.71959e-05, gnorm=0.435, clip=10, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=43764
2023-01-07 02:59:10 - progress_bar.py[line:274] - INFO: epoch 001:  10896 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4368, wps=102.9, ups=0.47, wpb=110.5, bsz=40, num_updates=10880, lr=4.71914e-05, gnorm=0.421, clip=10, loss_scale=128, train_wall=21, gb_free=10, ema_decay=0.9999, wall=43786
2023-01-07 02:59:32 - progress_bar.py[line:274] - INFO: epoch 001:  10906 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4082, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=10890, lr=4.71869e-05, gnorm=0.379, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43808
2023-01-07 02:59:54 - progress_bar.py[line:274] - INFO: epoch 001:  10916 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4286, wps=101.1, ups=0.46, wpb=109.2, bsz=40, num_updates=10900, lr=4.71824e-05, gnorm=0.466, clip=10, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=43830
2023-01-07 03:00:15 - progress_bar.py[line:274] - INFO: epoch 001:  10926 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3927, wps=102.9, ups=0.47, wpb=109.2, bsz=40, num_updates=10910, lr=4.71779e-05, gnorm=0.289, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=43851
2023-01-07 03:00:37 - progress_bar.py[line:274] - INFO: epoch 001:  10936 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4396, wps=101.7, ups=0.46, wpb=110, bsz=40, num_updates=10920, lr=4.71734e-05, gnorm=0.484, clip=10, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=43873
2023-01-07 03:00:59 - progress_bar.py[line:274] - INFO: epoch 001:  10946 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4146, wps=100.5, ups=0.46, wpb=109.6, bsz=40, num_updates=10930, lr=4.71689e-05, gnorm=0.466, clip=10, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=43895
2023-01-07 03:01:21 - progress_bar.py[line:274] - INFO: epoch 001:  10956 / 115845 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=106.2, nsentences=40, sample_size=106.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, vqa_score=0.3363, wps=97.8, ups=0.46, wpb=106.2, bsz=40, num_updates=10940, lr=4.71644e-05, gnorm=0.42, clip=0, loss_scale=128, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=43917
2023-01-07 03:01:43 - progress_bar.py[line:274] - INFO: epoch 001:  10966 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.398, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=10950, lr=4.71599e-05, gnorm=0.535, clip=20, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=43939
2023-01-07 03:02:05 - progress_bar.py[line:274] - INFO: epoch 001:  10976 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.398, wps=99.5, ups=0.46, wpb=108.5, bsz=40, num_updates=10960, lr=4.71554e-05, gnorm=0.408, clip=0, loss_scale=128, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=43961
2023-01-07 03:02:26 - progress_bar.py[line:274] - INFO: epoch 001:  10986 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3962, wps=102, ups=0.47, wpb=109.7, bsz=40, num_updates=10970, lr=4.71509e-05, gnorm=0.466, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=43982
2023-01-07 03:02:48 - progress_bar.py[line:274] - INFO: epoch 001:  10996 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3763, wps=103, ups=0.47, wpb=109.4, bsz=40, num_updates=10980, lr=4.71464e-05, gnorm=0.417, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44004
2023-01-07 03:03:09 - progress_bar.py[line:274] - INFO: epoch 001:  11006 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.395, wps=101.9, ups=0.47, wpb=109.1, bsz=40, num_updates=10990, lr=4.71419e-05, gnorm=0.299, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44025
2023-01-07 03:03:31 - progress_bar.py[line:274] - INFO: epoch 001:  11016 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4082, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=11000, lr=4.71374e-05, gnorm=0.481, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44047
2023-01-07 03:03:53 - progress_bar.py[line:274] - INFO: epoch 001:  11026 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4302, wps=103.6, ups=0.47, wpb=110.5, bsz=40, num_updates=11010, lr=4.7133e-05, gnorm=0.425, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44069
2023-01-07 03:04:15 - progress_bar.py[line:274] - INFO: epoch 001:  11036 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.441, wps=100.8, ups=0.46, wpb=110, bsz=40, num_updates=11020, lr=4.71285e-05, gnorm=0.399, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44091
2023-01-07 03:04:37 - progress_bar.py[line:274] - INFO: epoch 001:  11046 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3952, wps=102.5, ups=0.47, wpb=109.3, bsz=40, num_updates=11030, lr=4.7124e-05, gnorm=0.41, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44112
2023-01-07 03:04:58 - progress_bar.py[line:274] - INFO: epoch 001:  11056 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4124, wps=102.6, ups=0.47, wpb=108.5, bsz=40, num_updates=11040, lr=4.71195e-05, gnorm=0.453, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44134
2023-01-07 03:05:20 - progress_bar.py[line:274] - INFO: epoch 001:  11066 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.418, wps=101.1, ups=0.46, wpb=109.9, bsz=40, num_updates=11050, lr=4.7115e-05, gnorm=0.332, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44156
2023-01-07 03:05:42 - progress_bar.py[line:274] - INFO: epoch 001:  11076 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3834, wps=100.8, ups=0.46, wpb=109.5, bsz=40, num_updates=11060, lr=4.71105e-05, gnorm=0.439, clip=10, loss_scale=128, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=44178
2023-01-07 03:06:04 - progress_bar.py[line:274] - INFO: epoch 001:  11086 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4112, wps=99.6, ups=0.45, wpb=109.6, bsz=40, num_updates=11070, lr=4.7106e-05, gnorm=0.306, clip=0, loss_scale=128, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44200
2023-01-07 03:06:26 - progress_bar.py[line:274] - INFO: epoch 001:  11096 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4254, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=11080, lr=4.71015e-05, gnorm=0.42, clip=0, loss_scale=128, train_wall=22, gb_free=10, ema_decay=0.9999, wall=44222
2023-01-07 03:06:48 - progress_bar.py[line:274] - INFO: epoch 001:  11106 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4129, wps=100.6, ups=0.46, wpb=108.6, bsz=40, num_updates=11090, lr=4.7097e-05, gnorm=0.467, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44244
2023-01-07 03:07:10 - progress_bar.py[line:274] - INFO: epoch 001:  11116 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3776, wps=100.3, ups=0.46, wpb=108.8, bsz=40, num_updates=11100, lr=4.70925e-05, gnorm=0.424, clip=10, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44266
2023-01-07 03:07:32 - progress_bar.py[line:274] - INFO: epoch 001:  11126 / 115845 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3299, wps=101, ups=0.46, wpb=109.4, bsz=40, num_updates=11110, lr=4.7088e-05, gnorm=0.386, clip=0, loss_scale=128, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44287
2023-01-07 03:07:53 - progress_bar.py[line:274] - INFO: epoch 001:  11136 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.393, wps=102.4, ups=0.47, wpb=109.3, bsz=40, num_updates=11120, lr=4.70835e-05, gnorm=0.452, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44309
2023-01-07 03:08:15 - progress_bar.py[line:274] - INFO: epoch 001:  11146 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3911, wps=102.6, ups=0.47, wpb=109.2, bsz=40, num_updates=11130, lr=4.7079e-05, gnorm=1.012, clip=10, loss_scale=128, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=44331
2023-01-07 03:08:38 - progress_bar.py[line:274] - INFO: epoch 001:  11156 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4513, wps=102.4, ups=0.47, wpb=109.7, bsz=40, num_updates=11140, lr=4.70745e-05, gnorm=0.38, clip=0, loss_scale=128, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44352
2023-01-07 03:09:00 - progress_bar.py[line:274] - INFO: epoch 001:  11166 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4031, wps=101.9, ups=0.47, wpb=108.6, bsz=40, num_updates=11150, lr=4.707e-05, gnorm=0.425, clip=0, loss_scale=128, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44375
2023-01-07 03:09:23 - progress_bar.py[line:274] - INFO: epoch 001:  11176 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3929, wps=100.3, ups=0.46, wpb=109.1, bsz=40, num_updates=11160, lr=4.70655e-05, gnorm=0.474, clip=0, loss_scale=128, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44398
2023-01-07 03:09:46 - progress_bar.py[line:274] - INFO: epoch 001:  11186 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.449, wps=101.4, ups=0.46, wpb=109.1, bsz=40, num_updates=11170, lr=4.7061e-05, gnorm=0.492, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=44421
2023-01-07 03:10:09 - progress_bar.py[line:274] - INFO: epoch 001:  11196 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.413, wps=102, ups=0.46, wpb=110.5, bsz=40, num_updates=11180, lr=4.70565e-05, gnorm=0.378, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44444
2023-01-07 03:10:32 - progress_bar.py[line:274] - INFO: epoch 001:  11206 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.449, wps=103.1, ups=0.47, wpb=110.1, bsz=40, num_updates=11190, lr=4.7052e-05, gnorm=0.533, clip=20, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=44467
2023-01-07 03:10:55 - progress_bar.py[line:274] - INFO: epoch 001:  11216 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4596, wps=100.1, ups=0.46, wpb=109.2, bsz=40, num_updates=11200, lr=4.70475e-05, gnorm=0.379, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44490
2023-01-07 03:11:18 - progress_bar.py[line:274] - INFO: epoch 001:  11226 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4439, wps=98.6, ups=0.46, wpb=108.1, bsz=40, num_updates=11210, lr=4.7043e-05, gnorm=0.545, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44513
2023-01-07 03:11:40 - progress_bar.py[line:274] - INFO: epoch 001:  11236 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.377, wps=103.5, ups=0.47, wpb=110.5, bsz=40, num_updates=11220, lr=4.70385e-05, gnorm=0.412, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44535
2023-01-07 03:12:03 - progress_bar.py[line:274] - INFO: epoch 001:  11246 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4069, wps=99.5, ups=0.46, wpb=108.4, bsz=40, num_updates=11230, lr=4.7034e-05, gnorm=0.573, clip=20, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44558
2023-01-07 03:12:26 - progress_bar.py[line:274] - INFO: epoch 001:  11256 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4106, wps=99.9, ups=0.46, wpb=108.9, bsz=40, num_updates=11240, lr=4.70295e-05, gnorm=0.473, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44581
2023-01-07 03:12:49 - progress_bar.py[line:274] - INFO: epoch 001:  11266 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4595, wps=102.8, ups=0.46, wpb=111, bsz=40, num_updates=11250, lr=4.70251e-05, gnorm=0.457, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44604
2023-01-07 03:13:11 - progress_bar.py[line:274] - INFO: epoch 001:  11276 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4184, wps=102.2, ups=0.47, wpb=109.4, bsz=40, num_updates=11260, lr=4.70206e-05, gnorm=0.489, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=44626
2023-01-07 03:13:34 - progress_bar.py[line:274] - INFO: epoch 001:  11286 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4368, wps=99.8, ups=0.46, wpb=109.5, bsz=40, num_updates=11270, lr=4.70161e-05, gnorm=0.449, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=44649
2023-01-07 03:13:57 - progress_bar.py[line:274] - INFO: epoch 001:  11296 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3889, wps=100.5, ups=0.46, wpb=109.2, bsz=40, num_updates=11280, lr=4.70116e-05, gnorm=0.526, clip=0, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=44672
2023-01-07 03:14:20 - progress_bar.py[line:274] - INFO: epoch 001:  11306 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3561, wps=99.9, ups=0.46, wpb=109.4, bsz=40, num_updates=11290, lr=4.70071e-05, gnorm=0.523, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=44695
2023-01-07 03:14:42 - progress_bar.py[line:274] - INFO: epoch 001:  11316 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.395, wps=103.9, ups=0.48, wpb=108.7, bsz=40, num_updates=11300, lr=4.70026e-05, gnorm=0.451, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44717
2023-01-07 03:15:05 - progress_bar.py[line:274] - INFO: epoch 001:  11326 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3578, wps=101.7, ups=0.47, wpb=109, bsz=40, num_updates=11310, lr=4.69981e-05, gnorm=0.568, clip=20, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44740
2023-01-07 03:15:28 - progress_bar.py[line:274] - INFO: epoch 001:  11336 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4356, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=11320, lr=4.69936e-05, gnorm=0.366, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44762
2023-01-07 03:15:51 - progress_bar.py[line:274] - INFO: epoch 001:  11346 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4378, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=11330, lr=4.69891e-05, gnorm=0.419, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=44785
2023-01-07 03:16:14 - progress_bar.py[line:274] - INFO: epoch 001:  11356 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4789, wps=100, ups=0.46, wpb=107.9, bsz=40, num_updates=11340, lr=4.69846e-05, gnorm=0.503, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44809
2023-01-07 03:16:37 - progress_bar.py[line:274] - INFO: epoch 001:  11366 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3816, wps=103.2, ups=0.47, wpb=108.8, bsz=40, num_updates=11350, lr=4.69801e-05, gnorm=0.406, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44832
2023-01-07 03:16:59 - progress_bar.py[line:274] - INFO: epoch 001:  11376 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.375, wps=103.6, ups=0.48, wpb=108.9, bsz=40, num_updates=11360, lr=4.69756e-05, gnorm=0.44, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44854
2023-01-07 03:17:22 - progress_bar.py[line:274] - INFO: epoch 001:  11386 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=106.2, nsentences=40, sample_size=106.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4151, wps=98.3, ups=0.46, wpb=106.2, bsz=40, num_updates=11370, lr=4.69711e-05, gnorm=0.419, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44877
2023-01-07 03:17:45 - progress_bar.py[line:274] - INFO: epoch 001:  11396 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4645, wps=99.3, ups=0.46, wpb=108.2, bsz=40, num_updates=11380, lr=4.69666e-05, gnorm=0.378, clip=0, loss_scale=256, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=44899
2023-01-07 03:18:07 - progress_bar.py[line:274] - INFO: epoch 001:  11406 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4521, wps=101.5, ups=0.47, wpb=109.1, bsz=40, num_updates=11390, lr=4.69621e-05, gnorm=0.444, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=44922
2023-01-07 03:18:30 - progress_bar.py[line:274] - INFO: epoch 001:  11416 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4776, wps=101.1, ups=0.46, wpb=108.8, bsz=40, num_updates=11400, lr=4.69576e-05, gnorm=0.282, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=44945
2023-01-07 03:18:53 - progress_bar.py[line:274] - INFO: epoch 001:  11426 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3938, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=11410, lr=4.69531e-05, gnorm=0.362, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44968
2023-01-07 03:19:16 - progress_bar.py[line:274] - INFO: epoch 001:  11436 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3979, wps=99.2, ups=0.45, wpb=109.1, bsz=40, num_updates=11420, lr=4.69486e-05, gnorm=0.682, clip=20, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=44991
2023-01-07 03:19:39 - progress_bar.py[line:274] - INFO: epoch 001:  11446 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3544, wps=101.6, ups=0.47, wpb=108.9, bsz=40, num_updates=11430, lr=4.69441e-05, gnorm=0.481, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45014
2023-01-07 03:20:02 - progress_bar.py[line:274] - INFO: epoch 001:  11456 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4231, wps=103.4, ups=0.47, wpb=109.3, bsz=40, num_updates=11440, lr=4.69396e-05, gnorm=0.506, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45037
2023-01-07 03:20:25 - progress_bar.py[line:274] - INFO: epoch 001:  11466 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4778, wps=103.7, ups=0.48, wpb=108.9, bsz=40, num_updates=11450, lr=4.69351e-05, gnorm=0.45, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45059
2023-01-07 03:20:48 - progress_bar.py[line:274] - INFO: epoch 001:  11476 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4657, wps=101.2, ups=0.47, wpb=108.8, bsz=40, num_updates=11460, lr=4.69306e-05, gnorm=0.483, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=45082
2023-01-07 03:21:10 - progress_bar.py[line:274] - INFO: epoch 001:  11486 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4279, wps=103.6, ups=0.48, wpb=108.7, bsz=40, num_updates=11470, lr=4.69261e-05, gnorm=0.549, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45105
2023-01-07 03:21:33 - progress_bar.py[line:274] - INFO: epoch 001:  11496 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3819, wps=99.6, ups=0.46, wpb=108.4, bsz=40, num_updates=11480, lr=4.69216e-05, gnorm=0.287, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45128
2023-01-07 03:21:55 - progress_bar.py[line:274] - INFO: epoch 001:  11506 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.407, wps=105.1, ups=0.47, wpb=111, bsz=40, num_updates=11490, lr=4.69171e-05, gnorm=0.44, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45150
2023-01-07 03:22:18 - progress_bar.py[line:274] - INFO: epoch 001:  11516 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4413, wps=101.6, ups=0.46, wpb=111.4, bsz=40, num_updates=11500, lr=4.69127e-05, gnorm=0.416, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45173
2023-01-07 03:22:41 - progress_bar.py[line:274] - INFO: epoch 001:  11526 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3969, wps=102, ups=0.46, wpb=109.7, bsz=40, num_updates=11510, lr=4.69082e-05, gnorm=0.46, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45196
2023-01-07 03:23:04 - progress_bar.py[line:274] - INFO: epoch 001:  11536 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3923, wps=102.7, ups=0.47, wpb=109.7, bsz=40, num_updates=11520, lr=4.69037e-05, gnorm=0.406, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45219
2023-01-07 03:23:27 - progress_bar.py[line:274] - INFO: epoch 001:  11546 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4338, wps=100.5, ups=0.47, wpb=107, bsz=40, num_updates=11530, lr=4.68992e-05, gnorm=0.413, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45241
2023-01-07 03:23:50 - progress_bar.py[line:274] - INFO: epoch 001:  11556 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4241, wps=101.3, ups=0.46, wpb=109.3, bsz=40, num_updates=11540, lr=4.68947e-05, gnorm=0.712, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45264
2023-01-07 03:24:13 - progress_bar.py[line:274] - INFO: epoch 001:  11566 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.452, wps=103, ups=0.46, wpb=110.8, bsz=40, num_updates=11550, lr=4.68902e-05, gnorm=0.492, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45287
2023-01-07 03:24:36 - progress_bar.py[line:274] - INFO: epoch 001:  11576 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.439, wps=102.3, ups=0.47, wpb=108.8, bsz=40, num_updates=11560, lr=4.68857e-05, gnorm=0.429, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=45310
2023-01-07 03:24:57 - progress_bar.py[line:274] - INFO: epoch 001:  11586 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4093, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=11570, lr=4.68812e-05, gnorm=0.477, clip=10, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=45333
2023-01-07 03:25:19 - progress_bar.py[line:274] - INFO: epoch 001:  11596 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3535, wps=102.4, ups=0.47, wpb=108.5, bsz=40, num_updates=11580, lr=4.68767e-05, gnorm=0.504, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45355
2023-01-07 03:25:41 - progress_bar.py[line:274] - INFO: epoch 001:  11606 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3744, wps=98.1, ups=0.46, wpb=107.2, bsz=40, num_updates=11590, lr=4.68722e-05, gnorm=0.447, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45377
2023-01-07 03:26:03 - progress_bar.py[line:274] - INFO: epoch 001:  11616 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4162, wps=99.6, ups=0.45, wpb=109.6, bsz=40, num_updates=11600, lr=4.68677e-05, gnorm=0.458, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45399
2023-01-07 03:26:25 - progress_bar.py[line:274] - INFO: epoch 001:  11626 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4328, wps=99.6, ups=0.46, wpb=107.8, bsz=40, num_updates=11610, lr=4.68632e-05, gnorm=0.546, clip=20, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45421
2023-01-07 03:26:47 - progress_bar.py[line:274] - INFO: epoch 001:  11636 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3632, wps=100.9, ups=0.46, wpb=109.3, bsz=40, num_updates=11620, lr=4.68587e-05, gnorm=0.287, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45443
2023-01-07 03:27:08 - progress_bar.py[line:274] - INFO: epoch 001:  11646 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4513, wps=103, ups=0.47, wpb=108.5, bsz=40, num_updates=11630, lr=4.68542e-05, gnorm=0.307, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=45464
2023-01-07 03:27:30 - progress_bar.py[line:274] - INFO: epoch 001:  11656 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4055, wps=101, ups=0.47, wpb=108.5, bsz=40, num_updates=11640, lr=4.68497e-05, gnorm=0.475, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45486
2023-01-07 03:27:51 - progress_bar.py[line:274] - INFO: epoch 001:  11666 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.401, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=11650, lr=4.68452e-05, gnorm=0.404, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45507
2023-01-07 03:28:13 - progress_bar.py[line:274] - INFO: epoch 001:  11676 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.371, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=11660, lr=4.68407e-05, gnorm=0.292, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45529
2023-01-07 03:28:35 - progress_bar.py[line:274] - INFO: epoch 001:  11686 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3883, wps=102.5, ups=0.47, wpb=110.2, bsz=40, num_updates=11670, lr=4.68362e-05, gnorm=0.449, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45551
2023-01-07 03:28:57 - progress_bar.py[line:274] - INFO: epoch 001:  11696 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4145, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=11680, lr=4.68317e-05, gnorm=0.446, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45573
2023-01-07 03:29:19 - progress_bar.py[line:274] - INFO: epoch 001:  11706 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4229, wps=99.8, ups=0.46, wpb=108.2, bsz=40, num_updates=11690, lr=4.68272e-05, gnorm=0.301, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45595
2023-01-07 03:29:40 - progress_bar.py[line:274] - INFO: epoch 001:  11716 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4101, wps=99.1, ups=0.46, wpb=107, bsz=40, num_updates=11700, lr=4.68227e-05, gnorm=0.392, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45616
2023-01-07 03:30:02 - progress_bar.py[line:274] - INFO: epoch 001:  11726 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4143, wps=102.5, ups=0.47, wpb=108.2, bsz=40, num_updates=11710, lr=4.68182e-05, gnorm=0.402, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45638
2023-01-07 03:30:23 - progress_bar.py[line:274] - INFO: epoch 001:  11736 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4745, wps=104.8, ups=0.48, wpb=109.3, bsz=40, num_updates=11720, lr=4.68137e-05, gnorm=0.37, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=45659
2023-01-07 03:30:44 - progress_bar.py[line:274] - INFO: epoch 001:  11746 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.35, wps=103, ups=0.47, wpb=109.3, bsz=40, num_updates=11730, lr=4.68092e-05, gnorm=0.446, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=45680
2023-01-07 03:31:06 - progress_bar.py[line:274] - INFO: epoch 001:  11756 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4032, wps=102.9, ups=0.46, wpb=111.2, bsz=40, num_updates=11740, lr=4.68048e-05, gnorm=0.355, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=45702
2023-01-07 03:31:28 - progress_bar.py[line:274] - INFO: epoch 001:  11766 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3866, wps=100.7, ups=0.46, wpb=108.6, bsz=40, num_updates=11750, lr=4.68003e-05, gnorm=0.364, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=45724
2023-01-07 03:31:50 - progress_bar.py[line:274] - INFO: epoch 001:  11776 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4326, wps=100.1, ups=0.46, wpb=109, bsz=40, num_updates=11760, lr=4.67958e-05, gnorm=0.375, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=45746
2023-01-07 03:32:11 - progress_bar.py[line:274] - INFO: epoch 001:  11786 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4429, wps=103.3, ups=0.47, wpb=109.3, bsz=40, num_updates=11770, lr=4.67913e-05, gnorm=0.412, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=45767
2023-01-07 03:32:33 - progress_bar.py[line:274] - INFO: epoch 001:  11796 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4, wps=99.8, ups=0.46, wpb=107.6, bsz=40, num_updates=11780, lr=4.67868e-05, gnorm=0.325, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45789
2023-01-07 03:32:55 - progress_bar.py[line:274] - INFO: epoch 001:  11806 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4785, wps=101, ups=0.46, wpb=110.7, bsz=40, num_updates=11790, lr=4.67823e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=45811
2023-01-07 03:33:17 - progress_bar.py[line:274] - INFO: epoch 001:  11816 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3846, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=11800, lr=4.67778e-05, gnorm=0.422, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45833
2023-01-07 03:33:38 - progress_bar.py[line:274] - INFO: epoch 001:  11826 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4109, wps=101.2, ups=0.47, wpb=108.8, bsz=40, num_updates=11810, lr=4.67733e-05, gnorm=0.36, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45854
2023-01-07 03:33:59 - progress_bar.py[line:274] - INFO: epoch 001:  11836 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3981, wps=104.4, ups=0.48, wpb=108.5, bsz=40, num_updates=11820, lr=4.67688e-05, gnorm=0.375, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=45875
2023-01-07 03:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  11846 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.375, wps=100.8, ups=0.46, wpb=109.2, bsz=40, num_updates=11830, lr=4.67643e-05, gnorm=0.61, clip=20, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=45897
2023-01-07 03:34:43 - progress_bar.py[line:274] - INFO: epoch 001:  11856 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3555, wps=100.2, ups=0.46, wpb=108.3, bsz=40, num_updates=11840, lr=4.67598e-05, gnorm=0.359, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=45919
2023-01-07 03:35:05 - progress_bar.py[line:274] - INFO: epoch 001:  11866 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4121, wps=100.8, ups=0.46, wpb=108.5, bsz=40, num_updates=11850, lr=4.67553e-05, gnorm=0.3, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=45941
2023-01-07 03:35:26 - progress_bar.py[line:274] - INFO: epoch 001:  11876 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4279, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=11860, lr=4.67508e-05, gnorm=0.359, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=45962
2023-01-07 03:35:48 - progress_bar.py[line:274] - INFO: epoch 001:  11886 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4115, wps=101.7, ups=0.46, wpb=109.9, bsz=40, num_updates=11870, lr=4.67463e-05, gnorm=0.492, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=45984
2023-01-07 03:36:10 - progress_bar.py[line:274] - INFO: epoch 001:  11896 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3834, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=11880, lr=4.67418e-05, gnorm=0.458, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=46006
2023-01-07 03:36:31 - progress_bar.py[line:274] - INFO: epoch 001:  11906 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3966, wps=104.2, ups=0.47, wpb=110.9, bsz=40, num_updates=11890, lr=4.67373e-05, gnorm=0.278, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=46027
2023-01-07 03:36:53 - progress_bar.py[line:274] - INFO: epoch 001:  11916 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4368, wps=102.8, ups=0.47, wpb=110.5, bsz=40, num_updates=11900, lr=4.67328e-05, gnorm=0.672, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=46049
2023-01-07 03:37:15 - progress_bar.py[line:274] - INFO: epoch 001:  11926 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4082, wps=100.5, ups=0.46, wpb=109, bsz=40, num_updates=11910, lr=4.67283e-05, gnorm=0.417, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=46071
2023-01-07 03:37:37 - progress_bar.py[line:274] - INFO: epoch 001:  11936 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4645, wps=101.2, ups=0.46, wpb=110.2, bsz=40, num_updates=11920, lr=4.67238e-05, gnorm=0.471, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=46093
2023-01-07 03:37:58 - progress_bar.py[line:274] - INFO: epoch 001:  11946 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4573, wps=103.4, ups=0.47, wpb=109.3, bsz=40, num_updates=11930, lr=4.67193e-05, gnorm=0.554, clip=20, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=46114
2023-01-07 03:38:20 - progress_bar.py[line:274] - INFO: epoch 001:  11956 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4064, wps=100.2, ups=0.46, wpb=109, bsz=40, num_updates=11940, lr=4.67148e-05, gnorm=0.404, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=46136
2023-01-07 03:38:42 - progress_bar.py[line:274] - INFO: epoch 001:  11966 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4257, wps=99.6, ups=0.46, wpb=108.8, bsz=40, num_updates=11950, lr=4.67103e-05, gnorm=0.384, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=46158
2023-01-07 03:39:04 - progress_bar.py[line:274] - INFO: epoch 001:  11976 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=100.1, ups=0.46, wpb=107.8, bsz=40, num_updates=11960, lr=4.67058e-05, gnorm=0.402, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=46180
2023-01-07 03:39:26 - progress_bar.py[line:274] - INFO: epoch 001:  11986 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4718, wps=104, ups=0.47, wpb=110.5, bsz=40, num_updates=11970, lr=4.67013e-05, gnorm=0.421, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=46202
2023-01-07 03:39:48 - progress_bar.py[line:274] - INFO: epoch 001:  11996 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4709, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=11980, lr=4.66968e-05, gnorm=0.322, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=46223
2023-01-07 03:40:09 - progress_bar.py[line:274] - INFO: epoch 001:  12006 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4265, wps=101.1, ups=0.46, wpb=109, bsz=40, num_updates=11990, lr=4.66924e-05, gnorm=0.418, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=46245
2023-01-07 03:40:31 - progress_bar.py[line:274] - INFO: epoch 001:  12016 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4769, wps=101.4, ups=0.47, wpb=108.2, bsz=40, num_updates=12000, lr=4.66879e-05, gnorm=0.5, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=46267
2023-01-07 03:40:31 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 03:40:32 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 03:40:32 - train.py[line:551] - INFO: load:1.03 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 03:43:06 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 03:43:06 - train.py[line:551] - INFO: load:1.06 valid_run:153.67 task_valid:149.20 collect_output:3.36
2023-01-07 03:45:35 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 03:45:35 - train.py[line:551] - INFO: load:1.08 valid_run:302.96 task_valid:292.16 collect_output:8.59
2023-01-07 03:48:09 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 03:48:09 - train.py[line:551] - INFO: load:1.11 valid_run:456.90 task_valid:435.09 collect_output:18.55
2023-01-07 03:50:39 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 03:50:39 - train.py[line:551] - INFO: load:1.13 valid_run:606.53 task_valid:579.86 collect_output:22.36
2023-01-07 03:53:12 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 03:53:12 - train.py[line:551] - INFO: load:1.16 valid_run:759.79 task_valid:727.42 collect_output:27.01
2023-01-07 03:55:45 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 03:55:45 - train.py[line:551] - INFO: load:1.19 valid_run:912.32 task_valid:872.84 collect_output:33.07
2023-01-07 03:58:20 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 03:58:20 - train.py[line:551] - INFO: load:1.21 valid_run:1066.85 task_valid:1018.72 collect_output:40.67
2023-01-07 04:00:52 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 04:00:52 - train.py[line:551] - INFO: load:1.24 valid_run:1219.42 task_valid:1159.48 collect_output:51.45
2023-01-07 04:03:23 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 04:03:23 - train.py[line:551] - INFO: load:1.26 valid_run:1370.17 task_valid:1304.29 collect_output:56.33
2023-01-07 04:05:52 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 04:05:52 - train.py[line:551] - INFO: load:1.29 valid_run:1519.43 task_valid:1447.51 collect_output:61.29
2023-01-07 04:08:23 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 04:08:23 - train.py[line:551] - INFO: load:1.32 valid_run:1669.77 task_valid:1592.22 collect_output:65.88
2023-01-07 04:10:53 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 04:10:53 - train.py[line:551] - INFO: load:1.34 valid_run:1820.24 task_valid:1736.80 collect_output:70.73
2023-01-07 04:13:25 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 04:13:25 - train.py[line:551] - INFO: load:1.37 valid_run:1971.43 task_valid:1878.52 collect_output:79.14
2023-01-07 04:15:56 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 04:15:56 - train.py[line:551] - INFO: load:1.39 valid_run:2122.72 task_valid:2023.96 collect_output:83.94
2023-01-07 04:18:26 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 04:18:26 - train.py[line:551] - INFO: load:1.42 valid_run:2273.13 task_valid:2170.20 collect_output:87.07
2023-01-07 04:20:57 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 04:20:57 - train.py[line:551] - INFO: load:1.45 valid_run:2423.95 task_valid:2314.05 collect_output:92.99
2023-01-07 04:23:30 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 04:23:30 - train.py[line:551] - INFO: load:1.47 valid_run:2576.64 task_valid:2459.38 collect_output:99.31
2023-01-07 04:26:01 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 04:26:01 - train.py[line:551] - INFO: load:1.50 valid_run:2727.56 task_valid:2606.08 collect_output:102.48
2023-01-07 04:28:31 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 04:28:31 - train.py[line:551] - INFO: load:1.52 valid_run:2876.94 task_valid:2747.40 collect_output:109.49
2023-01-07 04:31:02 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 04:31:02 - train.py[line:551] - INFO: load:1.55 valid_run:3028.10 task_valid:2892.39 collect_output:114.64
2023-01-07 04:33:35 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 04:33:35 - train.py[line:551] - INFO: load:1.57 valid_run:3181.56 task_valid:3036.91 collect_output:122.53
2023-01-07 04:36:06 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 04:36:06 - train.py[line:551] - INFO: load:1.60 valid_run:3331.85 task_valid:3181.57 collect_output:127.09
2023-01-07 04:38:38 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 04:38:38 - train.py[line:551] - INFO: load:1.62 valid_run:3483.98 task_valid:3327.77 collect_output:131.92
2023-01-07 04:41:10 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 04:41:10 - train.py[line:551] - INFO: load:1.65 valid_run:3635.95 task_valid:3474.08 collect_output:136.50

====================================================================================================
SGG eval:     R @ 50: 0.4519;     R @ 100: 0.5536;     R @ 500: 0.6188;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2797;    mR @ 100: 0.3641;    mR @ 500: 0.4240;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6805) (covered in:0.7500) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4129) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.7908) (says:0.0000) (sitting on:0.6627) (standing on:0.1783) (using:0.5500) (walking in:0.0000) (walking on:0.5405) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4519;     R @ 100: 0.5536;     R @ 500: 0.6188;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2797;    mR @ 100: 0.3641;    mR @ 500: 0.4240;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6805) (covered in:0.7500) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.2500) (hanging from:0.4129) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.7908) (says:0.0000) (sitting on:0.6627) (standing on:0.1783) (using:0.5500) (walking in:0.0000) (walking on:0.5405) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-07 04:43:41 - train.py[line:487] - INFO: 0.5535761904761906
2023-01-07 04:43:41 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 04:43:42 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.395 | loss_v1 0 | loss_v2 0 | nll_loss 0.247 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.553576 | ppl 1.19 | vqa_score 0.5383 | wps 118.4 | wpb 89.9 | bsz 30 | num_updates 12000 | best_R@100 0.641887
2023-01-07 04:43:42 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2023-01-07 04:43:42 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_12000.pt
2023-01-07 04:44:24 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_12000.pt
2023-01-07 04:45:51 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.5535761904761906) (writing took 129.34642183221877 seconds)
2023-01-07 04:46:14 - progress_bar.py[line:274] - INFO: epoch 001:  12026 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4355, wps=0.6, ups=0, wpb=110.1, bsz=40, num_updates=12010, lr=4.66834e-05, gnorm=0.571, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50209
2023-01-07 04:46:35 - progress_bar.py[line:274] - INFO: epoch 001:  12036 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.44, wps=99.6, ups=0.46, wpb=108.1, bsz=40, num_updates=12020, lr=4.66789e-05, gnorm=0.432, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50231
2023-01-07 04:46:57 - progress_bar.py[line:274] - INFO: epoch 001:  12046 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4192, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=12030, lr=4.66744e-05, gnorm=0.459, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50253
2023-01-07 04:47:19 - progress_bar.py[line:274] - INFO: epoch 001:  12056 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4343, wps=100.3, ups=0.46, wpb=108.7, bsz=40, num_updates=12040, lr=4.66699e-05, gnorm=0.388, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50275
2023-01-07 04:47:41 - progress_bar.py[line:274] - INFO: epoch 001:  12066 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4581, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=12050, lr=4.66654e-05, gnorm=0.334, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50297
2023-01-07 04:48:03 - progress_bar.py[line:274] - INFO: epoch 001:  12076 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4444, wps=101, ups=0.46, wpb=109.3, bsz=40, num_updates=12060, lr=4.66609e-05, gnorm=0.692, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=50319
2023-01-07 04:48:24 - progress_bar.py[line:274] - INFO: epoch 001:  12086 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3959, wps=101.3, ups=0.46, wpb=109, bsz=40, num_updates=12070, lr=4.66564e-05, gnorm=0.511, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50340
2023-01-07 04:48:46 - progress_bar.py[line:274] - INFO: epoch 001:  12096 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.466, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=12080, lr=4.66519e-05, gnorm=0.475, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=50362
2023-01-07 04:49:08 - progress_bar.py[line:274] - INFO: epoch 001:  12106 / 115845 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4292, wps=101.5, ups=0.47, wpb=108.4, bsz=40, num_updates=12090, lr=4.66474e-05, gnorm=0.509, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=50383
2023-01-07 04:49:29 - progress_bar.py[line:274] - INFO: epoch 001:  12116 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4242, wps=103, ups=0.47, wpb=109.5, bsz=40, num_updates=12100, lr=4.66429e-05, gnorm=0.397, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50405
2023-01-07 04:49:51 - progress_bar.py[line:274] - INFO: epoch 001:  12126 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4533, wps=99.6, ups=0.46, wpb=108, bsz=40, num_updates=12110, lr=4.66384e-05, gnorm=0.382, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=50427
2023-01-07 04:50:13 - progress_bar.py[line:274] - INFO: epoch 001:  12136 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4219, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=12120, lr=4.66339e-05, gnorm=0.33, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=50449
2023-01-07 04:50:35 - progress_bar.py[line:274] - INFO: epoch 001:  12146 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4242, wps=101.6, ups=0.46, wpb=109.7, bsz=40, num_updates=12130, lr=4.66294e-05, gnorm=0.738, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=50471
2023-01-07 04:50:56 - progress_bar.py[line:274] - INFO: epoch 001:  12156 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4313, wps=101.7, ups=0.47, wpb=108.9, bsz=40, num_updates=12140, lr=4.66249e-05, gnorm=0.341, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=50492
2023-01-07 04:51:18 - progress_bar.py[line:274] - INFO: epoch 001:  12166 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.445, wps=101.6, ups=0.47, wpb=108.6, bsz=40, num_updates=12150, lr=4.66204e-05, gnorm=0.351, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=50514
2023-01-07 04:51:40 - progress_bar.py[line:274] - INFO: epoch 001:  12176 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=100.5, ups=0.46, wpb=108.8, bsz=40, num_updates=12160, lr=4.66159e-05, gnorm=0.375, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50536
2023-01-07 04:52:02 - progress_bar.py[line:274] - INFO: epoch 001:  12186 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4332, wps=100.2, ups=0.46, wpb=109.5, bsz=40, num_updates=12170, lr=4.66114e-05, gnorm=0.364, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50558
2023-01-07 04:52:23 - progress_bar.py[line:274] - INFO: epoch 001:  12196 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4813, wps=103.6, ups=0.47, wpb=109.4, bsz=40, num_updates=12180, lr=4.66069e-05, gnorm=0.445, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=50579
2023-01-07 04:52:45 - progress_bar.py[line:274] - INFO: epoch 001:  12206 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4197, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=12190, lr=4.66024e-05, gnorm=0.383, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50601
2023-01-07 04:53:07 - progress_bar.py[line:274] - INFO: epoch 001:  12216 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4673, wps=99, ups=0.46, wpb=107.8, bsz=40, num_updates=12200, lr=4.65979e-05, gnorm=0.388, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50623
2023-01-07 04:53:29 - progress_bar.py[line:274] - INFO: epoch 001:  12226 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4154, wps=99.9, ups=0.46, wpb=109.5, bsz=40, num_updates=12210, lr=4.65934e-05, gnorm=0.319, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=50645
2023-01-07 04:53:51 - progress_bar.py[line:274] - INFO: epoch 001:  12236 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4021, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=12220, lr=4.65889e-05, gnorm=0.311, clip=0, loss_scale=1024, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=50667
2023-01-07 04:54:12 - progress_bar.py[line:274] - INFO: epoch 001:  12246 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4444, wps=102.4, ups=0.47, wpb=109.4, bsz=40, num_updates=12230, lr=4.65845e-05, gnorm=0.337, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50688
2023-01-07 04:54:34 - progress_bar.py[line:274] - INFO: epoch 001:  12256 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4505, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=12240, lr=4.658e-05, gnorm=0.627, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50710
2023-01-07 04:54:56 - progress_bar.py[line:274] - INFO: epoch 001:  12266 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4238, wps=101.8, ups=0.47, wpb=108.7, bsz=40, num_updates=12250, lr=4.65755e-05, gnorm=0.504, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50732
2023-01-07 04:55:18 - progress_bar.py[line:274] - INFO: epoch 001:  12276 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4592, wps=101, ups=0.46, wpb=109.9, bsz=40, num_updates=12260, lr=4.6571e-05, gnorm=0.506, clip=20, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50754
2023-01-07 04:55:39 - progress_bar.py[line:274] - INFO: epoch 001:  12286 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4041, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=12270, lr=4.65665e-05, gnorm=0.243, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=50775
2023-01-07 04:56:01 - progress_bar.py[line:274] - INFO: epoch 001:  12296 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4167, wps=102.5, ups=0.47, wpb=108.1, bsz=40, num_updates=12280, lr=4.6562e-05, gnorm=0.411, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=50797
2023-01-07 04:56:22 - progress_bar.py[line:274] - INFO: epoch 001:  12306 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4278, wps=103, ups=0.47, wpb=109.8, bsz=40, num_updates=12290, lr=4.65575e-05, gnorm=0.424, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50818
2023-01-07 04:56:35 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 04:56:46 - progress_bar.py[line:274] - INFO: epoch 001:  12317 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.81, nsentences=40, sample_size=108.81, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4545, wps=95.6, ups=0.42, wpb=108.8, bsz=40, num_updates=12300, lr=4.6553e-05, gnorm=0.402, clip=0, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=50842
2023-01-07 04:57:08 - progress_bar.py[line:274] - INFO: epoch 001:  12327 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4155, wps=103.6, ups=0.47, wpb=109.8, bsz=40, num_updates=12310, lr=4.65485e-05, gnorm=0.555, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=50864
2023-01-07 04:57:29 - progress_bar.py[line:274] - INFO: epoch 001:  12337 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4848, wps=103.1, ups=0.47, wpb=108.7, bsz=40, num_updates=12320, lr=4.6544e-05, gnorm=0.39, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50885
2023-01-07 04:57:51 - progress_bar.py[line:274] - INFO: epoch 001:  12347 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4505, wps=103.7, ups=0.46, wpb=111.8, bsz=40, num_updates=12330, lr=4.65395e-05, gnorm=0.437, clip=10, loss_scale=512, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=50907
2023-01-07 04:58:13 - progress_bar.py[line:274] - INFO: epoch 001:  12357 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.455, wps=98.8, ups=0.46, wpb=108.4, bsz=40, num_updates=12340, lr=4.6535e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50929
2023-01-07 04:58:35 - progress_bar.py[line:274] - INFO: epoch 001:  12367 / 115845 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3911, wps=98.4, ups=0.46, wpb=106.6, bsz=40, num_updates=12350, lr=4.65305e-05, gnorm=0.429, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=50951
2023-01-07 04:58:56 - progress_bar.py[line:274] - INFO: epoch 001:  12377 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4372, wps=106.5, ups=0.49, wpb=109.8, bsz=40, num_updates=12360, lr=4.6526e-05, gnorm=0.42, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=50972
2023-01-07 04:59:18 - progress_bar.py[line:274] - INFO: epoch 001:  12387 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4185, wps=101.2, ups=0.46, wpb=110.7, bsz=40, num_updates=12370, lr=4.65215e-05, gnorm=0.339, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=50994
2023-01-07 04:59:40 - progress_bar.py[line:274] - INFO: epoch 001:  12397 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4186, wps=101.7, ups=0.47, wpb=109.1, bsz=40, num_updates=12380, lr=4.6517e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51016
2023-01-07 05:00:02 - progress_bar.py[line:274] - INFO: epoch 001:  12407 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.404, wps=102.3, ups=0.46, wpb=110, bsz=40, num_updates=12390, lr=4.65125e-05, gnorm=0.266, clip=0, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=51037
2023-01-07 05:00:23 - progress_bar.py[line:274] - INFO: epoch 001:  12417 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4346, wps=101.7, ups=0.47, wpb=108.8, bsz=40, num_updates=12400, lr=4.6508e-05, gnorm=0.39, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51059
2023-01-07 05:00:45 - progress_bar.py[line:274] - INFO: epoch 001:  12427 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4789, wps=102.1, ups=0.47, wpb=109.3, bsz=40, num_updates=12410, lr=4.65035e-05, gnorm=0.395, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51081
2023-01-07 05:01:06 - progress_bar.py[line:274] - INFO: epoch 001:  12437 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3909, wps=102.5, ups=0.47, wpb=109.9, bsz=40, num_updates=12420, lr=4.6499e-05, gnorm=0.341, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51102
2023-01-07 05:01:28 - progress_bar.py[line:274] - INFO: epoch 001:  12447 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4249, wps=102.2, ups=0.46, wpb=110.1, bsz=40, num_updates=12430, lr=4.64945e-05, gnorm=0.363, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51124
2023-01-07 05:01:50 - progress_bar.py[line:274] - INFO: epoch 001:  12457 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3935, wps=100.9, ups=0.47, wpb=107.5, bsz=40, num_updates=12440, lr=4.649e-05, gnorm=0.389, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51146
2023-01-07 05:02:11 - progress_bar.py[line:274] - INFO: epoch 001:  12467 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3889, wps=101.3, ups=0.47, wpb=108, bsz=40, num_updates=12450, lr=4.64855e-05, gnorm=0.49, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51167
2023-01-07 05:02:33 - progress_bar.py[line:274] - INFO: epoch 001:  12477 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4485, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=12460, lr=4.6481e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=51189
2023-01-07 05:02:55 - progress_bar.py[line:274] - INFO: epoch 001:  12487 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4623, wps=100.8, ups=0.47, wpb=108.4, bsz=40, num_updates=12470, lr=4.64765e-05, gnorm=0.367, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51210
2023-01-07 05:03:16 - progress_bar.py[line:274] - INFO: epoch 001:  12497 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3682, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=12480, lr=4.64721e-05, gnorm=0.598, clip=10, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=51232
2023-01-07 05:03:38 - progress_bar.py[line:274] - INFO: epoch 001:  12507 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4309, wps=102.2, ups=0.46, wpb=110, bsz=40, num_updates=12490, lr=4.64676e-05, gnorm=0.576, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51254
2023-01-07 05:03:59 - progress_bar.py[line:274] - INFO: epoch 001:  12517 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4286, wps=103.6, ups=0.47, wpb=109.2, bsz=40, num_updates=12500, lr=4.64631e-05, gnorm=0.375, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=51275
2023-01-07 05:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  12527 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4098, wps=101.9, ups=0.47, wpb=109.5, bsz=40, num_updates=12510, lr=4.64586e-05, gnorm=0.286, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51297
2023-01-07 05:04:43 - progress_bar.py[line:274] - INFO: epoch 001:  12537 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4641, wps=101.1, ups=0.46, wpb=110.1, bsz=40, num_updates=12520, lr=4.64541e-05, gnorm=0.315, clip=0, loss_scale=512, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=51319
2023-01-07 05:05:05 - progress_bar.py[line:274] - INFO: epoch 001:  12547 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4619, wps=100.8, ups=0.46, wpb=109.2, bsz=40, num_updates=12530, lr=4.64496e-05, gnorm=0.373, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51341
2023-01-07 05:05:27 - progress_bar.py[line:274] - INFO: epoch 001:  12557 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.468, wps=100.3, ups=0.47, wpb=107.3, bsz=40, num_updates=12540, lr=4.64451e-05, gnorm=0.607, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51362
2023-01-07 05:05:48 - progress_bar.py[line:274] - INFO: epoch 001:  12567 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4633, wps=101.2, ups=0.47, wpb=108.3, bsz=40, num_updates=12550, lr=4.64406e-05, gnorm=0.323, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=51384
2023-01-07 05:06:10 - progress_bar.py[line:274] - INFO: epoch 001:  12577 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3966, wps=101.7, ups=0.46, wpb=110.6, bsz=40, num_updates=12560, lr=4.64361e-05, gnorm=0.397, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51406
2023-01-07 05:06:32 - progress_bar.py[line:274] - INFO: epoch 001:  12587 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3971, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=12570, lr=4.64316e-05, gnorm=0.398, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51428
2023-01-07 05:06:54 - progress_bar.py[line:274] - INFO: epoch 001:  12597 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4787, wps=100.6, ups=0.46, wpb=108.8, bsz=40, num_updates=12580, lr=4.64271e-05, gnorm=0.417, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=51450
2023-01-07 05:07:16 - progress_bar.py[line:274] - INFO: epoch 001:  12607 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.385, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=12590, lr=4.64226e-05, gnorm=0.481, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=51472
2023-01-07 05:07:38 - progress_bar.py[line:274] - INFO: epoch 001:  12617 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3925, wps=100.2, ups=0.46, wpb=108.7, bsz=40, num_updates=12600, lr=4.64181e-05, gnorm=0.491, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=51494
2023-01-07 05:08:00 - progress_bar.py[line:274] - INFO: epoch 001:  12627 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4053, wps=100.9, ups=0.46, wpb=109.6, bsz=40, num_updates=12610, lr=4.64136e-05, gnorm=0.315, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51516
2023-01-07 05:08:21 - progress_bar.py[line:274] - INFO: epoch 001:  12637 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4541, wps=102.4, ups=0.47, wpb=109.1, bsz=40, num_updates=12620, lr=4.64091e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=51537
2023-01-07 05:08:43 - progress_bar.py[line:274] - INFO: epoch 001:  12647 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4388, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=12630, lr=4.64046e-05, gnorm=0.336, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=51559
2023-01-07 05:09:05 - progress_bar.py[line:274] - INFO: epoch 001:  12657 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4265, wps=99.6, ups=0.46, wpb=108.3, bsz=40, num_updates=12640, lr=4.64001e-05, gnorm=0.454, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=51581
2023-01-07 05:09:27 - progress_bar.py[line:274] - INFO: epoch 001:  12667 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3618, wps=99.9, ups=0.46, wpb=107.8, bsz=40, num_updates=12650, lr=4.63956e-05, gnorm=0.602, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51603
2023-01-07 05:09:49 - progress_bar.py[line:274] - INFO: epoch 001:  12677 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3927, wps=101.5, ups=0.46, wpb=110.2, bsz=40, num_updates=12660, lr=4.63911e-05, gnorm=0.388, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51625
2023-01-07 05:10:11 - progress_bar.py[line:274] - INFO: epoch 001:  12687 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.408, wps=102, ups=0.46, wpb=110.5, bsz=40, num_updates=12670, lr=4.63866e-05, gnorm=0.359, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=51646
2023-01-07 05:10:33 - progress_bar.py[line:274] - INFO: epoch 001:  12697 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4486, wps=101.1, ups=0.46, wpb=109.7, bsz=40, num_updates=12680, lr=4.63821e-05, gnorm=0.349, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51668
2023-01-07 05:10:54 - progress_bar.py[line:274] - INFO: epoch 001:  12707 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.398, wps=102, ups=0.47, wpb=108.5, bsz=40, num_updates=12690, lr=4.63776e-05, gnorm=0.375, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=51690
2023-01-07 05:11:16 - progress_bar.py[line:274] - INFO: epoch 001:  12717 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4398, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=12700, lr=4.63731e-05, gnorm=0.321, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51712
2023-01-07 05:11:37 - progress_bar.py[line:274] - INFO: epoch 001:  12727 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.414, wps=101.4, ups=0.47, wpb=108.4, bsz=40, num_updates=12710, lr=4.63686e-05, gnorm=0.408, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=51733
2023-01-07 05:11:59 - progress_bar.py[line:274] - INFO: epoch 001:  12737 / 115845 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4152, wps=100.5, ups=0.47, wpb=108, bsz=40, num_updates=12720, lr=4.63642e-05, gnorm=0.571, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51755
2023-01-07 05:12:20 - progress_bar.py[line:274] - INFO: epoch 001:  12747 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4503, wps=104.7, ups=0.48, wpb=109.8, bsz=40, num_updates=12730, lr=4.63597e-05, gnorm=0.25, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=51776
2023-01-07 05:12:42 - progress_bar.py[line:274] - INFO: epoch 001:  12757 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4112, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=12740, lr=4.63552e-05, gnorm=0.469, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=51798
2023-01-07 05:13:04 - progress_bar.py[line:274] - INFO: epoch 001:  12767 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4556, wps=101.5, ups=0.46, wpb=110, bsz=40, num_updates=12750, lr=4.63507e-05, gnorm=0.328, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51820
2023-01-07 05:13:26 - progress_bar.py[line:274] - INFO: epoch 001:  12777 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4577, wps=100.3, ups=0.46, wpb=109.7, bsz=40, num_updates=12760, lr=4.63462e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=51842
2023-01-07 05:13:47 - progress_bar.py[line:274] - INFO: epoch 001:  12787 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.433, wps=102.9, ups=0.47, wpb=108.5, bsz=40, num_updates=12770, lr=4.63417e-05, gnorm=0.426, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=51863
2023-01-07 05:14:09 - progress_bar.py[line:274] - INFO: epoch 001:  12797 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4692, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=12780, lr=4.63372e-05, gnorm=0.287, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=51885
2023-01-07 05:14:31 - progress_bar.py[line:274] - INFO: epoch 001:  12807 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=105.7, nsentences=40, sample_size=105.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4044, wps=98, ups=0.46, wpb=105.7, bsz=40, num_updates=12790, lr=4.63327e-05, gnorm=0.955, clip=30, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=51907
2023-01-07 05:14:52 - progress_bar.py[line:274] - INFO: epoch 001:  12817 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4286, wps=103.1, ups=0.47, wpb=108.9, bsz=40, num_updates=12800, lr=4.63282e-05, gnorm=0.406, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=51928
2023-01-07 05:15:14 - progress_bar.py[line:274] - INFO: epoch 001:  12827 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4513, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=12810, lr=4.63237e-05, gnorm=0.416, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=51950
2023-01-07 05:15:36 - progress_bar.py[line:274] - INFO: epoch 001:  12837 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.399, wps=99.4, ups=0.46, wpb=108.7, bsz=40, num_updates=12820, lr=4.63192e-05, gnorm=0.322, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=51972
2023-01-07 05:15:58 - progress_bar.py[line:274] - INFO: epoch 001:  12847 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4074, wps=100.7, ups=0.46, wpb=109.1, bsz=40, num_updates=12830, lr=4.63147e-05, gnorm=0.545, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=51994
2023-01-07 05:16:19 - progress_bar.py[line:274] - INFO: epoch 001:  12857 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4378, wps=103.4, ups=0.48, wpb=108.6, bsz=40, num_updates=12840, lr=4.63102e-05, gnorm=0.449, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=52015
2023-01-07 05:16:41 - progress_bar.py[line:274] - INFO: epoch 001:  12867 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4603, wps=103.6, ups=0.47, wpb=110.4, bsz=40, num_updates=12850, lr=4.63057e-05, gnorm=0.405, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52036
2023-01-07 05:17:02 - progress_bar.py[line:274] - INFO: epoch 001:  12877 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4444, wps=102.1, ups=0.46, wpb=109.8, bsz=40, num_updates=12860, lr=4.63012e-05, gnorm=0.452, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=52058
2023-01-07 05:17:24 - progress_bar.py[line:274] - INFO: epoch 001:  12887 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4819, wps=101.8, ups=0.47, wpb=109.4, bsz=40, num_updates=12870, lr=4.62967e-05, gnorm=0.722, clip=20, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=52080
2023-01-07 05:17:46 - progress_bar.py[line:274] - INFO: epoch 001:  12897 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.385, wps=103.5, ups=0.47, wpb=110.4, bsz=40, num_updates=12880, lr=4.62922e-05, gnorm=0.389, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52101
2023-01-07 05:18:07 - progress_bar.py[line:274] - INFO: epoch 001:  12907 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4372, wps=104.5, ups=0.47, wpb=110.2, bsz=40, num_updates=12890, lr=4.62877e-05, gnorm=0.328, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=52123
2023-01-07 05:18:29 - progress_bar.py[line:274] - INFO: epoch 001:  12917 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4167, wps=101.6, ups=0.47, wpb=108.8, bsz=40, num_updates=12900, lr=4.62832e-05, gnorm=0.277, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=52144
2023-01-07 05:18:50 - progress_bar.py[line:274] - INFO: epoch 001:  12927 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=12910, lr=4.62787e-05, gnorm=0.291, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=52166
2023-01-07 05:19:12 - progress_bar.py[line:274] - INFO: epoch 001:  12937 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4263, wps=101.2, ups=0.46, wpb=109.7, bsz=40, num_updates=12920, lr=4.62742e-05, gnorm=0.426, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=52188
2023-01-07 05:19:34 - progress_bar.py[line:274] - INFO: epoch 001:  12947 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3939, wps=100.3, ups=0.46, wpb=109.1, bsz=40, num_updates=12930, lr=4.62697e-05, gnorm=0.37, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=52210
2023-01-07 05:19:49 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 05:19:58 - progress_bar.py[line:274] - INFO: epoch 001:  12958 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=110.143, nsentences=40, sample_size=110.143, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4384, wps=97.7, ups=0.42, wpb=110.1, bsz=40, num_updates=12940, lr=4.62652e-05, gnorm=0.382, clip=0, loss_scale=512, train_wall=24, gb_free=10.1, ema_decay=0.9999, wall=52234
2023-01-07 05:20:20 - progress_bar.py[line:274] - INFO: epoch 001:  12968 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4058, wps=101.2, ups=0.47, wpb=108.5, bsz=40, num_updates=12950, lr=4.62607e-05, gnorm=0.487, clip=20, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52255
2023-01-07 05:20:41 - progress_bar.py[line:274] - INFO: epoch 001:  12978 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.505, wps=102.1, ups=0.47, wpb=108.2, bsz=40, num_updates=12960, lr=4.62562e-05, gnorm=0.383, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52277
2023-01-07 05:21:03 - progress_bar.py[line:274] - INFO: epoch 001:  12988 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4211, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=12970, lr=4.62518e-05, gnorm=0.466, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52299
2023-01-07 05:21:24 - progress_bar.py[line:274] - INFO: epoch 001:  12998 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4778, wps=102.2, ups=0.47, wpb=108.5, bsz=40, num_updates=12980, lr=4.62473e-05, gnorm=0.388, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52320
2023-01-07 05:21:46 - progress_bar.py[line:274] - INFO: epoch 001:  13008 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4611, wps=99, ups=0.46, wpb=108.5, bsz=40, num_updates=12990, lr=4.62428e-05, gnorm=0.56, clip=10, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=52342
2023-01-07 05:22:08 - progress_bar.py[line:274] - INFO: epoch 001:  13018 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4183, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=13000, lr=4.62383e-05, gnorm=0.374, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52364
2023-01-07 05:22:29 - progress_bar.py[line:274] - INFO: epoch 001:  13028 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.457, wps=105.7, ups=0.48, wpb=110, bsz=40, num_updates=13010, lr=4.62338e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52385
2023-01-07 05:22:51 - progress_bar.py[line:274] - INFO: epoch 001:  13038 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3873, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=13020, lr=4.62293e-05, gnorm=0.552, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52407
2023-01-07 05:23:13 - progress_bar.py[line:274] - INFO: epoch 001:  13048 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5106, wps=101.9, ups=0.47, wpb=109, bsz=40, num_updates=13030, lr=4.62248e-05, gnorm=0.431, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52429
2023-01-07 05:23:34 - progress_bar.py[line:274] - INFO: epoch 001:  13058 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3881, wps=102, ups=0.47, wpb=108.9, bsz=40, num_updates=13040, lr=4.62203e-05, gnorm=0.407, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=52450
2023-01-07 05:23:56 - progress_bar.py[line:274] - INFO: epoch 001:  13068 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4516, wps=100.4, ups=0.47, wpb=107.7, bsz=40, num_updates=13050, lr=4.62158e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52472
2023-01-07 05:24:18 - progress_bar.py[line:274] - INFO: epoch 001:  13078 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4154, wps=100.1, ups=0.46, wpb=108.6, bsz=40, num_updates=13060, lr=4.62113e-05, gnorm=0.518, clip=20, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=52494
2023-01-07 05:24:40 - progress_bar.py[line:274] - INFO: epoch 001:  13088 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4498, wps=98.1, ups=0.46, wpb=107.3, bsz=40, num_updates=13070, lr=4.62068e-05, gnorm=0.443, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52516
2023-01-07 05:25:02 - progress_bar.py[line:274] - INFO: epoch 001:  13098 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4249, wps=101.9, ups=0.46, wpb=110, bsz=40, num_updates=13080, lr=4.62023e-05, gnorm=0.492, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=52538
2023-01-07 05:25:24 - progress_bar.py[line:274] - INFO: epoch 001:  13108 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4061, wps=100.9, ups=0.47, wpb=108.2, bsz=40, num_updates=13090, lr=4.61978e-05, gnorm=0.441, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52560
2023-01-07 05:25:45 - progress_bar.py[line:274] - INFO: epoch 001:  13118 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4703, wps=100.5, ups=0.46, wpb=108.6, bsz=40, num_updates=13100, lr=4.61933e-05, gnorm=0.262, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=52581
2023-01-07 05:26:07 - progress_bar.py[line:274] - INFO: epoch 001:  13128 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.475, wps=99.9, ups=0.46, wpb=108.2, bsz=40, num_updates=13110, lr=4.61888e-05, gnorm=0.396, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=52603
2023-01-07 05:26:29 - progress_bar.py[line:274] - INFO: epoch 001:  13138 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4439, wps=102.9, ups=0.47, wpb=109, bsz=40, num_updates=13120, lr=4.61843e-05, gnorm=0.379, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52625
2023-01-07 05:26:51 - progress_bar.py[line:274] - INFO: epoch 001:  13148 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3991, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=13130, lr=4.61798e-05, gnorm=0.573, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52646
2023-01-07 05:27:12 - progress_bar.py[line:274] - INFO: epoch 001:  13158 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4372, wps=102.4, ups=0.47, wpb=109.8, bsz=40, num_updates=13140, lr=4.61753e-05, gnorm=0.423, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52668
2023-01-07 05:27:33 - progress_bar.py[line:274] - INFO: epoch 001:  13168 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4195, wps=105.8, ups=0.47, wpb=111.5, bsz=40, num_updates=13150, lr=4.61708e-05, gnorm=0.402, clip=20, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=52689
2023-01-07 05:27:55 - progress_bar.py[line:274] - INFO: epoch 001:  13178 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3834, wps=101.4, ups=0.46, wpb=109.5, bsz=40, num_updates=13160, lr=4.61663e-05, gnorm=0.34, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52711
2023-01-07 05:28:18 - progress_bar.py[line:274] - INFO: epoch 001:  13188 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3717, wps=100.4, ups=0.45, wpb=110.5, bsz=40, num_updates=13170, lr=4.61618e-05, gnorm=0.462, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=52733
2023-01-07 05:28:39 - progress_bar.py[line:274] - INFO: epoch 001:  13198 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.385, wps=101.3, ups=0.46, wpb=109.1, bsz=40, num_updates=13180, lr=4.61573e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=52755
2023-01-07 05:29:01 - progress_bar.py[line:274] - INFO: epoch 001:  13208 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4188, wps=102.2, ups=0.47, wpb=109, bsz=40, num_updates=13190, lr=4.61528e-05, gnorm=0.345, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52777
2023-01-07 05:29:23 - progress_bar.py[line:274] - INFO: epoch 001:  13218 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4315, wps=102.1, ups=0.46, wpb=111, bsz=40, num_updates=13200, lr=4.61483e-05, gnorm=0.319, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=52799
2023-01-07 05:29:45 - progress_bar.py[line:274] - INFO: epoch 001:  13228 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3947, wps=101.3, ups=0.47, wpb=108.8, bsz=40, num_updates=13210, lr=4.61439e-05, gnorm=0.415, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52820
2023-01-07 05:30:06 - progress_bar.py[line:274] - INFO: epoch 001:  13238 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=106.6, nsentences=40, sample_size=106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4091, wps=99.8, ups=0.47, wpb=106.6, bsz=40, num_updates=13220, lr=4.61394e-05, gnorm=0.241, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52842
2023-01-07 05:30:28 - progress_bar.py[line:274] - INFO: epoch 001:  13248 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4902, wps=101.7, ups=0.47, wpb=109.1, bsz=40, num_updates=13230, lr=4.61349e-05, gnorm=0.386, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52864
2023-01-07 05:30:50 - progress_bar.py[line:274] - INFO: epoch 001:  13258 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4531, wps=100.9, ups=0.46, wpb=109.8, bsz=40, num_updates=13240, lr=4.61304e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=52886
2023-01-07 05:31:11 - progress_bar.py[line:274] - INFO: epoch 001:  13268 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3791, wps=102, ups=0.47, wpb=108.4, bsz=40, num_updates=13250, lr=4.61259e-05, gnorm=0.303, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52907
2023-01-07 05:31:33 - progress_bar.py[line:274] - INFO: epoch 001:  13278 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4355, wps=104.1, ups=0.47, wpb=110.2, bsz=40, num_updates=13260, lr=4.61214e-05, gnorm=0.307, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52929
2023-01-07 05:31:54 - progress_bar.py[line:274] - INFO: epoch 001:  13288 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4558, wps=103.3, ups=0.48, wpb=108.7, bsz=40, num_updates=13270, lr=4.61169e-05, gnorm=0.349, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=52950
2023-01-07 05:32:15 - progress_bar.py[line:274] - INFO: epoch 001:  13298 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4, wps=103.3, ups=0.47, wpb=109.4, bsz=40, num_updates=13280, lr=4.61124e-05, gnorm=0.322, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=52971
2023-01-07 05:32:37 - progress_bar.py[line:274] - INFO: epoch 001:  13308 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4755, wps=101.8, ups=0.47, wpb=108.4, bsz=40, num_updates=13290, lr=4.61079e-05, gnorm=0.393, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=52993
2023-01-07 05:32:59 - progress_bar.py[line:274] - INFO: epoch 001:  13318 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4279, wps=99.4, ups=0.46, wpb=107.5, bsz=40, num_updates=13300, lr=4.61034e-05, gnorm=0.447, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53015
2023-01-07 05:33:20 - progress_bar.py[line:274] - INFO: epoch 001:  13328 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3557, wps=102.1, ups=0.47, wpb=109.8, bsz=40, num_updates=13310, lr=4.60989e-05, gnorm=0.31, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=53036
2023-01-07 05:33:42 - progress_bar.py[line:274] - INFO: epoch 001:  13338 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4667, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=13320, lr=4.60944e-05, gnorm=0.33, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=53058
2023-01-07 05:34:04 - progress_bar.py[line:274] - INFO: epoch 001:  13348 / 115845 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3843, wps=98.7, ups=0.46, wpb=107.8, bsz=40, num_updates=13330, lr=4.60899e-05, gnorm=0.353, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=53080
2023-01-07 05:34:26 - progress_bar.py[line:274] - INFO: epoch 001:  13358 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4, wps=101, ups=0.47, wpb=107.8, bsz=40, num_updates=13340, lr=4.60854e-05, gnorm=0.379, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53102
2023-01-07 05:34:48 - progress_bar.py[line:274] - INFO: epoch 001:  13368 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4634, wps=100.9, ups=0.47, wpb=107.8, bsz=40, num_updates=13350, lr=4.60809e-05, gnorm=0.347, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53123
2023-01-07 05:35:09 - progress_bar.py[line:274] - INFO: epoch 001:  13378 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4792, wps=104.2, ups=0.47, wpb=110.1, bsz=40, num_updates=13360, lr=4.60764e-05, gnorm=0.299, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53145
2023-01-07 05:35:30 - progress_bar.py[line:274] - INFO: epoch 001:  13388 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4924, wps=102.1, ups=0.47, wpb=108.9, bsz=40, num_updates=13370, lr=4.60719e-05, gnorm=0.498, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53166
2023-01-07 05:35:52 - progress_bar.py[line:274] - INFO: epoch 001:  13398 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.397, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=13380, lr=4.60674e-05, gnorm=0.32, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53188
2023-01-07 05:36:14 - progress_bar.py[line:274] - INFO: epoch 001:  13408 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4536, wps=101.2, ups=0.47, wpb=108.3, bsz=40, num_updates=13390, lr=4.60629e-05, gnorm=0.346, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53210
2023-01-07 05:36:36 - progress_bar.py[line:274] - INFO: epoch 001:  13418 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4507, wps=99.7, ups=0.46, wpb=107.4, bsz=40, num_updates=13400, lr=4.60584e-05, gnorm=0.364, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=53231
2023-01-07 05:36:57 - progress_bar.py[line:274] - INFO: epoch 001:  13428 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4263, wps=104.5, ups=0.47, wpb=110.8, bsz=40, num_updates=13410, lr=4.60539e-05, gnorm=0.249, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53253
2023-01-07 05:37:19 - progress_bar.py[line:274] - INFO: epoch 001:  13438 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4519, wps=101, ups=0.47, wpb=108.2, bsz=40, num_updates=13420, lr=4.60494e-05, gnorm=0.444, clip=0, loss_scale=512, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=53274
2023-01-07 05:37:40 - progress_bar.py[line:274] - INFO: epoch 001:  13448 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4167, wps=101.1, ups=0.47, wpb=108, bsz=40, num_updates=13430, lr=4.60449e-05, gnorm=0.359, clip=10, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=53296
2023-01-07 05:38:02 - progress_bar.py[line:274] - INFO: epoch 001:  13458 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4498, wps=102.6, ups=0.47, wpb=108.4, bsz=40, num_updates=13440, lr=4.60404e-05, gnorm=0.38, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53317
2023-01-07 05:38:23 - progress_bar.py[line:274] - INFO: epoch 001:  13468 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4567, wps=102, ups=0.47, wpb=108.9, bsz=40, num_updates=13450, lr=4.60359e-05, gnorm=0.304, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53339
2023-01-07 05:38:45 - progress_bar.py[line:274] - INFO: epoch 001:  13478 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4278, wps=100.9, ups=0.46, wpb=109.5, bsz=40, num_updates=13460, lr=4.60315e-05, gnorm=0.336, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=53361
2023-01-07 05:39:07 - progress_bar.py[line:274] - INFO: epoch 001:  13488 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4138, wps=98.8, ups=0.46, wpb=107.5, bsz=40, num_updates=13470, lr=4.6027e-05, gnorm=0.346, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=53383
2023-01-07 05:39:29 - progress_bar.py[line:274] - INFO: epoch 001:  13498 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4211, wps=101.5, ups=0.46, wpb=109.8, bsz=40, num_updates=13480, lr=4.60225e-05, gnorm=0.356, clip=0, loss_scale=1024, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=53405
2023-01-07 05:39:51 - progress_bar.py[line:274] - INFO: epoch 001:  13508 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.414, wps=100.7, ups=0.46, wpb=110, bsz=40, num_updates=13490, lr=4.6018e-05, gnorm=0.37, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=53427
2023-01-07 05:40:13 - progress_bar.py[line:274] - INFO: epoch 001:  13518 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=101.9, ups=0.47, wpb=109.1, bsz=40, num_updates=13500, lr=4.60135e-05, gnorm=0.436, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53448
2023-01-07 05:40:34 - progress_bar.py[line:274] - INFO: epoch 001:  13528 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4239, wps=103.9, ups=0.47, wpb=110.7, bsz=40, num_updates=13510, lr=4.6009e-05, gnorm=0.338, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53470
2023-01-07 05:40:55 - progress_bar.py[line:274] - INFO: epoch 001:  13538 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4663, wps=103.2, ups=0.47, wpb=109.6, bsz=40, num_updates=13520, lr=4.60045e-05, gnorm=0.466, clip=10, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=53491
2023-01-07 05:41:17 - progress_bar.py[line:274] - INFO: epoch 001:  13548 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.401, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=13530, lr=4.6e-05, gnorm=0.313, clip=0, loss_scale=1024, train_wall=22, gb_free=9.6, ema_decay=0.9999, wall=53513
2023-01-07 05:41:39 - progress_bar.py[line:274] - INFO: epoch 001:  13558 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4523, wps=100.9, ups=0.47, wpb=108.4, bsz=40, num_updates=13540, lr=4.59955e-05, gnorm=0.333, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53535
2023-01-07 05:42:00 - progress_bar.py[line:274] - INFO: epoch 001:  13568 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5318, wps=102.5, ups=0.47, wpb=108.8, bsz=40, num_updates=13550, lr=4.5991e-05, gnorm=0.277, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=53556
2023-01-07 05:42:22 - progress_bar.py[line:274] - INFO: epoch 001:  13578 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4465, wps=99.6, ups=0.47, wpb=106.9, bsz=40, num_updates=13560, lr=4.59865e-05, gnorm=0.301, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53578
2023-01-07 05:42:44 - progress_bar.py[line:274] - INFO: epoch 001:  13588 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5191, wps=104.1, ups=0.47, wpb=110.8, bsz=40, num_updates=13570, lr=4.5982e-05, gnorm=0.287, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53600
2023-01-07 05:43:05 - progress_bar.py[line:274] - INFO: epoch 001:  13598 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3861, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=13580, lr=4.59775e-05, gnorm=0.327, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53621
2023-01-07 05:43:27 - progress_bar.py[line:274] - INFO: epoch 001:  13608 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4308, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=13590, lr=4.5973e-05, gnorm=0.399, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53643
2023-01-07 05:43:49 - progress_bar.py[line:274] - INFO: epoch 001:  13618 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3791, wps=100.6, ups=0.46, wpb=109.2, bsz=40, num_updates=13600, lr=4.59685e-05, gnorm=0.596, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=53665
2023-01-07 05:44:11 - progress_bar.py[line:274] - INFO: epoch 001:  13628 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=103.1, ups=0.47, wpb=109.7, bsz=40, num_updates=13610, lr=4.5964e-05, gnorm=0.341, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=53687
2023-01-07 05:44:32 - progress_bar.py[line:274] - INFO: epoch 001:  13638 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4563, wps=101.2, ups=0.47, wpb=107.9, bsz=40, num_updates=13620, lr=4.59595e-05, gnorm=0.428, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53708
2023-01-07 05:44:54 - progress_bar.py[line:274] - INFO: epoch 001:  13648 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4118, wps=101.9, ups=0.47, wpb=109.5, bsz=40, num_updates=13630, lr=4.5955e-05, gnorm=0.27, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53730
2023-01-07 05:45:16 - progress_bar.py[line:274] - INFO: epoch 001:  13658 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4949, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=13640, lr=4.59505e-05, gnorm=0.318, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53752
2023-01-07 05:45:37 - progress_bar.py[line:274] - INFO: epoch 001:  13668 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4486, wps=106, ups=0.47, wpb=112, bsz=40, num_updates=13650, lr=4.5946e-05, gnorm=0.394, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=53773
2023-01-07 05:45:59 - progress_bar.py[line:274] - INFO: epoch 001:  13678 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4831, wps=99.1, ups=0.45, wpb=109.4, bsz=40, num_updates=13660, lr=4.59415e-05, gnorm=0.419, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=53795
2023-01-07 05:46:21 - progress_bar.py[line:274] - INFO: epoch 001:  13688 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.399, wps=102.9, ups=0.47, wpb=109.9, bsz=40, num_updates=13670, lr=4.5937e-05, gnorm=0.4, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53817
2023-01-07 05:46:43 - progress_bar.py[line:274] - INFO: epoch 001:  13698 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4247, wps=100.5, ups=0.46, wpb=108.6, bsz=40, num_updates=13680, lr=4.59325e-05, gnorm=0.438, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=53839
2023-01-07 05:47:04 - progress_bar.py[line:274] - INFO: epoch 001:  13708 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4199, wps=104.2, ups=0.47, wpb=110.2, bsz=40, num_updates=13690, lr=4.5928e-05, gnorm=0.421, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=53860
2023-01-07 05:47:26 - progress_bar.py[line:274] - INFO: epoch 001:  13718 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4432, wps=102.1, ups=0.46, wpb=110.3, bsz=40, num_updates=13700, lr=4.59236e-05, gnorm=0.36, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=53882
2023-01-07 05:47:48 - progress_bar.py[line:274] - INFO: epoch 001:  13728 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4335, wps=102, ups=0.46, wpb=109.9, bsz=40, num_updates=13710, lr=4.59191e-05, gnorm=0.327, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53904
2023-01-07 05:48:09 - progress_bar.py[line:274] - INFO: epoch 001:  13738 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4098, wps=103.7, ups=0.47, wpb=110.7, bsz=40, num_updates=13720, lr=4.59146e-05, gnorm=0.639, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53925
2023-01-07 05:48:31 - progress_bar.py[line:274] - INFO: epoch 001:  13748 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.355, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=13730, lr=4.59101e-05, gnorm=0.391, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=53947
2023-01-07 05:48:53 - progress_bar.py[line:274] - INFO: epoch 001:  13758 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.432, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=13740, lr=4.59056e-05, gnorm=0.281, clip=0, loss_scale=1024, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=53969
2023-01-07 05:49:15 - progress_bar.py[line:274] - INFO: epoch 001:  13768 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4771, wps=101.4, ups=0.47, wpb=108.4, bsz=40, num_updates=13750, lr=4.59011e-05, gnorm=0.276, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=53991
2023-01-07 05:49:37 - progress_bar.py[line:274] - INFO: epoch 001:  13778 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3971, wps=99.2, ups=0.46, wpb=109, bsz=40, num_updates=13760, lr=4.58966e-05, gnorm=0.53, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54013
2023-01-07 05:49:58 - progress_bar.py[line:274] - INFO: epoch 001:  13788 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4545, wps=103.3, ups=0.47, wpb=109.4, bsz=40, num_updates=13770, lr=4.58921e-05, gnorm=0.428, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=54034
2023-01-07 05:50:20 - progress_bar.py[line:274] - INFO: epoch 001:  13798 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4363, wps=101.6, ups=0.47, wpb=108.3, bsz=40, num_updates=13780, lr=4.58876e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=54056
2023-01-07 05:50:42 - progress_bar.py[line:274] - INFO: epoch 001:  13808 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4417, wps=98.8, ups=0.46, wpb=107.2, bsz=40, num_updates=13790, lr=4.58831e-05, gnorm=0.424, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54078
2023-01-07 05:51:03 - progress_bar.py[line:274] - INFO: epoch 001:  13818 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4308, wps=103.9, ups=0.48, wpb=109, bsz=40, num_updates=13800, lr=4.58786e-05, gnorm=0.407, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=54099
2023-01-07 05:51:25 - progress_bar.py[line:274] - INFO: epoch 001:  13828 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4554, wps=100.4, ups=0.46, wpb=109, bsz=40, num_updates=13810, lr=4.58741e-05, gnorm=0.343, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54121
2023-01-07 05:51:46 - progress_bar.py[line:274] - INFO: epoch 001:  13838 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4381, wps=101.3, ups=0.47, wpb=108.3, bsz=40, num_updates=13820, lr=4.58696e-05, gnorm=0.328, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54142
2023-01-07 05:52:08 - progress_bar.py[line:274] - INFO: epoch 001:  13848 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5049, wps=99.8, ups=0.46, wpb=108.5, bsz=40, num_updates=13830, lr=4.58651e-05, gnorm=0.287, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=54164
2023-01-07 05:52:30 - progress_bar.py[line:274] - INFO: epoch 001:  13858 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4462, wps=102.2, ups=0.47, wpb=109.8, bsz=40, num_updates=13840, lr=4.58606e-05, gnorm=0.198, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=54186
2023-01-07 05:52:52 - progress_bar.py[line:274] - INFO: epoch 001:  13868 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4167, wps=100.1, ups=0.46, wpb=107.7, bsz=40, num_updates=13850, lr=4.58561e-05, gnorm=0.344, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54208
2023-01-07 05:53:13 - progress_bar.py[line:274] - INFO: epoch 001:  13878 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4375, wps=104.9, ups=0.48, wpb=108.8, bsz=40, num_updates=13860, lr=4.58516e-05, gnorm=0.332, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=54229
2023-01-07 05:53:34 - progress_bar.py[line:274] - INFO: epoch 001:  13888 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4213, wps=100.5, ups=0.47, wpb=108, bsz=40, num_updates=13870, lr=4.58471e-05, gnorm=0.368, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54250
2023-01-07 05:53:36 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 05:53:58 - progress_bar.py[line:274] - INFO: epoch 001:  13899 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.667, nsentences=40, sample_size=109.667, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4455, wps=99.7, ups=0.43, wpb=109.7, bsz=40, num_updates=13880, lr=4.58426e-05, gnorm=0.377, clip=0, loss_scale=512, train_wall=23, gb_free=10.1, ema_decay=0.9999, wall=54274
2023-01-07 05:54:19 - progress_bar.py[line:274] - INFO: epoch 001:  13909 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4569, wps=102, ups=0.47, wpb=109.5, bsz=40, num_updates=13890, lr=4.58381e-05, gnorm=0.369, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54295
2023-01-07 05:54:41 - progress_bar.py[line:274] - INFO: epoch 001:  13919 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5238, wps=101.7, ups=0.47, wpb=108.6, bsz=40, num_updates=13900, lr=4.58336e-05, gnorm=0.448, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=54317
2023-01-07 05:55:03 - progress_bar.py[line:274] - INFO: epoch 001:  13929 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3781, wps=102.1, ups=0.46, wpb=110, bsz=40, num_updates=13910, lr=4.58291e-05, gnorm=0.512, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=54339
2023-01-07 05:55:24 - progress_bar.py[line:274] - INFO: epoch 001:  13939 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4925, wps=102, ups=0.47, wpb=109.4, bsz=40, num_updates=13920, lr=4.58246e-05, gnorm=0.491, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=54360
2023-01-07 05:55:46 - progress_bar.py[line:274] - INFO: epoch 001:  13949 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4121, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=13930, lr=4.58201e-05, gnorm=0.375, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54382
2023-01-07 05:56:08 - progress_bar.py[line:274] - INFO: epoch 001:  13959 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.401, wps=103.1, ups=0.47, wpb=109.6, bsz=40, num_updates=13940, lr=4.58156e-05, gnorm=0.311, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=54404
2023-01-07 05:56:29 - progress_bar.py[line:274] - INFO: epoch 001:  13969 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.467, wps=101.7, ups=0.47, wpb=108.2, bsz=40, num_updates=13950, lr=4.58112e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54425
2023-01-07 05:56:51 - progress_bar.py[line:274] - INFO: epoch 001:  13979 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4677, wps=104, ups=0.47, wpb=109.9, bsz=40, num_updates=13960, lr=4.58067e-05, gnorm=0.384, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=54447
2023-01-07 05:57:12 - progress_bar.py[line:274] - INFO: epoch 001:  13989 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4235, wps=101.8, ups=0.47, wpb=108.9, bsz=40, num_updates=13970, lr=4.58022e-05, gnorm=0.296, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54468
2023-01-07 05:57:34 - progress_bar.py[line:274] - INFO: epoch 001:  13999 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.48, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=13980, lr=4.57977e-05, gnorm=0.277, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=54490
2023-01-07 05:57:56 - progress_bar.py[line:274] - INFO: epoch 001:  14009 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4974, wps=103.2, ups=0.47, wpb=110, bsz=40, num_updates=13990, lr=4.57932e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=54512
2023-01-07 05:58:18 - progress_bar.py[line:274] - INFO: epoch 001:  14019 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.401, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=14000, lr=4.57887e-05, gnorm=0.328, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=54533
2023-01-07 05:58:18 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 05:58:19 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 05:58:19 - train.py[line:551] - INFO: load:0.97 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 06:00:51 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 06:00:51 - train.py[line:551] - INFO: load:1.00 valid_run:152.35 task_valid:147.92 collect_output:3.37
2023-01-07 06:03:20 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 06:03:20 - train.py[line:551] - INFO: load:1.02 valid_run:301.48 task_valid:290.66 collect_output:8.74
2023-01-07 06:05:54 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 06:05:54 - train.py[line:551] - INFO: load:1.05 valid_run:454.79 task_valid:433.38 collect_output:18.27
2023-01-07 06:08:24 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 06:08:24 - train.py[line:551] - INFO: load:1.08 valid_run:604.54 task_valid:577.94 collect_output:22.44
2023-01-07 06:10:56 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 06:10:56 - train.py[line:551] - INFO: load:1.10 valid_run:757.33 task_valid:725.08 collect_output:27.06
2023-01-07 06:13:29 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 06:13:29 - train.py[line:551] - INFO: load:1.13 valid_run:909.51 task_valid:870.15 collect_output:33.14
2023-01-07 06:16:03 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 06:16:03 - train.py[line:551] - INFO: load:1.16 valid_run:1063.81 task_valid:1015.75 collect_output:40.82
2023-01-07 06:18:36 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 06:18:36 - train.py[line:551] - INFO: load:1.18 valid_run:1216.17 task_valid:1156.31 collect_output:51.60
2023-01-07 06:21:06 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 06:21:06 - train.py[line:551] - INFO: load:1.21 valid_run:1366.22 task_valid:1300.68 collect_output:56.27
2023-01-07 06:23:35 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 06:23:35 - train.py[line:551] - INFO: load:1.23 valid_run:1515.24 task_valid:1443.36 collect_output:61.59
2023-01-07 06:26:05 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 06:26:05 - train.py[line:551] - INFO: load:1.26 valid_run:1665.16 task_valid:1587.74 collect_output:66.11
2023-01-07 06:28:36 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 06:28:36 - train.py[line:551] - INFO: load:1.29 valid_run:1815.87 task_valid:1732.27 collect_output:71.28
2023-01-07 06:31:06 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 06:31:06 - train.py[line:551] - INFO: load:1.31 valid_run:1966.67 task_valid:1873.53 collect_output:79.79
2023-01-07 06:33:37 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 06:33:37 - train.py[line:551] - INFO: load:1.34 valid_run:2117.51 task_valid:2018.58 collect_output:84.56
2023-01-07 06:36:08 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 06:36:08 - train.py[line:551] - INFO: load:1.36 valid_run:2267.69 task_valid:2164.73 collect_output:87.56
2023-01-07 06:38:38 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 06:38:38 - train.py[line:551] - INFO: load:1.39 valid_run:2418.23 task_valid:2308.79 collect_output:93.02
2023-01-07 06:41:11 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 06:41:11 - train.py[line:551] - INFO: load:1.42 valid_run:2570.77 task_valid:2453.89 collect_output:99.43
2023-01-07 06:43:42 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 06:43:42 - train.py[line:551] - INFO: load:1.44 valid_run:2721.51 task_valid:2600.42 collect_output:102.62
2023-01-07 06:46:11 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 06:46:11 - train.py[line:551] - INFO: load:1.47 valid_run:2870.53 task_valid:2741.42 collect_output:109.65
2023-01-07 06:48:42 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 06:48:42 - train.py[line:551] - INFO: load:1.50 valid_run:3021.50 task_valid:2886.36 collect_output:114.67
2023-01-07 06:51:15 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 06:51:15 - train.py[line:551] - INFO: load:1.52 valid_run:3174.31 task_valid:3030.48 collect_output:122.33
2023-01-07 06:53:44 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 06:53:44 - train.py[line:551] - INFO: load:1.55 valid_run:3323.99 task_valid:3174.58 collect_output:126.91
2023-01-07 06:56:16 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 06:56:16 - train.py[line:551] - INFO: load:1.58 valid_run:3475.63 task_valid:3320.35 collect_output:131.76
2023-01-07 06:58:48 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 06:58:48 - train.py[line:551] - INFO: load:1.61 valid_run:3627.40 task_valid:3466.58 collect_output:136.30

====================================================================================================
SGG eval:     R @ 50: 0.4296;     R @ 100: 0.5497;     R @ 500: 0.5921;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2621;    mR @ 100: 0.3619;    mR @ 500: 0.4070;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6829) (covered in:0.7500) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9375) (playing:0.0000) (riding:0.7245) (says:0.0000) (sitting on:0.6990) (standing on:0.1933) (using:0.6000) (walking in:0.0000) (walking on:0.4324) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4296;     R @ 100: 0.5497;     R @ 500: 0.5921;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2621;    mR @ 100: 0.3619;    mR @ 500: 0.4070;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6829) (covered in:0.7500) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9375) (playing:0.0000) (riding:0.7245) (says:0.0000) (sitting on:0.6990) (standing on:0.1933) (using:0.6000) (walking in:0.0000) (walking on:0.4324) (watching:0.2639) 
--------------------------------------------------------
====================================================================================================

2023-01-07 07:01:19 - train.py[line:487] - INFO: 0.549742857142857
2023-01-07 07:01:19 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 07:01:19 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.393 | loss_v1 0 | loss_v2 0 | nll_loss 0.238 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.549743 | ppl 1.18 | vqa_score 0.4966 | wps 118.7 | wpb 89.9 | bsz 30 | num_updates 14000 | best_R@100 0.641887
2023-01-07 07:01:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 14000 updates
2023-01-07 07:01:19 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_14000.pt
2023-01-07 07:02:00 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_14000.pt
2023-01-07 07:03:26 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_14000.pt (epoch 1 @ 14000 updates, score 0.549742857142857) (writing took 126.18736082874238 seconds)
2023-01-07 07:03:48 - progress_bar.py[line:274] - INFO: epoch 001:  14029 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4429, wps=0.5, ups=0, wpb=108, bsz=40, num_updates=14010, lr=4.57842e-05, gnorm=0.373, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=58463
2023-01-07 07:04:09 - progress_bar.py[line:274] - INFO: epoch 001:  14039 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4194, wps=103.2, ups=0.47, wpb=109.1, bsz=40, num_updates=14020, lr=4.57797e-05, gnorm=0.195, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=58485
2023-01-07 07:04:31 - progress_bar.py[line:274] - INFO: epoch 001:  14049 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4317, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=14030, lr=4.57752e-05, gnorm=0.459, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58507
2023-01-07 07:04:52 - progress_bar.py[line:274] - INFO: epoch 001:  14059 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4913, wps=103.4, ups=0.46, wpb=111.3, bsz=40, num_updates=14040, lr=4.57707e-05, gnorm=0.629, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58528
2023-01-07 07:05:14 - progress_bar.py[line:274] - INFO: epoch 001:  14069 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4098, wps=104.3, ups=0.48, wpb=109, bsz=40, num_updates=14050, lr=4.57662e-05, gnorm=0.363, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58549
2023-01-07 07:05:35 - progress_bar.py[line:274] - INFO: epoch 001:  14079 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4286, wps=102.4, ups=0.47, wpb=108.5, bsz=40, num_updates=14060, lr=4.57617e-05, gnorm=0.586, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58571
2023-01-07 07:05:56 - progress_bar.py[line:274] - INFO: epoch 001:  14089 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4055, wps=102.2, ups=0.48, wpb=107.1, bsz=40, num_updates=14070, lr=4.57572e-05, gnorm=0.431, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58592
2023-01-07 07:06:18 - progress_bar.py[line:274] - INFO: epoch 001:  14099 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4615, wps=103.9, ups=0.47, wpb=109.4, bsz=40, num_updates=14080, lr=4.57527e-05, gnorm=0.217, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=58613
2023-01-07 07:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  14109 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3835, wps=102.7, ups=0.47, wpb=109.3, bsz=40, num_updates=14090, lr=4.57482e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=58635
2023-01-07 07:07:01 - progress_bar.py[line:274] - INFO: epoch 001:  14119 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4309, wps=103.8, ups=0.47, wpb=111.6, bsz=40, num_updates=14100, lr=4.57437e-05, gnorm=0.385, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58657
2023-01-07 07:07:23 - progress_bar.py[line:274] - INFO: epoch 001:  14129 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4724, wps=99.4, ups=0.46, wpb=108.6, bsz=40, num_updates=14110, lr=4.57392e-05, gnorm=0.441, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58679
2023-01-07 07:07:45 - progress_bar.py[line:274] - INFO: epoch 001:  14139 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3895, wps=101, ups=0.46, wpb=109.5, bsz=40, num_updates=14120, lr=4.57347e-05, gnorm=0.555, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58701
2023-01-07 07:08:07 - progress_bar.py[line:274] - INFO: epoch 001:  14149 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.514, wps=101.5, ups=0.46, wpb=111.1, bsz=40, num_updates=14130, lr=4.57302e-05, gnorm=0.454, clip=20, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=58723
2023-01-07 07:08:29 - progress_bar.py[line:274] - INFO: epoch 001:  14159 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3931, wps=102.4, ups=0.46, wpb=111.6, bsz=40, num_updates=14140, lr=4.57257e-05, gnorm=0.369, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58745
2023-01-07 07:08:51 - progress_bar.py[line:274] - INFO: epoch 001:  14169 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4709, wps=101.1, ups=0.47, wpb=108, bsz=40, num_updates=14150, lr=4.57212e-05, gnorm=0.421, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=58766
2023-01-07 07:09:13 - progress_bar.py[line:274] - INFO: epoch 001:  14179 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3508, wps=102.4, ups=0.47, wpb=109.3, bsz=40, num_updates=14160, lr=4.57167e-05, gnorm=0.316, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=58788
2023-01-07 07:09:34 - progress_bar.py[line:274] - INFO: epoch 001:  14189 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4356, wps=105.8, ups=0.48, wpb=110.2, bsz=40, num_updates=14170, lr=4.57122e-05, gnorm=0.349, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=58810
2023-01-07 07:09:56 - progress_bar.py[line:274] - INFO: epoch 001:  14199 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4348, wps=101.9, ups=0.46, wpb=110.6, bsz=40, num_updates=14180, lr=4.57077e-05, gnorm=0.375, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58832
2023-01-07 07:10:18 - progress_bar.py[line:274] - INFO: epoch 001:  14209 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4039, wps=104, ups=0.47, wpb=109.5, bsz=40, num_updates=14190, lr=4.57033e-05, gnorm=0.325, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58853
2023-01-07 07:10:39 - progress_bar.py[line:274] - INFO: epoch 001:  14219 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.467, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=14200, lr=4.56988e-05, gnorm=0.315, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=58875
2023-01-07 07:11:01 - progress_bar.py[line:274] - INFO: epoch 001:  14229 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3568, wps=100.5, ups=0.46, wpb=109.1, bsz=40, num_updates=14210, lr=4.56943e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58897
2023-01-07 07:11:24 - progress_bar.py[line:274] - INFO: epoch 001:  14239 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4521, wps=97.6, ups=0.46, wpb=106.5, bsz=40, num_updates=14220, lr=4.56898e-05, gnorm=0.25, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=58919
2023-01-07 07:11:46 - progress_bar.py[line:274] - INFO: epoch 001:  14249 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4272, wps=99.7, ups=0.46, wpb=108.2, bsz=40, num_updates=14230, lr=4.56853e-05, gnorm=0.377, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58942
2023-01-07 07:12:07 - progress_bar.py[line:274] - INFO: epoch 001:  14259 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3819, wps=102.8, ups=0.47, wpb=108.7, bsz=40, num_updates=14240, lr=4.56808e-05, gnorm=0.421, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=58963
2023-01-07 07:12:30 - progress_bar.py[line:274] - INFO: epoch 001:  14269 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4061, wps=100.7, ups=0.46, wpb=108.9, bsz=40, num_updates=14250, lr=4.56763e-05, gnorm=0.275, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=58985
2023-01-07 07:12:52 - progress_bar.py[line:274] - INFO: epoch 001:  14279 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4091, wps=100.7, ups=0.46, wpb=109, bsz=40, num_updates=14260, lr=4.56718e-05, gnorm=0.265, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=59007
2023-01-07 07:13:13 - progress_bar.py[line:274] - INFO: epoch 001:  14289 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4778, wps=102.3, ups=0.47, wpb=108.2, bsz=40, num_updates=14270, lr=4.56673e-05, gnorm=0.317, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59029
2023-01-07 07:13:35 - progress_bar.py[line:274] - INFO: epoch 001:  14299 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4623, wps=102.7, ups=0.47, wpb=108.7, bsz=40, num_updates=14280, lr=4.56628e-05, gnorm=0.374, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=59050
2023-01-07 07:13:57 - progress_bar.py[line:274] - INFO: epoch 001:  14309 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3881, wps=100.8, ups=0.47, wpb=108.2, bsz=40, num_updates=14290, lr=4.56583e-05, gnorm=0.395, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59073
2023-01-07 07:14:19 - progress_bar.py[line:274] - INFO: epoch 001:  14319 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4309, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=14300, lr=4.56538e-05, gnorm=0.307, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59094
2023-01-07 07:14:40 - progress_bar.py[line:274] - INFO: epoch 001:  14329 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4213, wps=103.6, ups=0.47, wpb=109.5, bsz=40, num_updates=14310, lr=4.56493e-05, gnorm=0.296, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59116
2023-01-07 07:15:02 - progress_bar.py[line:274] - INFO: epoch 001:  14339 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4049, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=14320, lr=4.56448e-05, gnorm=0.329, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59138
2023-01-07 07:15:24 - progress_bar.py[line:274] - INFO: epoch 001:  14349 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.401, wps=103.4, ups=0.47, wpb=109.2, bsz=40, num_updates=14330, lr=4.56403e-05, gnorm=0.354, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59159
2023-01-07 07:15:46 - progress_bar.py[line:274] - INFO: epoch 001:  14359 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4833, wps=99.1, ups=0.46, wpb=108.6, bsz=40, num_updates=14340, lr=4.56358e-05, gnorm=0.294, clip=0, loss_scale=512, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=59182
2023-01-07 07:16:08 - progress_bar.py[line:274] - INFO: epoch 001:  14369 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4335, wps=103.5, ups=0.48, wpb=108.4, bsz=40, num_updates=14350, lr=4.56313e-05, gnorm=0.295, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59203
2023-01-07 07:16:30 - progress_bar.py[line:274] - INFO: epoch 001:  14379 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.46, wps=98.3, ups=0.45, wpb=108.9, bsz=40, num_updates=14360, lr=4.56268e-05, gnorm=0.277, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=59226
2023-01-07 07:16:52 - progress_bar.py[line:274] - INFO: epoch 001:  14389 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4703, wps=105.2, ups=0.48, wpb=109.5, bsz=40, num_updates=14370, lr=4.56223e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=59247
2023-01-07 07:17:14 - progress_bar.py[line:274] - INFO: epoch 001:  14399 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4422, wps=102.9, ups=0.47, wpb=108.9, bsz=40, num_updates=14380, lr=4.56178e-05, gnorm=0.556, clip=20, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59269
2023-01-07 07:17:35 - progress_bar.py[line:274] - INFO: epoch 001:  14409 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4554, wps=102.5, ups=0.47, wpb=108.3, bsz=40, num_updates=14390, lr=4.56133e-05, gnorm=0.293, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59291
2023-01-07 07:17:57 - progress_bar.py[line:274] - INFO: epoch 001:  14419 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4641, wps=102.1, ups=0.46, wpb=110.5, bsz=40, num_updates=14400, lr=4.56088e-05, gnorm=0.384, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=59313
2023-01-07 07:18:20 - progress_bar.py[line:274] - INFO: epoch 001:  14429 / 115845 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4279, wps=98.9, ups=0.46, wpb=107.6, bsz=40, num_updates=14410, lr=4.56043e-05, gnorm=0.577, clip=10, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=59335
2023-01-07 07:18:41 - progress_bar.py[line:274] - INFO: epoch 001:  14439 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4091, wps=101.4, ups=0.47, wpb=108.3, bsz=40, num_updates=14420, lr=4.55998e-05, gnorm=0.298, clip=0, loss_scale=1024, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=59357
2023-01-07 07:19:03 - progress_bar.py[line:274] - INFO: epoch 001:  14449 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4175, wps=101.5, ups=0.46, wpb=109.6, bsz=40, num_updates=14430, lr=4.55953e-05, gnorm=0.243, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59379
2023-01-07 07:19:25 - progress_bar.py[line:274] - INFO: epoch 001:  14459 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4144, wps=101.6, ups=0.47, wpb=108.2, bsz=40, num_updates=14440, lr=4.55909e-05, gnorm=0.472, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59401
2023-01-07 07:19:47 - progress_bar.py[line:274] - INFO: epoch 001:  14469 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4831, wps=100.2, ups=0.46, wpb=108.3, bsz=40, num_updates=14450, lr=4.55864e-05, gnorm=0.482, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59423
2023-01-07 07:20:10 - progress_bar.py[line:274] - INFO: epoch 001:  14479 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5052, wps=100.4, ups=0.46, wpb=109.9, bsz=40, num_updates=14460, lr=4.55819e-05, gnorm=0.379, clip=10, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=59445
2023-01-07 07:20:32 - progress_bar.py[line:274] - INFO: epoch 001:  14489 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4485, wps=101.6, ups=0.46, wpb=109.5, bsz=40, num_updates=14470, lr=4.55774e-05, gnorm=0.345, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59467
2023-01-07 07:20:54 - progress_bar.py[line:274] - INFO: epoch 001:  14499 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4263, wps=101.6, ups=0.46, wpb=110.3, bsz=40, num_updates=14480, lr=4.55729e-05, gnorm=0.359, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=59489
2023-01-07 07:21:15 - progress_bar.py[line:274] - INFO: epoch 001:  14509 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4754, wps=103.5, ups=0.47, wpb=110, bsz=40, num_updates=14490, lr=4.55684e-05, gnorm=0.295, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59511
2023-01-07 07:21:37 - progress_bar.py[line:274] - INFO: epoch 001:  14519 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4498, wps=101, ups=0.47, wpb=108, bsz=40, num_updates=14500, lr=4.55639e-05, gnorm=0.434, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=59533
2023-01-07 07:21:59 - progress_bar.py[line:274] - INFO: epoch 001:  14529 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.474, wps=101.8, ups=0.46, wpb=109.6, bsz=40, num_updates=14510, lr=4.55594e-05, gnorm=0.403, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59555
2023-01-07 07:22:21 - progress_bar.py[line:274] - INFO: epoch 001:  14539 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4555, wps=101.4, ups=0.47, wpb=108.8, bsz=40, num_updates=14520, lr=4.55549e-05, gnorm=0.401, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59577
2023-01-07 07:22:43 - progress_bar.py[line:274] - INFO: epoch 001:  14549 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3952, wps=101.2, ups=0.47, wpb=108.7, bsz=40, num_updates=14530, lr=4.55504e-05, gnorm=0.34, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59599
2023-01-07 07:23:05 - progress_bar.py[line:274] - INFO: epoch 001:  14559 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4588, wps=103.5, ups=0.47, wpb=109.3, bsz=40, num_updates=14540, lr=4.55459e-05, gnorm=0.382, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59620
2023-01-07 07:23:27 - progress_bar.py[line:274] - INFO: epoch 001:  14569 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4313, wps=102.8, ups=0.47, wpb=110, bsz=40, num_updates=14550, lr=4.55414e-05, gnorm=0.241, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59642
2023-01-07 07:23:48 - progress_bar.py[line:274] - INFO: epoch 001:  14579 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4412, wps=103.3, ups=0.47, wpb=109.1, bsz=40, num_updates=14560, lr=4.55369e-05, gnorm=0.393, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=59664
2023-01-07 07:24:10 - progress_bar.py[line:274] - INFO: epoch 001:  14589 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4483, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=14570, lr=4.55324e-05, gnorm=0.365, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59686
2023-01-07 07:24:12 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 07:24:34 - progress_bar.py[line:274] - INFO: epoch 001:  14600 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.381, nsentences=40, sample_size=109.381, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4692, wps=98.7, ups=0.43, wpb=109.4, bsz=40, num_updates=14580, lr=4.55279e-05, gnorm=0.514, clip=20, loss_scale=512, train_wall=23, gb_free=10, ema_decay=0.9999, wall=59709
2023-01-07 07:24:56 - progress_bar.py[line:274] - INFO: epoch 001:  14610 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4564, wps=99.8, ups=0.46, wpb=108.9, bsz=40, num_updates=14590, lr=4.55234e-05, gnorm=0.302, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59732
2023-01-07 07:25:17 - progress_bar.py[line:274] - INFO: epoch 001:  14620 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4066, wps=106.5, ups=0.48, wpb=110.3, bsz=40, num_updates=14600, lr=4.55189e-05, gnorm=0.294, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59753
2023-01-07 07:25:39 - progress_bar.py[line:274] - INFO: epoch 001:  14630 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4898, wps=102.2, ups=0.47, wpb=108.8, bsz=40, num_updates=14610, lr=4.55144e-05, gnorm=0.301, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=59775
2023-01-07 07:26:01 - progress_bar.py[line:274] - INFO: epoch 001:  14640 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4239, wps=100.7, ups=0.46, wpb=110.5, bsz=40, num_updates=14620, lr=4.55099e-05, gnorm=0.389, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59797
2023-01-07 07:26:23 - progress_bar.py[line:274] - INFO: epoch 001:  14650 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4211, wps=101.2, ups=0.46, wpb=109.1, bsz=40, num_updates=14630, lr=4.55054e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=59819
2023-01-07 07:26:45 - progress_bar.py[line:274] - INFO: epoch 001:  14660 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4271, wps=100.6, ups=0.46, wpb=109.5, bsz=40, num_updates=14640, lr=4.55009e-05, gnorm=0.246, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=59841
2023-01-07 07:27:07 - progress_bar.py[line:274] - INFO: epoch 001:  14670 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5493, wps=103.7, ups=0.47, wpb=109.2, bsz=40, num_updates=14650, lr=4.54964e-05, gnorm=0.374, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59863
2023-01-07 07:27:29 - progress_bar.py[line:274] - INFO: epoch 001:  14680 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5191, wps=103.6, ups=0.47, wpb=109.8, bsz=40, num_updates=14660, lr=4.54919e-05, gnorm=0.264, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=59884
2023-01-07 07:27:50 - progress_bar.py[line:274] - INFO: epoch 001:  14690 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4581, wps=103.7, ups=0.47, wpb=109.4, bsz=40, num_updates=14670, lr=4.54874e-05, gnorm=0.325, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=59906
2023-01-07 07:28:13 - progress_bar.py[line:274] - INFO: epoch 001:  14700 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4313, wps=99.9, ups=0.46, wpb=109.5, bsz=40, num_updates=14680, lr=4.5483e-05, gnorm=0.314, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=59928
2023-01-07 07:28:35 - progress_bar.py[line:274] - INFO: epoch 001:  14710 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4179, wps=99.9, ups=0.46, wpb=108.1, bsz=40, num_updates=14690, lr=4.54785e-05, gnorm=0.335, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=59950
2023-01-07 07:28:57 - progress_bar.py[line:274] - INFO: epoch 001:  14720 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4091, wps=100.6, ups=0.46, wpb=108.4, bsz=40, num_updates=14700, lr=4.5474e-05, gnorm=0.381, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=59972
2023-01-07 07:29:19 - progress_bar.py[line:274] - INFO: epoch 001:  14730 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4925, wps=103, ups=0.47, wpb=110.7, bsz=40, num_updates=14710, lr=4.54695e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=59994
2023-01-07 07:29:41 - progress_bar.py[line:274] - INFO: epoch 001:  14740 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4118, wps=102.2, ups=0.46, wpb=110.9, bsz=40, num_updates=14720, lr=4.5465e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60017
2023-01-07 07:30:03 - progress_bar.py[line:274] - INFO: epoch 001:  14750 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4975, wps=100.5, ups=0.46, wpb=109.3, bsz=40, num_updates=14730, lr=4.54605e-05, gnorm=0.344, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60039
2023-01-07 07:30:25 - progress_bar.py[line:274] - INFO: epoch 001:  14760 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4155, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=14740, lr=4.5456e-05, gnorm=0.372, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60061
2023-01-07 07:30:47 - progress_bar.py[line:274] - INFO: epoch 001:  14770 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4216, wps=106, ups=0.48, wpb=111.5, bsz=40, num_updates=14750, lr=4.54515e-05, gnorm=0.47, clip=20, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=60082
2023-01-07 07:31:08 - progress_bar.py[line:274] - INFO: epoch 001:  14780 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4253, wps=103.7, ups=0.47, wpb=110.1, bsz=40, num_updates=14760, lr=4.5447e-05, gnorm=0.303, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60104
2023-01-07 07:31:30 - progress_bar.py[line:274] - INFO: epoch 001:  14790 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4586, wps=102.2, ups=0.46, wpb=110.3, bsz=40, num_updates=14770, lr=4.54425e-05, gnorm=0.442, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=60126
2023-01-07 07:31:52 - progress_bar.py[line:274] - INFO: epoch 001:  14800 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3807, wps=103.5, ups=0.47, wpb=109.6, bsz=40, num_updates=14780, lr=4.5438e-05, gnorm=0.287, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=60148
2023-01-07 07:32:14 - progress_bar.py[line:274] - INFO: epoch 001:  14810 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4375, wps=100.5, ups=0.46, wpb=108.9, bsz=40, num_updates=14790, lr=4.54335e-05, gnorm=0.36, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60170
2023-01-07 07:32:36 - progress_bar.py[line:274] - INFO: epoch 001:  14820 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4596, wps=102.1, ups=0.47, wpb=109.6, bsz=40, num_updates=14800, lr=4.5429e-05, gnorm=0.365, clip=10, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=60192
2023-01-07 07:32:58 - progress_bar.py[line:274] - INFO: epoch 001:  14830 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4385, wps=103.4, ups=0.47, wpb=110.1, bsz=40, num_updates=14810, lr=4.54245e-05, gnorm=0.322, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=60213
2023-01-07 07:33:20 - progress_bar.py[line:274] - INFO: epoch 001:  14840 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4372, wps=100.4, ups=0.46, wpb=108.8, bsz=40, num_updates=14820, lr=4.542e-05, gnorm=0.337, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60235
2023-01-07 07:33:42 - progress_bar.py[line:274] - INFO: epoch 001:  14850 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.414, wps=101.4, ups=0.47, wpb=108.7, bsz=40, num_updates=14830, lr=4.54155e-05, gnorm=0.429, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=60257
2023-01-07 07:34:03 - progress_bar.py[line:274] - INFO: epoch 001:  14860 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4335, wps=103.3, ups=0.48, wpb=108.2, bsz=40, num_updates=14840, lr=4.5411e-05, gnorm=0.414, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60279
2023-01-07 07:34:25 - progress_bar.py[line:274] - INFO: epoch 001:  14870 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3934, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=14850, lr=4.54065e-05, gnorm=0.384, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=60301
2023-01-07 07:34:46 - progress_bar.py[line:274] - INFO: epoch 001:  14880 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=103.9, ups=0.48, wpb=108.9, bsz=40, num_updates=14860, lr=4.5402e-05, gnorm=0.351, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60322
2023-01-07 07:35:04 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 07:35:11 - progress_bar.py[line:274] - INFO: epoch 001:  14891 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.095, nsentences=40, sample_size=108.095, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4477, wps=95.9, ups=0.42, wpb=108.1, bsz=40, num_updates=14870, lr=4.53975e-05, gnorm=0.281, clip=0, loss_scale=256, train_wall=24, gb_free=10.1, ema_decay=0.9999, wall=60346
2023-01-07 07:35:32 - progress_bar.py[line:274] - INFO: epoch 001:  14901 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4709, wps=102.3, ups=0.47, wpb=109.1, bsz=40, num_updates=14880, lr=4.5393e-05, gnorm=0.374, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60368
2023-01-07 07:35:54 - progress_bar.py[line:274] - INFO: epoch 001:  14911 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4608, wps=100, ups=0.46, wpb=108.2, bsz=40, num_updates=14890, lr=4.53885e-05, gnorm=0.581, clip=10, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=60390
2023-01-07 07:36:16 - progress_bar.py[line:274] - INFO: epoch 001:  14921 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4301, wps=101, ups=0.46, wpb=109.7, bsz=40, num_updates=14900, lr=4.5384e-05, gnorm=0.371, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=60412
2023-01-07 07:36:38 - progress_bar.py[line:274] - INFO: epoch 001:  14931 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4575, wps=100.3, ups=0.46, wpb=108, bsz=40, num_updates=14910, lr=4.53795e-05, gnorm=0.444, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60434
2023-01-07 07:36:59 - progress_bar.py[line:274] - INFO: epoch 001:  14941 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5056, wps=102.2, ups=0.46, wpb=110.1, bsz=40, num_updates=14920, lr=4.5375e-05, gnorm=0.357, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60455
2023-01-07 07:37:21 - progress_bar.py[line:274] - INFO: epoch 001:  14951 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4749, wps=103.6, ups=0.47, wpb=110.3, bsz=40, num_updates=14930, lr=4.53706e-05, gnorm=0.461, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60477
2023-01-07 07:37:43 - progress_bar.py[line:274] - INFO: epoch 001:  14961 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4632, wps=99.7, ups=0.46, wpb=109.4, bsz=40, num_updates=14940, lr=4.53661e-05, gnorm=0.389, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=60499
2023-01-07 07:38:05 - progress_bar.py[line:274] - INFO: epoch 001:  14971 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4554, wps=102.5, ups=0.47, wpb=109.1, bsz=40, num_updates=14950, lr=4.53616e-05, gnorm=0.432, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60520
2023-01-07 07:38:26 - progress_bar.py[line:274] - INFO: epoch 001:  14981 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3775, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=14960, lr=4.53571e-05, gnorm=0.535, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60542
2023-01-07 07:38:48 - progress_bar.py[line:274] - INFO: epoch 001:  14991 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.453, wps=101.7, ups=0.46, wpb=110.2, bsz=40, num_updates=14970, lr=4.53526e-05, gnorm=0.416, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60564
2023-01-07 07:39:10 - progress_bar.py[line:274] - INFO: epoch 001:  15001 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3668, wps=101.5, ups=0.47, wpb=108.2, bsz=40, num_updates=14980, lr=4.53481e-05, gnorm=0.323, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60586
2023-01-07 07:39:31 - progress_bar.py[line:274] - INFO: epoch 001:  15011 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3695, wps=102.4, ups=0.47, wpb=108.7, bsz=40, num_updates=14990, lr=4.53436e-05, gnorm=0.288, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60607
2023-01-07 07:39:53 - progress_bar.py[line:274] - INFO: epoch 001:  15021 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4444, wps=100.4, ups=0.46, wpb=108.3, bsz=40, num_updates=15000, lr=4.53391e-05, gnorm=0.312, clip=0, loss_scale=256, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=60629
2023-01-07 07:40:15 - progress_bar.py[line:274] - INFO: epoch 001:  15031 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5118, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=15010, lr=4.53346e-05, gnorm=0.545, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=60651
2023-01-07 07:40:37 - progress_bar.py[line:274] - INFO: epoch 001:  15041 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.456, wps=100.4, ups=0.46, wpb=109.2, bsz=40, num_updates=15020, lr=4.53301e-05, gnorm=0.275, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60673
2023-01-07 07:40:59 - progress_bar.py[line:274] - INFO: epoch 001:  15051 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4876, wps=101.7, ups=0.46, wpb=109.7, bsz=40, num_updates=15030, lr=4.53256e-05, gnorm=1.707, clip=10, loss_scale=256, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=60695
2023-01-07 07:41:21 - progress_bar.py[line:274] - INFO: epoch 001:  15061 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4639, wps=103.5, ups=0.47, wpb=110.6, bsz=40, num_updates=15040, lr=4.53211e-05, gnorm=0.299, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=60717
2023-01-07 07:41:43 - progress_bar.py[line:274] - INFO: epoch 001:  15071 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4208, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=15050, lr=4.53166e-05, gnorm=0.46, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60739
2023-01-07 07:42:05 - progress_bar.py[line:274] - INFO: epoch 001:  15081 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4192, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=15060, lr=4.53121e-05, gnorm=0.377, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60761
2023-01-07 07:42:27 - progress_bar.py[line:274] - INFO: epoch 001:  15091 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4279, wps=102.2, ups=0.47, wpb=108.4, bsz=40, num_updates=15070, lr=4.53076e-05, gnorm=0.313, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60783
2023-01-07 07:42:49 - progress_bar.py[line:274] - INFO: epoch 001:  15101 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3909, wps=102.2, ups=0.47, wpb=108.9, bsz=40, num_updates=15080, lr=4.53031e-05, gnorm=0.466, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=60805
2023-01-07 07:43:11 - progress_bar.py[line:274] - INFO: epoch 001:  15111 / 115845 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4354, wps=101.1, ups=0.47, wpb=107.8, bsz=40, num_updates=15090, lr=4.52986e-05, gnorm=0.412, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=60826
2023-01-07 07:43:33 - progress_bar.py[line:274] - INFO: epoch 001:  15121 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4888, wps=104.1, ups=0.47, wpb=109.8, bsz=40, num_updates=15100, lr=4.52941e-05, gnorm=0.251, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=60848
2023-01-07 07:43:54 - progress_bar.py[line:274] - INFO: epoch 001:  15131 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4774, wps=102.4, ups=0.47, wpb=109.3, bsz=40, num_updates=15110, lr=4.52896e-05, gnorm=0.343, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=60870
2023-01-07 07:44:16 - progress_bar.py[line:274] - INFO: epoch 001:  15141 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5054, wps=103.2, ups=0.47, wpb=109.1, bsz=40, num_updates=15120, lr=4.52851e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60892
2023-01-07 07:44:38 - progress_bar.py[line:274] - INFO: epoch 001:  15151 / 115845 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3645, wps=100.3, ups=0.46, wpb=108, bsz=40, num_updates=15130, lr=4.52806e-05, gnorm=0.382, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60914
2023-01-07 07:45:01 - progress_bar.py[line:274] - INFO: epoch 001:  15161 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4747, wps=100, ups=0.46, wpb=109.8, bsz=40, num_updates=15140, lr=4.52761e-05, gnorm=0.332, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=60936
2023-01-07 07:45:23 - progress_bar.py[line:274] - INFO: epoch 001:  15171 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4485, wps=101.8, ups=0.46, wpb=109.8, bsz=40, num_updates=15150, lr=4.52716e-05, gnorm=0.277, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=60958
2023-01-07 07:45:45 - progress_bar.py[line:274] - INFO: epoch 001:  15181 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4716, wps=102.8, ups=0.47, wpb=109.5, bsz=40, num_updates=15160, lr=4.52671e-05, gnorm=0.384, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=60980
2023-01-07 07:46:07 - progress_bar.py[line:274] - INFO: epoch 001:  15191 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4206, wps=98.9, ups=0.46, wpb=106.5, bsz=40, num_updates=15170, lr=4.52627e-05, gnorm=0.386, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61003
2023-01-07 07:46:29 - progress_bar.py[line:274] - INFO: epoch 001:  15201 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.484, wps=101.8, ups=0.46, wpb=110.7, bsz=40, num_updates=15180, lr=4.52582e-05, gnorm=0.288, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=61025
2023-01-07 07:46:52 - progress_bar.py[line:274] - INFO: epoch 001:  15211 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4272, wps=100.4, ups=0.46, wpb=109.3, bsz=40, num_updates=15190, lr=4.52537e-05, gnorm=0.255, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61047
2023-01-07 07:47:14 - progress_bar.py[line:274] - INFO: epoch 001:  15221 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4455, wps=102.9, ups=0.47, wpb=108.9, bsz=40, num_updates=15200, lr=4.52492e-05, gnorm=0.395, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61069
2023-01-07 07:47:35 - progress_bar.py[line:274] - INFO: epoch 001:  15231 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4022, wps=102.5, ups=0.47, wpb=109.5, bsz=40, num_updates=15210, lr=4.52447e-05, gnorm=0.252, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61091
2023-01-07 07:47:58 - progress_bar.py[line:274] - INFO: epoch 001:  15241 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.46, wps=101.1, ups=0.46, wpb=108.9, bsz=40, num_updates=15220, lr=4.52402e-05, gnorm=0.199, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=61113
2023-01-07 07:48:20 - progress_bar.py[line:274] - INFO: epoch 001:  15251 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4815, wps=101, ups=0.46, wpb=109.8, bsz=40, num_updates=15230, lr=4.52357e-05, gnorm=0.194, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61135
2023-01-07 07:48:42 - progress_bar.py[line:274] - INFO: epoch 001:  15261 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5291, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=15240, lr=4.52312e-05, gnorm=0.351, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61157
2023-01-07 07:49:03 - progress_bar.py[line:274] - INFO: epoch 001:  15271 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4466, wps=102.6, ups=0.47, wpb=108.5, bsz=40, num_updates=15250, lr=4.52267e-05, gnorm=0.296, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61179
2023-01-07 07:49:25 - progress_bar.py[line:274] - INFO: epoch 001:  15281 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4369, wps=102.5, ups=0.47, wpb=109.1, bsz=40, num_updates=15260, lr=4.52222e-05, gnorm=0.288, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61201
2023-01-07 07:49:47 - progress_bar.py[line:274] - INFO: epoch 001:  15291 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.456, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=15270, lr=4.52177e-05, gnorm=0.264, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61223
2023-01-07 07:50:10 - progress_bar.py[line:274] - INFO: epoch 001:  15301 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4615, wps=100, ups=0.46, wpb=108.4, bsz=40, num_updates=15280, lr=4.52132e-05, gnorm=0.269, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61245
2023-01-07 07:50:32 - progress_bar.py[line:274] - INFO: epoch 001:  15311 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.505, wps=101.1, ups=0.46, wpb=109.4, bsz=40, num_updates=15290, lr=4.52087e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61267
2023-01-07 07:50:54 - progress_bar.py[line:274] - INFO: epoch 001:  15321 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3958, wps=100.3, ups=0.46, wpb=108.8, bsz=40, num_updates=15300, lr=4.52042e-05, gnorm=0.247, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61290
2023-01-07 07:51:16 - progress_bar.py[line:274] - INFO: epoch 001:  15331 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4045, wps=101.2, ups=0.46, wpb=109.2, bsz=40, num_updates=15310, lr=4.51997e-05, gnorm=0.448, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61312
2023-01-07 07:51:39 - progress_bar.py[line:274] - INFO: epoch 001:  15341 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.445, wps=100.5, ups=0.46, wpb=109.5, bsz=40, num_updates=15320, lr=4.51952e-05, gnorm=0.398, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61334
2023-01-07 07:52:00 - progress_bar.py[line:274] - INFO: epoch 001:  15351 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4021, wps=103.3, ups=0.47, wpb=110.1, bsz=40, num_updates=15330, lr=4.51907e-05, gnorm=0.486, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=61356
2023-01-07 07:52:23 - progress_bar.py[line:274] - INFO: epoch 001:  15361 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4794, wps=100.4, ups=0.46, wpb=109.5, bsz=40, num_updates=15340, lr=4.51862e-05, gnorm=0.271, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=61378
2023-01-07 07:52:46 - progress_bar.py[line:274] - INFO: epoch 001:  15371 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4158, wps=98.3, ups=0.45, wpb=108.1, bsz=40, num_updates=15350, lr=4.51817e-05, gnorm=0.311, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61401
2023-01-07 07:53:08 - progress_bar.py[line:274] - INFO: epoch 001:  15381 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4474, wps=102.6, ups=0.47, wpb=109.9, bsz=40, num_updates=15360, lr=4.51772e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61423
2023-01-07 07:53:29 - progress_bar.py[line:274] - INFO: epoch 001:  15391 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4536, wps=103.9, ups=0.47, wpb=110.7, bsz=40, num_updates=15370, lr=4.51727e-05, gnorm=0.261, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=61445
2023-01-07 07:53:51 - progress_bar.py[line:274] - INFO: epoch 001:  15401 / 115845 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4585, wps=103.1, ups=0.48, wpb=108.2, bsz=40, num_updates=15380, lr=4.51682e-05, gnorm=0.425, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=61467
2023-01-07 07:54:13 - progress_bar.py[line:274] - INFO: epoch 001:  15411 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3821, wps=103, ups=0.47, wpb=109, bsz=40, num_updates=15390, lr=4.51637e-05, gnorm=0.304, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61488
2023-01-07 07:54:35 - progress_bar.py[line:274] - INFO: epoch 001:  15421 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3726, wps=102.1, ups=0.47, wpb=107.8, bsz=40, num_updates=15400, lr=4.51592e-05, gnorm=0.274, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=61510
2023-01-07 07:54:57 - progress_bar.py[line:274] - INFO: epoch 001:  15431 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3671, wps=100.3, ups=0.46, wpb=108, bsz=40, num_updates=15410, lr=4.51547e-05, gnorm=0.304, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61532
2023-01-07 07:55:19 - progress_bar.py[line:274] - INFO: epoch 001:  15441 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4316, wps=101.7, ups=0.46, wpb=109.6, bsz=40, num_updates=15420, lr=4.51503e-05, gnorm=0.35, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61554
2023-01-07 07:55:41 - progress_bar.py[line:274] - INFO: epoch 001:  15451 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4848, wps=101.5, ups=0.46, wpb=110.3, bsz=40, num_updates=15430, lr=4.51458e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61577
2023-01-07 07:56:03 - progress_bar.py[line:274] - INFO: epoch 001:  15461 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4292, wps=102.5, ups=0.48, wpb=107.2, bsz=40, num_updates=15440, lr=4.51413e-05, gnorm=0.405, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61598
2023-01-07 07:56:25 - progress_bar.py[line:274] - INFO: epoch 001:  15471 / 115845 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4422, wps=100.2, ups=0.46, wpb=108.2, bsz=40, num_updates=15450, lr=4.51368e-05, gnorm=0.337, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61620
2023-01-07 07:56:47 - progress_bar.py[line:274] - INFO: epoch 001:  15481 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5222, wps=101.2, ups=0.47, wpb=108.4, bsz=40, num_updates=15460, lr=4.51323e-05, gnorm=0.273, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61642
2023-01-07 07:57:08 - progress_bar.py[line:274] - INFO: epoch 001:  15491 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.457, wps=103.4, ups=0.48, wpb=108.7, bsz=40, num_updates=15470, lr=4.51278e-05, gnorm=0.394, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61664
2023-01-07 07:57:31 - progress_bar.py[line:274] - INFO: epoch 001:  15501 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4136, wps=102.6, ups=0.47, wpb=110, bsz=40, num_updates=15480, lr=4.51233e-05, gnorm=0.504, clip=20, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=61686
2023-01-07 07:57:53 - progress_bar.py[line:274] - INFO: epoch 001:  15511 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4292, wps=99.4, ups=0.45, wpb=109.3, bsz=40, num_updates=15490, lr=4.51188e-05, gnorm=0.316, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61709
2023-01-07 07:58:15 - progress_bar.py[line:274] - INFO: epoch 001:  15521 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4433, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=15500, lr=4.51143e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=61731
2023-01-07 07:58:37 - progress_bar.py[line:274] - INFO: epoch 001:  15531 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.45, wps=101.5, ups=0.46, wpb=110.1, bsz=40, num_updates=15510, lr=4.51098e-05, gnorm=0.26, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61753
2023-01-07 07:58:59 - progress_bar.py[line:274] - INFO: epoch 001:  15541 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4389, wps=102.7, ups=0.47, wpb=110.3, bsz=40, num_updates=15520, lr=4.51053e-05, gnorm=0.381, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=61775
2023-01-07 07:59:21 - progress_bar.py[line:274] - INFO: epoch 001:  15551 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4523, wps=101.8, ups=0.47, wpb=109.4, bsz=40, num_updates=15530, lr=4.51008e-05, gnorm=0.33, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61797
2023-01-07 07:59:43 - progress_bar.py[line:274] - INFO: epoch 001:  15561 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4502, wps=99.6, ups=0.46, wpb=108.3, bsz=40, num_updates=15540, lr=4.50963e-05, gnorm=0.444, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=61819
2023-01-07 08:00:04 - progress_bar.py[line:274] - INFO: epoch 001:  15571 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.445, wps=102.4, ups=0.47, wpb=110.1, bsz=40, num_updates=15550, lr=4.50918e-05, gnorm=0.354, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61840
2023-01-07 08:00:26 - progress_bar.py[line:274] - INFO: epoch 001:  15581 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4455, wps=102, ups=0.47, wpb=108.1, bsz=40, num_updates=15560, lr=4.50873e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=61862
2023-01-07 08:00:47 - progress_bar.py[line:274] - INFO: epoch 001:  15591 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4726, wps=101.9, ups=0.46, wpb=109.6, bsz=40, num_updates=15570, lr=4.50828e-05, gnorm=0.345, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=61883
2023-01-07 08:01:10 - progress_bar.py[line:274] - INFO: epoch 001:  15601 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.453, wps=99.3, ups=0.45, wpb=109.2, bsz=40, num_updates=15580, lr=4.50783e-05, gnorm=0.347, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61906
2023-01-07 08:01:32 - progress_bar.py[line:274] - INFO: epoch 001:  15611 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3774, wps=100, ups=0.46, wpb=108.1, bsz=40, num_updates=15590, lr=4.50738e-05, gnorm=0.436, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=61927
2023-01-07 08:01:53 - progress_bar.py[line:274] - INFO: epoch 001:  15621 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4976, wps=102.4, ups=0.47, wpb=108.6, bsz=40, num_updates=15600, lr=4.50693e-05, gnorm=0.377, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=61949
2023-01-07 08:02:15 - progress_bar.py[line:274] - INFO: epoch 001:  15631 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3947, wps=99.7, ups=0.46, wpb=109.1, bsz=40, num_updates=15610, lr=4.50648e-05, gnorm=0.241, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=61971
2023-01-07 08:02:17 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 08:02:39 - progress_bar.py[line:274] - INFO: epoch 001:  15642 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.762, nsentences=40, sample_size=108.762, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4459, wps=97.5, ups=0.43, wpb=108.8, bsz=40, num_updates=15620, lr=4.50603e-05, gnorm=0.332, clip=0, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=61995
2023-01-07 08:03:01 - progress_bar.py[line:274] - INFO: epoch 001:  15652 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4486, wps=102.5, ups=0.46, wpb=111, bsz=40, num_updates=15630, lr=4.50558e-05, gnorm=0.271, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62017
2023-01-07 08:03:22 - progress_bar.py[line:274] - INFO: epoch 001:  15662 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4873, wps=101.3, ups=0.46, wpb=109.5, bsz=40, num_updates=15640, lr=4.50513e-05, gnorm=0.39, clip=0, loss_scale=256, train_wall=22, gb_free=9.6, ema_decay=0.9999, wall=62038
2023-01-07 08:03:44 - progress_bar.py[line:274] - INFO: epoch 001:  15672 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.487, wps=103.1, ups=0.47, wpb=109.4, bsz=40, num_updates=15650, lr=4.50468e-05, gnorm=0.329, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62060
2023-01-07 08:04:06 - progress_bar.py[line:274] - INFO: epoch 001:  15682 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.49, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=15660, lr=4.50424e-05, gnorm=0.286, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62082
2023-01-07 08:04:28 - progress_bar.py[line:274] - INFO: epoch 001:  15692 / 115845 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.4611, wps=102.9, ups=0.46, wpb=111.8, bsz=40, num_updates=15670, lr=4.50379e-05, gnorm=0.46, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62103
2023-01-07 08:04:50 - progress_bar.py[line:274] - INFO: epoch 001:  15702 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4559, wps=101, ups=0.46, wpb=110.1, bsz=40, num_updates=15680, lr=4.50334e-05, gnorm=0.255, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=62126
2023-01-07 08:05:11 - progress_bar.py[line:274] - INFO: epoch 001:  15712 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4718, wps=102.4, ups=0.47, wpb=109.3, bsz=40, num_updates=15690, lr=4.50289e-05, gnorm=0.318, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=62147
2023-01-07 08:05:33 - progress_bar.py[line:274] - INFO: epoch 001:  15722 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4597, wps=99, ups=0.46, wpb=108, bsz=40, num_updates=15700, lr=4.50244e-05, gnorm=0.369, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=62169
2023-01-07 08:05:55 - progress_bar.py[line:274] - INFO: epoch 001:  15732 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4465, wps=99.5, ups=0.46, wpb=108.2, bsz=40, num_updates=15710, lr=4.50199e-05, gnorm=0.272, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62191
2023-01-07 08:06:17 - progress_bar.py[line:274] - INFO: epoch 001:  15742 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4921, wps=102.3, ups=0.47, wpb=109.4, bsz=40, num_updates=15720, lr=4.50154e-05, gnorm=0.273, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=62213
2023-01-07 08:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  15752 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4817, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=15730, lr=4.50109e-05, gnorm=0.282, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62235
2023-01-07 08:07:01 - progress_bar.py[line:274] - INFO: epoch 001:  15762 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4603, wps=100.4, ups=0.46, wpb=108.6, bsz=40, num_updates=15740, lr=4.50064e-05, gnorm=0.319, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=62257
2023-01-07 08:07:22 - progress_bar.py[line:274] - INFO: epoch 001:  15772 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.403, wps=102.7, ups=0.47, wpb=108.9, bsz=40, num_updates=15750, lr=4.50019e-05, gnorm=0.472, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=62278
2023-01-07 08:07:44 - progress_bar.py[line:274] - INFO: epoch 001:  15782 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4667, wps=102.7, ups=0.47, wpb=109.6, bsz=40, num_updates=15760, lr=4.49974e-05, gnorm=0.34, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62300
2023-01-07 08:08:06 - progress_bar.py[line:274] - INFO: epoch 001:  15792 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.466, wps=100.1, ups=0.46, wpb=108.9, bsz=40, num_updates=15770, lr=4.49929e-05, gnorm=0.315, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=62322
2023-01-07 08:08:28 - progress_bar.py[line:274] - INFO: epoch 001:  15802 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4118, wps=99.8, ups=0.46, wpb=108.7, bsz=40, num_updates=15780, lr=4.49884e-05, gnorm=0.305, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62344
2023-01-07 08:08:49 - progress_bar.py[line:274] - INFO: epoch 001:  15812 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4974, wps=103.3, ups=0.47, wpb=110.1, bsz=40, num_updates=15790, lr=4.49839e-05, gnorm=0.309, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62365
2023-01-07 08:09:11 - progress_bar.py[line:274] - INFO: epoch 001:  15822 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4354, wps=101.6, ups=0.47, wpb=109.1, bsz=40, num_updates=15800, lr=4.49794e-05, gnorm=0.359, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62387
2023-01-07 08:09:32 - progress_bar.py[line:274] - INFO: epoch 001:  15832 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4638, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=15810, lr=4.49749e-05, gnorm=0.469, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62408
2023-01-07 08:09:54 - progress_bar.py[line:274] - INFO: epoch 001:  15842 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4041, wps=99.6, ups=0.46, wpb=108.1, bsz=40, num_updates=15820, lr=4.49704e-05, gnorm=0.325, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62430
2023-01-07 08:10:16 - progress_bar.py[line:274] - INFO: epoch 001:  15852 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.407, wps=104, ups=0.47, wpb=110.1, bsz=40, num_updates=15830, lr=4.49659e-05, gnorm=0.342, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62452
2023-01-07 08:10:37 - progress_bar.py[line:274] - INFO: epoch 001:  15862 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4346, wps=104.4, ups=0.47, wpb=110.4, bsz=40, num_updates=15840, lr=4.49614e-05, gnorm=0.3, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=62473
2023-01-07 08:10:59 - progress_bar.py[line:274] - INFO: epoch 001:  15872 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.46, wps=101.1, ups=0.46, wpb=108.8, bsz=40, num_updates=15850, lr=4.49569e-05, gnorm=0.286, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62495
2023-01-07 08:11:21 - progress_bar.py[line:274] - INFO: epoch 001:  15882 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4118, wps=102.5, ups=0.47, wpb=109.3, bsz=40, num_updates=15860, lr=4.49524e-05, gnorm=0.298, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=62516
2023-01-07 08:11:42 - progress_bar.py[line:274] - INFO: epoch 001:  15892 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4471, wps=103.3, ups=0.47, wpb=109.8, bsz=40, num_updates=15870, lr=4.49479e-05, gnorm=0.307, clip=10, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=62538
2023-01-07 08:12:04 - progress_bar.py[line:274] - INFO: epoch 001:  15902 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4676, wps=100, ups=0.46, wpb=107.9, bsz=40, num_updates=15880, lr=4.49434e-05, gnorm=0.276, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62560
2023-01-07 08:12:26 - progress_bar.py[line:274] - INFO: epoch 001:  15912 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4601, wps=99.3, ups=0.46, wpb=107.7, bsz=40, num_updates=15890, lr=4.49389e-05, gnorm=0.258, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62582
2023-01-07 08:12:47 - progress_bar.py[line:274] - INFO: epoch 001:  15922 / 115845 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.4115, wps=102.1, ups=0.47, wpb=108, bsz=40, num_updates=15900, lr=4.49344e-05, gnorm=0.456, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62603
2023-01-07 08:13:09 - progress_bar.py[line:274] - INFO: epoch 001:  15932 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4225, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=15910, lr=4.493e-05, gnorm=0.3, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=62625
2023-01-07 08:13:31 - progress_bar.py[line:274] - INFO: epoch 001:  15942 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5152, wps=100.8, ups=0.45, wpb=110.9, bsz=40, num_updates=15920, lr=4.49255e-05, gnorm=0.315, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=62647
2023-01-07 08:13:53 - progress_bar.py[line:274] - INFO: epoch 001:  15952 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3938, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=15930, lr=4.4921e-05, gnorm=0.322, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=62669
2023-01-07 08:14:15 - progress_bar.py[line:274] - INFO: epoch 001:  15962 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4394, wps=102.9, ups=0.47, wpb=108.9, bsz=40, num_updates=15940, lr=4.49165e-05, gnorm=0.284, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62690
2023-01-07 08:14:36 - progress_bar.py[line:274] - INFO: epoch 001:  15972 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4104, wps=102.1, ups=0.47, wpb=107.9, bsz=40, num_updates=15950, lr=4.4912e-05, gnorm=0.351, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=62712
2023-01-07 08:14:57 - progress_bar.py[line:274] - INFO: epoch 001:  15982 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4328, wps=102.4, ups=0.48, wpb=107.6, bsz=40, num_updates=15960, lr=4.49075e-05, gnorm=0.635, clip=30, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62733
2023-01-07 08:15:19 - progress_bar.py[line:274] - INFO: epoch 001:  15992 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4257, wps=102.2, ups=0.46, wpb=110.9, bsz=40, num_updates=15970, lr=4.4903e-05, gnorm=0.345, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62755
2023-01-07 08:15:41 - progress_bar.py[line:274] - INFO: epoch 001:  16002 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4271, wps=101.9, ups=0.47, wpb=109.4, bsz=40, num_updates=15980, lr=4.48985e-05, gnorm=0.283, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=62777
2023-01-07 08:16:02 - progress_bar.py[line:274] - INFO: epoch 001:  16012 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3881, wps=101.8, ups=0.47, wpb=109.3, bsz=40, num_updates=15990, lr=4.4894e-05, gnorm=0.224, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=62798
2023-01-07 08:16:24 - progress_bar.py[line:274] - INFO: epoch 001:  16022 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3784, wps=101.9, ups=0.46, wpb=109.9, bsz=40, num_updates=16000, lr=4.48895e-05, gnorm=0.302, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=62820
2023-01-07 08:16:24 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 08:16:26 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 08:16:26 - train.py[line:551] - INFO: load:1.11 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 08:16:42 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 9.29 GiB already allocated; 266.19 MiB free; 36.84 GiB reserved in total by PyTorch)
2023-01-07 08:16:42 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 27        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9511 MB |   14741 MB |    8913 TB |    8913 TB |
|       from large pool |    9337 MB |   14567 MB |    8909 TB |    8909 TB |
|       from small pool |     174 MB |     175 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9511 MB |   14741 MB |    8913 TB |    8913 TB |
|       from large pool |    9337 MB |   14567 MB |    8909 TB |    8909 TB |
|       from small pool |     174 MB |     175 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   37728 MB |   37852 MB |  294012 MB |  256284 MB |
|       from large pool |   37552 MB |   37670 MB |  293610 MB |  256058 MB |
|       from small pool |     176 MB |     182 MB |     402 MB |     226 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   28216 MB |   32648 MB |    9680 TB |    9680 TB |
|       from large pool |   28214 MB |   32645 MB |    9676 TB |    9676 TB |
|       from small pool |       1 MB |       3 MB |       4 TB |       4 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4634    |    4648    |  421167 K  |  421162 K  |
|       from large pool |     698    |     710    |  129835 K  |  129834 K  |
|       from small pool |    3936    |    3946    |  291332 K  |  291328 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4634    |    4648    |  421167 K  |  421162 K  |
|       from large pool |     698    |     710    |  129835 K  |  129834 K  |
|       from small pool |    3936    |    3946    |  291332 K  |  291328 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     160    |     164    |     617    |     457    |
|       from large pool |      72    |      73    |     416    |     344    |
|       from small pool |      88    |      91    |     201    |     113    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      93    |     104    |  312305 K  |  312305 K  |
|       from large pool |      44    |      48    |   62951 K  |   62951 K  |
|       from small pool |      49    |      64    |  249353 K  |  249353 K  |
|===========================================================================|

2023-01-07 08:16:42 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-07 08:16:42 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-07 08:18:59 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 08:18:59 - train.py[line:551] - INFO: load:1.14 valid_run:152.92 task_valid:148.19 collect_output:2.85
2023-01-07 08:21:28 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 08:21:28 - train.py[line:551] - INFO: load:1.16 valid_run:301.96 task_valid:291.02 collect_output:8.08
2023-01-07 08:24:01 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 08:24:01 - train.py[line:551] - INFO: load:1.19 valid_run:455.13 task_valid:433.54 collect_output:17.67
2023-01-07 08:26:31 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 08:26:31 - train.py[line:551] - INFO: load:1.22 valid_run:604.89 task_valid:578.06 collect_output:21.92
2023-01-07 08:29:04 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 08:29:04 - train.py[line:551] - INFO: load:1.24 valid_run:757.56 task_valid:725.11 collect_output:26.54
2023-01-07 08:31:36 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 08:31:36 - train.py[line:551] - INFO: load:1.27 valid_run:910.07 task_valid:870.54 collect_output:32.60
2023-01-07 08:34:11 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 08:34:11 - train.py[line:551] - INFO: load:1.29 valid_run:1064.47 task_valid:1016.13 collect_output:40.41
2023-01-07 08:36:43 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 08:36:43 - train.py[line:551] - INFO: load:1.32 valid_run:1216.85 task_valid:1156.82 collect_output:51.08
2023-01-07 08:39:13 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 08:39:13 - train.py[line:551] - INFO: load:1.35 valid_run:1367.22 task_valid:1301.25 collect_output:56.00
2023-01-07 08:41:43 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 08:41:43 - train.py[line:551] - INFO: load:1.37 valid_run:1516.71 task_valid:1444.24 collect_output:61.48
2023-01-07 08:44:13 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 08:44:13 - train.py[line:551] - INFO: load:1.40 valid_run:1666.96 task_valid:1588.92 collect_output:66.03
2023-01-07 08:46:44 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 08:46:44 - train.py[line:551] - INFO: load:1.43 valid_run:1817.58 task_valid:1733.68 collect_output:70.87
2023-01-07 08:49:15 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 08:49:15 - train.py[line:551] - INFO: load:1.45 valid_run:1968.10 task_valid:1875.08 collect_output:78.98
2023-01-07 08:51:45 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 08:51:45 - train.py[line:551] - INFO: load:1.48 valid_run:2118.83 task_valid:2020.15 collect_output:83.61
2023-01-07 08:54:16 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 08:54:16 - train.py[line:551] - INFO: load:1.51 valid_run:2269.18 task_valid:2166.52 collect_output:86.59
2023-01-07 08:56:47 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 08:56:47 - train.py[line:551] - INFO: load:1.53 valid_run:2419.82 task_valid:2310.46 collect_output:92.27
2023-01-07 08:59:19 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 08:59:19 - train.py[line:551] - INFO: load:1.56 valid_run:2572.21 task_valid:2455.87 collect_output:98.24
2023-01-07 09:01:50 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 09:01:50 - train.py[line:551] - INFO: load:1.59 valid_run:2722.96 task_valid:2602.63 collect_output:101.21
2023-01-07 09:04:19 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 09:04:19 - train.py[line:551] - INFO: load:1.61 valid_run:2872.20 task_valid:2744.04 collect_output:108.04
2023-01-07 09:06:50 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 09:06:50 - train.py[line:551] - INFO: load:1.64 valid_run:3023.12 task_valid:2888.86 collect_output:113.11
2023-01-07 09:09:23 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 09:09:23 - train.py[line:551] - INFO: load:1.67 valid_run:3175.97 task_valid:3033.15 collect_output:120.68
2023-01-07 09:11:53 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 09:11:53 - train.py[line:551] - INFO: load:1.69 valid_run:3325.68 task_valid:3177.47 collect_output:125.05
2023-01-07 09:14:25 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 09:14:25 - train.py[line:551] - INFO: load:1.72 valid_run:3477.47 task_valid:3323.49 collect_output:129.81
2023-01-07 09:16:57 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 09:16:57 - train.py[line:551] - INFO: load:1.75 valid_run:3629.35 task_valid:3469.77 collect_output:134.38

====================================================================================================
SGG eval:     R @ 50: 0.4207;     R @ 100: 0.4997;     R @ 500: 0.5403;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2690;    mR @ 100: 0.3379;    mR @ 500: 0.3693;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6585) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.8378) (playing:0.0000) (riding:0.5392) (says:0.0000) (sitting on:0.7143) (standing on:0.1933) (using:0.5500) (walking in:0.0000) (walking on:0.3333) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-07 09:19:28 - train.py[line:487] - INFO: 0.49967619047619055

====================================================================================================
SGG eval:     R @ 50: 0.4207;     R @ 100: 0.4997;     R @ 500: 0.5403;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2690;    mR @ 100: 0.3379;    mR @ 500: 0.3693;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6585) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.8378) (playing:0.0000) (riding:0.5392) (says:0.0000) (sitting on:0.7143) (standing on:0.1933) (using:0.5500) (walking in:0.0000) (walking on:0.3333) (watching:0.1806) 
--------------------------------------------------------
====================================================================================================

2023-01-07 09:19:28 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 09:19:28 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.386 | loss_v1 0 | loss_v2 0 | nll_loss 0.237 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.499676 | ppl 1.18 | vqa_score 0.4426 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 16000 | best_R@100 0.641887
2023-01-07 09:19:28 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 16000 updates
2023-01-07 09:19:28 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_16000.pt
2023-01-07 09:20:11 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_16000.pt
2023-01-07 09:21:47 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_16000.pt (epoch 1 @ 16000 updates, score 0.49967619047619055) (writing took 138.99409168586135 seconds)
2023-01-07 09:22:09 - progress_bar.py[line:274] - INFO: epoch 001:  16032 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4607, wps=0.6, ups=0, wpb=108.8, bsz=40, num_updates=16010, lr=4.4885e-05, gnorm=0.716, clip=20, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=66765
2023-01-07 09:22:31 - progress_bar.py[line:274] - INFO: epoch 001:  16042 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4696, wps=100.6, ups=0.46, wpb=110.5, bsz=40, num_updates=16020, lr=4.48805e-05, gnorm=0.35, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=66787
2023-01-07 09:22:53 - progress_bar.py[line:274] - INFO: epoch 001:  16052 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4876, wps=101, ups=0.46, wpb=109.7, bsz=40, num_updates=16030, lr=4.4876e-05, gnorm=0.363, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66809
2023-01-07 09:23:15 - progress_bar.py[line:274] - INFO: epoch 001:  16062 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4404, wps=101.6, ups=0.46, wpb=109.5, bsz=40, num_updates=16040, lr=4.48715e-05, gnorm=0.255, clip=0, loss_scale=256, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=66831
2023-01-07 09:23:37 - progress_bar.py[line:274] - INFO: epoch 001:  16072 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4307, wps=98.8, ups=0.46, wpb=108.3, bsz=40, num_updates=16050, lr=4.4867e-05, gnorm=0.395, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66853
2023-01-07 09:23:58 - progress_bar.py[line:274] - INFO: epoch 001:  16082 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4021, wps=104.4, ups=0.47, wpb=110.2, bsz=40, num_updates=16060, lr=4.48625e-05, gnorm=0.231, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=66874
2023-01-07 09:24:20 - progress_bar.py[line:274] - INFO: epoch 001:  16092 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4404, wps=100, ups=0.46, wpb=107.5, bsz=40, num_updates=16070, lr=4.4858e-05, gnorm=0.252, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=66896
2023-01-07 09:24:42 - progress_bar.py[line:274] - INFO: epoch 001:  16102 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4569, wps=102.8, ups=0.47, wpb=108.8, bsz=40, num_updates=16080, lr=4.48535e-05, gnorm=0.286, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=66917
2023-01-07 09:25:04 - progress_bar.py[line:274] - INFO: epoch 001:  16112 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4153, wps=100.1, ups=0.46, wpb=109.9, bsz=40, num_updates=16090, lr=4.4849e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66940
2023-01-07 09:25:25 - progress_bar.py[line:274] - INFO: epoch 001:  16122 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4408, wps=102.9, ups=0.48, wpb=107.6, bsz=40, num_updates=16100, lr=4.48445e-05, gnorm=0.384, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=66961
2023-01-07 09:25:47 - progress_bar.py[line:274] - INFO: epoch 001:  16132 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4084, wps=101.4, ups=0.46, wpb=110.6, bsz=40, num_updates=16110, lr=4.484e-05, gnorm=0.344, clip=10, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=66983
2023-01-07 09:26:09 - progress_bar.py[line:274] - INFO: epoch 001:  16142 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4608, wps=100.1, ups=0.47, wpb=107.2, bsz=40, num_updates=16120, lr=4.48355e-05, gnorm=0.321, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67005
2023-01-07 09:26:30 - progress_bar.py[line:274] - INFO: epoch 001:  16152 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4021, wps=105.1, ups=0.48, wpb=109.1, bsz=40, num_updates=16130, lr=4.4831e-05, gnorm=0.344, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67026
2023-01-07 09:26:51 - progress_bar.py[line:274] - INFO: epoch 001:  16162 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4213, wps=103.1, ups=0.47, wpb=108.9, bsz=40, num_updates=16140, lr=4.48265e-05, gnorm=0.341, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67047
2023-01-07 09:27:13 - progress_bar.py[line:274] - INFO: epoch 001:  16172 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4677, wps=99, ups=0.46, wpb=108.3, bsz=40, num_updates=16150, lr=4.48221e-05, gnorm=0.31, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67069
2023-01-07 09:27:35 - progress_bar.py[line:274] - INFO: epoch 001:  16182 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4221, wps=104, ups=0.47, wpb=110.3, bsz=40, num_updates=16160, lr=4.48176e-05, gnorm=0.337, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67090
2023-01-07 09:27:57 - progress_bar.py[line:274] - INFO: epoch 001:  16192 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.398, wps=100.2, ups=0.46, wpb=108.8, bsz=40, num_updates=16170, lr=4.48131e-05, gnorm=0.298, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67112
2023-01-07 09:28:18 - progress_bar.py[line:274] - INFO: epoch 001:  16202 / 115845 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4372, wps=103.9, ups=0.48, wpb=108.9, bsz=40, num_updates=16180, lr=4.48086e-05, gnorm=0.381, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67134
2023-01-07 09:28:39 - progress_bar.py[line:274] - INFO: epoch 001:  16212 / 115845 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4419, wps=99.7, ups=0.46, wpb=107.4, bsz=40, num_updates=16190, lr=4.48041e-05, gnorm=0.344, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67155
2023-01-07 09:29:01 - progress_bar.py[line:274] - INFO: epoch 001:  16222 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4734, wps=101.5, ups=0.47, wpb=108.3, bsz=40, num_updates=16200, lr=4.47996e-05, gnorm=0.381, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=67177
2023-01-07 09:29:03 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 09:29:25 - progress_bar.py[line:274] - INFO: epoch 001:  16233 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.333, nsentences=40, sample_size=110.333, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4353, wps=97.7, ups=0.42, wpb=110.3, bsz=40, num_updates=16210, lr=4.47951e-05, gnorm=0.326, clip=0, loss_scale=256, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=67201
2023-01-07 09:29:46 - progress_bar.py[line:274] - INFO: epoch 001:  16243 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4641, wps=101.8, ups=0.47, wpb=107.6, bsz=40, num_updates=16220, lr=4.47906e-05, gnorm=0.283, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67222
2023-01-07 09:30:08 - progress_bar.py[line:274] - INFO: epoch 001:  16253 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4434, wps=100.5, ups=0.47, wpb=107.2, bsz=40, num_updates=16230, lr=4.47861e-05, gnorm=0.319, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67244
2023-01-07 09:30:29 - progress_bar.py[line:274] - INFO: epoch 001:  16263 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4709, wps=102.7, ups=0.47, wpb=108.9, bsz=40, num_updates=16240, lr=4.47816e-05, gnorm=0.295, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67265
2023-01-07 09:30:51 - progress_bar.py[line:274] - INFO: epoch 001:  16273 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4683, wps=100.9, ups=0.46, wpb=108.9, bsz=40, num_updates=16250, lr=4.47771e-05, gnorm=0.316, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67287
2023-01-07 09:31:13 - progress_bar.py[line:274] - INFO: epoch 001:  16283 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4897, wps=100.5, ups=0.46, wpb=109.2, bsz=40, num_updates=16260, lr=4.47726e-05, gnorm=0.351, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67309
2023-01-07 09:31:35 - progress_bar.py[line:274] - INFO: epoch 001:  16293 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=102.5, ups=0.47, wpb=109.2, bsz=40, num_updates=16270, lr=4.47681e-05, gnorm=0.23, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67330
2023-01-07 09:31:56 - progress_bar.py[line:274] - INFO: epoch 001:  16303 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4394, wps=102.6, ups=0.47, wpb=108.5, bsz=40, num_updates=16280, lr=4.47636e-05, gnorm=0.447, clip=10, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=67352
2023-01-07 09:32:18 - progress_bar.py[line:274] - INFO: epoch 001:  16313 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4428, wps=101.4, ups=0.46, wpb=109.6, bsz=40, num_updates=16290, lr=4.47591e-05, gnorm=0.26, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=67374
2023-01-07 09:32:39 - progress_bar.py[line:274] - INFO: epoch 001:  16323 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5, wps=100.8, ups=0.47, wpb=108.1, bsz=40, num_updates=16300, lr=4.47546e-05, gnorm=0.417, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67395
2023-01-07 09:33:01 - progress_bar.py[line:274] - INFO: epoch 001:  16333 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4279, wps=98.5, ups=0.46, wpb=106.9, bsz=40, num_updates=16310, lr=4.47501e-05, gnorm=0.422, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=67417
2023-01-07 09:33:24 - progress_bar.py[line:274] - INFO: epoch 001:  16343 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4588, wps=98, ups=0.45, wpb=107.9, bsz=40, num_updates=16320, lr=4.47456e-05, gnorm=0.452, clip=10, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=67439
2023-01-07 09:33:45 - progress_bar.py[line:274] - INFO: epoch 001:  16353 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4603, wps=102.8, ups=0.47, wpb=110.2, bsz=40, num_updates=16330, lr=4.47411e-05, gnorm=0.391, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=67461
2023-01-07 09:34:07 - progress_bar.py[line:274] - INFO: epoch 001:  16363 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4564, wps=102.2, ups=0.47, wpb=109.6, bsz=40, num_updates=16340, lr=4.47366e-05, gnorm=0.236, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67483
2023-01-07 09:34:29 - progress_bar.py[line:274] - INFO: epoch 001:  16373 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.467, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=16350, lr=4.47321e-05, gnorm=0.42, clip=10, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=67505
2023-01-07 09:34:50 - progress_bar.py[line:274] - INFO: epoch 001:  16383 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4348, wps=102.5, ups=0.47, wpb=109.3, bsz=40, num_updates=16360, lr=4.47276e-05, gnorm=0.329, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67526
2023-01-07 09:35:12 - progress_bar.py[line:274] - INFO: epoch 001:  16393 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4225, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=16370, lr=4.47231e-05, gnorm=0.196, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67548
2023-01-07 09:35:34 - progress_bar.py[line:274] - INFO: epoch 001:  16403 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4908, wps=99.5, ups=0.46, wpb=107.5, bsz=40, num_updates=16380, lr=4.47186e-05, gnorm=0.244, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67570
2023-01-07 09:35:56 - progress_bar.py[line:274] - INFO: epoch 001:  16413 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4049, wps=100.2, ups=0.46, wpb=108.2, bsz=40, num_updates=16390, lr=4.47141e-05, gnorm=0.363, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67592
2023-01-07 09:36:17 - progress_bar.py[line:274] - INFO: epoch 001:  16423 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4195, wps=103.4, ups=0.47, wpb=110.2, bsz=40, num_updates=16400, lr=4.47097e-05, gnorm=0.228, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=67613
2023-01-07 09:36:39 - progress_bar.py[line:274] - INFO: epoch 001:  16433 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.509, wps=104.6, ups=0.47, wpb=111.5, bsz=40, num_updates=16410, lr=4.47052e-05, gnorm=0.245, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67635
2023-01-07 09:37:00 - progress_bar.py[line:274] - INFO: epoch 001:  16443 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4573, wps=102.9, ups=0.47, wpb=110, bsz=40, num_updates=16420, lr=4.47007e-05, gnorm=0.264, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=67656
2023-01-07 09:37:22 - progress_bar.py[line:274] - INFO: epoch 001:  16453 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=99.8, ups=0.46, wpb=108.2, bsz=40, num_updates=16430, lr=4.46962e-05, gnorm=0.345, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=67678
2023-01-07 09:37:44 - progress_bar.py[line:274] - INFO: epoch 001:  16463 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4118, wps=102.8, ups=0.47, wpb=109.5, bsz=40, num_updates=16440, lr=4.46917e-05, gnorm=0.308, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67700
2023-01-07 09:38:05 - progress_bar.py[line:274] - INFO: epoch 001:  16473 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.432, wps=103.4, ups=0.47, wpb=110, bsz=40, num_updates=16450, lr=4.46872e-05, gnorm=0.405, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67721
2023-01-07 09:38:27 - progress_bar.py[line:274] - INFO: epoch 001:  16483 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4595, wps=104, ups=0.48, wpb=109.4, bsz=40, num_updates=16460, lr=4.46827e-05, gnorm=0.481, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67743
2023-01-07 09:38:48 - progress_bar.py[line:274] - INFO: epoch 001:  16493 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4895, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=16470, lr=4.46782e-05, gnorm=0.259, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67764
2023-01-07 09:39:10 - progress_bar.py[line:274] - INFO: epoch 001:  16503 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4309, wps=103.8, ups=0.47, wpb=110.1, bsz=40, num_updates=16480, lr=4.46737e-05, gnorm=0.256, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=67786
2023-01-07 09:39:31 - progress_bar.py[line:274] - INFO: epoch 001:  16513 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4127, wps=105.2, ups=0.48, wpb=110.6, bsz=40, num_updates=16490, lr=4.46692e-05, gnorm=0.291, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67807
2023-01-07 09:39:53 - progress_bar.py[line:274] - INFO: epoch 001:  16523 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4974, wps=100.1, ups=0.46, wpb=110, bsz=40, num_updates=16500, lr=4.46647e-05, gnorm=0.435, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67829
2023-01-07 09:40:16 - progress_bar.py[line:274] - INFO: epoch 001:  16533 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4588, wps=99.4, ups=0.46, wpb=108.6, bsz=40, num_updates=16510, lr=4.46602e-05, gnorm=0.35, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=67851
2023-01-07 09:40:37 - progress_bar.py[line:274] - INFO: epoch 001:  16543 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4734, wps=101.6, ups=0.46, wpb=109.3, bsz=40, num_updates=16520, lr=4.46557e-05, gnorm=0.359, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=67873
2023-01-07 09:40:59 - progress_bar.py[line:274] - INFO: epoch 001:  16553 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4615, wps=103.6, ups=0.47, wpb=109.2, bsz=40, num_updates=16530, lr=4.46512e-05, gnorm=0.2, clip=0, loss_scale=256, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=67894
2023-01-07 09:41:21 - progress_bar.py[line:274] - INFO: epoch 001:  16563 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4428, wps=100.5, ups=0.46, wpb=110, bsz=40, num_updates=16540, lr=4.46467e-05, gnorm=0.387, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=67917
2023-01-07 09:41:43 - progress_bar.py[line:274] - INFO: epoch 001:  16573 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5023, wps=100.3, ups=0.46, wpb=108.9, bsz=40, num_updates=16550, lr=4.46422e-05, gnorm=0.376, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=67938
2023-01-07 09:42:04 - progress_bar.py[line:274] - INFO: epoch 001:  16583 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4474, wps=104.4, ups=0.48, wpb=109.7, bsz=40, num_updates=16560, lr=4.46377e-05, gnorm=0.261, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=67960
2023-01-07 09:42:25 - progress_bar.py[line:274] - INFO: epoch 001:  16593 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4195, wps=102.6, ups=0.47, wpb=108.2, bsz=40, num_updates=16570, lr=4.46332e-05, gnorm=0.306, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=67981
2023-01-07 09:42:47 - progress_bar.py[line:274] - INFO: epoch 001:  16603 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4639, wps=100.6, ups=0.46, wpb=110, bsz=40, num_updates=16580, lr=4.46287e-05, gnorm=0.354, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=68003
2023-01-07 09:43:09 - progress_bar.py[line:274] - INFO: epoch 001:  16613 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4227, wps=100.7, ups=0.46, wpb=108.5, bsz=40, num_updates=16590, lr=4.46242e-05, gnorm=0.333, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68025
2023-01-07 09:43:31 - progress_bar.py[line:274] - INFO: epoch 001:  16623 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.489, wps=103.1, ups=0.47, wpb=109.8, bsz=40, num_updates=16600, lr=4.46197e-05, gnorm=0.323, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68046
2023-01-07 09:43:52 - progress_bar.py[line:274] - INFO: epoch 001:  16633 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4146, wps=101.6, ups=0.47, wpb=108.7, bsz=40, num_updates=16610, lr=4.46152e-05, gnorm=0.25, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68068
2023-01-07 09:44:14 - progress_bar.py[line:274] - INFO: epoch 001:  16643 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4479, wps=98.8, ups=0.45, wpb=108.8, bsz=40, num_updates=16620, lr=4.46107e-05, gnorm=0.265, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=68090
2023-01-07 09:44:36 - progress_bar.py[line:274] - INFO: epoch 001:  16653 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=16630, lr=4.46062e-05, gnorm=0.434, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68112
2023-01-07 09:44:58 - progress_bar.py[line:274] - INFO: epoch 001:  16663 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.397, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=16640, lr=4.46018e-05, gnorm=0.271, clip=0, loss_scale=256, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=68134
2023-01-07 09:45:19 - progress_bar.py[line:274] - INFO: epoch 001:  16673 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4333, wps=103.2, ups=0.48, wpb=108, bsz=40, num_updates=16650, lr=4.45973e-05, gnorm=0.316, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68155
2023-01-07 09:45:41 - progress_bar.py[line:274] - INFO: epoch 001:  16683 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4505, wps=100.3, ups=0.46, wpb=108.1, bsz=40, num_updates=16660, lr=4.45928e-05, gnorm=0.204, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68177
2023-01-07 09:46:03 - progress_bar.py[line:274] - INFO: epoch 001:  16693 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4306, wps=99.9, ups=0.46, wpb=108.2, bsz=40, num_updates=16670, lr=4.45883e-05, gnorm=0.265, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=68199
2023-01-07 09:46:24 - progress_bar.py[line:274] - INFO: epoch 001:  16703 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.466, wps=104.6, ups=0.47, wpb=110.2, bsz=40, num_updates=16680, lr=4.45838e-05, gnorm=0.435, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68220
2023-01-07 09:46:46 - progress_bar.py[line:274] - INFO: epoch 001:  16713 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=102.4, ups=0.46, wpb=110.1, bsz=40, num_updates=16690, lr=4.45793e-05, gnorm=0.303, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68242
2023-01-07 09:47:07 - progress_bar.py[line:274] - INFO: epoch 001:  16723 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4175, wps=101.5, ups=0.47, wpb=108.2, bsz=40, num_updates=16700, lr=4.45748e-05, gnorm=0.318, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68263
2023-01-07 09:47:29 - progress_bar.py[line:274] - INFO: epoch 001:  16733 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5258, wps=104.2, ups=0.47, wpb=110.5, bsz=40, num_updates=16710, lr=4.45703e-05, gnorm=0.425, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68285
2023-01-07 09:47:51 - progress_bar.py[line:274] - INFO: epoch 001:  16743 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4537, wps=98.6, ups=0.45, wpb=108.5, bsz=40, num_updates=16720, lr=4.45658e-05, gnorm=0.302, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=68307
2023-01-07 09:48:13 - progress_bar.py[line:274] - INFO: epoch 001:  16753 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5025, wps=99.9, ups=0.46, wpb=108, bsz=40, num_updates=16730, lr=4.45613e-05, gnorm=0.549, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=68329
2023-01-07 09:48:35 - progress_bar.py[line:274] - INFO: epoch 001:  16763 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4231, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=16740, lr=4.45568e-05, gnorm=0.436, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68350
2023-01-07 09:48:56 - progress_bar.py[line:274] - INFO: epoch 001:  16773 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4406, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=16750, lr=4.45523e-05, gnorm=0.311, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=68372
2023-01-07 09:49:18 - progress_bar.py[line:274] - INFO: epoch 001:  16783 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4503, wps=102.5, ups=0.46, wpb=110.5, bsz=40, num_updates=16760, lr=4.45478e-05, gnorm=0.244, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68394
2023-01-07 09:49:40 - progress_bar.py[line:274] - INFO: epoch 001:  16793 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4244, wps=101.1, ups=0.46, wpb=109.4, bsz=40, num_updates=16770, lr=4.45433e-05, gnorm=0.427, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=68416
2023-01-07 09:50:02 - progress_bar.py[line:274] - INFO: epoch 001:  16803 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4171, wps=102.7, ups=0.47, wpb=109.5, bsz=40, num_updates=16780, lr=4.45388e-05, gnorm=0.384, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68437
2023-01-07 09:50:23 - progress_bar.py[line:274] - INFO: epoch 001:  16813 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.468, wps=101.7, ups=0.46, wpb=109.4, bsz=40, num_updates=16790, lr=4.45343e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=68459
2023-01-07 09:50:45 - progress_bar.py[line:274] - INFO: epoch 001:  16823 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5051, wps=102.2, ups=0.46, wpb=110.2, bsz=40, num_updates=16800, lr=4.45298e-05, gnorm=0.298, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68481
2023-01-07 09:51:07 - progress_bar.py[line:274] - INFO: epoch 001:  16833 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4074, wps=102.1, ups=0.46, wpb=110.8, bsz=40, num_updates=16810, lr=4.45253e-05, gnorm=0.306, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68503
2023-01-07 09:51:29 - progress_bar.py[line:274] - INFO: epoch 001:  16843 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5284, wps=99.7, ups=0.46, wpb=107.3, bsz=40, num_updates=16820, lr=4.45208e-05, gnorm=0.304, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68525
2023-01-07 09:51:50 - progress_bar.py[line:274] - INFO: epoch 001:  16853 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4527, wps=102.9, ups=0.47, wpb=108.6, bsz=40, num_updates=16830, lr=4.45163e-05, gnorm=0.264, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68546
2023-01-07 09:52:12 - progress_bar.py[line:274] - INFO: epoch 001:  16863 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4061, wps=100.5, ups=0.46, wpb=108.3, bsz=40, num_updates=16840, lr=4.45118e-05, gnorm=0.202, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=68568
2023-01-07 09:52:33 - progress_bar.py[line:274] - INFO: epoch 001:  16873 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5026, wps=106.9, ups=0.48, wpb=110.3, bsz=40, num_updates=16850, lr=4.45073e-05, gnorm=0.413, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68588
2023-01-07 09:52:54 - progress_bar.py[line:274] - INFO: epoch 001:  16883 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3947, wps=102.9, ups=0.47, wpb=109.5, bsz=40, num_updates=16860, lr=4.45028e-05, gnorm=0.37, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68610
2023-01-07 09:53:16 - progress_bar.py[line:274] - INFO: epoch 001:  16893 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4527, wps=104.2, ups=0.47, wpb=110.6, bsz=40, num_updates=16870, lr=4.44983e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68632
2023-01-07 09:53:38 - progress_bar.py[line:274] - INFO: epoch 001:  16903 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4615, wps=102, ups=0.47, wpb=108.8, bsz=40, num_updates=16880, lr=4.44938e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68654
2023-01-07 09:54:00 - progress_bar.py[line:274] - INFO: epoch 001:  16913 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4078, wps=103.4, ups=0.47, wpb=110.2, bsz=40, num_updates=16890, lr=4.44894e-05, gnorm=0.286, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68676
2023-01-07 09:54:22 - progress_bar.py[line:274] - INFO: epoch 001:  16923 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4463, wps=105.1, ups=0.48, wpb=109.9, bsz=40, num_updates=16900, lr=4.44849e-05, gnorm=0.287, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68697
2023-01-07 09:54:44 - progress_bar.py[line:274] - INFO: epoch 001:  16933 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4195, wps=100.4, ups=0.46, wpb=109.1, bsz=40, num_updates=16910, lr=4.44804e-05, gnorm=0.223, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68720
2023-01-07 09:55:06 - progress_bar.py[line:274] - INFO: epoch 001:  16943 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4319, wps=102.9, ups=0.47, wpb=109, bsz=40, num_updates=16920, lr=4.44759e-05, gnorm=0.351, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68741
2023-01-07 09:55:28 - progress_bar.py[line:274] - INFO: epoch 001:  16953 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4372, wps=103.9, ups=0.47, wpb=110, bsz=40, num_updates=16930, lr=4.44714e-05, gnorm=0.328, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=68763
2023-01-07 09:55:49 - progress_bar.py[line:274] - INFO: epoch 001:  16963 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.478, wps=104, ups=0.48, wpb=108.7, bsz=40, num_updates=16940, lr=4.44669e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68785
2023-01-07 09:56:11 - progress_bar.py[line:274] - INFO: epoch 001:  16973 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4631, wps=101.4, ups=0.47, wpb=108.1, bsz=40, num_updates=16950, lr=4.44624e-05, gnorm=0.217, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=68807
2023-01-07 09:56:33 - progress_bar.py[line:274] - INFO: epoch 001:  16983 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4857, wps=103.2, ups=0.46, wpb=111.1, bsz=40, num_updates=16960, lr=4.44579e-05, gnorm=0.273, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68829
2023-01-07 09:56:55 - progress_bar.py[line:274] - INFO: epoch 001:  16993 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4278, wps=101.2, ups=0.47, wpb=108, bsz=40, num_updates=16970, lr=4.44534e-05, gnorm=0.173, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68851
2023-01-07 09:57:18 - progress_bar.py[line:274] - INFO: epoch 001:  17003 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.495, wps=101.1, ups=0.46, wpb=110, bsz=40, num_updates=16980, lr=4.44489e-05, gnorm=0.285, clip=10, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=68873
2023-01-07 09:57:40 - progress_bar.py[line:274] - INFO: epoch 001:  17013 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4244, wps=103.4, ups=0.47, wpb=109.1, bsz=40, num_updates=16990, lr=4.44444e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=68895
2023-01-07 09:58:02 - progress_bar.py[line:274] - INFO: epoch 001:  17023 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4569, wps=100.7, ups=0.46, wpb=109.3, bsz=40, num_updates=17000, lr=4.44399e-05, gnorm=0.226, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=68917
2023-01-07 09:58:23 - progress_bar.py[line:274] - INFO: epoch 001:  17033 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4646, wps=104.3, ups=0.48, wpb=108.8, bsz=40, num_updates=17010, lr=4.44354e-05, gnorm=0.324, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=68939
2023-01-07 09:58:45 - progress_bar.py[line:274] - INFO: epoch 001:  17043 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4118, wps=101, ups=0.47, wpb=107.8, bsz=40, num_updates=17020, lr=4.44309e-05, gnorm=0.183, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=68961
2023-01-07 09:59:07 - progress_bar.py[line:274] - INFO: epoch 001:  17053 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4794, wps=99.7, ups=0.46, wpb=109.1, bsz=40, num_updates=17030, lr=4.44264e-05, gnorm=0.483, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=68983
2023-01-07 09:59:30 - progress_bar.py[line:274] - INFO: epoch 001:  17063 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4953, wps=99.6, ups=0.46, wpb=107.4, bsz=40, num_updates=17040, lr=4.44219e-05, gnorm=0.341, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69005
2023-01-07 09:59:52 - progress_bar.py[line:274] - INFO: epoch 001:  17073 / 115845 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5562, wps=104.3, ups=0.47, wpb=111.3, bsz=40, num_updates=17050, lr=4.44174e-05, gnorm=0.287, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=69027
2023-01-07 10:00:13 - progress_bar.py[line:274] - INFO: epoch 001:  17083 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4069, wps=100.9, ups=0.47, wpb=108.2, bsz=40, num_updates=17060, lr=4.44129e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69049
2023-01-07 10:00:36 - progress_bar.py[line:274] - INFO: epoch 001:  17093 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4815, wps=98.9, ups=0.46, wpb=108.3, bsz=40, num_updates=17070, lr=4.44084e-05, gnorm=0.333, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=69071
2023-01-07 10:00:58 - progress_bar.py[line:274] - INFO: epoch 001:  17103 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4392, wps=104.7, ups=0.48, wpb=109.2, bsz=40, num_updates=17080, lr=4.44039e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=69093
2023-01-07 10:01:20 - progress_bar.py[line:274] - INFO: epoch 001:  17113 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4657, wps=102, ups=0.47, wpb=109, bsz=40, num_updates=17090, lr=4.43994e-05, gnorm=0.227, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=69115
2023-01-07 10:01:42 - progress_bar.py[line:274] - INFO: epoch 001:  17123 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.49, wps=100.4, ups=0.46, wpb=109.9, bsz=40, num_updates=17100, lr=4.43949e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=69138
2023-01-07 10:02:04 - progress_bar.py[line:274] - INFO: epoch 001:  17133 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4378, wps=103.7, ups=0.47, wpb=109.5, bsz=40, num_updates=17110, lr=4.43904e-05, gnorm=0.412, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=69159
2023-01-07 10:02:26 - progress_bar.py[line:274] - INFO: epoch 001:  17143 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5105, wps=101.1, ups=0.46, wpb=109.2, bsz=40, num_updates=17120, lr=4.43859e-05, gnorm=0.391, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=69181
2023-01-07 10:02:48 - progress_bar.py[line:274] - INFO: epoch 001:  17153 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.456, wps=104.5, ups=0.47, wpb=110.4, bsz=40, num_updates=17130, lr=4.43815e-05, gnorm=0.287, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=69203
2023-01-07 10:03:09 - progress_bar.py[line:274] - INFO: epoch 001:  17163 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3842, wps=103.1, ups=0.47, wpb=110.3, bsz=40, num_updates=17140, lr=4.4377e-05, gnorm=0.305, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69225
2023-01-07 10:03:32 - progress_bar.py[line:274] - INFO: epoch 001:  17173 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4697, wps=102.6, ups=0.46, wpb=110.4, bsz=40, num_updates=17150, lr=4.43725e-05, gnorm=0.241, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=69247
2023-01-07 10:03:54 - progress_bar.py[line:274] - INFO: epoch 001:  17183 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5245, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=17160, lr=4.4368e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=69269
2023-01-07 10:04:16 - progress_bar.py[line:274] - INFO: epoch 001:  17193 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4221, wps=103.4, ups=0.47, wpb=109.9, bsz=40, num_updates=17170, lr=4.43635e-05, gnorm=0.319, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=69291
2023-01-07 10:04:37 - progress_bar.py[line:274] - INFO: epoch 001:  17203 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=102.2, ups=0.47, wpb=107.8, bsz=40, num_updates=17180, lr=4.4359e-05, gnorm=0.263, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=69313
2023-01-07 10:04:59 - progress_bar.py[line:274] - INFO: epoch 001:  17213 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.484, wps=105.7, ups=0.48, wpb=110.7, bsz=40, num_updates=17190, lr=4.43545e-05, gnorm=0.254, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69334
2023-01-07 10:05:21 - progress_bar.py[line:274] - INFO: epoch 001:  17223 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5101, wps=102.1, ups=0.47, wpb=109.5, bsz=40, num_updates=17200, lr=4.435e-05, gnorm=0.217, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=69356
2023-01-07 10:05:43 - progress_bar.py[line:274] - INFO: epoch 001:  17233 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4619, wps=98.8, ups=0.46, wpb=108.5, bsz=40, num_updates=17210, lr=4.43455e-05, gnorm=0.387, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=69379
2023-01-07 10:06:05 - progress_bar.py[line:274] - INFO: epoch 001:  17243 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5167, wps=101, ups=0.47, wpb=107.8, bsz=40, num_updates=17220, lr=4.4341e-05, gnorm=0.386, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=69401
2023-01-07 10:06:27 - progress_bar.py[line:274] - INFO: epoch 001:  17253 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4352, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=17230, lr=4.43365e-05, gnorm=0.224, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=69423
2023-01-07 10:06:50 - progress_bar.py[line:274] - INFO: epoch 001:  17263 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4279, wps=99.8, ups=0.46, wpb=108.6, bsz=40, num_updates=17240, lr=4.4332e-05, gnorm=0.243, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=69445
2023-01-07 10:07:12 - progress_bar.py[line:274] - INFO: epoch 001:  17273 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.404, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=17250, lr=4.43275e-05, gnorm=0.361, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=69468
2023-01-07 10:07:34 - progress_bar.py[line:274] - INFO: epoch 001:  17283 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4062, wps=104.5, ups=0.47, wpb=110.1, bsz=40, num_updates=17260, lr=4.4323e-05, gnorm=0.301, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=69489
2023-01-07 10:07:56 - progress_bar.py[line:274] - INFO: epoch 001:  17293 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4646, wps=100.9, ups=0.46, wpb=109.5, bsz=40, num_updates=17270, lr=4.43185e-05, gnorm=0.32, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=69512
2023-01-07 10:08:18 - progress_bar.py[line:274] - INFO: epoch 001:  17303 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4521, wps=103.1, ups=0.48, wpb=107.2, bsz=40, num_updates=17280, lr=4.4314e-05, gnorm=0.246, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69533
2023-01-07 10:08:40 - progress_bar.py[line:274] - INFO: epoch 001:  17313 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5175, wps=100.2, ups=0.47, wpb=107.4, bsz=40, num_updates=17290, lr=4.43095e-05, gnorm=0.259, clip=0, loss_scale=1024, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=69555
2023-01-07 10:09:02 - progress_bar.py[line:274] - INFO: epoch 001:  17323 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4378, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=17300, lr=4.4305e-05, gnorm=0.217, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69577
2023-01-07 10:09:24 - progress_bar.py[line:274] - INFO: epoch 001:  17333 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4118, wps=102.9, ups=0.47, wpb=109.5, bsz=40, num_updates=17310, lr=4.43005e-05, gnorm=0.253, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69599
2023-01-07 10:09:46 - progress_bar.py[line:274] - INFO: epoch 001:  17343 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4851, wps=103.1, ups=0.47, wpb=109.8, bsz=40, num_updates=17320, lr=4.4296e-05, gnorm=0.346, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69621
2023-01-07 10:10:08 - progress_bar.py[line:274] - INFO: epoch 001:  17353 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4412, wps=99.3, ups=0.46, wpb=108.5, bsz=40, num_updates=17330, lr=4.42915e-05, gnorm=0.35, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69644
2023-01-07 10:10:30 - progress_bar.py[line:274] - INFO: epoch 001:  17363 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4444, wps=99.7, ups=0.46, wpb=108.5, bsz=40, num_updates=17340, lr=4.4287e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=69666
2023-01-07 10:10:52 - progress_bar.py[line:274] - INFO: epoch 001:  17373 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4596, wps=101.3, ups=0.46, wpb=109.2, bsz=40, num_updates=17350, lr=4.42825e-05, gnorm=0.258, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=69688
2023-01-07 10:11:14 - progress_bar.py[line:274] - INFO: epoch 001:  17383 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4518, wps=101.2, ups=0.46, wpb=109.7, bsz=40, num_updates=17360, lr=4.4278e-05, gnorm=0.253, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=69710
2023-01-07 10:11:36 - progress_bar.py[line:274] - INFO: epoch 001:  17393 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4493, wps=101.6, ups=0.46, wpb=110.5, bsz=40, num_updates=17370, lr=4.42735e-05, gnorm=0.421, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=69732
2023-01-07 10:11:57 - progress_bar.py[line:274] - INFO: epoch 001:  17403 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4683, wps=100.7, ups=0.46, wpb=108.4, bsz=40, num_updates=17380, lr=4.42691e-05, gnorm=0.455, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=69753
2023-01-07 10:12:19 - progress_bar.py[line:274] - INFO: epoch 001:  17413 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4231, wps=101, ups=0.46, wpb=109.5, bsz=40, num_updates=17390, lr=4.42646e-05, gnorm=0.279, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=69775
2023-01-07 10:12:41 - progress_bar.py[line:274] - INFO: epoch 001:  17423 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4794, wps=100.7, ups=0.46, wpb=109.1, bsz=40, num_updates=17400, lr=4.42601e-05, gnorm=0.431, clip=0, loss_scale=1024, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=69797
2023-01-07 10:13:02 - progress_bar.py[line:274] - INFO: epoch 001:  17433 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3978, wps=105.4, ups=0.48, wpb=110.4, bsz=40, num_updates=17410, lr=4.42556e-05, gnorm=0.324, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69818
2023-01-07 10:13:24 - progress_bar.py[line:274] - INFO: epoch 001:  17443 / 115845 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4302, wps=104.4, ups=0.47, wpb=111.3, bsz=40, num_updates=17420, lr=4.42511e-05, gnorm=0.214, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=69840
2023-01-07 10:13:46 - progress_bar.py[line:274] - INFO: epoch 001:  17453 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4513, wps=102.7, ups=0.46, wpb=110.5, bsz=40, num_updates=17430, lr=4.42466e-05, gnorm=0.334, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=69862
2023-01-07 10:14:07 - progress_bar.py[line:274] - INFO: epoch 001:  17463 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4126, wps=102.5, ups=0.47, wpb=108.7, bsz=40, num_updates=17440, lr=4.42421e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69883
2023-01-07 10:14:29 - progress_bar.py[line:274] - INFO: epoch 001:  17473 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.403, wps=101.1, ups=0.47, wpb=108.3, bsz=40, num_updates=17450, lr=4.42376e-05, gnorm=0.384, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69905
2023-01-07 10:14:50 - progress_bar.py[line:274] - INFO: epoch 001:  17483 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4363, wps=101.4, ups=0.47, wpb=107.4, bsz=40, num_updates=17460, lr=4.42331e-05, gnorm=0.278, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69926
2023-01-07 10:15:12 - progress_bar.py[line:274] - INFO: epoch 001:  17493 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4361, wps=99.5, ups=0.46, wpb=107, bsz=40, num_updates=17470, lr=4.42286e-05, gnorm=0.215, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=69948
2023-01-07 10:15:33 - progress_bar.py[line:274] - INFO: epoch 001:  17503 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.442, wps=103.8, ups=0.47, wpb=110.4, bsz=40, num_updates=17480, lr=4.42241e-05, gnorm=0.293, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=69969
2023-01-07 10:15:55 - progress_bar.py[line:274] - INFO: epoch 001:  17513 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4503, wps=102.4, ups=0.47, wpb=109.1, bsz=40, num_updates=17490, lr=4.42196e-05, gnorm=0.36, clip=10, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=69991
2023-01-07 10:16:16 - progress_bar.py[line:274] - INFO: epoch 001:  17523 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4813, wps=103.5, ups=0.47, wpb=109, bsz=40, num_updates=17500, lr=4.42151e-05, gnorm=0.242, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70012
2023-01-07 10:16:37 - progress_bar.py[line:274] - INFO: epoch 001:  17533 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4292, wps=103.3, ups=0.47, wpb=108.9, bsz=40, num_updates=17510, lr=4.42106e-05, gnorm=0.38, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70033
2023-01-07 10:16:59 - progress_bar.py[line:274] - INFO: epoch 001:  17543 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4368, wps=101, ups=0.46, wpb=109.7, bsz=40, num_updates=17520, lr=4.42061e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=70055
2023-01-07 10:17:21 - progress_bar.py[line:274] - INFO: epoch 001:  17553 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4692, wps=100.3, ups=0.46, wpb=108.4, bsz=40, num_updates=17530, lr=4.42016e-05, gnorm=0.269, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=70077
2023-01-07 10:17:43 - progress_bar.py[line:274] - INFO: epoch 001:  17563 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4129, wps=100, ups=0.46, wpb=109.4, bsz=40, num_updates=17540, lr=4.41971e-05, gnorm=0.379, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=70099
2023-01-07 10:18:05 - progress_bar.py[line:274] - INFO: epoch 001:  17573 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4525, wps=103.4, ups=0.47, wpb=110.5, bsz=40, num_updates=17550, lr=4.41926e-05, gnorm=0.322, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70121
2023-01-07 10:18:27 - progress_bar.py[line:274] - INFO: epoch 001:  17583 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3557, wps=101.2, ups=0.46, wpb=108.8, bsz=40, num_updates=17560, lr=4.41881e-05, gnorm=0.192, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70143
2023-01-07 10:18:48 - progress_bar.py[line:274] - INFO: epoch 001:  17593 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4626, wps=100.3, ups=0.47, wpb=107.6, bsz=40, num_updates=17570, lr=4.41836e-05, gnorm=0.556, clip=20, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=70164
2023-01-07 10:19:10 - progress_bar.py[line:274] - INFO: epoch 001:  17603 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4694, wps=102.2, ups=0.47, wpb=109.8, bsz=40, num_updates=17580, lr=4.41791e-05, gnorm=0.239, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70186
2023-01-07 10:19:32 - progress_bar.py[line:274] - INFO: epoch 001:  17613 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4512, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=17590, lr=4.41746e-05, gnorm=0.301, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70208
2023-01-07 10:19:53 - progress_bar.py[line:274] - INFO: epoch 001:  17623 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4468, wps=101.8, ups=0.47, wpb=109, bsz=40, num_updates=17600, lr=4.41701e-05, gnorm=0.401, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70229
2023-01-07 10:20:15 - progress_bar.py[line:274] - INFO: epoch 001:  17633 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.47, wps=102.2, ups=0.47, wpb=109.8, bsz=40, num_updates=17610, lr=4.41656e-05, gnorm=0.32, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=70251
2023-01-07 10:20:37 - progress_bar.py[line:274] - INFO: epoch 001:  17643 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4434, wps=99.9, ups=0.46, wpb=108.2, bsz=40, num_updates=17620, lr=4.41612e-05, gnorm=0.318, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=70273
2023-01-07 10:20:59 - progress_bar.py[line:274] - INFO: epoch 001:  17653 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4471, wps=99.2, ups=0.46, wpb=108.2, bsz=40, num_updates=17630, lr=4.41567e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70295
2023-01-07 10:21:21 - progress_bar.py[line:274] - INFO: epoch 001:  17663 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5074, wps=98.6, ups=0.46, wpb=107, bsz=40, num_updates=17640, lr=4.41522e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=70317
2023-01-07 10:21:42 - progress_bar.py[line:274] - INFO: epoch 001:  17673 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4316, wps=101.9, ups=0.47, wpb=108.5, bsz=40, num_updates=17650, lr=4.41477e-05, gnorm=0.29, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70338
2023-01-07 10:22:04 - progress_bar.py[line:274] - INFO: epoch 001:  17683 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4643, wps=102.5, ups=0.47, wpb=109.7, bsz=40, num_updates=17660, lr=4.41432e-05, gnorm=0.32, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70360
2023-01-07 10:22:26 - progress_bar.py[line:274] - INFO: epoch 001:  17693 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.445, wps=101.1, ups=0.47, wpb=107.2, bsz=40, num_updates=17670, lr=4.41387e-05, gnorm=0.26, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70381
2023-01-07 10:22:48 - progress_bar.py[line:274] - INFO: epoch 001:  17703 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4471, wps=100.8, ups=0.46, wpb=110.4, bsz=40, num_updates=17680, lr=4.41342e-05, gnorm=0.345, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70404
2023-01-07 10:23:09 - progress_bar.py[line:274] - INFO: epoch 001:  17713 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=102.2, ups=0.46, wpb=109.9, bsz=40, num_updates=17690, lr=4.41297e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70425
2023-01-07 10:23:30 - progress_bar.py[line:274] - INFO: epoch 001:  17723 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4408, wps=104.5, ups=0.49, wpb=107, bsz=40, num_updates=17700, lr=4.41252e-05, gnorm=0.369, clip=20, loss_scale=1024, train_wall=20, gb_free=10.3, ema_decay=0.9999, wall=70446
2023-01-07 10:23:52 - progress_bar.py[line:274] - INFO: epoch 001:  17733 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.401, wps=101.2, ups=0.47, wpb=108, bsz=40, num_updates=17710, lr=4.41207e-05, gnorm=0.375, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70468
2023-01-07 10:24:13 - progress_bar.py[line:274] - INFO: epoch 001:  17743 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4348, wps=103.3, ups=0.47, wpb=110.6, bsz=40, num_updates=17720, lr=4.41162e-05, gnorm=0.467, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70489
2023-01-07 10:24:34 - progress_bar.py[line:274] - INFO: epoch 001:  17753 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4129, wps=104.9, ups=0.48, wpb=108.9, bsz=40, num_updates=17730, lr=4.41117e-05, gnorm=0.371, clip=0, loss_scale=1024, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=70510
2023-01-07 10:24:56 - progress_bar.py[line:274] - INFO: epoch 001:  17763 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5136, wps=100.2, ups=0.47, wpb=107.7, bsz=40, num_updates=17740, lr=4.41072e-05, gnorm=0.336, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70532
2023-01-07 10:25:18 - progress_bar.py[line:274] - INFO: epoch 001:  17773 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4062, wps=102.3, ups=0.46, wpb=110.8, bsz=40, num_updates=17750, lr=4.41027e-05, gnorm=0.225, clip=0, loss_scale=2048, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=70554
2023-01-07 10:25:40 - progress_bar.py[line:274] - INFO: epoch 001:  17783 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4712, wps=99.9, ups=0.46, wpb=108.8, bsz=40, num_updates=17760, lr=4.40982e-05, gnorm=0.337, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70576
2023-01-07 10:26:02 - progress_bar.py[line:274] - INFO: epoch 001:  17793 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4703, wps=101.6, ups=0.47, wpb=109.1, bsz=40, num_updates=17770, lr=4.40937e-05, gnorm=0.234, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70598
2023-01-07 10:26:23 - progress_bar.py[line:274] - INFO: epoch 001:  17803 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4901, wps=105.2, ups=0.48, wpb=110.6, bsz=40, num_updates=17780, lr=4.40892e-05, gnorm=0.339, clip=0, loss_scale=2048, train_wall=21, gb_free=10, ema_decay=0.9999, wall=70619
2023-01-07 10:26:45 - progress_bar.py[line:274] - INFO: epoch 001:  17813 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.402, wps=101.2, ups=0.46, wpb=109.6, bsz=40, num_updates=17790, lr=4.40847e-05, gnorm=0.253, clip=0, loss_scale=2048, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=70641
2023-01-07 10:27:07 - progress_bar.py[line:274] - INFO: epoch 001:  17823 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.41, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=17800, lr=4.40802e-05, gnorm=0.32, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70663
2023-01-07 10:27:29 - progress_bar.py[line:274] - INFO: epoch 001:  17833 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4348, wps=102.8, ups=0.47, wpb=108.6, bsz=40, num_updates=17810, lr=4.40757e-05, gnorm=0.301, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70685
2023-01-07 10:27:51 - progress_bar.py[line:274] - INFO: epoch 001:  17843 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4974, wps=100.5, ups=0.46, wpb=109.2, bsz=40, num_updates=17820, lr=4.40712e-05, gnorm=0.193, clip=0, loss_scale=2048, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=70707
2023-01-07 10:28:11 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-07 10:28:16 - progress_bar.py[line:274] - INFO: epoch 001:  17854 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.333, nsentences=40, sample_size=110.333, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4734, wps=97.5, ups=0.42, wpb=110.3, bsz=40, num_updates=17830, lr=4.40667e-05, gnorm=0.289, clip=0, loss_scale=1024, train_wall=24, gb_free=10.3, ema_decay=0.9999, wall=70731
2023-01-07 10:28:38 - progress_bar.py[line:274] - INFO: epoch 001:  17864 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.396, wps=100.7, ups=0.46, wpb=108.6, bsz=40, num_updates=17840, lr=4.40622e-05, gnorm=0.302, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=70753
2023-01-07 10:28:59 - progress_bar.py[line:274] - INFO: epoch 001:  17874 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4638, wps=103.5, ups=0.48, wpb=107.4, bsz=40, num_updates=17850, lr=4.40577e-05, gnorm=0.349, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=70775
2023-01-07 10:29:21 - progress_bar.py[line:274] - INFO: epoch 001:  17884 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.467, wps=102.8, ups=0.47, wpb=110.3, bsz=40, num_updates=17860, lr=4.40532e-05, gnorm=0.364, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70797
2023-01-07 10:29:43 - progress_bar.py[line:274] - INFO: epoch 001:  17894 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4976, wps=101.2, ups=0.47, wpb=108.1, bsz=40, num_updates=17870, lr=4.40488e-05, gnorm=0.207, clip=0, loss_scale=1024, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=70819
2023-01-07 10:30:06 - progress_bar.py[line:274] - INFO: epoch 001:  17904 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4684, wps=102.4, ups=0.46, wpb=110.8, bsz=40, num_updates=17880, lr=4.40443e-05, gnorm=0.224, clip=0, loss_scale=1024, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=70841
2023-01-07 10:30:28 - progress_bar.py[line:274] - INFO: epoch 001:  17914 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3838, wps=102.1, ups=0.47, wpb=108.5, bsz=40, num_updates=17890, lr=4.40398e-05, gnorm=0.471, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70863
2023-01-07 10:30:50 - progress_bar.py[line:274] - INFO: epoch 001:  17924 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4762, wps=101.2, ups=0.46, wpb=109.4, bsz=40, num_updates=17900, lr=4.40353e-05, gnorm=0.235, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=70885
2023-01-07 10:31:12 - progress_bar.py[line:274] - INFO: epoch 001:  17934 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4127, wps=101.3, ups=0.46, wpb=110.2, bsz=40, num_updates=17910, lr=4.40308e-05, gnorm=0.22, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70908
2023-01-07 10:31:35 - progress_bar.py[line:274] - INFO: epoch 001:  17944 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5074, wps=101.3, ups=0.47, wpb=108.8, bsz=40, num_updates=17920, lr=4.40263e-05, gnorm=0.36, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=70930
2023-01-07 10:31:56 - progress_bar.py[line:274] - INFO: epoch 001:  17954 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3969, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=17930, lr=4.40218e-05, gnorm=0.248, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=70952
2023-01-07 10:32:18 - progress_bar.py[line:274] - INFO: epoch 001:  17964 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3913, wps=100.8, ups=0.46, wpb=108.9, bsz=40, num_updates=17940, lr=4.40173e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=70974
2023-01-07 10:32:41 - progress_bar.py[line:274] - INFO: epoch 001:  17974 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4652, wps=101.3, ups=0.46, wpb=110, bsz=40, num_updates=17950, lr=4.40128e-05, gnorm=0.251, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=70996
2023-01-07 10:33:03 - progress_bar.py[line:274] - INFO: epoch 001:  17984 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4527, wps=99.9, ups=0.46, wpb=107.6, bsz=40, num_updates=17960, lr=4.40083e-05, gnorm=0.291, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=71019
2023-01-07 10:33:25 - progress_bar.py[line:274] - INFO: epoch 001:  17994 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4945, wps=104.7, ups=0.48, wpb=110.1, bsz=40, num_updates=17970, lr=4.40038e-05, gnorm=0.192, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=71040
2023-01-07 10:33:47 - progress_bar.py[line:274] - INFO: epoch 001:  18004 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4244, wps=99.6, ups=0.46, wpb=108.1, bsz=40, num_updates=17980, lr=4.39993e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=71063
2023-01-07 10:34:09 - progress_bar.py[line:274] - INFO: epoch 001:  18014 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.415, wps=105.3, ups=0.48, wpb=109.6, bsz=40, num_updates=17990, lr=4.39948e-05, gnorm=0.351, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=71084
2023-01-07 10:34:31 - progress_bar.py[line:274] - INFO: epoch 001:  18024 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.434, wps=100.9, ups=0.47, wpb=108.3, bsz=40, num_updates=18000, lr=4.39903e-05, gnorm=0.3, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=71106
2023-01-07 10:34:31 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 10:34:32 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 10:34:32 - train.py[line:551] - INFO: load:1.16 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 10:37:05 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 10:37:05 - train.py[line:551] - INFO: load:1.19 valid_run:152.28 task_valid:148.26 collect_output:2.94
2023-01-07 10:39:34 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 10:39:34 - train.py[line:551] - INFO: load:1.21 valid_run:301.30 task_valid:290.85 collect_output:8.35
2023-01-07 10:42:07 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 10:42:07 - train.py[line:551] - INFO: load:1.24 valid_run:454.45 task_valid:433.51 collect_output:17.82
2023-01-07 10:44:36 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 10:44:36 - train.py[line:551] - INFO: load:1.26 valid_run:603.80 task_valid:578.03 collect_output:21.64
2023-01-07 10:47:09 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 10:47:09 - train.py[line:551] - INFO: load:1.29 valid_run:756.83 task_valid:725.29 collect_output:26.36
2023-01-07 10:49:42 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 10:49:42 - train.py[line:551] - INFO: load:1.32 valid_run:909.01 task_valid:870.38 collect_output:32.45
2023-01-07 10:52:18 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 10:52:18 - train.py[line:551] - INFO: load:1.34 valid_run:1065.40 task_valid:1016.56 collect_output:41.62
2023-01-07 10:54:51 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 10:54:51 - train.py[line:551] - INFO: load:1.37 valid_run:1217.79 task_valid:1157.13 collect_output:52.43
2023-01-07 10:57:21 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 10:57:21 - train.py[line:551] - INFO: load:1.40 valid_run:1368.14 task_valid:1301.76 collect_output:57.13
2023-01-07 10:59:50 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 10:59:50 - train.py[line:551] - INFO: load:1.42 valid_run:1517.34 task_valid:1444.53 collect_output:62.55
2023-01-07 11:02:21 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 11:02:21 - train.py[line:551] - INFO: load:1.45 valid_run:1667.52 task_valid:1589.14 collect_output:67.08
2023-01-07 11:04:51 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 11:04:51 - train.py[line:551] - INFO: load:1.48 valid_run:1818.04 task_valid:1733.69 collect_output:72.01
2023-01-07 11:07:22 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 11:07:22 - train.py[line:551] - INFO: load:1.51 valid_run:1968.87 task_valid:1875.44 collect_output:80.09
2023-01-07 11:09:53 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 11:09:53 - train.py[line:551] - INFO: load:1.53 valid_run:2119.85 task_valid:2020.63 collect_output:84.86
2023-01-07 11:12:23 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 11:12:23 - train.py[line:551] - INFO: load:1.56 valid_run:2269.95 task_valid:2166.79 collect_output:87.79
2023-01-07 11:14:54 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 11:14:54 - train.py[line:551] - INFO: load:1.59 valid_run:2420.47 task_valid:2310.56 collect_output:93.54
2023-01-07 11:17:26 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 11:17:26 - train.py[line:551] - INFO: load:1.61 valid_run:2572.81 task_valid:2455.90 collect_output:99.54
2023-01-07 11:19:57 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 11:19:57 - train.py[line:551] - INFO: load:1.64 valid_run:2723.66 task_valid:2602.48 collect_output:102.81
2023-01-07 11:22:26 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 11:22:26 - train.py[line:551] - INFO: load:1.67 valid_run:2872.75 task_valid:2743.71 collect_output:109.65
2023-01-07 11:24:57 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 11:24:57 - train.py[line:551] - INFO: load:1.70 valid_run:3023.60 task_valid:2888.62 collect_output:114.59
2023-01-07 11:27:30 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 11:27:30 - train.py[line:551] - INFO: load:1.72 valid_run:3176.48 task_valid:3033.32 collect_output:121.76
2023-01-07 11:30:00 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 11:30:00 - train.py[line:551] - INFO: load:1.75 valid_run:3326.48 task_valid:3177.85 collect_output:126.20
2023-01-07 11:32:32 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 11:32:32 - train.py[line:551] - INFO: load:1.78 valid_run:3478.21 task_valid:3323.84 collect_output:130.94
2023-01-07 11:35:04 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 11:35:04 - train.py[line:551] - INFO: load:1.80 valid_run:3629.78 task_valid:3470.06 collect_output:135.29

====================================================================================================
SGG eval:     R @ 50: 0.4171;     R @ 100: 0.4813;     R @ 500: 0.5214;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2599;    mR @ 100: 0.3154;    mR @ 500: 0.3536;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4341) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.7812) (playing:0.0000) (riding:0.5147) (says:0.0000) (sitting on:0.7168) (standing on:0.2033) (using:0.6500) (walking in:0.0000) (walking on:0.2432) (watching:0.0972) 
--------------------------------------------------------
====================================================================================================

2023-01-07 11:37:35 - train.py[line:487] - INFO: 0.4812952380952381

====================================================================================================
SGG eval:     R @ 50: 0.4171;     R @ 100: 0.4813;     R @ 500: 0.5214;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2599;    mR @ 100: 0.3154;    mR @ 500: 0.3536;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4341) (covered in:0.8125) (covering:0.3714) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.7812) (playing:0.0000) (riding:0.5147) (says:0.0000) (sitting on:0.7168) (standing on:0.2033) (using:0.6500) (walking in:0.0000) (walking on:0.2432) (watching:0.0972) 
--------------------------------------------------------
====================================================================================================

2023-01-07 11:37:35 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 11:37:36 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.373 | loss_v1 0 | loss_v2 0 | nll_loss 0.223 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.481295 | ppl 1.17 | vqa_score 0.4088 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 18000 | best_R@100 0.641887
2023-01-07 11:37:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 18000 updates
2023-01-07 11:37:36 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_18000.pt
2023-01-07 11:38:19 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_18000.pt
2023-01-07 11:39:53 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_18000.pt (epoch 1 @ 18000 updates, score 0.4812952380952381) (writing took 137.01967156492174 seconds)
2023-01-07 11:40:16 - progress_bar.py[line:274] - INFO: epoch 001:  18034 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3889, wps=0.6, ups=0, wpb=109.3, bsz=40, num_updates=18010, lr=4.39858e-05, gnorm=0.353, clip=10, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=75051
2023-01-07 11:40:38 - progress_bar.py[line:274] - INFO: epoch 001:  18044 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4158, wps=101.3, ups=0.46, wpb=109.4, bsz=40, num_updates=18020, lr=4.39813e-05, gnorm=0.279, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75073
2023-01-07 11:41:00 - progress_bar.py[line:274] - INFO: epoch 001:  18054 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4555, wps=103.4, ups=0.47, wpb=109.2, bsz=40, num_updates=18030, lr=4.39768e-05, gnorm=0.343, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75095
2023-01-07 11:41:23 - progress_bar.py[line:274] - INFO: epoch 001:  18064 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4292, wps=98.7, ups=0.46, wpb=107.6, bsz=40, num_updates=18040, lr=4.39723e-05, gnorm=0.266, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75118
2023-01-07 11:41:44 - progress_bar.py[line:274] - INFO: epoch 001:  18074 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4105, wps=103.7, ups=0.47, wpb=109.5, bsz=40, num_updates=18050, lr=4.39678e-05, gnorm=0.224, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75140
2023-01-07 11:42:06 - progress_bar.py[line:274] - INFO: epoch 001:  18084 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4138, wps=104.2, ups=0.48, wpb=109.4, bsz=40, num_updates=18060, lr=4.39633e-05, gnorm=0.331, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=75162
2023-01-07 11:42:29 - progress_bar.py[line:274] - INFO: epoch 001:  18094 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4808, wps=101.2, ups=0.46, wpb=109.2, bsz=40, num_updates=18070, lr=4.39588e-05, gnorm=0.203, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75184
2023-01-07 11:42:51 - progress_bar.py[line:274] - INFO: epoch 001:  18104 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4352, wps=103.7, ups=0.47, wpb=109.8, bsz=40, num_updates=18080, lr=4.39543e-05, gnorm=0.293, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=75206
2023-01-07 11:43:13 - progress_bar.py[line:274] - INFO: epoch 001:  18114 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4638, wps=100, ups=0.46, wpb=109.2, bsz=40, num_updates=18090, lr=4.39498e-05, gnorm=0.44, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75229
2023-01-07 11:43:35 - progress_bar.py[line:274] - INFO: epoch 001:  18124 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.42, wps=102.7, ups=0.47, wpb=109.5, bsz=40, num_updates=18100, lr=4.39453e-05, gnorm=0.248, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=75250
2023-01-07 11:43:58 - progress_bar.py[line:274] - INFO: epoch 001:  18134 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4109, wps=99.4, ups=0.46, wpb=108.9, bsz=40, num_updates=18110, lr=4.39409e-05, gnorm=0.385, clip=10, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=75273
2023-01-07 11:44:20 - progress_bar.py[line:274] - INFO: epoch 001:  18144 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4884, wps=100.8, ups=0.47, wpb=108, bsz=40, num_updates=18120, lr=4.39364e-05, gnorm=0.237, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=75295
2023-01-07 11:44:42 - progress_bar.py[line:274] - INFO: epoch 001:  18154 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4133, wps=100.2, ups=0.46, wpb=108.6, bsz=40, num_updates=18130, lr=4.39319e-05, gnorm=0.376, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75318
2023-01-07 11:45:03 - progress_bar.py[line:274] - INFO: epoch 001:  18164 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4272, wps=102.9, ups=0.47, wpb=109, bsz=40, num_updates=18140, lr=4.39274e-05, gnorm=0.223, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75339
2023-01-07 11:45:25 - progress_bar.py[line:274] - INFO: epoch 001:  18174 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.462, wps=103.2, ups=0.46, wpb=111.2, bsz=40, num_updates=18150, lr=4.39229e-05, gnorm=0.286, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75361
2023-01-07 11:45:47 - progress_bar.py[line:274] - INFO: epoch 001:  18184 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4802, wps=102.8, ups=0.46, wpb=111.6, bsz=40, num_updates=18160, lr=4.39184e-05, gnorm=0.405, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=75383
2023-01-07 11:46:09 - progress_bar.py[line:274] - INFO: epoch 001:  18194 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4314, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=18170, lr=4.39139e-05, gnorm=0.395, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=75405
2023-01-07 11:46:31 - progress_bar.py[line:274] - INFO: epoch 001:  18204 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.545, wps=99.9, ups=0.46, wpb=107.8, bsz=40, num_updates=18180, lr=4.39094e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=75426
2023-01-07 11:46:52 - progress_bar.py[line:274] - INFO: epoch 001:  18214 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5323, wps=101.6, ups=0.46, wpb=109.5, bsz=40, num_updates=18190, lr=4.39049e-05, gnorm=0.159, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75448
2023-01-07 11:47:14 - progress_bar.py[line:274] - INFO: epoch 001:  18224 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4408, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=18200, lr=4.39004e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=75470
2023-01-07 11:47:36 - progress_bar.py[line:274] - INFO: epoch 001:  18234 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=106.8, nsentences=40, sample_size=106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4933, wps=99, ups=0.46, wpb=106.8, bsz=40, num_updates=18210, lr=4.38959e-05, gnorm=0.247, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=75492
2023-01-07 11:47:58 - progress_bar.py[line:274] - INFO: epoch 001:  18244 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4392, wps=101.8, ups=0.46, wpb=110, bsz=40, num_updates=18220, lr=4.38914e-05, gnorm=0.291, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=75514
2023-01-07 11:48:19 - progress_bar.py[line:274] - INFO: epoch 001:  18254 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4, wps=103.6, ups=0.48, wpb=108.8, bsz=40, num_updates=18230, lr=4.38869e-05, gnorm=0.278, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75535
2023-01-07 11:48:41 - progress_bar.py[line:274] - INFO: epoch 001:  18264 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3905, wps=101.8, ups=0.46, wpb=109.7, bsz=40, num_updates=18240, lr=4.38824e-05, gnorm=0.383, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75557
2023-01-07 11:49:03 - progress_bar.py[line:274] - INFO: epoch 001:  18274 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.399, wps=100.7, ups=0.47, wpb=107.3, bsz=40, num_updates=18250, lr=4.38779e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=75578
2023-01-07 11:49:24 - progress_bar.py[line:274] - INFO: epoch 001:  18284 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4365, wps=101.5, ups=0.47, wpb=108.7, bsz=40, num_updates=18260, lr=4.38734e-05, gnorm=0.268, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75600
2023-01-07 11:49:46 - progress_bar.py[line:274] - INFO: epoch 001:  18294 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4372, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=18270, lr=4.38689e-05, gnorm=0.298, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=75622
2023-01-07 11:50:08 - progress_bar.py[line:274] - INFO: epoch 001:  18304 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3696, wps=107.8, ups=0.48, wpb=112.1, bsz=40, num_updates=18280, lr=4.38644e-05, gnorm=0.143, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=75643
2023-01-07 11:50:25 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 11:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  18315 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.619, nsentences=40, sample_size=109.619, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5092, wps=99.2, ups=0.43, wpb=109.6, bsz=40, num_updates=18290, lr=4.38599e-05, gnorm=0.446, clip=10, loss_scale=512, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=75667
2023-01-07 11:50:53 - progress_bar.py[line:274] - INFO: epoch 001:  18325 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5253, wps=101, ups=0.47, wpb=108.1, bsz=40, num_updates=18300, lr=4.38554e-05, gnorm=0.243, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=75688
2023-01-07 11:51:15 - progress_bar.py[line:274] - INFO: epoch 001:  18335 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4138, wps=100.8, ups=0.46, wpb=108.8, bsz=40, num_updates=18310, lr=4.38509e-05, gnorm=0.285, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=75710
2023-01-07 11:51:36 - progress_bar.py[line:274] - INFO: epoch 001:  18345 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4527, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=18320, lr=4.38464e-05, gnorm=0.325, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75732
2023-01-07 11:51:58 - progress_bar.py[line:274] - INFO: epoch 001:  18355 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4162, wps=100.1, ups=0.46, wpb=108.7, bsz=40, num_updates=18330, lr=4.38419e-05, gnorm=0.409, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=75754
2023-01-07 11:52:20 - progress_bar.py[line:274] - INFO: epoch 001:  18365 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.43, wps=100.3, ups=0.46, wpb=109, bsz=40, num_updates=18340, lr=4.38374e-05, gnorm=0.421, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=75776
2023-01-07 11:52:42 - progress_bar.py[line:274] - INFO: epoch 001:  18375 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4143, wps=100.9, ups=0.47, wpb=107.6, bsz=40, num_updates=18350, lr=4.38329e-05, gnorm=0.318, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75798
2023-01-07 11:53:04 - progress_bar.py[line:274] - INFO: epoch 001:  18385 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4406, wps=102.6, ups=0.47, wpb=109.5, bsz=40, num_updates=18360, lr=4.38285e-05, gnorm=0.165, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75819
2023-01-07 11:53:26 - progress_bar.py[line:274] - INFO: epoch 001:  18395 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4227, wps=98.8, ups=0.45, wpb=108.6, bsz=40, num_updates=18370, lr=4.3824e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=75842
2023-01-07 11:53:48 - progress_bar.py[line:274] - INFO: epoch 001:  18405 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5279, wps=101.1, ups=0.47, wpb=108.2, bsz=40, num_updates=18380, lr=4.38195e-05, gnorm=0.348, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=75863
2023-01-07 11:54:10 - progress_bar.py[line:274] - INFO: epoch 001:  18415 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4389, wps=101.7, ups=0.46, wpb=109.5, bsz=40, num_updates=18390, lr=4.3815e-05, gnorm=0.248, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75885
2023-01-07 11:54:31 - progress_bar.py[line:274] - INFO: epoch 001:  18425 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3894, wps=102.9, ups=0.47, wpb=109.7, bsz=40, num_updates=18400, lr=4.38105e-05, gnorm=0.319, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=75907
2023-01-07 11:54:53 - progress_bar.py[line:274] - INFO: epoch 001:  18435 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4595, wps=102, ups=0.47, wpb=109.6, bsz=40, num_updates=18410, lr=4.3806e-05, gnorm=0.427, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=75929
2023-01-07 11:55:15 - progress_bar.py[line:274] - INFO: epoch 001:  18445 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.481, wps=101.8, ups=0.47, wpb=109.3, bsz=40, num_updates=18420, lr=4.38015e-05, gnorm=0.311, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=75950
2023-01-07 11:55:36 - progress_bar.py[line:274] - INFO: epoch 001:  18455 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.46, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=18430, lr=4.3797e-05, gnorm=0.245, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=75972
2023-01-07 11:55:58 - progress_bar.py[line:274] - INFO: epoch 001:  18465 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.401, wps=102.1, ups=0.47, wpb=108.7, bsz=40, num_updates=18440, lr=4.37925e-05, gnorm=0.243, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=75994
2023-01-07 11:56:19 - progress_bar.py[line:274] - INFO: epoch 001:  18475 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4384, wps=100.8, ups=0.47, wpb=108.3, bsz=40, num_updates=18450, lr=4.3788e-05, gnorm=0.359, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76015
2023-01-07 11:56:41 - progress_bar.py[line:274] - INFO: epoch 001:  18485 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.42, wps=101.7, ups=0.47, wpb=109, bsz=40, num_updates=18460, lr=4.37835e-05, gnorm=0.33, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76037
2023-01-07 11:57:03 - progress_bar.py[line:274] - INFO: epoch 001:  18495 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4121, wps=101.8, ups=0.47, wpb=109.2, bsz=40, num_updates=18470, lr=4.3779e-05, gnorm=0.216, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=76059
2023-01-07 11:57:25 - progress_bar.py[line:274] - INFO: epoch 001:  18505 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4718, wps=102.3, ups=0.47, wpb=109.9, bsz=40, num_updates=18480, lr=4.37745e-05, gnorm=0.519, clip=10, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=76080
2023-01-07 11:57:46 - progress_bar.py[line:274] - INFO: epoch 001:  18515 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4747, wps=102.1, ups=0.47, wpb=109.3, bsz=40, num_updates=18490, lr=4.377e-05, gnorm=0.278, clip=0, loss_scale=512, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=76102
2023-01-07 11:58:08 - progress_bar.py[line:274] - INFO: epoch 001:  18525 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4769, wps=103.3, ups=0.47, wpb=110, bsz=40, num_updates=18500, lr=4.37655e-05, gnorm=0.196, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76124
2023-01-07 11:58:30 - progress_bar.py[line:274] - INFO: epoch 001:  18535 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4189, wps=99.4, ups=0.46, wpb=108.3, bsz=40, num_updates=18510, lr=4.3761e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76146
2023-01-07 11:58:52 - progress_bar.py[line:274] - INFO: epoch 001:  18545 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4541, wps=102.5, ups=0.47, wpb=109.4, bsz=40, num_updates=18520, lr=4.37565e-05, gnorm=0.436, clip=20, loss_scale=512, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=76167
2023-01-07 11:59:14 - progress_bar.py[line:274] - INFO: epoch 001:  18555 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4485, wps=99.8, ups=0.46, wpb=108.3, bsz=40, num_updates=18530, lr=4.3752e-05, gnorm=0.262, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76190
2023-01-07 11:59:35 - progress_bar.py[line:274] - INFO: epoch 001:  18565 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4022, wps=102.7, ups=0.47, wpb=109.9, bsz=40, num_updates=18540, lr=4.37475e-05, gnorm=0.333, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=76211
2023-01-07 11:59:58 - progress_bar.py[line:274] - INFO: epoch 001:  18575 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3623, wps=98.9, ups=0.46, wpb=108, bsz=40, num_updates=18550, lr=4.3743e-05, gnorm=0.212, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76233
2023-01-07 12:00:19 - progress_bar.py[line:274] - INFO: epoch 001:  18585 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4815, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=18560, lr=4.37385e-05, gnorm=0.367, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=76255
2023-01-07 12:00:41 - progress_bar.py[line:274] - INFO: epoch 001:  18595 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4819, wps=103.6, ups=0.47, wpb=110.2, bsz=40, num_updates=18570, lr=4.3734e-05, gnorm=0.225, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76277
2023-01-07 12:01:03 - progress_bar.py[line:274] - INFO: epoch 001:  18605 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4541, wps=103, ups=0.47, wpb=109.8, bsz=40, num_updates=18580, lr=4.37295e-05, gnorm=0.208, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76298
2023-01-07 12:01:24 - progress_bar.py[line:274] - INFO: epoch 001:  18615 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4471, wps=103, ups=0.48, wpb=108.1, bsz=40, num_updates=18590, lr=4.3725e-05, gnorm=0.32, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76320
2023-01-07 12:01:45 - progress_bar.py[line:274] - INFO: epoch 001:  18625 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4179, wps=104.9, ups=0.48, wpb=108.5, bsz=40, num_updates=18600, lr=4.37206e-05, gnorm=0.241, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76341
2023-01-07 12:02:07 - progress_bar.py[line:274] - INFO: epoch 001:  18635 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3526, wps=101.8, ups=0.46, wpb=110.5, bsz=40, num_updates=18610, lr=4.37161e-05, gnorm=0.208, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=76363
2023-01-07 12:02:28 - progress_bar.py[line:274] - INFO: epoch 001:  18645 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4717, wps=100.9, ups=0.47, wpb=108.2, bsz=40, num_updates=18620, lr=4.37116e-05, gnorm=0.452, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76384
2023-01-07 12:02:50 - progress_bar.py[line:274] - INFO: epoch 001:  18655 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4512, wps=100.9, ups=0.47, wpb=107.4, bsz=40, num_updates=18630, lr=4.37071e-05, gnorm=0.286, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76406
2023-01-07 12:03:12 - progress_bar.py[line:274] - INFO: epoch 001:  18665 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4155, wps=99.5, ups=0.46, wpb=108.6, bsz=40, num_updates=18640, lr=4.37026e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=76428
2023-01-07 12:03:34 - progress_bar.py[line:274] - INFO: epoch 001:  18675 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4829, wps=100.3, ups=0.47, wpb=107.2, bsz=40, num_updates=18650, lr=4.36981e-05, gnorm=0.289, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=76450
2023-01-07 12:03:55 - progress_bar.py[line:274] - INFO: epoch 001:  18685 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4575, wps=103, ups=0.47, wpb=109.5, bsz=40, num_updates=18660, lr=4.36936e-05, gnorm=0.415, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76471
2023-01-07 12:04:18 - progress_bar.py[line:274] - INFO: epoch 001:  18695 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4221, wps=99, ups=0.45, wpb=108.9, bsz=40, num_updates=18670, lr=4.36891e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76493
2023-01-07 12:04:39 - progress_bar.py[line:274] - INFO: epoch 001:  18705 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4466, wps=100.3, ups=0.46, wpb=108.4, bsz=40, num_updates=18680, lr=4.36846e-05, gnorm=0.285, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=76515
2023-01-07 12:05:01 - progress_bar.py[line:274] - INFO: epoch 001:  18715 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4278, wps=99.9, ups=0.46, wpb=108.9, bsz=40, num_updates=18690, lr=4.36801e-05, gnorm=0.389, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=76537
2023-01-07 12:05:23 - progress_bar.py[line:274] - INFO: epoch 001:  18725 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4627, wps=101, ups=0.46, wpb=108.6, bsz=40, num_updates=18700, lr=4.36756e-05, gnorm=0.479, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76559
2023-01-07 12:05:45 - progress_bar.py[line:274] - INFO: epoch 001:  18735 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4922, wps=102.7, ups=0.47, wpb=110.4, bsz=40, num_updates=18710, lr=4.36711e-05, gnorm=0.404, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76581
2023-01-07 12:06:07 - progress_bar.py[line:274] - INFO: epoch 001:  18745 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4776, wps=103.2, ups=0.47, wpb=110.2, bsz=40, num_updates=18720, lr=4.36666e-05, gnorm=0.333, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76602
2023-01-07 12:06:29 - progress_bar.py[line:274] - INFO: epoch 001:  18755 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4536, wps=102.9, ups=0.46, wpb=111.8, bsz=40, num_updates=18730, lr=4.36621e-05, gnorm=0.269, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76624
2023-01-07 12:06:51 - progress_bar.py[line:274] - INFO: epoch 001:  18765 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4423, wps=100.3, ups=0.46, wpb=108.9, bsz=40, num_updates=18740, lr=4.36576e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76646
2023-01-07 12:06:55 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 12:07:14 - progress_bar.py[line:274] - INFO: epoch 001:  18776 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.762, nsentences=40, sample_size=109.762, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4907, wps=101.2, ups=0.44, wpb=109.8, bsz=40, num_updates=18750, lr=4.36531e-05, gnorm=0.268, clip=0, loss_scale=256, train_wall=23, gb_free=10.4, ema_decay=0.9999, wall=76669
2023-01-07 12:07:35 - progress_bar.py[line:274] - INFO: epoch 001:  18786 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4764, wps=101.7, ups=0.47, wpb=108.9, bsz=40, num_updates=18760, lr=4.36486e-05, gnorm=0.334, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76691
2023-01-07 12:07:57 - progress_bar.py[line:274] - INFO: epoch 001:  18796 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4498, wps=101.6, ups=0.47, wpb=108.2, bsz=40, num_updates=18770, lr=4.36441e-05, gnorm=0.277, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76713
2023-01-07 12:08:19 - progress_bar.py[line:274] - INFO: epoch 001:  18806 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.433, wps=99.7, ups=0.47, wpb=107.1, bsz=40, num_updates=18780, lr=4.36396e-05, gnorm=0.238, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=76734
2023-01-07 12:08:40 - progress_bar.py[line:274] - INFO: epoch 001:  18816 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.48, wps=102.3, ups=0.47, wpb=109.9, bsz=40, num_updates=18790, lr=4.36351e-05, gnorm=0.364, clip=0, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=76756
2023-01-07 12:09:02 - progress_bar.py[line:274] - INFO: epoch 001:  18826 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3978, wps=101.8, ups=0.47, wpb=109.3, bsz=40, num_updates=18800, lr=4.36306e-05, gnorm=0.336, clip=10, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76778
2023-01-07 12:09:24 - progress_bar.py[line:274] - INFO: epoch 001:  18836 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=99.4, ups=0.46, wpb=108, bsz=40, num_updates=18810, lr=4.36261e-05, gnorm=0.287, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76800
2023-01-07 12:09:46 - progress_bar.py[line:274] - INFO: epoch 001:  18846 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4603, wps=101, ups=0.46, wpb=109.5, bsz=40, num_updates=18820, lr=4.36216e-05, gnorm=0.352, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=76822
2023-01-07 12:10:08 - progress_bar.py[line:274] - INFO: epoch 001:  18856 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4746, wps=99.6, ups=0.47, wpb=107, bsz=40, num_updates=18830, lr=4.36171e-05, gnorm=0.261, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76844
2023-01-07 12:10:29 - progress_bar.py[line:274] - INFO: epoch 001:  18866 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.462, wps=102.6, ups=0.47, wpb=109.7, bsz=40, num_updates=18840, lr=4.36126e-05, gnorm=0.412, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=76865
2023-01-07 12:10:51 - progress_bar.py[line:274] - INFO: epoch 001:  18876 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5112, wps=101.4, ups=0.47, wpb=108.3, bsz=40, num_updates=18850, lr=4.36082e-05, gnorm=0.354, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76887
2023-01-07 12:11:12 - progress_bar.py[line:274] - INFO: epoch 001:  18886 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.385, wps=104.5, ups=0.48, wpb=108.9, bsz=40, num_updates=18860, lr=4.36037e-05, gnorm=0.304, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=76908
2023-01-07 12:11:33 - progress_bar.py[line:274] - INFO: epoch 001:  18896 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4778, wps=104.4, ups=0.47, wpb=110.6, bsz=40, num_updates=18870, lr=4.35992e-05, gnorm=0.195, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76929
2023-01-07 12:11:55 - progress_bar.py[line:274] - INFO: epoch 001:  18906 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4681, wps=102.2, ups=0.46, wpb=109.9, bsz=40, num_updates=18880, lr=4.35947e-05, gnorm=0.254, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=76951
2023-01-07 12:12:17 - progress_bar.py[line:274] - INFO: epoch 001:  18916 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5077, wps=99.7, ups=0.46, wpb=108.4, bsz=40, num_updates=18890, lr=4.35902e-05, gnorm=0.258, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=76973
2023-01-07 12:12:40 - progress_bar.py[line:274] - INFO: epoch 001:  18926 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4365, wps=101.5, ups=0.46, wpb=111, bsz=40, num_updates=18900, lr=4.35857e-05, gnorm=0.259, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=76995
2023-01-07 12:13:01 - progress_bar.py[line:274] - INFO: epoch 001:  18936 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4839, wps=101.9, ups=0.47, wpb=107.9, bsz=40, num_updates=18910, lr=4.35812e-05, gnorm=0.2, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=77017
2023-01-07 12:13:23 - progress_bar.py[line:274] - INFO: epoch 001:  18946 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4264, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=18920, lr=4.35767e-05, gnorm=0.224, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77039
2023-01-07 12:13:45 - progress_bar.py[line:274] - INFO: epoch 001:  18956 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5077, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=18930, lr=4.35722e-05, gnorm=0.29, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=77061
2023-01-07 12:14:07 - progress_bar.py[line:274] - INFO: epoch 001:  18966 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4518, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=18940, lr=4.35677e-05, gnorm=0.306, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77082
2023-01-07 12:14:29 - progress_bar.py[line:274] - INFO: epoch 001:  18976 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4087, wps=101.3, ups=0.46, wpb=109.7, bsz=40, num_updates=18950, lr=4.35632e-05, gnorm=0.293, clip=10, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=77104
2023-01-07 12:14:50 - progress_bar.py[line:274] - INFO: epoch 001:  18986 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4402, wps=100.8, ups=0.47, wpb=107.3, bsz=40, num_updates=18960, lr=4.35587e-05, gnorm=0.258, clip=0, loss_scale=256, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=77126
2023-01-07 12:15:11 - progress_bar.py[line:274] - INFO: epoch 001:  18996 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4953, wps=104.3, ups=0.48, wpb=109.2, bsz=40, num_updates=18970, lr=4.35542e-05, gnorm=0.336, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77147
2023-01-07 12:15:33 - progress_bar.py[line:274] - INFO: epoch 001:  19006 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4627, wps=102.9, ups=0.47, wpb=109.4, bsz=40, num_updates=18980, lr=4.35497e-05, gnorm=0.188, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77169
2023-01-07 12:15:55 - progress_bar.py[line:274] - INFO: epoch 001:  19016 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4187, wps=99.2, ups=0.46, wpb=108, bsz=40, num_updates=18990, lr=4.35452e-05, gnorm=0.176, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=77191
2023-01-07 12:16:17 - progress_bar.py[line:274] - INFO: epoch 001:  19026 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.5046, wps=100, ups=0.46, wpb=108.4, bsz=40, num_updates=19000, lr=4.35407e-05, gnorm=0.324, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77213
2023-01-07 12:16:38 - progress_bar.py[line:274] - INFO: epoch 001:  19036 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4952, wps=103.1, ups=0.48, wpb=107.9, bsz=40, num_updates=19010, lr=4.35362e-05, gnorm=0.239, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77234
2023-01-07 12:16:59 - progress_bar.py[line:274] - INFO: epoch 001:  19046 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4385, wps=104.9, ups=0.48, wpb=109.7, bsz=40, num_updates=19020, lr=4.35317e-05, gnorm=0.148, clip=0, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=77255
2023-01-07 12:17:21 - progress_bar.py[line:274] - INFO: epoch 001:  19056 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4646, wps=104.3, ups=0.48, wpb=109.5, bsz=40, num_updates=19030, lr=4.35272e-05, gnorm=0.363, clip=10, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=77277
2023-01-07 12:17:42 - progress_bar.py[line:274] - INFO: epoch 001:  19066 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4492, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=19040, lr=4.35227e-05, gnorm=0.199, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77298
2023-01-07 12:18:04 - progress_bar.py[line:274] - INFO: epoch 001:  19076 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4925, wps=101.1, ups=0.46, wpb=109.1, bsz=40, num_updates=19050, lr=4.35182e-05, gnorm=0.329, clip=10, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=77320
2023-01-07 12:18:26 - progress_bar.py[line:274] - INFO: epoch 001:  19086 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.478, wps=101.4, ups=0.47, wpb=108.4, bsz=40, num_updates=19060, lr=4.35137e-05, gnorm=0.701, clip=10, loss_scale=256, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=77342
2023-01-07 12:18:48 - progress_bar.py[line:274] - INFO: epoch 001:  19096 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.467, wps=98.8, ups=0.46, wpb=106.9, bsz=40, num_updates=19070, lr=4.35092e-05, gnorm=0.223, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77364
2023-01-07 12:19:10 - progress_bar.py[line:274] - INFO: epoch 001:  19106 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.456, wps=102.7, ups=0.46, wpb=110.8, bsz=40, num_updates=19080, lr=4.35047e-05, gnorm=0.486, clip=0, loss_scale=256, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=77386
2023-01-07 12:19:32 - progress_bar.py[line:274] - INFO: epoch 001:  19116 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4343, wps=99.4, ups=0.46, wpb=108.4, bsz=40, num_updates=19090, lr=4.35003e-05, gnorm=0.172, clip=0, loss_scale=256, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=77408
2023-01-07 12:19:54 - progress_bar.py[line:274] - INFO: epoch 001:  19126 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.407, wps=101.5, ups=0.46, wpb=109.4, bsz=40, num_updates=19100, lr=4.34958e-05, gnorm=0.341, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77430
2023-01-07 12:20:16 - progress_bar.py[line:274] - INFO: epoch 001:  19136 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.45, wps=101.2, ups=0.46, wpb=109.4, bsz=40, num_updates=19110, lr=4.34913e-05, gnorm=0.3, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77451
2023-01-07 12:20:37 - progress_bar.py[line:274] - INFO: epoch 001:  19146 / 115845 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4326, wps=101.3, ups=0.47, wpb=108.8, bsz=40, num_updates=19120, lr=4.34868e-05, gnorm=0.296, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77473
2023-01-07 12:20:59 - progress_bar.py[line:274] - INFO: epoch 001:  19156 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.46, wps=100.4, ups=0.46, wpb=108.9, bsz=40, num_updates=19130, lr=4.34823e-05, gnorm=0.24, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77495
2023-01-07 12:21:21 - progress_bar.py[line:274] - INFO: epoch 001:  19166 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4115, wps=101.2, ups=0.47, wpb=108.6, bsz=40, num_updates=19140, lr=4.34778e-05, gnorm=0.419, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=77517
2023-01-07 12:21:43 - progress_bar.py[line:274] - INFO: epoch 001:  19176 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4126, wps=102.4, ups=0.46, wpb=110.2, bsz=40, num_updates=19150, lr=4.34733e-05, gnorm=0.236, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77539
2023-01-07 12:22:04 - progress_bar.py[line:274] - INFO: epoch 001:  19186 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4785, wps=104.4, ups=0.47, wpb=110.4, bsz=40, num_updates=19160, lr=4.34688e-05, gnorm=0.341, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77560
2023-01-07 12:22:26 - progress_bar.py[line:274] - INFO: epoch 001:  19196 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4263, wps=100.4, ups=0.46, wpb=108.6, bsz=40, num_updates=19170, lr=4.34643e-05, gnorm=0.42, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=77582
2023-01-07 12:22:48 - progress_bar.py[line:274] - INFO: epoch 001:  19206 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4422, wps=101.8, ups=0.47, wpb=109.2, bsz=40, num_updates=19180, lr=4.34598e-05, gnorm=0.338, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=77604
2023-01-07 12:23:10 - progress_bar.py[line:274] - INFO: epoch 001:  19216 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4706, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=19190, lr=4.34553e-05, gnorm=0.327, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77626
2023-01-07 12:23:32 - progress_bar.py[line:274] - INFO: epoch 001:  19226 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4471, wps=101, ups=0.46, wpb=109.4, bsz=40, num_updates=19200, lr=4.34508e-05, gnorm=0.183, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77648
2023-01-07 12:23:53 - progress_bar.py[line:274] - INFO: epoch 001:  19236 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.463, wps=103.6, ups=0.48, wpb=108.8, bsz=40, num_updates=19210, lr=4.34463e-05, gnorm=0.254, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77669
2023-01-07 12:24:15 - progress_bar.py[line:274] - INFO: epoch 001:  19246 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4328, wps=101.7, ups=0.46, wpb=110.1, bsz=40, num_updates=19220, lr=4.34418e-05, gnorm=0.452, clip=20, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=77691
2023-01-07 12:24:37 - progress_bar.py[line:274] - INFO: epoch 001:  19256 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4335, wps=103, ups=0.47, wpb=110.2, bsz=40, num_updates=19230, lr=4.34373e-05, gnorm=0.384, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=77713
2023-01-07 12:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  19266 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3978, wps=102.8, ups=0.47, wpb=109.8, bsz=40, num_updates=19240, lr=4.34328e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77734
2023-01-07 12:25:21 - progress_bar.py[line:274] - INFO: epoch 001:  19276 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4491, wps=98.1, ups=0.46, wpb=107.7, bsz=40, num_updates=19250, lr=4.34283e-05, gnorm=0.325, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=77757
2023-01-07 12:25:42 - progress_bar.py[line:274] - INFO: epoch 001:  19286 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4597, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=19260, lr=4.34238e-05, gnorm=0.336, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77778
2023-01-07 12:26:04 - progress_bar.py[line:274] - INFO: epoch 001:  19296 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5026, wps=102.3, ups=0.46, wpb=110.2, bsz=40, num_updates=19270, lr=4.34193e-05, gnorm=0.223, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=77800
2023-01-07 12:26:26 - progress_bar.py[line:274] - INFO: epoch 001:  19306 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=100.3, ups=0.46, wpb=109, bsz=40, num_updates=19280, lr=4.34148e-05, gnorm=0.188, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=77822
2023-01-07 12:26:48 - progress_bar.py[line:274] - INFO: epoch 001:  19316 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.481, wps=103.4, ups=0.47, wpb=110.3, bsz=40, num_updates=19290, lr=4.34103e-05, gnorm=0.29, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77844
2023-01-07 12:27:10 - progress_bar.py[line:274] - INFO: epoch 001:  19326 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3891, wps=99.3, ups=0.46, wpb=107.6, bsz=40, num_updates=19300, lr=4.34058e-05, gnorm=0.554, clip=20, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77866
2023-01-07 12:27:31 - progress_bar.py[line:274] - INFO: epoch 001:  19336 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4133, wps=100.1, ups=0.47, wpb=107.4, bsz=40, num_updates=19310, lr=4.34013e-05, gnorm=0.265, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77887
2023-01-07 12:27:53 - progress_bar.py[line:274] - INFO: epoch 001:  19346 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4251, wps=101.9, ups=0.47, wpb=108.8, bsz=40, num_updates=19320, lr=4.33968e-05, gnorm=0.394, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77909
2023-01-07 12:28:15 - progress_bar.py[line:274] - INFO: epoch 001:  19356 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5094, wps=99.4, ups=0.46, wpb=107.4, bsz=40, num_updates=19330, lr=4.33923e-05, gnorm=0.218, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=77931
2023-01-07 12:28:37 - progress_bar.py[line:274] - INFO: epoch 001:  19366 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4175, wps=100, ups=0.47, wpb=107.4, bsz=40, num_updates=19340, lr=4.33879e-05, gnorm=0.283, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=77952
2023-01-07 12:28:59 - progress_bar.py[line:274] - INFO: epoch 001:  19376 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4615, wps=99.5, ups=0.46, wpb=108, bsz=40, num_updates=19350, lr=4.33834e-05, gnorm=0.217, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=77974
2023-01-07 12:29:20 - progress_bar.py[line:274] - INFO: epoch 001:  19386 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=19360, lr=4.33789e-05, gnorm=0.261, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=77996
2023-01-07 12:29:42 - progress_bar.py[line:274] - INFO: epoch 001:  19396 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4229, wps=100.6, ups=0.46, wpb=109, bsz=40, num_updates=19370, lr=4.33744e-05, gnorm=0.429, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=78018
2023-01-07 12:30:04 - progress_bar.py[line:274] - INFO: epoch 001:  19406 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4483, wps=101.6, ups=0.47, wpb=108.1, bsz=40, num_updates=19380, lr=4.33699e-05, gnorm=0.413, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78040
2023-01-07 12:30:26 - progress_bar.py[line:274] - INFO: epoch 001:  19416 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4595, wps=102.7, ups=0.46, wpb=110.8, bsz=40, num_updates=19390, lr=4.33654e-05, gnorm=0.227, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=78062
2023-01-07 12:30:47 - progress_bar.py[line:274] - INFO: epoch 001:  19426 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4417, wps=103.9, ups=0.47, wpb=109.5, bsz=40, num_updates=19400, lr=4.33609e-05, gnorm=0.531, clip=20, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78083
2023-01-07 12:31:09 - progress_bar.py[line:274] - INFO: epoch 001:  19436 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4585, wps=99.9, ups=0.46, wpb=108.9, bsz=40, num_updates=19410, lr=4.33564e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=78105
2023-01-07 12:31:31 - progress_bar.py[line:274] - INFO: epoch 001:  19446 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4251, wps=101.6, ups=0.47, wpb=108.4, bsz=40, num_updates=19420, lr=4.33519e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=78127
2023-01-07 12:31:53 - progress_bar.py[line:274] - INFO: epoch 001:  19456 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4238, wps=99.5, ups=0.47, wpb=107, bsz=40, num_updates=19430, lr=4.33474e-05, gnorm=0.377, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=78148
2023-01-07 12:32:15 - progress_bar.py[line:274] - INFO: epoch 001:  19466 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4225, wps=97.7, ups=0.45, wpb=107.7, bsz=40, num_updates=19440, lr=4.33429e-05, gnorm=0.312, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=78171
2023-01-07 12:32:37 - progress_bar.py[line:274] - INFO: epoch 001:  19476 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4627, wps=98.9, ups=0.46, wpb=108.4, bsz=40, num_updates=19450, lr=4.33384e-05, gnorm=0.279, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=78193
2023-01-07 12:32:59 - progress_bar.py[line:274] - INFO: epoch 001:  19486 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3797, wps=103.1, ups=0.47, wpb=109.6, bsz=40, num_updates=19460, lr=4.33339e-05, gnorm=0.325, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78215
2023-01-07 12:33:21 - progress_bar.py[line:274] - INFO: epoch 001:  19496 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=100.9, ups=0.46, wpb=109.6, bsz=40, num_updates=19470, lr=4.33294e-05, gnorm=0.293, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=78236
2023-01-07 12:33:43 - progress_bar.py[line:274] - INFO: epoch 001:  19506 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4293, wps=100, ups=0.46, wpb=108.6, bsz=40, num_updates=19480, lr=4.33249e-05, gnorm=0.213, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=78259
2023-01-07 12:34:04 - progress_bar.py[line:274] - INFO: epoch 001:  19516 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.401, wps=102.1, ups=0.47, wpb=108.6, bsz=40, num_updates=19490, lr=4.33204e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78280
2023-01-07 12:34:26 - progress_bar.py[line:274] - INFO: epoch 001:  19526 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4363, wps=100.7, ups=0.46, wpb=108.5, bsz=40, num_updates=19500, lr=4.33159e-05, gnorm=0.242, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78302
2023-01-07 12:34:48 - progress_bar.py[line:274] - INFO: epoch 001:  19536 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4317, wps=100.8, ups=0.46, wpb=109.6, bsz=40, num_updates=19510, lr=4.33114e-05, gnorm=0.252, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=78324
2023-01-07 12:35:10 - progress_bar.py[line:274] - INFO: epoch 001:  19546 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4524, wps=102.1, ups=0.47, wpb=108.2, bsz=40, num_updates=19520, lr=4.33069e-05, gnorm=0.376, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78345
2023-01-07 12:35:31 - progress_bar.py[line:274] - INFO: epoch 001:  19556 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5076, wps=101.3, ups=0.46, wpb=109, bsz=40, num_updates=19530, lr=4.33024e-05, gnorm=0.211, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=78367
2023-01-07 12:35:53 - progress_bar.py[line:274] - INFO: epoch 001:  19566 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4813, wps=102.8, ups=0.47, wpb=110.4, bsz=40, num_updates=19540, lr=4.32979e-05, gnorm=0.191, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78389
2023-01-07 12:36:15 - progress_bar.py[line:274] - INFO: epoch 001:  19576 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5178, wps=102.1, ups=0.47, wpb=108.2, bsz=40, num_updates=19550, lr=4.32934e-05, gnorm=0.291, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78410
2023-01-07 12:36:36 - progress_bar.py[line:274] - INFO: epoch 001:  19586 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.388, wps=102.3, ups=0.46, wpb=110.4, bsz=40, num_updates=19560, lr=4.32889e-05, gnorm=0.282, clip=0, loss_scale=512, train_wall=22, gb_free=9.5, ema_decay=0.9999, wall=78432
2023-01-07 12:36:58 - progress_bar.py[line:274] - INFO: epoch 001:  19596 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4821, wps=103.6, ups=0.47, wpb=109.5, bsz=40, num_updates=19570, lr=4.32844e-05, gnorm=0.273, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=78454
2023-01-07 12:37:20 - progress_bar.py[line:274] - INFO: epoch 001:  19606 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4878, wps=100.3, ups=0.46, wpb=107.9, bsz=40, num_updates=19580, lr=4.328e-05, gnorm=0.387, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78475
2023-01-07 12:37:42 - progress_bar.py[line:274] - INFO: epoch 001:  19616 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4619, wps=100.3, ups=0.46, wpb=109.7, bsz=40, num_updates=19590, lr=4.32755e-05, gnorm=0.177, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=78498
2023-01-07 12:38:04 - progress_bar.py[line:274] - INFO: epoch 001:  19626 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3618, wps=101.1, ups=0.46, wpb=109.8, bsz=40, num_updates=19600, lr=4.3271e-05, gnorm=0.226, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=78519
2023-01-07 12:38:26 - progress_bar.py[line:274] - INFO: epoch 001:  19636 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5099, wps=100.6, ups=0.46, wpb=110.1, bsz=40, num_updates=19610, lr=4.32665e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=78542
2023-01-07 12:38:47 - progress_bar.py[line:274] - INFO: epoch 001:  19646 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4257, wps=102.8, ups=0.47, wpb=108.7, bsz=40, num_updates=19620, lr=4.3262e-05, gnorm=0.234, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78563
2023-01-07 12:39:09 - progress_bar.py[line:274] - INFO: epoch 001:  19656 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4244, wps=102, ups=0.47, wpb=109.2, bsz=40, num_updates=19630, lr=4.32575e-05, gnorm=0.377, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78585
2023-01-07 12:39:31 - progress_bar.py[line:274] - INFO: epoch 001:  19666 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4429, wps=100.8, ups=0.47, wpb=107.8, bsz=40, num_updates=19640, lr=4.3253e-05, gnorm=0.341, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=78606
2023-01-07 12:39:52 - progress_bar.py[line:274] - INFO: epoch 001:  19676 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5344, wps=102.6, ups=0.47, wpb=109.2, bsz=40, num_updates=19650, lr=4.32485e-05, gnorm=0.343, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78628
2023-01-07 12:40:14 - progress_bar.py[line:274] - INFO: epoch 001:  19686 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4486, wps=104.8, ups=0.47, wpb=111.1, bsz=40, num_updates=19660, lr=4.3244e-05, gnorm=0.226, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=78650
2023-01-07 12:40:36 - progress_bar.py[line:274] - INFO: epoch 001:  19696 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4872, wps=103, ups=0.47, wpb=110.1, bsz=40, num_updates=19670, lr=4.32395e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=21, gb_free=9.2, ema_decay=0.9999, wall=78671
2023-01-07 12:40:57 - progress_bar.py[line:274] - INFO: epoch 001:  19706 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4307, wps=103.8, ups=0.47, wpb=109.6, bsz=40, num_updates=19680, lr=4.3235e-05, gnorm=0.215, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=78693
2023-01-07 12:41:19 - progress_bar.py[line:274] - INFO: epoch 001:  19716 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4698, wps=101.9, ups=0.47, wpb=108.6, bsz=40, num_updates=19690, lr=4.32305e-05, gnorm=0.274, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78714
2023-01-07 12:41:41 - progress_bar.py[line:274] - INFO: epoch 001:  19726 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5054, wps=101.4, ups=0.46, wpb=110.3, bsz=40, num_updates=19700, lr=4.3226e-05, gnorm=0.336, clip=10, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=78736
2023-01-07 12:42:02 - progress_bar.py[line:274] - INFO: epoch 001:  19736 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4796, wps=100.9, ups=0.47, wpb=107.7, bsz=40, num_updates=19710, lr=4.32215e-05, gnorm=0.304, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78758
2023-01-07 12:42:24 - progress_bar.py[line:274] - INFO: epoch 001:  19746 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4421, wps=105.1, ups=0.48, wpb=109.8, bsz=40, num_updates=19720, lr=4.3217e-05, gnorm=0.261, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78779
2023-01-07 12:42:45 - progress_bar.py[line:274] - INFO: epoch 001:  19756 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3883, wps=102.2, ups=0.47, wpb=109.2, bsz=40, num_updates=19730, lr=4.32125e-05, gnorm=0.391, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=78801
2023-01-07 12:43:07 - progress_bar.py[line:274] - INFO: epoch 001:  19766 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4653, wps=103.3, ups=0.48, wpb=108.2, bsz=40, num_updates=19740, lr=4.3208e-05, gnorm=0.261, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=78822
2023-01-07 12:43:28 - progress_bar.py[line:274] - INFO: epoch 001:  19776 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4612, wps=100.1, ups=0.46, wpb=108, bsz=40, num_updates=19750, lr=4.32035e-05, gnorm=0.229, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=78844
2023-01-07 12:43:50 - progress_bar.py[line:274] - INFO: epoch 001:  19786 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4927, wps=101.2, ups=0.46, wpb=109.2, bsz=40, num_updates=19760, lr=4.3199e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=78866
2023-01-07 12:44:12 - progress_bar.py[line:274] - INFO: epoch 001:  19796 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4466, wps=99.9, ups=0.46, wpb=108.5, bsz=40, num_updates=19770, lr=4.31945e-05, gnorm=0.254, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=78888
2023-01-07 12:44:34 - progress_bar.py[line:274] - INFO: epoch 001:  19806 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4208, wps=101.3, ups=0.47, wpb=108.3, bsz=40, num_updates=19780, lr=4.319e-05, gnorm=0.214, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=78910
2023-01-07 12:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  19816 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4571, wps=99.9, ups=0.46, wpb=107.6, bsz=40, num_updates=19790, lr=4.31855e-05, gnorm=0.308, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=78932
2023-01-07 12:45:18 - progress_bar.py[line:274] - INFO: epoch 001:  19826 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4555, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=19800, lr=4.3181e-05, gnorm=0.281, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=78953
2023-01-07 12:45:39 - progress_bar.py[line:274] - INFO: epoch 001:  19836 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4279, wps=102.9, ups=0.47, wpb=110.3, bsz=40, num_updates=19810, lr=4.31765e-05, gnorm=0.228, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=78975
2023-01-07 12:46:01 - progress_bar.py[line:274] - INFO: epoch 001:  19846 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=103.9, ups=0.47, wpb=110.5, bsz=40, num_updates=19820, lr=4.3172e-05, gnorm=0.219, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=78997
2023-01-07 12:46:23 - progress_bar.py[line:274] - INFO: epoch 001:  19856 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4434, wps=100.5, ups=0.46, wpb=109, bsz=40, num_updates=19830, lr=4.31676e-05, gnorm=0.262, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=79019
2023-01-07 12:46:45 - progress_bar.py[line:274] - INFO: epoch 001:  19866 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4227, wps=98.7, ups=0.46, wpb=108.2, bsz=40, num_updates=19840, lr=4.31631e-05, gnorm=0.28, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=79041
2023-01-07 12:47:07 - progress_bar.py[line:274] - INFO: epoch 001:  19876 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4798, wps=101.9, ups=0.47, wpb=109.3, bsz=40, num_updates=19850, lr=4.31586e-05, gnorm=0.268, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=79063
2023-01-07 12:47:29 - progress_bar.py[line:274] - INFO: epoch 001:  19886 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4532, wps=99.8, ups=0.46, wpb=107.7, bsz=40, num_updates=19860, lr=4.31541e-05, gnorm=0.323, clip=0, loss_scale=1024, train_wall=22, gb_free=9.6, ema_decay=0.9999, wall=79085
2023-01-07 12:47:51 - progress_bar.py[line:274] - INFO: epoch 001:  19896 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4465, wps=99.9, ups=0.46, wpb=108.7, bsz=40, num_updates=19870, lr=4.31496e-05, gnorm=0.36, clip=10, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=79107
2023-01-07 12:48:13 - progress_bar.py[line:274] - INFO: epoch 001:  19906 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3969, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=19880, lr=4.31451e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=79128
2023-01-07 12:48:34 - progress_bar.py[line:274] - INFO: epoch 001:  19916 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4657, wps=102, ups=0.47, wpb=108.6, bsz=40, num_updates=19890, lr=4.31406e-05, gnorm=0.295, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=79150
2023-01-07 12:48:56 - progress_bar.py[line:274] - INFO: epoch 001:  19926 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4611, wps=101.2, ups=0.46, wpb=109.8, bsz=40, num_updates=19900, lr=4.31361e-05, gnorm=0.378, clip=10, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=79172
2023-01-07 12:49:19 - progress_bar.py[line:274] - INFO: epoch 001:  19936 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4354, wps=97.7, ups=0.45, wpb=108.3, bsz=40, num_updates=19910, lr=4.31316e-05, gnorm=0.278, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=79194
2023-01-07 12:49:41 - progress_bar.py[line:274] - INFO: epoch 001:  19946 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4724, wps=102.9, ups=0.47, wpb=109.6, bsz=40, num_updates=19920, lr=4.31271e-05, gnorm=0.181, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=79216
2023-01-07 12:50:03 - progress_bar.py[line:274] - INFO: epoch 001:  19956 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4133, wps=101.7, ups=0.47, wpb=109.2, bsz=40, num_updates=19930, lr=4.31226e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=79238
2023-01-07 12:50:25 - progress_bar.py[line:274] - INFO: epoch 001:  19966 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.484, wps=101.8, ups=0.46, wpb=109.6, bsz=40, num_updates=19940, lr=4.31181e-05, gnorm=0.32, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=79260
2023-01-07 12:50:46 - progress_bar.py[line:274] - INFO: epoch 001:  19976 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4346, wps=100.6, ups=0.47, wpb=107, bsz=40, num_updates=19950, lr=4.31136e-05, gnorm=0.183, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=79282
2023-01-07 12:51:09 - progress_bar.py[line:274] - INFO: epoch 001:  19986 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4335, wps=100.1, ups=0.46, wpb=109.2, bsz=40, num_updates=19960, lr=4.31091e-05, gnorm=0.176, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=79304
2023-01-07 12:51:31 - progress_bar.py[line:274] - INFO: epoch 001:  19996 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4683, wps=102.4, ups=0.47, wpb=109.9, bsz=40, num_updates=19970, lr=4.31046e-05, gnorm=0.314, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=79326
2023-01-07 12:51:52 - progress_bar.py[line:274] - INFO: epoch 001:  20006 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.455, wps=100.1, ups=0.46, wpb=108.3, bsz=40, num_updates=19980, lr=4.31001e-05, gnorm=0.286, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=79348
2023-01-07 12:52:15 - progress_bar.py[line:274] - INFO: epoch 001:  20016 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.393, wps=100.4, ups=0.46, wpb=109.9, bsz=40, num_updates=19990, lr=4.30956e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=79370
2023-01-07 12:52:37 - progress_bar.py[line:274] - INFO: epoch 001:  20026 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4479, wps=101.7, ups=0.46, wpb=109.4, bsz=40, num_updates=20000, lr=4.30911e-05, gnorm=0.389, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=79392
2023-01-07 12:52:37 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 12:52:38 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 12:52:38 - train.py[line:551] - INFO: load:1.41 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 12:55:10 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 12:55:10 - train.py[line:551] - INFO: load:1.43 valid_run:151.73 task_valid:147.47 collect_output:3.19
2023-01-07 12:57:39 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 12:57:39 - train.py[line:551] - INFO: load:1.46 valid_run:300.44 task_valid:289.92 collect_output:8.43
2023-01-07 13:00:12 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 13:00:12 - train.py[line:551] - INFO: load:1.48 valid_run:453.52 task_valid:432.52 collect_output:17.91
2023-01-07 13:02:41 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 13:02:41 - train.py[line:551] - INFO: load:1.51 valid_run:602.65 task_valid:576.81 collect_output:21.75
2023-01-07 13:05:14 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 13:05:14 - train.py[line:551] - INFO: load:1.53 valid_run:755.21 task_valid:723.65 collect_output:26.47
2023-01-07 13:07:46 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 13:07:46 - train.py[line:551] - INFO: load:1.56 valid_run:907.28 task_valid:868.59 collect_output:32.61
2023-01-07 13:10:20 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 13:10:20 - train.py[line:551] - INFO: load:1.58 valid_run:1061.20 task_valid:1014.08 collect_output:40.02
2023-01-07 13:12:52 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 13:12:52 - train.py[line:551] - INFO: load:1.61 valid_run:1213.18 task_valid:1154.74 collect_output:50.35
2023-01-07 13:15:22 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 13:15:22 - train.py[line:551] - INFO: load:1.63 valid_run:1363.34 task_valid:1298.80 collect_output:55.44
2023-01-07 13:17:51 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 13:17:51 - train.py[line:551] - INFO: load:1.66 valid_run:1512.16 task_valid:1441.44 collect_output:60.62
2023-01-07 13:20:21 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 13:20:21 - train.py[line:551] - INFO: load:1.69 valid_run:1662.17 task_valid:1585.83 collect_output:65.21
2023-01-07 13:22:52 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 13:22:52 - train.py[line:551] - INFO: load:1.71 valid_run:1812.58 task_valid:1730.54 collect_output:69.90
2023-01-07 13:25:22 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 13:25:22 - train.py[line:551] - INFO: load:1.74 valid_run:1962.89 task_valid:1871.81 collect_output:77.92
2023-01-07 13:27:53 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 13:27:53 - train.py[line:551] - INFO: load:1.77 valid_run:2113.77 task_valid:2016.94 collect_output:82.65
2023-01-07 13:30:23 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 13:30:23 - train.py[line:551] - INFO: load:1.79 valid_run:2263.83 task_valid:2162.94 collect_output:85.69
2023-01-07 13:32:54 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 13:32:54 - train.py[line:551] - INFO: load:1.82 valid_run:2414.41 task_valid:2307.03 collect_output:91.17
2023-01-07 13:35:26 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 13:35:26 - train.py[line:551] - INFO: load:1.85 valid_run:2566.53 task_valid:2451.96 collect_output:97.35
2023-01-07 13:37:57 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 13:37:57 - train.py[line:551] - INFO: load:1.88 valid_run:2717.39 task_valid:2598.61 collect_output:100.53
2023-01-07 13:40:26 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 13:40:26 - train.py[line:551] - INFO: load:1.90 valid_run:2866.21 task_valid:2739.71 collect_output:107.25
2023-01-07 13:42:57 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 13:42:57 - train.py[line:551] - INFO: load:1.93 valid_run:3016.99 task_valid:2884.56 collect_output:112.15
2023-01-07 13:45:29 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 13:45:29 - train.py[line:551] - INFO: load:1.95 valid_run:3169.57 task_valid:3028.79 collect_output:119.48
2023-01-07 13:47:59 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 13:47:59 - train.py[line:551] - INFO: load:1.98 valid_run:3319.30 task_valid:3172.95 collect_output:124.07
2023-01-07 13:50:31 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 13:50:31 - train.py[line:551] - INFO: load:2.01 valid_run:3470.80 task_valid:3318.73 collect_output:128.76
2023-01-07 13:53:02 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 13:53:02 - train.py[line:551] - INFO: load:2.04 valid_run:3622.50 task_valid:3465.25 collect_output:132.94

====================================================================================================
SGG eval:     R @ 50: 0.4038;     R @ 100: 0.4720;     R @ 500: 0.5007;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2476;    mR @ 100: 0.3104;    mR @ 500: 0.3305;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3854) (covered in:0.8125) (covering:0.3714) (eating:0.6471) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8646) (playing:0.0000) (riding:0.4788) (says:0.0000) (sitting on:0.7350) (standing on:0.1900) (using:0.7000) (walking in:0.0000) (walking on:0.1892) (watching:0.1389) 
--------------------------------------------------------
====================================================================================================

2023-01-07 13:55:33 - train.py[line:487] - INFO: 0.47196190476190475
2023-01-07 13:55:33 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-01-07 13:55:34 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.381 | loss_v1 0 | loss_v2 0 | nll_loss 0.229 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.471962 | ppl 1.17 | vqa_score 0.3919 | wps 118.8 | wpb 89.9 | bsz 30 | num_updates 20000 | best_R@100 0.641887
2023-01-07 13:55:34 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 20000 updates
2023-01-07 13:55:34 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_20000.pt

====================================================================================================
SGG eval:     R @ 50: 0.4038;     R @ 100: 0.4720;     R @ 500: 0.5007;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2476;    mR @ 100: 0.3104;    mR @ 500: 0.3305;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3854) (covered in:0.8125) (covering:0.3714) (eating:0.6471) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8646) (playing:0.0000) (riding:0.4788) (says:0.0000) (sitting on:0.7350) (standing on:0.1900) (using:0.7000) (walking in:0.0000) (walking on:0.1892) (watching:0.1389) 
--------------------------------------------------------
====================================================================================================

2023-01-07 13:56:12 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_20000.pt
2023-01-07 13:57:34 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score 0.47196190476190475) (writing took 120.23029180057347 seconds)
2023-01-07 13:57:56 - progress_bar.py[line:274] - INFO: epoch 001:  20036 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4365, wps=0.6, ups=0, wpb=109.6, bsz=40, num_updates=20010, lr=4.30866e-05, gnorm=0.321, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83312
2023-01-07 13:58:17 - progress_bar.py[line:274] - INFO: epoch 001:  20046 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4589, wps=103.1, ups=0.48, wpb=107.8, bsz=40, num_updates=20020, lr=4.30821e-05, gnorm=0.234, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=83333
2023-01-07 13:58:38 - progress_bar.py[line:274] - INFO: epoch 001:  20056 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4129, wps=106.1, ups=0.48, wpb=109.8, bsz=40, num_updates=20030, lr=4.30776e-05, gnorm=0.213, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=83354
2023-01-07 13:59:00 - progress_bar.py[line:274] - INFO: epoch 001:  20066 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.401, wps=101.5, ups=0.47, wpb=108.2, bsz=40, num_updates=20040, lr=4.30731e-05, gnorm=0.245, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83376
2023-01-07 13:59:22 - progress_bar.py[line:274] - INFO: epoch 001:  20076 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3784, wps=100.8, ups=0.46, wpb=109.5, bsz=40, num_updates=20050, lr=4.30686e-05, gnorm=0.361, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83398
2023-01-07 13:59:44 - progress_bar.py[line:274] - INFO: epoch 001:  20086 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4657, wps=101.9, ups=0.47, wpb=108.9, bsz=40, num_updates=20060, lr=4.30641e-05, gnorm=0.182, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83420
2023-01-07 13:59:50 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 14:00:08 - progress_bar.py[line:274] - INFO: epoch 001:  20097 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.238, nsentences=40, sample_size=108.238, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4533, wps=95.7, ups=0.42, wpb=108.2, bsz=40, num_updates=20070, lr=4.30597e-05, gnorm=0.407, clip=10, loss_scale=512, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=83444
2023-01-07 14:00:30 - progress_bar.py[line:274] - INFO: epoch 001:  20107 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4611, wps=103.5, ups=0.47, wpb=111.1, bsz=40, num_updates=20080, lr=4.30552e-05, gnorm=0.158, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=83466
2023-01-07 14:00:52 - progress_bar.py[line:274] - INFO: epoch 001:  20117 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4389, wps=102.7, ups=0.47, wpb=110.1, bsz=40, num_updates=20090, lr=4.30507e-05, gnorm=0.361, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83488
2023-01-07 14:01:14 - progress_bar.py[line:274] - INFO: epoch 001:  20127 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4208, wps=102.9, ups=0.47, wpb=108.5, bsz=40, num_updates=20100, lr=4.30462e-05, gnorm=0.418, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=83509
2023-01-07 14:01:36 - progress_bar.py[line:274] - INFO: epoch 001:  20137 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4378, wps=103, ups=0.47, wpb=109.5, bsz=40, num_updates=20110, lr=4.30417e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=83531
2023-01-07 14:01:57 - progress_bar.py[line:274] - INFO: epoch 001:  20147 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4348, wps=102.6, ups=0.47, wpb=110.2, bsz=40, num_updates=20120, lr=4.30372e-05, gnorm=0.191, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83553
2023-01-07 14:02:20 - progress_bar.py[line:274] - INFO: epoch 001:  20157 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3568, wps=100.5, ups=0.46, wpb=109, bsz=40, num_updates=20130, lr=4.30327e-05, gnorm=0.162, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83575
2023-01-07 14:02:42 - progress_bar.py[line:274] - INFO: epoch 001:  20167 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4742, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=20140, lr=4.30282e-05, gnorm=0.338, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=83597
2023-01-07 14:03:04 - progress_bar.py[line:274] - INFO: epoch 001:  20177 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4764, wps=100.4, ups=0.46, wpb=108.5, bsz=40, num_updates=20150, lr=4.30237e-05, gnorm=0.286, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83619
2023-01-07 14:03:26 - progress_bar.py[line:274] - INFO: epoch 001:  20187 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4031, wps=101.4, ups=0.47, wpb=108.8, bsz=40, num_updates=20160, lr=4.30192e-05, gnorm=0.208, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83641
2023-01-07 14:03:47 - progress_bar.py[line:274] - INFO: epoch 001:  20197 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4021, wps=102.6, ups=0.47, wpb=108.5, bsz=40, num_updates=20170, lr=4.30147e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83663
2023-01-07 14:04:09 - progress_bar.py[line:274] - INFO: epoch 001:  20207 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5153, wps=102.8, ups=0.46, wpb=110.8, bsz=40, num_updates=20180, lr=4.30102e-05, gnorm=0.401, clip=10, loss_scale=512, train_wall=22, gb_free=9.4, ema_decay=0.9999, wall=83685
2023-01-07 14:04:31 - progress_bar.py[line:274] - INFO: epoch 001:  20217 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4769, wps=103.1, ups=0.47, wpb=109.6, bsz=40, num_updates=20190, lr=4.30057e-05, gnorm=0.262, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83707
2023-01-07 14:04:52 - progress_bar.py[line:274] - INFO: epoch 001:  20227 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4412, wps=102.1, ups=0.47, wpb=108, bsz=40, num_updates=20200, lr=4.30012e-05, gnorm=0.359, clip=10, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=83728
2023-01-07 14:05:15 - progress_bar.py[line:274] - INFO: epoch 001:  20237 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4121, wps=98.3, ups=0.45, wpb=108.6, bsz=40, num_updates=20210, lr=4.29967e-05, gnorm=0.359, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83751
2023-01-07 14:05:36 - progress_bar.py[line:274] - INFO: epoch 001:  20247 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4098, wps=103.4, ups=0.48, wpb=108.7, bsz=40, num_updates=20220, lr=4.29922e-05, gnorm=0.192, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83772
2023-01-07 14:05:58 - progress_bar.py[line:274] - INFO: epoch 001:  20257 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5158, wps=101.9, ups=0.46, wpb=109.6, bsz=40, num_updates=20230, lr=4.29877e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=83794
2023-01-07 14:06:21 - progress_bar.py[line:274] - INFO: epoch 001:  20267 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4372, wps=101.1, ups=0.46, wpb=110, bsz=40, num_updates=20240, lr=4.29832e-05, gnorm=0.369, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83816
2023-01-07 14:06:43 - progress_bar.py[line:274] - INFO: epoch 001:  20277 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4586, wps=102.2, ups=0.46, wpb=111.1, bsz=40, num_updates=20250, lr=4.29787e-05, gnorm=0.461, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83838
2023-01-07 14:07:05 - progress_bar.py[line:274] - INFO: epoch 001:  20287 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4167, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=20260, lr=4.29742e-05, gnorm=0.319, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83860
2023-01-07 14:07:27 - progress_bar.py[line:274] - INFO: epoch 001:  20297 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4271, wps=99, ups=0.46, wpb=108.5, bsz=40, num_updates=20270, lr=4.29697e-05, gnorm=0.223, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83883
2023-01-07 14:07:49 - progress_bar.py[line:274] - INFO: epoch 001:  20307 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4348, wps=101.1, ups=0.47, wpb=108.6, bsz=40, num_updates=20280, lr=4.29652e-05, gnorm=0.239, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=83905
2023-01-07 14:08:10 - progress_bar.py[line:274] - INFO: epoch 001:  20317 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5211, wps=105.8, ups=0.48, wpb=110, bsz=40, num_updates=20290, lr=4.29607e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=21, gb_free=10.8, ema_decay=0.9999, wall=83926
2023-01-07 14:08:32 - progress_bar.py[line:274] - INFO: epoch 001:  20327 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.445, wps=102.4, ups=0.47, wpb=109.2, bsz=40, num_updates=20300, lr=4.29562e-05, gnorm=0.243, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=83948
2023-01-07 14:08:54 - progress_bar.py[line:274] - INFO: epoch 001:  20337 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.439, wps=101.1, ups=0.46, wpb=109.5, bsz=40, num_updates=20310, lr=4.29517e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=83970
2023-01-07 14:09:15 - progress_bar.py[line:274] - INFO: epoch 001:  20347 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4657, wps=103.5, ups=0.48, wpb=107.4, bsz=40, num_updates=20320, lr=4.29473e-05, gnorm=0.344, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=83991
2023-01-07 14:09:37 - progress_bar.py[line:274] - INFO: epoch 001:  20357 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4817, wps=101.2, ups=0.46, wpb=109.4, bsz=40, num_updates=20330, lr=4.29428e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84013
2023-01-07 14:10:00 - progress_bar.py[line:274] - INFO: epoch 001:  20367 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4238, wps=98.7, ups=0.46, wpb=108.2, bsz=40, num_updates=20340, lr=4.29383e-05, gnorm=0.285, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=84035
2023-01-07 14:10:22 - progress_bar.py[line:274] - INFO: epoch 001:  20377 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4831, wps=101.5, ups=0.46, wpb=110.1, bsz=40, num_updates=20350, lr=4.29338e-05, gnorm=0.231, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84057
2023-01-07 14:10:44 - progress_bar.py[line:274] - INFO: epoch 001:  20387 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4307, wps=101.5, ups=0.47, wpb=109, bsz=40, num_updates=20360, lr=4.29293e-05, gnorm=0.184, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=84079
2023-01-07 14:11:06 - progress_bar.py[line:274] - INFO: epoch 001:  20397 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4975, wps=100.8, ups=0.46, wpb=109.2, bsz=40, num_updates=20370, lr=4.29248e-05, gnorm=0.398, clip=10, loss_scale=512, train_wall=22, gb_free=10.7, ema_decay=0.9999, wall=84101
2023-01-07 14:11:18 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-07 14:11:29 - progress_bar.py[line:274] - INFO: epoch 001:  20408 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.619, nsentences=40, sample_size=108.619, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4727, wps=98.4, ups=0.43, wpb=108.6, bsz=40, num_updates=20380, lr=4.29203e-05, gnorm=0.19, clip=0, loss_scale=256, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=84125
2023-01-07 14:11:52 - progress_bar.py[line:274] - INFO: epoch 001:  20418 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4438, wps=101.5, ups=0.46, wpb=109.9, bsz=40, num_updates=20390, lr=4.29158e-05, gnorm=0.218, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84147
2023-01-07 14:12:13 - progress_bar.py[line:274] - INFO: epoch 001:  20428 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4657, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=20400, lr=4.29113e-05, gnorm=0.203, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84169
2023-01-07 14:12:35 - progress_bar.py[line:274] - INFO: epoch 001:  20438 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4866, wps=103.7, ups=0.47, wpb=109.5, bsz=40, num_updates=20410, lr=4.29068e-05, gnorm=0.298, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84190
2023-01-07 14:12:57 - progress_bar.py[line:274] - INFO: epoch 001:  20448 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.42, wps=102, ups=0.47, wpb=109.5, bsz=40, num_updates=20420, lr=4.29023e-05, gnorm=0.229, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84212
2023-01-07 14:13:18 - progress_bar.py[line:274] - INFO: epoch 001:  20458 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4611, wps=106, ups=0.48, wpb=110.2, bsz=40, num_updates=20430, lr=4.28978e-05, gnorm=0.23, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=84234
2023-01-07 14:13:40 - progress_bar.py[line:274] - INFO: epoch 001:  20468 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4587, wps=102.1, ups=0.47, wpb=108.6, bsz=40, num_updates=20440, lr=4.28933e-05, gnorm=0.203, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84255
2023-01-07 14:14:02 - progress_bar.py[line:274] - INFO: epoch 001:  20478 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4632, wps=102.5, ups=0.46, wpb=110.2, bsz=40, num_updates=20450, lr=4.28888e-05, gnorm=0.2, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=84277
2023-01-07 14:14:23 - progress_bar.py[line:274] - INFO: epoch 001:  20488 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4318, wps=105.8, ups=0.48, wpb=111, bsz=40, num_updates=20460, lr=4.28843e-05, gnorm=0.279, clip=0, loss_scale=256, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=84299
2023-01-07 14:14:45 - progress_bar.py[line:274] - INFO: epoch 001:  20498 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4308, wps=102.5, ups=0.47, wpb=109.6, bsz=40, num_updates=20470, lr=4.28798e-05, gnorm=0.289, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84321
2023-01-07 14:15:07 - progress_bar.py[line:274] - INFO: epoch 001:  20508 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4256, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=20480, lr=4.28753e-05, gnorm=0.264, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=84343
2023-01-07 14:15:29 - progress_bar.py[line:274] - INFO: epoch 001:  20518 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5308, wps=100.9, ups=0.46, wpb=108.7, bsz=40, num_updates=20490, lr=4.28708e-05, gnorm=0.387, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=84364
2023-01-07 14:15:51 - progress_bar.py[line:274] - INFO: epoch 001:  20528 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4256, wps=102.8, ups=0.47, wpb=110.2, bsz=40, num_updates=20500, lr=4.28663e-05, gnorm=0.221, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84386
2023-01-07 14:16:13 - progress_bar.py[line:274] - INFO: epoch 001:  20538 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.43, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=20510, lr=4.28618e-05, gnorm=0.258, clip=0, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=84408
2023-01-07 14:16:35 - progress_bar.py[line:274] - INFO: epoch 001:  20548 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4031, wps=101.6, ups=0.47, wpb=108.5, bsz=40, num_updates=20520, lr=4.28573e-05, gnorm=0.343, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=84430
2023-01-07 14:16:57 - progress_bar.py[line:274] - INFO: epoch 001:  20558 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.466, wps=103, ups=0.47, wpb=110, bsz=40, num_updates=20530, lr=4.28528e-05, gnorm=0.249, clip=0, loss_scale=256, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=84452
2023-01-07 14:17:18 - progress_bar.py[line:274] - INFO: epoch 001:  20568 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4821, wps=104, ups=0.47, wpb=110.1, bsz=40, num_updates=20540, lr=4.28483e-05, gnorm=0.25, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84474
2023-01-07 14:17:40 - progress_bar.py[line:274] - INFO: epoch 001:  20578 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4636, wps=101.4, ups=0.47, wpb=108.9, bsz=40, num_updates=20550, lr=4.28438e-05, gnorm=0.369, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=84496
2023-01-07 14:18:02 - progress_bar.py[line:274] - INFO: epoch 001:  20588 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4019, wps=101.9, ups=0.47, wpb=108.7, bsz=40, num_updates=20560, lr=4.28394e-05, gnorm=0.383, clip=10, loss_scale=256, train_wall=21, gb_free=10, ema_decay=0.9999, wall=84518
2023-01-07 14:18:24 - progress_bar.py[line:274] - INFO: epoch 001:  20598 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4098, wps=102.7, ups=0.47, wpb=109.3, bsz=40, num_updates=20570, lr=4.28349e-05, gnorm=0.736, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84540
2023-01-07 14:18:46 - progress_bar.py[line:274] - INFO: epoch 001:  20608 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4631, wps=101.6, ups=0.46, wpb=109.3, bsz=40, num_updates=20580, lr=4.28304e-05, gnorm=0.438, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84561
2023-01-07 14:19:07 - progress_bar.py[line:274] - INFO: epoch 001:  20618 / 115845 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=106.1, nsentences=40, sample_size=106.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4566, wps=99.4, ups=0.47, wpb=106.1, bsz=40, num_updates=20590, lr=4.28259e-05, gnorm=0.261, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84583
2023-01-07 14:19:30 - progress_bar.py[line:274] - INFO: epoch 001:  20628 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4205, wps=99.1, ups=0.46, wpb=108.3, bsz=40, num_updates=20600, lr=4.28214e-05, gnorm=0.291, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=84605
2023-01-07 14:19:52 - progress_bar.py[line:274] - INFO: epoch 001:  20638 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.42, wps=100.9, ups=0.46, wpb=109.7, bsz=40, num_updates=20610, lr=4.28169e-05, gnorm=0.217, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84627
2023-01-07 14:20:13 - progress_bar.py[line:274] - INFO: epoch 001:  20648 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4359, wps=103.9, ups=0.47, wpb=109.7, bsz=40, num_updates=20620, lr=4.28124e-05, gnorm=0.28, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84649
2023-01-07 14:20:35 - progress_bar.py[line:274] - INFO: epoch 001:  20658 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=102.4, ups=0.46, wpb=110.3, bsz=40, num_updates=20630, lr=4.28079e-05, gnorm=0.212, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84671
2023-01-07 14:20:57 - progress_bar.py[line:274] - INFO: epoch 001:  20668 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5399, wps=102.6, ups=0.47, wpb=110.2, bsz=40, num_updates=20640, lr=4.28034e-05, gnorm=0.322, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84692
2023-01-07 14:21:19 - progress_bar.py[line:274] - INFO: epoch 001:  20678 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4308, wps=100.5, ups=0.46, wpb=109.7, bsz=40, num_updates=20650, lr=4.27989e-05, gnorm=0.272, clip=0, loss_scale=256, train_wall=22, gb_free=10, ema_decay=0.9999, wall=84715
2023-01-07 14:21:40 - progress_bar.py[line:274] - INFO: epoch 001:  20688 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4742, wps=102.8, ups=0.47, wpb=109.6, bsz=40, num_updates=20660, lr=4.27944e-05, gnorm=0.167, clip=0, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=84736
2023-01-07 14:22:02 - progress_bar.py[line:274] - INFO: epoch 001:  20698 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.436, wps=99.2, ups=0.46, wpb=107.8, bsz=40, num_updates=20670, lr=4.27899e-05, gnorm=0.173, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=84758
2023-01-07 14:22:24 - progress_bar.py[line:274] - INFO: epoch 001:  20708 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4382, wps=103, ups=0.47, wpb=110.1, bsz=40, num_updates=20680, lr=4.27854e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=84780
2023-01-07 14:22:45 - progress_bar.py[line:274] - INFO: epoch 001:  20718 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4091, wps=102.5, ups=0.47, wpb=109, bsz=40, num_updates=20690, lr=4.27809e-05, gnorm=0.201, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=84801
2023-01-07 14:23:08 - progress_bar.py[line:274] - INFO: epoch 001:  20728 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5253, wps=99.1, ups=0.46, wpb=108.3, bsz=40, num_updates=20700, lr=4.27764e-05, gnorm=0.16, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=84823
2023-01-07 14:23:29 - progress_bar.py[line:274] - INFO: epoch 001:  20738 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4656, wps=104, ups=0.47, wpb=110, bsz=40, num_updates=20710, lr=4.27719e-05, gnorm=0.196, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84845
2023-01-07 14:23:51 - progress_bar.py[line:274] - INFO: epoch 001:  20748 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4171, wps=102.1, ups=0.47, wpb=108.3, bsz=40, num_updates=20720, lr=4.27674e-05, gnorm=0.301, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=84866
2023-01-07 14:24:12 - progress_bar.py[line:274] - INFO: epoch 001:  20758 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4087, wps=101.5, ups=0.47, wpb=108.3, bsz=40, num_updates=20730, lr=4.27629e-05, gnorm=0.322, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84888
2023-01-07 14:24:34 - progress_bar.py[line:274] - INFO: epoch 001:  20768 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4714, wps=102.6, ups=0.47, wpb=108.5, bsz=40, num_updates=20740, lr=4.27584e-05, gnorm=0.212, clip=0, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84909
2023-01-07 14:24:55 - progress_bar.py[line:274] - INFO: epoch 001:  20778 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4089, wps=101.7, ups=0.47, wpb=109.2, bsz=40, num_updates=20750, lr=4.27539e-05, gnorm=0.544, clip=20, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84931
2023-01-07 14:25:17 - progress_bar.py[line:274] - INFO: epoch 001:  20788 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.54, wps=102, ups=0.46, wpb=109.8, bsz=40, num_updates=20760, lr=4.27494e-05, gnorm=0.361, clip=10, loss_scale=256, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=84953
2023-01-07 14:25:39 - progress_bar.py[line:274] - INFO: epoch 001:  20798 / 115845 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.385, wps=100.7, ups=0.46, wpb=108.8, bsz=40, num_updates=20770, lr=4.27449e-05, gnorm=0.31, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=84975
2023-01-07 14:26:01 - progress_bar.py[line:274] - INFO: epoch 001:  20808 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4131, wps=98.9, ups=0.46, wpb=107.5, bsz=40, num_updates=20780, lr=4.27404e-05, gnorm=0.273, clip=0, loss_scale=256, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=84997
2023-01-07 14:26:23 - progress_bar.py[line:274] - INFO: epoch 001:  20818 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4783, wps=100.2, ups=0.46, wpb=108.7, bsz=40, num_updates=20790, lr=4.27359e-05, gnorm=0.248, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85019
2023-01-07 14:26:45 - progress_bar.py[line:274] - INFO: epoch 001:  20828 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4596, wps=100, ups=0.46, wpb=108.5, bsz=40, num_updates=20800, lr=4.27314e-05, gnorm=0.321, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=85041
2023-01-07 14:27:07 - progress_bar.py[line:274] - INFO: epoch 001:  20838 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4928, wps=99.6, ups=0.46, wpb=107.7, bsz=40, num_updates=20810, lr=4.2727e-05, gnorm=0.253, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85063
2023-01-07 14:27:28 - progress_bar.py[line:274] - INFO: epoch 001:  20848 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3807, wps=101.6, ups=0.47, wpb=108.8, bsz=40, num_updates=20820, lr=4.27225e-05, gnorm=0.354, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85084
2023-01-07 14:27:50 - progress_bar.py[line:274] - INFO: epoch 001:  20858 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5093, wps=101.6, ups=0.46, wpb=109.3, bsz=40, num_updates=20830, lr=4.2718e-05, gnorm=0.405, clip=10, loss_scale=256, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=85106
2023-01-07 14:28:12 - progress_bar.py[line:274] - INFO: epoch 001:  20868 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.516, wps=103.5, ups=0.47, wpb=110.6, bsz=40, num_updates=20840, lr=4.27135e-05, gnorm=0.251, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85128
2023-01-07 14:28:34 - progress_bar.py[line:274] - INFO: epoch 001:  20878 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5122, wps=100, ups=0.46, wpb=108.5, bsz=40, num_updates=20850, lr=4.2709e-05, gnorm=0.238, clip=0, loss_scale=256, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85150
2023-01-07 14:28:55 - progress_bar.py[line:274] - INFO: epoch 001:  20888 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4343, wps=102.2, ups=0.47, wpb=108.5, bsz=40, num_updates=20860, lr=4.27045e-05, gnorm=0.223, clip=0, loss_scale=256, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85171
2023-01-07 14:29:17 - progress_bar.py[line:274] - INFO: epoch 001:  20898 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4749, wps=103.5, ups=0.47, wpb=110.5, bsz=40, num_updates=20870, lr=4.27e-05, gnorm=0.271, clip=0, loss_scale=256, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=85193
2023-01-07 14:29:39 - progress_bar.py[line:274] - INFO: epoch 001:  20908 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4541, wps=100.6, ups=0.46, wpb=108.9, bsz=40, num_updates=20880, lr=4.26955e-05, gnorm=0.3, clip=0, loss_scale=256, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=85215
2023-01-07 14:30:01 - progress_bar.py[line:274] - INFO: epoch 001:  20918 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4976, wps=100.4, ups=0.46, wpb=108.9, bsz=40, num_updates=20890, lr=4.2691e-05, gnorm=0.371, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=85237
2023-01-07 14:30:23 - progress_bar.py[line:274] - INFO: epoch 001:  20928 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4185, wps=101.6, ups=0.47, wpb=109.2, bsz=40, num_updates=20900, lr=4.26865e-05, gnorm=0.245, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85258
2023-01-07 14:30:45 - progress_bar.py[line:274] - INFO: epoch 001:  20938 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4518, wps=101.7, ups=0.46, wpb=109.4, bsz=40, num_updates=20910, lr=4.2682e-05, gnorm=0.299, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=85281
2023-01-07 14:31:06 - progress_bar.py[line:274] - INFO: epoch 001:  20948 / 115845 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=106.5, nsentences=40, sample_size=106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, vqa_score=0.3935, wps=100.7, ups=0.47, wpb=106.5, bsz=40, num_updates=20920, lr=4.26775e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85302
2023-01-07 14:31:28 - progress_bar.py[line:274] - INFO: epoch 001:  20958 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3918, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=20930, lr=4.2673e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=85324
2023-01-07 14:31:49 - progress_bar.py[line:274] - INFO: epoch 001:  20968 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4583, wps=102.8, ups=0.47, wpb=109.2, bsz=40, num_updates=20940, lr=4.26685e-05, gnorm=0.351, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85345
2023-01-07 14:32:11 - progress_bar.py[line:274] - INFO: epoch 001:  20978 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4769, wps=102.9, ups=0.47, wpb=109.8, bsz=40, num_updates=20950, lr=4.2664e-05, gnorm=0.212, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85367
2023-01-07 14:32:32 - progress_bar.py[line:274] - INFO: epoch 001:  20988 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4575, wps=101.7, ups=0.47, wpb=107.9, bsz=40, num_updates=20960, lr=4.26595e-05, gnorm=0.297, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85388
2023-01-07 14:32:54 - progress_bar.py[line:274] - INFO: epoch 001:  20998 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4213, wps=101.8, ups=0.46, wpb=109.5, bsz=40, num_updates=20970, lr=4.2655e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=85410
2023-01-07 14:33:16 - progress_bar.py[line:274] - INFO: epoch 001:  21008 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4657, wps=102, ups=0.47, wpb=108.3, bsz=40, num_updates=20980, lr=4.26505e-05, gnorm=0.406, clip=10, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=85431
2023-01-07 14:33:37 - progress_bar.py[line:274] - INFO: epoch 001:  21018 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=101.7, ups=0.47, wpb=109.3, bsz=40, num_updates=20990, lr=4.2646e-05, gnorm=0.224, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85453
2023-01-07 14:33:59 - progress_bar.py[line:274] - INFO: epoch 001:  21028 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.436, wps=101, ups=0.47, wpb=108.4, bsz=40, num_updates=21000, lr=4.26415e-05, gnorm=0.209, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=85475
2023-01-07 14:34:21 - progress_bar.py[line:274] - INFO: epoch 001:  21038 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4531, wps=100.2, ups=0.46, wpb=109.3, bsz=40, num_updates=21010, lr=4.2637e-05, gnorm=0.275, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=85497
2023-01-07 14:34:43 - progress_bar.py[line:274] - INFO: epoch 001:  21048 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4673, wps=101.1, ups=0.46, wpb=108.9, bsz=40, num_updates=21020, lr=4.26325e-05, gnorm=0.25, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85519
2023-01-07 14:35:05 - progress_bar.py[line:274] - INFO: epoch 001:  21058 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.375, wps=100.8, ups=0.46, wpb=108.6, bsz=40, num_updates=21030, lr=4.2628e-05, gnorm=0.185, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85541
2023-01-07 14:35:27 - progress_bar.py[line:274] - INFO: epoch 001:  21068 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4608, wps=100.3, ups=0.46, wpb=108.9, bsz=40, num_updates=21040, lr=4.26235e-05, gnorm=0.277, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85563
2023-01-07 14:35:49 - progress_bar.py[line:274] - INFO: epoch 001:  21078 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3971, wps=101.1, ups=0.47, wpb=108.5, bsz=40, num_updates=21050, lr=4.26191e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=85584
2023-01-07 14:36:11 - progress_bar.py[line:274] - INFO: epoch 001:  21088 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=101.9, ups=0.46, wpb=109.7, bsz=40, num_updates=21060, lr=4.26146e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85606
2023-01-07 14:36:32 - progress_bar.py[line:274] - INFO: epoch 001:  21098 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5238, wps=102.9, ups=0.48, wpb=106.9, bsz=40, num_updates=21070, lr=4.26101e-05, gnorm=0.221, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85627
2023-01-07 14:36:53 - progress_bar.py[line:274] - INFO: epoch 001:  21108 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3902, wps=101.7, ups=0.47, wpb=109.1, bsz=40, num_updates=21080, lr=4.26056e-05, gnorm=0.25, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85649
2023-01-07 14:37:15 - progress_bar.py[line:274] - INFO: epoch 001:  21118 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4698, wps=100.9, ups=0.46, wpb=109, bsz=40, num_updates=21090, lr=4.26011e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=85671
2023-01-07 14:37:37 - progress_bar.py[line:274] - INFO: epoch 001:  21128 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4505, wps=100.1, ups=0.47, wpb=107.4, bsz=40, num_updates=21100, lr=4.25966e-05, gnorm=0.348, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85693
2023-01-07 14:37:59 - progress_bar.py[line:274] - INFO: epoch 001:  21138 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4975, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=21110, lr=4.25921e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=85715
2023-01-07 14:38:21 - progress_bar.py[line:274] - INFO: epoch 001:  21148 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4384, wps=99.3, ups=0.46, wpb=108.5, bsz=40, num_updates=21120, lr=4.25876e-05, gnorm=0.233, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85737
2023-01-07 14:38:43 - progress_bar.py[line:274] - INFO: epoch 001:  21158 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4171, wps=99.8, ups=0.46, wpb=109.2, bsz=40, num_updates=21130, lr=4.25831e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=22, gb_free=10, ema_decay=0.9999, wall=85759
2023-01-07 14:39:05 - progress_bar.py[line:274] - INFO: epoch 001:  21168 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.451, wps=101.1, ups=0.46, wpb=109.6, bsz=40, num_updates=21140, lr=4.25786e-05, gnorm=0.196, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=85781
2023-01-07 14:39:26 - progress_bar.py[line:274] - INFO: epoch 001:  21178 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.439, wps=103.4, ups=0.47, wpb=108.9, bsz=40, num_updates=21150, lr=4.25741e-05, gnorm=0.249, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=85802
2023-01-07 14:39:48 - progress_bar.py[line:274] - INFO: epoch 001:  21188 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4745, wps=100.4, ups=0.46, wpb=108, bsz=40, num_updates=21160, lr=4.25696e-05, gnorm=0.175, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85824
2023-01-07 14:40:10 - progress_bar.py[line:274] - INFO: epoch 001:  21198 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4145, wps=100.7, ups=0.46, wpb=109.4, bsz=40, num_updates=21170, lr=4.25651e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=85846
2023-01-07 14:40:32 - progress_bar.py[line:274] - INFO: epoch 001:  21208 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4515, wps=102.3, ups=0.47, wpb=108.6, bsz=40, num_updates=21180, lr=4.25606e-05, gnorm=0.322, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85868
2023-01-07 14:40:53 - progress_bar.py[line:274] - INFO: epoch 001:  21218 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.54, wps=103.7, ups=0.48, wpb=108.7, bsz=40, num_updates=21190, lr=4.25561e-05, gnorm=0.437, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85889
2023-01-07 14:41:15 - progress_bar.py[line:274] - INFO: epoch 001:  21228 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4631, wps=102.3, ups=0.47, wpb=108.9, bsz=40, num_updates=21200, lr=4.25516e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85910
2023-01-07 14:41:36 - progress_bar.py[line:274] - INFO: epoch 001:  21238 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.467, wps=103.2, ups=0.47, wpb=109.9, bsz=40, num_updates=21210, lr=4.25471e-05, gnorm=0.197, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=85932
2023-01-07 14:41:58 - progress_bar.py[line:274] - INFO: epoch 001:  21248 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4612, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=21220, lr=4.25426e-05, gnorm=0.358, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=85954
2023-01-07 14:42:20 - progress_bar.py[line:274] - INFO: epoch 001:  21258 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.435, wps=102.6, ups=0.47, wpb=109.8, bsz=40, num_updates=21230, lr=4.25381e-05, gnorm=0.211, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=85976
2023-01-07 14:42:42 - progress_bar.py[line:274] - INFO: epoch 001:  21268 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.403, wps=101.7, ups=0.47, wpb=109.1, bsz=40, num_updates=21240, lr=4.25336e-05, gnorm=0.206, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=85997
2023-01-07 14:43:03 - progress_bar.py[line:274] - INFO: epoch 001:  21278 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.524, wps=102.1, ups=0.47, wpb=109.8, bsz=40, num_updates=21250, lr=4.25291e-05, gnorm=0.26, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86019
2023-01-07 14:43:25 - progress_bar.py[line:274] - INFO: epoch 001:  21288 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4742, wps=105.9, ups=0.48, wpb=111.3, bsz=40, num_updates=21260, lr=4.25246e-05, gnorm=0.299, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86041
2023-01-07 14:43:47 - progress_bar.py[line:274] - INFO: epoch 001:  21298 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4732, wps=97.6, ups=0.46, wpb=107, bsz=40, num_updates=21270, lr=4.25201e-05, gnorm=0.405, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86063
2023-01-07 14:44:08 - progress_bar.py[line:274] - INFO: epoch 001:  21308 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3838, wps=104, ups=0.47, wpb=109.6, bsz=40, num_updates=21280, lr=4.25156e-05, gnorm=0.315, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86084
2023-01-07 14:44:30 - progress_bar.py[line:274] - INFO: epoch 001:  21318 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4533, wps=101.5, ups=0.46, wpb=110.1, bsz=40, num_updates=21290, lr=4.25111e-05, gnorm=0.214, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=86106
2023-01-07 14:44:52 - progress_bar.py[line:274] - INFO: epoch 001:  21328 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4737, wps=102.3, ups=0.47, wpb=109, bsz=40, num_updates=21300, lr=4.25067e-05, gnorm=0.153, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86128
2023-01-07 14:45:14 - progress_bar.py[line:274] - INFO: epoch 001:  21338 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4308, wps=98.9, ups=0.46, wpb=108.4, bsz=40, num_updates=21310, lr=4.25022e-05, gnorm=0.274, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=86150
2023-01-07 14:45:36 - progress_bar.py[line:274] - INFO: epoch 001:  21348 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5105, wps=102.4, ups=0.46, wpb=110.2, bsz=40, num_updates=21320, lr=4.24977e-05, gnorm=0.3, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86172
2023-01-07 14:45:57 - progress_bar.py[line:274] - INFO: epoch 001:  21358 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4301, wps=104, ups=0.48, wpb=109.2, bsz=40, num_updates=21330, lr=4.24932e-05, gnorm=0.438, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86193
2023-01-07 14:46:19 - progress_bar.py[line:274] - INFO: epoch 001:  21368 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4417, wps=100, ups=0.47, wpb=107.3, bsz=40, num_updates=21340, lr=4.24887e-05, gnorm=0.305, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86215
2023-01-07 14:46:41 - progress_bar.py[line:274] - INFO: epoch 001:  21378 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5027, wps=103.1, ups=0.47, wpb=110, bsz=40, num_updates=21350, lr=4.24842e-05, gnorm=0.395, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86236
2023-01-07 14:47:02 - progress_bar.py[line:274] - INFO: epoch 001:  21388 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4065, wps=101.8, ups=0.47, wpb=108.5, bsz=40, num_updates=21360, lr=4.24797e-05, gnorm=0.187, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86258
2023-01-07 14:47:24 - progress_bar.py[line:274] - INFO: epoch 001:  21398 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4774, wps=102.2, ups=0.47, wpb=109.4, bsz=40, num_updates=21370, lr=4.24752e-05, gnorm=0.19, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86280
2023-01-07 14:47:46 - progress_bar.py[line:274] - INFO: epoch 001:  21408 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4778, wps=101.2, ups=0.46, wpb=108.9, bsz=40, num_updates=21380, lr=4.24707e-05, gnorm=0.237, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86301
2023-01-07 14:48:07 - progress_bar.py[line:274] - INFO: epoch 001:  21418 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4622, wps=102.8, ups=0.48, wpb=107.6, bsz=40, num_updates=21390, lr=4.24662e-05, gnorm=0.232, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86323
2023-01-07 14:48:29 - progress_bar.py[line:274] - INFO: epoch 001:  21428 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5, wps=102.1, ups=0.47, wpb=109.7, bsz=40, num_updates=21400, lr=4.24617e-05, gnorm=0.203, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86344
2023-01-07 14:48:50 - progress_bar.py[line:274] - INFO: epoch 001:  21438 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4673, wps=102.6, ups=0.47, wpb=109, bsz=40, num_updates=21410, lr=4.24572e-05, gnorm=0.222, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=86366
2023-01-07 14:49:12 - progress_bar.py[line:274] - INFO: epoch 001:  21448 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4948, wps=99.4, ups=0.45, wpb=109.6, bsz=40, num_updates=21420, lr=4.24527e-05, gnorm=0.236, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=86388
2023-01-07 14:49:34 - progress_bar.py[line:274] - INFO: epoch 001:  21458 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4433, wps=100.8, ups=0.46, wpb=109, bsz=40, num_updates=21430, lr=4.24482e-05, gnorm=0.23, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86410
2023-01-07 14:49:55 - progress_bar.py[line:274] - INFO: epoch 001:  21468 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4874, wps=106.2, ups=0.48, wpb=109.9, bsz=40, num_updates=21440, lr=4.24437e-05, gnorm=0.181, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=86431
2023-01-07 14:50:17 - progress_bar.py[line:274] - INFO: epoch 001:  21478 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4774, wps=100.9, ups=0.46, wpb=109.3, bsz=40, num_updates=21450, lr=4.24392e-05, gnorm=0.27, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=86453
2023-01-07 14:50:38 - progress_bar.py[line:274] - INFO: epoch 001:  21488 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4444, wps=104.2, ups=0.48, wpb=108.2, bsz=40, num_updates=21460, lr=4.24347e-05, gnorm=0.387, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86474
2023-01-07 14:51:00 - progress_bar.py[line:274] - INFO: epoch 001:  21498 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4677, wps=101.1, ups=0.47, wpb=108.6, bsz=40, num_updates=21470, lr=4.24302e-05, gnorm=0.393, clip=10, loss_scale=1024, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=86496
2023-01-07 14:51:22 - progress_bar.py[line:274] - INFO: epoch 001:  21508 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=102.6, ups=0.47, wpb=109.2, bsz=40, num_updates=21480, lr=4.24257e-05, gnorm=0.29, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86517
2023-01-07 14:51:43 - progress_bar.py[line:274] - INFO: epoch 001:  21518 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4265, wps=102.2, ups=0.47, wpb=109.9, bsz=40, num_updates=21490, lr=4.24212e-05, gnorm=0.215, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86539
2023-01-07 14:51:50 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 14:52:07 - progress_bar.py[line:274] - INFO: epoch 001:  21529 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.667, nsentences=40, sample_size=110.667, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4648, wps=100.5, ups=0.43, wpb=110.7, bsz=40, num_updates=21500, lr=4.24167e-05, gnorm=0.454, clip=10, loss_scale=512, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=86563
2023-01-07 14:52:29 - progress_bar.py[line:274] - INFO: epoch 001:  21539 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4466, wps=100.4, ups=0.47, wpb=107.7, bsz=40, num_updates=21510, lr=4.24122e-05, gnorm=0.157, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86584
2023-01-07 14:52:50 - progress_bar.py[line:274] - INFO: epoch 001:  21549 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4638, wps=100.8, ups=0.46, wpb=108.7, bsz=40, num_updates=21520, lr=4.24077e-05, gnorm=0.333, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=86606
2023-01-07 14:53:11 - progress_bar.py[line:274] - INFO: epoch 001:  21559 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4545, wps=106.3, ups=0.48, wpb=110, bsz=40, num_updates=21530, lr=4.24032e-05, gnorm=0.345, clip=0, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=86627
2023-01-07 14:53:33 - progress_bar.py[line:274] - INFO: epoch 001:  21569 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4764, wps=101.6, ups=0.46, wpb=109.3, bsz=40, num_updates=21540, lr=4.23988e-05, gnorm=0.181, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86649
2023-01-07 14:53:55 - progress_bar.py[line:274] - INFO: epoch 001:  21579 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4722, wps=101.9, ups=0.47, wpb=108.1, bsz=40, num_updates=21550, lr=4.23943e-05, gnorm=0.328, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=86671
2023-01-07 14:54:16 - progress_bar.py[line:274] - INFO: epoch 001:  21589 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4072, wps=101.5, ups=0.46, wpb=109.2, bsz=40, num_updates=21560, lr=4.23898e-05, gnorm=0.216, clip=0, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=86692
2023-01-07 14:54:38 - progress_bar.py[line:274] - INFO: epoch 001:  21599 / 115845 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.145, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.526, wps=104.2, ups=0.47, wpb=109.9, bsz=40, num_updates=21570, lr=4.23853e-05, gnorm=0.135, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86714
2023-01-07 14:54:59 - progress_bar.py[line:274] - INFO: epoch 001:  21609 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4503, wps=103.7, ups=0.47, wpb=110.1, bsz=40, num_updates=21580, lr=4.23808e-05, gnorm=0.506, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86735
2023-01-07 14:55:21 - progress_bar.py[line:274] - INFO: epoch 001:  21619 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4528, wps=99.6, ups=0.46, wpb=107.9, bsz=40, num_updates=21590, lr=4.23763e-05, gnorm=0.843, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86757
2023-01-07 14:55:43 - progress_bar.py[line:274] - INFO: epoch 001:  21629 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4354, wps=102.3, ups=0.47, wpb=108.6, bsz=40, num_updates=21600, lr=4.23718e-05, gnorm=0.317, clip=0, loss_scale=512, train_wall=21, gb_free=10, ema_decay=0.9999, wall=86779
2023-01-07 14:56:04 - progress_bar.py[line:274] - INFO: epoch 001:  21639 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4272, wps=101.5, ups=0.47, wpb=108, bsz=40, num_updates=21610, lr=4.23673e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86800
2023-01-07 14:56:26 - progress_bar.py[line:274] - INFO: epoch 001:  21649 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=102, ups=0.47, wpb=109.3, bsz=40, num_updates=21620, lr=4.23628e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=86822
2023-01-07 14:56:48 - progress_bar.py[line:274] - INFO: epoch 001:  21659 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.43, wps=100.1, ups=0.46, wpb=108.4, bsz=40, num_updates=21630, lr=4.23583e-05, gnorm=0.234, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=86844
2023-01-07 14:57:10 - progress_bar.py[line:274] - INFO: epoch 001:  21669 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4051, wps=100.6, ups=0.46, wpb=108.3, bsz=40, num_updates=21640, lr=4.23538e-05, gnorm=0.406, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=86866
2023-01-07 14:57:32 - progress_bar.py[line:274] - INFO: epoch 001:  21679 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4537, wps=100, ups=0.46, wpb=107.6, bsz=40, num_updates=21650, lr=4.23493e-05, gnorm=0.165, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=86888
2023-01-07 14:57:54 - progress_bar.py[line:274] - INFO: epoch 001:  21689 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4216, wps=101.6, ups=0.46, wpb=110.3, bsz=40, num_updates=21660, lr=4.23448e-05, gnorm=0.256, clip=10, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=86910
2023-01-07 14:58:16 - progress_bar.py[line:274] - INFO: epoch 001:  21699 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4384, wps=101.8, ups=0.46, wpb=109.9, bsz=40, num_updates=21670, lr=4.23403e-05, gnorm=0.231, clip=0, loss_scale=512, train_wall=22, gb_free=9.9, ema_decay=0.9999, wall=86932
2023-01-07 14:58:38 - progress_bar.py[line:274] - INFO: epoch 001:  21709 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4167, wps=99.7, ups=0.46, wpb=108.3, bsz=40, num_updates=21680, lr=4.23358e-05, gnorm=0.191, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86954
2023-01-07 14:58:59 - progress_bar.py[line:274] - INFO: epoch 001:  21719 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4762, wps=104.4, ups=0.48, wpb=109.1, bsz=40, num_updates=21690, lr=4.23313e-05, gnorm=0.265, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=86975
2023-01-07 14:59:21 - progress_bar.py[line:274] - INFO: epoch 001:  21729 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4921, wps=101.6, ups=0.46, wpb=110.6, bsz=40, num_updates=21700, lr=4.23268e-05, gnorm=0.145, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=86997
2023-01-07 14:59:43 - progress_bar.py[line:274] - INFO: epoch 001:  21739 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5095, wps=102, ups=0.47, wpb=108.7, bsz=40, num_updates=21710, lr=4.23223e-05, gnorm=0.305, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=87019
2023-01-07 15:00:05 - progress_bar.py[line:274] - INFO: epoch 001:  21749 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.45, wps=100.5, ups=0.46, wpb=108.5, bsz=40, num_updates=21720, lr=4.23178e-05, gnorm=0.314, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=87041
2023-01-07 15:00:26 - progress_bar.py[line:274] - INFO: epoch 001:  21759 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4619, wps=101.9, ups=0.46, wpb=109.6, bsz=40, num_updates=21730, lr=4.23133e-05, gnorm=0.216, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87062
2023-01-07 15:00:48 - progress_bar.py[line:274] - INFO: epoch 001:  21769 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4541, wps=102.2, ups=0.47, wpb=108.8, bsz=40, num_updates=21740, lr=4.23088e-05, gnorm=0.247, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87084
2023-01-07 15:01:09 - progress_bar.py[line:274] - INFO: epoch 001:  21779 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4428, wps=101.9, ups=0.47, wpb=108.4, bsz=40, num_updates=21750, lr=4.23043e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87105
2023-01-07 15:01:31 - progress_bar.py[line:274] - INFO: epoch 001:  21789 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4492, wps=102.8, ups=0.47, wpb=109.9, bsz=40, num_updates=21760, lr=4.22998e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=21, gb_free=9.6, ema_decay=0.9999, wall=87127
2023-01-07 15:01:53 - progress_bar.py[line:274] - INFO: epoch 001:  21799 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4286, wps=100.2, ups=0.46, wpb=108, bsz=40, num_updates=21770, lr=4.22953e-05, gnorm=0.364, clip=10, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=87149
2023-01-07 15:02:15 - progress_bar.py[line:274] - INFO: epoch 001:  21809 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3762, wps=101.9, ups=0.46, wpb=109.8, bsz=40, num_updates=21780, lr=4.22908e-05, gnorm=0.258, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=87171
2023-01-07 15:02:36 - progress_bar.py[line:274] - INFO: epoch 001:  21819 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.445, wps=104.1, ups=0.47, wpb=110, bsz=40, num_updates=21790, lr=4.22864e-05, gnorm=0.187, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=87192
2023-01-07 15:02:59 - progress_bar.py[line:274] - INFO: epoch 001:  21829 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4922, wps=102.3, ups=0.47, wpb=109.8, bsz=40, num_updates=21800, lr=4.22819e-05, gnorm=0.21, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87214
2023-01-07 15:03:20 - progress_bar.py[line:274] - INFO: epoch 001:  21839 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4396, wps=103, ups=0.47, wpb=109.2, bsz=40, num_updates=21810, lr=4.22774e-05, gnorm=0.384, clip=10, loss_scale=512, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=87236
2023-01-07 15:03:43 - progress_bar.py[line:274] - INFO: epoch 001:  21849 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.393, wps=100, ups=0.46, wpb=108.9, bsz=40, num_updates=21820, lr=4.22729e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=87258
2023-01-07 15:04:05 - progress_bar.py[line:274] - INFO: epoch 001:  21859 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4293, wps=104.4, ups=0.47, wpb=110.6, bsz=40, num_updates=21830, lr=4.22684e-05, gnorm=0.23, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87280
2023-01-07 15:04:27 - progress_bar.py[line:274] - INFO: epoch 001:  21869 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4903, wps=100.5, ups=0.47, wpb=107.9, bsz=40, num_updates=21840, lr=4.22639e-05, gnorm=0.327, clip=0, loss_scale=512, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=87302
2023-01-07 15:04:49 - progress_bar.py[line:274] - INFO: epoch 001:  21879 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4402, wps=102.2, ups=0.47, wpb=108.8, bsz=40, num_updates=21850, lr=4.22594e-05, gnorm=0.259, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=87324
2023-01-07 15:05:11 - progress_bar.py[line:274] - INFO: epoch 001:  21889 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4033, wps=102.6, ups=0.47, wpb=109.5, bsz=40, num_updates=21860, lr=4.22549e-05, gnorm=0.372, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87346
2023-01-07 15:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  21899 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4952, wps=103.6, ups=0.48, wpb=108.1, bsz=40, num_updates=21870, lr=4.22504e-05, gnorm=0.229, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87368
2023-01-07 15:05:54 - progress_bar.py[line:274] - INFO: epoch 001:  21909 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4817, wps=102.1, ups=0.46, wpb=109.9, bsz=40, num_updates=21880, lr=4.22459e-05, gnorm=0.287, clip=10, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87390
2023-01-07 15:06:16 - progress_bar.py[line:274] - INFO: epoch 001:  21919 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4278, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=21890, lr=4.22414e-05, gnorm=0.188, clip=0, loss_scale=512, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=87412
2023-01-07 15:06:37 - progress_bar.py[line:274] - INFO: epoch 001:  21929 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4776, wps=104.8, ups=0.47, wpb=110.4, bsz=40, num_updates=21900, lr=4.22369e-05, gnorm=0.342, clip=10, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87433
2023-01-07 15:06:59 - progress_bar.py[line:274] - INFO: epoch 001:  21939 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4402, wps=104.5, ups=0.47, wpb=110.3, bsz=40, num_updates=21910, lr=4.22324e-05, gnorm=0.243, clip=0, loss_scale=512, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=87455
2023-01-07 15:07:20 - progress_bar.py[line:274] - INFO: epoch 001:  21949 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3805, wps=104.2, ups=0.48, wpb=108.9, bsz=40, num_updates=21920, lr=4.22279e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87476
2023-01-07 15:07:42 - progress_bar.py[line:274] - INFO: epoch 001:  21959 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4541, wps=101.7, ups=0.47, wpb=108.9, bsz=40, num_updates=21930, lr=4.22234e-05, gnorm=0.316, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=87498
2023-01-07 15:08:04 - progress_bar.py[line:274] - INFO: epoch 001:  21969 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4189, wps=99.7, ups=0.46, wpb=108.6, bsz=40, num_updates=21940, lr=4.22189e-05, gnorm=0.195, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=87520
2023-01-07 15:08:26 - progress_bar.py[line:274] - INFO: epoch 001:  21979 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4628, wps=100.7, ups=0.46, wpb=108.3, bsz=40, num_updates=21950, lr=4.22144e-05, gnorm=0.232, clip=0, loss_scale=512, train_wall=21, gb_free=9.5, ema_decay=0.9999, wall=87542
2023-01-07 15:08:47 - progress_bar.py[line:274] - INFO: epoch 001:  21989 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5026, wps=103.5, ups=0.47, wpb=110.6, bsz=40, num_updates=21960, lr=4.22099e-05, gnorm=0.4, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87563
2023-01-07 15:09:09 - progress_bar.py[line:274] - INFO: epoch 001:  21999 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4872, wps=103.6, ups=0.47, wpb=109.5, bsz=40, num_updates=21970, lr=4.22054e-05, gnorm=0.141, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=87585
2023-01-07 15:09:31 - progress_bar.py[line:274] - INFO: epoch 001:  22009 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4785, wps=98.9, ups=0.46, wpb=107.3, bsz=40, num_updates=21980, lr=4.22009e-05, gnorm=0.27, clip=0, loss_scale=512, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=87607
2023-01-07 15:09:53 - progress_bar.py[line:274] - INFO: epoch 001:  22019 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.41, wps=100, ups=0.46, wpb=109.8, bsz=40, num_updates=21990, lr=4.21964e-05, gnorm=0.265, clip=0, loss_scale=512, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=87629
2023-01-07 15:10:15 - progress_bar.py[line:274] - INFO: epoch 001:  22029 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4069, wps=103.2, ups=0.47, wpb=108.9, bsz=40, num_updates=22000, lr=4.21919e-05, gnorm=0.215, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=87650
2023-01-07 15:10:15 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 15:10:16 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 15:10:16 - train.py[line:551] - INFO: load:1.15 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 15:12:48 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 15:12:48 - train.py[line:551] - INFO: load:1.18 valid_run:151.63 task_valid:147.58 collect_output:3.02
2023-01-07 15:15:17 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 15:15:17 - train.py[line:551] - INFO: load:1.20 valid_run:300.46 task_valid:290.28 collect_output:8.13
2023-01-07 15:17:50 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 15:17:50 - train.py[line:551] - INFO: load:1.23 valid_run:453.44 task_valid:432.51 collect_output:17.87
2023-01-07 15:20:19 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 15:20:19 - train.py[line:551] - INFO: load:1.25 valid_run:602.61 task_valid:576.89 collect_output:21.67
2023-01-07 15:22:51 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 15:22:51 - train.py[line:551] - INFO: load:1.28 valid_run:755.05 task_valid:723.86 collect_output:26.15
2023-01-07 15:25:24 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 15:25:24 - train.py[line:551] - INFO: load:1.30 valid_run:907.17 task_valid:869.05 collect_output:32.07
2023-01-07 15:27:58 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 15:27:58 - train.py[line:551] - INFO: load:1.33 valid_run:1061.36 task_valid:1014.49 collect_output:39.83
2023-01-07 15:30:30 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 15:30:30 - train.py[line:551] - INFO: load:1.35 valid_run:1213.12 task_valid:1155.03 collect_output:50.04
2023-01-07 15:33:00 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 15:33:00 - train.py[line:551] - INFO: load:1.38 valid_run:1363.05 task_valid:1299.31 collect_output:54.71
2023-01-07 15:35:29 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 15:35:29 - train.py[line:551] - INFO: load:1.40 valid_run:1512.00 task_valid:1441.96 collect_output:59.99
2023-01-07 15:37:59 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 15:37:59 - train.py[line:551] - INFO: load:1.43 valid_run:1662.22 task_valid:1586.40 collect_output:64.78
2023-01-07 15:40:29 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 15:40:29 - train.py[line:551] - INFO: load:1.46 valid_run:1812.43 task_valid:1730.96 collect_output:69.44
2023-01-07 15:43:00 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 15:43:00 - train.py[line:551] - INFO: load:1.48 valid_run:1962.68 task_valid:1872.29 collect_output:77.35
2023-01-07 15:45:31 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 15:45:31 - train.py[line:551] - INFO: load:1.51 valid_run:2113.60 task_valid:2017.59 collect_output:81.93
2023-01-07 15:48:01 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 15:48:01 - train.py[line:551] - INFO: load:1.54 valid_run:2263.90 task_valid:2163.68 collect_output:85.10
2023-01-07 15:50:31 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 15:50:31 - train.py[line:551] - INFO: load:1.56 valid_run:2414.15 task_valid:2307.22 collect_output:90.81
2023-01-07 15:53:03 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 15:53:03 - train.py[line:551] - INFO: load:1.59 valid_run:2566.13 task_valid:2452.08 collect_output:96.94
2023-01-07 15:55:34 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 15:55:34 - train.py[line:551] - INFO: load:1.61 valid_run:2716.92 task_valid:2598.77 collect_output:100.03
2023-01-07 15:58:03 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 15:58:03 - train.py[line:551] - INFO: load:1.64 valid_run:2866.07 task_valid:2739.82 collect_output:107.13
2023-01-07 16:00:34 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 16:00:34 - train.py[line:551] - INFO: load:1.66 valid_run:3016.76 task_valid:2884.60 collect_output:112.01
2023-01-07 16:03:07 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 16:03:07 - train.py[line:551] - INFO: load:1.69 valid_run:3169.11 task_valid:3028.84 collect_output:119.06
2023-01-07 16:05:36 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 16:05:36 - train.py[line:551] - INFO: load:1.72 valid_run:3318.60 task_valid:3173.03 collect_output:123.34
2023-01-07 16:08:08 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 16:08:08 - train.py[line:551] - INFO: load:1.74 valid_run:3470.37 task_valid:3319.06 collect_output:128.05
2023-01-07 16:10:40 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 16:10:40 - train.py[line:551] - INFO: load:1.77 valid_run:3621.82 task_valid:3465.16 collect_output:132.41

====================================================================================================
SGG eval:     R @ 50: 0.3895;     R @ 100: 0.4515;     R @ 500: 0.4765;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2400;    mR @ 100: 0.2937;    mR @ 500: 0.3121;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3756) (covered in:0.8125) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6875) (playing:0.0000) (riding:0.4788) (says:0.0000) (sitting on:0.6993) (standing on:0.1800) (using:0.7000) (walking in:0.0000) (walking on:0.1892) (watching:0.0972) 
--------------------------------------------------------
====================================================================================================

2023-01-07 16:13:10 - train.py[line:487] - INFO: 0.45146190476190473
2023-01-07 16:13:10 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.3895;     R @ 100: 0.4515;     R @ 500: 0.4765;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2400;    mR @ 100: 0.2937;    mR @ 500: 0.3121;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3756) (covered in:0.8125) (covering:0.3714) (eating:0.5882) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6875) (playing:0.0000) (riding:0.4788) (says:0.0000) (sitting on:0.6993) (standing on:0.1800) (using:0.7000) (walking in:0.0000) (walking on:0.1892) (watching:0.0972) 
--------------------------------------------------------
====================================================================================================

2023-01-07 16:13:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.385 | loss_v1 0 | loss_v2 0 | nll_loss 0.236 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.451462 | ppl 1.18 | vqa_score 0.3604 | wps 118.9 | wpb 89.9 | bsz 30 | num_updates 22000 | best_R@100 0.641887
2023-01-07 16:13:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 22000 updates
2023-01-07 16:13:11 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_22000.pt
2023-01-07 16:13:57 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_22000.pt
2023-01-07 16:15:28 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_22000.pt (epoch 1 @ 22000 updates, score 0.45146190476190473) (writing took 136.80850764736533 seconds)
2023-01-07 16:15:49 - progress_bar.py[line:274] - INFO: epoch 001:  22039 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4583, wps=0.6, ups=0, wpb=109.7, bsz=40, num_updates=22010, lr=4.21874e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=91585
2023-01-07 16:16:11 - progress_bar.py[line:274] - INFO: epoch 001:  22049 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4466, wps=100.4, ups=0.46, wpb=108.9, bsz=40, num_updates=22020, lr=4.21829e-05, gnorm=0.222, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=91607
2023-01-07 16:16:34 - progress_bar.py[line:274] - INFO: epoch 001:  22059 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4412, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=22030, lr=4.21785e-05, gnorm=0.464, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=91629
2023-01-07 16:16:55 - progress_bar.py[line:274] - INFO: epoch 001:  22069 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4769, wps=102.8, ups=0.47, wpb=109.4, bsz=40, num_updates=22040, lr=4.2174e-05, gnorm=0.326, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=91651
2023-01-07 16:17:17 - progress_bar.py[line:274] - INFO: epoch 001:  22079 / 115845 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4076, wps=105.9, ups=0.48, wpb=109.9, bsz=40, num_updates=22050, lr=4.21695e-05, gnorm=0.317, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=91672
2023-01-07 16:17:39 - progress_bar.py[line:274] - INFO: epoch 001:  22089 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.47, wps=101.2, ups=0.46, wpb=109.3, bsz=40, num_updates=22060, lr=4.2165e-05, gnorm=0.172, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=91694
2023-01-07 16:18:01 - progress_bar.py[line:274] - INFO: epoch 001:  22099 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4439, wps=101.3, ups=0.47, wpb=108, bsz=40, num_updates=22070, lr=4.21605e-05, gnorm=0.203, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=91716
2023-01-07 16:18:22 - progress_bar.py[line:274] - INFO: epoch 001:  22109 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.43, wps=102.5, ups=0.47, wpb=108.9, bsz=40, num_updates=22080, lr=4.2156e-05, gnorm=0.438, clip=20, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=91738
2023-01-07 16:18:45 - progress_bar.py[line:274] - INFO: epoch 001:  22119 / 115845 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4129, wps=99.7, ups=0.46, wpb=108.4, bsz=40, num_updates=22090, lr=4.21515e-05, gnorm=0.388, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=91760
2023-01-07 16:19:06 - progress_bar.py[line:274] - INFO: epoch 001:  22129 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4455, wps=103, ups=0.47, wpb=108.9, bsz=40, num_updates=22100, lr=4.2147e-05, gnorm=0.262, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=91782
2023-01-07 16:19:28 - progress_bar.py[line:274] - INFO: epoch 001:  22139 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4673, wps=103.5, ups=0.47, wpb=109.2, bsz=40, num_updates=22110, lr=4.21425e-05, gnorm=0.331, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=91803
2023-01-07 16:19:49 - progress_bar.py[line:274] - INFO: epoch 001:  22149 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.396, wps=103, ups=0.47, wpb=109.3, bsz=40, num_updates=22120, lr=4.2138e-05, gnorm=0.222, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=91825
2023-01-07 16:20:11 - progress_bar.py[line:274] - INFO: epoch 001:  22159 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5121, wps=102.2, ups=0.47, wpb=108.8, bsz=40, num_updates=22130, lr=4.21335e-05, gnorm=0.364, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=91847
2023-01-07 16:20:33 - progress_bar.py[line:274] - INFO: epoch 001:  22169 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4764, wps=104.3, ups=0.47, wpb=110.9, bsz=40, num_updates=22140, lr=4.2129e-05, gnorm=0.259, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=91869
2023-01-07 16:20:55 - progress_bar.py[line:274] - INFO: epoch 001:  22179 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4559, wps=98.8, ups=0.46, wpb=107.8, bsz=40, num_updates=22150, lr=4.21245e-05, gnorm=0.219, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=91891
2023-01-07 16:21:17 - progress_bar.py[line:274] - INFO: epoch 001:  22189 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4874, wps=102.5, ups=0.47, wpb=109, bsz=40, num_updates=22160, lr=4.212e-05, gnorm=0.168, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=91913
2023-01-07 16:21:39 - progress_bar.py[line:274] - INFO: epoch 001:  22199 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4726, wps=100, ups=0.46, wpb=108, bsz=40, num_updates=22170, lr=4.21155e-05, gnorm=0.27, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=91935
2023-01-07 16:22:01 - progress_bar.py[line:274] - INFO: epoch 001:  22209 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4899, wps=101.9, ups=0.47, wpb=109.4, bsz=40, num_updates=22180, lr=4.2111e-05, gnorm=0.227, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=91957
2023-01-07 16:22:24 - progress_bar.py[line:274] - INFO: epoch 001:  22219 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4413, wps=99.6, ups=0.46, wpb=108.7, bsz=40, num_updates=22190, lr=4.21065e-05, gnorm=0.339, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=91979
2023-01-07 16:22:46 - progress_bar.py[line:274] - INFO: epoch 001:  22229 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4537, wps=100.2, ups=0.46, wpb=108.4, bsz=40, num_updates=22200, lr=4.2102e-05, gnorm=0.294, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=92001
2023-01-07 16:23:08 - progress_bar.py[line:274] - INFO: epoch 001:  22239 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4783, wps=103.3, ups=0.47, wpb=110.5, bsz=40, num_updates=22210, lr=4.20975e-05, gnorm=0.275, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92024
2023-01-07 16:23:30 - progress_bar.py[line:274] - INFO: epoch 001:  22249 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4486, wps=104.2, ups=0.48, wpb=108.6, bsz=40, num_updates=22220, lr=4.2093e-05, gnorm=0.245, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=92045
2023-01-07 16:23:52 - progress_bar.py[line:274] - INFO: epoch 001:  22259 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4423, wps=100.6, ups=0.46, wpb=109.2, bsz=40, num_updates=22230, lr=4.20885e-05, gnorm=0.242, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92068
2023-01-07 16:24:14 - progress_bar.py[line:274] - INFO: epoch 001:  22269 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.441, wps=102.7, ups=0.47, wpb=109.8, bsz=40, num_updates=22240, lr=4.2084e-05, gnorm=0.249, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92089
2023-01-07 16:24:35 - progress_bar.py[line:274] - INFO: epoch 001:  22279 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4378, wps=103.3, ups=0.48, wpb=108.5, bsz=40, num_updates=22250, lr=4.20795e-05, gnorm=0.181, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=92111
2023-01-07 16:24:58 - progress_bar.py[line:274] - INFO: epoch 001:  22289 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4308, wps=102.1, ups=0.47, wpb=109.6, bsz=40, num_updates=22260, lr=4.2075e-05, gnorm=0.277, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=92133
2023-01-07 16:25:20 - progress_bar.py[line:274] - INFO: epoch 001:  22299 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4822, wps=102.4, ups=0.47, wpb=110, bsz=40, num_updates=22270, lr=4.20705e-05, gnorm=0.291, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92155
2023-01-07 16:25:42 - progress_bar.py[line:274] - INFO: epoch 001:  22309 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4829, wps=99.9, ups=0.46, wpb=108.6, bsz=40, num_updates=22280, lr=4.20661e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=92177
2023-01-07 16:26:03 - progress_bar.py[line:274] - INFO: epoch 001:  22319 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4639, wps=102.9, ups=0.47, wpb=108.9, bsz=40, num_updates=22290, lr=4.20616e-05, gnorm=0.174, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=92199
2023-01-07 16:26:25 - progress_bar.py[line:274] - INFO: epoch 001:  22329 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5304, wps=101.8, ups=0.47, wpb=109.2, bsz=40, num_updates=22300, lr=4.20571e-05, gnorm=0.254, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=92221
2023-01-07 16:26:47 - progress_bar.py[line:274] - INFO: epoch 001:  22339 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4278, wps=102.9, ups=0.47, wpb=110.6, bsz=40, num_updates=22310, lr=4.20526e-05, gnorm=0.296, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92243
2023-01-07 16:27:09 - progress_bar.py[line:274] - INFO: epoch 001:  22349 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4589, wps=101.4, ups=0.47, wpb=108.6, bsz=40, num_updates=22320, lr=4.20481e-05, gnorm=0.245, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92265
2023-01-07 16:27:31 - progress_bar.py[line:274] - INFO: epoch 001:  22359 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4906, wps=101.9, ups=0.47, wpb=108.5, bsz=40, num_updates=22330, lr=4.20436e-05, gnorm=0.41, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=92287
2023-01-07 16:27:53 - progress_bar.py[line:274] - INFO: epoch 001:  22369 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4892, wps=103.2, ups=0.47, wpb=110.9, bsz=40, num_updates=22340, lr=4.20391e-05, gnorm=0.207, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92309
2023-01-07 16:28:15 - progress_bar.py[line:274] - INFO: epoch 001:  22379 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4404, wps=100.2, ups=0.46, wpb=108.7, bsz=40, num_updates=22350, lr=4.20346e-05, gnorm=0.335, clip=0, loss_scale=1024, train_wall=22, gb_free=9.5, ema_decay=0.9999, wall=92331
2023-01-07 16:28:37 - progress_bar.py[line:274] - INFO: epoch 001:  22389 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.401, wps=102.9, ups=0.47, wpb=109.5, bsz=40, num_updates=22360, lr=4.20301e-05, gnorm=0.21, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92353
2023-01-07 16:28:59 - progress_bar.py[line:274] - INFO: epoch 001:  22399 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4279, wps=102.6, ups=0.47, wpb=108.4, bsz=40, num_updates=22370, lr=4.20256e-05, gnorm=0.26, clip=10, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=92374
2023-01-07 16:29:20 - progress_bar.py[line:274] - INFO: epoch 001:  22409 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4573, wps=103.8, ups=0.48, wpb=108.4, bsz=40, num_updates=22380, lr=4.20211e-05, gnorm=0.275, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92396
2023-01-07 16:29:43 - progress_bar.py[line:274] - INFO: epoch 001:  22419 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4356, wps=96.7, ups=0.45, wpb=108.1, bsz=40, num_updates=22390, lr=4.20166e-05, gnorm=0.274, clip=0, loss_scale=1024, train_wall=22, gb_free=9.8, ema_decay=0.9999, wall=92419
2023-01-07 16:30:06 - progress_bar.py[line:274] - INFO: epoch 001:  22429 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=100.3, ups=0.46, wpb=109.2, bsz=40, num_updates=22400, lr=4.20121e-05, gnorm=0.197, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92441
2023-01-07 16:30:27 - progress_bar.py[line:274] - INFO: epoch 001:  22439 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4127, wps=103.7, ups=0.47, wpb=109.2, bsz=40, num_updates=22410, lr=4.20076e-05, gnorm=0.175, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92463
2023-01-07 16:30:49 - progress_bar.py[line:274] - INFO: epoch 001:  22449 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4187, wps=101.5, ups=0.47, wpb=108.5, bsz=40, num_updates=22420, lr=4.20031e-05, gnorm=0.326, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92485
2023-01-07 16:31:12 - progress_bar.py[line:274] - INFO: epoch 001:  22459 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4764, wps=100.4, ups=0.46, wpb=110.1, bsz=40, num_updates=22430, lr=4.19986e-05, gnorm=0.249, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=92507
2023-01-07 16:31:33 - progress_bar.py[line:274] - INFO: epoch 001:  22469 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.44, wps=103.4, ups=0.47, wpb=109.9, bsz=40, num_updates=22440, lr=4.19941e-05, gnorm=0.281, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92529
2023-01-07 16:31:55 - progress_bar.py[line:274] - INFO: epoch 001:  22479 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4471, wps=99.6, ups=0.47, wpb=107, bsz=40, num_updates=22450, lr=4.19896e-05, gnorm=0.234, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92551
2023-01-07 16:32:18 - progress_bar.py[line:274] - INFO: epoch 001:  22489 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.402, wps=99.8, ups=0.46, wpb=108.3, bsz=40, num_updates=22460, lr=4.19851e-05, gnorm=0.204, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=92573
2023-01-07 16:32:39 - progress_bar.py[line:274] - INFO: epoch 001:  22499 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4335, wps=104.5, ups=0.48, wpb=108.9, bsz=40, num_updates=22470, lr=4.19806e-05, gnorm=0.212, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92595
2023-01-07 16:33:01 - progress_bar.py[line:274] - INFO: epoch 001:  22509 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4167, wps=100.1, ups=0.46, wpb=109.6, bsz=40, num_updates=22480, lr=4.19761e-05, gnorm=0.171, clip=0, loss_scale=1024, train_wall=22, gb_free=10.5, ema_decay=0.9999, wall=92617
2023-01-07 16:33:23 - progress_bar.py[line:274] - INFO: epoch 001:  22519 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4899, wps=102.4, ups=0.47, wpb=109, bsz=40, num_updates=22490, lr=4.19716e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=92639
2023-01-07 16:33:44 - progress_bar.py[line:274] - INFO: epoch 001:  22529 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4254, wps=107.5, ups=0.48, wpb=111.1, bsz=40, num_updates=22500, lr=4.19671e-05, gnorm=0.255, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=92660
2023-01-07 16:34:06 - progress_bar.py[line:274] - INFO: epoch 001:  22539 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4322, wps=100.9, ups=0.46, wpb=108.6, bsz=40, num_updates=22510, lr=4.19626e-05, gnorm=0.246, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=92682
2023-01-07 16:34:28 - progress_bar.py[line:274] - INFO: epoch 001:  22549 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4444, wps=103, ups=0.47, wpb=109.6, bsz=40, num_updates=22520, lr=4.19582e-05, gnorm=0.435, clip=10, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=92703
2023-01-07 16:34:49 - progress_bar.py[line:274] - INFO: epoch 001:  22559 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4599, wps=103.5, ups=0.47, wpb=109, bsz=40, num_updates=22530, lr=4.19537e-05, gnorm=0.37, clip=0, loss_scale=2048, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=92725
2023-01-07 16:35:12 - progress_bar.py[line:274] - INFO: epoch 001:  22569 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4632, wps=102.2, ups=0.46, wpb=110.6, bsz=40, num_updates=22540, lr=4.19492e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92747
2023-01-07 16:35:20 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-07 16:35:35 - progress_bar.py[line:274] - INFO: epoch 001:  22580 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.762, nsentences=40, sample_size=109.762, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4742, wps=98.6, ups=0.43, wpb=109.8, bsz=40, num_updates=22550, lr=4.19447e-05, gnorm=0.362, clip=10, loss_scale=1024, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=92771
2023-01-07 16:35:57 - progress_bar.py[line:274] - INFO: epoch 001:  22590 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4372, wps=101.3, ups=0.47, wpb=108.7, bsz=40, num_updates=22560, lr=4.19402e-05, gnorm=0.225, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92793
2023-01-07 16:36:19 - progress_bar.py[line:274] - INFO: epoch 001:  22600 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4677, wps=100.9, ups=0.46, wpb=109.4, bsz=40, num_updates=22570, lr=4.19357e-05, gnorm=0.226, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=92815
2023-01-07 16:36:42 - progress_bar.py[line:274] - INFO: epoch 001:  22610 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4335, wps=99.2, ups=0.46, wpb=108.1, bsz=40, num_updates=22580, lr=4.19312e-05, gnorm=0.177, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92837
2023-01-07 16:37:04 - progress_bar.py[line:274] - INFO: epoch 001:  22620 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5245, wps=100.9, ups=0.47, wpb=108.1, bsz=40, num_updates=22590, lr=4.19267e-05, gnorm=0.361, clip=10, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=92859
2023-01-07 16:37:26 - progress_bar.py[line:274] - INFO: epoch 001:  22630 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.407, wps=101.8, ups=0.46, wpb=109.6, bsz=40, num_updates=22600, lr=4.19222e-05, gnorm=0.312, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=92881
2023-01-07 16:37:47 - progress_bar.py[line:274] - INFO: epoch 001:  22640 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4899, wps=102.5, ups=0.47, wpb=109.4, bsz=40, num_updates=22610, lr=4.19177e-05, gnorm=0.322, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92903
2023-01-07 16:38:09 - progress_bar.py[line:274] - INFO: epoch 001:  22650 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4948, wps=103.1, ups=0.48, wpb=108, bsz=40, num_updates=22620, lr=4.19132e-05, gnorm=0.254, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=92924
2023-01-07 16:38:31 - progress_bar.py[line:274] - INFO: epoch 001:  22660 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4178, wps=100.3, ups=0.46, wpb=108.1, bsz=40, num_updates=22630, lr=4.19087e-05, gnorm=0.352, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=92947
2023-01-07 16:38:53 - progress_bar.py[line:274] - INFO: epoch 001:  22670 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4141, wps=100, ups=0.46, wpb=108, bsz=40, num_updates=22640, lr=4.19042e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=92969
2023-01-07 16:39:15 - progress_bar.py[line:274] - INFO: epoch 001:  22680 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.44, wps=102.3, ups=0.47, wpb=109.2, bsz=40, num_updates=22650, lr=4.18997e-05, gnorm=0.334, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=92990
2023-01-07 16:39:37 - progress_bar.py[line:274] - INFO: epoch 001:  22690 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4648, wps=101, ups=0.46, wpb=108.9, bsz=40, num_updates=22660, lr=4.18952e-05, gnorm=0.25, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93013
2023-01-07 16:39:59 - progress_bar.py[line:274] - INFO: epoch 001:  22700 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4592, wps=102.9, ups=0.47, wpb=109.1, bsz=40, num_updates=22670, lr=4.18907e-05, gnorm=0.352, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93034
2023-01-07 16:40:21 - progress_bar.py[line:274] - INFO: epoch 001:  22710 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4322, wps=104.9, ups=0.47, wpb=110.4, bsz=40, num_updates=22680, lr=4.18862e-05, gnorm=0.255, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=93056
2023-01-07 16:40:43 - progress_bar.py[line:274] - INFO: epoch 001:  22720 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.475, wps=99.3, ups=0.46, wpb=107.6, bsz=40, num_updates=22690, lr=4.18817e-05, gnorm=0.358, clip=10, loss_scale=1024, train_wall=22, gb_free=9.7, ema_decay=0.9999, wall=93079
2023-01-07 16:41:05 - progress_bar.py[line:274] - INFO: epoch 001:  22730 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4776, wps=103, ups=0.47, wpb=109.4, bsz=40, num_updates=22700, lr=4.18772e-05, gnorm=0.243, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=93100
2023-01-07 16:41:29 - progress_bar.py[line:274] - INFO: epoch 001:  22740 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4, wps=104.7, ups=0.48, wpb=108.8, bsz=40, num_updates=22710, lr=4.18727e-05, gnorm=0.195, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=93122
2023-01-07 16:41:51 - progress_bar.py[line:274] - INFO: epoch 001:  22750 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4154, wps=103.1, ups=0.47, wpb=109.9, bsz=40, num_updates=22720, lr=4.18682e-05, gnorm=0.184, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93146
2023-01-07 16:42:13 - progress_bar.py[line:274] - INFO: epoch 001:  22760 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4396, wps=103.9, ups=0.47, wpb=110.7, bsz=40, num_updates=22730, lr=4.18637e-05, gnorm=0.282, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=93169
2023-01-07 16:42:35 - progress_bar.py[line:274] - INFO: epoch 001:  22770 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4555, wps=103.3, ups=0.47, wpb=111, bsz=40, num_updates=22740, lr=4.18592e-05, gnorm=0.244, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93190
2023-01-07 16:42:57 - progress_bar.py[line:274] - INFO: epoch 001:  22780 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4602, wps=100.1, ups=0.46, wpb=108.3, bsz=40, num_updates=22750, lr=4.18547e-05, gnorm=0.285, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93212
2023-01-07 16:43:19 - progress_bar.py[line:274] - INFO: epoch 001:  22790 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4404, wps=102.7, ups=0.47, wpb=109.2, bsz=40, num_updates=22760, lr=4.18502e-05, gnorm=0.189, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93234
2023-01-07 16:43:40 - progress_bar.py[line:274] - INFO: epoch 001:  22800 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5025, wps=100.5, ups=0.47, wpb=107.5, bsz=40, num_updates=22770, lr=4.18458e-05, gnorm=0.199, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=93256
2023-01-07 16:44:02 - progress_bar.py[line:274] - INFO: epoch 001:  22810 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4861, wps=103.3, ups=0.47, wpb=109.7, bsz=40, num_updates=22780, lr=4.18413e-05, gnorm=0.316, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93278
2023-01-07 16:44:23 - progress_bar.py[line:274] - INFO: epoch 001:  22820 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4396, wps=103, ups=0.48, wpb=107.8, bsz=40, num_updates=22790, lr=4.18368e-05, gnorm=0.257, clip=0, loss_scale=1024, train_wall=21, gb_free=9.8, ema_decay=0.9999, wall=93299
2023-01-07 16:44:46 - progress_bar.py[line:274] - INFO: epoch 001:  22830 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4898, wps=101, ups=0.46, wpb=109.2, bsz=40, num_updates=22800, lr=4.18323e-05, gnorm=0.285, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93321
2023-01-07 16:45:08 - progress_bar.py[line:274] - INFO: epoch 001:  22840 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4457, wps=101.5, ups=0.46, wpb=109.5, bsz=40, num_updates=22810, lr=4.18278e-05, gnorm=0.268, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=93343
2023-01-07 16:45:29 - progress_bar.py[line:274] - INFO: epoch 001:  22850 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4976, wps=103.8, ups=0.47, wpb=109.4, bsz=40, num_updates=22820, lr=4.18233e-05, gnorm=0.266, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=93365
2023-01-07 16:45:51 - progress_bar.py[line:274] - INFO: epoch 001:  22860 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.415, wps=104.7, ups=0.48, wpb=108.3, bsz=40, num_updates=22830, lr=4.18188e-05, gnorm=0.261, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=93386
2023-01-07 16:46:12 - progress_bar.py[line:274] - INFO: epoch 001:  22870 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4869, wps=102, ups=0.47, wpb=108.6, bsz=40, num_updates=22840, lr=4.18143e-05, gnorm=0.319, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93408
2023-01-07 16:46:34 - progress_bar.py[line:274] - INFO: epoch 001:  22880 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4772, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=22850, lr=4.18098e-05, gnorm=0.307, clip=10, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=93430
2023-01-07 16:46:56 - progress_bar.py[line:274] - INFO: epoch 001:  22890 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4085, wps=102, ups=0.47, wpb=109.4, bsz=40, num_updates=22860, lr=4.18053e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93452
2023-01-07 16:47:18 - progress_bar.py[line:274] - INFO: epoch 001:  22900 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4208, wps=101.3, ups=0.47, wpb=107.7, bsz=40, num_updates=22870, lr=4.18008e-05, gnorm=0.21, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93474
2023-01-07 16:47:40 - progress_bar.py[line:274] - INFO: epoch 001:  22910 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4306, wps=101.7, ups=0.48, wpb=107, bsz=40, num_updates=22880, lr=4.17963e-05, gnorm=0.407, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=93495
2023-01-07 16:48:02 - progress_bar.py[line:274] - INFO: epoch 001:  22920 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4709, wps=101.1, ups=0.46, wpb=110.2, bsz=40, num_updates=22890, lr=4.17918e-05, gnorm=0.182, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=93517
2023-01-07 16:48:25 - progress_bar.py[line:274] - INFO: epoch 001:  22930 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4656, wps=103, ups=0.47, wpb=109.4, bsz=40, num_updates=22900, lr=4.17873e-05, gnorm=0.316, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=93540
2023-01-07 16:48:48 - progress_bar.py[line:274] - INFO: epoch 001:  22940 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4067, wps=100.5, ups=0.47, wpb=107.9, bsz=40, num_updates=22910, lr=4.17828e-05, gnorm=0.345, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=93562
2023-01-07 16:49:10 - progress_bar.py[line:274] - INFO: epoch 001:  22950 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4378, wps=102.9, ups=0.47, wpb=108.3, bsz=40, num_updates=22920, lr=4.17783e-05, gnorm=0.325, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93585
2023-01-07 16:49:32 - progress_bar.py[line:274] - INFO: epoch 001:  22960 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4118, wps=101.1, ups=0.46, wpb=108.8, bsz=40, num_updates=22930, lr=4.17738e-05, gnorm=0.213, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93607
2023-01-07 16:49:55 - progress_bar.py[line:274] - INFO: epoch 001:  22970 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=101.1, ups=0.46, wpb=108.8, bsz=40, num_updates=22940, lr=4.17693e-05, gnorm=0.248, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=93630
2023-01-07 16:50:17 - progress_bar.py[line:274] - INFO: epoch 001:  22980 / 115845 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.385, wps=102, ups=0.47, wpb=108.2, bsz=40, num_updates=22950, lr=4.17648e-05, gnorm=0.198, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93652
2023-01-07 16:50:40 - progress_bar.py[line:274] - INFO: epoch 001:  22990 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.39, wps=100.2, ups=0.46, wpb=107.8, bsz=40, num_updates=22960, lr=4.17603e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=93675
2023-01-07 16:51:02 - progress_bar.py[line:274] - INFO: epoch 001:  23000 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.385, wps=103.9, ups=0.48, wpb=108.5, bsz=40, num_updates=22970, lr=4.17558e-05, gnorm=0.433, clip=20, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93697
2023-01-07 16:51:24 - progress_bar.py[line:274] - INFO: epoch 001:  23010 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5025, wps=100, ups=0.46, wpb=109, bsz=40, num_updates=22980, lr=4.17513e-05, gnorm=0.197, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=93720
2023-01-07 16:51:48 - progress_bar.py[line:274] - INFO: epoch 001:  23020 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4796, wps=99.1, ups=0.46, wpb=108.8, bsz=40, num_updates=22990, lr=4.17468e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=93743
2023-01-07 16:52:11 - progress_bar.py[line:274] - INFO: epoch 001:  23030 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4158, wps=101, ups=0.47, wpb=108.2, bsz=40, num_updates=23000, lr=4.17423e-05, gnorm=0.155, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93766
2023-01-07 16:52:33 - progress_bar.py[line:274] - INFO: epoch 001:  23040 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4352, wps=104.8, ups=0.48, wpb=110.2, bsz=40, num_updates=23010, lr=4.17379e-05, gnorm=0.443, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93788
2023-01-07 16:52:55 - progress_bar.py[line:274] - INFO: epoch 001:  23050 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4323, wps=102.6, ups=0.47, wpb=108.8, bsz=40, num_updates=23020, lr=4.17334e-05, gnorm=0.185, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93810
2023-01-07 16:53:17 - progress_bar.py[line:274] - INFO: epoch 001:  23060 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4392, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=23030, lr=4.17289e-05, gnorm=0.279, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93832
2023-01-07 16:53:40 - progress_bar.py[line:274] - INFO: epoch 001:  23070 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4844, wps=100.7, ups=0.46, wpb=109.5, bsz=40, num_updates=23040, lr=4.17244e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93855
2023-01-07 16:54:02 - progress_bar.py[line:274] - INFO: epoch 001:  23080 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4869, wps=101, ups=0.46, wpb=109.1, bsz=40, num_updates=23050, lr=4.17199e-05, gnorm=0.304, clip=0, loss_scale=1024, train_wall=22, gb_free=10.6, ema_decay=0.9999, wall=93877
2023-01-07 16:54:25 - progress_bar.py[line:274] - INFO: epoch 001:  23090 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4316, wps=101.2, ups=0.46, wpb=109.9, bsz=40, num_updates=23060, lr=4.17154e-05, gnorm=0.24, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=93900
2023-01-07 16:54:47 - progress_bar.py[line:274] - INFO: epoch 001:  23100 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.43, wps=101.7, ups=0.46, wpb=110, bsz=40, num_updates=23070, lr=4.17109e-05, gnorm=0.18, clip=0, loss_scale=2048, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=93922
2023-01-07 16:55:10 - progress_bar.py[line:274] - INFO: epoch 001:  23110 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4126, wps=102.9, ups=0.47, wpb=108.7, bsz=40, num_updates=23080, lr=4.17064e-05, gnorm=0.179, clip=0, loss_scale=2048, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=93944
2023-01-07 16:55:32 - progress_bar.py[line:274] - INFO: epoch 001:  23120 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3627, wps=102.7, ups=0.47, wpb=109.3, bsz=40, num_updates=23090, lr=4.17019e-05, gnorm=0.331, clip=10, loss_scale=2048, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=93967
2023-01-07 16:55:55 - progress_bar.py[line:274] - INFO: epoch 001:  23130 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4186, wps=99.4, ups=0.46, wpb=108.2, bsz=40, num_updates=23100, lr=4.16974e-05, gnorm=0.337, clip=10, loss_scale=2048, train_wall=22, gb_free=10, ema_decay=0.9999, wall=93990
2023-01-07 16:56:18 - progress_bar.py[line:274] - INFO: epoch 001:  23140 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4824, wps=101.1, ups=0.46, wpb=109.4, bsz=40, num_updates=23110, lr=4.16929e-05, gnorm=0.269, clip=0, loss_scale=2048, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94013
2023-01-07 16:56:40 - progress_bar.py[line:274] - INFO: epoch 001:  23150 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=107.4, nsentences=40, sample_size=107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4686, wps=100.7, ups=0.47, wpb=107.4, bsz=40, num_updates=23120, lr=4.16884e-05, gnorm=0.312, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94035
2023-01-07 16:57:01 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-07 16:57:04 - progress_bar.py[line:274] - INFO: epoch 001:  23161 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=110.333, nsentences=40, sample_size=110.333, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.432, wps=98.1, ups=0.42, wpb=110.3, bsz=40, num_updates=23130, lr=4.16839e-05, gnorm=0.33, clip=10, loss_scale=1024, train_wall=24, gb_free=10.2, ema_decay=0.9999, wall=94060
2023-01-07 16:57:27 - progress_bar.py[line:274] - INFO: epoch 001:  23171 / 115845 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.3611, wps=101.1, ups=0.46, wpb=108.7, bsz=40, num_updates=23140, lr=4.16794e-05, gnorm=0.222, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=94082
2023-01-07 16:57:48 - progress_bar.py[line:274] - INFO: epoch 001:  23181 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.445, wps=103.3, ups=0.47, wpb=109.3, bsz=40, num_updates=23150, lr=4.16749e-05, gnorm=0.345, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94104
2023-01-07 16:58:11 - progress_bar.py[line:274] - INFO: epoch 001:  23191 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4419, wps=98.2, ups=0.45, wpb=108.7, bsz=40, num_updates=23160, lr=4.16704e-05, gnorm=0.318, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=94127
2023-01-07 16:58:34 - progress_bar.py[line:274] - INFO: epoch 001:  23201 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4926, wps=99.5, ups=0.46, wpb=107.8, bsz=40, num_updates=23170, lr=4.16659e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94149
2023-01-07 16:58:57 - progress_bar.py[line:274] - INFO: epoch 001:  23211 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4526, wps=99.6, ups=0.46, wpb=109, bsz=40, num_updates=23180, lr=4.16614e-05, gnorm=0.274, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94172
2023-01-07 16:59:19 - progress_bar.py[line:274] - INFO: epoch 001:  23221 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.433, wps=101.7, ups=0.47, wpb=109.2, bsz=40, num_updates=23190, lr=4.16569e-05, gnorm=0.258, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94194
2023-01-07 16:59:41 - progress_bar.py[line:274] - INFO: epoch 001:  23231 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4778, wps=102.2, ups=0.47, wpb=109.7, bsz=40, num_updates=23200, lr=4.16524e-05, gnorm=0.199, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=94217
2023-01-07 17:00:04 - progress_bar.py[line:274] - INFO: epoch 001:  23241 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4313, wps=99.2, ups=0.46, wpb=107.6, bsz=40, num_updates=23210, lr=4.16479e-05, gnorm=0.218, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=94239
2023-01-07 17:00:26 - progress_bar.py[line:274] - INFO: epoch 001:  23251 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4619, wps=100.8, ups=0.47, wpb=108.2, bsz=40, num_updates=23220, lr=4.16434e-05, gnorm=0.322, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=94261
2023-01-07 17:00:48 - progress_bar.py[line:274] - INFO: epoch 001:  23261 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4398, wps=98.6, ups=0.46, wpb=107.1, bsz=40, num_updates=23230, lr=4.16389e-05, gnorm=0.286, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=94284
2023-01-07 17:01:11 - progress_bar.py[line:274] - INFO: epoch 001:  23271 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4764, wps=104.7, ups=0.47, wpb=110.6, bsz=40, num_updates=23240, lr=4.16344e-05, gnorm=0.322, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94306
2023-01-07 17:01:33 - progress_bar.py[line:274] - INFO: epoch 001:  23281 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4279, wps=99.8, ups=0.46, wpb=107.6, bsz=40, num_updates=23250, lr=4.163e-05, gnorm=0.216, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=94328
2023-01-07 17:01:55 - progress_bar.py[line:274] - INFO: epoch 001:  23291 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.392, wps=100.8, ups=0.47, wpb=108.2, bsz=40, num_updates=23260, lr=4.16255e-05, gnorm=0.257, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=94350
2023-01-07 17:02:18 - progress_bar.py[line:274] - INFO: epoch 001:  23301 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4513, wps=99.4, ups=0.45, wpb=109.3, bsz=40, num_updates=23270, lr=4.1621e-05, gnorm=0.29, clip=0, loss_scale=1024, train_wall=22, gb_free=9.4, ema_decay=0.9999, wall=94373
2023-01-07 17:02:40 - progress_bar.py[line:274] - INFO: epoch 001:  23311 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.425, wps=102.8, ups=0.47, wpb=108.9, bsz=40, num_updates=23280, lr=4.16165e-05, gnorm=0.4, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=94396
2023-01-07 17:03:03 - progress_bar.py[line:274] - INFO: epoch 001:  23321 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4718, wps=99.7, ups=0.46, wpb=108.6, bsz=40, num_updates=23290, lr=4.1612e-05, gnorm=0.354, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94418
2023-01-07 17:03:25 - progress_bar.py[line:274] - INFO: epoch 001:  23331 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4531, wps=102.5, ups=0.47, wpb=110.1, bsz=40, num_updates=23300, lr=4.16075e-05, gnorm=0.307, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94440
2023-01-07 17:03:47 - progress_bar.py[line:274] - INFO: epoch 001:  23341 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.455, wps=100.5, ups=0.47, wpb=107.8, bsz=40, num_updates=23310, lr=4.1603e-05, gnorm=0.314, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=94462
2023-01-07 17:04:09 - progress_bar.py[line:274] - INFO: epoch 001:  23351 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3938, wps=100, ups=0.47, wpb=107.2, bsz=40, num_updates=23320, lr=4.15985e-05, gnorm=0.199, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94485
2023-01-07 17:04:32 - progress_bar.py[line:274] - INFO: epoch 001:  23361 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4362, wps=102.3, ups=0.46, wpb=110.3, bsz=40, num_updates=23330, lr=4.1594e-05, gnorm=0.2, clip=0, loss_scale=1024, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=94507
2023-01-07 17:04:54 - progress_bar.py[line:274] - INFO: epoch 001:  23371 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4309, wps=101.4, ups=0.47, wpb=108.6, bsz=40, num_updates=23340, lr=4.15895e-05, gnorm=0.228, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94529
2023-01-07 17:05:16 - progress_bar.py[line:274] - INFO: epoch 001:  23381 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4184, wps=101.2, ups=0.46, wpb=109, bsz=40, num_updates=23350, lr=4.1585e-05, gnorm=0.324, clip=0, loss_scale=1024, train_wall=21, gb_free=10.7, ema_decay=0.9999, wall=94552
2023-01-07 17:05:38 - progress_bar.py[line:274] - INFO: epoch 001:  23391 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4471, wps=103.5, ups=0.47, wpb=109, bsz=40, num_updates=23360, lr=4.15805e-05, gnorm=0.299, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=94574
2023-01-07 17:06:00 - progress_bar.py[line:274] - INFO: epoch 001:  23401 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4432, wps=105.1, ups=0.47, wpb=110.7, bsz=40, num_updates=23370, lr=4.1576e-05, gnorm=0.346, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=94596
2023-01-07 17:06:22 - progress_bar.py[line:274] - INFO: epoch 001:  23411 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4785, wps=101.6, ups=0.47, wpb=108.7, bsz=40, num_updates=23380, lr=4.15715e-05, gnorm=0.306, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94618
2023-01-07 17:06:44 - progress_bar.py[line:274] - INFO: epoch 001:  23421 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4884, wps=102.1, ups=0.47, wpb=108.4, bsz=40, num_updates=23390, lr=4.1567e-05, gnorm=0.143, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94640
2023-01-07 17:07:07 - progress_bar.py[line:274] - INFO: epoch 001:  23431 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4866, wps=102.8, ups=0.46, wpb=110.7, bsz=40, num_updates=23400, lr=4.15625e-05, gnorm=0.252, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=94662
2023-01-07 17:07:29 - progress_bar.py[line:274] - INFO: epoch 001:  23441 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.53, wps=100.7, ups=0.46, wpb=109.1, bsz=40, num_updates=23410, lr=4.1558e-05, gnorm=0.205, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=94684
2023-01-07 17:07:52 - progress_bar.py[line:274] - INFO: epoch 001:  23451 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4569, wps=100, ups=0.46, wpb=108.5, bsz=40, num_updates=23420, lr=4.15535e-05, gnorm=0.313, clip=10, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94707
2023-01-07 17:08:14 - progress_bar.py[line:274] - INFO: epoch 001:  23461 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5075, wps=100.7, ups=0.47, wpb=108.1, bsz=40, num_updates=23430, lr=4.1549e-05, gnorm=0.259, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94729
2023-01-07 17:08:36 - progress_bar.py[line:274] - INFO: epoch 001:  23471 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4811, wps=100.9, ups=0.47, wpb=107.5, bsz=40, num_updates=23440, lr=4.15445e-05, gnorm=0.269, clip=0, loss_scale=1024, train_wall=21, gb_free=9.7, ema_decay=0.9999, wall=94751
2023-01-07 17:08:58 - progress_bar.py[line:274] - INFO: epoch 001:  23481 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4833, wps=100.4, ups=0.46, wpb=108.1, bsz=40, num_updates=23450, lr=4.154e-05, gnorm=0.309, clip=0, loss_scale=1024, train_wall=21, gb_free=10.1, ema_decay=0.9999, wall=94773
2023-01-07 17:09:20 - progress_bar.py[line:274] - INFO: epoch 001:  23491 / 115845 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4562, wps=100.6, ups=0.47, wpb=107.5, bsz=40, num_updates=23460, lr=4.15355e-05, gnorm=0.313, clip=10, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=94795
2023-01-07 17:09:42 - progress_bar.py[line:274] - INFO: epoch 001:  23501 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4899, wps=103.7, ups=0.47, wpb=109.4, bsz=40, num_updates=23470, lr=4.1531e-05, gnorm=0.176, clip=0, loss_scale=1024, train_wall=21, gb_free=10.5, ema_decay=0.9999, wall=94817
2023-01-07 17:10:04 - progress_bar.py[line:274] - INFO: epoch 001:  23511 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5025, wps=101.6, ups=0.46, wpb=110.2, bsz=40, num_updates=23480, lr=4.15265e-05, gnorm=0.259, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=94839
2023-01-07 17:10:26 - progress_bar.py[line:274] - INFO: epoch 001:  23521 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4201, wps=99.3, ups=0.46, wpb=107.5, bsz=40, num_updates=23490, lr=4.1522e-05, gnorm=0.238, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=94862
2023-01-07 17:10:48 - progress_bar.py[line:274] - INFO: epoch 001:  23531 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.414, wps=103.2, ups=0.47, wpb=110.4, bsz=40, num_updates=23500, lr=4.15176e-05, gnorm=0.245, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=94884
2023-01-07 17:11:10 - progress_bar.py[line:274] - INFO: epoch 001:  23541 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4332, wps=105.3, ups=0.48, wpb=110.1, bsz=40, num_updates=23510, lr=4.15131e-05, gnorm=0.231, clip=10, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94905
2023-01-07 17:11:33 - progress_bar.py[line:274] - INFO: epoch 001:  23551 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5071, wps=99.3, ups=0.46, wpb=108.8, bsz=40, num_updates=23520, lr=4.15086e-05, gnorm=0.279, clip=0, loss_scale=1024, train_wall=22, gb_free=10, ema_decay=0.9999, wall=94928
2023-01-07 17:11:55 - progress_bar.py[line:274] - INFO: epoch 001:  23561 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4051, wps=101.4, ups=0.46, wpb=110.2, bsz=40, num_updates=23530, lr=4.15041e-05, gnorm=0.244, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=94950
2023-01-07 17:12:17 - progress_bar.py[line:274] - INFO: epoch 001:  23571 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4749, wps=101.3, ups=0.47, wpb=107, bsz=40, num_updates=23540, lr=4.14996e-05, gnorm=0.324, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=94972
2023-01-07 17:12:39 - progress_bar.py[line:274] - INFO: epoch 001:  23581 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4706, wps=103.6, ups=0.47, wpb=109.2, bsz=40, num_updates=23550, lr=4.14951e-05, gnorm=0.264, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=94994
2023-01-07 17:13:01 - progress_bar.py[line:274] - INFO: epoch 001:  23591 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4265, wps=100.3, ups=0.46, wpb=109.3, bsz=40, num_updates=23560, lr=4.14906e-05, gnorm=0.187, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95017
2023-01-07 17:13:24 - progress_bar.py[line:274] - INFO: epoch 001:  23601 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4845, wps=102.3, ups=0.47, wpb=109.9, bsz=40, num_updates=23570, lr=4.14861e-05, gnorm=0.444, clip=10, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=95039
2023-01-07 17:13:46 - progress_bar.py[line:274] - INFO: epoch 001:  23611 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4381, wps=100.7, ups=0.46, wpb=109.3, bsz=40, num_updates=23580, lr=4.14816e-05, gnorm=0.156, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95061
2023-01-07 17:14:08 - progress_bar.py[line:274] - INFO: epoch 001:  23621 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4555, wps=103.1, ups=0.47, wpb=110.1, bsz=40, num_updates=23590, lr=4.14771e-05, gnorm=0.275, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95083
2023-01-07 17:14:29 - progress_bar.py[line:274] - INFO: epoch 001:  23631 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5122, wps=105.5, ups=0.48, wpb=109, bsz=40, num_updates=23600, lr=4.14726e-05, gnorm=0.299, clip=0, loss_scale=1024, train_wall=21, gb_free=10.6, ema_decay=0.9999, wall=95105
2023-01-07 17:14:52 - progress_bar.py[line:274] - INFO: epoch 001:  23641 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4833, wps=101, ups=0.46, wpb=108.7, bsz=40, num_updates=23610, lr=4.14681e-05, gnorm=0.433, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95127
2023-01-07 17:15:14 - progress_bar.py[line:274] - INFO: epoch 001:  23651 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3886, wps=101.4, ups=0.47, wpb=107.5, bsz=40, num_updates=23620, lr=4.14636e-05, gnorm=0.294, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95149
2023-01-07 17:15:35 - progress_bar.py[line:274] - INFO: epoch 001:  23661 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4789, wps=105.3, ups=0.48, wpb=109.8, bsz=40, num_updates=23630, lr=4.14591e-05, gnorm=0.42, clip=10, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95171
2023-01-07 17:15:59 - progress_bar.py[line:274] - INFO: epoch 001:  23671 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4521, wps=99.4, ups=0.46, wpb=108, bsz=40, num_updates=23640, lr=4.14546e-05, gnorm=0.302, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95193
2023-01-07 17:16:21 - progress_bar.py[line:274] - INFO: epoch 001:  23681 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4615, wps=100.9, ups=0.46, wpb=108.8, bsz=40, num_updates=23650, lr=4.14501e-05, gnorm=0.224, clip=0, loss_scale=2048, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95216
2023-01-07 17:16:44 - progress_bar.py[line:274] - INFO: epoch 001:  23691 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3861, wps=102.6, ups=0.47, wpb=108.7, bsz=40, num_updates=23660, lr=4.14456e-05, gnorm=0.19, clip=0, loss_scale=2048, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95238
2023-01-07 17:17:07 - progress_bar.py[line:274] - INFO: epoch 001:  23701 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4498, wps=99.8, ups=0.46, wpb=108.3, bsz=40, num_updates=23670, lr=4.14411e-05, gnorm=0.368, clip=0, loss_scale=2048, train_wall=22, gb_free=10.1, ema_decay=0.9999, wall=95262
2023-01-07 17:17:29 - progress_bar.py[line:274] - INFO: epoch 001:  23711 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4219, wps=104.4, ups=0.47, wpb=110.1, bsz=40, num_updates=23680, lr=4.14366e-05, gnorm=0.243, clip=0, loss_scale=2048, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=95284
2023-01-07 17:17:40 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2023-01-07 17:17:55 - progress_bar.py[line:274] - INFO: epoch 001:  23722 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=108.381, nsentences=40, sample_size=108.381, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4876, wps=96.8, ups=0.43, wpb=108.4, bsz=40, num_updates=23690, lr=4.14321e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=23, gb_free=10.2, ema_decay=0.9999, wall=95309
2023-01-07 17:18:17 - progress_bar.py[line:274] - INFO: epoch 001:  23732 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.408, wps=103.5, ups=0.47, wpb=109.5, bsz=40, num_updates=23700, lr=4.14276e-05, gnorm=0.183, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=95332
2023-01-07 17:18:40 - progress_bar.py[line:274] - INFO: epoch 001:  23742 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4892, wps=104.1, ups=0.47, wpb=109.9, bsz=40, num_updates=23710, lr=4.14231e-05, gnorm=0.186, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95355
2023-01-07 17:19:03 - progress_bar.py[line:274] - INFO: epoch 001:  23752 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3907, wps=103, ups=0.47, wpb=109.2, bsz=40, num_updates=23720, lr=4.14186e-05, gnorm=0.148, clip=0, loss_scale=1024, train_wall=21, gb_free=10, ema_decay=0.9999, wall=95378
2023-01-07 17:19:25 - progress_bar.py[line:274] - INFO: epoch 001:  23762 / 115845 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=106.1, nsentences=40, sample_size=106.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4623, wps=100.4, ups=0.47, wpb=106.1, bsz=40, num_updates=23730, lr=4.14141e-05, gnorm=0.157, clip=0, loss_scale=1024, train_wall=21, gb_free=9.4, ema_decay=0.9999, wall=95400
2023-01-07 17:19:48 - progress_bar.py[line:274] - INFO: epoch 001:  23772 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4118, wps=99.8, ups=0.46, wpb=108.4, bsz=40, num_updates=23740, lr=4.14097e-05, gnorm=0.217, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95423
2023-01-07 17:20:12 - progress_bar.py[line:274] - INFO: epoch 001:  23782 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4162, wps=100.4, ups=0.46, wpb=109.7, bsz=40, num_updates=23750, lr=4.14052e-05, gnorm=0.214, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95446
2023-01-07 17:20:35 - progress_bar.py[line:274] - INFO: epoch 001:  23792 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4813, wps=99.1, ups=0.45, wpb=110, bsz=40, num_updates=23760, lr=4.14007e-05, gnorm=0.276, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=95470
2023-01-07 17:20:58 - progress_bar.py[line:274] - INFO: epoch 001:  23802 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4354, wps=103.5, ups=0.47, wpb=109.3, bsz=40, num_updates=23770, lr=4.13962e-05, gnorm=0.205, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95493
2023-01-07 17:21:23 - progress_bar.py[line:274] - INFO: epoch 001:  23812 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4188, wps=95.4, ups=0.44, wpb=109.3, bsz=40, num_updates=23780, lr=4.13917e-05, gnorm=0.2, clip=0, loss_scale=1024, train_wall=23, gb_free=10.4, ema_decay=0.9999, wall=95517
2023-01-07 17:21:45 - progress_bar.py[line:274] - INFO: epoch 001:  23822 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4641, wps=99.9, ups=0.46, wpb=107.9, bsz=40, num_updates=23790, lr=4.13872e-05, gnorm=0.182, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95540
2023-01-07 17:22:08 - progress_bar.py[line:274] - INFO: epoch 001:  23832 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4476, wps=100.3, ups=0.46, wpb=107.9, bsz=40, num_updates=23800, lr=4.13827e-05, gnorm=0.279, clip=10, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95563
2023-01-07 17:22:31 - progress_bar.py[line:274] - INFO: epoch 001:  23842 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4247, wps=99.3, ups=0.46, wpb=108, bsz=40, num_updates=23810, lr=4.13782e-05, gnorm=0.2, clip=0, loss_scale=1024, train_wall=22, gb_free=10.2, ema_decay=0.9999, wall=95586
2023-01-07 17:22:54 - progress_bar.py[line:274] - INFO: epoch 001:  23852 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4667, wps=102.7, ups=0.47, wpb=110, bsz=40, num_updates=23820, lr=4.13737e-05, gnorm=0.119, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95608
2023-01-07 17:23:17 - progress_bar.py[line:274] - INFO: epoch 001:  23862 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4822, wps=101.1, ups=0.46, wpb=109.2, bsz=40, num_updates=23830, lr=4.13692e-05, gnorm=0.344, clip=10, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95632
2023-01-07 17:23:40 - progress_bar.py[line:274] - INFO: epoch 001:  23872 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4611, wps=102.1, ups=0.47, wpb=109.6, bsz=40, num_updates=23840, lr=4.13647e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=95654
2023-01-07 17:24:03 - progress_bar.py[line:274] - INFO: epoch 001:  23882 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4842, wps=102.5, ups=0.47, wpb=109.7, bsz=40, num_updates=23850, lr=4.13602e-05, gnorm=0.194, clip=0, loss_scale=1024, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95677
2023-01-07 17:24:25 - progress_bar.py[line:274] - INFO: epoch 001:  23892 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4475, wps=103.3, ups=0.48, wpb=108.2, bsz=40, num_updates=23860, lr=4.13557e-05, gnorm=0.235, clip=0, loss_scale=1024, train_wall=21, gb_free=9.9, ema_decay=0.9999, wall=95700
2023-01-07 17:24:47 - progress_bar.py[line:274] - INFO: epoch 001:  23902 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4352, wps=104.5, ups=0.48, wpb=109.7, bsz=40, num_updates=23870, lr=4.13512e-05, gnorm=0.254, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95722
2023-01-07 17:25:11 - progress_bar.py[line:274] - INFO: epoch 001:  23912 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4308, wps=101.2, ups=0.46, wpb=110.2, bsz=40, num_updates=23880, lr=4.13467e-05, gnorm=0.198, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95745
2023-01-07 17:25:34 - progress_bar.py[line:274] - INFO: epoch 001:  23922 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4439, wps=101.5, ups=0.47, wpb=108.9, bsz=40, num_updates=23890, lr=4.13422e-05, gnorm=0.177, clip=0, loss_scale=1024, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95768
2023-01-07 17:25:57 - progress_bar.py[line:274] - INFO: epoch 001:  23932 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4683, wps=99.1, ups=0.46, wpb=107.7, bsz=40, num_updates=23900, lr=4.13377e-05, gnorm=0.29, clip=0, loss_scale=1024, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=95791
2023-01-07 17:26:20 - progress_bar.py[line:274] - INFO: epoch 001:  23942 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.476, wps=100.7, ups=0.46, wpb=109.6, bsz=40, num_updates=23910, lr=4.13332e-05, gnorm=0.235, clip=0, loss_scale=1024, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95815
2023-01-07 17:26:43 - progress_bar.py[line:274] - INFO: epoch 001:  23952 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4698, wps=100.8, ups=0.46, wpb=108.4, bsz=40, num_updates=23920, lr=4.13287e-05, gnorm=0.33, clip=0, loss_scale=1024, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=95837
2023-01-07 17:26:58 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 17:27:08 - progress_bar.py[line:274] - INFO: epoch 001:  23963 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.714, nsentences=40, sample_size=109.714, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4976, wps=98.2, ups=0.43, wpb=109.7, bsz=40, num_updates=23930, lr=4.13242e-05, gnorm=0.213, clip=0, loss_scale=512, train_wall=23, gb_free=9.7, ema_decay=0.9999, wall=95862
2023-01-07 17:27:31 - progress_bar.py[line:274] - INFO: epoch 001:  23973 / 115845 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.15, vqa_score=0.4528, wps=98.3, ups=0.46, wpb=107, bsz=40, num_updates=23940, lr=4.13197e-05, gnorm=0.293, clip=0, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95886
2023-01-07 17:27:54 - progress_bar.py[line:274] - INFO: epoch 001:  23983 / 115845 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4686, wps=102.9, ups=0.47, wpb=110.4, bsz=40, num_updates=23950, lr=4.13152e-05, gnorm=0.215, clip=0, loss_scale=512, train_wall=21, gb_free=10.2, ema_decay=0.9999, wall=95909
2023-01-07 17:28:16 - progress_bar.py[line:274] - INFO: epoch 001:  23993 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4643, wps=104.7, ups=0.48, wpb=108.8, bsz=40, num_updates=23960, lr=4.13107e-05, gnorm=0.231, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95931
2023-01-07 17:28:39 - progress_bar.py[line:274] - INFO: epoch 001:  24003 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.42, wps=102.1, ups=0.47, wpb=109.2, bsz=40, num_updates=23970, lr=4.13062e-05, gnorm=0.252, clip=0, loss_scale=512, train_wall=21, gb_free=10.4, ema_decay=0.9999, wall=95954
2023-01-07 17:29:03 - progress_bar.py[line:274] - INFO: epoch 001:  24013 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3668, wps=100.5, ups=0.46, wpb=109.7, bsz=40, num_updates=23980, lr=4.13017e-05, gnorm=0.308, clip=10, loss_scale=512, train_wall=22, gb_free=10.3, ema_decay=0.9999, wall=95977
2023-01-07 17:29:26 - progress_bar.py[line:274] - INFO: epoch 001:  24023 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4663, wps=101.2, ups=0.47, wpb=107.7, bsz=40, num_updates=23990, lr=4.12973e-05, gnorm=0.309, clip=0, loss_scale=512, train_wall=21, gb_free=10.3, ema_decay=0.9999, wall=96000
2023-01-07 17:29:49 - progress_bar.py[line:274] - INFO: epoch 001:  24033 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5323, wps=101.8, ups=0.46, wpb=111.5, bsz=40, num_updates=24000, lr=4.12928e-05, gnorm=0.185, clip=0, loss_scale=512, train_wall=22, gb_free=10.4, ema_decay=0.9999, wall=96024
2023-01-07 17:29:49 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 17:29:51 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 17:29:51 - train.py[line:551] - INFO: load:1.17 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 17:29:51 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 39.59 GiB total capacity; 8.80 GiB already allocated; 2.26 GiB free; 34.84 GiB reserved in total by PyTorch)
2023-01-07 17:29:51 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 28        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9013 MB |   10146 MB |   13635 TB |   13635 TB |
|       from large pool |    8839 MB |    9971 MB |   13629 TB |   13629 TB |
|       from small pool |     174 MB |     174 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9013 MB |   10146 MB |   13635 TB |   13635 TB |
|       from large pool |    8839 MB |    9971 MB |   13629 TB |   13629 TB |
|       from small pool |     174 MB |     174 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   35678 MB |   35684 MB |  300400 MB |  264722 MB |
|       from large pool |   35502 MB |   35502 MB |  299970 MB |  264468 MB |
|       from small pool |     176 MB |     182 MB |     430 MB |     254 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   26664 MB |   30738 MB |   15916 TB |   15916 TB |
|       from large pool |   26662 MB |   30736 MB |   15910 TB |   15910 TB |
|       from small pool |       1 MB |       2 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  645505 K  |  645501 K  |
|       from large pool |     698    |     710    |  198634 K  |  198634 K  |
|       from small pool |    3925    |    3943    |  446871 K  |  446867 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  645505 K  |  645501 K  |
|       from large pool |     698    |     710    |  198634 K  |  198634 K  |
|       from small pool |    3925    |    3943    |  446871 K  |  446867 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     155    |     158    |     632    |     477    |
|       from large pool |      67    |      67    |     417    |     350    |
|       from small pool |      88    |      91    |     215    |     127    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     122    |     126    |  474059 K  |  474059 K  |
|       from large pool |      63    |      64    |   91663 K  |   91663 K  |
|       from small pool |      59    |      66    |  382395 K  |  382395 K  |
|===========================================================================|

2023-01-07 17:29:51 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-07 17:29:51 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-07 17:32:23 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 17:32:23 - train.py[line:551] - INFO: load:1.19 valid_run:152.61 task_valid:147.63 collect_output:2.98
2023-01-07 17:34:52 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 17:34:52 - train.py[line:551] - INFO: load:1.22 valid_run:301.64 task_valid:290.60 collect_output:8.03
2023-01-07 17:37:26 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 17:37:26 - train.py[line:551] - INFO: load:1.24 valid_run:455.21 task_valid:433.40 collect_output:17.78
2023-01-07 17:40:50 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 17:40:50 - train.py[line:551] - INFO: load:1.27 valid_run:659.21 task_valid:633.15 collect_output:20.53
2023-01-07 17:45:09 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 17:45:09 - train.py[line:551] - INFO: load:1.29 valid_run:918.37 task_valid:889.72 collect_output:21.10
2023-01-07 17:49:24 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 17:49:24 - train.py[line:551] - INFO: load:1.32 valid_run:1173.35 task_valid:1142.06 collect_output:21.65
2023-01-07 17:53:39 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 17:53:39 - train.py[line:551] - INFO: load:1.35 valid_run:1428.03 task_valid:1394.13 collect_output:22.19
2023-01-07 17:57:48 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 17:57:48 - train.py[line:551] - INFO: load:1.38 valid_run:1676.37 task_valid:1639.86 collect_output:22.75
2023-01-07 18:02:01 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 18:02:01 - train.py[line:551] - INFO: load:1.40 valid_run:1929.56 task_valid:1890.48 collect_output:23.29
2023-01-07 18:06:12 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 18:06:12 - train.py[line:551] - INFO: load:1.43 valid_run:2180.28 task_valid:2138.60 collect_output:23.83
2023-01-07 18:10:25 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 18:10:25 - train.py[line:551] - INFO: load:1.46 valid_run:2433.13 task_valid:2388.86 collect_output:24.38
2023-01-07 18:14:39 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 18:14:39 - train.py[line:551] - INFO: load:1.48 valid_run:2687.42 task_valid:2640.50 collect_output:24.95
2023-01-07 18:18:51 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 18:18:51 - train.py[line:551] - INFO: load:1.51 valid_run:2939.14 task_valid:2889.43 collect_output:25.53
2023-01-07 18:23:05 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 18:23:05 - train.py[line:551] - INFO: load:1.54 valid_run:3193.09 task_valid:3140.78 collect_output:26.09
2023-01-07 18:27:20 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 18:27:20 - train.py[line:551] - INFO: load:1.56 valid_run:3448.41 task_valid:3393.46 collect_output:26.67
2023-01-07 18:31:33 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 18:31:33 - train.py[line:551] - INFO: load:1.59 valid_run:3701.17 task_valid:3643.56 collect_output:27.25
2023-01-07 18:35:48 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 18:35:48 - train.py[line:551] - INFO: load:1.62 valid_run:3955.63 task_valid:3895.38 collect_output:27.83
2023-01-07 18:40:03 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 18:40:03 - train.py[line:551] - INFO: load:1.65 valid_run:4211.16 task_valid:4148.29 collect_output:28.40
2023-01-07 18:44:12 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 18:44:12 - train.py[line:551] - INFO: load:1.67 valid_run:4460.33 task_valid:4394.84 collect_output:28.99
2023-01-07 18:48:28 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 18:48:28 - train.py[line:551] - INFO: load:1.70 valid_run:4715.92 task_valid:4647.80 collect_output:29.57
2023-01-07 18:52:41 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 18:52:41 - train.py[line:551] - INFO: load:1.73 valid_run:4968.59 task_valid:4897.82 collect_output:30.15
2023-01-07 18:56:54 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 18:56:54 - train.py[line:551] - INFO: load:1.76 valid_run:5221.61 task_valid:5148.21 collect_output:30.73
2023-01-07 19:01:09 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 19:01:09 - train.py[line:551] - INFO: load:1.79 valid_run:5476.88 task_valid:5400.86 collect_output:31.32
2023-01-07 19:05:25 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 19:05:25 - train.py[line:551] - INFO: load:1.81 valid_run:5732.09 task_valid:5653.44 collect_output:31.90

====================================================================================================
SGG eval:     R @ 50: 0.3730;     R @ 100: 0.4371;     R @ 500: 0.4599;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2343;    mR @ 100: 0.2876;    mR @ 500: 0.3102;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3902) (covered in:0.8125) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6667) (playing:0.0000) (riding:0.4788) (says:0.0000) (sitting on:0.6874) (standing on:0.1350) (using:0.7000) (walking in:0.0000) (walking on:0.1892) (watching:0.0972) 
--------------------------------------------------------
====================================================================================================

2023-01-07 19:09:35 - train.py[line:487] - INFO: 0.43706190476190476
2023-01-07 19:09:35 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.3730;     R @ 100: 0.4371;     R @ 500: 0.4599;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2343;    mR @ 100: 0.2876;    mR @ 500: 0.3102;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3902) (covered in:0.8125) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6667) (playing:0.0000) (riding:0.4788) (says:0.0000) (sitting on:0.6874) (standing on:0.1350) (using:0.7000) (walking in:0.0000) (walking on:0.1892) (watching:0.0972) 
--------------------------------------------------------
====================================================================================================

2023-01-07 19:09:35 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.394 | loss_v1 0 | loss_v2 0 | nll_loss 0.245 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.437062 | ppl 1.19 | vqa_score 0.3446 | wps 75 | wpb 89.9 | bsz 30 | num_updates 24000 | best_R@100 0.641887
2023-01-07 19:09:35 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 24000 updates
2023-01-07 19:09:35 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_24000.pt
2023-01-07 19:10:20 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_24000.pt
2023-01-07 19:11:58 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_24000.pt (epoch 1 @ 24000 updates, score 0.43706190476190476) (writing took 142.4495513997972 seconds)
2023-01-07 19:12:29 - progress_bar.py[line:274] - INFO: epoch 001:  24043 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4162, wps=0.4, ups=0, wpb=109, bsz=40, num_updates=24010, lr=4.12883e-05, gnorm=0.302, clip=0, loss_scale=512, train_wall=31, gb_free=10.1, ema_decay=0.9999, wall=102185
2023-01-07 19:13:00 - progress_bar.py[line:274] - INFO: epoch 001:  24053 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5185, wps=70.4, ups=0.32, wpb=109.1, bsz=40, num_updates=24020, lr=4.12838e-05, gnorm=0.221, clip=0, loss_scale=512, train_wall=31, gb_free=10.5, ema_decay=0.9999, wall=102216
2023-01-07 19:13:30 - progress_bar.py[line:274] - INFO: epoch 001:  24063 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4488, wps=72.5, ups=0.34, wpb=108.1, bsz=40, num_updates=24030, lr=4.12793e-05, gnorm=0.149, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=102246
2023-01-07 19:14:01 - progress_bar.py[line:274] - INFO: epoch 001:  24073 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4836, wps=72.2, ups=0.33, wpb=108.8, bsz=40, num_updates=24040, lr=4.12748e-05, gnorm=0.126, clip=0, loss_scale=512, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=102277
2023-01-07 19:14:32 - progress_bar.py[line:274] - INFO: epoch 001:  24083 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4826, wps=71.6, ups=0.33, wpb=109.5, bsz=40, num_updates=24050, lr=4.12703e-05, gnorm=0.291, clip=0, loss_scale=512, train_wall=31, gb_free=10.3, ema_decay=0.9999, wall=102307
2023-01-07 19:15:02 - progress_bar.py[line:274] - INFO: epoch 001:  24093 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4826, wps=71, ups=0.33, wpb=108.4, bsz=40, num_updates=24060, lr=4.12658e-05, gnorm=0.201, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=102338
2023-01-07 19:15:32 - progress_bar.py[line:274] - INFO: epoch 001:  24103 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3738, wps=72.1, ups=0.33, wpb=107.6, bsz=40, num_updates=24070, lr=4.12613e-05, gnorm=0.346, clip=10, loss_scale=512, train_wall=30, gb_free=9.7, ema_decay=0.9999, wall=102368
2023-01-07 19:16:02 - progress_bar.py[line:274] - INFO: epoch 001:  24113 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.485, wps=73.3, ups=0.34, wpb=108.2, bsz=40, num_updates=24080, lr=4.12568e-05, gnorm=0.229, clip=0, loss_scale=512, train_wall=29, gb_free=10.3, ema_decay=0.9999, wall=102398
2023-01-07 19:16:33 - progress_bar.py[line:274] - INFO: epoch 001:  24123 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3969, wps=72.3, ups=0.33, wpb=109.1, bsz=40, num_updates=24090, lr=4.12523e-05, gnorm=0.394, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=102428
2023-01-07 19:17:03 - progress_bar.py[line:274] - INFO: epoch 001:  24133 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.405, wps=71.3, ups=0.33, wpb=109.3, bsz=40, num_updates=24100, lr=4.12478e-05, gnorm=0.314, clip=0, loss_scale=512, train_wall=31, gb_free=10.3, ema_decay=0.9999, wall=102459
2023-01-07 19:17:34 - progress_bar.py[line:274] - INFO: epoch 001:  24143 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4433, wps=72.8, ups=0.33, wpb=110.4, bsz=40, num_updates=24110, lr=4.12433e-05, gnorm=0.201, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=102490
2023-01-07 19:18:05 - progress_bar.py[line:274] - INFO: epoch 001:  24153 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3679, wps=71, ups=0.33, wpb=109.1, bsz=40, num_updates=24120, lr=4.12388e-05, gnorm=0.465, clip=10, loss_scale=512, train_wall=31, gb_free=10.4, ema_decay=0.9999, wall=102521
2023-01-07 19:18:35 - progress_bar.py[line:274] - INFO: epoch 001:  24163 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4417, wps=72.3, ups=0.33, wpb=109, bsz=40, num_updates=24130, lr=4.12343e-05, gnorm=0.178, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=102551
2023-01-07 19:19:06 - progress_bar.py[line:274] - INFO: epoch 001:  24173 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3979, wps=73.1, ups=0.33, wpb=110.2, bsz=40, num_updates=24140, lr=4.12298e-05, gnorm=0.334, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=102582
2023-01-07 19:19:37 - progress_bar.py[line:274] - INFO: epoch 001:  24183 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3684, wps=71.8, ups=0.33, wpb=109.6, bsz=40, num_updates=24150, lr=4.12253e-05, gnorm=0.269, clip=0, loss_scale=512, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=102613
2023-01-07 19:20:07 - progress_bar.py[line:274] - INFO: epoch 001:  24193 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.495, wps=71.6, ups=0.33, wpb=109.2, bsz=40, num_updates=24160, lr=4.12208e-05, gnorm=0.369, clip=10, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=102643
2023-01-07 19:20:37 - progress_bar.py[line:274] - INFO: epoch 001:  24203 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4112, wps=73.4, ups=0.34, wpb=109.1, bsz=40, num_updates=24170, lr=4.12163e-05, gnorm=0.373, clip=10, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=102673
2023-01-07 19:21:08 - progress_bar.py[line:274] - INFO: epoch 001:  24213 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4745, wps=72.6, ups=0.33, wpb=108.8, bsz=40, num_updates=24180, lr=4.12118e-05, gnorm=0.243, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=102703
2023-01-07 19:21:38 - progress_bar.py[line:274] - INFO: epoch 001:  24223 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4824, wps=73.1, ups=0.33, wpb=109.2, bsz=40, num_updates=24190, lr=4.12073e-05, gnorm=0.262, clip=0, loss_scale=512, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=102734
2023-01-07 19:22:07 - progress_bar.py[line:274] - INFO: epoch 001:  24233 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4439, wps=74.3, ups=0.34, wpb=108.9, bsz=40, num_updates=24200, lr=4.12028e-05, gnorm=0.251, clip=0, loss_scale=512, train_wall=29, gb_free=9.9, ema_decay=0.9999, wall=102763
2023-01-07 19:22:38 - progress_bar.py[line:274] - INFO: epoch 001:  24243 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4429, wps=71.2, ups=0.33, wpb=107.9, bsz=40, num_updates=24210, lr=4.11983e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=102794
2023-01-07 19:23:08 - progress_bar.py[line:274] - INFO: epoch 001:  24253 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4554, wps=72.9, ups=0.33, wpb=109.3, bsz=40, num_updates=24220, lr=4.11938e-05, gnorm=0.382, clip=10, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=102824
2023-01-07 19:23:40 - progress_bar.py[line:274] - INFO: epoch 001:  24263 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.3981, wps=69.9, ups=0.32, wpb=108.4, bsz=40, num_updates=24230, lr=4.11894e-05, gnorm=0.324, clip=10, loss_scale=512, train_wall=31, gb_free=10.1, ema_decay=0.9999, wall=102855
2023-01-07 19:24:10 - progress_bar.py[line:274] - INFO: epoch 001:  24273 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4603, wps=73.9, ups=0.34, wpb=110.1, bsz=40, num_updates=24240, lr=4.11849e-05, gnorm=0.346, clip=0, loss_scale=512, train_wall=30, gb_free=10.7, ema_decay=0.9999, wall=102885
2023-01-07 19:24:40 - progress_bar.py[line:274] - INFO: epoch 001:  24283 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4061, wps=72.8, ups=0.33, wpb=109.9, bsz=40, num_updates=24250, lr=4.11804e-05, gnorm=0.301, clip=0, loss_scale=512, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=102916
2023-01-07 19:25:11 - progress_bar.py[line:274] - INFO: epoch 001:  24293 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=106.9, nsentences=40, sample_size=106.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4693, wps=70.1, ups=0.33, wpb=106.9, bsz=40, num_updates=24260, lr=4.11759e-05, gnorm=0.356, clip=10, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=102947
2023-01-07 19:25:41 - progress_bar.py[line:274] - INFO: epoch 001:  24303 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4828, wps=73.4, ups=0.33, wpb=109.9, bsz=40, num_updates=24270, lr=4.11714e-05, gnorm=0.407, clip=10, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=102977
2023-01-07 19:26:11 - progress_bar.py[line:274] - INFO: epoch 001:  24313 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.1, nsentences=40, sample_size=107.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3927, wps=71.1, ups=0.33, wpb=107.1, bsz=40, num_updates=24280, lr=4.11669e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=30, gb_free=10, ema_decay=0.9999, wall=103007
2023-01-07 19:26:42 - progress_bar.py[line:274] - INFO: epoch 001:  24323 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4659, wps=72.2, ups=0.33, wpb=110.2, bsz=40, num_updates=24290, lr=4.11624e-05, gnorm=0.427, clip=10, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=103038
2023-01-07 19:27:13 - progress_bar.py[line:274] - INFO: epoch 001:  24333 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3862, wps=71.9, ups=0.33, wpb=109.7, bsz=40, num_updates=24300, lr=4.11579e-05, gnorm=0.182, clip=0, loss_scale=512, train_wall=30, gb_free=10.7, ema_decay=0.9999, wall=103069
2023-01-07 19:27:43 - progress_bar.py[line:274] - INFO: epoch 001:  24343 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4427, wps=74.3, ups=0.34, wpb=109.4, bsz=40, num_updates=24310, lr=4.11534e-05, gnorm=0.297, clip=0, loss_scale=512, train_wall=29, gb_free=10.3, ema_decay=0.9999, wall=103098
2023-01-07 19:28:12 - progress_bar.py[line:274] - INFO: epoch 001:  24353 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4127, wps=74.1, ups=0.34, wpb=109.2, bsz=40, num_updates=24320, lr=4.11489e-05, gnorm=0.281, clip=0, loss_scale=512, train_wall=29, gb_free=10.2, ema_decay=0.9999, wall=103128
2023-01-07 19:28:42 - progress_bar.py[line:274] - INFO: epoch 001:  24363 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4717, wps=72.9, ups=0.34, wpb=108.6, bsz=40, num_updates=24330, lr=4.11444e-05, gnorm=0.274, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103158
2023-01-07 19:29:13 - progress_bar.py[line:274] - INFO: epoch 001:  24373 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4372, wps=73, ups=0.33, wpb=110, bsz=40, num_updates=24340, lr=4.11399e-05, gnorm=0.392, clip=10, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103189
2023-01-07 19:29:44 - progress_bar.py[line:274] - INFO: epoch 001:  24383 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4689, wps=70.9, ups=0.33, wpb=108.8, bsz=40, num_updates=24350, lr=4.11354e-05, gnorm=0.263, clip=0, loss_scale=512, train_wall=31, gb_free=10.3, ema_decay=0.9999, wall=103220
2023-01-07 19:30:14 - progress_bar.py[line:274] - INFO: epoch 001:  24393 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4794, wps=72.4, ups=0.33, wpb=109, bsz=40, num_updates=24360, lr=4.11309e-05, gnorm=0.284, clip=0, loss_scale=512, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=103250
2023-01-07 19:30:44 - progress_bar.py[line:274] - INFO: epoch 001:  24403 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4038, wps=72.2, ups=0.33, wpb=108.8, bsz=40, num_updates=24370, lr=4.11264e-05, gnorm=0.493, clip=10, loss_scale=512, train_wall=30, gb_free=10.7, ema_decay=0.9999, wall=103280
2023-01-07 19:31:15 - progress_bar.py[line:274] - INFO: epoch 001:  24413 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4593, wps=72.6, ups=0.33, wpb=108.8, bsz=40, num_updates=24380, lr=4.11219e-05, gnorm=0.302, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103310
2023-01-07 19:31:45 - progress_bar.py[line:274] - INFO: epoch 001:  24423 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.432, wps=72.6, ups=0.33, wpb=108.5, bsz=40, num_updates=24390, lr=4.11174e-05, gnorm=0.236, clip=0, loss_scale=512, train_wall=30, gb_free=9.7, ema_decay=0.9999, wall=103341
2023-01-07 19:32:15 - progress_bar.py[line:274] - INFO: epoch 001:  24433 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4251, wps=71.5, ups=0.33, wpb=107.8, bsz=40, num_updates=24400, lr=4.11129e-05, gnorm=0.335, clip=0, loss_scale=512, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=103371
2023-01-07 19:32:45 - progress_bar.py[line:274] - INFO: epoch 001:  24443 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4427, wps=73, ups=0.33, wpb=109.4, bsz=40, num_updates=24410, lr=4.11084e-05, gnorm=0.355, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103401
2023-01-07 19:33:15 - progress_bar.py[line:274] - INFO: epoch 001:  24453 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4785, wps=72.7, ups=0.33, wpb=108.7, bsz=40, num_updates=24420, lr=4.11039e-05, gnorm=0.263, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103431
2023-01-07 19:33:45 - progress_bar.py[line:274] - INFO: epoch 001:  24463 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5052, wps=73.4, ups=0.34, wpb=109.2, bsz=40, num_updates=24430, lr=4.10994e-05, gnorm=0.185, clip=0, loss_scale=512, train_wall=30, gb_free=9.9, ema_decay=0.9999, wall=103461
2023-01-07 19:34:16 - progress_bar.py[line:274] - INFO: epoch 001:  24473 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4866, wps=71.8, ups=0.33, wpb=109.9, bsz=40, num_updates=24440, lr=4.10949e-05, gnorm=0.211, clip=0, loss_scale=1024, train_wall=31, gb_free=10.4, ema_decay=0.9999, wall=103492
2023-01-07 19:34:47 - progress_bar.py[line:274] - INFO: epoch 001:  24483 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4545, wps=72.5, ups=0.33, wpb=108.9, bsz=40, num_updates=24450, lr=4.10904e-05, gnorm=0.243, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103522
2023-01-07 19:35:17 - progress_bar.py[line:274] - INFO: epoch 001:  24493 / 115845 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4175, wps=72, ups=0.33, wpb=108.2, bsz=40, num_updates=24460, lr=4.10859e-05, gnorm=0.302, clip=0, loss_scale=1024, train_wall=30, gb_free=10, ema_decay=0.9999, wall=103553
2023-01-07 19:35:47 - progress_bar.py[line:274] - INFO: epoch 001:  24503 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4891, wps=75, ups=0.34, wpb=109.9, bsz=40, num_updates=24470, lr=4.10814e-05, gnorm=0.229, clip=0, loss_scale=1024, train_wall=29, gb_free=10.2, ema_decay=0.9999, wall=103583
2023-01-07 19:36:18 - progress_bar.py[line:274] - INFO: epoch 001:  24513 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4279, wps=70.3, ups=0.32, wpb=109, bsz=40, num_updates=24480, lr=4.1077e-05, gnorm=0.215, clip=0, loss_scale=1024, train_wall=31, gb_free=10.4, ema_decay=0.9999, wall=103614
2023-01-07 19:36:48 - progress_bar.py[line:274] - INFO: epoch 001:  24523 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4455, wps=72.5, ups=0.33, wpb=108.7, bsz=40, num_updates=24490, lr=4.10725e-05, gnorm=0.228, clip=0, loss_scale=1024, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=103644
2023-01-07 19:37:19 - progress_bar.py[line:274] - INFO: epoch 001:  24533 / 115845 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.5211, wps=72.8, ups=0.33, wpb=110.9, bsz=40, num_updates=24500, lr=4.1068e-05, gnorm=0.152, clip=0, loss_scale=1024, train_wall=30, gb_free=10, ema_decay=0.9999, wall=103675
2023-01-07 19:37:49 - progress_bar.py[line:274] - INFO: epoch 001:  24543 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4021, wps=73, ups=0.33, wpb=110, bsz=40, num_updates=24510, lr=4.10635e-05, gnorm=0.281, clip=10, loss_scale=1024, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=103705
2023-01-07 19:38:19 - progress_bar.py[line:274] - INFO: epoch 001:  24553 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.419, wps=73.8, ups=0.34, wpb=109.8, bsz=40, num_updates=24520, lr=4.1059e-05, gnorm=0.312, clip=0, loss_scale=1024, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=103735
2023-01-07 19:38:50 - progress_bar.py[line:274] - INFO: epoch 001:  24563 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3805, wps=70.7, ups=0.33, wpb=107.9, bsz=40, num_updates=24530, lr=4.10545e-05, gnorm=0.179, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103766
2023-01-07 19:39:20 - progress_bar.py[line:274] - INFO: epoch 001:  24573 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4472, wps=72.4, ups=0.33, wpb=108.7, bsz=40, num_updates=24540, lr=4.105e-05, gnorm=0.245, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103796
2023-01-07 19:39:51 - progress_bar.py[line:274] - INFO: epoch 001:  24583 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5303, wps=71.2, ups=0.33, wpb=109.2, bsz=40, num_updates=24550, lr=4.10455e-05, gnorm=0.358, clip=0, loss_scale=1024, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=103827
2023-01-07 19:40:22 - progress_bar.py[line:274] - INFO: epoch 001:  24593 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4439, wps=71.8, ups=0.33, wpb=108.6, bsz=40, num_updates=24560, lr=4.1041e-05, gnorm=0.272, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103857
2023-01-07 19:40:53 - progress_bar.py[line:274] - INFO: epoch 001:  24603 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4899, wps=71.3, ups=0.32, wpb=109.7, bsz=40, num_updates=24570, lr=4.10365e-05, gnorm=0.256, clip=0, loss_scale=1024, train_wall=31, gb_free=9.7, ema_decay=0.9999, wall=103888
2023-01-07 19:41:23 - progress_bar.py[line:274] - INFO: epoch 001:  24613 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5258, wps=73.8, ups=0.34, wpb=109.9, bsz=40, num_updates=24580, lr=4.1032e-05, gnorm=0.24, clip=0, loss_scale=1024, train_wall=30, gb_free=10.6, ema_decay=0.9999, wall=103918
2023-01-07 19:41:53 - progress_bar.py[line:274] - INFO: epoch 001:  24623 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3802, wps=71.3, ups=0.33, wpb=108.5, bsz=40, num_updates=24590, lr=4.10275e-05, gnorm=0.262, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103949
2023-01-07 19:42:24 - progress_bar.py[line:274] - INFO: epoch 001:  24633 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.445, wps=71, ups=0.33, wpb=108.2, bsz=40, num_updates=24600, lr=4.1023e-05, gnorm=0.171, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=103980
2023-01-07 19:42:55 - progress_bar.py[line:274] - INFO: epoch 001:  24643 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4682, wps=70.4, ups=0.32, wpb=108.6, bsz=40, num_updates=24610, lr=4.10185e-05, gnorm=0.232, clip=0, loss_scale=1024, train_wall=31, gb_free=10.1, ema_decay=0.9999, wall=104011
2023-01-07 19:43:26 - progress_bar.py[line:274] - INFO: epoch 001:  24653 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4502, wps=71, ups=0.33, wpb=108.3, bsz=40, num_updates=24620, lr=4.1014e-05, gnorm=0.208, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104042
2023-01-07 19:43:57 - progress_bar.py[line:274] - INFO: epoch 001:  24663 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5343, wps=70, ups=0.33, wpb=107.5, bsz=40, num_updates=24630, lr=4.10095e-05, gnorm=0.171, clip=0, loss_scale=1024, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=104073
2023-01-07 19:44:27 - progress_bar.py[line:274] - INFO: epoch 001:  24673 / 115845 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4087, wps=70.8, ups=0.33, wpb=107.6, bsz=40, num_updates=24640, lr=4.1005e-05, gnorm=0.267, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104103
2023-01-07 19:44:58 - progress_bar.py[line:274] - INFO: epoch 001:  24683 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4683, wps=71.6, ups=0.33, wpb=108.6, bsz=40, num_updates=24650, lr=4.10005e-05, gnorm=0.245, clip=0, loss_scale=1024, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=104134
2023-01-07 19:45:28 - progress_bar.py[line:274] - INFO: epoch 001:  24693 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4455, wps=71.6, ups=0.33, wpb=108.2, bsz=40, num_updates=24660, lr=4.0996e-05, gnorm=0.178, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104164
2023-01-07 19:45:59 - progress_bar.py[line:274] - INFO: epoch 001:  24703 / 115845 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4444, wps=72.9, ups=0.33, wpb=109.8, bsz=40, num_updates=24670, lr=4.09915e-05, gnorm=0.36, clip=10, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104195
2023-01-07 19:46:29 - progress_bar.py[line:274] - INFO: epoch 001:  24713 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4975, wps=73.6, ups=0.34, wpb=109.6, bsz=40, num_updates=24680, lr=4.0987e-05, gnorm=0.194, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104225
2023-01-07 19:46:59 - progress_bar.py[line:274] - INFO: epoch 001:  24723 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5167, wps=72.7, ups=0.33, wpb=109.5, bsz=40, num_updates=24690, lr=4.09825e-05, gnorm=0.157, clip=0, loss_scale=1024, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=104255
2023-01-07 19:47:30 - progress_bar.py[line:274] - INFO: epoch 001:  24733 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4734, wps=71.8, ups=0.33, wpb=108.1, bsz=40, num_updates=24700, lr=4.0978e-05, gnorm=0.289, clip=10, loss_scale=1024, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=104285
2023-01-07 19:47:59 - progress_bar.py[line:274] - INFO: epoch 001:  24743 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4798, wps=74.4, ups=0.34, wpb=110.1, bsz=40, num_updates=24710, lr=4.09735e-05, gnorm=0.328, clip=0, loss_scale=1024, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=104315
2023-01-07 19:48:30 - progress_bar.py[line:274] - INFO: epoch 001:  24753 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4632, wps=73.2, ups=0.33, wpb=110.3, bsz=40, num_updates=24720, lr=4.09691e-05, gnorm=0.271, clip=0, loss_scale=1024, train_wall=30, gb_free=10.6, ema_decay=0.9999, wall=104346
2023-01-07 19:49:00 - progress_bar.py[line:274] - INFO: epoch 001:  24763 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4897, wps=73.5, ups=0.34, wpb=109.3, bsz=40, num_updates=24730, lr=4.09646e-05, gnorm=0.349, clip=10, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104376
2023-01-07 19:49:30 - progress_bar.py[line:274] - INFO: epoch 001:  24773 / 115845 loss=0.307, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4521, wps=73.2, ups=0.33, wpb=109.8, bsz=40, num_updates=24740, lr=4.09601e-05, gnorm=0.305, clip=10, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104406
2023-01-07 19:50:01 - progress_bar.py[line:274] - INFO: epoch 001:  24783 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4387, wps=70.4, ups=0.33, wpb=108.3, bsz=40, num_updates=24750, lr=4.09556e-05, gnorm=0.399, clip=10, loss_scale=1024, train_wall=31, gb_free=10.4, ema_decay=0.9999, wall=104437
2023-01-07 19:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  24793 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4569, wps=73, ups=0.33, wpb=109.1, bsz=40, num_updates=24760, lr=4.09511e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104467
2023-01-07 19:51:02 - progress_bar.py[line:274] - INFO: epoch 001:  24803 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.466, wps=71.9, ups=0.33, wpb=109.2, bsz=40, num_updates=24770, lr=4.09466e-05, gnorm=0.287, clip=0, loss_scale=1024, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=104497
2023-01-07 19:51:32 - progress_bar.py[line:274] - INFO: epoch 001:  24813 / 115845 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4229, wps=72.1, ups=0.33, wpb=108.8, bsz=40, num_updates=24780, lr=4.09421e-05, gnorm=0.33, clip=0, loss_scale=1024, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=104528
2023-01-07 19:52:03 - progress_bar.py[line:274] - INFO: epoch 001:  24823 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=107, nsentences=40, sample_size=107, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4676, wps=70.3, ups=0.33, wpb=107, bsz=40, num_updates=24790, lr=4.09376e-05, gnorm=0.193, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104559
2023-01-07 19:52:33 - progress_bar.py[line:274] - INFO: epoch 001:  24833 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5024, wps=72.5, ups=0.34, wpb=108, bsz=40, num_updates=24800, lr=4.09331e-05, gnorm=0.212, clip=0, loss_scale=1024, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=104589
2023-01-07 19:53:04 - progress_bar.py[line:274] - INFO: epoch 001:  24843 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4211, wps=70.7, ups=0.32, wpb=109.6, bsz=40, num_updates=24810, lr=4.09286e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=104620
2023-01-07 19:53:35 - progress_bar.py[line:274] - INFO: epoch 001:  24853 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4158, wps=71.6, ups=0.33, wpb=108.9, bsz=40, num_updates=24820, lr=4.09241e-05, gnorm=0.285, clip=0, loss_scale=1024, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=104651
2023-01-07 19:54:06 - progress_bar.py[line:274] - INFO: epoch 001:  24863 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4306, wps=70.7, ups=0.33, wpb=108.4, bsz=40, num_updates=24830, lr=4.09196e-05, gnorm=0.189, clip=0, loss_scale=1024, train_wall=31, gb_free=10.3, ema_decay=0.9999, wall=104682
2023-01-07 19:54:37 - progress_bar.py[line:274] - INFO: epoch 001:  24873 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4384, wps=70.8, ups=0.33, wpb=108.3, bsz=40, num_updates=24840, lr=4.09151e-05, gnorm=0.304, clip=0, loss_scale=1024, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=104712
2023-01-07 19:55:07 - progress_bar.py[line:274] - INFO: epoch 001:  24883 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=71.8, ups=0.33, wpb=108.2, bsz=40, num_updates=24850, lr=4.09106e-05, gnorm=0.295, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104743
2023-01-07 19:55:36 - progress_bar.py[line:274] - INFO: epoch 001:  24893 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.397, wps=75.3, ups=0.34, wpb=109.8, bsz=40, num_updates=24860, lr=4.09061e-05, gnorm=0.204, clip=0, loss_scale=1024, train_wall=29, gb_free=10.3, ema_decay=0.9999, wall=104772
2023-01-07 19:56:07 - progress_bar.py[line:274] - INFO: epoch 001:  24903 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4596, wps=72.4, ups=0.33, wpb=108.7, bsz=40, num_updates=24870, lr=4.09016e-05, gnorm=0.223, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104802
2023-01-07 19:56:22 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 19:56:40 - progress_bar.py[line:274] - INFO: epoch 001:  24914 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=109.286, nsentences=40, sample_size=109.286, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4955, wps=69.1, ups=0.3, wpb=109.3, bsz=40, num_updates=24880, lr=4.08971e-05, gnorm=0.228, clip=0, loss_scale=512, train_wall=33, gb_free=10.1, ema_decay=0.9999, wall=104836
2023-01-07 19:57:10 - progress_bar.py[line:274] - INFO: epoch 001:  24924 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.476, wps=73.7, ups=0.34, wpb=108.4, bsz=40, num_updates=24890, lr=4.08926e-05, gnorm=0.26, clip=10, loss_scale=512, train_wall=29, gb_free=10.7, ema_decay=0.9999, wall=104866
2023-01-07 19:57:41 - progress_bar.py[line:274] - INFO: epoch 001:  24934 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4462, wps=72.7, ups=0.33, wpb=109.7, bsz=40, num_updates=24900, lr=4.08881e-05, gnorm=0.308, clip=10, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=104897
2023-01-07 19:58:13 - progress_bar.py[line:274] - INFO: epoch 001:  24944 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4683, wps=70, ups=0.32, wpb=108, bsz=40, num_updates=24910, lr=4.08836e-05, gnorm=0.16, clip=0, loss_scale=512, train_wall=31, gb_free=9.9, ema_decay=0.9999, wall=104928
2023-01-07 19:58:43 - progress_bar.py[line:274] - INFO: epoch 001:  24954 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4, wps=75, ups=0.34, wpb=110, bsz=40, num_updates=24920, lr=4.08791e-05, gnorm=0.253, clip=0, loss_scale=512, train_wall=29, gb_free=9.9, ema_decay=0.9999, wall=104958
2023-01-07 19:59:13 - progress_bar.py[line:274] - INFO: epoch 001:  24964 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4203, wps=73.3, ups=0.34, wpb=108, bsz=40, num_updates=24930, lr=4.08746e-05, gnorm=0.293, clip=10, loss_scale=512, train_wall=29, gb_free=10.2, ema_decay=0.9999, wall=104988
2023-01-07 19:59:44 - progress_bar.py[line:274] - INFO: epoch 001:  24974 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=71.7, ups=0.33, wpb=109.1, bsz=40, num_updates=24940, lr=4.08701e-05, gnorm=0.276, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=105019
2023-01-07 20:00:14 - progress_bar.py[line:274] - INFO: epoch 001:  24984 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4564, wps=72.8, ups=0.33, wpb=109.9, bsz=40, num_updates=24950, lr=4.08656e-05, gnorm=0.242, clip=0, loss_scale=512, train_wall=30, gb_free=10, ema_decay=0.9999, wall=105050
2023-01-07 20:00:45 - progress_bar.py[line:274] - INFO: epoch 001:  24994 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4433, wps=73.3, ups=0.34, wpb=109.4, bsz=40, num_updates=24960, lr=4.08611e-05, gnorm=0.264, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=105080
2023-01-07 20:01:15 - progress_bar.py[line:274] - INFO: epoch 001:  25004 / 115845 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4844, wps=74.4, ups=0.34, wpb=108.7, bsz=40, num_updates=24970, lr=4.08567e-05, gnorm=0.24, clip=0, loss_scale=512, train_wall=29, gb_free=10.1, ema_decay=0.9999, wall=105110
2023-01-07 20:01:46 - progress_bar.py[line:274] - INFO: epoch 001:  25014 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4468, wps=72.4, ups=0.33, wpb=110, bsz=40, num_updates=24980, lr=4.08522e-05, gnorm=0.208, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=105141
2023-01-07 20:02:16 - progress_bar.py[line:274] - INFO: epoch 001:  25024 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4604, wps=73.1, ups=0.34, wpb=109, bsz=40, num_updates=24990, lr=4.08477e-05, gnorm=0.557, clip=10, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=105172
2023-01-07 20:02:47 - progress_bar.py[line:274] - INFO: epoch 001:  25034 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4286, wps=72.2, ups=0.33, wpb=109.6, bsz=40, num_updates=25000, lr=4.08432e-05, gnorm=0.297, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=105203
2023-01-07 20:03:18 - progress_bar.py[line:274] - INFO: epoch 001:  25044 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3934, wps=72.5, ups=0.33, wpb=110, bsz=40, num_updates=25010, lr=4.08387e-05, gnorm=0.322, clip=0, loss_scale=512, train_wall=30, gb_free=10.6, ema_decay=0.9999, wall=105234
2023-01-07 20:03:49 - progress_bar.py[line:274] - INFO: epoch 001:  25054 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5161, wps=71.8, ups=0.33, wpb=109.9, bsz=40, num_updates=25020, lr=4.08342e-05, gnorm=0.229, clip=0, loss_scale=512, train_wall=31, gb_free=10.1, ema_decay=0.9999, wall=105265
2023-01-07 20:04:21 - progress_bar.py[line:274] - INFO: epoch 001:  25064 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4159, wps=69.5, ups=0.32, wpb=108.2, bsz=40, num_updates=25030, lr=4.08297e-05, gnorm=0.204, clip=0, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=105297
2023-01-07 20:04:52 - progress_bar.py[line:274] - INFO: epoch 001:  25074 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4604, wps=71.3, ups=0.33, wpb=107.3, bsz=40, num_updates=25040, lr=4.08252e-05, gnorm=0.221, clip=0, loss_scale=512, train_wall=30, gb_free=10, ema_decay=0.9999, wall=105327
2023-01-07 20:05:22 - progress_bar.py[line:274] - INFO: epoch 001:  25084 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4806, wps=74.5, ups=0.34, wpb=109.4, bsz=40, num_updates=25050, lr=4.08207e-05, gnorm=0.329, clip=10, loss_scale=512, train_wall=29, gb_free=10.3, ema_decay=0.9999, wall=105357
2023-01-07 20:05:52 - progress_bar.py[line:274] - INFO: epoch 001:  25094 / 115845 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5026, wps=72.9, ups=0.33, wpb=109.3, bsz=40, num_updates=25060, lr=4.08162e-05, gnorm=0.209, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=105388
2023-01-07 20:06:23 - progress_bar.py[line:274] - INFO: epoch 001:  25104 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4689, wps=73.4, ups=0.34, wpb=108.3, bsz=40, num_updates=25070, lr=4.08117e-05, gnorm=0.419, clip=10, loss_scale=512, train_wall=29, gb_free=10.7, ema_decay=0.9999, wall=105418
2023-01-07 20:06:54 - progress_bar.py[line:274] - INFO: epoch 001:  25114 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4742, wps=71.4, ups=0.33, wpb=109.1, bsz=40, num_updates=25080, lr=4.08072e-05, gnorm=0.227, clip=0, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=105449
2023-01-07 20:07:25 - progress_bar.py[line:274] - INFO: epoch 001:  25124 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4324, wps=71, ups=0.32, wpb=110.1, bsz=40, num_updates=25090, lr=4.08027e-05, gnorm=0.331, clip=10, loss_scale=512, train_wall=31, gb_free=10.1, ema_decay=0.9999, wall=105481
2023-01-07 20:07:56 - progress_bar.py[line:274] - INFO: epoch 001:  25134 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4306, wps=72.8, ups=0.34, wpb=107.5, bsz=40, num_updates=25100, lr=4.07982e-05, gnorm=0.212, clip=0, loss_scale=512, train_wall=29, gb_free=10.2, ema_decay=0.9999, wall=105511
2023-01-07 20:08:26 - progress_bar.py[line:274] - INFO: epoch 001:  25144 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=107.5, nsentences=40, sample_size=107.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4427, wps=70.9, ups=0.33, wpb=107.5, bsz=40, num_updates=25110, lr=4.07937e-05, gnorm=0.209, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=105542
2023-01-07 20:08:57 - progress_bar.py[line:274] - INFO: epoch 001:  25154 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4151, wps=71.8, ups=0.33, wpb=107.6, bsz=40, num_updates=25120, lr=4.07892e-05, gnorm=0.258, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=105573
2023-01-07 20:09:27 - progress_bar.py[line:274] - INFO: epoch 001:  25164 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4123, wps=73.9, ups=0.34, wpb=108.1, bsz=40, num_updates=25130, lr=4.07847e-05, gnorm=0.205, clip=0, loss_scale=512, train_wall=29, gb_free=10.2, ema_decay=0.9999, wall=105602
2023-01-07 20:09:58 - progress_bar.py[line:274] - INFO: epoch 001:  25174 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.455, wps=73.5, ups=0.33, wpb=110.1, bsz=40, num_updates=25140, lr=4.07802e-05, gnorm=0.235, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=105633
2023-01-07 20:10:28 - progress_bar.py[line:274] - INFO: epoch 001:  25184 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.3886, wps=72.1, ups=0.33, wpb=108.3, bsz=40, num_updates=25150, lr=4.07757e-05, gnorm=0.398, clip=10, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=105664
2023-01-07 20:11:00 - progress_bar.py[line:274] - INFO: epoch 001:  25194 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4392, wps=71.4, ups=0.33, wpb=108.7, bsz=40, num_updates=25160, lr=4.07712e-05, gnorm=0.15, clip=0, loss_scale=512, train_wall=30, gb_free=10.7, ema_decay=0.9999, wall=105695
2023-01-07 20:11:30 - progress_bar.py[line:274] - INFO: epoch 001:  25204 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4831, wps=72.5, ups=0.33, wpb=109.4, bsz=40, num_updates=25170, lr=4.07667e-05, gnorm=0.177, clip=0, loss_scale=512, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=105726
2023-01-07 20:12:01 - progress_bar.py[line:274] - INFO: epoch 001:  25214 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.463, wps=72.4, ups=0.33, wpb=108.8, bsz=40, num_updates=25180, lr=4.07622e-05, gnorm=0.289, clip=0, loss_scale=512, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=105757
2023-01-07 20:12:32 - progress_bar.py[line:274] - INFO: epoch 001:  25224 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.445, wps=72.4, ups=0.33, wpb=109.4, bsz=40, num_updates=25190, lr=4.07577e-05, gnorm=0.269, clip=0, loss_scale=512, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=105787
2023-01-07 20:13:02 - progress_bar.py[line:274] - INFO: epoch 001:  25234 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4293, wps=73.2, ups=0.34, wpb=108.4, bsz=40, num_updates=25200, lr=4.07532e-05, gnorm=0.366, clip=10, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=105817
2023-01-07 20:13:33 - progress_bar.py[line:274] - INFO: epoch 001:  25244 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.475, wps=73.3, ups=0.33, wpb=110.8, bsz=40, num_updates=25210, lr=4.07488e-05, gnorm=0.215, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=105848
2023-01-07 20:14:04 - progress_bar.py[line:274] - INFO: epoch 001:  25254 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4656, wps=71.3, ups=0.33, wpb=109.4, bsz=40, num_updates=25220, lr=4.07443e-05, gnorm=0.256, clip=0, loss_scale=512, train_wall=31, gb_free=10.1, ema_decay=0.9999, wall=105879
2023-01-07 20:14:34 - progress_bar.py[line:274] - INFO: epoch 001:  25264 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4663, wps=73.2, ups=0.34, wpb=108.6, bsz=40, num_updates=25230, lr=4.07398e-05, gnorm=0.276, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=105910
2023-01-07 20:15:05 - progress_bar.py[line:274] - INFO: epoch 001:  25274 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4039, wps=71.5, ups=0.33, wpb=108.7, bsz=40, num_updates=25240, lr=4.07353e-05, gnorm=0.303, clip=0, loss_scale=512, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=105941
2023-01-07 20:15:36 - progress_bar.py[line:274] - INFO: epoch 001:  25284 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4495, wps=71.2, ups=0.32, wpb=109.9, bsz=40, num_updates=25250, lr=4.07308e-05, gnorm=0.239, clip=0, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=105972
2023-01-07 20:16:06 - progress_bar.py[line:274] - INFO: epoch 001:  25294 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.5024, wps=73, ups=0.34, wpb=108.5, bsz=40, num_updates=25260, lr=4.07263e-05, gnorm=0.475, clip=20, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=106002
2023-01-07 20:16:37 - progress_bar.py[line:274] - INFO: epoch 001:  25304 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4402, wps=71.5, ups=0.33, wpb=108, bsz=40, num_updates=25270, lr=4.07218e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=106032
2023-01-07 20:17:07 - progress_bar.py[line:274] - INFO: epoch 001:  25314 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.457, wps=72.6, ups=0.34, wpb=108.2, bsz=40, num_updates=25280, lr=4.07173e-05, gnorm=0.229, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=106062
2023-01-07 20:17:38 - progress_bar.py[line:274] - INFO: epoch 001:  25324 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5, wps=71.2, ups=0.33, wpb=109.4, bsz=40, num_updates=25290, lr=4.07128e-05, gnorm=0.169, clip=0, loss_scale=512, train_wall=31, gb_free=10.3, ema_decay=0.9999, wall=106093
2023-01-07 20:18:07 - progress_bar.py[line:274] - INFO: epoch 001:  25334 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.475, wps=75.3, ups=0.34, wpb=110.3, bsz=40, num_updates=25300, lr=4.07083e-05, gnorm=0.255, clip=0, loss_scale=512, train_wall=29, gb_free=10.2, ema_decay=0.9999, wall=106123
2023-01-07 20:18:36 - progress_bar.py[line:274] - INFO: epoch 001:  25344 / 115845 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.4943, wps=75.7, ups=0.34, wpb=110.6, bsz=40, num_updates=25310, lr=4.07038e-05, gnorm=0.192, clip=0, loss_scale=512, train_wall=29, gb_free=10.2, ema_decay=0.9999, wall=106152
2023-01-07 20:19:08 - progress_bar.py[line:274] - INFO: epoch 001:  25354 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4851, wps=70.4, ups=0.32, wpb=108.9, bsz=40, num_updates=25320, lr=4.06993e-05, gnorm=0.153, clip=0, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=106183
2023-01-07 20:19:39 - progress_bar.py[line:274] - INFO: epoch 001:  25364 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4271, wps=70.9, ups=0.33, wpb=109, bsz=40, num_updates=25330, lr=4.06948e-05, gnorm=0.266, clip=0, loss_scale=512, train_wall=31, gb_free=10.4, ema_decay=0.9999, wall=106214
2023-01-07 20:20:09 - progress_bar.py[line:274] - INFO: epoch 001:  25374 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4216, wps=72.8, ups=0.34, wpb=108.3, bsz=40, num_updates=25340, lr=4.06903e-05, gnorm=0.154, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=106244
2023-01-07 20:20:39 - progress_bar.py[line:274] - INFO: epoch 001:  25384 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4527, wps=72.5, ups=0.33, wpb=109.9, bsz=40, num_updates=25350, lr=4.06858e-05, gnorm=0.192, clip=0, loss_scale=512, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=106275
2023-01-07 20:21:10 - progress_bar.py[line:274] - INFO: epoch 001:  25394 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.435, wps=70.3, ups=0.32, wpb=109.4, bsz=40, num_updates=25360, lr=4.06813e-05, gnorm=0.183, clip=0, loss_scale=512, train_wall=31, gb_free=10.4, ema_decay=0.9999, wall=106306
2023-01-07 20:21:41 - progress_bar.py[line:274] - INFO: epoch 001:  25404 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4375, wps=72.8, ups=0.33, wpb=109.3, bsz=40, num_updates=25370, lr=4.06768e-05, gnorm=0.234, clip=0, loss_scale=512, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=106337
2023-01-07 20:22:11 - progress_bar.py[line:274] - INFO: epoch 001:  25414 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.3962, wps=72.6, ups=0.33, wpb=108.7, bsz=40, num_updates=25380, lr=4.06723e-05, gnorm=0.197, clip=0, loss_scale=512, train_wall=30, gb_free=10, ema_decay=0.9999, wall=106367
2023-01-07 20:22:41 - progress_bar.py[line:274] - INFO: epoch 001:  25424 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4162, wps=71.8, ups=0.33, wpb=108.5, bsz=40, num_updates=25390, lr=4.06678e-05, gnorm=0.203, clip=0, loss_scale=1024, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=106397
2023-01-07 20:23:12 - progress_bar.py[line:274] - INFO: epoch 001:  25434 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4783, wps=72.2, ups=0.33, wpb=108.4, bsz=40, num_updates=25400, lr=4.06633e-05, gnorm=0.2, clip=0, loss_scale=1024, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=106427
2023-01-07 20:23:42 - progress_bar.py[line:274] - INFO: epoch 001:  25444 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.43, wps=73, ups=0.33, wpb=109.7, bsz=40, num_updates=25410, lr=4.06588e-05, gnorm=0.136, clip=0, loss_scale=1024, train_wall=30, gb_free=9.9, ema_decay=0.9999, wall=106458
2023-01-07 20:24:12 - progress_bar.py[line:274] - INFO: epoch 001:  25454 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4468, wps=73.1, ups=0.33, wpb=111.1, bsz=40, num_updates=25420, lr=4.06543e-05, gnorm=0.263, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=106488
2023-01-07 20:24:43 - progress_bar.py[line:274] - INFO: epoch 001:  25464 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4333, wps=70.7, ups=0.33, wpb=108.6, bsz=40, num_updates=25430, lr=4.06498e-05, gnorm=0.272, clip=0, loss_scale=1024, train_wall=31, gb_free=10.3, ema_decay=0.9999, wall=106519
2023-01-07 20:25:14 - progress_bar.py[line:274] - INFO: epoch 001:  25474 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4826, wps=72.4, ups=0.33, wpb=109.4, bsz=40, num_updates=25440, lr=4.06453e-05, gnorm=0.239, clip=0, loss_scale=1024, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=106550
2023-01-07 20:25:44 - progress_bar.py[line:274] - INFO: epoch 001:  25484 / 115845 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4378, wps=74.5, ups=0.34, wpb=110.6, bsz=40, num_updates=25450, lr=4.06408e-05, gnorm=0.189, clip=0, loss_scale=1024, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=106580
2023-01-07 20:26:14 - progress_bar.py[line:274] - INFO: epoch 001:  25494 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5189, wps=73.5, ups=0.34, wpb=109.5, bsz=40, num_updates=25460, lr=4.06364e-05, gnorm=0.257, clip=10, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=106610
2023-01-07 20:26:44 - progress_bar.py[line:274] - INFO: epoch 001:  25504 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4231, wps=72.1, ups=0.33, wpb=108.8, bsz=40, num_updates=25470, lr=4.06319e-05, gnorm=0.26, clip=0, loss_scale=1024, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=106640
2023-01-07 20:27:15 - progress_bar.py[line:274] - INFO: epoch 001:  25514 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.449, wps=71.8, ups=0.33, wpb=110, bsz=40, num_updates=25480, lr=4.06274e-05, gnorm=0.194, clip=0, loss_scale=1024, train_wall=31, gb_free=10.3, ema_decay=0.9999, wall=106671
2023-01-07 20:27:45 - progress_bar.py[line:274] - INFO: epoch 001:  25524 / 115845 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5048, wps=71.9, ups=0.33, wpb=108.4, bsz=40, num_updates=25490, lr=4.06229e-05, gnorm=0.155, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=106701
2023-01-07 20:28:14 - progress_bar.py[line:274] - INFO: epoch 001:  25534 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5172, wps=76.1, ups=0.35, wpb=109.3, bsz=40, num_updates=25500, lr=4.06184e-05, gnorm=0.33, clip=10, loss_scale=1024, train_wall=29, gb_free=10.2, ema_decay=0.9999, wall=106730
2023-01-07 20:28:44 - progress_bar.py[line:274] - INFO: epoch 001:  25544 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4292, wps=73, ups=0.34, wpb=108.9, bsz=40, num_updates=25510, lr=4.06139e-05, gnorm=0.204, clip=0, loss_scale=1024, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=106760
2023-01-07 20:29:15 - progress_bar.py[line:274] - INFO: epoch 001:  25554 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5126, wps=72, ups=0.33, wpb=108.9, bsz=40, num_updates=25520, lr=4.06094e-05, gnorm=0.33, clip=0, loss_scale=1024, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=106791
2023-01-07 20:29:46 - progress_bar.py[line:274] - INFO: epoch 001:  25564 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4869, wps=71.6, ups=0.33, wpb=108.8, bsz=40, num_updates=25530, lr=4.06049e-05, gnorm=0.178, clip=0, loss_scale=1024, train_wall=30, gb_free=10, ema_decay=0.9999, wall=106821
2023-01-07 20:30:16 - progress_bar.py[line:274] - INFO: epoch 001:  25574 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4541, wps=71.8, ups=0.33, wpb=107.2, bsz=40, num_updates=25540, lr=4.06004e-05, gnorm=0.202, clip=0, loss_scale=1024, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=106851
2023-01-07 20:30:42 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 20:30:48 - progress_bar.py[line:274] - INFO: epoch 001:  25585 / 115845 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=108.286, nsentences=40, sample_size=108.286, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4513, wps=69.8, ups=0.31, wpb=108.3, bsz=40, num_updates=25550, lr=4.05959e-05, gnorm=0.257, clip=0, loss_scale=512, train_wall=33, gb_free=10.2, ema_decay=0.9999, wall=106884
2023-01-07 20:31:19 - progress_bar.py[line:274] - INFO: epoch 001:  25595 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4423, wps=70.9, ups=0.32, wpb=109.2, bsz=40, num_updates=25560, lr=4.05914e-05, gnorm=0.314, clip=10, loss_scale=512, train_wall=31, gb_free=10.5, ema_decay=0.9999, wall=106915
2023-01-07 20:31:50 - progress_bar.py[line:274] - INFO: epoch 001:  25605 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4528, wps=70.9, ups=0.33, wpb=108.4, bsz=40, num_updates=25570, lr=4.05869e-05, gnorm=0.302, clip=0, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=106946
2023-01-07 20:32:21 - progress_bar.py[line:274] - INFO: epoch 001:  25615 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3909, wps=71, ups=0.33, wpb=108.9, bsz=40, num_updates=25580, lr=4.05824e-05, gnorm=0.295, clip=0, loss_scale=512, train_wall=31, gb_free=10.1, ema_decay=0.9999, wall=106977
2023-01-07 20:32:52 - progress_bar.py[line:274] - INFO: epoch 001:  25625 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4948, wps=72.6, ups=0.33, wpb=109.7, bsz=40, num_updates=25590, lr=4.05779e-05, gnorm=0.232, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=107007
2023-01-07 20:33:22 - progress_bar.py[line:274] - INFO: epoch 001:  25635 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4732, wps=73.1, ups=0.33, wpb=109.5, bsz=40, num_updates=25600, lr=4.05734e-05, gnorm=0.163, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=107038
2023-01-07 20:33:52 - progress_bar.py[line:274] - INFO: epoch 001:  25645 / 115845 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4541, wps=72.4, ups=0.33, wpb=109.6, bsz=40, num_updates=25610, lr=4.05689e-05, gnorm=0.167, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=107068
2023-01-07 20:34:23 - progress_bar.py[line:274] - INFO: epoch 001:  25655 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4339, wps=73, ups=0.33, wpb=110.2, bsz=40, num_updates=25620, lr=4.05644e-05, gnorm=0.235, clip=0, loss_scale=512, train_wall=30, gb_free=10, ema_decay=0.9999, wall=107099
2023-01-07 20:34:52 - progress_bar.py[line:274] - INFO: epoch 001:  25665 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4143, wps=73.9, ups=0.34, wpb=109.3, bsz=40, num_updates=25630, lr=4.05599e-05, gnorm=0.19, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=107128
2023-01-07 20:35:24 - progress_bar.py[line:274] - INFO: epoch 001:  25675 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4811, wps=70.5, ups=0.32, wpb=109, bsz=40, num_updates=25640, lr=4.05554e-05, gnorm=0.262, clip=0, loss_scale=512, train_wall=31, gb_free=10.1, ema_decay=0.9999, wall=107159
2023-01-07 20:35:54 - progress_bar.py[line:274] - INFO: epoch 001:  25685 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4596, wps=72.2, ups=0.33, wpb=108.9, bsz=40, num_updates=25650, lr=4.05509e-05, gnorm=0.179, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=107190
2023-01-07 20:36:24 - progress_bar.py[line:274] - INFO: epoch 001:  25695 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4858, wps=74.1, ups=0.34, wpb=109.2, bsz=40, num_updates=25660, lr=4.05464e-05, gnorm=0.197, clip=0, loss_scale=512, train_wall=29, gb_free=10.6, ema_decay=0.9999, wall=107220
2023-01-07 20:36:54 - progress_bar.py[line:274] - INFO: epoch 001:  25705 / 115845 loss=0.309, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5, wps=72.4, ups=0.33, wpb=109, bsz=40, num_updates=25670, lr=4.05419e-05, gnorm=0.308, clip=0, loss_scale=512, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=107250
2023-01-07 20:37:25 - progress_bar.py[line:274] - INFO: epoch 001:  25715 / 115845 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5028, wps=72, ups=0.33, wpb=110.2, bsz=40, num_updates=25680, lr=4.05374e-05, gnorm=0.269, clip=10, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=107281
2023-01-07 20:37:55 - progress_bar.py[line:274] - INFO: epoch 001:  25725 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4817, wps=73.9, ups=0.34, wpb=109.8, bsz=40, num_updates=25690, lr=4.05329e-05, gnorm=0.266, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=107311
2023-01-07 20:38:25 - progress_bar.py[line:274] - INFO: epoch 001:  25735 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4787, wps=71, ups=0.33, wpb=107.8, bsz=40, num_updates=25700, lr=4.05285e-05, gnorm=0.312, clip=10, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=107341
2023-01-07 20:38:55 - progress_bar.py[line:274] - INFO: epoch 001:  25745 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4732, wps=73.5, ups=0.34, wpb=109, bsz=40, num_updates=25710, lr=4.0524e-05, gnorm=0.234, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=107371
2023-01-07 20:39:26 - progress_bar.py[line:274] - INFO: epoch 001:  25755 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4839, wps=71.8, ups=0.33, wpb=109.5, bsz=40, num_updates=25720, lr=4.05195e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=107402
2023-01-07 20:39:56 - progress_bar.py[line:274] - INFO: epoch 001:  25765 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4854, wps=72.8, ups=0.33, wpb=110.2, bsz=40, num_updates=25730, lr=4.0515e-05, gnorm=0.509, clip=10, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=107432
2023-01-07 20:40:27 - progress_bar.py[line:274] - INFO: epoch 001:  25775 / 115845 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4813, wps=71.6, ups=0.33, wpb=109.7, bsz=40, num_updates=25740, lr=4.05105e-05, gnorm=0.295, clip=0, loss_scale=512, train_wall=31, gb_free=10.5, ema_decay=0.9999, wall=107463
2023-01-07 20:40:58 - progress_bar.py[line:274] - INFO: epoch 001:  25785 / 115845 loss=0.324, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4372, wps=72.1, ups=0.33, wpb=108.7, bsz=40, num_updates=25750, lr=4.0506e-05, gnorm=0.243, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=107494
2023-01-07 20:41:28 - progress_bar.py[line:274] - INFO: epoch 001:  25795 / 115845 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4972, wps=73.2, ups=0.33, wpb=110.4, bsz=40, num_updates=25760, lr=4.05015e-05, gnorm=0.222, clip=0, loss_scale=512, train_wall=30, gb_free=10, ema_decay=0.9999, wall=107524
2023-01-07 20:41:58 - progress_bar.py[line:274] - INFO: epoch 001:  25805 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4229, wps=71.8, ups=0.33, wpb=108.5, bsz=40, num_updates=25770, lr=4.0497e-05, gnorm=0.25, clip=0, loss_scale=512, train_wall=30, gb_free=9.9, ema_decay=0.9999, wall=107554
2023-01-07 20:42:29 - progress_bar.py[line:274] - INFO: epoch 001:  25815 / 115845 loss=0.318, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4755, wps=70.6, ups=0.33, wpb=107.9, bsz=40, num_updates=25780, lr=4.04925e-05, gnorm=0.169, clip=0, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=107585
2023-01-07 20:42:59 - progress_bar.py[line:274] - INFO: epoch 001:  25825 / 115845 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4634, wps=72.9, ups=0.33, wpb=109.4, bsz=40, num_updates=25790, lr=4.0488e-05, gnorm=0.361, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=107615
2023-01-07 20:43:30 - progress_bar.py[line:274] - INFO: epoch 001:  25835 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4677, wps=70.4, ups=0.33, wpb=108.3, bsz=40, num_updates=25800, lr=4.04835e-05, gnorm=0.187, clip=0, loss_scale=512, train_wall=31, gb_free=10, ema_decay=0.9999, wall=107646
2023-01-07 20:44:01 - progress_bar.py[line:274] - INFO: epoch 001:  25845 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4925, wps=70.4, ups=0.32, wpb=108.7, bsz=40, num_updates=25810, lr=4.0479e-05, gnorm=0.368, clip=10, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=107677
2023-01-07 20:44:31 - progress_bar.py[line:274] - INFO: epoch 001:  25855 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4536, wps=74.8, ups=0.34, wpb=109.1, bsz=40, num_updates=25820, lr=4.04745e-05, gnorm=0.257, clip=0, loss_scale=512, train_wall=29, gb_free=10.3, ema_decay=0.9999, wall=107707
2023-01-07 20:45:01 - progress_bar.py[line:274] - INFO: epoch 001:  25865 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4372, wps=71.9, ups=0.33, wpb=108.8, bsz=40, num_updates=25830, lr=4.047e-05, gnorm=0.248, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=107737
2023-01-07 20:45:32 - progress_bar.py[line:274] - INFO: epoch 001:  25875 / 115845 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4265, wps=70.4, ups=0.33, wpb=108.1, bsz=40, num_updates=25840, lr=4.04655e-05, gnorm=0.219, clip=0, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=107768
2023-01-07 20:46:02 - progress_bar.py[line:274] - INFO: epoch 001:  25885 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3982, wps=73.4, ups=0.34, wpb=108.5, bsz=40, num_updates=25850, lr=4.0461e-05, gnorm=0.272, clip=0, loss_scale=512, train_wall=29, gb_free=10.2, ema_decay=0.9999, wall=107798
2023-01-07 20:46:32 - progress_bar.py[line:274] - INFO: epoch 001:  25895 / 115845 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4831, wps=72.5, ups=0.34, wpb=107.2, bsz=40, num_updates=25860, lr=4.04565e-05, gnorm=0.166, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=107828
2023-01-07 20:47:03 - progress_bar.py[line:274] - INFO: epoch 001:  25905 / 115845 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, vqa_score=0.4457, wps=71.6, ups=0.32, wpb=110.3, bsz=40, num_updates=25870, lr=4.0452e-05, gnorm=0.112, clip=0, loss_scale=512, train_wall=31, gb_free=10.1, ema_decay=0.9999, wall=107859
2023-01-07 20:47:33 - progress_bar.py[line:274] - INFO: epoch 001:  25915 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4579, wps=72.9, ups=0.34, wpb=107.7, bsz=40, num_updates=25880, lr=4.04475e-05, gnorm=0.295, clip=0, loss_scale=512, train_wall=29, gb_free=10.3, ema_decay=0.9999, wall=107889
2023-01-07 20:48:03 - progress_bar.py[line:274] - INFO: epoch 001:  25925 / 115845 loss=0.308, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.5152, wps=70.6, ups=0.33, wpb=107.7, bsz=40, num_updates=25890, lr=4.0443e-05, gnorm=0.211, clip=0, loss_scale=512, train_wall=30, gb_free=10.6, ema_decay=0.9999, wall=107919
2023-01-07 20:48:34 - progress_bar.py[line:274] - INFO: epoch 001:  25935 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4674, wps=73.4, ups=0.33, wpb=109.8, bsz=40, num_updates=25900, lr=4.04385e-05, gnorm=0.324, clip=10, loss_scale=512, train_wall=30, gb_free=10.7, ema_decay=0.9999, wall=107949
2023-01-07 20:49:04 - progress_bar.py[line:274] - INFO: epoch 001:  25945 / 115845 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4483, wps=71.2, ups=0.33, wpb=109, bsz=40, num_updates=25910, lr=4.0434e-05, gnorm=0.194, clip=0, loss_scale=512, train_wall=31, gb_free=10.3, ema_decay=0.9999, wall=107980
2023-01-07 20:49:35 - progress_bar.py[line:274] - INFO: epoch 001:  25955 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4571, wps=71, ups=0.33, wpb=109, bsz=40, num_updates=25920, lr=4.04295e-05, gnorm=0.201, clip=0, loss_scale=512, train_wall=31, gb_free=10.3, ema_decay=0.9999, wall=108011
2023-01-07 20:50:06 - progress_bar.py[line:274] - INFO: epoch 001:  25965 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4286, wps=72.4, ups=0.33, wpb=108.9, bsz=40, num_updates=25930, lr=4.0425e-05, gnorm=0.49, clip=10, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=108042
2023-01-07 20:50:36 - progress_bar.py[line:274] - INFO: epoch 001:  25975 / 115845 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4904, wps=71.7, ups=0.33, wpb=109, bsz=40, num_updates=25940, lr=4.04205e-05, gnorm=0.336, clip=10, loss_scale=512, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=108072
2023-01-07 20:51:05 - progress_bar.py[line:274] - INFO: epoch 001:  25985 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4483, wps=75.3, ups=0.35, wpb=108.6, bsz=40, num_updates=25950, lr=4.04161e-05, gnorm=0.147, clip=0, loss_scale=512, train_wall=29, gb_free=10.2, ema_decay=0.9999, wall=108101
2023-01-07 20:51:36 - progress_bar.py[line:274] - INFO: epoch 001:  25995 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.5023, wps=72.3, ups=0.33, wpb=108.5, bsz=40, num_updates=25960, lr=4.04116e-05, gnorm=0.192, clip=0, loss_scale=512, train_wall=30, gb_free=10.5, ema_decay=0.9999, wall=108131
2023-01-07 20:52:06 - progress_bar.py[line:274] - INFO: epoch 001:  26005 / 115845 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=107.2, nsentences=40, sample_size=107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4186, wps=70.1, ups=0.33, wpb=107.2, bsz=40, num_updates=25970, lr=4.04071e-05, gnorm=0.28, clip=0, loss_scale=512, train_wall=31, gb_free=10.3, ema_decay=0.9999, wall=108162
2023-01-07 20:52:37 - progress_bar.py[line:274] - INFO: epoch 001:  26015 / 115845 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, vqa_score=0.4555, wps=71.1, ups=0.33, wpb=109.1, bsz=40, num_updates=25980, lr=4.04026e-05, gnorm=0.166, clip=0, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=108193
2023-01-07 20:53:08 - progress_bar.py[line:274] - INFO: epoch 001:  26025 / 115845 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4495, wps=73.2, ups=0.33, wpb=109.8, bsz=40, num_updates=25990, lr=4.03981e-05, gnorm=0.25, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=108223
2023-01-07 20:53:38 - progress_bar.py[line:274] - INFO: epoch 001:  26035 / 115845 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.4096, wps=72.3, ups=0.33, wpb=110.6, bsz=40, num_updates=26000, lr=4.03936e-05, gnorm=0.227, clip=0, loss_scale=512, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=108254
2023-01-07 20:53:38 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-01-07 20:53:40 - train.py[line:549] - INFO: 0 / 4988
2023-01-07 20:53:40 - train.py[line:551] - INFO: load:1.14 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-01-07 20:53:41 - trainer.py[line:1409] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 39.59 GiB total capacity; 8.81 GiB already allocated; 1.87 GiB free; 29.16 GiB reserved in total by PyTorch)
2023-01-07 20:53:41 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 5            |        cudaMalloc retries: 29        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9019 MB |   10152 MB |   14817 TB |   14817 TB |
|       from large pool |    8845 MB |    9977 MB |   14810 TB |   14810 TB |
|       from small pool |     174 MB |     174 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9019 MB |   10152 MB |   14817 TB |   14817 TB |
|       from large pool |    8845 MB |    9977 MB |   14810 TB |   14810 TB |
|       from small pool |     174 MB |     174 MB |       6 TB |       6 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   29864 MB |   31502 MB |  310048 MB |  280184 MB |
|       from large pool |   29688 MB |   31324 MB |  309596 MB |  279908 MB |
|       from small pool |     176 MB |     178 MB |     452 MB |     276 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   20844 MB |   24778 MB |   17579 TB |   17579 TB |
|       from large pool |   20842 MB |   24775 MB |   17572 TB |   17572 TB |
|       from small pool |       1 MB |       2 MB |       7 TB |       7 TB |
|---------------------------------------------------------------------------|
| Allocations           |    4623    |    4637    |  701611 K  |  701606 K  |
|       from large pool |     698    |     710    |  215840 K  |  215839 K  |
|       from small pool |    3925    |    3943    |  485770 K  |  485767 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    4623    |    4637    |  701611 K  |  701606 K  |
|       from large pool |     698    |     710    |  215840 K  |  215839 K  |
|       from small pool |    3925    |    3943    |  485770 K  |  485767 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     176    |     183    |     674    |     498    |
|       from large pool |      88    |      94    |     448    |     360    |
|       from small pool |      88    |      89    |     226    |     138    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     121    |     123    |  516730 K  |  516729 K  |
|       from large pool |      66    |      66    |  100564 K  |  100564 K  |
|       from small pool |      55    |      63    |  416165 K  |  416165 K  |
|===========================================================================|

2023-01-07 20:53:41 - trainer.py[line:1412] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-01-07 20:53:41 - trainer.py[line:1158] - WARNING: ran out of memory in validation step, retrying batch
2023-01-07 20:57:57 - train.py[line:549] - INFO: 200 / 4988
2023-01-07 20:57:57 - train.py[line:551] - INFO: load:1.17 valid_run:257.29 task_valid:253.25 collect_output:0.57
2023-01-07 21:02:07 - train.py[line:549] - INFO: 400 / 4988
2023-01-07 21:02:07 - train.py[line:551] - INFO: load:1.19 valid_run:507.18 task_valid:500.55 collect_output:1.13
2023-01-07 21:06:17 - train.py[line:549] - INFO: 600 / 4988
2023-01-07 21:06:17 - train.py[line:551] - INFO: load:1.22 valid_run:756.80 task_valid:747.58 collect_output:1.69
2023-01-07 21:10:28 - train.py[line:549] - INFO: 800 / 4988
2023-01-07 21:10:28 - train.py[line:551] - INFO: load:1.25 valid_run:1008.07 task_valid:996.28 collect_output:2.24
2023-01-07 21:14:43 - train.py[line:549] - INFO: 1000 / 4988
2023-01-07 21:14:43 - train.py[line:551] - INFO: load:1.28 valid_run:1262.41 task_valid:1248.06 collect_output:2.80
2023-01-07 21:18:55 - train.py[line:549] - INFO: 1200 / 4988
2023-01-07 21:18:55 - train.py[line:551] - INFO: load:1.31 valid_run:1514.83 task_valid:1497.92 collect_output:3.33
2023-01-07 21:23:08 - train.py[line:549] - INFO: 1400 / 4988
2023-01-07 21:23:08 - train.py[line:551] - INFO: load:1.33 valid_run:1767.85 task_valid:1748.37 collect_output:3.86
2023-01-07 21:27:15 - train.py[line:549] - INFO: 1600 / 4988
2023-01-07 21:27:15 - train.py[line:551] - INFO: load:1.36 valid_run:2014.73 task_valid:1992.67 collect_output:4.39
2023-01-07 21:31:27 - train.py[line:549] - INFO: 1800 / 4988
2023-01-07 21:31:27 - train.py[line:551] - INFO: load:1.39 valid_run:2266.63 task_valid:2242.00 collect_output:4.94
2023-01-07 21:35:36 - train.py[line:549] - INFO: 2000 / 4988
2023-01-07 21:35:36 - train.py[line:551] - INFO: load:1.41 valid_run:2515.90 task_valid:2488.71 collect_output:5.49
2023-01-07 21:39:49 - train.py[line:549] - INFO: 2200 / 4988
2023-01-07 21:39:49 - train.py[line:551] - INFO: load:1.44 valid_run:2767.91 task_valid:2738.13 collect_output:6.04
2023-01-07 21:44:00 - train.py[line:549] - INFO: 2400 / 4988
2023-01-07 21:44:00 - train.py[line:551] - INFO: load:1.47 valid_run:3019.73 task_valid:2987.37 collect_output:6.60
2023-01-07 21:48:08 - train.py[line:549] - INFO: 2600 / 4988
2023-01-07 21:48:09 - train.py[line:551] - INFO: load:1.49 valid_run:3267.72 task_valid:3232.77 collect_output:7.15
2023-01-07 21:52:21 - train.py[line:549] - INFO: 2800 / 4988
2023-01-07 21:52:21 - train.py[line:551] - INFO: load:1.52 valid_run:3520.25 task_valid:3482.71 collect_output:7.72
2023-01-07 21:56:35 - train.py[line:549] - INFO: 3000 / 4988
2023-01-07 21:56:35 - train.py[line:551] - INFO: load:1.55 valid_run:3774.52 task_valid:3734.37 collect_output:8.28
2023-01-07 22:00:46 - train.py[line:549] - INFO: 3200 / 4988
2023-01-07 22:00:46 - train.py[line:551] - INFO: load:1.58 valid_run:4024.63 task_valid:3981.92 collect_output:8.86
2023-01-07 22:04:58 - train.py[line:549] - INFO: 3400 / 4988
2023-01-07 22:04:58 - train.py[line:551] - INFO: load:1.61 valid_run:4276.81 task_valid:4231.53 collect_output:9.43
2023-01-07 22:09:13 - train.py[line:549] - INFO: 3600 / 4988
2023-01-07 22:09:13 - train.py[line:551] - INFO: load:1.63 valid_run:4531.60 task_valid:4483.68 collect_output:10.01
2023-01-07 22:13:21 - train.py[line:549] - INFO: 3800 / 4988
2023-01-07 22:13:21 - train.py[line:551] - INFO: load:1.66 valid_run:4779.32 task_valid:4728.81 collect_output:10.59
2023-01-07 22:17:34 - train.py[line:549] - INFO: 4000 / 4988
2023-01-07 22:17:34 - train.py[line:551] - INFO: load:1.69 valid_run:5032.28 task_valid:4979.16 collect_output:11.16
2023-01-07 22:21:45 - train.py[line:549] - INFO: 4200 / 4988
2023-01-07 22:21:45 - train.py[line:551] - INFO: load:1.72 valid_run:5283.99 task_valid:5228.27 collect_output:11.74
2023-01-07 22:25:57 - train.py[line:549] - INFO: 4400 / 4988
2023-01-07 22:25:57 - train.py[line:551] - INFO: load:1.74 valid_run:5535.67 task_valid:5477.35 collect_output:12.32
2023-01-07 22:30:11 - train.py[line:549] - INFO: 4600 / 4988
2023-01-07 22:30:11 - train.py[line:551] - INFO: load:1.77 valid_run:5789.45 task_valid:5728.53 collect_output:12.90
2023-01-07 22:34:25 - train.py[line:549] - INFO: 4800 / 4988
2023-01-07 22:34:25 - train.py[line:551] - INFO: load:1.80 valid_run:6043.72 task_valid:5980.22 collect_output:13.48

====================================================================================================
SGG eval:     R @ 50: 0.3573;     R @ 100: 0.4264;     R @ 500: 0.4461;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2298;    mR @ 100: 0.2774;    mR @ 500: 0.2991;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3659) (covered in:0.6875) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6667) (playing:0.0000) (riding:0.4526) (says:0.0000) (sitting on:0.6998) (standing on:0.1200) (using:0.7000) (walking in:0.0000) (walking on:0.1622) (watching:0.0972) 
--------------------------------------------------------
====================================================================================================

2023-01-07 22:38:35 - train.py[line:487] - INFO: 0.4263952380952381
2023-01-07 22:38:35 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.3573;     R @ 100: 0.4264;     R @ 500: 0.4461;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2298;    mR @ 100: 0.2774;    mR @ 500: 0.2991;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3659) (covered in:0.6875) (covering:0.3714) (eating:0.5294) (flying in:0.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6667) (playing:0.0000) (riding:0.4526) (says:0.0000) (sitting on:0.6998) (standing on:0.1200) (using:0.7000) (walking in:0.0000) (walking on:0.1622) (watching:0.0972) 
--------------------------------------------------------
====================================================================================================

2023-01-07 22:38:35 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.398 | loss_v1 0 | loss_v2 0 | nll_loss 0.245 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.426395 | ppl 1.18 | vqa_score 0.3333 | wps 71.3 | wpb 89.9 | bsz 30 | num_updates 26000 | best_R@100 0.641887
2023-01-07 22:38:35 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 26000 updates
2023-01-07 22:38:35 - trainer.py[line:472] - INFO: Saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_26000.pt
2023-01-07 22:39:21 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_26000.pt
2023-01-07 22:40:51 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_visualDS_momentum0.995_alpha1.0/1_B20_A1_E1_0.04_5e-5_480/checkpoint_1_26000.pt (epoch 1 @ 26000 updates, score 0.4263952380952381) (writing took 135.7636496629566 seconds)
2023-01-07 22:41:22 - progress_bar.py[line:274] - INFO: epoch 001:  26045 / 115845 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.455, wps=0.3, ups=0, wpb=108.3, bsz=40, num_updates=26010, lr=4.03891e-05, gnorm=0.135, clip=0, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=114717
2023-01-07 22:41:52 - progress_bar.py[line:274] - INFO: epoch 001:  26055 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.5022, wps=71.3, ups=0.33, wpb=108.8, bsz=40, num_updates=26020, lr=4.03846e-05, gnorm=0.359, clip=10, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=114748
2023-01-07 22:42:23 - progress_bar.py[line:274] - INFO: epoch 001:  26065 / 115845 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=107.6, nsentences=40, sample_size=107.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4692, wps=72, ups=0.33, wpb=107.6, bsz=40, num_updates=26030, lr=4.03801e-05, gnorm=0.229, clip=10, loss_scale=512, train_wall=30, gb_free=10.3, ema_decay=0.9999, wall=114778
2023-01-07 22:42:53 - progress_bar.py[line:274] - INFO: epoch 001:  26075 / 115845 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.14, vqa_score=0.4516, wps=72.9, ups=0.34, wpb=108.7, bsz=40, num_updates=26040, lr=4.03756e-05, gnorm=0.197, clip=0, loss_scale=512, train_wall=30, gb_free=10.1, ema_decay=0.9999, wall=114809
2023-01-07 22:43:23 - progress_bar.py[line:274] - INFO: epoch 001:  26085 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.455, wps=72.9, ups=0.33, wpb=108.9, bsz=40, num_updates=26050, lr=4.03711e-05, gnorm=0.233, clip=0, loss_scale=512, train_wall=30, gb_free=10.2, ema_decay=0.9999, wall=114839
2023-01-07 22:43:55 - progress_bar.py[line:274] - INFO: epoch 001:  26095 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.432, wps=71.7, ups=0.33, wpb=109.2, bsz=40, num_updates=26060, lr=4.03666e-05, gnorm=0.23, clip=0, loss_scale=1024, train_wall=30, gb_free=10.4, ema_decay=0.9999, wall=114870
2023-01-07 22:44:26 - progress_bar.py[line:274] - INFO: epoch 001:  26105 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4439, wps=71.5, ups=0.33, wpb=109.7, bsz=40, num_updates=26070, lr=4.03621e-05, gnorm=0.257, clip=0, loss_scale=1024, train_wall=31, gb_free=10.2, ema_decay=0.9999, wall=114901
2023-01-07 22:44:56 - progress_bar.py[line:274] - INFO: epoch 001:  26115 / 115845 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, vqa_score=0.473, wps=73.8, ups=0.34, wpb=109.1, bsz=40, num_updates=26080, lr=4.03576e-05, gnorm=0.234, clip=0, loss_scale=1024, train_wall=30, gb_free=10.7, ema_decay=0.9999, wall=114931
2023-01-07 22:45:27 - progress_bar.py[line:274] - INFO: epoch 001:  26125 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.4948, wps=70.5, ups=0.32, wpb=110, bsz=40, num_updates=26090, lr=4.03531e-05, gnorm=0.17, clip=0, loss_scale=1024, train_wall=31, gb_free=10.4, ema_decay=0.9999, wall=114963
2023-01-07 22:45:33 - trainer.py[line:1002] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-07 22:46:00 - progress_bar.py[line:274] - INFO: epoch 001:  26136 / 115845 loss=inf, loss_v1=0, loss_v2=0, nll_loss=inf, ntokens=109.286, nsentences=40, sample_size=109.286, sample_size_v1=0, sample_size_v2=0, ppl=inf, vqa_score=0.3697, wps=70.9, ups=0.31, wpb=109.3, bsz=40, num_updates=26100, lr=4.03486e-05, gnorm=0.198, clip=0, loss_scale=512, train_wall=32, gb_free=10.2, ema_decay=0.9999, wall=114995
2023-01-07 22:46:31 - progress_bar.py[line:274] - INFO: epoch 001:  26146 / 115845 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, vqa_score=0.4564, wps=70.7, ups=0.33, wpb=108.2, bsz=40, num_updates=26110, lr=4.03441e-05, gnorm=0.182, clip=0, loss_scale=512, train_wall=31, gb_free=9.9, ema_decay=0.9999, wall=115026
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2726614
Killing subprocess 2726615
Main process received SIGINT, exiting
